Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                48        
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Importance Splitting on succruns-v1.
Training for 100000 steps ...
    10/100000: episode: 1, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    20/100000: episode: 2, duration: 0.008s, episode steps: 10, steps per second: 1253, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    30/100000: episode: 3, duration: 0.006s, episode steps: 10, steps per second: 1727, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    40/100000: episode: 4, duration: 0.006s, episode steps: 10, steps per second: 1808, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    50/100000: episode: 5, duration: 0.005s, episode steps: 10, steps per second: 2029, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    60/100000: episode: 6, duration: 0.005s, episode steps: 10, steps per second: 2055, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    70/100000: episode: 7, duration: 0.005s, episode steps: 10, steps per second: 2055, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    80/100000: episode: 8, duration: 0.005s, episode steps: 10, steps per second: 2156, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
    90/100000: episode: 9, duration: 0.005s, episode steps: 10, steps per second: 2113, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   100/100000: episode: 10, duration: 0.005s, episode steps: 10, steps per second: 1908, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   110/100000: episode: 11, duration: 0.005s, episode steps: 10, steps per second: 2068, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   120/100000: episode: 12, duration: 0.005s, episode steps: 10, steps per second: 2080, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   130/100000: episode: 13, duration: 0.005s, episode steps: 10, steps per second: 1875, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   140/100000: episode: 14, duration: 0.005s, episode steps: 10, steps per second: 2132, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   150/100000: episode: 15, duration: 0.005s, episode steps: 10, steps per second: 1883, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   160/100000: episode: 16, duration: 0.005s, episode steps: 10, steps per second: 1992, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   170/100000: episode: 17, duration: 0.005s, episode steps: 10, steps per second: 2204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   180/100000: episode: 18, duration: 0.005s, episode steps: 10, steps per second: 2191, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   190/100000: episode: 19, duration: 0.005s, episode steps: 10, steps per second: 2118, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   200/100000: episode: 20, duration: 0.005s, episode steps: 10, steps per second: 2091, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   210/100000: episode: 21, duration: 0.005s, episode steps: 10, steps per second: 2215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   220/100000: episode: 22, duration: 0.004s, episode steps: 10, steps per second: 2252, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   230/100000: episode: 23, duration: 0.005s, episode steps: 10, steps per second: 1876, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   240/100000: episode: 24, duration: 0.005s, episode steps: 10, steps per second: 2198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   250/100000: episode: 25, duration: 0.005s, episode steps: 10, steps per second: 2065, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   260/100000: episode: 26, duration: 0.005s, episode steps: 10, steps per second: 2082, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   270/100000: episode: 27, duration: 0.005s, episode steps: 10, steps per second: 2103, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   280/100000: episode: 28, duration: 0.005s, episode steps: 10, steps per second: 1989, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   290/100000: episode: 29, duration: 0.005s, episode steps: 10, steps per second: 2071, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   300/100000: episode: 30, duration: 0.005s, episode steps: 10, steps per second: 2135, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   310/100000: episode: 31, duration: 0.004s, episode steps: 10, steps per second: 2244, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   320/100000: episode: 32, duration: 0.005s, episode steps: 10, steps per second: 2107, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   330/100000: episode: 33, duration: 0.005s, episode steps: 10, steps per second: 2184, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   340/100000: episode: 34, duration: 0.005s, episode steps: 10, steps per second: 1984, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   350/100000: episode: 35, duration: 0.005s, episode steps: 10, steps per second: 2156, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   360/100000: episode: 36, duration: 0.005s, episode steps: 10, steps per second: 1884, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   370/100000: episode: 37, duration: 0.005s, episode steps: 10, steps per second: 2194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   380/100000: episode: 38, duration: 0.005s, episode steps: 10, steps per second: 2090, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   390/100000: episode: 39, duration: 0.004s, episode steps: 10, steps per second: 2226, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   400/100000: episode: 40, duration: 0.005s, episode steps: 10, steps per second: 2219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   410/100000: episode: 41, duration: 0.005s, episode steps: 10, steps per second: 2138, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   420/100000: episode: 42, duration: 0.005s, episode steps: 10, steps per second: 2201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   430/100000: episode: 43, duration: 0.005s, episode steps: 10, steps per second: 2123, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   440/100000: episode: 44, duration: 0.008s, episode steps: 10, steps per second: 1185, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   450/100000: episode: 45, duration: 0.006s, episode steps: 10, steps per second: 1611, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   460/100000: episode: 46, duration: 0.005s, episode steps: 10, steps per second: 2176, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   470/100000: episode: 47, duration: 0.005s, episode steps: 10, steps per second: 2153, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   480/100000: episode: 48, duration: 0.005s, episode steps: 10, steps per second: 2192, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   490/100000: episode: 49, duration: 0.004s, episode steps: 10, steps per second: 2248, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   500/100000: episode: 50, duration: 0.005s, episode steps: 10, steps per second: 2127, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   510/100000: episode: 51, duration: 0.651s, episode steps: 10, steps per second: 15, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.054169, mae: 0.215812, mean_q: 0.411850
   520/100000: episode: 52, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.031497, mae: 0.155385, mean_q: 0.256906
   530/100000: episode: 53, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.017423, mae: 0.140908, mean_q: 0.177094
   540/100000: episode: 54, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.018250, mae: 0.127872, mean_q: 0.182700
   550/100000: episode: 55, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.018351, mae: 0.129214, mean_q: 0.199092
   560/100000: episode: 56, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.010317, mae: 0.104443, mean_q: 0.151442
   570/100000: episode: 57, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.009837, mae: 0.087250, mean_q: 0.176353
   580/100000: episode: 58, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.008280, mae: 0.085012, mean_q: 0.156704
   590/100000: episode: 59, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.007089, mae: 0.080809, mean_q: 0.140971
   600/100000: episode: 60, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.007006, mae: 0.076337, mean_q: 0.144976
   610/100000: episode: 61, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.005258, mae: 0.072827, mean_q: 0.127612
   620/100000: episode: 62, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.004066, mae: 0.060885, mean_q: 0.121717
   630/100000: episode: 63, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.003822, mae: 0.057001, mean_q: 0.126313
   640/100000: episode: 64, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.003254, mae: 0.056871, mean_q: 0.101016
   650/100000: episode: 65, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002644, mae: 0.049767, mean_q: 0.105570
   660/100000: episode: 66, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002737, mae: 0.046926, mean_q: 0.112113
   670/100000: episode: 67, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.002192, mae: 0.045901, mean_q: 0.094784
   680/100000: episode: 68, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001872, mae: 0.042313, mean_q: 0.084535
   690/100000: episode: 69, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001881, mae: 0.040079, mean_q: 0.091917
   700/100000: episode: 70, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001402, mae: 0.036716, mean_q: 0.083616
   710/100000: episode: 71, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001583, mae: 0.041271, mean_q: 0.074739
   720/100000: episode: 72, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.001147, mae: 0.034719, mean_q: 0.071719
   730/100000: episode: 73, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001137, mae: 0.032349, mean_q: 0.075336
   740/100000: episode: 74, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001021, mae: 0.032236, mean_q: 0.067757
   750/100000: episode: 75, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000943, mae: 0.031158, mean_q: 0.067961
   760/100000: episode: 76, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000693, mae: 0.026411, mean_q: 0.061836
   770/100000: episode: 77, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000579, mae: 0.023181, mean_q: 0.061381
   780/100000: episode: 78, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000525, mae: 0.023179, mean_q: 0.056283
   790/100000: episode: 79, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000611, mae: 0.025353, mean_q: 0.046775
   800/100000: episode: 80, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000497, mae: 0.022574, mean_q: 0.050760
   810/100000: episode: 81, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000434, mae: 0.021642, mean_q: 0.042975
   820/100000: episode: 82, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000357, mae: 0.020257, mean_q: 0.041483
   830/100000: episode: 83, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000311, mae: 0.017829, mean_q: 0.042749
   840/100000: episode: 84, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000202, mae: 0.014400, mean_q: 0.042436
   850/100000: episode: 85, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000261, mae: 0.015987, mean_q: 0.038557
   860/100000: episode: 86, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000209, mae: 0.014668, mean_q: 0.035005
   870/100000: episode: 87, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000172, mae: 0.013216, mean_q: 0.034573
   880/100000: episode: 88, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000158, mae: 0.013160, mean_q: 0.030948
   890/100000: episode: 89, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000245, mae: 0.014316, mean_q: 0.031380
   900/100000: episode: 90, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000150, mae: 0.012060, mean_q: 0.027497
   910/100000: episode: 91, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000173, mae: 0.012864, mean_q: 0.027055
   920/100000: episode: 92, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000108, mae: 0.010063, mean_q: 0.028432
   930/100000: episode: 93, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000072, mae: 0.008819, mean_q: 0.025652
   940/100000: episode: 94, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000450, mae: 0.011924, mean_q: 0.025280
   950/100000: episode: 95, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000346, mae: 0.011189, mean_q: 0.026368
   960/100000: episode: 96, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000313, mae: 0.011033, mean_q: 0.023009
   970/100000: episode: 97, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000096, mae: 0.008359, mean_q: 0.022786
   980/100000: episode: 98, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000078, mae: 0.008446, mean_q: 0.019286
   990/100000: episode: 99, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000070, mae: 0.008592, mean_q: 0.018225
  1000/100000: episode: 100, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000089, mae: 0.008350, mean_q: 0.018256
  1010/100000: episode: 101, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000058, mae: 0.007483, mean_q: 0.016891
  1020/100000: episode: 102, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000071, mae: 0.006541, mean_q: 0.017431
  1030/100000: episode: 103, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000084, mae: 0.007711, mean_q: 0.016268
  1040/100000: episode: 104, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000051, mae: 0.006843, mean_q: 0.014833
  1050/100000: episode: 105, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000066, mae: 0.006573, mean_q: 0.016344
  1060/100000: episode: 106, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000254, mae: 0.007440, mean_q: 0.015360
  1070/100000: episode: 107, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000307, mae: 0.009244, mean_q: 0.017520
  1080/100000: episode: 108, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000207, mae: 0.007684, mean_q: 0.016825
  1090/100000: episode: 109, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000087, mae: 0.006628, mean_q: 0.014744
  1100/100000: episode: 110, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000030, mae: 0.005469, mean_q: 0.014983
  1110/100000: episode: 111, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000235, mae: 0.006355, mean_q: 0.012260
  1120/100000: episode: 112, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000245, mae: 0.007373, mean_q: 0.013913
  1130/100000: episode: 113, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000055, mae: 0.005447, mean_q: 0.011132
  1140/100000: episode: 114, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000030, mae: 0.005205, mean_q: 0.010862
  1150/100000: episode: 115, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000280, mae: 0.007244, mean_q: 0.012306
  1160/100000: episode: 116, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000244, mae: 0.006178, mean_q: 0.009864
  1170/100000: episode: 117, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000050, mae: 0.006127, mean_q: 0.012821
  1180/100000: episode: 118, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000225, mae: 0.007166, mean_q: 0.012220
  1190/100000: episode: 119, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000039, mae: 0.005537, mean_q: 0.009309
  1200/100000: episode: 120, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000025, mae: 0.005098, mean_q: 0.007807
  1210/100000: episode: 121, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000449, mae: 0.008124, mean_q: 0.010011
  1220/100000: episode: 122, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000087, mae: 0.007964, mean_q: 0.011782
  1230/100000: episode: 123, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000032, mae: 0.004867, mean_q: 0.008058
  1240/100000: episode: 124, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000045, mae: 0.004777, mean_q: 0.007678
  1250/100000: episode: 125, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000217, mae: 0.005772, mean_q: 0.008065
  1260/100000: episode: 126, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000232, mae: 0.007284, mean_q: 0.011213
  1270/100000: episode: 127, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000228, mae: 0.006724, mean_q: 0.010496
  1280/100000: episode: 128, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000249, mae: 0.006139, mean_q: 0.007616
  1290/100000: episode: 129, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000253, mae: 0.006673, mean_q: 0.009124
  1300/100000: episode: 130, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000081, mae: 0.005798, mean_q: 0.007780
  1310/100000: episode: 131, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000028, mae: 0.004257, mean_q: 0.007387
  1320/100000: episode: 132, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.003903, mean_q: 0.005465
  1330/100000: episode: 133, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000048, mae: 0.004492, mean_q: 0.006408
  1340/100000: episode: 134, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000050, mae: 0.004563, mean_q: 0.006116
  1350/100000: episode: 135, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000029, mae: 0.004505, mean_q: 0.006609
  1360/100000: episode: 136, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000030, mae: 0.004116, mean_q: 0.005018
  1370/100000: episode: 137, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000043, mae: 0.004087, mean_q: 0.005199
  1380/100000: episode: 138, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000052, mae: 0.004355, mean_q: 0.006323
  1390/100000: episode: 139, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000043, mae: 0.003972, mean_q: 0.006009
  1400/100000: episode: 140, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000408, mae: 0.007071, mean_q: 0.008918
  1410/100000: episode: 141, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000273, mae: 0.007223, mean_q: 0.008831
  1420/100000: episode: 142, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000041, mae: 0.003909, mean_q: 0.004647
  1430/100000: episode: 143, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000212, mae: 0.004757, mean_q: 0.004732
  1440/100000: episode: 144, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000216, mae: 0.005563, mean_q: 0.007448
  1450/100000: episode: 145, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000192, mae: 0.005418, mean_q: 0.005361
  1460/100000: episode: 146, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000066, mae: 0.004712, mean_q: 0.006842
  1470/100000: episode: 147, duration: 0.082s, episode steps: 10, steps per second: 121, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000061, mae: 0.004333, mean_q: 0.004741
  1480/100000: episode: 148, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000032, mae: 0.004075, mean_q: 0.005716
  1490/100000: episode: 149, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000053, mae: 0.004168, mean_q: 0.005763
[Info] 1-TH LEVEL FOUND: 0.17332354187965393, Considering 99/100 traces
  1500/100000: episode: 150, duration: 1.203s, episode steps: 10, steps per second: 8, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000043, mae: 0.004267, mean_q: 0.004395
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.17332354187965393
  1501/100000: episode: 151, duration: 0.990s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000030, mae: 0.004872, mean_q: 0.006497
  1511/100000: episode: 152, duration: 0.106s, episode steps: 10, steps per second: 94, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000031, mae: 0.003640, mean_q: 0.003865
  1521/100000: episode: 153, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000018, mae: 0.003387, mean_q: 0.003469
  1531/100000: episode: 154, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000314, mae: 0.005352, mean_q: 0.005202
  1541/100000: episode: 155, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000062, mae: 0.005798, mean_q: 0.007709
  1551/100000: episode: 156, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000282, mae: 0.005749, mean_q: 0.007125
  1561/100000: episode: 157, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000032, mae: 0.004874, mean_q: 0.003845
  1571/100000: episode: 158, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000027, mae: 0.004149, mean_q: 0.003041
  1581/100000: episode: 159, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.004049, mean_q: 0.004606
  1591/100000: episode: 160, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000051, mae: 0.004450, mean_q: 0.005113
  1601/100000: episode: 161, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.003505, mean_q: 0.004464
  1611/100000: episode: 162, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000039, mae: 0.003535, mean_q: 0.003564
  1621/100000: episode: 163, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000183, mae: 0.005412, mean_q: 0.006999
  1631/100000: episode: 164, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000035, mae: 0.004567, mean_q: 0.005034
  1641/100000: episode: 165, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000011, mae: 0.002672, mean_q: 0.002667
  1651/100000: episode: 166, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.003202, mean_q: 0.002850
  1661/100000: episode: 167, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000212, mae: 0.004325, mean_q: 0.003358
  1671/100000: episode: 168, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000018, mae: 0.003402, mean_q: 0.004189
  1681/100000: episode: 169, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000320, mae: 0.006447, mean_q: 0.008014
  1691/100000: episode: 170, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000079, mae: 0.005718, mean_q: 0.006907
  1701/100000: episode: 171, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000214, mae: 0.005055, mean_q: 0.005298
  1711/100000: episode: 172, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000040, mae: 0.003997, mean_q: 0.003804
  1721/100000: episode: 173, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000024, mae: 0.003288, mean_q: 0.003924
  1731/100000: episode: 174, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000041, mae: 0.004339, mean_q: 0.002649
  1741/100000: episode: 175, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000075, mae: 0.004482, mean_q: 0.004596
  1751/100000: episode: 176, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000064, mae: 0.004586, mean_q: 0.005079
  1761/100000: episode: 177, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000210, mae: 0.005003, mean_q: 0.005466
  1771/100000: episode: 178, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000048, mae: 0.004051, mean_q: 0.005568
  1781/100000: episode: 179, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000282, mae: 0.005905, mean_q: 0.006354
  1791/100000: episode: 180, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000151, mae: 0.005022, mean_q: 0.005373
  1801/100000: episode: 181, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000047, mae: 0.003805, mean_q: 0.004237
  1811/100000: episode: 182, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000058, mae: 0.004317, mean_q: 0.003584
  1821/100000: episode: 183, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.003644, mean_q: 0.004140
  1831/100000: episode: 184, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.003030, mean_q: 0.003086
  1841/100000: episode: 185, duration: 0.097s, episode steps: 10, steps per second: 104, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000078, mae: 0.004678, mean_q: 0.004322
  1851/100000: episode: 186, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000012, mae: 0.002739, mean_q: 0.003632
  1861/100000: episode: 187, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000034, mae: 0.003376, mean_q: 0.004743
  1871/100000: episode: 188, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000135, mae: 0.003507, mean_q: 0.004762
  1881/100000: episode: 189, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000068, mae: 0.005418, mean_q: 0.006952
  1891/100000: episode: 190, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000038, mae: 0.004198, mean_q: 0.005641
  1901/100000: episode: 191, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000027, mae: 0.003313, mean_q: 0.002592
  1911/100000: episode: 192, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003008, mean_q: 0.002886
  1921/100000: episode: 193, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000281, mae: 0.006627, mean_q: 0.006470
  1931/100000: episode: 194, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.004180, mean_q: 0.003017
  1941/100000: episode: 195, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000019, mae: 0.003380, mean_q: 0.003491
  1951/100000: episode: 196, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000020, mae: 0.003021, mean_q: 0.003330
  1961/100000: episode: 197, duration: 0.105s, episode steps: 10, steps per second: 96, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000035, mae: 0.003178, mean_q: 0.003679
  1971/100000: episode: 198, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000048, mae: 0.003729, mean_q: 0.004638
  1981/100000: episode: 199, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000028, mae: 0.003519, mean_q: 0.004912
  1991/100000: episode: 200, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000072, mae: 0.004109, mean_q: 0.004395
  2001/100000: episode: 201, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000009, mae: 0.002674, mean_q: 0.003488
  2011/100000: episode: 202, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000054, mae: 0.004974, mean_q: 0.007045
  2021/100000: episode: 203, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000144, mae: 0.005131, mean_q: 0.006458
  2031/100000: episode: 204, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000038, mae: 0.003835, mean_q: 0.003037
  2041/100000: episode: 205, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000084, mae: 0.004382, mean_q: 0.005000
  2051/100000: episode: 206, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000192, mae: 0.006342, mean_q: 0.008053
  2061/100000: episode: 207, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000051, mae: 0.005570, mean_q: 0.005825
  2071/100000: episode: 208, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000135, mae: 0.004318, mean_q: 0.004401
  2081/100000: episode: 209, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000215, mae: 0.004947, mean_q: 0.004785
  2091/100000: episode: 210, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000043, mae: 0.003917, mean_q: 0.004503
  2101/100000: episode: 211, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000022, mae: 0.003398, mean_q: 0.004128
  2111/100000: episode: 212, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000159, mae: 0.004838, mean_q: 0.005125
  2121/100000: episode: 213, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000055, mae: 0.004926, mean_q: 0.005259
  2131/100000: episode: 214, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000214, mae: 0.004759, mean_q: 0.005109
  2141/100000: episode: 215, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000058, mae: 0.004788, mean_q: 0.004880
  2151/100000: episode: 216, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000055, mae: 0.004476, mean_q: 0.004459
  2161/100000: episode: 217, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000017, mae: 0.003279, mean_q: 0.003636
  2171/100000: episode: 218, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000035, mae: 0.003111, mean_q: 0.003806
  2181/100000: episode: 219, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000059, mae: 0.004455, mean_q: 0.005461
  2191/100000: episode: 220, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000028, mae: 0.003240, mean_q: 0.003444
  2201/100000: episode: 221, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000052, mae: 0.003595, mean_q: 0.003335
  2211/100000: episode: 222, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000155, mae: 0.004613, mean_q: 0.004959
  2221/100000: episode: 223, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000132, mae: 0.005610, mean_q: 0.007346
  2231/100000: episode: 224, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000063, mae: 0.004798, mean_q: 0.004413
  2241/100000: episode: 225, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.003035, mean_q: 0.002672
  2251/100000: episode: 226, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000011, mae: 0.002967, mean_q: 0.003629
  2261/100000: episode: 227, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000201, mae: 0.004209, mean_q: 0.004910
  2271/100000: episode: 228, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000041, mae: 0.004170, mean_q: 0.004559
  2281/100000: episode: 229, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000009, mae: 0.002503, mean_q: 0.003734
  2291/100000: episode: 230, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000242, mae: 0.005096, mean_q: 0.005856
  2301/100000: episode: 231, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000053, mae: 0.005090, mean_q: 0.006744
  2311/100000: episode: 232, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000049, mae: 0.004439, mean_q: 0.004660
  2321/100000: episode: 233, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000194, mae: 0.004620, mean_q: 0.003521
  2331/100000: episode: 234, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000170, mae: 0.005899, mean_q: 0.006648
  2341/100000: episode: 235, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000040, mae: 0.004351, mean_q: 0.005815
  2351/100000: episode: 236, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000040, mae: 0.004144, mean_q: 0.003932
  2361/100000: episode: 237, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000062, mae: 0.003821, mean_q: 0.003148
  2371/100000: episode: 238, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.002428, mean_q: 0.002648
  2381/100000: episode: 239, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000023, mae: 0.002841, mean_q: 0.003533
  2391/100000: episode: 240, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000032, mae: 0.003384, mean_q: 0.003755
  2401/100000: episode: 241, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000063, mae: 0.003553, mean_q: 0.004413
  2411/100000: episode: 242, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003793, mean_q: 0.006035
  2421/100000: episode: 243, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000202, mae: 0.004776, mean_q: 0.004889
  2431/100000: episode: 244, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003677, mean_q: 0.005460
  2441/100000: episode: 245, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.002860, mean_q: 0.003797
  2451/100000: episode: 246, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000048, mae: 0.003581, mean_q: 0.004003
  2461/100000: episode: 247, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000035, mae: 0.002943, mean_q: 0.003798
  2471/100000: episode: 248, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000144, mae: 0.005547, mean_q: 0.006907
  2481/100000: episode: 249, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000075, mae: 0.005060, mean_q: 0.006242
  2491/100000: episode: 250, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000042, mae: 0.003584, mean_q: 0.003434
[Info] 1-TH LEVEL FOUND: 0.045643437653779984, Considering 12/100 traces
  2501/100000: episode: 251, duration: 0.698s, episode steps: 10, steps per second: 14, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000089, mae: 0.004598, mean_q: 0.004089
  2507/100000: episode: 252, duration: 0.040s, episode steps: 6, steps per second: 150, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000270, mae: 0.004651, mean_q: 0.003404
  2511/100000: episode: 253, duration: 0.030s, episode steps: 4, steps per second: 134, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000055, mae: 0.005570, mean_q: 0.008167
  2513/100000: episode: 254, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000049, mae: 0.005542, mean_q: 0.005143
  2519/100000: episode: 255, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000051, mae: 0.004490, mean_q: 0.003731
  2521/100000: episode: 256, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000016, mae: 0.004103, mean_q: 0.005007
  2527/100000: episode: 257, duration: 0.028s, episode steps: 6, steps per second: 211, episode reward: 0.136, mean reward: 0.023 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000197, mae: 0.004756, mean_q: 0.005109
  2529/100000: episode: 258, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000016, mae: 0.003995, mean_q: 0.006322
  2531/100000: episode: 259, duration: 0.012s, episode steps: 2, steps per second: 168, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000145, mae: 0.005663, mean_q: 0.007073
  2533/100000: episode: 260, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000039, mae: 0.005706, mean_q: 0.005758
  2537/100000: episode: 261, duration: 0.020s, episode steps: 4, steps per second: 199, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000393, mae: 0.007945, mean_q: 0.005731
  2543/100000: episode: 262, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000086, mae: 0.006828, mean_q: 0.008435
  2549/100000: episode: 263, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000066, mae: 0.004972, mean_q: 0.001816
  2553/100000: episode: 264, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000045, mae: 0.005148, mean_q: 0.005389
  2555/100000: episode: 265, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000027, mae: 0.004374, mean_q: 0.001898
  2557/100000: episode: 266, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000184, mae: 0.006518, mean_q: 0.004070
[Info] FALSIFICATION!
  2562/100000: episode: 267, duration: 0.370s, episode steps: 5, steps per second: 14, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000032, mae: 0.005077, mean_q: 0.007362
  2564/100000: episode: 268, duration: 0.033s, episode steps: 2, steps per second: 60, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000028, mae: 0.005414, mean_q: 0.002017
  2566/100000: episode: 269, duration: 0.017s, episode steps: 2, steps per second: 118, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000085, mae: 0.003568, mean_q: 0.003645
  2568/100000: episode: 270, duration: 0.018s, episode steps: 2, steps per second: 113, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000067, mae: 0.007168, mean_q: 0.010468
  2570/100000: episode: 271, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000132, mae: 0.006191, mean_q: 0.006997
  2576/100000: episode: 272, duration: 0.042s, episode steps: 6, steps per second: 142, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000220, mae: 0.005770, mean_q: 0.005245
  2578/100000: episode: 273, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000029, mae: 0.004645, mean_q: 0.007289
  2580/100000: episode: 274, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000073, mae: 0.005357, mean_q: 0.005194
  2582/100000: episode: 275, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000192, mae: 0.007333, mean_q: 0.005788
  2586/100000: episode: 276, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000051, mae: 0.005323, mean_q: 0.007701
  2592/100000: episode: 277, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000369, mae: 0.006231, mean_q: 0.003873
  2598/100000: episode: 278, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000112, mae: 0.005635, mean_q: 0.005662
  2600/100000: episode: 279, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000047, mae: 0.004776, mean_q: 0.005610
  2604/100000: episode: 280, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000100, mae: 0.005935, mean_q: 0.005532
  2606/100000: episode: 281, duration: 0.012s, episode steps: 2, steps per second: 167, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000048, mae: 0.004103, mean_q: 0.005576
  2608/100000: episode: 282, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000011, mae: 0.002957, mean_q: 0.005506
  2610/100000: episode: 283, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000924, mae: 0.009541, mean_q: 0.005530
  2612/100000: episode: 284, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000145, mae: 0.006542, mean_q: 0.007770
  2614/100000: episode: 285, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000035, mae: 0.004046, mean_q: 0.005652
  2616/100000: episode: 286, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000063, mae: 0.005518, mean_q: 0.007756
  2618/100000: episode: 287, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000005, mae: 0.002530, mean_q: 0.003172
  2620/100000: episode: 288, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000177, mae: 0.007923, mean_q: 0.008189
  2626/100000: episode: 289, duration: 0.035s, episode steps: 6, steps per second: 173, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000048, mae: 0.004130, mean_q: 0.004549
  2628/100000: episode: 290, duration: 0.018s, episode steps: 2, steps per second: 112, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000045, mae: 0.003781, mean_q: 0.003762
  2630/100000: episode: 291, duration: 0.016s, episode steps: 2, steps per second: 126, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000043, mae: 0.003973, mean_q: 0.005829
  2632/100000: episode: 292, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000022, mae: 0.003382, mean_q: 0.004371
  2638/100000: episode: 293, duration: 0.035s, episode steps: 6, steps per second: 173, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000020, mae: 0.003231, mean_q: 0.002635
  2644/100000: episode: 294, duration: 0.040s, episode steps: 6, steps per second: 152, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000034, mae: 0.003887, mean_q: 0.003837
  2650/100000: episode: 295, duration: 0.044s, episode steps: 6, steps per second: 136, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000033, mae: 0.003791, mean_q: 0.002614
  2654/100000: episode: 296, duration: 0.024s, episode steps: 4, steps per second: 168, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000336, mae: 0.006191, mean_q: 0.005047
  2660/100000: episode: 297, duration: 0.046s, episode steps: 6, steps per second: 131, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000070, mae: 0.004505, mean_q: 0.005327
  2664/100000: episode: 298, duration: 0.035s, episode steps: 4, steps per second: 114, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000412, mae: 0.006911, mean_q: 0.008097
  2666/100000: episode: 299, duration: 0.020s, episode steps: 2, steps per second: 99, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000259, mae: 0.011906, mean_q: 0.015663
  2670/100000: episode: 300, duration: 0.031s, episode steps: 4, steps per second: 127, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000448, mae: 0.016597, mean_q: 0.014673
  2676/100000: episode: 301, duration: 0.044s, episode steps: 6, steps per second: 136, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000118, mae: 0.009441, mean_q: 0.002233
  2678/100000: episode: 302, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000078, mae: 0.008090, mean_q: 0.007578
  2680/100000: episode: 303, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001509, mae: 0.014106, mean_q: 0.000395
  2682/100000: episode: 304, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006880, mae: 0.019013, mean_q: 0.000723
  2688/100000: episode: 305, duration: 0.035s, episode steps: 6, steps per second: 170, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000252, mae: 0.012839, mean_q: 0.014370
  2694/100000: episode: 306, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000214, mae: 0.011529, mean_q: 0.006234
  2700/100000: episode: 307, duration: 0.049s, episode steps: 6, steps per second: 124, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.002187, mae: 0.011057, mean_q: 0.005702
  2706/100000: episode: 308, duration: 0.036s, episode steps: 6, steps per second: 166, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000117, mae: 0.006776, mean_q: 0.008420
  2708/100000: episode: 309, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000042, mae: 0.004372, mean_q: 0.004910
  2710/100000: episode: 310, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000038, mae: 0.005236, mean_q: 0.004592
  2712/100000: episode: 311, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000871, mae: 0.010427, mean_q: 0.005694
  2716/100000: episode: 312, duration: 0.032s, episode steps: 4, steps per second: 124, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003115, mae: 0.013111, mean_q: 0.008995
  2722/100000: episode: 313, duration: 0.045s, episode steps: 6, steps per second: 134, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000409, mae: 0.010289, mean_q: 0.012153
  2724/100000: episode: 314, duration: 0.018s, episode steps: 2, steps per second: 110, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000214, mae: 0.012260, mean_q: 0.008410
  2726/100000: episode: 315, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000128, mae: 0.007276, mean_q: 0.004233
  2732/100000: episode: 316, duration: 0.054s, episode steps: 6, steps per second: 110, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000070, mae: 0.006445, mean_q: 0.006659
  2738/100000: episode: 317, duration: 0.046s, episode steps: 6, steps per second: 130, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000116, mae: 0.006777, mean_q: 0.001408
  2740/100000: episode: 318, duration: 0.019s, episode steps: 2, steps per second: 104, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000082, mae: 0.006628, mean_q: 0.005986
  2742/100000: episode: 319, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000914, mae: 0.008561, mean_q: 0.006716
  2744/100000: episode: 320, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000024, mae: 0.003364, mean_q: 0.005856
  2748/100000: episode: 321, duration: 0.034s, episode steps: 4, steps per second: 117, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000054, mae: 0.005432, mean_q: 0.006250
  2750/100000: episode: 322, duration: 0.019s, episode steps: 2, steps per second: 103, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000075, mae: 0.006583, mean_q: 0.011219
  2754/100000: episode: 323, duration: 0.033s, episode steps: 4, steps per second: 122, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000536, mae: 0.011363, mean_q: 0.013706
  2756/100000: episode: 324, duration: 0.017s, episode steps: 2, steps per second: 120, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000014, mae: 0.002846, mean_q: 0.004446
  2762/100000: episode: 325, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000089, mae: 0.006214, mean_q: 0.008648
  2764/100000: episode: 326, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000031, mae: 0.004248, mean_q: 0.007237
  2766/100000: episode: 327, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000506, mae: 0.009582, mean_q: 0.010002
  2768/100000: episode: 328, duration: 0.014s, episode steps: 2, steps per second: 142, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000040, mae: 0.003531, mean_q: 0.001111
  2774/100000: episode: 329, duration: 0.034s, episode steps: 6, steps per second: 176, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000652, mae: 0.008236, mean_q: 0.005238
  2780/100000: episode: 330, duration: 0.033s, episode steps: 6, steps per second: 180, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000285, mae: 0.009098, mean_q: 0.009258
  2784/100000: episode: 331, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.003115, mae: 0.013318, mean_q: 0.011074
  2786/100000: episode: 332, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000287, mae: 0.013189, mean_q: 0.020659
  2788/100000: episode: 333, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000151, mae: 0.008264, mean_q: 0.009209
  2794/100000: episode: 334, duration: 0.033s, episode steps: 6, steps per second: 184, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000110, mae: 0.008452, mean_q: 0.003943
  2798/100000: episode: 335, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000076, mae: 0.006160, mean_q: 0.005794
  2804/100000: episode: 336, duration: 0.033s, episode steps: 6, steps per second: 183, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.002539, mae: 0.013205, mean_q: 0.006689
  2806/100000: episode: 337, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000107, mae: 0.006503, mean_q: 0.010328
  2812/100000: episode: 338, duration: 0.033s, episode steps: 6, steps per second: 182, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002091, mae: 0.017008, mean_q: 0.017434
[Info] Complete ISplit Iteration
[Info] Levels: [0.045643438, 0.1686216]
[Info] Cond. Prob: [0.12, 0.01]
[Info] Error Prob: 0.0012

  2816/100000: episode: 339, duration: 0.965s, episode steps: 4, steps per second: 4, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000260, mae: 0.011385, mean_q: 0.005754
  2826/100000: episode: 340, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000131, mae: 0.007079, mean_q: 0.003159
  2836/100000: episode: 341, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001520, mae: 0.012659, mean_q: 0.007501
  2846/100000: episode: 342, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001439, mae: 0.016684, mean_q: 0.014361
  2856/100000: episode: 343, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000200, mae: 0.011320, mean_q: 0.006651
  2866/100000: episode: 344, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000333, mae: 0.010764, mean_q: 0.008923
  2876/100000: episode: 345, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002789, mae: 0.024682, mean_q: 0.019541
  2886/100000: episode: 346, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000175, mae: 0.009600, mean_q: 0.004356
  2896/100000: episode: 347, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000248, mae: 0.008567, mean_q: 0.001347
  2906/100000: episode: 348, duration: 0.114s, episode steps: 10, steps per second: 87, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000226, mae: 0.011582, mean_q: 0.010964
  2916/100000: episode: 349, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000126, mae: 0.007409, mean_q: 0.007890
  2926/100000: episode: 350, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002592, mae: 0.015143, mean_q: 0.012248
  2936/100000: episode: 351, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000418, mae: 0.014455, mean_q: 0.012161
  2946/100000: episode: 352, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000142, mae: 0.007519, mean_q: 0.002935
  2956/100000: episode: 353, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000702, mae: 0.012910, mean_q: 0.010510
  2966/100000: episode: 354, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000162, mae: 0.008872, mean_q: 0.009901
  2976/100000: episode: 355, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000088, mae: 0.006286, mean_q: 0.004974
  2986/100000: episode: 356, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000238, mae: 0.006882, mean_q: 0.006370
  2996/100000: episode: 357, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000370, mae: 0.009913, mean_q: 0.011638
  3006/100000: episode: 358, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000240, mae: 0.008197, mean_q: 0.007502
  3016/100000: episode: 359, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000115, mae: 0.006214, mean_q: 0.005266
  3026/100000: episode: 360, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001367, mae: 0.011971, mean_q: 0.010756
  3036/100000: episode: 361, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000313, mae: 0.012955, mean_q: 0.009595
  3046/100000: episode: 362, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000148, mae: 0.008341, mean_q: 0.004130
  3056/100000: episode: 363, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001641, mae: 0.016537, mean_q: 0.013418
  3066/100000: episode: 364, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000345, mae: 0.013734, mean_q: 0.009586
  3076/100000: episode: 365, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000118, mae: 0.008556, mean_q: 0.001499
  3086/100000: episode: 366, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000238, mae: 0.008138, mean_q: 0.004526
  3096/100000: episode: 367, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000269, mae: 0.008178, mean_q: 0.007669
  3106/100000: episode: 368, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001346, mae: 0.012116, mean_q: 0.013025
  3116/100000: episode: 369, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001262, mae: 0.012710, mean_q: 0.010479
  3126/100000: episode: 370, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000192, mae: 0.009134, mean_q: 0.008027
  3136/100000: episode: 371, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000278, mae: 0.007825, mean_q: 0.004601
  3146/100000: episode: 372, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000118, mae: 0.007341, mean_q: 0.004901
[Info] FALSIFICATION!
  3156/100000: episode: 373, duration: 0.359s, episode steps: 10, steps per second: 28, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.001312, mae: 0.009431, mean_q: 0.009870
  3166/100000: episode: 374, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000215, mae: 0.009267, mean_q: 0.010625
  3176/100000: episode: 375, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001253, mae: 0.009099, mean_q: 0.005615
  3186/100000: episode: 376, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000069, mae: 0.006243, mean_q: 0.005741
  3196/100000: episode: 377, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000105, mae: 0.005693, mean_q: 0.006909
  3206/100000: episode: 378, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000081, mae: 0.005451, mean_q: 0.005931
  3216/100000: episode: 379, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000178, mae: 0.007416, mean_q: 0.008219
  3226/100000: episode: 380, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000134, mae: 0.006650, mean_q: 0.008532
  3236/100000: episode: 381, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001282, mae: 0.008994, mean_q: 0.008555
  3246/100000: episode: 382, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000204, mae: 0.008712, mean_q: 0.010898
  3256/100000: episode: 383, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000083, mae: 0.005813, mean_q: 0.004208
  3266/100000: episode: 384, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000402, mae: 0.008316, mean_q: 0.004834
  3276/100000: episode: 385, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000310, mae: 0.008826, mean_q: 0.009642
  3286/100000: episode: 386, duration: 0.125s, episode steps: 10, steps per second: 80, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000107, mae: 0.007020, mean_q: 0.008394
  3296/100000: episode: 387, duration: 0.097s, episode steps: 10, steps per second: 104, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000278, mae: 0.007944, mean_q: 0.008503
  3306/100000: episode: 388, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000124, mae: 0.006819, mean_q: 0.007337
  3316/100000: episode: 389, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001211, mae: 0.009051, mean_q: 0.007017
  3326/100000: episode: 390, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000185, mae: 0.009321, mean_q: 0.009888
  3336/100000: episode: 391, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000325, mae: 0.007836, mean_q: 0.009229
  3346/100000: episode: 392, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000239, mae: 0.008020, mean_q: 0.007111
  3356/100000: episode: 393, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000132, mae: 0.006701, mean_q: 0.005975
  3366/100000: episode: 394, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000083, mae: 0.006642, mean_q: 0.007757
  3376/100000: episode: 395, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000079, mae: 0.005905, mean_q: 0.006281
  3386/100000: episode: 396, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001398, mae: 0.010141, mean_q: 0.009168
  3396/100000: episode: 397, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001300, mae: 0.015107, mean_q: 0.010864
  3406/100000: episode: 398, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001511, mae: 0.013284, mean_q: 0.010187
  3416/100000: episode: 399, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000337, mae: 0.011563, mean_q: 0.011171
  3426/100000: episode: 400, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002369, mae: 0.016683, mean_q: 0.013438
  3436/100000: episode: 401, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000188, mae: 0.007566, mean_q: 0.008309
  3446/100000: episode: 402, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000117, mae: 0.006111, mean_q: 0.004076
  3456/100000: episode: 403, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002278, mae: 0.015496, mean_q: 0.013330
  3466/100000: episode: 404, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001103, mae: 0.014835, mean_q: 0.013394
  3476/100000: episode: 405, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000134, mae: 0.008172, mean_q: 0.004406
  3486/100000: episode: 406, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000209, mae: 0.008300, mean_q: 0.002629
  3496/100000: episode: 407, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000314, mae: 0.007697, mean_q: 0.005807
  3506/100000: episode: 408, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000127, mae: 0.007708, mean_q: 0.008250
  3516/100000: episode: 409, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001186, mae: 0.011211, mean_q: 0.012795
  3526/100000: episode: 410, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000107, mae: 0.007304, mean_q: 0.004956
  3536/100000: episode: 411, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000144, mae: 0.006420, mean_q: 0.004887
  3546/100000: episode: 412, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000093, mae: 0.005996, mean_q: 0.006613
  3556/100000: episode: 413, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000165, mae: 0.007169, mean_q: 0.006732
  3566/100000: episode: 414, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000132, mae: 0.007298, mean_q: 0.008335
  3576/100000: episode: 415, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000381, mae: 0.008692, mean_q: 0.009324
  3586/100000: episode: 416, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000306, mae: 0.008307, mean_q: 0.012363
  3596/100000: episode: 417, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000242, mae: 0.006948, mean_q: 0.007407
  3606/100000: episode: 418, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000134, mae: 0.006359, mean_q: 0.003857
  3616/100000: episode: 419, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000114, mae: 0.005752, mean_q: 0.006655
  3626/100000: episode: 420, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000246, mae: 0.006749, mean_q: 0.007361
  3636/100000: episode: 421, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001034, mae: 0.009346, mean_q: 0.010030
  3646/100000: episode: 422, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000168, mae: 0.007772, mean_q: 0.006918
  3656/100000: episode: 423, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000205, mae: 0.006886, mean_q: 0.005592
  3666/100000: episode: 424, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000231, mae: 0.005747, mean_q: 0.006468
  3676/100000: episode: 425, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000082, mae: 0.005717, mean_q: 0.006288
  3686/100000: episode: 426, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000110, mae: 0.005939, mean_q: 0.007247
  3696/100000: episode: 427, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000154, mae: 0.007679, mean_q: 0.009970
  3706/100000: episode: 428, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001296, mae: 0.010238, mean_q: 0.008275
  3716/100000: episode: 429, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000166, mae: 0.007869, mean_q: 0.007203
  3726/100000: episode: 430, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000285, mae: 0.007110, mean_q: 0.005894
  3736/100000: episode: 431, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000116, mae: 0.006044, mean_q: 0.007503
  3746/100000: episode: 432, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000061, mae: 0.005121, mean_q: 0.006793
  3756/100000: episode: 433, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000070, mae: 0.004881, mean_q: 0.004833
  3766/100000: episode: 434, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000112, mae: 0.005611, mean_q: 0.006694
  3776/100000: episode: 435, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000068, mae: 0.005284, mean_q: 0.006329
  3786/100000: episode: 436, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000126, mae: 0.005266, mean_q: 0.006874
  3796/100000: episode: 437, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000062, mae: 0.004332, mean_q: 0.005780
  3806/100000: episode: 438, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000342, mae: 0.007680, mean_q: 0.008745
[Info] Complete ISplit Iteration
[Info] Levels: [0.1699141]
[Info] Cond. Prob: [0.01]
[Info] Error Prob: 0.01

  3816/100000: episode: 439, duration: 0.803s, episode steps: 10, steps per second: 12, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000053, mae: 0.005056, mean_q: 0.003672
  3826/100000: episode: 440, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001343, mae: 0.009423, mean_q: 0.006117
  3836/100000: episode: 441, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000201, mae: 0.009658, mean_q: 0.010124
  3846/100000: episode: 442, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000120, mae: 0.005745, mean_q: 0.006534
  3856/100000: episode: 443, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000248, mae: 0.006047, mean_q: 0.004484
  3866/100000: episode: 444, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000214, mae: 0.005525, mean_q: 0.006010
  3876/100000: episode: 445, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001128, mae: 0.009887, mean_q: 0.009772
  3886/100000: episode: 446, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000209, mae: 0.008287, mean_q: 0.007571
  3896/100000: episode: 447, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001556, mae: 0.010479, mean_q: 0.007274
  3906/100000: episode: 448, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001184, mae: 0.010309, mean_q: 0.010443
  3916/100000: episode: 449, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000286, mae: 0.008888, mean_q: 0.013545
  3926/100000: episode: 450, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000421, mae: 0.009425, mean_q: 0.007082
  3936/100000: episode: 451, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000075, mae: 0.005759, mean_q: 0.004174
  3946/100000: episode: 452, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000106, mae: 0.006587, mean_q: 0.007484
  3956/100000: episode: 453, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000257, mae: 0.007648, mean_q: 0.007896
  3966/100000: episode: 454, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001012, mae: 0.008288, mean_q: 0.007691
  3976/100000: episode: 455, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000116, mae: 0.006965, mean_q: 0.006814
  3986/100000: episode: 456, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001318, mae: 0.012256, mean_q: 0.013942
  3996/100000: episode: 457, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001202, mae: 0.010554, mean_q: 0.005727
  4006/100000: episode: 458, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001242, mae: 0.013112, mean_q: 0.014236
  4016/100000: episode: 459, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000170, mae: 0.008286, mean_q: 0.007173
  4026/100000: episode: 460, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000064, mae: 0.005605, mean_q: 0.002146
  4036/100000: episode: 461, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001148, mae: 0.007917, mean_q: 0.005917
  4046/100000: episode: 462, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000124, mae: 0.006894, mean_q: 0.007909
  4056/100000: episode: 463, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000116, mae: 0.006332, mean_q: 0.009748
  4066/100000: episode: 464, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000100, mae: 0.006342, mean_q: 0.006223
  4076/100000: episode: 465, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000121, mae: 0.006160, mean_q: 0.006481
  4086/100000: episode: 466, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000067, mae: 0.005059, mean_q: 0.006767
  4096/100000: episode: 467, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000086, mae: 0.005732, mean_q: 0.005649
  4106/100000: episode: 468, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000068, mae: 0.005037, mean_q: 0.006510
  4116/100000: episode: 469, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000117, mae: 0.006007, mean_q: 0.006795
  4126/100000: episode: 470, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000122, mae: 0.005855, mean_q: 0.006198
  4136/100000: episode: 471, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000110, mae: 0.006250, mean_q: 0.006341
  4146/100000: episode: 472, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000206, mae: 0.006540, mean_q: 0.008955
  4156/100000: episode: 473, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000987, mae: 0.007117, mean_q: 0.006623
  4166/100000: episode: 474, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000159, mae: 0.006807, mean_q: 0.006803
  4176/100000: episode: 475, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000190, mae: 0.008451, mean_q: 0.009057
  4186/100000: episode: 476, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001915, mae: 0.013761, mean_q: 0.013677
  4196/100000: episode: 477, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000176, mae: 0.008145, mean_q: 0.006220
  4206/100000: episode: 478, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000050, mae: 0.005069, mean_q: 0.003490
  4216/100000: episode: 479, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000173, mae: 0.006513, mean_q: 0.005856
  4226/100000: episode: 480, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001164, mae: 0.009167, mean_q: 0.009424
  4236/100000: episode: 481, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000501, mae: 0.013625, mean_q: 0.014934
  4246/100000: episode: 482, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000075, mae: 0.006356, mean_q: 0.002399
  4256/100000: episode: 483, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001294, mae: 0.007860, mean_q: 0.003385
  4266/100000: episode: 484, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000090, mae: 0.006965, mean_q: 0.008682
  4276/100000: episode: 485, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000110, mae: 0.006733, mean_q: 0.007111
  4286/100000: episode: 486, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001241, mae: 0.008603, mean_q: 0.005356
  4296/100000: episode: 487, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000188, mae: 0.009085, mean_q: 0.008063
  4306/100000: episode: 488, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001072, mae: 0.009208, mean_q: 0.008017
  4316/100000: episode: 489, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000912, mae: 0.009540, mean_q: 0.010475
  4326/100000: episode: 490, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000232, mae: 0.008418, mean_q: 0.008092
  4336/100000: episode: 491, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001141, mae: 0.010750, mean_q: 0.010542
  4346/100000: episode: 492, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000139, mae: 0.007194, mean_q: 0.008090
  4356/100000: episode: 493, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000176, mae: 0.007537, mean_q: 0.005049
  4366/100000: episode: 494, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000379, mae: 0.007974, mean_q: 0.008156
  4376/100000: episode: 495, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000206, mae: 0.009041, mean_q: 0.010974
  4386/100000: episode: 496, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000134, mae: 0.006020, mean_q: 0.005143
  4396/100000: episode: 497, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000299, mae: 0.007168, mean_q: 0.010062
  4406/100000: episode: 498, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000954, mae: 0.009561, mean_q: 0.010721
  4416/100000: episode: 499, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000327, mae: 0.009136, mean_q: 0.008941
  4426/100000: episode: 500, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000173, mae: 0.005547, mean_q: 0.005894
  4436/100000: episode: 501, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000990, mae: 0.009819, mean_q: 0.011206
  4446/100000: episode: 502, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000176, mae: 0.008154, mean_q: 0.008167
  4456/100000: episode: 503, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001151, mae: 0.009031, mean_q: 0.008029
  4466/100000: episode: 504, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000096, mae: 0.005842, mean_q: 0.005799
  4476/100000: episode: 505, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000067, mae: 0.005154, mean_q: 0.004349
  4486/100000: episode: 506, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000141, mae: 0.006730, mean_q: 0.005656
  4496/100000: episode: 507, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000112, mae: 0.006297, mean_q: 0.005930
  4506/100000: episode: 508, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001119, mae: 0.010838, mean_q: 0.009946
  4516/100000: episode: 509, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000995, mae: 0.010534, mean_q: 0.009290
  4526/100000: episode: 510, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000474, mae: 0.011286, mean_q: 0.012101
  4536/100000: episode: 511, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001279, mae: 0.010916, mean_q: 0.011050
  4546/100000: episode: 512, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000388, mae: 0.009154, mean_q: 0.008446
  4556/100000: episode: 513, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000112, mae: 0.006103, mean_q: 0.005111
  4566/100000: episode: 514, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000191, mae: 0.007088, mean_q: 0.005911
  4576/100000: episode: 515, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000087, mae: 0.005826, mean_q: 0.007054
  4586/100000: episode: 516, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000110, mae: 0.005714, mean_q: 0.005736
  4596/100000: episode: 517, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000240, mae: 0.006839, mean_q: 0.007592
  4606/100000: episode: 518, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000090, mae: 0.005584, mean_q: 0.007303
  4616/100000: episode: 519, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000219, mae: 0.006660, mean_q: 0.005797
  4626/100000: episode: 520, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000097, mae: 0.005360, mean_q: 0.005565
  4636/100000: episode: 521, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000315, mae: 0.009938, mean_q: 0.010151
  4646/100000: episode: 522, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000310, mae: 0.009442, mean_q: 0.007410
  4656/100000: episode: 523, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000145, mae: 0.007055, mean_q: 0.002753
  4666/100000: episode: 524, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000044, mae: 0.005046, mean_q: 0.004261
  4676/100000: episode: 525, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000393, mae: 0.008307, mean_q: 0.008381
  4686/100000: episode: 526, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000097, mae: 0.007475, mean_q: 0.007798
  4696/100000: episode: 527, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000142, mae: 0.006112, mean_q: 0.006536
  4706/100000: episode: 528, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000251, mae: 0.006058, mean_q: 0.004830
  4716/100000: episode: 529, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000329, mae: 0.007581, mean_q: 0.006043
  4726/100000: episode: 530, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000151, mae: 0.007837, mean_q: 0.009088
  4736/100000: episode: 531, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000109, mae: 0.006034, mean_q: 0.006751
  4746/100000: episode: 532, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000257, mae: 0.007071, mean_q: 0.005945
  4756/100000: episode: 533, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001380, mae: 0.012966, mean_q: 0.015520
  4766/100000: episode: 534, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000271, mae: 0.010405, mean_q: 0.004332
  4776/100000: episode: 535, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000219, mae: 0.008823, mean_q: 0.003510
  4786/100000: episode: 536, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001144, mae: 0.011902, mean_q: 0.012030
  4796/100000: episode: 537, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000243, mae: 0.007877, mean_q: 0.006742
  4806/100000: episode: 538, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000089, mae: 0.005283, mean_q: 0.003246
[Info] 1-TH LEVEL FOUND: 0.03843415156006813, Considering 10/100 traces
  4816/100000: episode: 539, duration: 0.772s, episode steps: 10, steps per second: 13, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000464, mae: 0.009411, mean_q: 0.009924
[Info] FALSIFICATION!
  4822/100000: episode: 540, duration: 0.253s, episode steps: 6, steps per second: 24, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.001282, mae: 0.010782, mean_q: 0.011980
  4829/100000: episode: 541, duration: 0.048s, episode steps: 7, steps per second: 145, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000226, mae: 0.008781, mean_q: 0.010571
  4836/100000: episode: 542, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000134, mae: 0.006089, mean_q: 0.003984
  4840/100000: episode: 543, duration: 0.026s, episode steps: 4, steps per second: 155, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000731, mae: 0.009375, mean_q: 0.004029
  4847/100000: episode: 544, duration: 0.039s, episode steps: 7, steps per second: 178, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001667, mae: 0.010244, mean_q: 0.007717
  4849/100000: episode: 545, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000104, mae: 0.006187, mean_q: 0.009307
  4853/100000: episode: 546, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000375, mae: 0.013069, mean_q: 0.007797
  4857/100000: episode: 547, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000095, mae: 0.006538, mean_q: 0.005503
  4861/100000: episode: 548, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000099, mae: 0.006866, mean_q: 0.008905
  4865/100000: episode: 549, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000170, mae: 0.007720, mean_q: 0.006041
  4872/100000: episode: 550, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000101, mae: 0.006070, mean_q: 0.005502
  4876/100000: episode: 551, duration: 0.020s, episode steps: 4, steps per second: 195, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000501, mae: 0.008878, mean_q: 0.008787
  4883/100000: episode: 552, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.021, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.429 [-1.000, 11.000], loss: 0.000083, mae: 0.004876, mean_q: 0.005981
  4887/100000: episode: 553, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000075, mae: 0.005239, mean_q: 0.007431
  4891/100000: episode: 554, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000138, mae: 0.006389, mean_q: 0.007507
  4895/100000: episode: 555, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000493, mae: 0.009547, mean_q: 0.008535
  4897/100000: episode: 556, duration: 0.016s, episode steps: 2, steps per second: 121, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000352, mae: 0.010393, mean_q: 0.010850
  4899/100000: episode: 557, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000581, mae: 0.009133, mean_q: 0.014119
  4906/100000: episode: 558, duration: 0.043s, episode steps: 7, steps per second: 161, episode reward: 0.080, mean reward: 0.011 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000102, mae: 0.005226, mean_q: 0.006255
  4910/100000: episode: 559, duration: 0.028s, episode steps: 4, steps per second: 141, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002022, mae: 0.012870, mean_q: 0.012207
  4917/100000: episode: 560, duration: 0.041s, episode steps: 7, steps per second: 172, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000162, mae: 0.007089, mean_q: 0.009832
  4924/100000: episode: 561, duration: 0.043s, episode steps: 7, steps per second: 163, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000590, mae: 0.010840, mean_q: 0.010447
  4931/100000: episode: 562, duration: 0.040s, episode steps: 7, steps per second: 175, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001292, mae: 0.010109, mean_q: 0.011562
  4935/100000: episode: 563, duration: 0.029s, episode steps: 4, steps per second: 140, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000368, mae: 0.010737, mean_q: 0.012946
[Info] FALSIFICATION!
  4941/100000: episode: 564, duration: 0.188s, episode steps: 6, steps per second: 32, episode reward: 1.578, mean reward: 0.263 [0.007, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 7.500 [5.000, 10.000], loss: 0.000157, mae: 0.006814, mean_q: 0.008776
  4948/100000: episode: 565, duration: 0.036s, episode steps: 7, steps per second: 196, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000080, mae: 0.005081, mean_q: 0.004720
  4950/100000: episode: 566, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000042, mae: 0.005022, mean_q: 0.001722
  4954/100000: episode: 567, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000030, mae: 0.004105, mean_q: 0.003042
  4961/100000: episode: 568, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000599, mae: 0.010578, mean_q: 0.006802
  4968/100000: episode: 569, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000410, mae: 0.011797, mean_q: 0.011584
  4972/100000: episode: 570, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000255, mae: 0.010687, mean_q: 0.014233
  4979/100000: episode: 571, duration: 0.033s, episode steps: 7, steps per second: 213, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000211, mae: 0.008691, mean_q: 0.010826
  4983/100000: episode: 572, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002431, mae: 0.012345, mean_q: 0.007049
  4990/100000: episode: 573, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.001324, mae: 0.009649, mean_q: 0.010845
  4997/100000: episode: 574, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000111, mae: 0.007842, mean_q: 0.007726
  4999/100000: episode: 575, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000459, mae: 0.009975, mean_q: 0.011978
  5001/100000: episode: 576, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000111, mae: 0.006778, mean_q: 0.004086
  5003/100000: episode: 577, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000514, mae: 0.014701, mean_q: 0.015491
  5007/100000: episode: 578, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000098, mae: 0.005184, mean_q: 0.007005
  5014/100000: episode: 579, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.213, mean reward: 0.030 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000163, mae: 0.006699, mean_q: 0.006862
  5021/100000: episode: 580, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.143, mean reward: 0.020 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000129, mae: 0.006453, mean_q: 0.008850
  5023/100000: episode: 581, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000799, mae: 0.016429, mean_q: 0.016747
  5030/100000: episode: 582, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000189, mae: 0.006590, mean_q: 0.008032
  5034/100000: episode: 583, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000380, mae: 0.008451, mean_q: 0.009999
  5041/100000: episode: 584, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000176, mae: 0.007464, mean_q: 0.009698
  5048/100000: episode: 585, duration: 0.041s, episode steps: 7, steps per second: 171, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000108, mae: 0.006116, mean_q: 0.007746
  5050/100000: episode: 586, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000017, mae: 0.003501, mean_q: 0.004633
  5052/100000: episode: 587, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000116, mae: 0.006792, mean_q: 0.002624
  5054/100000: episode: 588, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000083, mae: 0.005569, mean_q: 0.006931
  5061/100000: episode: 589, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.088, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000128, mae: 0.006313, mean_q: 0.007094
  5068/100000: episode: 590, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000291, mae: 0.007447, mean_q: 0.009029
  5075/100000: episode: 591, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.001885, mae: 0.015729, mean_q: 0.016588
  5082/100000: episode: 592, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000100, mae: 0.006738, mean_q: 0.005217
  5084/100000: episode: 593, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000043, mae: 0.004521, mean_q: 0.006089
  5086/100000: episode: 594, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000074, mae: 0.004431, mean_q: 0.004700
  5090/100000: episode: 595, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000623, mae: 0.010809, mean_q: 0.009416
  5097/100000: episode: 596, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.080, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000187, mae: 0.009174, mean_q: 0.013901
  5099/100000: episode: 597, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000070, mae: 0.007242, mean_q: 0.002495
  5106/100000: episode: 598, duration: 0.033s, episode steps: 7, steps per second: 209, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.002739, mae: 0.017255, mean_q: 0.016819
  5110/100000: episode: 599, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000553, mae: 0.011957, mean_q: 0.010352
  5117/100000: episode: 600, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.002423, mae: 0.015111, mean_q: 0.011924
  5121/100000: episode: 601, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000595, mae: 0.012851, mean_q: 0.014151
  5123/100000: episode: 602, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000342, mae: 0.011026, mean_q: 0.001458
  5125/100000: episode: 603, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000171, mae: 0.009583, mean_q: -0.003017
  5129/100000: episode: 604, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000183, mae: 0.008664, mean_q: 0.005823
  5136/100000: episode: 605, duration: 0.033s, episode steps: 7, steps per second: 214, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001930, mae: 0.015877, mean_q: 0.010295
  5143/100000: episode: 606, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.001183, mae: 0.015221, mean_q: 0.016286
  5145/100000: episode: 607, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000313, mae: 0.013751, mean_q: 0.018557
  5149/100000: episode: 608, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000553, mae: 0.016036, mean_q: 0.020548
  5153/100000: episode: 609, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000423, mae: 0.011611, mean_q: 0.003952
  5160/100000: episode: 610, duration: 0.034s, episode steps: 7, steps per second: 208, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000431, mae: 0.010509, mean_q: 0.006973
  5162/100000: episode: 611, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000290, mae: 0.006603, mean_q: 0.002488
  5169/100000: episode: 612, duration: 0.033s, episode steps: 7, steps per second: 212, episode reward: 1.947, mean reward: 0.278 [0.007, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 7.857 [5.000, 11.000], loss: 0.000333, mae: 0.009422, mean_q: 0.009099
  5176/100000: episode: 613, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.001596, mae: 0.017254, mean_q: 0.018524
  5180/100000: episode: 614, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002265, mae: 0.014041, mean_q: 0.011759
  5182/100000: episode: 615, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.002944, mae: 0.020490, mean_q: 0.024607
  5184/100000: episode: 616, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000288, mae: 0.010861, mean_q: 0.017011
  5191/100000: episode: 617, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.041, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000211, mae: 0.009152, mean_q: 0.010075
  5198/100000: episode: 618, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000525, mae: 0.010371, mean_q: 0.008797
  5205/100000: episode: 619, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.012, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.286 [-1.000, 11.000], loss: 0.000299, mae: 0.008753, mean_q: 0.011367
  5209/100000: episode: 620, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000314, mae: 0.011315, mean_q: 0.014989
  5216/100000: episode: 621, duration: 0.034s, episode steps: 7, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000219, mae: 0.009512, mean_q: 0.007645
  5218/100000: episode: 622, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000220, mae: 0.009974, mean_q: 0.008743
  5220/100000: episode: 623, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000090, mae: 0.005702, mean_q: 0.006452
  5224/100000: episode: 624, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000081, mae: 0.006181, mean_q: 0.005907
  5228/100000: episode: 625, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000454, mae: 0.011766, mean_q: 0.015297
  5230/100000: episode: 626, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000053, mae: 0.005692, mean_q: 0.007522
  5232/100000: episode: 627, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000648, mae: 0.011420, mean_q: 0.010038
  5239/100000: episode: 628, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000631, mae: 0.012577, mean_q: 0.017332
[Info] Complete ISplit Iteration
[Info] Levels: [0.03843415, 0.37138042]
[Info] Cond. Prob: [0.1, 0.02]
[Info] Error Prob: 0.002

  5243/100000: episode: 629, duration: 0.727s, episode steps: 4, steps per second: 6, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000238, mae: 0.009040, mean_q: 0.012222
  5253/100000: episode: 630, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002714, mae: 0.018550, mean_q: 0.019652
  5263/100000: episode: 631, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001128, mae: 0.013981, mean_q: 0.011426
  5273/100000: episode: 632, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001076, mae: 0.012245, mean_q: 0.014638
  5283/100000: episode: 633, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000270, mae: 0.008535, mean_q: 0.008524
  5293/100000: episode: 634, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001975, mae: 0.012926, mean_q: 0.010211
  5303/100000: episode: 635, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000646, mae: 0.014976, mean_q: 0.014151
  5313/100000: episode: 636, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000229, mae: 0.008901, mean_q: 0.004665
  5323/100000: episode: 637, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000424, mae: 0.010929, mean_q: 0.006163
  5333/100000: episode: 638, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001593, mae: 0.018000, mean_q: 0.015866
  5343/100000: episode: 639, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001187, mae: 0.019299, mean_q: 0.023121
  5353/100000: episode: 640, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000391, mae: 0.008653, mean_q: 0.005000
  5363/100000: episode: 641, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000419, mae: 0.009042, mean_q: 0.007888
  5373/100000: episode: 642, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000473, mae: 0.012069, mean_q: 0.014247
  5383/100000: episode: 643, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000453, mae: 0.010279, mean_q: 0.007440
  5393/100000: episode: 644, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000434, mae: 0.010696, mean_q: 0.011782
  5403/100000: episode: 645, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000124, mae: 0.006677, mean_q: 0.010536
  5413/100000: episode: 646, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000521, mae: 0.011459, mean_q: 0.016241
  5423/100000: episode: 647, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000192, mae: 0.008090, mean_q: 0.003564
  5433/100000: episode: 648, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001141, mae: 0.011349, mean_q: 0.010372
  5443/100000: episode: 649, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000406, mae: 0.012161, mean_q: 0.015318
  5453/100000: episode: 650, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000136, mae: 0.007073, mean_q: 0.007294
  5463/100000: episode: 651, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001437, mae: 0.011404, mean_q: 0.009387
  5473/100000: episode: 652, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000249, mae: 0.009635, mean_q: 0.010988
  5483/100000: episode: 653, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001479, mae: 0.013301, mean_q: 0.014553
  5493/100000: episode: 654, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000254, mae: 0.008934, mean_q: 0.009759
  5503/100000: episode: 655, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000198, mae: 0.008295, mean_q: 0.008705
  5513/100000: episode: 656, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000978, mae: 0.010646, mean_q: 0.010275
  5523/100000: episode: 657, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000462, mae: 0.011115, mean_q: 0.013358
  5533/100000: episode: 658, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000919, mae: 0.009806, mean_q: 0.009981
  5543/100000: episode: 659, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001317, mae: 0.014874, mean_q: 0.014035
  5553/100000: episode: 660, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001702, mae: 0.012488, mean_q: 0.010687
  5563/100000: episode: 661, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000242, mae: 0.008952, mean_q: 0.010689
  5573/100000: episode: 662, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000236, mae: 0.008127, mean_q: 0.007290
  5583/100000: episode: 663, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002345, mae: 0.015956, mean_q: 0.011180
  5593/100000: episode: 664, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000666, mae: 0.016023, mean_q: 0.019971
  5603/100000: episode: 665, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001270, mae: 0.011745, mean_q: 0.010675
  5613/100000: episode: 666, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000321, mae: 0.008588, mean_q: 0.010626
  5623/100000: episode: 667, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000251, mae: 0.009054, mean_q: 0.006396
  5633/100000: episode: 668, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000446, mae: 0.010009, mean_q: 0.011148
  5643/100000: episode: 669, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000397, mae: 0.009844, mean_q: 0.011686
  5653/100000: episode: 670, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002032, mae: 0.016513, mean_q: 0.019243
  5663/100000: episode: 671, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001079, mae: 0.014730, mean_q: 0.011234
  5673/100000: episode: 672, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001270, mae: 0.009998, mean_q: 0.004787
  5683/100000: episode: 673, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000249, mae: 0.009924, mean_q: 0.011567
  5693/100000: episode: 674, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000176, mae: 0.008043, mean_q: 0.011425
  5703/100000: episode: 675, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000482, mae: 0.011121, mean_q: 0.014395
  5713/100000: episode: 676, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000138, mae: 0.007523, mean_q: 0.007444
  5723/100000: episode: 677, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000148, mae: 0.007143, mean_q: 0.007016
  5733/100000: episode: 678, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000382, mae: 0.010767, mean_q: 0.009605
  5743/100000: episode: 679, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000401, mae: 0.012231, mean_q: 0.017268
  5753/100000: episode: 680, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000963, mae: 0.011144, mean_q: 0.014580
  5763/100000: episode: 681, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001780, mae: 0.017500, mean_q: 0.020936
  5773/100000: episode: 682, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000887, mae: 0.012246, mean_q: 0.014142
  5783/100000: episode: 683, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000307, mae: 0.008318, mean_q: 0.007084
  5793/100000: episode: 684, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001384, mae: 0.015421, mean_q: 0.020905
  5803/100000: episode: 685, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000293, mae: 0.009361, mean_q: 0.009612
  5813/100000: episode: 686, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000167, mae: 0.006884, mean_q: 0.005238
  5823/100000: episode: 687, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000639, mae: 0.012796, mean_q: 0.010041
  5833/100000: episode: 688, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001218, mae: 0.013906, mean_q: 0.017492
  5843/100000: episode: 689, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001450, mae: 0.015918, mean_q: 0.020542
  5853/100000: episode: 690, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000602, mae: 0.010749, mean_q: 0.007675
  5863/100000: episode: 691, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000096, mae: 0.006471, mean_q: 0.007418
  5873/100000: episode: 692, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000248, mae: 0.009338, mean_q: 0.013199
  5883/100000: episode: 693, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000311, mae: 0.009180, mean_q: 0.012964
  5893/100000: episode: 694, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000401, mae: 0.010539, mean_q: 0.013613
  5903/100000: episode: 695, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001107, mae: 0.012734, mean_q: 0.012707
  5913/100000: episode: 696, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000304, mae: 0.010812, mean_q: 0.012497
  5923/100000: episode: 697, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000920, mae: 0.010769, mean_q: 0.010756
  5933/100000: episode: 698, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000219, mae: 0.006787, mean_q: 0.010222
  5943/100000: episode: 699, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000414, mae: 0.009856, mean_q: 0.008622
  5953/100000: episode: 700, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000223, mae: 0.008084, mean_q: 0.008673
  5963/100000: episode: 701, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001514, mae: 0.016092, mean_q: 0.016544
  5973/100000: episode: 702, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000236, mae: 0.010456, mean_q: 0.014237
  5983/100000: episode: 703, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001153, mae: 0.010971, mean_q: 0.010025
  5993/100000: episode: 704, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000323, mae: 0.010428, mean_q: 0.006947
  6003/100000: episode: 705, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000202, mae: 0.007829, mean_q: 0.006577
  6013/100000: episode: 706, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000228, mae: 0.009084, mean_q: 0.010197
  6023/100000: episode: 707, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000266, mae: 0.009168, mean_q: 0.011618
  6033/100000: episode: 708, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000872, mae: 0.011950, mean_q: 0.016846
  6043/100000: episode: 709, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000421, mae: 0.011965, mean_q: 0.013719
  6053/100000: episode: 710, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001317, mae: 0.011634, mean_q: 0.011951
  6063/100000: episode: 711, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000392, mae: 0.010679, mean_q: 0.008183
  6073/100000: episode: 712, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000275, mae: 0.010566, mean_q: 0.007559
  6083/100000: episode: 713, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000589, mae: 0.013442, mean_q: 0.015316
  6093/100000: episode: 714, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000274, mae: 0.010225, mean_q: 0.012318
  6103/100000: episode: 715, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000132, mae: 0.007145, mean_q: 0.009747
  6113/100000: episode: 716, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000203, mae: 0.006790, mean_q: 0.009500
  6123/100000: episode: 717, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000229, mae: 0.007595, mean_q: 0.007029
  6133/100000: episode: 718, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000413, mae: 0.008820, mean_q: 0.009653
  6143/100000: episode: 719, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000230, mae: 0.007952, mean_q: 0.010856
  6153/100000: episode: 720, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000715, mae: 0.008932, mean_q: 0.011628
  6163/100000: episode: 721, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001130, mae: 0.011279, mean_q: 0.011498
  6173/100000: episode: 722, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000367, mae: 0.009336, mean_q: 0.012470
  6183/100000: episode: 723, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000319, mae: 0.009752, mean_q: 0.007003
  6193/100000: episode: 724, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000131, mae: 0.007442, mean_q: 0.007075
  6203/100000: episode: 725, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001086, mae: 0.011095, mean_q: 0.009966
  6213/100000: episode: 726, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000228, mae: 0.010545, mean_q: 0.014043
  6223/100000: episode: 727, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000972, mae: 0.011456, mean_q: 0.011161
  6233/100000: episode: 728, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000216, mae: 0.007884, mean_q: 0.010072
[Info] 1-TH LEVEL FOUND: 0.04677712917327881, Considering 12/100 traces
  6243/100000: episode: 729, duration: 0.652s, episode steps: 10, steps per second: 15, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000521, mae: 0.012546, mean_q: 0.013495
  6249/100000: episode: 730, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001721, mae: 0.014620, mean_q: 0.021418
  6253/100000: episode: 731, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001686, mae: 0.016153, mean_q: 0.016746
  6257/100000: episode: 732, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000401, mae: 0.008816, mean_q: 0.013363
  6263/100000: episode: 733, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001563, mae: 0.013024, mean_q: 0.016408
  6269/100000: episode: 734, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.339, mean reward: 0.056 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000376, mae: 0.009390, mean_q: 0.010325
  6273/100000: episode: 735, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000086, mae: 0.005523, mean_q: 0.006509
  6279/100000: episode: 736, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000237, mae: 0.008572, mean_q: 0.008445
  6283/100000: episode: 737, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000431, mae: 0.009776, mean_q: 0.006801
  6287/100000: episode: 738, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000300, mae: 0.010648, mean_q: 0.009306
  6293/100000: episode: 739, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000349, mae: 0.009109, mean_q: 0.011562
  6297/100000: episode: 740, duration: 0.020s, episode steps: 4, steps per second: 197, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000579, mae: 0.011741, mean_q: 0.012033
  6301/100000: episode: 741, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000281, mae: 0.009507, mean_q: 0.013217
  6305/100000: episode: 742, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000329, mae: 0.010838, mean_q: 0.013772
  6309/100000: episode: 743, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000298, mae: 0.008711, mean_q: 0.007990
  6315/100000: episode: 744, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000618, mae: 0.013551, mean_q: 0.016197
  6319/100000: episode: 745, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000155, mae: 0.008163, mean_q: 0.011872
  6323/100000: episode: 746, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000067, mae: 0.006671, mean_q: 0.009360
  6329/100000: episode: 747, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001746, mae: 0.012640, mean_q: 0.013166
  6335/100000: episode: 748, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001342, mae: 0.013731, mean_q: 0.017104
  6339/100000: episode: 749, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002335, mae: 0.015843, mean_q: 0.017699
  6345/100000: episode: 750, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000819, mae: 0.014338, mean_q: 0.019533
  6351/100000: episode: 751, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000703, mae: 0.014040, mean_q: 0.009088
  6355/100000: episode: 752, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000266, mae: 0.009380, mean_q: 0.003653
  6359/100000: episode: 753, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000313, mae: 0.008993, mean_q: 0.002873
  6363/100000: episode: 754, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000327, mae: 0.010756, mean_q: 0.010323
  6367/100000: episode: 755, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000739, mae: 0.015364, mean_q: 0.016885
  6371/100000: episode: 756, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001859, mae: 0.014890, mean_q: 0.016586
  6375/100000: episode: 757, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000314, mae: 0.014299, mean_q: 0.024213
  6379/100000: episode: 758, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000315, mae: 0.012289, mean_q: 0.013633
  6383/100000: episode: 759, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000321, mae: 0.010264, mean_q: 0.006660
  6387/100000: episode: 760, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000137, mae: 0.007646, mean_q: 0.007069
  6391/100000: episode: 761, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000132, mae: 0.006930, mean_q: 0.006082
  6397/100000: episode: 762, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000083, mae: 0.006580, mean_q: 0.004011
  6401/100000: episode: 763, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000709, mae: 0.012823, mean_q: 0.008611
  6407/100000: episode: 764, duration: 0.029s, episode steps: 6, steps per second: 204, episode reward: 0.105, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.002198, mae: 0.018691, mean_q: 0.014634
  6411/100000: episode: 765, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000176, mae: 0.012790, mean_q: 0.019168
  6415/100000: episode: 766, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000803, mae: 0.016605, mean_q: 0.021088
  6421/100000: episode: 767, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000541, mae: 0.014305, mean_q: 0.014176
  6427/100000: episode: 768, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000314, mae: 0.009433, mean_q: 0.007957
  6431/100000: episode: 769, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000157, mae: 0.008646, mean_q: 0.005375
  6435/100000: episode: 770, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000681, mae: 0.011773, mean_q: 0.011176
[Info] FALSIFICATION!
  6440/100000: episode: 771, duration: 0.258s, episode steps: 5, steps per second: 19, episode reward: 1.571, mean reward: 0.314 [0.018, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.000 [6.000, 10.000], loss: 0.000198, mae: 0.009227, mean_q: 0.012634
  6444/100000: episode: 772, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001865, mae: 0.018404, mean_q: 0.023383
  6448/100000: episode: 773, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001280, mae: 0.015091, mean_q: 0.021847
  6452/100000: episode: 774, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001159, mae: 0.018368, mean_q: 0.015067
  6458/100000: episode: 775, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 1.308, mean reward: 0.218 [0.018, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.250 [6.000, 11.000], loss: 0.000866, mae: 0.014183, mean_q: 0.010168
  6462/100000: episode: 776, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000581, mae: 0.013131, mean_q: 0.004189
  6468/100000: episode: 777, duration: 0.030s, episode steps: 6, steps per second: 201, episode reward: 0.125, mean reward: 0.021 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.167 [-1.000, 11.000], loss: 0.000298, mae: 0.008725, mean_q: 0.006483
  6472/100000: episode: 778, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000341, mae: 0.011200, mean_q: 0.016290
  6478/100000: episode: 779, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000246, mae: 0.010990, mean_q: 0.014593
  6482/100000: episode: 780, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001963, mae: 0.017106, mean_q: 0.018860
  6488/100000: episode: 781, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.001601, mae: 0.016481, mean_q: 0.018707
  6492/100000: episode: 782, duration: 0.021s, episode steps: 4, steps per second: 195, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000218, mae: 0.008842, mean_q: 0.011824
  6498/100000: episode: 783, duration: 0.029s, episode steps: 6, steps per second: 206, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000571, mae: 0.011790, mean_q: 0.012818
  6504/100000: episode: 784, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000431, mae: 0.011006, mean_q: 0.010295
  6508/100000: episode: 785, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000526, mae: 0.012657, mean_q: 0.010005
  6514/100000: episode: 786, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.002678, mae: 0.018440, mean_q: 0.014019
  6518/100000: episode: 787, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000622, mae: 0.018068, mean_q: 0.027027
  6524/100000: episode: 788, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000716, mae: 0.017040, mean_q: 0.021866
  6528/100000: episode: 789, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000609, mae: 0.015038, mean_q: 0.015920
  6534/100000: episode: 790, duration: 0.031s, episode steps: 6, steps per second: 195, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000283, mae: 0.009766, mean_q: 0.006377
  6540/100000: episode: 791, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000470, mae: 0.013415, mean_q: 0.008633
  6544/100000: episode: 792, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.001088, mae: 0.017755, mean_q: 0.009132
  6548/100000: episode: 793, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001213, mae: 0.018800, mean_q: 0.018272
  6552/100000: episode: 794, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000214, mae: 0.014227, mean_q: 0.016400
  6558/100000: episode: 795, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.002565, mae: 0.021931, mean_q: 0.025746
  6562/100000: episode: 796, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000799, mae: 0.016938, mean_q: 0.028594
  6566/100000: episode: 797, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000488, mae: 0.013943, mean_q: 0.015566
  6570/100000: episode: 798, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.004220, mae: 0.023252, mean_q: 0.018424
  6574/100000: episode: 799, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000556, mae: 0.011418, mean_q: 0.017950
  6580/100000: episode: 800, duration: 0.031s, episode steps: 6, steps per second: 194, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000670, mae: 0.014503, mean_q: 0.015568
  6584/100000: episode: 801, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.001625, mae: 0.015908, mean_q: 0.017118
  6588/100000: episode: 802, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001977, mae: 0.019995, mean_q: 0.020898
  6592/100000: episode: 803, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000355, mae: 0.011937, mean_q: 0.014565
  6596/100000: episode: 804, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.002920, mae: 0.020592, mean_q: 0.020743
  6602/100000: episode: 805, duration: 0.030s, episode steps: 6, steps per second: 200, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000713, mae: 0.016630, mean_q: 0.014669
  6606/100000: episode: 806, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001844, mae: 0.017052, mean_q: 0.010648
  6612/100000: episode: 807, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000478, mae: 0.014418, mean_q: 0.020249
  6616/100000: episode: 808, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.002531, mae: 0.025735, mean_q: 0.026971
  6622/100000: episode: 809, duration: 0.029s, episode steps: 6, steps per second: 209, episode reward: 0.073, mean reward: 0.012 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.001651, mae: 0.015096, mean_q: 0.018972
  6626/100000: episode: 810, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000795, mae: 0.015587, mean_q: 0.023194
  6632/100000: episode: 811, duration: 0.030s, episode steps: 6, steps per second: 202, episode reward: 0.210, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000476, mae: 0.014103, mean_q: 0.007265
  6638/100000: episode: 812, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002168, mae: 0.018134, mean_q: 0.015479
  6644/100000: episode: 813, duration: 0.029s, episode steps: 6, steps per second: 207, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000397, mae: 0.013949, mean_q: 0.007747
  6650/100000: episode: 814, duration: 0.029s, episode steps: 6, steps per second: 205, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000495, mae: 0.015172, mean_q: 0.018539
  6656/100000: episode: 815, duration: 0.028s, episode steps: 6, steps per second: 212, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000425, mae: 0.014127, mean_q: 0.013507
  6660/100000: episode: 816, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000514, mae: 0.016812, mean_q: 0.023502
[Info] Complete ISplit Iteration
[Info] Levels: [0.04677713, 0.43567127]
[Info] Cond. Prob: [0.12, 0.01]
[Info] Error Prob: 0.0012

  6666/100000: episode: 817, duration: 0.739s, episode steps: 6, steps per second: 8, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000138, mae: 0.009079, mean_q: 0.010030
  6676/100000: episode: 818, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000504, mae: 0.013173, mean_q: 0.014756
  6686/100000: episode: 819, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000464, mae: 0.013131, mean_q: 0.016512
  6696/100000: episode: 820, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000545, mae: 0.014977, mean_q: 0.010217
  6706/100000: episode: 821, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001889, mae: 0.020379, mean_q: 0.016106
  6716/100000: episode: 822, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000568, mae: 0.018138, mean_q: 0.023753
  6726/100000: episode: 823, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.002069, mae: 0.017158, mean_q: 0.017251
  6736/100000: episode: 824, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000684, mae: 0.015626, mean_q: 0.019547
  6746/100000: episode: 825, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000398, mae: 0.011053, mean_q: 0.008985
  6756/100000: episode: 826, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000384, mae: 0.010627, mean_q: 0.011464
  6766/100000: episode: 827, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000667, mae: 0.015462, mean_q: 0.012598
  6776/100000: episode: 828, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000816, mae: 0.018155, mean_q: 0.027393
  6786/100000: episode: 829, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000652, mae: 0.015602, mean_q: 0.017002
  6796/100000: episode: 830, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000764, mae: 0.013500, mean_q: 0.010120
  6806/100000: episode: 831, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001329, mae: 0.013816, mean_q: 0.012499
  6816/100000: episode: 832, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000655, mae: 0.015458, mean_q: 0.020059
  6826/100000: episode: 833, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000525, mae: 0.013560, mean_q: 0.017631
  6836/100000: episode: 834, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001544, mae: 0.014899, mean_q: 0.011484
  6846/100000: episode: 835, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000644, mae: 0.015445, mean_q: 0.015708
  6856/100000: episode: 836, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.002222, mae: 0.020030, mean_q: 0.014303
  6866/100000: episode: 837, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000453, mae: 0.015321, mean_q: 0.019512
  6876/100000: episode: 838, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000499, mae: 0.012550, mean_q: 0.011496
  6886/100000: episode: 839, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000781, mae: 0.016054, mean_q: 0.016726
  6896/100000: episode: 840, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000638, mae: 0.017126, mean_q: 0.014934
  6906/100000: episode: 841, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001451, mae: 0.017081, mean_q: 0.019594
  6916/100000: episode: 842, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001210, mae: 0.019721, mean_q: 0.025419
  6926/100000: episode: 843, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000739, mae: 0.015031, mean_q: 0.010199
  6936/100000: episode: 844, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000422, mae: 0.011888, mean_q: 0.013769
  6946/100000: episode: 845, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001065, mae: 0.015516, mean_q: 0.022356
  6956/100000: episode: 846, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000320, mae: 0.010673, mean_q: 0.010126
  6966/100000: episode: 847, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000542, mae: 0.013827, mean_q: 0.012550
  6976/100000: episode: 848, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001131, mae: 0.015325, mean_q: 0.017451
  6986/100000: episode: 849, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000466, mae: 0.012884, mean_q: 0.016096
  6996/100000: episode: 850, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000276, mae: 0.010855, mean_q: 0.011976
  7006/100000: episode: 851, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000563, mae: 0.013645, mean_q: 0.015578
  7016/100000: episode: 852, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001081, mae: 0.014410, mean_q: 0.018181
  7026/100000: episode: 853, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001439, mae: 0.015840, mean_q: 0.018579
  7036/100000: episode: 854, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001355, mae: 0.021165, mean_q: 0.022040
  7046/100000: episode: 855, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000713, mae: 0.015362, mean_q: 0.014696
  7056/100000: episode: 856, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000510, mae: 0.015069, mean_q: 0.015843
  7066/100000: episode: 857, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000675, mae: 0.015570, mean_q: 0.015902
  7076/100000: episode: 858, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001651, mae: 0.016481, mean_q: 0.013715
  7086/100000: episode: 859, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000848, mae: 0.013494, mean_q: 0.023910
  7096/100000: episode: 860, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000646, mae: 0.015149, mean_q: 0.017158
  7106/100000: episode: 861, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001913, mae: 0.016201, mean_q: 0.016233
  7116/100000: episode: 862, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002038, mae: 0.018753, mean_q: 0.021948
  7126/100000: episode: 863, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001030, mae: 0.013970, mean_q: 0.014448
  7136/100000: episode: 864, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001042, mae: 0.014165, mean_q: 0.015057
  7146/100000: episode: 865, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000738, mae: 0.014065, mean_q: 0.017680
  7156/100000: episode: 866, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000868, mae: 0.013841, mean_q: 0.024366
  7166/100000: episode: 867, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000304, mae: 0.010957, mean_q: 0.021362
  7176/100000: episode: 868, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000247, mae: 0.008725, mean_q: 0.010881
  7186/100000: episode: 869, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000558, mae: 0.011608, mean_q: 0.015276
  7196/100000: episode: 870, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001347, mae: 0.013689, mean_q: 0.013589
  7206/100000: episode: 871, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001101, mae: 0.014265, mean_q: 0.018300
  7216/100000: episode: 872, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001502, mae: 0.018226, mean_q: 0.026704
  7226/100000: episode: 873, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000683, mae: 0.013859, mean_q: 0.013354
  7236/100000: episode: 874, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001046, mae: 0.014503, mean_q: 0.018555
  7246/100000: episode: 875, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000969, mae: 0.015057, mean_q: 0.020656
  7256/100000: episode: 876, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000737, mae: 0.011176, mean_q: 0.011342
  7266/100000: episode: 877, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001358, mae: 0.014158, mean_q: 0.012041
  7276/100000: episode: 878, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000807, mae: 0.015920, mean_q: 0.018334
  7286/100000: episode: 879, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000703, mae: 0.014018, mean_q: 0.009753
  7296/100000: episode: 880, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000933, mae: 0.015727, mean_q: 0.016817
  7306/100000: episode: 881, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001328, mae: 0.018833, mean_q: 0.023990
  7316/100000: episode: 882, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000343, mae: 0.010040, mean_q: 0.011680
  7326/100000: episode: 883, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000425, mae: 0.010185, mean_q: 0.013485
  7336/100000: episode: 884, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000306, mae: 0.009597, mean_q: 0.007948
  7346/100000: episode: 885, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000303, mae: 0.008658, mean_q: 0.011354
  7356/100000: episode: 886, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000527, mae: 0.011998, mean_q: 0.014065
  7366/100000: episode: 887, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000386, mae: 0.012095, mean_q: 0.015375
  7376/100000: episode: 888, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000501, mae: 0.011042, mean_q: 0.011982
  7386/100000: episode: 889, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000505, mae: 0.011169, mean_q: 0.013970
  7396/100000: episode: 890, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000541, mae: 0.012902, mean_q: 0.016840
  7406/100000: episode: 891, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000602, mae: 0.012711, mean_q: 0.020518
  7416/100000: episode: 892, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001233, mae: 0.013332, mean_q: 0.017271
  7426/100000: episode: 893, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001521, mae: 0.017674, mean_q: 0.022388
  7436/100000: episode: 894, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000534, mae: 0.011493, mean_q: 0.013065
  7446/100000: episode: 895, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000379, mae: 0.010993, mean_q: 0.006642
  7456/100000: episode: 896, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000538, mae: 0.015297, mean_q: 0.012748
  7466/100000: episode: 897, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000546, mae: 0.014138, mean_q: 0.012877
  7476/100000: episode: 898, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001593, mae: 0.017389, mean_q: 0.019728
  7486/100000: episode: 899, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001810, mae: 0.016825, mean_q: 0.017370
  7496/100000: episode: 900, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001019, mae: 0.014920, mean_q: 0.022815
  7506/100000: episode: 901, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000848, mae: 0.014390, mean_q: 0.009284
  7516/100000: episode: 902, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001295, mae: 0.017989, mean_q: 0.014179
  7526/100000: episode: 903, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000524, mae: 0.014480, mean_q: 0.019820
  7536/100000: episode: 904, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000558, mae: 0.011596, mean_q: 0.009927
  7546/100000: episode: 905, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000723, mae: 0.013878, mean_q: 0.021365
  7556/100000: episode: 906, duration: 0.066s, episode steps: 10, steps per second: 153, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001060, mae: 0.013720, mean_q: 0.020721
  7566/100000: episode: 907, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000708, mae: 0.013287, mean_q: 0.014041
  7576/100000: episode: 908, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000612, mae: 0.014103, mean_q: 0.017899
  7586/100000: episode: 909, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000840, mae: 0.015338, mean_q: 0.021537
  7596/100000: episode: 910, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000685, mae: 0.013246, mean_q: 0.014171
  7606/100000: episode: 911, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000359, mae: 0.010279, mean_q: 0.016461
  7616/100000: episode: 912, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000977, mae: 0.014062, mean_q: 0.017100
  7626/100000: episode: 913, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000559, mae: 0.012350, mean_q: 0.010146
  7636/100000: episode: 914, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000681, mae: 0.013276, mean_q: 0.011393
  7646/100000: episode: 915, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000519, mae: 0.011411, mean_q: 0.013837
  7656/100000: episode: 916, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001262, mae: 0.014166, mean_q: 0.017179
[Info] 1-TH LEVEL FOUND: 0.005566021893173456, Considering 100/100 traces
  7666/100000: episode: 917, duration: 0.686s, episode steps: 10, steps per second: 15, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000385, mae: 0.009769, mean_q: 0.011894
[Info] 2-TH LEVEL FOUND: 0.0069009107537567616, Considering 16/100 traces
  7676/100000: episode: 918, duration: 0.783s, episode steps: 10, steps per second: 13, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000299, mae: 0.009599, mean_q: 0.009116
  7679/100000: episode: 919, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000520, mae: 0.011985, mean_q: 0.017185
  7682/100000: episode: 920, duration: 0.019s, episode steps: 3, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000620, mae: 0.013037, mean_q: 0.016405
  7687/100000: episode: 921, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.002373, mae: 0.014467, mean_q: 0.009551
  7692/100000: episode: 922, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 11.000], loss: 0.001272, mae: 0.015766, mean_q: 0.020051
  7698/100000: episode: 923, duration: 0.032s, episode steps: 6, steps per second: 188, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000536, mae: 0.013251, mean_q: 0.015481
  7703/100000: episode: 924, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.000611, mae: 0.011710, mean_q: 0.013686
  7708/100000: episode: 925, duration: 0.027s, episode steps: 5, steps per second: 189, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 11.000], loss: 0.000308, mae: 0.009433, mean_q: 0.007005
  7713/100000: episode: 926, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 11.000], loss: 0.000529, mae: 0.011437, mean_q: 0.006380
  7718/100000: episode: 927, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 11.000], loss: 0.000270, mae: 0.009995, mean_q: 0.009993
  7723/100000: episode: 928, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 11.000], loss: 0.000216, mae: 0.009645, mean_q: 0.006921
  7728/100000: episode: 929, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 11.000], loss: 0.000590, mae: 0.012860, mean_q: 0.016051
  7733/100000: episode: 930, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.004, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.200 [-1.000, 11.000], loss: 0.000602, mae: 0.012714, mean_q: 0.013503
  7738/100000: episode: 931, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.001, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.000271, mae: 0.010309, mean_q: 0.010145
  7743/100000: episode: 932, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000477, mae: 0.013387, mean_q: 0.016434
  7748/100000: episode: 933, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 11.000], loss: 0.000390, mae: 0.010902, mean_q: 0.013731
  7753/100000: episode: 934, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.000459, mae: 0.011456, mean_q: 0.014892
  7758/100000: episode: 935, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.004, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.200 [-1.000, 11.000], loss: 0.000401, mae: 0.010884, mean_q: 0.013169
  7763/100000: episode: 936, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 11.000], loss: 0.000577, mae: 0.014127, mean_q: 0.016149
  7768/100000: episode: 937, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 11.000], loss: 0.000341, mae: 0.010986, mean_q: 0.013459
  7773/100000: episode: 938, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.000383, mae: 0.010329, mean_q: 0.009745
  7778/100000: episode: 939, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 11.000], loss: 0.000339, mae: 0.010747, mean_q: 0.010355
  7783/100000: episode: 940, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 11.000], loss: 0.000847, mae: 0.015965, mean_q: 0.023662
  7788/100000: episode: 941, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 11.000], loss: 0.000323, mae: 0.012214, mean_q: 0.007588
  7793/100000: episode: 942, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.004, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.200 [-1.000, 11.000], loss: 0.000292, mae: 0.011929, mean_q: 0.010909
  7798/100000: episode: 943, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.001, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.002721, mae: 0.016289, mean_q: 0.008335
  7801/100000: episode: 944, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.003734, mae: 0.019691, mean_q: 0.012423
  7806/100000: episode: 945, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.002279, mae: 0.021587, mean_q: 0.029302
  7812/100000: episode: 946, duration: 0.029s, episode steps: 6, steps per second: 208, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.001999, mae: 0.020809, mean_q: 0.019746
  7817/100000: episode: 947, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 11.000], loss: 0.000444, mae: 0.010730, mean_q: 0.014303
  7822/100000: episode: 948, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.000393, mae: 0.010132, mean_q: 0.011384
  7827/100000: episode: 949, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 11.000], loss: 0.000629, mae: 0.014697, mean_q: 0.007361
  7832/100000: episode: 950, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.002575, mae: 0.019936, mean_q: 0.014288
  7838/100000: episode: 951, duration: 0.029s, episode steps: 6, steps per second: 210, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.001163, mae: 0.012585, mean_q: 0.015009
  7841/100000: episode: 952, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000190, mae: 0.009852, mean_q: 0.016800
  7846/100000: episode: 953, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.000510, mae: 0.011920, mean_q: 0.018894
  7849/100000: episode: 954, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000043, mae: 0.005970, mean_q: 0.005480
  7854/100000: episode: 955, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.001, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.000256, mae: 0.009048, mean_q: 0.007000
  7859/100000: episode: 956, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.004, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.200 [-1.000, 11.000], loss: 0.000366, mae: 0.010889, mean_q: 0.005776
  7862/100000: episode: 957, duration: 0.021s, episode steps: 3, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000344, mae: 0.009159, mean_q: 0.007182
  7865/100000: episode: 958, duration: 0.023s, episode steps: 3, steps per second: 132, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000068, mae: 0.005929, mean_q: 0.007093
  7871/100000: episode: 959, duration: 0.037s, episode steps: 6, steps per second: 162, episode reward: 0.168, mean reward: 0.028 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000207, mae: 0.009424, mean_q: 0.010004
  7876/100000: episode: 960, duration: 0.030s, episode steps: 5, steps per second: 167, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000440, mae: 0.011571, mean_q: 0.020533
  7881/100000: episode: 961, duration: 0.033s, episode steps: 5, steps per second: 153, episode reward: 0.004, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.200 [-1.000, 11.000], loss: 0.000684, mae: 0.015874, mean_q: 0.018221
  7886/100000: episode: 962, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.000185, mae: 0.008054, mean_q: 0.008339
  7891/100000: episode: 963, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000273, mae: 0.009492, mean_q: 0.007018
  7896/100000: episode: 964, duration: 0.033s, episode steps: 5, steps per second: 150, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.000303, mae: 0.010064, mean_q: 0.008439
  7902/100000: episode: 965, duration: 0.039s, episode steps: 6, steps per second: 154, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000810, mae: 0.013658, mean_q: 0.010574
  7907/100000: episode: 966, duration: 0.035s, episode steps: 5, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 11.000], loss: 0.000306, mae: 0.010357, mean_q: 0.011508
  7912/100000: episode: 967, duration: 0.031s, episode steps: 5, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 11.000], loss: 0.000502, mae: 0.012874, mean_q: 0.011956
  7915/100000: episode: 968, duration: 0.020s, episode steps: 3, steps per second: 149, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003591, mae: 0.018881, mean_q: 0.015233
  7920/100000: episode: 969, duration: 0.031s, episode steps: 5, steps per second: 163, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001916, mae: 0.023702, mean_q: 0.031952
  7925/100000: episode: 970, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 11.000], loss: 0.000434, mae: 0.013766, mean_q: 0.018563
  7930/100000: episode: 971, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 11.000], loss: 0.000609, mae: 0.012270, mean_q: 0.018103
  7935/100000: episode: 972, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.000375, mae: 0.010597, mean_q: 0.008021
  7940/100000: episode: 973, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 11.000], loss: 0.000777, mae: 0.013248, mean_q: 0.009248
  7943/100000: episode: 974, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000792, mae: 0.015330, mean_q: 0.016577
  7949/100000: episode: 975, duration: 0.033s, episode steps: 6, steps per second: 181, episode reward: 0.093, mean reward: 0.016 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.083 [-1.000, 11.000], loss: 0.000742, mae: 0.014202, mean_q: 0.016099
  7952/100000: episode: 976, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000402, mae: 0.012588, mean_q: 0.011508
  7957/100000: episode: 977, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.004, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.200 [-1.000, 11.000], loss: 0.000253, mae: 0.010631, mean_q: 0.009833
  7960/100000: episode: 978, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000732, mae: 0.009830, mean_q: 0.009114
  7965/100000: episode: 979, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.001, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.000612, mae: 0.014909, mean_q: 0.013837
  7968/100000: episode: 980, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000163, mae: 0.010334, mean_q: 0.009938
  7974/100000: episode: 981, duration: 0.030s, episode steps: 6, steps per second: 199, episode reward: 0.082, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000243, mae: 0.011711, mean_q: 0.015997
  7979/100000: episode: 982, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 11.000], loss: 0.000169, mae: 0.009778, mean_q: 0.010547
  7982/100000: episode: 983, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.001030, mae: 0.015295, mean_q: 0.015420
  7987/100000: episode: 984, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 11.000], loss: 0.000310, mae: 0.010162, mean_q: 0.012055
  7992/100000: episode: 985, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.004, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 5.200 [-1.000, 11.000], loss: 0.000137, mae: 0.007137, mean_q: 0.009864
  7997/100000: episode: 986, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.002471, mae: 0.016711, mean_q: 0.013643
  8002/100000: episode: 987, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.000584, mae: 0.014648, mean_q: 0.012791
  8007/100000: episode: 988, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.001, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.001729, mae: 0.016308, mean_q: 0.013040
  8012/100000: episode: 989, duration: 0.032s, episode steps: 5, steps per second: 158, episode reward: 0.001, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.000323, mae: 0.010494, mean_q: 0.011857
  8018/100000: episode: 990, duration: 0.033s, episode steps: 6, steps per second: 179, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.001857, mae: 0.014419, mean_q: 0.009708
  8023/100000: episode: 991, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 11.000], loss: 0.000892, mae: 0.017911, mean_q: 0.021659
  8028/100000: episode: 992, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.002244, mae: 0.021864, mean_q: 0.021940
  8031/100000: episode: 993, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.667 [-1.000, 11.000], loss: 0.000715, mae: 0.013108, mean_q: 0.018536
  8034/100000: episode: 994, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.833 [-1.000, 11.000], loss: 0.000720, mae: 0.014003, mean_q: 0.011453
  8039/100000: episode: 995, duration: 0.059s, episode steps: 5, steps per second: 85, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 11.000], loss: 0.000306, mae: 0.009446, mean_q: 0.016857
  8044/100000: episode: 996, duration: 0.061s, episode steps: 5, steps per second: 82, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000586, mae: 0.012438, mean_q: 0.008595
  8050/100000: episode: 997, duration: 0.057s, episode steps: 6, steps per second: 105, episode reward: 1.941, mean reward: 0.323 [0.018, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.333 [6.000, 11.000], loss: 0.000606, mae: 0.013101, mean_q: 0.009973
  8053/100000: episode: 998, duration: 0.038s, episode steps: 3, steps per second: 78, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000333, mae: 0.010637, mean_q: 0.016337
  8058/100000: episode: 999, duration: 0.039s, episode steps: 5, steps per second: 127, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 11.000], loss: 0.000325, mae: 0.011028, mean_q: 0.013271
  8063/100000: episode: 1000, duration: 0.037s, episode steps: 5, steps per second: 136, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.000368, mae: 0.011085, mean_q: 0.014434
  8068/100000: episode: 1001, duration: 0.060s, episode steps: 5, steps per second: 84, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 11.000], loss: 0.000112, mae: 0.007084, mean_q: 0.008775
[Info] 3-TH LEVEL FOUND: 0.11459953337907791, Considering 13/100 traces
  8073/100000: episode: 1002, duration: 0.879s, episode steps: 5, steps per second: 6, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 5.100 [-1.000, 11.000], loss: 0.003630, mae: 0.021966, mean_q: 0.024345
  8076/100000: episode: 1003, duration: 0.019s, episode steps: 3, steps per second: 159, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000754, mae: 0.015751, mean_q: 0.025452
  8079/100000: episode: 1004, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000909, mae: 0.014712, mean_q: 0.021059
  8082/100000: episode: 1005, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000357, mae: 0.009955, mean_q: 0.006931
  8085/100000: episode: 1006, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000286, mae: 0.007994, mean_q: 0.009277
  8088/100000: episode: 1007, duration: 0.017s, episode steps: 3, steps per second: 178, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000306, mae: 0.010949, mean_q: 0.009827
  8091/100000: episode: 1008, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000130, mae: 0.007975, mean_q: 0.004683
  8094/100000: episode: 1009, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.006393, mae: 0.027729, mean_q: 0.013336
  8097/100000: episode: 1010, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000600, mae: 0.016506, mean_q: 0.021506
  8102/100000: episode: 1011, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000542, mae: 0.015167, mean_q: 0.012447
  8107/100000: episode: 1012, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000198, mae: 0.011236, mean_q: 0.014104
  8110/100000: episode: 1013, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000144, mae: 0.007608, mean_q: 0.007398
  8113/100000: episode: 1014, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000866, mae: 0.015474, mean_q: 0.018484
  8116/100000: episode: 1015, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000506, mae: 0.011667, mean_q: 0.015075
  8121/100000: episode: 1016, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001262, mae: 0.015327, mean_q: 0.022671
  8124/100000: episode: 1017, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000235, mae: 0.009705, mean_q: 0.015279
  8127/100000: episode: 1018, duration: 0.017s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002451, mae: 0.014841, mean_q: 0.019980
  8130/100000: episode: 1019, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000214, mae: 0.011039, mean_q: 0.017841
  8133/100000: episode: 1020, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000945, mae: 0.015970, mean_q: 0.017035
  8138/100000: episode: 1021, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000144, mae: 0.007738, mean_q: 0.009035
  8143/100000: episode: 1022, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000782, mae: 0.012979, mean_q: 0.014519
  8146/100000: episode: 1023, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.002180, mae: 0.019506, mean_q: 0.010949
  8151/100000: episode: 1024, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000275, mae: 0.009861, mean_q: 0.013231
  8156/100000: episode: 1025, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000421, mae: 0.010611, mean_q: 0.014492
  8161/100000: episode: 1026, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.002779, mae: 0.018926, mean_q: 0.019663
  8164/100000: episode: 1027, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000684, mae: 0.014773, mean_q: 0.019036
  8169/100000: episode: 1028, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.001184, mae: 0.021307, mean_q: 0.026293
  8174/100000: episode: 1029, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000556, mae: 0.014319, mean_q: 0.017387
  8179/100000: episode: 1030, duration: 0.028s, episode steps: 5, steps per second: 178, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000410, mae: 0.011554, mean_q: 0.001958
  8184/100000: episode: 1031, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000810, mae: 0.013291, mean_q: 0.009558
  8187/100000: episode: 1032, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001207, mae: 0.020334, mean_q: 0.008258
  8190/100000: episode: 1033, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000539, mae: 0.015604, mean_q: 0.011121
  8193/100000: episode: 1034, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.005004, mae: 0.030446, mean_q: 0.019427
  8196/100000: episode: 1035, duration: 0.016s, episode steps: 3, steps per second: 182, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000566, mae: 0.017721, mean_q: 0.023267
  8199/100000: episode: 1036, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000421, mae: 0.018813, mean_q: 0.023138
  8202/100000: episode: 1037, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000355, mae: 0.014834, mean_q: 0.020970
  8205/100000: episode: 1038, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000452, mae: 0.015996, mean_q: 0.027946
  8208/100000: episode: 1039, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001282, mae: 0.020146, mean_q: 0.019968
  8211/100000: episode: 1040, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000992, mae: 0.020780, mean_q: 0.025423
  8216/100000: episode: 1041, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.002770, mae: 0.021600, mean_q: 0.019519
  8219/100000: episode: 1042, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001442, mae: 0.024277, mean_q: 0.028664
  8222/100000: episode: 1043, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000617, mae: 0.014886, mean_q: 0.021222
  8225/100000: episode: 1044, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003962, mae: 0.028167, mean_q: 0.027341
  8230/100000: episode: 1045, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000718, mae: 0.014474, mean_q: 0.013132
  8233/100000: episode: 1046, duration: 0.019s, episode steps: 3, steps per second: 161, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001068, mae: 0.017109, mean_q: 0.029062
  8238/100000: episode: 1047, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000630, mae: 0.014136, mean_q: 0.019299
  8243/100000: episode: 1048, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001116, mae: 0.019389, mean_q: 0.022383
  8248/100000: episode: 1049, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000725, mae: 0.016692, mean_q: 0.022169
  8251/100000: episode: 1050, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000486, mae: 0.013248, mean_q: 0.012455
  8254/100000: episode: 1051, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.002438, mae: 0.020541, mean_q: 0.021862
  8257/100000: episode: 1052, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000811, mae: 0.014375, mean_q: 0.020782
  8262/100000: episode: 1053, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.001816, mae: 0.017334, mean_q: 0.015306
  8265/100000: episode: 1054, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003456, mae: 0.022220, mean_q: 0.019273
  8270/100000: episode: 1055, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001075, mae: 0.018826, mean_q: 0.024932
  8273/100000: episode: 1056, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001193, mae: 0.019399, mean_q: 0.023871
  8278/100000: episode: 1057, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000507, mae: 0.012708, mean_q: 0.012269
  8281/100000: episode: 1058, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.001354, mae: 0.014876, mean_q: 0.010811
  8284/100000: episode: 1059, duration: 0.018s, episode steps: 3, steps per second: 170, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000911, mae: 0.016950, mean_q: 0.011319
  8287/100000: episode: 1060, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000315, mae: 0.010922, mean_q: 0.018714
[Info] FALSIFICATION!
  8291/100000: episode: 1061, duration: 0.276s, episode steps: 4, steps per second: 14, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.002832, mae: 0.026928, mean_q: 0.029704
  8294/100000: episode: 1062, duration: 0.020s, episode steps: 3, steps per second: 151, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000654, mae: 0.015930, mean_q: 0.020487
[Info] FALSIFICATION!
  8298/100000: episode: 1063, duration: 0.269s, episode steps: 4, steps per second: 15, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000547, mae: 0.016777, mean_q: 0.022908
  8303/100000: episode: 1064, duration: 0.030s, episode steps: 5, steps per second: 168, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000884, mae: 0.016001, mean_q: 0.024006
  8306/100000: episode: 1065, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000771, mae: 0.018328, mean_q: 0.015928
  8309/100000: episode: 1066, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000476, mae: 0.011697, mean_q: 0.007523
  8314/100000: episode: 1067, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003527, mae: 0.026720, mean_q: 0.020494
  8319/100000: episode: 1068, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000969, mae: 0.019620, mean_q: 0.028521
  8324/100000: episode: 1069, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.004109, mae: 0.029781, mean_q: 0.029320
  8327/100000: episode: 1070, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000209, mae: 0.010952, mean_q: 0.010943
  8330/100000: episode: 1071, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000837, mae: 0.018388, mean_q: 0.025691
  8333/100000: episode: 1072, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000241, mae: 0.009974, mean_q: 0.009678
  8338/100000: episode: 1073, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 1.922, mean reward: 0.384 [0.050, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 8.800 [7.000, 11.000], loss: 0.000682, mae: 0.016055, mean_q: 0.010426
  8343/100000: episode: 1074, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001122, mae: 0.020061, mean_q: 0.022173
  8346/100000: episode: 1075, duration: 0.017s, episode steps: 3, steps per second: 177, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000765, mae: 0.017727, mean_q: 0.024664
  8351/100000: episode: 1076, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002745, mae: 0.026392, mean_q: 0.030673
  8354/100000: episode: 1077, duration: 0.017s, episode steps: 3, steps per second: 174, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000804, mae: 0.015772, mean_q: 0.023887
  8359/100000: episode: 1078, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.001026, mae: 0.019524, mean_q: 0.024392
  8362/100000: episode: 1079, duration: 0.017s, episode steps: 3, steps per second: 181, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001120, mae: 0.021374, mean_q: 0.011765
  8365/100000: episode: 1080, duration: 0.016s, episode steps: 3, steps per second: 184, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.001736, mae: 0.026407, mean_q: 0.014832
  8370/100000: episode: 1081, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000759, mae: 0.017845, mean_q: 0.016641
  8373/100000: episode: 1082, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.003200, mae: 0.025733, mean_q: 0.024660
  8378/100000: episode: 1083, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.001741, mae: 0.027270, mean_q: 0.036856
  8383/100000: episode: 1084, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000708, mae: 0.017659, mean_q: 0.019772
  8388/100000: episode: 1085, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000669, mae: 0.017031, mean_q: 0.016392
  8391/100000: episode: 1086, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000654, mae: 0.018632, mean_q: 0.005479
  8394/100000: episode: 1087, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000457, mae: 0.014050, mean_q: 0.011560
  8399/100000: episode: 1088, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.001432, mae: 0.024252, mean_q: 0.028236
[Info] Complete ISplit Iteration
[Info] Levels: [0.005566022, 0.0069009108, 0.11459953, 0.50956124]
[Info] Cond. Prob: [1.0, 0.16, 0.13, 0.02]
[Info] Error Prob: 0.0004160000000000001

  8404/100000: episode: 1089, duration: 0.910s, episode steps: 5, steps per second: 5, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000646, mae: 0.017317, mean_q: 0.013524
  8414/100000: episode: 1090, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001357, mae: 0.025088, mean_q: 0.028660
  8424/100000: episode: 1091, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001680, mae: 0.018649, mean_q: 0.019110
  8434/100000: episode: 1092, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001890, mae: 0.020845, mean_q: 0.025503
  8444/100000: episode: 1093, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001016, mae: 0.018177, mean_q: 0.017204
  8454/100000: episode: 1094, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001673, mae: 0.018664, mean_q: 0.024004
  8464/100000: episode: 1095, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001078, mae: 0.021024, mean_q: 0.023959
  8474/100000: episode: 1096, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000695, mae: 0.016388, mean_q: 0.015297
  8484/100000: episode: 1097, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001561, mae: 0.016693, mean_q: 0.014957
  8494/100000: episode: 1098, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000815, mae: 0.017990, mean_q: 0.020374
  8504/100000: episode: 1099, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001249, mae: 0.018629, mean_q: 0.024903
  8514/100000: episode: 1100, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002278, mae: 0.023421, mean_q: 0.030638
  8524/100000: episode: 1101, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000717, mae: 0.014892, mean_q: 0.016350
  8534/100000: episode: 1102, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002845, mae: 0.027652, mean_q: 0.036392
  8544/100000: episode: 1103, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001968, mae: 0.023358, mean_q: 0.030410
  8554/100000: episode: 1104, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001136, mae: 0.020139, mean_q: 0.017344
  8564/100000: episode: 1105, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001298, mae: 0.017729, mean_q: 0.015735
  8574/100000: episode: 1106, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000873, mae: 0.018852, mean_q: 0.019436
  8584/100000: episode: 1107, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001419, mae: 0.018776, mean_q: 0.018176
  8594/100000: episode: 1108, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001583, mae: 0.018961, mean_q: 0.027710
  8604/100000: episode: 1109, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001047, mae: 0.020401, mean_q: 0.020015
  8614/100000: episode: 1110, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000972, mae: 0.016171, mean_q: 0.010198
  8624/100000: episode: 1111, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001971, mae: 0.023138, mean_q: 0.027732
  8634/100000: episode: 1112, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000780, mae: 0.016491, mean_q: 0.017384
  8644/100000: episode: 1113, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000708, mae: 0.015754, mean_q: 0.015563
  8654/100000: episode: 1114, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001559, mae: 0.022079, mean_q: 0.027519
  8664/100000: episode: 1115, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002041, mae: 0.022199, mean_q: 0.022724
  8674/100000: episode: 1116, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000552, mae: 0.014459, mean_q: 0.015279
  8684/100000: episode: 1117, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000721, mae: 0.017774, mean_q: 0.016644
  8694/100000: episode: 1118, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000763, mae: 0.015552, mean_q: 0.017837
  8704/100000: episode: 1119, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001878, mae: 0.020398, mean_q: 0.024352
  8714/100000: episode: 1120, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002554, mae: 0.019419, mean_q: 0.019431
  8724/100000: episode: 1121, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000879, mae: 0.016032, mean_q: 0.018004
  8734/100000: episode: 1122, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001630, mae: 0.016391, mean_q: 0.022639
  8744/100000: episode: 1123, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000896, mae: 0.017502, mean_q: 0.022096
  8754/100000: episode: 1124, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.002058, mae: 0.019988, mean_q: 0.021549
  8764/100000: episode: 1125, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000982, mae: 0.017243, mean_q: 0.023780
  8774/100000: episode: 1126, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000768, mae: 0.016132, mean_q: 0.019238
  8784/100000: episode: 1127, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000838, mae: 0.017130, mean_q: 0.017112
  8794/100000: episode: 1128, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001222, mae: 0.021390, mean_q: 0.026960
  8804/100000: episode: 1129, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002430, mae: 0.020050, mean_q: 0.018690
  8814/100000: episode: 1130, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001501, mae: 0.020534, mean_q: 0.026814
  8824/100000: episode: 1131, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002610, mae: 0.020049, mean_q: 0.019590
  8834/100000: episode: 1132, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000802, mae: 0.015833, mean_q: 0.018217
  8844/100000: episode: 1133, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000874, mae: 0.017293, mean_q: 0.015227
  8854/100000: episode: 1134, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001472, mae: 0.016056, mean_q: 0.014470
  8864/100000: episode: 1135, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002548, mae: 0.024638, mean_q: 0.028504
  8874/100000: episode: 1136, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001919, mae: 0.018528, mean_q: 0.024636
  8884/100000: episode: 1137, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002348, mae: 0.023300, mean_q: 0.034413
  8894/100000: episode: 1138, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001099, mae: 0.015897, mean_q: 0.020975
  8904/100000: episode: 1139, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001337, mae: 0.018020, mean_q: 0.026779
  8914/100000: episode: 1140, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000932, mae: 0.016210, mean_q: 0.013935
  8924/100000: episode: 1141, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001646, mae: 0.019986, mean_q: 0.020131
  8934/100000: episode: 1142, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001955, mae: 0.022491, mean_q: 0.029265
  8944/100000: episode: 1143, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001092, mae: 0.018848, mean_q: 0.015135
  8954/100000: episode: 1144, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002937, mae: 0.022486, mean_q: 0.015865
  8964/100000: episode: 1145, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001107, mae: 0.020881, mean_q: 0.031748
  8974/100000: episode: 1146, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001193, mae: 0.022548, mean_q: 0.028898
  8984/100000: episode: 1147, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002341, mae: 0.020697, mean_q: 0.013335
  8994/100000: episode: 1148, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000834, mae: 0.019324, mean_q: 0.017428
  9004/100000: episode: 1149, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001033, mae: 0.019729, mean_q: 0.028281
  9014/100000: episode: 1150, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001929, mae: 0.022040, mean_q: 0.019816
  9024/100000: episode: 1151, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002012, mae: 0.019777, mean_q: 0.020793
  9034/100000: episode: 1152, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000772, mae: 0.016083, mean_q: 0.023085
  9044/100000: episode: 1153, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001137, mae: 0.019038, mean_q: 0.017230
  9054/100000: episode: 1154, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001557, mae: 0.020840, mean_q: 0.024937
  9064/100000: episode: 1155, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000931, mae: 0.018030, mean_q: 0.022572
  9074/100000: episode: 1156, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001444, mae: 0.017939, mean_q: 0.020914
  9084/100000: episode: 1157, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001265, mae: 0.017268, mean_q: 0.018235
  9094/100000: episode: 1158, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000517, mae: 0.013950, mean_q: 0.015169
  9104/100000: episode: 1159, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000777, mae: 0.016074, mean_q: 0.022028
  9114/100000: episode: 1160, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001331, mae: 0.021528, mean_q: 0.027931
  9124/100000: episode: 1161, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001757, mae: 0.021918, mean_q: 0.026076
  9134/100000: episode: 1162, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001443, mae: 0.018961, mean_q: 0.028443
  9144/100000: episode: 1163, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001475, mae: 0.020289, mean_q: 0.018763
  9154/100000: episode: 1164, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001873, mae: 0.020215, mean_q: 0.021764
  9164/100000: episode: 1165, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001592, mae: 0.020841, mean_q: 0.023484
  9174/100000: episode: 1166, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002167, mae: 0.025140, mean_q: 0.031052
  9184/100000: episode: 1167, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000969, mae: 0.017501, mean_q: 0.016930
  9194/100000: episode: 1168, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001633, mae: 0.018278, mean_q: 0.026938
  9204/100000: episode: 1169, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.002017, mae: 0.020528, mean_q: 0.028597
  9214/100000: episode: 1170, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000675, mae: 0.015416, mean_q: 0.014663
  9224/100000: episode: 1171, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001441, mae: 0.015918, mean_q: 0.010621
  9234/100000: episode: 1172, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000996, mae: 0.019651, mean_q: 0.021095
  9244/100000: episode: 1173, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000485, mae: 0.014901, mean_q: 0.019992
  9254/100000: episode: 1174, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001114, mae: 0.020673, mean_q: 0.026760
  9264/100000: episode: 1175, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002519, mae: 0.023777, mean_q: 0.016248
  9274/100000: episode: 1176, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001953, mae: 0.021258, mean_q: 0.022260
  9284/100000: episode: 1177, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000702, mae: 0.017451, mean_q: 0.021327
  9294/100000: episode: 1178, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000934, mae: 0.017895, mean_q: 0.022946
  9304/100000: episode: 1179, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001441, mae: 0.018854, mean_q: 0.026637
  9314/100000: episode: 1180, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000627, mae: 0.014245, mean_q: 0.019074
  9324/100000: episode: 1181, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000600, mae: 0.013220, mean_q: 0.013009
  9334/100000: episode: 1182, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000567, mae: 0.013837, mean_q: 0.015290
  9344/100000: episode: 1183, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000761, mae: 0.016209, mean_q: 0.014078
  9354/100000: episode: 1184, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002474, mae: 0.019327, mean_q: 0.017231
  9364/100000: episode: 1185, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.002444, mae: 0.022571, mean_q: 0.023976
  9374/100000: episode: 1186, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000925, mae: 0.017991, mean_q: 0.024179
  9384/100000: episode: 1187, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001850, mae: 0.019238, mean_q: 0.022353
  9394/100000: episode: 1188, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001403, mae: 0.018345, mean_q: 0.025042
[Info] 1-TH LEVEL FOUND: 0.006487512029707432, Considering 100/100 traces
  9404/100000: episode: 1189, duration: 0.703s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000832, mae: 0.017348, mean_q: 0.022679
[Info] 2-TH LEVEL FOUND: 0.009393545798957348, Considering 100/100 traces
  9414/100000: episode: 1190, duration: 0.673s, episode steps: 10, steps per second: 15, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.002329, mae: 0.021466, mean_q: 0.020439
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.009393545798957348
  9424/100000: episode: 1191, duration: 0.479s, episode steps: 10, steps per second: 21, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001454, mae: 0.022660, mean_q: 0.028075
  9434/100000: episode: 1192, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.002404, mae: 0.021034, mean_q: 0.027583
  9444/100000: episode: 1193, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.002195, mae: 0.019699, mean_q: 0.019656
  9454/100000: episode: 1194, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000920, mae: 0.016153, mean_q: 0.017208
  9464/100000: episode: 1195, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000628, mae: 0.013789, mean_q: 0.018585
  9474/100000: episode: 1196, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001768, mae: 0.017144, mean_q: 0.015811
  9484/100000: episode: 1197, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002148, mae: 0.023343, mean_q: 0.027125
  9494/100000: episode: 1198, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000541, mae: 0.014602, mean_q: 0.013148
  9504/100000: episode: 1199, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002125, mae: 0.017967, mean_q: 0.010058
  9514/100000: episode: 1200, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001914, mae: 0.021497, mean_q: 0.025666
  9524/100000: episode: 1201, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001366, mae: 0.020008, mean_q: 0.028828
  9534/100000: episode: 1202, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002343, mae: 0.020813, mean_q: 0.020329
  9544/100000: episode: 1203, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000646, mae: 0.014195, mean_q: 0.015830
  9554/100000: episode: 1204, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001295, mae: 0.016435, mean_q: 0.016121
  9564/100000: episode: 1205, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000853, mae: 0.017006, mean_q: 0.020954
  9574/100000: episode: 1206, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.002833, mae: 0.020858, mean_q: 0.022067
  9584/100000: episode: 1207, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001749, mae: 0.018596, mean_q: 0.020900
  9594/100000: episode: 1208, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000820, mae: 0.014954, mean_q: 0.018289
  9604/100000: episode: 1209, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.002432, mae: 0.019178, mean_q: 0.019224
  9614/100000: episode: 1210, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000923, mae: 0.016398, mean_q: 0.021119
  9624/100000: episode: 1211, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000469, mae: 0.011735, mean_q: 0.010188
  9634/100000: episode: 1212, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000437, mae: 0.011488, mean_q: 0.010434
  9644/100000: episode: 1213, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000438, mae: 0.012112, mean_q: 0.014462
  9654/100000: episode: 1214, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000485, mae: 0.011887, mean_q: 0.011859
  9664/100000: episode: 1215, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001023, mae: 0.017934, mean_q: 0.014308
  9674/100000: episode: 1216, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000555, mae: 0.014849, mean_q: 0.014439
  9684/100000: episode: 1217, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001846, mae: 0.020210, mean_q: 0.021718
  9694/100000: episode: 1218, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001549, mae: 0.018229, mean_q: 0.021050
  9704/100000: episode: 1219, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000971, mae: 0.017223, mean_q: 0.026891
  9714/100000: episode: 1220, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001650, mae: 0.017807, mean_q: 0.017243
  9724/100000: episode: 1221, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000753, mae: 0.014513, mean_q: 0.012840
  9734/100000: episode: 1222, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000906, mae: 0.017430, mean_q: 0.014183
  9744/100000: episode: 1223, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000552, mae: 0.012983, mean_q: 0.017319
  9754/100000: episode: 1224, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000546, mae: 0.013282, mean_q: 0.015446
  9764/100000: episode: 1225, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000799, mae: 0.014777, mean_q: 0.017801
  9774/100000: episode: 1226, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000859, mae: 0.016345, mean_q: 0.021237
  9784/100000: episode: 1227, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000916, mae: 0.015388, mean_q: 0.020305
  9794/100000: episode: 1228, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001062, mae: 0.014332, mean_q: 0.017920
  9804/100000: episode: 1229, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000691, mae: 0.013977, mean_q: 0.012649
  9814/100000: episode: 1230, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000600, mae: 0.013728, mean_q: 0.013028
  9824/100000: episode: 1231, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001589, mae: 0.016688, mean_q: 0.018148
  9834/100000: episode: 1232, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000891, mae: 0.018286, mean_q: 0.021909
  9844/100000: episode: 1233, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001278, mae: 0.014470, mean_q: 0.012275
  9854/100000: episode: 1234, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001025, mae: 0.013704, mean_q: 0.014923
  9864/100000: episode: 1235, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000530, mae: 0.013452, mean_q: 0.021977
  9874/100000: episode: 1236, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001510, mae: 0.016181, mean_q: 0.019931
  9884/100000: episode: 1237, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000807, mae: 0.015590, mean_q: 0.019757
  9894/100000: episode: 1238, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000598, mae: 0.012048, mean_q: 0.010991
  9904/100000: episode: 1239, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001599, mae: 0.017045, mean_q: 0.017414
  9914/100000: episode: 1240, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000935, mae: 0.012562, mean_q: 0.013926
  9924/100000: episode: 1241, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000552, mae: 0.012724, mean_q: 0.017308
  9934/100000: episode: 1242, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001501, mae: 0.014636, mean_q: 0.013530
  9944/100000: episode: 1243, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001617, mae: 0.019710, mean_q: 0.030956
  9954/100000: episode: 1244, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000740, mae: 0.013809, mean_q: 0.019411
  9964/100000: episode: 1245, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000710, mae: 0.013687, mean_q: 0.009955
  9974/100000: episode: 1246, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000642, mae: 0.012624, mean_q: 0.015035
  9984/100000: episode: 1247, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000608, mae: 0.013900, mean_q: 0.018067
  9994/100000: episode: 1248, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001490, mae: 0.014067, mean_q: 0.016003
 10004/100000: episode: 1249, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000691, mae: 0.014812, mean_q: 0.017749
 10014/100000: episode: 1250, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001755, mae: 0.014776, mean_q: 0.018432
 10024/100000: episode: 1251, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001581, mae: 0.017317, mean_q: 0.025270
 10034/100000: episode: 1252, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000786, mae: 0.013641, mean_q: 0.014927
 10044/100000: episode: 1253, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001632, mae: 0.016279, mean_q: 0.011864
 10054/100000: episode: 1254, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001156, mae: 0.014864, mean_q: 0.017344
 10064/100000: episode: 1255, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.002898, mae: 0.025263, mean_q: 0.022202
 10074/100000: episode: 1256, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001472, mae: 0.015831, mean_q: 0.019125
 10084/100000: episode: 1257, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000797, mae: 0.014698, mean_q: 0.016763
 10094/100000: episode: 1258, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000885, mae: 0.016766, mean_q: 0.012031
 10104/100000: episode: 1259, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000506, mae: 0.012411, mean_q: 0.013339
 10114/100000: episode: 1260, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001220, mae: 0.016298, mean_q: 0.018480
 10124/100000: episode: 1261, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001477, mae: 0.016336, mean_q: 0.021376
 10134/100000: episode: 1262, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.002069, mae: 0.018386, mean_q: 0.017859
 10144/100000: episode: 1263, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000594, mae: 0.011285, mean_q: 0.009842
 10154/100000: episode: 1264, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000758, mae: 0.013752, mean_q: 0.017311
 10164/100000: episode: 1265, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001108, mae: 0.019511, mean_q: 0.023796
 10174/100000: episode: 1266, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000935, mae: 0.015320, mean_q: 0.018176
 10184/100000: episode: 1267, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000662, mae: 0.014431, mean_q: 0.013299
 10194/100000: episode: 1268, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001736, mae: 0.018325, mean_q: 0.019336
 10204/100000: episode: 1269, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000766, mae: 0.015011, mean_q: 0.015714
 10214/100000: episode: 1270, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000519, mae: 0.012257, mean_q: 0.016684
 10224/100000: episode: 1271, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001471, mae: 0.015435, mean_q: 0.017648
 10234/100000: episode: 1272, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001724, mae: 0.019111, mean_q: 0.021773
 10244/100000: episode: 1273, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000716, mae: 0.013392, mean_q: 0.013852
 10254/100000: episode: 1274, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001875, mae: 0.015495, mean_q: 0.011434
 10264/100000: episode: 1275, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002013, mae: 0.022716, mean_q: 0.030476
 10274/100000: episode: 1276, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000676, mae: 0.014342, mean_q: 0.017415
 10284/100000: episode: 1277, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001610, mae: 0.013870, mean_q: 0.008814
 10294/100000: episode: 1278, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000427, mae: 0.012246, mean_q: 0.014793
 10304/100000: episode: 1279, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001899, mae: 0.021833, mean_q: 0.026351
 10314/100000: episode: 1280, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000866, mae: 0.017866, mean_q: 0.021259
 10324/100000: episode: 1281, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000499, mae: 0.010788, mean_q: 0.008912
 10334/100000: episode: 1282, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001391, mae: 0.014358, mean_q: 0.009564
 10344/100000: episode: 1283, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000563, mae: 0.014776, mean_q: 0.015678
 10354/100000: episode: 1284, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001370, mae: 0.017765, mean_q: 0.016889
 10364/100000: episode: 1285, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001429, mae: 0.015030, mean_q: 0.020669
 10374/100000: episode: 1286, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001023, mae: 0.014971, mean_q: 0.021559
 10384/100000: episode: 1287, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001988, mae: 0.017073, mean_q: 0.019733
 10394/100000: episode: 1288, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000636, mae: 0.012127, mean_q: 0.018858
 10404/100000: episode: 1289, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000571, mae: 0.011889, mean_q: 0.013700
 10414/100000: episode: 1290, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000684, mae: 0.012436, mean_q: 0.006663
[Info] 1-TH LEVEL FOUND: 0.012585869058966637, Considering 100/100 traces
 10424/100000: episode: 1291, duration: 0.735s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001170, mae: 0.014268, mean_q: 0.014009
[Info] 2-TH LEVEL FOUND: 0.013554063625633717, Considering 100/100 traces
 10434/100000: episode: 1292, duration: 0.692s, episode steps: 10, steps per second: 14, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001231, mae: 0.016675, mean_q: 0.018808
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.013554063625633717
 10444/100000: episode: 1293, duration: 0.486s, episode steps: 10, steps per second: 21, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000685, mae: 0.016152, mean_q: 0.024125
 10454/100000: episode: 1294, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001002, mae: 0.011851, mean_q: 0.012225
 10464/100000: episode: 1295, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000750, mae: 0.014244, mean_q: 0.015280
 10474/100000: episode: 1296, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000780, mae: 0.015132, mean_q: 0.017401
 10484/100000: episode: 1297, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001539, mae: 0.016486, mean_q: 0.023752
 10494/100000: episode: 1298, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001467, mae: 0.014402, mean_q: 0.016927
 10504/100000: episode: 1299, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000947, mae: 0.011828, mean_q: 0.012222
 10514/100000: episode: 1300, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001444, mae: 0.014313, mean_q: 0.015291
 10524/100000: episode: 1301, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000646, mae: 0.012901, mean_q: 0.020260
 10534/100000: episode: 1302, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001424, mae: 0.012830, mean_q: 0.011349
 10544/100000: episode: 1303, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000518, mae: 0.011395, mean_q: 0.012944
 10554/100000: episode: 1304, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001536, mae: 0.017192, mean_q: 0.018798
 10564/100000: episode: 1305, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000738, mae: 0.015471, mean_q: 0.018353
 10574/100000: episode: 1306, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000615, mae: 0.013448, mean_q: 0.017659
 10584/100000: episode: 1307, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001510, mae: 0.016425, mean_q: 0.019823
 10594/100000: episode: 1308, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000604, mae: 0.010770, mean_q: 0.013045
 10604/100000: episode: 1309, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002874, mae: 0.021082, mean_q: 0.021818
 10614/100000: episode: 1310, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.002183, mae: 0.021552, mean_q: 0.028544
 10624/100000: episode: 1311, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000929, mae: 0.016752, mean_q: 0.014595
 10634/100000: episode: 1312, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000568, mae: 0.011843, mean_q: 0.007386
 10644/100000: episode: 1313, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000870, mae: 0.013571, mean_q: 0.007682
 10654/100000: episode: 1314, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000339, mae: 0.013671, mean_q: 0.012246
 10664/100000: episode: 1315, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001857, mae: 0.020117, mean_q: 0.019001
 10674/100000: episode: 1316, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000600, mae: 0.014572, mean_q: 0.022554
 10684/100000: episode: 1317, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001829, mae: 0.015952, mean_q: 0.017473
 10694/100000: episode: 1318, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001581, mae: 0.016401, mean_q: 0.017198
 10704/100000: episode: 1319, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.002196, mae: 0.017279, mean_q: 0.017527
 10714/100000: episode: 1320, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000658, mae: 0.011867, mean_q: 0.018647
 10724/100000: episode: 1321, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001298, mae: 0.013236, mean_q: 0.016405
 10734/100000: episode: 1322, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000497, mae: 0.012212, mean_q: 0.016589
 10744/100000: episode: 1323, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000553, mae: 0.011201, mean_q: 0.013369
 10754/100000: episode: 1324, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000557, mae: 0.013261, mean_q: 0.014139
 10764/100000: episode: 1325, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000359, mae: 0.009694, mean_q: 0.009176
 10774/100000: episode: 1326, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000703, mae: 0.013070, mean_q: 0.010287
 10784/100000: episode: 1327, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000382, mae: 0.013818, mean_q: 0.013609
 10794/100000: episode: 1328, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000960, mae: 0.014953, mean_q: 0.016956
 10804/100000: episode: 1329, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000795, mae: 0.015037, mean_q: 0.020443
 10814/100000: episode: 1330, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000550, mae: 0.012430, mean_q: 0.015305
 10824/100000: episode: 1331, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000325, mae: 0.009054, mean_q: 0.010304
 10834/100000: episode: 1332, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002275, mae: 0.015510, mean_q: 0.014629
 10844/100000: episode: 1333, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000979, mae: 0.014245, mean_q: 0.018058
 10854/100000: episode: 1334, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000604, mae: 0.011223, mean_q: 0.020409
 10864/100000: episode: 1335, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000350, mae: 0.009430, mean_q: 0.007463
 10874/100000: episode: 1336, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001103, mae: 0.010727, mean_q: 0.007957
 10884/100000: episode: 1337, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000454, mae: 0.011416, mean_q: 0.010095
 10894/100000: episode: 1338, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000431, mae: 0.012215, mean_q: 0.016292
 10904/100000: episode: 1339, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001201, mae: 0.013486, mean_q: 0.017770
 10914/100000: episode: 1340, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000811, mae: 0.014823, mean_q: 0.016324
 10924/100000: episode: 1341, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000453, mae: 0.009994, mean_q: 0.007332
 10934/100000: episode: 1342, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000387, mae: 0.010348, mean_q: 0.009057
 10944/100000: episode: 1343, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000442, mae: 0.012104, mean_q: 0.010846
 10954/100000: episode: 1344, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001396, mae: 0.014065, mean_q: 0.014967
 10964/100000: episode: 1345, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000586, mae: 0.013856, mean_q: 0.021470
 10974/100000: episode: 1346, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.002013, mae: 0.015715, mean_q: 0.016502
 10984/100000: episode: 1347, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000623, mae: 0.011402, mean_q: 0.013503
 10994/100000: episode: 1348, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000438, mae: 0.008866, mean_q: 0.013370
 11004/100000: episode: 1349, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000382, mae: 0.009539, mean_q: 0.010966
 11014/100000: episode: 1350, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000354, mae: 0.009523, mean_q: 0.011376
 11024/100000: episode: 1351, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000645, mae: 0.012207, mean_q: 0.016800
 11034/100000: episode: 1352, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000331, mae: 0.008943, mean_q: 0.013077
 11044/100000: episode: 1353, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.002291, mae: 0.016818, mean_q: 0.015802
 11054/100000: episode: 1354, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000926, mae: 0.014394, mean_q: 0.019977
 11064/100000: episode: 1355, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000539, mae: 0.010274, mean_q: 0.011035
 11074/100000: episode: 1356, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000779, mae: 0.010939, mean_q: 0.005564
 11084/100000: episode: 1357, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000457, mae: 0.011814, mean_q: 0.012626
 11094/100000: episode: 1358, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001282, mae: 0.013724, mean_q: 0.013998
 11104/100000: episode: 1359, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000919, mae: 0.014252, mean_q: 0.017285
 11114/100000: episode: 1360, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001017, mae: 0.012357, mean_q: 0.019053
 11124/100000: episode: 1361, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000449, mae: 0.010082, mean_q: 0.012269
 11134/100000: episode: 1362, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000552, mae: 0.009020, mean_q: 0.006951
 11144/100000: episode: 1363, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001642, mae: 0.013042, mean_q: 0.011900
 11154/100000: episode: 1364, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000550, mae: 0.011936, mean_q: 0.016571
 11164/100000: episode: 1365, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001045, mae: 0.010987, mean_q: 0.013877
 11174/100000: episode: 1366, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001656, mae: 0.015546, mean_q: 0.019957
 11184/100000: episode: 1367, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001272, mae: 0.012106, mean_q: 0.016756
 11194/100000: episode: 1368, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000667, mae: 0.010101, mean_q: 0.013784
 11204/100000: episode: 1369, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000994, mae: 0.012922, mean_q: 0.008176
 11214/100000: episode: 1370, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000491, mae: 0.010852, mean_q: 0.010244
 11224/100000: episode: 1371, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001426, mae: 0.014157, mean_q: 0.013938
 11234/100000: episode: 1372, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000484, mae: 0.012341, mean_q: 0.015372
 11244/100000: episode: 1373, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000291, mae: 0.007650, mean_q: 0.010793
 11254/100000: episode: 1374, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000367, mae: 0.007734, mean_q: 0.009882
 11264/100000: episode: 1375, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000841, mae: 0.009362, mean_q: 0.009726
 11274/100000: episode: 1376, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001196, mae: 0.011461, mean_q: 0.018694
 11284/100000: episode: 1377, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000666, mae: 0.010732, mean_q: 0.014789
 11294/100000: episode: 1378, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000750, mae: 0.012206, mean_q: 0.010603
 11304/100000: episode: 1379, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001558, mae: 0.013321, mean_q: 0.011338
 11314/100000: episode: 1380, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002159, mae: 0.016342, mean_q: 0.021247
 11324/100000: episode: 1381, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000396, mae: 0.008977, mean_q: 0.009565
 11334/100000: episode: 1382, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000587, mae: 0.009579, mean_q: 0.004184
 11344/100000: episode: 1383, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001883, mae: 0.011941, mean_q: 0.008448
 11354/100000: episode: 1384, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000394, mae: 0.012748, mean_q: 0.014579
 11364/100000: episode: 1385, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.002110, mae: 0.017888, mean_q: 0.017951
 11374/100000: episode: 1386, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001370, mae: 0.012336, mean_q: 0.013922
 11384/100000: episode: 1387, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000276, mae: 0.007503, mean_q: 0.006164
 11394/100000: episode: 1388, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000498, mae: 0.009916, mean_q: 0.007227
 11404/100000: episode: 1389, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000445, mae: 0.009848, mean_q: 0.010558
 11414/100000: episode: 1390, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000219, mae: 0.006759, mean_q: 0.009289
 11424/100000: episode: 1391, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001328, mae: 0.009410, mean_q: 0.008304
 11434/100000: episode: 1392, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001080, mae: 0.009874, mean_q: 0.010312
[Info] 1-TH LEVEL FOUND: 0.0031866985373198986, Considering 100/100 traces
 11444/100000: episode: 1393, duration: 0.685s, episode steps: 10, steps per second: 15, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000371, mae: 0.007720, mean_q: 0.015943
[Info] 2-TH LEVEL FOUND: 0.005829518660902977, Considering 100/100 traces
 11454/100000: episode: 1394, duration: 0.634s, episode steps: 10, steps per second: 16, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000835, mae: 0.010018, mean_q: 0.009789
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005829518660902977
 11455/100000: episode: 1395, duration: 0.515s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.001240, mae: 0.017275, mean_q: 0.009859
 11465/100000: episode: 1396, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000520, mae: 0.009490, mean_q: 0.009130
 11475/100000: episode: 1397, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001854, mae: 0.012596, mean_q: 0.016660
 11485/100000: episode: 1398, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000471, mae: 0.009252, mean_q: 0.015341
 11495/100000: episode: 1399, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000407, mae: 0.008097, mean_q: 0.006762
 11505/100000: episode: 1400, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001330, mae: 0.012482, mean_q: 0.018659
 11515/100000: episode: 1401, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001213, mae: 0.014025, mean_q: 0.021667
 11525/100000: episode: 1402, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000257, mae: 0.006208, mean_q: 0.007073
 11535/100000: episode: 1403, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000423, mae: 0.007977, mean_q: 0.007046
 11545/100000: episode: 1404, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001023, mae: 0.011123, mean_q: 0.012062
 11555/100000: episode: 1405, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000659, mae: 0.011286, mean_q: 0.014880
 11565/100000: episode: 1406, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001631, mae: 0.012834, mean_q: 0.010888
 11575/100000: episode: 1407, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001141, mae: 0.010225, mean_q: 0.011447
 11585/100000: episode: 1408, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000456, mae: 0.008325, mean_q: 0.011499
 11595/100000: episode: 1409, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000709, mae: 0.012309, mean_q: 0.012847
 11605/100000: episode: 1410, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000608, mae: 0.010766, mean_q: 0.011965
 11615/100000: episode: 1411, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000420, mae: 0.009206, mean_q: 0.011533
 11625/100000: episode: 1412, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000577, mae: 0.010259, mean_q: 0.011234
 11635/100000: episode: 1413, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001446, mae: 0.013098, mean_q: 0.012728
 11645/100000: episode: 1414, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001334, mae: 0.012904, mean_q: 0.016600
 11655/100000: episode: 1415, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000711, mae: 0.008404, mean_q: 0.011449
 11665/100000: episode: 1416, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001441, mae: 0.012221, mean_q: 0.012161
 11675/100000: episode: 1417, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000717, mae: 0.011681, mean_q: 0.017927
 11685/100000: episode: 1418, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000492, mae: 0.008597, mean_q: 0.010135
 11695/100000: episode: 1419, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000373, mae: 0.007817, mean_q: 0.008449
 11705/100000: episode: 1420, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000476, mae: 0.010076, mean_q: 0.008276
 11715/100000: episode: 1421, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001562, mae: 0.012075, mean_q: 0.011802
 11725/100000: episode: 1422, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000442, mae: 0.009223, mean_q: 0.013518
 11735/100000: episode: 1423, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001027, mae: 0.011122, mean_q: 0.013020
 11745/100000: episode: 1424, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000471, mae: 0.008897, mean_q: 0.012017
 11755/100000: episode: 1425, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000483, mae: 0.008694, mean_q: 0.007678
 11765/100000: episode: 1426, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000435, mae: 0.007980, mean_q: 0.009622
 11775/100000: episode: 1427, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001412, mae: 0.012814, mean_q: 0.013572
 11785/100000: episode: 1428, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000531, mae: 0.010160, mean_q: 0.017124
 11795/100000: episode: 1429, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000417, mae: 0.007661, mean_q: 0.009412
 11805/100000: episode: 1430, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000261, mae: 0.005252, mean_q: 0.005062
 11815/100000: episode: 1431, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001327, mae: 0.011363, mean_q: 0.011048
 11825/100000: episode: 1432, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001034, mae: 0.015058, mean_q: 0.017269
 11835/100000: episode: 1433, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000299, mae: 0.008986, mean_q: 0.011474
 11845/100000: episode: 1434, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000762, mae: 0.009968, mean_q: 0.010698
 11855/100000: episode: 1435, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000693, mae: 0.012571, mean_q: 0.015237
 11865/100000: episode: 1436, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000354, mae: 0.008556, mean_q: 0.007804
 11875/100000: episode: 1437, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000959, mae: 0.009370, mean_q: 0.009153
 11885/100000: episode: 1438, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000675, mae: 0.014984, mean_q: 0.018822
 11895/100000: episode: 1439, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000518, mae: 0.010340, mean_q: 0.011013
 11905/100000: episode: 1440, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.001382, mae: 0.009081, mean_q: 0.005483
 11915/100000: episode: 1441, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001145, mae: 0.009865, mean_q: 0.008186
 11925/100000: episode: 1442, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000700, mae: 0.012827, mean_q: 0.016992
 11935/100000: episode: 1443, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000625, mae: 0.011255, mean_q: 0.014674
 11945/100000: episode: 1444, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000531, mae: 0.010355, mean_q: 0.008367
 11955/100000: episode: 1445, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001487, mae: 0.008861, mean_q: 0.004571
 11965/100000: episode: 1446, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000360, mae: 0.010388, mean_q: 0.010270
 11975/100000: episode: 1447, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001411, mae: 0.015392, mean_q: 0.021144
 11985/100000: episode: 1448, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001290, mae: 0.015005, mean_q: 0.015145
 11995/100000: episode: 1449, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000510, mae: 0.009762, mean_q: 0.011426
 12005/100000: episode: 1450, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000421, mae: 0.009626, mean_q: 0.010762
 12015/100000: episode: 1451, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000553, mae: 0.009355, mean_q: 0.009870
 12025/100000: episode: 1452, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000224, mae: 0.006692, mean_q: 0.007766
 12035/100000: episode: 1453, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000424, mae: 0.009572, mean_q: 0.012129
 12045/100000: episode: 1454, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000084, mae: 0.004839, mean_q: 0.006279
 12055/100000: episode: 1455, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000199, mae: 0.006136, mean_q: 0.007019
 12065/100000: episode: 1456, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001643, mae: 0.012393, mean_q: 0.015579
 12075/100000: episode: 1457, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000624, mae: 0.009951, mean_q: 0.015162
 12085/100000: episode: 1458, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000424, mae: 0.007995, mean_q: 0.008150
 12095/100000: episode: 1459, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000485, mae: 0.010842, mean_q: 0.010192
 12105/100000: episode: 1460, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000361, mae: 0.008245, mean_q: 0.010504
 12115/100000: episode: 1461, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000482, mae: 0.009926, mean_q: 0.012006
 12125/100000: episode: 1462, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000885, mae: 0.013085, mean_q: 0.010408
 12135/100000: episode: 1463, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001436, mae: 0.013227, mean_q: 0.013983
 12145/100000: episode: 1464, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001342, mae: 0.014556, mean_q: 0.020434
 12155/100000: episode: 1465, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001451, mae: 0.011859, mean_q: 0.010643
 12165/100000: episode: 1466, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000227, mae: 0.006276, mean_q: 0.005201
 12175/100000: episode: 1467, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000348, mae: 0.006724, mean_q: 0.008768
 12185/100000: episode: 1468, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000540, mae: 0.009312, mean_q: 0.013524
 12195/100000: episode: 1469, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001617, mae: 0.015928, mean_q: 0.016046
 12205/100000: episode: 1470, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000296, mae: 0.008610, mean_q: 0.015046
 12215/100000: episode: 1471, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001009, mae: 0.013775, mean_q: 0.015858
 12225/100000: episode: 1472, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001791, mae: 0.012784, mean_q: 0.005501
 12235/100000: episode: 1473, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000439, mae: 0.011306, mean_q: 0.012108
 12245/100000: episode: 1474, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000610, mae: 0.012110, mean_q: 0.014369
 12255/100000: episode: 1475, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000356, mae: 0.007328, mean_q: 0.009126
 12265/100000: episode: 1476, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000303, mae: 0.007515, mean_q: 0.010592
 12275/100000: episode: 1477, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000280, mae: 0.007122, mean_q: 0.008380
 12285/100000: episode: 1478, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000546, mae: 0.010311, mean_q: 0.011617
 12295/100000: episode: 1479, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000436, mae: 0.009850, mean_q: 0.012130
 12305/100000: episode: 1480, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000270, mae: 0.006735, mean_q: 0.007918
 12315/100000: episode: 1481, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000640, mae: 0.010275, mean_q: 0.010468
 12325/100000: episode: 1482, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000464, mae: 0.010830, mean_q: 0.012508
 12335/100000: episode: 1483, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000220, mae: 0.006268, mean_q: 0.008765
 12345/100000: episode: 1484, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001877, mae: 0.012050, mean_q: 0.010336
 12355/100000: episode: 1485, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000832, mae: 0.010189, mean_q: 0.014771
 12365/100000: episode: 1486, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000416, mae: 0.008630, mean_q: 0.013933
 12375/100000: episode: 1487, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000619, mae: 0.011622, mean_q: 0.013150
 12385/100000: episode: 1488, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000528, mae: 0.010185, mean_q: 0.014024
 12395/100000: episode: 1489, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000575, mae: 0.010616, mean_q: 0.008999
 12405/100000: episode: 1490, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001358, mae: 0.011771, mean_q: 0.012253
 12415/100000: episode: 1491, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001006, mae: 0.012846, mean_q: 0.014536
 12425/100000: episode: 1492, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000970, mae: 0.011265, mean_q: 0.016140
 12435/100000: episode: 1493, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000950, mae: 0.010971, mean_q: 0.016368
 12445/100000: episode: 1494, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000628, mae: 0.010334, mean_q: 0.015737
[Info] 1-TH LEVEL FOUND: 0.008819113485515118, Considering 100/100 traces
 12455/100000: episode: 1495, duration: 0.657s, episode steps: 10, steps per second: 15, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000133, mae: 0.005752, mean_q: 0.002748
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.008819113485515118
 12456/100000: episode: 1496, duration: 0.450s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000211, mae: 0.005455, mean_q: 0.005223
 12466/100000: episode: 1497, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001364, mae: 0.010062, mean_q: 0.008076
 12476/100000: episode: 1498, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000423, mae: 0.010021, mean_q: 0.012336
 12486/100000: episode: 1499, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000428, mae: 0.008732, mean_q: 0.011444
 12496/100000: episode: 1500, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000223, mae: 0.006267, mean_q: 0.009025
 12506/100000: episode: 1501, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001910, mae: 0.014874, mean_q: 0.016345
 12516/100000: episode: 1502, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001486, mae: 0.011735, mean_q: 0.012158
 12526/100000: episode: 1503, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000313, mae: 0.007227, mean_q: 0.007672
 12536/100000: episode: 1504, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000180, mae: 0.005330, mean_q: 0.005382
 12546/100000: episode: 1505, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001378, mae: 0.011756, mean_q: 0.012535
 12556/100000: episode: 1506, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000257, mae: 0.008016, mean_q: 0.011027
 12566/100000: episode: 1507, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000333, mae: 0.007772, mean_q: 0.008999
 12576/100000: episode: 1508, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000574, mae: 0.009441, mean_q: 0.007616
 12586/100000: episode: 1509, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000437, mae: 0.009670, mean_q: 0.012745
 12596/100000: episode: 1510, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000321, mae: 0.008277, mean_q: 0.011574
 12606/100000: episode: 1511, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000391, mae: 0.008287, mean_q: 0.008040
 12616/100000: episode: 1512, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000333, mae: 0.007473, mean_q: 0.007044
 12626/100000: episode: 1513, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000373, mae: 0.007398, mean_q: 0.008842
 12636/100000: episode: 1514, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000960, mae: 0.011058, mean_q: 0.012845
 12646/100000: episode: 1515, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000524, mae: 0.009670, mean_q: 0.012921
 12656/100000: episode: 1516, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000946, mae: 0.008215, mean_q: 0.007166
 12666/100000: episode: 1517, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000561, mae: 0.009026, mean_q: 0.010805
 12676/100000: episode: 1518, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000327, mae: 0.006555, mean_q: 0.006615
 12686/100000: episode: 1519, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000198, mae: 0.006171, mean_q: 0.006342
 12696/100000: episode: 1520, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001366, mae: 0.011839, mean_q: 0.013180
 12706/100000: episode: 1521, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000510, mae: 0.008291, mean_q: 0.008671
 12716/100000: episode: 1522, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000272, mae: 0.005767, mean_q: 0.004980
 12726/100000: episode: 1523, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000308, mae: 0.006664, mean_q: 0.007284
 12736/100000: episode: 1524, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000401, mae: 0.008282, mean_q: 0.010355
 12746/100000: episode: 1525, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000952, mae: 0.007899, mean_q: 0.009080
 12756/100000: episode: 1526, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000371, mae: 0.006602, mean_q: 0.009237
 12766/100000: episode: 1527, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000214, mae: 0.005670, mean_q: 0.003976
 12776/100000: episode: 1528, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000189, mae: 0.005263, mean_q: 0.008128
 12786/100000: episode: 1529, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000901, mae: 0.007582, mean_q: 0.009485
 12796/100000: episode: 1530, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000381, mae: 0.007255, mean_q: 0.010293
 12806/100000: episode: 1531, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000108, mae: 0.003631, mean_q: 0.001273
 12816/100000: episode: 1532, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000791, mae: 0.008041, mean_q: 0.008678
 12826/100000: episode: 1533, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000059, mae: 0.003901, mean_q: 0.005924
 12836/100000: episode: 1534, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000066, mae: 0.004256, mean_q: 0.007371
 12846/100000: episode: 1535, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.003701, mean_q: 0.007233
 12856/100000: episode: 1536, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000112, mae: 0.004224, mean_q: 0.005284
 12866/100000: episode: 1537, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000090, mae: 0.003479, mean_q: 0.009142
 12876/100000: episode: 1538, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000188, mae: 0.003952, mean_q: 0.005222
 12886/100000: episode: 1539, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000040, mae: 0.002713, mean_q: 0.003314
 12896/100000: episode: 1540, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000034, mae: 0.002992, mean_q: 0.003400
 12906/100000: episode: 1541, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000081, mae: 0.003706, mean_q: 0.004224
 12916/100000: episode: 1542, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000008, mae: 0.002770, mean_q: 0.005042
 12926/100000: episode: 1543, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000058, mae: 0.003470, mean_q: 0.005490
 12936/100000: episode: 1544, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000054, mae: 0.003964, mean_q: 0.004876
 12946/100000: episode: 1545, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000137, mae: 0.004372, mean_q: 0.004610
 12956/100000: episode: 1546, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000049, mae: 0.004076, mean_q: 0.005466
 12966/100000: episode: 1547, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000078, mae: 0.003670, mean_q: 0.004344
 12976/100000: episode: 1548, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000095, mae: 0.004068, mean_q: 0.004921
 12986/100000: episode: 1549, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000043, mae: 0.003339, mean_q: 0.005568
 12996/100000: episode: 1550, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000104, mae: 0.004218, mean_q: 0.005425
 13006/100000: episode: 1551, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.002666, mean_q: 0.003799
 13016/100000: episode: 1552, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.003198, mean_q: 0.003650
 13026/100000: episode: 1553, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002643, mean_q: 0.003798
 13036/100000: episode: 1554, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000024, mae: 0.002923, mean_q: 0.004657
 13046/100000: episode: 1555, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000060, mae: 0.003403, mean_q: 0.004012
 13056/100000: episode: 1556, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000058, mae: 0.003659, mean_q: 0.007187
 13066/100000: episode: 1557, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000057, mae: 0.003667, mean_q: 0.004815
 13076/100000: episode: 1558, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000057, mae: 0.003435, mean_q: 0.004029
 13086/100000: episode: 1559, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000038, mae: 0.003346, mean_q: 0.005527
 13096/100000: episode: 1560, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000045, mae: 0.002980, mean_q: 0.004364
 13106/100000: episode: 1561, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000022, mae: 0.002354, mean_q: 0.003980
 13116/100000: episode: 1562, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.002971, mean_q: 0.004078
 13126/100000: episode: 1563, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000167, mae: 0.005415, mean_q: 0.006864
 13136/100000: episode: 1564, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000028, mae: 0.003169, mean_q: 0.004295
 13146/100000: episode: 1565, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000064, mae: 0.003689, mean_q: 0.004920
 13156/100000: episode: 1566, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000050, mae: 0.003511, mean_q: 0.004841
 13166/100000: episode: 1567, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003069, mean_q: 0.004233
 13176/100000: episode: 1568, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000055, mae: 0.003889, mean_q: 0.004390
 13186/100000: episode: 1569, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000156, mae: 0.004458, mean_q: 0.005018
 13196/100000: episode: 1570, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000106, mae: 0.004071, mean_q: 0.006120
 13206/100000: episode: 1571, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000099, mae: 0.004575, mean_q: 0.008238
 13216/100000: episode: 1572, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000016, mae: 0.002423, mean_q: 0.003668
 13226/100000: episode: 1573, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000055, mae: 0.002565, mean_q: 0.003965
 13236/100000: episode: 1574, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000042, mae: 0.002583, mean_q: 0.002857
 13246/100000: episode: 1575, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000194, mae: 0.003386, mean_q: 0.004016
 13256/100000: episode: 1576, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000054, mae: 0.004418, mean_q: 0.004676
 13266/100000: episode: 1577, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000036, mae: 0.003831, mean_q: 0.005552
 13276/100000: episode: 1578, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002813, mean_q: 0.004542
 13286/100000: episode: 1579, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000127, mae: 0.004143, mean_q: 0.005565
 13296/100000: episode: 1580, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000127, mae: 0.004336, mean_q: 0.006054
 13306/100000: episode: 1581, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003146, mean_q: 0.004644
 13316/100000: episode: 1582, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000029, mae: 0.003379, mean_q: 0.004188
 13326/100000: episode: 1583, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000266, mae: 0.005875, mean_q: 0.007029
 13336/100000: episode: 1584, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.002413, mean_q: 0.003022
 13346/100000: episode: 1585, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000056, mae: 0.004071, mean_q: 0.005094
 13356/100000: episode: 1586, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000018, mae: 0.003025, mean_q: 0.004316
 13366/100000: episode: 1587, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000087, mae: 0.003386, mean_q: 0.003677
 13376/100000: episode: 1588, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000175, mae: 0.003998, mean_q: 0.004601
 13386/100000: episode: 1589, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000037, mae: 0.004018, mean_q: 0.007574
 13396/100000: episode: 1590, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000026, mae: 0.004031, mean_q: 0.005415
 13406/100000: episode: 1591, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000066, mae: 0.003969, mean_q: 0.006724
 13416/100000: episode: 1592, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000033, mae: 0.003601, mean_q: 0.003898
 13426/100000: episode: 1593, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000134, mae: 0.004266, mean_q: 0.006731
 13436/100000: episode: 1594, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000136, mae: 0.004030, mean_q: 0.004884
 13446/100000: episode: 1595, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000097, mae: 0.003226, mean_q: 0.004141
[Info] 1-TH LEVEL FOUND: 0.0037419258151203394, Considering 100/100 traces
 13456/100000: episode: 1596, duration: 0.709s, episode steps: 10, steps per second: 14, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.002777, mean_q: 0.003848
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0037419258151203394
 13466/100000: episode: 1597, duration: 0.481s, episode steps: 10, steps per second: 21, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000110, mae: 0.004007, mean_q: 0.004630
 13476/100000: episode: 1598, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000098, mae: 0.004326, mean_q: 0.004460
 13486/100000: episode: 1599, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000025, mae: 0.002835, mean_q: 0.003756
 13496/100000: episode: 1600, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000061, mae: 0.003691, mean_q: 0.004624
 13506/100000: episode: 1601, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003522, mean_q: 0.005144
 13516/100000: episode: 1602, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000028, mae: 0.003435, mean_q: 0.004076
 13526/100000: episode: 1603, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000072, mae: 0.004602, mean_q: 0.005344
 13536/100000: episode: 1604, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000068, mae: 0.003262, mean_q: 0.004651
 13546/100000: episode: 1605, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000104, mae: 0.004450, mean_q: 0.004187
 13556/100000: episode: 1606, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000021, mae: 0.003951, mean_q: 0.005467
 13566/100000: episode: 1607, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.003023, mean_q: 0.004434
 13576/100000: episode: 1608, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000053, mae: 0.002822, mean_q: 0.003107
 13586/100000: episode: 1609, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000026, mae: 0.003242, mean_q: 0.004398
 13596/100000: episode: 1610, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000031, mae: 0.003574, mean_q: 0.005560
 13606/100000: episode: 1611, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000105, mae: 0.004524, mean_q: 0.004644
 13616/100000: episode: 1612, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000029, mae: 0.004135, mean_q: 0.004909
 13626/100000: episode: 1613, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003339, mean_q: 0.004712
 13636/100000: episode: 1614, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000057, mae: 0.003439, mean_q: 0.004240
 13646/100000: episode: 1615, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000060, mae: 0.003798, mean_q: 0.004295
 13656/100000: episode: 1616, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000059, mae: 0.003351, mean_q: 0.004705
 13666/100000: episode: 1617, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000025, mae: 0.003485, mean_q: 0.004513
 13676/100000: episode: 1618, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000090, mae: 0.004076, mean_q: 0.004506
 13686/100000: episode: 1619, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000048, mae: 0.003490, mean_q: 0.004843
 13696/100000: episode: 1620, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000091, mae: 0.004347, mean_q: 0.004929
 13706/100000: episode: 1621, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000024, mae: 0.003508, mean_q: 0.004719
 13716/100000: episode: 1622, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000023, mae: 0.003085, mean_q: 0.004310
 13726/100000: episode: 1623, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000052, mae: 0.003223, mean_q: 0.003979
 13736/100000: episode: 1624, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000047, mae: 0.003370, mean_q: 0.004517
 13746/100000: episode: 1625, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000015, mae: 0.002822, mean_q: 0.004327
 13756/100000: episode: 1626, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000023, mae: 0.002863, mean_q: 0.003989
 13766/100000: episode: 1627, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.003409, mean_q: 0.004445
 13776/100000: episode: 1628, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000053, mae: 0.003643, mean_q: 0.004434
 13786/100000: episode: 1629, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000040, mae: 0.003177, mean_q: 0.004474
 13796/100000: episode: 1630, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000067, mae: 0.003947, mean_q: 0.004868
 13806/100000: episode: 1631, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000024, mae: 0.003368, mean_q: 0.004770
 13816/100000: episode: 1632, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000072, mae: 0.004344, mean_q: 0.005127
 13826/100000: episode: 1633, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000047, mae: 0.003598, mean_q: 0.004776
 13836/100000: episode: 1634, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000052, mae: 0.003843, mean_q: 0.005490
 13846/100000: episode: 1635, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000017, mae: 0.002956, mean_q: 0.004126
 13856/100000: episode: 1636, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003024, mean_q: 0.003923
 13866/100000: episode: 1637, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000007, mae: 0.002549, mean_q: 0.004578
 13876/100000: episode: 1638, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003392, mean_q: 0.004777
 13886/100000: episode: 1639, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003150, mean_q: 0.004611
 13896/100000: episode: 1640, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.003366, mean_q: 0.004623
 13906/100000: episode: 1641, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000055, mae: 0.003276, mean_q: 0.004358
 13916/100000: episode: 1642, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000055, mae: 0.003310, mean_q: 0.004010
 13926/100000: episode: 1643, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000049, mae: 0.003486, mean_q: 0.004697
 13936/100000: episode: 1644, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003243, mean_q: 0.004518
 13946/100000: episode: 1645, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003054, mean_q: 0.004736
 13956/100000: episode: 1646, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000082, mae: 0.003773, mean_q: 0.004345
 13966/100000: episode: 1647, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000044, mae: 0.004349, mean_q: 0.005423
 13976/100000: episode: 1648, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002941, mean_q: 0.004772
 13986/100000: episode: 1649, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000025, mae: 0.002760, mean_q: 0.003346
 13996/100000: episode: 1650, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000015, mae: 0.002939, mean_q: 0.004219
 14006/100000: episode: 1651, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000043, mae: 0.002745, mean_q: 0.003936
 14016/100000: episode: 1652, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003595, mean_q: 0.005297
 14026/100000: episode: 1653, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.003018, mean_q: 0.004347
 14036/100000: episode: 1654, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000047, mae: 0.003097, mean_q: 0.003897
 14046/100000: episode: 1655, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002862, mean_q: 0.004808
 14056/100000: episode: 1656, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.003143, mean_q: 0.004062
 14066/100000: episode: 1657, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.002899, mean_q: 0.004389
 14076/100000: episode: 1658, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000010, mae: 0.002457, mean_q: 0.003993
 14086/100000: episode: 1659, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000016, mae: 0.002443, mean_q: 0.003537
 14096/100000: episode: 1660, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000015, mae: 0.002858, mean_q: 0.004177
 14106/100000: episode: 1661, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000052, mae: 0.003651, mean_q: 0.003986
 14116/100000: episode: 1662, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000025, mae: 0.003408, mean_q: 0.004405
 14126/100000: episode: 1663, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000013, mae: 0.003122, mean_q: 0.004766
 14136/100000: episode: 1664, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003272, mean_q: 0.004238
 14146/100000: episode: 1665, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.002994, mean_q: 0.004114
 14156/100000: episode: 1666, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.003515, mean_q: 0.004409
 14166/100000: episode: 1667, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000011, mae: 0.002876, mean_q: 0.004475
 14176/100000: episode: 1668, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002569, mean_q: 0.003801
 14186/100000: episode: 1669, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000028, mae: 0.003153, mean_q: 0.003892
 14196/100000: episode: 1670, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.003346, mean_q: 0.005065
 14206/100000: episode: 1671, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000080, mae: 0.003885, mean_q: 0.004192
 14216/100000: episode: 1672, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003701, mean_q: 0.004947
 14226/100000: episode: 1673, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003359, mean_q: 0.004728
 14236/100000: episode: 1674, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000035, mae: 0.002919, mean_q: 0.004439
 14246/100000: episode: 1675, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.002810, mean_q: 0.004718
 14256/100000: episode: 1676, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002760, mean_q: 0.003692
 14266/100000: episode: 1677, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000066, mae: 0.003717, mean_q: 0.004695
 14276/100000: episode: 1678, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000024, mae: 0.003754, mean_q: 0.005069
 14286/100000: episode: 1679, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000048, mae: 0.003599, mean_q: 0.004574
 14296/100000: episode: 1680, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003071, mean_q: 0.004626
 14306/100000: episode: 1681, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000020, mae: 0.002689, mean_q: 0.003772
 14316/100000: episode: 1682, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000018, mae: 0.002768, mean_q: 0.003678
 14326/100000: episode: 1683, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000010, mae: 0.002499, mean_q: 0.004111
 14336/100000: episode: 1684, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.002628, mean_q: 0.003669
 14346/100000: episode: 1685, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000070, mae: 0.003462, mean_q: 0.003926
 14356/100000: episode: 1686, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000032, mae: 0.003800, mean_q: 0.004609
 14366/100000: episode: 1687, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003731, mean_q: 0.004778
 14376/100000: episode: 1688, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000025, mae: 0.003248, mean_q: 0.004270
 14386/100000: episode: 1689, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000045, mae: 0.003339, mean_q: 0.004625
 14396/100000: episode: 1690, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000029, mae: 0.003364, mean_q: 0.004926
 14406/100000: episode: 1691, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000027, mae: 0.002966, mean_q: 0.003901
 14416/100000: episode: 1692, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.002980, mean_q: 0.003969
 14426/100000: episode: 1693, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003015, mean_q: 0.004060
 14436/100000: episode: 1694, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000054, mae: 0.003713, mean_q: 0.004862
 14446/100000: episode: 1695, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000025, mae: 0.002709, mean_q: 0.004365
 14456/100000: episode: 1696, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000017, mae: 0.002692, mean_q: 0.003919
[Info] 1-TH LEVEL FOUND: 0.02413072995841503, Considering 100/100 traces
 14466/100000: episode: 1697, duration: 0.706s, episode steps: 10, steps per second: 14, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000042, mae: 0.003010, mean_q: 0.004666
[Info] 2-TH LEVEL FOUND: 0.02637936733663082, Considering 100/100 traces
 14467/100000: episode: 1698, duration: 0.615s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000039, mae: 0.003565, mean_q: 0.004117
[Info] 3-TH LEVEL FOUND: 0.02811104990541935, Considering 100/100 traces
 14468/100000: episode: 1699, duration: 0.618s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000007, mae: 0.002474, mean_q: 0.004207
[Info] 4-TH LEVEL FOUND: 0.0294010192155838, Considering 100/100 traces
 14469/100000: episode: 1700, duration: 0.701s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000002, mae: 0.001808, mean_q: 0.004187
[Info] 5-TH LEVEL FOUND: 0.030443955212831497, Considering 100/100 traces
 14470/100000: episode: 1701, duration: 0.689s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000038, mae: 0.003304, mean_q: 0.004056
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.030443955212831497
 14471/100000: episode: 1702, duration: 0.446s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000094, mae: 0.004574, mean_q: 0.006203
 14481/100000: episode: 1703, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000036, mae: 0.002882, mean_q: 0.003888
 14491/100000: episode: 1704, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000009, mae: 0.002413, mean_q: 0.003745
 14501/100000: episode: 1705, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.002772, mean_q: 0.003908
 14511/100000: episode: 1706, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000047, mae: 0.003330, mean_q: 0.004206
 14521/100000: episode: 1707, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000077, mae: 0.003903, mean_q: 0.004462
 14531/100000: episode: 1708, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002974, mean_q: 0.004384
 14541/100000: episode: 1709, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000057, mae: 0.003059, mean_q: 0.003122
 14551/100000: episode: 1710, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000041, mae: 0.003345, mean_q: 0.004780
 14561/100000: episode: 1711, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000059, mae: 0.003655, mean_q: 0.004633
 14571/100000: episode: 1712, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000060, mae: 0.003582, mean_q: 0.003793
 14581/100000: episode: 1713, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003042, mean_q: 0.004337
 14591/100000: episode: 1714, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000071, mae: 0.004082, mean_q: 0.004078
 14601/100000: episode: 1715, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000088, mae: 0.004846, mean_q: 0.005972
 14611/100000: episode: 1716, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000006, mae: 0.001929, mean_q: 0.003290
 14621/100000: episode: 1717, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000102, mae: 0.003776, mean_q: 0.003090
 14631/100000: episode: 1718, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000045, mae: 0.003595, mean_q: 0.004815
 14641/100000: episode: 1719, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000125, mae: 0.004860, mean_q: 0.004559
 14651/100000: episode: 1720, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.004232, mean_q: 0.005515
 14661/100000: episode: 1721, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003392, mean_q: 0.004225
 14671/100000: episode: 1722, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003195, mean_q: 0.003976
 14681/100000: episode: 1723, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003085, mean_q: 0.004439
 14691/100000: episode: 1724, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.002607, mean_q: 0.003754
 14701/100000: episode: 1725, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000067, mae: 0.004136, mean_q: 0.004271
 14711/100000: episode: 1726, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000048, mae: 0.003875, mean_q: 0.005432
 14721/100000: episode: 1727, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000009, mae: 0.002158, mean_q: 0.003856
 14731/100000: episode: 1728, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000028, mae: 0.002377, mean_q: 0.003433
 14741/100000: episode: 1729, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000056, mae: 0.003740, mean_q: 0.004939
 14751/100000: episode: 1730, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.003276, mean_q: 0.005120
 14761/100000: episode: 1731, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000081, mae: 0.003926, mean_q: 0.004560
 14771/100000: episode: 1732, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000041, mae: 0.003117, mean_q: 0.004681
 14781/100000: episode: 1733, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000095, mae: 0.003518, mean_q: 0.004324
 14791/100000: episode: 1734, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002028, mean_q: 0.003124
 14801/100000: episode: 1735, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000069, mae: 0.003372, mean_q: 0.004689
 14811/100000: episode: 1736, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000041, mae: 0.002883, mean_q: 0.003405
 14821/100000: episode: 1737, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000079, mae: 0.004046, mean_q: 0.004286
 14831/100000: episode: 1738, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000119, mae: 0.004359, mean_q: 0.004449
 14841/100000: episode: 1739, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000089, mae: 0.004342, mean_q: 0.005447
 14851/100000: episode: 1740, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000071, mae: 0.004217, mean_q: 0.005063
 14861/100000: episode: 1741, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002805, mean_q: 0.004249
 14871/100000: episode: 1742, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000029, mae: 0.003218, mean_q: 0.003778
 14881/100000: episode: 1743, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000031, mae: 0.003303, mean_q: 0.004747
 14891/100000: episode: 1744, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000016, mae: 0.002092, mean_q: 0.002866
 14901/100000: episode: 1745, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000021, mae: 0.002743, mean_q: 0.003644
 14911/100000: episode: 1746, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000020, mae: 0.003669, mean_q: 0.004963
 14921/100000: episode: 1747, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.003210, mean_q: 0.004140
 14931/100000: episode: 1748, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000062, mae: 0.003823, mean_q: 0.003926
 14941/100000: episode: 1749, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000025, mae: 0.003751, mean_q: 0.005306
 14951/100000: episode: 1750, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000047, mae: 0.002948, mean_q: 0.003736
 14961/100000: episode: 1751, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000028, mae: 0.003186, mean_q: 0.003752
 14971/100000: episode: 1752, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000052, mae: 0.004187, mean_q: 0.005185
 14981/100000: episode: 1753, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000013, mae: 0.002889, mean_q: 0.004458
 14991/100000: episode: 1754, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000027, mae: 0.003021, mean_q: 0.003491
 15001/100000: episode: 1755, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000021, mae: 0.003137, mean_q: 0.004267
 15011/100000: episode: 1756, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000025, mae: 0.003241, mean_q: 0.004420
 15021/100000: episode: 1757, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000043, mae: 0.003327, mean_q: 0.004209
 15031/100000: episode: 1758, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000013, mae: 0.002475, mean_q: 0.003823
 15041/100000: episode: 1759, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000045, mae: 0.002908, mean_q: 0.003678
 15051/100000: episode: 1760, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000078, mae: 0.004421, mean_q: 0.005088
 15061/100000: episode: 1761, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003891, mean_q: 0.005245
 15071/100000: episode: 1762, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000020, mae: 0.002429, mean_q: 0.003325
 15081/100000: episode: 1763, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.002836, mean_q: 0.004081
 15091/100000: episode: 1764, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002633, mean_q: 0.004084
 15101/100000: episode: 1765, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.002669, mean_q: 0.003369
 15111/100000: episode: 1766, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000008, mae: 0.002724, mean_q: 0.004274
 15121/100000: episode: 1767, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000014, mae: 0.002260, mean_q: 0.003501
 15131/100000: episode: 1768, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000079, mae: 0.003730, mean_q: 0.004377
 15141/100000: episode: 1769, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000020, mae: 0.003207, mean_q: 0.005004
 15151/100000: episode: 1770, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000013, mae: 0.002552, mean_q: 0.003387
 15161/100000: episode: 1771, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000011, mae: 0.002417, mean_q: 0.003740
 15171/100000: episode: 1772, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000053, mae: 0.003609, mean_q: 0.004010
 15181/100000: episode: 1773, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000077, mae: 0.004420, mean_q: 0.005013
 15191/100000: episode: 1774, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000012, mae: 0.002909, mean_q: 0.004427
 15201/100000: episode: 1775, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.002532, mean_q: 0.002924
 15211/100000: episode: 1776, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.003219, mean_q: 0.004492
 15221/100000: episode: 1777, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000018, mae: 0.003015, mean_q: 0.004157
 15231/100000: episode: 1778, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000078, mae: 0.003986, mean_q: 0.004213
 15241/100000: episode: 1779, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.003418, mean_q: 0.004878
 15251/100000: episode: 1780, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000010, mae: 0.002377, mean_q: 0.003624
 15261/100000: episode: 1781, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000031, mae: 0.003278, mean_q: 0.004234
 15271/100000: episode: 1782, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000039, mae: 0.002943, mean_q: 0.004101
 15281/100000: episode: 1783, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002804, mean_q: 0.004066
 15291/100000: episode: 1784, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000035, mae: 0.002588, mean_q: 0.003930
 15301/100000: episode: 1785, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000020, mae: 0.002751, mean_q: 0.003781
 15311/100000: episode: 1786, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000083, mae: 0.003673, mean_q: 0.004143
 15321/100000: episode: 1787, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000018, mae: 0.003038, mean_q: 0.004140
 15331/100000: episode: 1788, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000050, mae: 0.003566, mean_q: 0.004685
 15341/100000: episode: 1789, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000089, mae: 0.005136, mean_q: 0.005647
 15351/100000: episode: 1790, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000024, mae: 0.003578, mean_q: 0.005178
 15361/100000: episode: 1791, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000035, mae: 0.003153, mean_q: 0.004196
 15371/100000: episode: 1792, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000022, mae: 0.003985, mean_q: 0.005435
 15381/100000: episode: 1793, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000048, mae: 0.003577, mean_q: 0.004671
 15391/100000: episode: 1794, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000053, mae: 0.003731, mean_q: 0.005101
 15401/100000: episode: 1795, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000095, mae: 0.004951, mean_q: 0.005276
 15411/100000: episode: 1796, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000022, mae: 0.003737, mean_q: 0.005231
 15421/100000: episode: 1797, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.002258, mean_q: 0.003223
 15431/100000: episode: 1798, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003082, mean_q: 0.004344
 15441/100000: episode: 1799, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000028, mae: 0.003039, mean_q: 0.004261
 15451/100000: episode: 1800, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000014, mae: 0.002763, mean_q: 0.004217
 15461/100000: episode: 1801, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000020, mae: 0.002974, mean_q: 0.004019
[Info] 1-TH LEVEL FOUND: 0.010994365438818932, Considering 100/100 traces
 15471/100000: episode: 1802, duration: 0.701s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000016, mae: 0.003246, mean_q: 0.004522
[Info] 2-TH LEVEL FOUND: 0.016866540536284447, Considering 100/100 traces
 15472/100000: episode: 1803, duration: 0.653s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000008, mae: 0.002868, mean_q: 0.004736
[Info] 3-TH LEVEL FOUND: 0.021495848894119263, Considering 100/100 traces
 15473/100000: episode: 1804, duration: 0.753s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000004, mae: 0.002406, mean_q: 0.004864
[Info] 4-TH LEVEL FOUND: 0.02537335641682148, Considering 100/100 traces
 15474/100000: episode: 1805, duration: 0.639s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000042, mae: 0.004091, mean_q: 0.004835
[Info] 5-TH LEVEL FOUND: 0.028284503147006035, Considering 100/100 traces
 15475/100000: episode: 1806, duration: 0.696s, episode steps: 1, steps per second: 1, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000004, mae: 0.002695, mean_q: 0.004935
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.028284503147006035
 15476/100000: episode: 1807, duration: 0.446s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000093, mae: 0.006691, mean_q: 0.005517
 15486/100000: episode: 1808, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003225, mean_q: 0.004304
 15496/100000: episode: 1809, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000010, mae: 0.002360, mean_q: 0.004049
 15506/100000: episode: 1810, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000013, mae: 0.001926, mean_q: 0.002883
 15516/100000: episode: 1811, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000018, mae: 0.002849, mean_q: 0.004259
 15526/100000: episode: 1812, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000064, mae: 0.004034, mean_q: 0.004341
 15536/100000: episode: 1813, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000036, mae: 0.004063, mean_q: 0.005063
 15546/100000: episode: 1814, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003063, mean_q: 0.003880
 15556/100000: episode: 1815, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002716, mean_q: 0.004224
 15566/100000: episode: 1816, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000025, mae: 0.003090, mean_q: 0.004473
 15576/100000: episode: 1817, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000017, mae: 0.003061, mean_q: 0.004047
 15586/100000: episode: 1818, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000028, mae: 0.003594, mean_q: 0.004252
 15596/100000: episode: 1819, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000017, mae: 0.003224, mean_q: 0.004905
 15606/100000: episode: 1820, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.002717, mean_q: 0.003514
 15616/100000: episode: 1821, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000013, mae: 0.002511, mean_q: 0.003976
 15626/100000: episode: 1822, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000014, mae: 0.002552, mean_q: 0.003820
 15636/100000: episode: 1823, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000084, mae: 0.003549, mean_q: 0.003855
 15646/100000: episode: 1824, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000022, mae: 0.003899, mean_q: 0.005270
 15656/100000: episode: 1825, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000084, mae: 0.003616, mean_q: 0.004649
 15666/100000: episode: 1826, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000038, mae: 0.003271, mean_q: 0.004164
 15676/100000: episode: 1827, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000012, mae: 0.002537, mean_q: 0.003553
 15686/100000: episode: 1828, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000009, mae: 0.002220, mean_q: 0.003667
 15696/100000: episode: 1829, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003581, mean_q: 0.003931
 15706/100000: episode: 1830, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000047, mae: 0.004619, mean_q: 0.004820
 15716/100000: episode: 1831, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002441, mean_q: 0.003506
 15726/100000: episode: 1832, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000029, mae: 0.002616, mean_q: 0.004024
 15736/100000: episode: 1833, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000017, mae: 0.002996, mean_q: 0.004033
 15746/100000: episode: 1834, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000101, mae: 0.004294, mean_q: 0.003499
 15756/100000: episode: 1835, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000085, mae: 0.003754, mean_q: 0.005223
 15766/100000: episode: 1836, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000049, mae: 0.002654, mean_q: 0.002173
 15776/100000: episode: 1837, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000066, mae: 0.004923, mean_q: 0.005422
 15786/100000: episode: 1838, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000091, mae: 0.004054, mean_q: 0.003653
 15796/100000: episode: 1839, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000025, mae: 0.003568, mean_q: 0.004128
 15806/100000: episode: 1840, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.004607, mean_q: 0.005164
 15816/100000: episode: 1841, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000015, mae: 0.002414, mean_q: 0.003328
 15826/100000: episode: 1842, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000016, mae: 0.002619, mean_q: 0.003562
 15836/100000: episode: 1843, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000090, mae: 0.005475, mean_q: 0.005607
 15846/100000: episode: 1844, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000020, mae: 0.003807, mean_q: 0.005086
 15856/100000: episode: 1845, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002217, mean_q: 0.002873
 15866/100000: episode: 1846, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003050, mean_q: 0.004043
 15876/100000: episode: 1847, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000007, mae: 0.002471, mean_q: 0.004203
 15886/100000: episode: 1848, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003008, mean_q: 0.003580
 15896/100000: episode: 1849, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000054, mae: 0.004427, mean_q: 0.005183
 15906/100000: episode: 1850, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000037, mae: 0.003738, mean_q: 0.004832
 15916/100000: episode: 1851, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003111, mean_q: 0.004293
 15926/100000: episode: 1852, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000026, mae: 0.003143, mean_q: 0.004144
 15936/100000: episode: 1853, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000022, mae: 0.002962, mean_q: 0.003823
 15946/100000: episode: 1854, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002889, mean_q: 0.004469
 15956/100000: episode: 1855, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002832, mean_q: 0.003832
 15966/100000: episode: 1856, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000026, mae: 0.003467, mean_q: 0.004341
 15976/100000: episode: 1857, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000018, mae: 0.003053, mean_q: 0.004358
 15986/100000: episode: 1858, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000042, mae: 0.003606, mean_q: 0.004045
 15996/100000: episode: 1859, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003780, mean_q: 0.004869
 16006/100000: episode: 1860, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000049, mae: 0.003543, mean_q: 0.004290
 16016/100000: episode: 1861, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000009, mae: 0.002769, mean_q: 0.004251
 16026/100000: episode: 1862, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000041, mae: 0.002698, mean_q: 0.003302
 16036/100000: episode: 1863, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003094, mean_q: 0.004271
 16046/100000: episode: 1864, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000012, mae: 0.002775, mean_q: 0.004442
 16056/100000: episode: 1865, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000016, mae: 0.002545, mean_q: 0.003605
 16066/100000: episode: 1866, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002648, mean_q: 0.003860
 16076/100000: episode: 1867, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.003551, mean_q: 0.004177
 16086/100000: episode: 1868, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003800, mean_q: 0.004688
 16096/100000: episode: 1869, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003002, mean_q: 0.004131
 16106/100000: episode: 1870, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.002994, mean_q: 0.003974
 16116/100000: episode: 1871, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000009, mae: 0.002240, mean_q: 0.003701
 16126/100000: episode: 1872, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000026, mae: 0.003322, mean_q: 0.004066
 16136/100000: episode: 1873, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000013, mae: 0.002781, mean_q: 0.004219
 16146/100000: episode: 1874, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.003037, mean_q: 0.003872
 16156/100000: episode: 1875, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002965, mean_q: 0.004178
 16166/100000: episode: 1876, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.002815, mean_q: 0.003707
 16176/100000: episode: 1877, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000063, mae: 0.004439, mean_q: 0.004731
 16186/100000: episode: 1878, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000021, mae: 0.004244, mean_q: 0.005790
 16196/100000: episode: 1879, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000045, mae: 0.002478, mean_q: 0.002986
 16206/100000: episode: 1880, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002806, mean_q: 0.004451
 16216/100000: episode: 1881, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000028, mae: 0.003430, mean_q: 0.003946
 16226/100000: episode: 1882, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000023, mae: 0.003647, mean_q: 0.004769
 16236/100000: episode: 1883, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000030, mae: 0.003182, mean_q: 0.003730
 16246/100000: episode: 1884, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000045, mae: 0.003699, mean_q: 0.004979
 16256/100000: episode: 1885, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000026, mae: 0.003314, mean_q: 0.004198
 16266/100000: episode: 1886, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.002819, mean_q: 0.003981
 16276/100000: episode: 1887, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000041, mae: 0.003291, mean_q: 0.004309
 16286/100000: episode: 1888, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.003297, mean_q: 0.004639
 16296/100000: episode: 1889, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000019, mae: 0.002267, mean_q: 0.003260
 16306/100000: episode: 1890, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000010, mae: 0.002874, mean_q: 0.004673
 16316/100000: episode: 1891, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000065, mae: 0.004179, mean_q: 0.003988
 16326/100000: episode: 1892, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000023, mae: 0.004150, mean_q: 0.005935
 16336/100000: episode: 1893, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.002619, mean_q: 0.003292
 16346/100000: episode: 1894, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003046, mean_q: 0.004198
 16356/100000: episode: 1895, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003306, mean_q: 0.004788
 16366/100000: episode: 1896, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000034, mae: 0.003399, mean_q: 0.003898
 16376/100000: episode: 1897, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000045, mae: 0.004757, mean_q: 0.006315
 16386/100000: episode: 1898, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000015, mae: 0.002669, mean_q: 0.003554
 16396/100000: episode: 1899, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000047, mae: 0.003357, mean_q: 0.004112
 16406/100000: episode: 1900, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000047, mae: 0.003883, mean_q: 0.004868
 16416/100000: episode: 1901, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.002813, mean_q: 0.003705
 16426/100000: episode: 1902, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000013, mae: 0.002589, mean_q: 0.004191
 16436/100000: episode: 1903, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000013, mae: 0.002632, mean_q: 0.003828
 16446/100000: episode: 1904, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000052, mae: 0.003607, mean_q: 0.004580
 16456/100000: episode: 1905, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000015, mae: 0.002681, mean_q: 0.004026
 16466/100000: episode: 1906, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000060, mae: 0.003758, mean_q: 0.003913
[Info] 1-TH LEVEL FOUND: 0.0035879195202142, Considering 100/100 traces
 16476/100000: episode: 1907, duration: 0.717s, episode steps: 10, steps per second: 14, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000024, mae: 0.004004, mean_q: 0.005601
[Info] 2-TH LEVEL FOUND: 0.0344795398414135, Considering 100/100 traces
 16486/100000: episode: 1908, duration: 0.644s, episode steps: 10, steps per second: 16, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000044, mae: 0.002782, mean_q: 0.003165
[Info] 3-TH LEVEL FOUND: 0.04078091308474541, Considering 100/100 traces
 16487/100000: episode: 1909, duration: 0.621s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000011, mae: 0.002994, mean_q: 0.004376
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.04078091308474541
 16488/100000: episode: 1910, duration: 0.496s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000030, mae: 0.003927, mean_q: 0.006767
 16498/100000: episode: 1911, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000053, mae: 0.004284, mean_q: 0.005298
 16508/100000: episode: 1912, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000057, mae: 0.004044, mean_q: 0.004560
 16518/100000: episode: 1913, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000078, mae: 0.004827, mean_q: 0.005499
 16528/100000: episode: 1914, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000055, mae: 0.003737, mean_q: 0.004507
 16538/100000: episode: 1915, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000073, mae: 0.004293, mean_q: 0.005282
 16548/100000: episode: 1916, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000021, mae: 0.003302, mean_q: 0.004606
 16558/100000: episode: 1917, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000018, mae: 0.002732, mean_q: 0.003857
 16568/100000: episode: 1918, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000061, mae: 0.004090, mean_q: 0.004691
 16578/100000: episode: 1919, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000051, mae: 0.004125, mean_q: 0.005101
 16588/100000: episode: 1920, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000050, mae: 0.003689, mean_q: 0.004701
 16598/100000: episode: 1921, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000014, mae: 0.002635, mean_q: 0.004330
 16608/100000: episode: 1922, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000018, mae: 0.002795, mean_q: 0.004007
 16618/100000: episode: 1923, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003275, mean_q: 0.004506
 16628/100000: episode: 1924, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000045, mae: 0.002960, mean_q: 0.004024
 16638/100000: episode: 1925, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000057, mae: 0.004403, mean_q: 0.005360
 16648/100000: episode: 1926, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000022, mae: 0.002729, mean_q: 0.003716
 16658/100000: episode: 1927, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003135, mean_q: 0.004407
 16668/100000: episode: 1928, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000123, mae: 0.004392, mean_q: 0.004678
 16678/100000: episode: 1929, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003749, mean_q: 0.005241
 16688/100000: episode: 1930, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003085, mean_q: 0.004215
 16698/100000: episode: 1931, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000006, mae: 0.002057, mean_q: 0.003734
 16708/100000: episode: 1932, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000024, mae: 0.003122, mean_q: 0.003964
 16718/100000: episode: 1933, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000019, mae: 0.003840, mean_q: 0.005610
 16728/100000: episode: 1934, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000050, mae: 0.002935, mean_q: 0.003220
 16738/100000: episode: 1935, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000041, mae: 0.003519, mean_q: 0.005015
 16748/100000: episode: 1936, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000021, mae: 0.002834, mean_q: 0.004063
 16758/100000: episode: 1937, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003769, mean_q: 0.004919
 16768/100000: episode: 1938, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000076, mae: 0.004742, mean_q: 0.005454
 16778/100000: episode: 1939, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.002723, mean_q: 0.003486
 16788/100000: episode: 1940, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000039, mae: 0.003324, mean_q: 0.004752
 16798/100000: episode: 1941, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000056, mae: 0.003877, mean_q: 0.004613
 16808/100000: episode: 1942, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.003058, mean_q: 0.004445
 16818/100000: episode: 1943, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000041, mae: 0.003200, mean_q: 0.004513
 16828/100000: episode: 1944, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003216, mean_q: 0.004324
 16838/100000: episode: 1945, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000011, mae: 0.002804, mean_q: 0.004516
 16848/100000: episode: 1946, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000064, mae: 0.004349, mean_q: 0.005570
 16858/100000: episode: 1947, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000046, mae: 0.003076, mean_q: 0.003924
 16868/100000: episode: 1948, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000086, mae: 0.004539, mean_q: 0.004715
 16878/100000: episode: 1949, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000033, mae: 0.004229, mean_q: 0.005408
 16888/100000: episode: 1950, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000048, mae: 0.003505, mean_q: 0.004161
 16898/100000: episode: 1951, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000020, mae: 0.003264, mean_q: 0.004731
 16908/100000: episode: 1952, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.003782, mean_q: 0.004872
 16918/100000: episode: 1953, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002772, mean_q: 0.004454
 16928/100000: episode: 1954, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000059, mae: 0.003191, mean_q: 0.005351
 16938/100000: episode: 1955, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000227, mae: 0.005143, mean_q: 0.004369
 16948/100000: episode: 1956, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000073, mae: 0.004134, mean_q: 0.006043
 16958/100000: episode: 1957, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000152, mae: 0.004203, mean_q: 0.003578
 16968/100000: episode: 1958, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000057, mae: 0.004400, mean_q: 0.004225
 16978/100000: episode: 1959, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000058, mae: 0.004476, mean_q: 0.005565
 16988/100000: episode: 1960, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000015, mae: 0.002512, mean_q: 0.003603
 16998/100000: episode: 1961, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002866, mean_q: 0.004126
 17008/100000: episode: 1962, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002664, mean_q: 0.003974
 17018/100000: episode: 1963, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000023, mae: 0.003249, mean_q: 0.004245
 17028/100000: episode: 1964, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000060, mae: 0.003816, mean_q: 0.005166
 17038/100000: episode: 1965, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000028, mae: 0.002928, mean_q: 0.004009
 17048/100000: episode: 1966, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000027, mae: 0.003024, mean_q: 0.003582
 17058/100000: episode: 1967, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000073, mae: 0.004025, mean_q: 0.004201
 17068/100000: episode: 1968, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000048, mae: 0.003797, mean_q: 0.004867
 17078/100000: episode: 1969, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.002877, mean_q: 0.003951
 17088/100000: episode: 1970, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003204, mean_q: 0.004272
 17098/100000: episode: 1971, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000060, mae: 0.004799, mean_q: 0.005461
 17108/100000: episode: 1972, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000084, mae: 0.003741, mean_q: 0.004963
 17118/100000: episode: 1973, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000011, mae: 0.002232, mean_q: 0.003912
 17128/100000: episode: 1974, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000030, mae: 0.003089, mean_q: 0.003422
 17138/100000: episode: 1975, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000120, mae: 0.005286, mean_q: 0.005161
 17148/100000: episode: 1976, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000015, mae: 0.003212, mean_q: 0.004862
 17158/100000: episode: 1977, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000062, mae: 0.003329, mean_q: 0.003914
 17168/100000: episode: 1978, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000028, mae: 0.004369, mean_q: 0.005878
 17178/100000: episode: 1979, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.002433, mean_q: 0.003179
 17188/100000: episode: 1980, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000047, mae: 0.003497, mean_q: 0.004622
 17198/100000: episode: 1981, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003019, mean_q: 0.004112
 17208/100000: episode: 1982, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000032, mae: 0.003682, mean_q: 0.004323
 17218/100000: episode: 1983, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.003144, mean_q: 0.004787
 17228/100000: episode: 1984, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000050, mae: 0.003433, mean_q: 0.003997
 17238/100000: episode: 1985, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000045, mae: 0.003218, mean_q: 0.004165
 17248/100000: episode: 1986, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.003142, mean_q: 0.004607
 17258/100000: episode: 1987, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000041, mae: 0.003331, mean_q: 0.004462
 17268/100000: episode: 1988, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000057, mae: 0.003813, mean_q: 0.004183
 17278/100000: episode: 1989, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003894, mean_q: 0.005651
 17288/100000: episode: 1990, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000075, mae: 0.003616, mean_q: 0.004630
 17298/100000: episode: 1991, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000101, mae: 0.004036, mean_q: 0.004724
 17308/100000: episode: 1992, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.002942, mean_q: 0.003529
 17318/100000: episode: 1993, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002923, mean_q: 0.004340
 17328/100000: episode: 1994, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000009, mae: 0.001827, mean_q: 0.003008
 17338/100000: episode: 1995, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000165, mae: 0.006302, mean_q: 0.005938
 17348/100000: episode: 1996, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003809, mean_q: 0.005076
 17358/100000: episode: 1997, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000044, mae: 0.003178, mean_q: 0.003871
 17368/100000: episode: 1998, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.002958, mean_q: 0.004173
 17378/100000: episode: 1999, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000018, mae: 0.002836, mean_q: 0.003839
 17388/100000: episode: 2000, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000049, mae: 0.004049, mean_q: 0.004869
 17398/100000: episode: 2001, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000041, mae: 0.004101, mean_q: 0.004430
 17408/100000: episode: 2002, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000037, mae: 0.003112, mean_q: 0.004719
 17418/100000: episode: 2003, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000018, mae: 0.003073, mean_q: 0.004272
 17428/100000: episode: 2004, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000048, mae: 0.003337, mean_q: 0.004164
 17438/100000: episode: 2005, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000049, mae: 0.003927, mean_q: 0.004960
 17448/100000: episode: 2006, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000083, mae: 0.004941, mean_q: 0.005581
 17458/100000: episode: 2007, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000044, mae: 0.003324, mean_q: 0.004074
 17468/100000: episode: 2008, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003144, mean_q: 0.004491
 17478/100000: episode: 2009, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003363, mean_q: 0.004540
[Info] 1-TH LEVEL FOUND: 0.00628706905990839, Considering 100/100 traces
 17488/100000: episode: 2010, duration: 0.660s, episode steps: 10, steps per second: 15, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000061, mae: 0.004416, mean_q: 0.004964
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.00628706905990839
 17489/100000: episode: 2011, duration: 0.472s, episode steps: 1, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.000 [-1.000, 11.000], loss: 0.000010, mae: 0.003891, mean_q: 0.005808
 17499/100000: episode: 2012, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000085, mae: 0.004585, mean_q: 0.005407
 17509/100000: episode: 2013, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000109, mae: 0.005607, mean_q: 0.006136
 17519/100000: episode: 2014, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000025, mae: 0.003773, mean_q: 0.005432
 17529/100000: episode: 2015, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000057, mae: 0.003614, mean_q: 0.003988
 17539/100000: episode: 2016, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000074, mae: 0.004518, mean_q: 0.005649
 17549/100000: episode: 2017, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000037, mae: 0.003515, mean_q: 0.004091
 17559/100000: episode: 2018, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000041, mae: 0.003837, mean_q: 0.005436
 17569/100000: episode: 2019, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000042, mae: 0.003704, mean_q: 0.004989
 17579/100000: episode: 2020, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000059, mae: 0.003644, mean_q: 0.003503
 17589/100000: episode: 2021, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000050, mae: 0.004469, mean_q: 0.005800
 17599/100000: episode: 2022, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000053, mae: 0.003986, mean_q: 0.004806
 17609/100000: episode: 2023, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003201, mean_q: 0.004346
 17619/100000: episode: 2024, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000076, mae: 0.003687, mean_q: 0.004425
 17629/100000: episode: 2025, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000044, mae: 0.003527, mean_q: 0.005130
 17639/100000: episode: 2026, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000052, mae: 0.003398, mean_q: 0.004248
 17649/100000: episode: 2027, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000075, mae: 0.004182, mean_q: 0.005711
 17659/100000: episode: 2028, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000043, mae: 0.003449, mean_q: 0.005078
 17669/100000: episode: 2029, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000040, mae: 0.003411, mean_q: 0.003889
 17679/100000: episode: 2030, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000104, mae: 0.005692, mean_q: 0.006435
 17689/100000: episode: 2031, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000065, mae: 0.004541, mean_q: 0.005292
 17699/100000: episode: 2032, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000027, mae: 0.003035, mean_q: 0.003988
 17709/100000: episode: 2033, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000077, mae: 0.004769, mean_q: 0.005919
 17719/100000: episode: 2034, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000024, mae: 0.003343, mean_q: 0.004451
 17729/100000: episode: 2035, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000091, mae: 0.004381, mean_q: 0.005454
 17739/100000: episode: 2036, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000036, mae: 0.002864, mean_q: 0.003631
 17749/100000: episode: 2037, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000110, mae: 0.006449, mean_q: 0.007129
 17759/100000: episode: 2038, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000014, mae: 0.002589, mean_q: 0.003670
 17769/100000: episode: 2039, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.002892, mean_q: 0.003254
 17779/100000: episode: 2040, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000056, mae: 0.004203, mean_q: 0.005198
 17789/100000: episode: 2041, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000074, mae: 0.004412, mean_q: 0.004888
 17799/100000: episode: 2042, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000038, mae: 0.004320, mean_q: 0.005665
 17809/100000: episode: 2043, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002919, mean_q: 0.004249
 17819/100000: episode: 2044, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000057, mae: 0.004479, mean_q: 0.005500
 17829/100000: episode: 2045, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000016, mae: 0.003013, mean_q: 0.004973
 17839/100000: episode: 2046, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000074, mae: 0.003445, mean_q: 0.004155
 17849/100000: episode: 2047, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000018, mae: 0.002706, mean_q: 0.004564
 17859/100000: episode: 2048, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000023, mae: 0.002819, mean_q: 0.003540
 17869/100000: episode: 2049, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000122, mae: 0.004847, mean_q: 0.005510
 17879/100000: episode: 2050, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000127, mae: 0.005502, mean_q: 0.005460
 17889/100000: episode: 2051, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000033, mae: 0.003369, mean_q: 0.004606
 17899/100000: episode: 2052, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000054, mae: 0.003323, mean_q: 0.004138
 17909/100000: episode: 2053, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000064, mae: 0.003801, mean_q: 0.004738
 17919/100000: episode: 2054, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000057, mae: 0.003150, mean_q: 0.003875
 17929/100000: episode: 2055, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000020, mae: 0.003586, mean_q: 0.005139
 17939/100000: episode: 2056, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.002542, mean_q: 0.003734
 17949/100000: episode: 2057, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000067, mae: 0.003110, mean_q: 0.003754
 17959/100000: episode: 2058, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000106, mae: 0.005522, mean_q: 0.006437
 17969/100000: episode: 2059, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000040, mae: 0.003689, mean_q: 0.004379
 17979/100000: episode: 2060, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000041, mae: 0.003939, mean_q: 0.004929
 17989/100000: episode: 2061, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000030, mae: 0.003829, mean_q: 0.005065
 17999/100000: episode: 2062, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000022, mae: 0.002489, mean_q: 0.003278
 18009/100000: episode: 2063, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.004728, mean_q: 0.006237
 18019/100000: episode: 2064, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000035, mae: 0.003091, mean_q: 0.003991
 18029/100000: episode: 2065, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000071, mae: 0.003591, mean_q: 0.004455
 18039/100000: episode: 2066, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000040, mae: 0.003828, mean_q: 0.004576
 18049/100000: episode: 2067, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000039, mae: 0.003612, mean_q: 0.005320
 18059/100000: episode: 2068, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000055, mae: 0.003693, mean_q: 0.004240
 18069/100000: episode: 2069, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000079, mae: 0.005069, mean_q: 0.005830
 18079/100000: episode: 2070, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000060, mae: 0.004016, mean_q: 0.004568
 18089/100000: episode: 2071, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000051, mae: 0.003959, mean_q: 0.005240
 18099/100000: episode: 2072, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003425, mean_q: 0.004713
 18109/100000: episode: 2073, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000072, mae: 0.003839, mean_q: 0.004439
 18119/100000: episode: 2074, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000130, mae: 0.006286, mean_q: 0.006845
 18129/100000: episode: 2075, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000026, mae: 0.003948, mean_q: 0.005440
 18139/100000: episode: 2076, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000095, mae: 0.004297, mean_q: 0.004971
 18149/100000: episode: 2077, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000105, mae: 0.004977, mean_q: 0.005288
 18159/100000: episode: 2078, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000058, mae: 0.003833, mean_q: 0.005325
 18169/100000: episode: 2079, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003058, mean_q: 0.004398
 18179/100000: episode: 2080, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000017, mae: 0.002997, mean_q: 0.004888
 18189/100000: episode: 2081, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000051, mae: 0.003946, mean_q: 0.004902
 18199/100000: episode: 2082, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000050, mae: 0.003538, mean_q: 0.004798
 18209/100000: episode: 2083, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002813, mean_q: 0.004600
 18219/100000: episode: 2084, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000082, mae: 0.004669, mean_q: 0.005121
 18229/100000: episode: 2085, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000055, mae: 0.004347, mean_q: 0.005195
 18239/100000: episode: 2086, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000071, mae: 0.004695, mean_q: 0.005504
 18249/100000: episode: 2087, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000040, mae: 0.003851, mean_q: 0.005690
 18259/100000: episode: 2088, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000050, mae: 0.003233, mean_q: 0.004038
 18269/100000: episode: 2089, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000100, mae: 0.004696, mean_q: 0.005503
 18279/100000: episode: 2090, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000080, mae: 0.004610, mean_q: 0.005690
 18289/100000: episode: 2091, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000018, mae: 0.003143, mean_q: 0.005013
 18299/100000: episode: 2092, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000086, mae: 0.004393, mean_q: 0.004759
 18309/100000: episode: 2093, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000134, mae: 0.006565, mean_q: 0.007246
 18319/100000: episode: 2094, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000074, mae: 0.004127, mean_q: 0.005131
 18329/100000: episode: 2095, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.004045, mean_q: 0.005560
 18339/100000: episode: 2096, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000029, mae: 0.003888, mean_q: 0.005334
 18349/100000: episode: 2097, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000031, mae: 0.003704, mean_q: 0.004760
 18359/100000: episode: 2098, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000041, mae: 0.003471, mean_q: 0.005299
 18369/100000: episode: 2099, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000038, mae: 0.002721, mean_q: 0.003980
 18379/100000: episode: 2100, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000015, mae: 0.002950, mean_q: 0.004641
 18389/100000: episode: 2101, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000043, mae: 0.003311, mean_q: 0.004670
 18399/100000: episode: 2102, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000020, mae: 0.003306, mean_q: 0.005285
 18409/100000: episode: 2103, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000066, mae: 0.003310, mean_q: 0.004315
 18419/100000: episode: 2104, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000025, mae: 0.003445, mean_q: 0.005054
 18429/100000: episode: 2105, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000037, mae: 0.002690, mean_q: 0.004206
 18439/100000: episode: 2106, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000115, mae: 0.005172, mean_q: 0.005338
 18449/100000: episode: 2107, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000023, mae: 0.003971, mean_q: 0.005714
 18459/100000: episode: 2108, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000012, mae: 0.002065, mean_q: 0.003266
 18469/100000: episode: 2109, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.003599, mean_q: 0.005433
 18479/100000: episode: 2110, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000008, mae: 0.002280, mean_q: 0.003973
[Info] 1-TH LEVEL FOUND: 0.006401306018233299, Considering 100/100 traces
 18489/100000: episode: 2111, duration: 0.692s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000064, mae: 0.003799, mean_q: 0.004590
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006401306018233299
 18499/100000: episode: 2112, duration: 0.566s, episode steps: 10, steps per second: 18, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000024, mae: 0.004067, mean_q: 0.006183
 18509/100000: episode: 2113, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000023, mae: 0.002720, mean_q: 0.003527
 18519/100000: episode: 2114, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000041, mae: 0.003039, mean_q: 0.004488
 18529/100000: episode: 2115, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000060, mae: 0.003612, mean_q: 0.004648
 18539/100000: episode: 2116, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000042, mae: 0.003177, mean_q: 0.004529
 18549/100000: episode: 2117, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000027, mae: 0.002755, mean_q: 0.004228
 18559/100000: episode: 2118, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000046, mae: 0.003454, mean_q: 0.004446
 18569/100000: episode: 2119, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000043, mae: 0.003977, mean_q: 0.005926
 18579/100000: episode: 2120, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000028, mae: 0.003578, mean_q: 0.004481
 18589/100000: episode: 2121, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000019, mae: 0.003149, mean_q: 0.004849
 18599/100000: episode: 2122, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000075, mae: 0.004030, mean_q: 0.004588
 18609/100000: episode: 2123, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000128, mae: 0.005464, mean_q: 0.006475
 18619/100000: episode: 2124, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000075, mae: 0.004002, mean_q: 0.005111
 18629/100000: episode: 2125, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000026, mae: 0.003687, mean_q: 0.004927
 18639/100000: episode: 2126, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000097, mae: 0.003964, mean_q: 0.004594
 18649/100000: episode: 2127, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000023, mae: 0.003465, mean_q: 0.004782
 18659/100000: episode: 2128, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003222, mean_q: 0.004455
 18669/100000: episode: 2129, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000069, mae: 0.004040, mean_q: 0.005614
 18679/100000: episode: 2130, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000084, mae: 0.004176, mean_q: 0.004892
 18689/100000: episode: 2131, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000086, mae: 0.005217, mean_q: 0.006234
 18699/100000: episode: 2132, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000052, mae: 0.003416, mean_q: 0.005380
 18709/100000: episode: 2133, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000013, mae: 0.002690, mean_q: 0.003806
 18719/100000: episode: 2134, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000062, mae: 0.004555, mean_q: 0.005406
 18729/100000: episode: 2135, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000122, mae: 0.005592, mean_q: 0.005802
 18739/100000: episode: 2136, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000035, mae: 0.004608, mean_q: 0.006946
 18749/100000: episode: 2137, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000024, mae: 0.003251, mean_q: 0.004316
 18759/100000: episode: 2138, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000077, mae: 0.004320, mean_q: 0.005097
 18769/100000: episode: 2139, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000060, mae: 0.004707, mean_q: 0.005715
 18779/100000: episode: 2140, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000080, mae: 0.004712, mean_q: 0.005732
 18789/100000: episode: 2141, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000098, mae: 0.004416, mean_q: 0.005144
 18799/100000: episode: 2142, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000109, mae: 0.004888, mean_q: 0.005736
 18809/100000: episode: 2143, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000036, mae: 0.004921, mean_q: 0.007400
 18819/100000: episode: 2144, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000026, mae: 0.002905, mean_q: 0.002531
 18829/100000: episode: 2145, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000077, mae: 0.005643, mean_q: 0.005972
 18839/100000: episode: 2146, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000053, mae: 0.004787, mean_q: 0.006270
 18849/100000: episode: 2147, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000100, mae: 0.004569, mean_q: 0.004066
 18859/100000: episode: 2148, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000048, mae: 0.004633, mean_q: 0.005798
 18869/100000: episode: 2149, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000053, mae: 0.003523, mean_q: 0.004428
 18879/100000: episode: 2150, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000043, mae: 0.003738, mean_q: 0.005520
 18889/100000: episode: 2151, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000029, mae: 0.002651, mean_q: 0.004975
 18899/100000: episode: 2152, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000038, mae: 0.002941, mean_q: 0.004684
 18909/100000: episode: 2153, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000084, mae: 0.004332, mean_q: 0.005298
 18919/100000: episode: 2154, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000039, mae: 0.002603, mean_q: 0.004074
 18929/100000: episode: 2155, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000058, mae: 0.004292, mean_q: 0.005028
 18939/100000: episode: 2156, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000040, mae: 0.003294, mean_q: 0.004597
 18949/100000: episode: 2157, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000135, mae: 0.005685, mean_q: 0.005658
 18959/100000: episode: 2158, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000068, mae: 0.004723, mean_q: 0.006337
 18969/100000: episode: 2159, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000010, mae: 0.001839, mean_q: 0.003201
 18979/100000: episode: 2160, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000045, mae: 0.003190, mean_q: 0.004337
 18989/100000: episode: 2161, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000079, mae: 0.005358, mean_q: 0.006414
 18999/100000: episode: 2162, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000081, mae: 0.004438, mean_q: 0.005329
 19009/100000: episode: 2163, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.003661, mean_q: 0.005400
 19019/100000: episode: 2164, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000093, mae: 0.004527, mean_q: 0.004987
 19029/100000: episode: 2165, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000030, mae: 0.003701, mean_q: 0.005811
 19039/100000: episode: 2166, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000105, mae: 0.004787, mean_q: 0.006042
 19049/100000: episode: 2167, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.003012, mean_q: 0.004834
 19059/100000: episode: 2168, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000079, mae: 0.004343, mean_q: 0.005366
 19069/100000: episode: 2169, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000032, mae: 0.004057, mean_q: 0.005408
 19079/100000: episode: 2170, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000040, mae: 0.004014, mean_q: 0.005188
 19089/100000: episode: 2171, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003827, mean_q: 0.005658
 19099/100000: episode: 2172, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000060, mae: 0.003688, mean_q: 0.004647
 19109/100000: episode: 2173, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000027, mae: 0.003424, mean_q: 0.005315
 19119/100000: episode: 2174, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000071, mae: 0.004297, mean_q: 0.005528
 19129/100000: episode: 2175, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000102, mae: 0.005030, mean_q: 0.005699
 19139/100000: episode: 2176, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000076, mae: 0.004419, mean_q: 0.005636
 19149/100000: episode: 2177, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000036, mae: 0.003041, mean_q: 0.004889
 19159/100000: episode: 2178, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000039, mae: 0.002994, mean_q: 0.004311
 19169/100000: episode: 2179, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000046, mae: 0.003659, mean_q: 0.005388
 19179/100000: episode: 2180, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000028, mae: 0.003249, mean_q: 0.004805
 19189/100000: episode: 2181, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003207, mean_q: 0.004890
 19199/100000: episode: 2182, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000099, mae: 0.005349, mean_q: 0.005408
 19209/100000: episode: 2183, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000157, mae: 0.007339, mean_q: 0.007306
 19219/100000: episode: 2184, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000061, mae: 0.004724, mean_q: 0.006564
 19229/100000: episode: 2185, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.002598, mean_q: 0.002890
 19239/100000: episode: 2186, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000011, mae: 0.002893, mean_q: 0.004993
 19249/100000: episode: 2187, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000050, mae: 0.003289, mean_q: 0.004372
 19259/100000: episode: 2188, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000054, mae: 0.004372, mean_q: 0.005497
 19269/100000: episode: 2189, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000065, mae: 0.005145, mean_q: 0.007241
 19279/100000: episode: 2190, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000045, mae: 0.002636, mean_q: 0.003495
 19289/100000: episode: 2191, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000100, mae: 0.004646, mean_q: 0.006189
 19299/100000: episode: 2192, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000048, mae: 0.004050, mean_q: 0.005585
 19309/100000: episode: 2193, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000046, mae: 0.004300, mean_q: 0.005598
 19319/100000: episode: 2194, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000073, mae: 0.003880, mean_q: 0.004493
 19329/100000: episode: 2195, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000055, mae: 0.003894, mean_q: 0.005935
 19339/100000: episode: 2196, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003437, mean_q: 0.006149
 19349/100000: episode: 2197, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000068, mae: 0.003682, mean_q: 0.004132
 19359/100000: episode: 2198, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000021, mae: 0.002961, mean_q: 0.004509
 19369/100000: episode: 2199, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000031, mae: 0.003675, mean_q: 0.004939
 19379/100000: episode: 2200, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003431, mean_q: 0.005131
 19389/100000: episode: 2201, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000062, mae: 0.003863, mean_q: 0.004630
 19399/100000: episode: 2202, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000023, mae: 0.003339, mean_q: 0.004639
 19409/100000: episode: 2203, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000027, mae: 0.003746, mean_q: 0.004924
 19419/100000: episode: 2204, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000017, mae: 0.003083, mean_q: 0.004796
 19429/100000: episode: 2205, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000096, mae: 0.004175, mean_q: 0.004918
 19439/100000: episode: 2206, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000053, mae: 0.003909, mean_q: 0.005042
 19449/100000: episode: 2207, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000069, mae: 0.004046, mean_q: 0.005539
 19459/100000: episode: 2208, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000040, mae: 0.002965, mean_q: 0.004459
 19469/100000: episode: 2209, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000087, mae: 0.004704, mean_q: 0.004903
 19479/100000: episode: 2210, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000020, mae: 0.003795, mean_q: 0.005642
 19489/100000: episode: 2211, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000074, mae: 0.003465, mean_q: 0.003788
[Info] 1-TH LEVEL FOUND: 0.004845635965466499, Considering 100/100 traces
 19499/100000: episode: 2212, duration: 0.671s, episode steps: 10, steps per second: 15, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000071, mae: 0.004917, mean_q: 0.006235
[Info] 2-TH LEVEL FOUND: 0.005033607594668865, Considering 100/100 traces
 19509/100000: episode: 2213, duration: 0.782s, episode steps: 10, steps per second: 13, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000048, mae: 0.003534, mean_q: 0.004352
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005033607594668865
 19519/100000: episode: 2214, duration: 0.495s, episode steps: 10, steps per second: 20, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000019, mae: 0.003425, mean_q: 0.005102
[Info] FALSIFICATION!
 19529/100000: episode: 2215, duration: 0.297s, episode steps: 10, steps per second: 34, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000019, mae: 0.003287, mean_q: 0.004823
 19539/100000: episode: 2216, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000274, mae: 0.006041, mean_q: 0.005634
 19549/100000: episode: 2217, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000336, mae: 0.008880, mean_q: 0.008890
 19559/100000: episode: 2218, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000075, mae: 0.004517, mean_q: 0.005520
 19569/100000: episode: 2219, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000110, mae: 0.004747, mean_q: 0.004493
 19579/100000: episode: 2220, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000081, mae: 0.006191, mean_q: 0.007994
 19589/100000: episode: 2221, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.002899, mean_q: 0.003981
 19599/100000: episode: 2222, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000081, mae: 0.004657, mean_q: 0.005595
 19609/100000: episode: 2223, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000030, mae: 0.003965, mean_q: 0.005583
 19619/100000: episode: 2224, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000074, mae: 0.003718, mean_q: 0.004553
 19629/100000: episode: 2225, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000033, mae: 0.004324, mean_q: 0.005931
 19639/100000: episode: 2226, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000080, mae: 0.004207, mean_q: 0.005151
 19649/100000: episode: 2227, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003799, mean_q: 0.005764
 19659/100000: episode: 2228, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000041, mae: 0.003322, mean_q: 0.004616
 19669/100000: episode: 2229, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000033, mae: 0.003909, mean_q: 0.005205
 19679/100000: episode: 2230, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000093, mae: 0.004284, mean_q: 0.005434
 19689/100000: episode: 2231, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000054, mae: 0.004605, mean_q: 0.005943
 19699/100000: episode: 2232, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000136, mae: 0.005660, mean_q: 0.005795
 19709/100000: episode: 2233, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000033, mae: 0.004766, mean_q: 0.006325
 19719/100000: episode: 2234, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.002675, mean_q: 0.004568
 19729/100000: episode: 2235, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000019, mae: 0.002903, mean_q: 0.004374
 19739/100000: episode: 2236, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000048, mae: 0.003823, mean_q: 0.005107
 19749/100000: episode: 2237, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000110, mae: 0.005910, mean_q: 0.006423
 19759/100000: episode: 2238, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000258, mae: 0.004970, mean_q: 0.005544
 19769/100000: episode: 2239, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000075, mae: 0.005600, mean_q: 0.007519
 19779/100000: episode: 2240, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003071, mean_q: 0.004513
 19789/100000: episode: 2241, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.002871, mean_q: 0.004396
 19799/100000: episode: 2242, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000074, mae: 0.004319, mean_q: 0.005388
 19809/100000: episode: 2243, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000319, mae: 0.006351, mean_q: 0.005794
 19819/100000: episode: 2244, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000035, mae: 0.005753, mean_q: 0.007767
 19829/100000: episode: 2245, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000284, mae: 0.005533, mean_q: 0.005473
 19839/100000: episode: 2246, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000023, mae: 0.003930, mean_q: 0.005968
 19849/100000: episode: 2247, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000092, mae: 0.003692, mean_q: 0.004881
 19859/100000: episode: 2248, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000168, mae: 0.006816, mean_q: 0.006575
 19869/100000: episode: 2249, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000048, mae: 0.005033, mean_q: 0.007283
 19879/100000: episode: 2250, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000111, mae: 0.004242, mean_q: 0.004256
 19889/100000: episode: 2251, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.004357, mean_q: 0.006722
 19899/100000: episode: 2252, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000046, mae: 0.003263, mean_q: 0.004278
 19909/100000: episode: 2253, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000042, mae: 0.003557, mean_q: 0.005532
 19919/100000: episode: 2254, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000067, mae: 0.004033, mean_q: 0.005634
 19929/100000: episode: 2255, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.002874, mean_q: 0.004396
 19939/100000: episode: 2256, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003091, mean_q: 0.004979
 19949/100000: episode: 2257, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000015, mae: 0.002552, mean_q: 0.004227
 19959/100000: episode: 2258, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.003040, mean_q: 0.004277
 19969/100000: episode: 2259, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000262, mae: 0.006067, mean_q: 0.006568
 19979/100000: episode: 2260, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000111, mae: 0.006576, mean_q: 0.007780
 19989/100000: episode: 2261, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000084, mae: 0.004684, mean_q: 0.005698
 19999/100000: episode: 2262, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.003323, mean_q: 0.005217
 20009/100000: episode: 2263, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000028, mae: 0.003492, mean_q: 0.005082
 20019/100000: episode: 2264, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000049, mae: 0.003502, mean_q: 0.004809
 20029/100000: episode: 2265, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000095, mae: 0.004512, mean_q: 0.005546
 20039/100000: episode: 2266, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000129, mae: 0.005786, mean_q: 0.006608
 20049/100000: episode: 2267, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000082, mae: 0.004661, mean_q: 0.005469
 20059/100000: episode: 2268, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000054, mae: 0.004641, mean_q: 0.006193
 20069/100000: episode: 2269, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000051, mae: 0.004432, mean_q: 0.006029
 20079/100000: episode: 2270, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000098, mae: 0.003914, mean_q: 0.004645
 20089/100000: episode: 2271, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003519, mean_q: 0.005698
 20099/100000: episode: 2272, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000092, mae: 0.003752, mean_q: 0.004551
 20109/100000: episode: 2273, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000054, mae: 0.004494, mean_q: 0.005997
 20119/100000: episode: 2274, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000067, mae: 0.004077, mean_q: 0.005505
 20129/100000: episode: 2275, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000320, mae: 0.006737, mean_q: 0.006110
 20139/100000: episode: 2276, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000128, mae: 0.006684, mean_q: 0.008066
 20149/100000: episode: 2277, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.003232, mean_q: 0.004473
 20159/100000: episode: 2278, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000091, mae: 0.003506, mean_q: 0.004331
 20169/100000: episode: 2279, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000342, mae: 0.007429, mean_q: 0.006868
 20179/100000: episode: 2280, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000050, mae: 0.005380, mean_q: 0.007876
 20189/100000: episode: 2281, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001833, mae: 0.007947, mean_q: 0.004436
 20199/100000: episode: 2282, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000108, mae: 0.008231, mean_q: 0.010588
 20209/100000: episode: 2283, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000053, mae: 0.003663, mean_q: 0.004687
 20219/100000: episode: 2284, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.002674, mean_q: 0.004596
 20229/100000: episode: 2285, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003838, mean_q: 0.005762
 20239/100000: episode: 2286, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.001593, mae: 0.007134, mean_q: 0.005949
 20249/100000: episode: 2287, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000060, mae: 0.005811, mean_q: 0.008082
 20259/100000: episode: 2288, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000079, mae: 0.004212, mean_q: 0.005162
 20269/100000: episode: 2289, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000117, mae: 0.006080, mean_q: 0.006794
 20279/100000: episode: 2290, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000055, mae: 0.004556, mean_q: 0.006334
 20289/100000: episode: 2291, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000256, mae: 0.004774, mean_q: 0.005217
 20299/100000: episode: 2292, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000050, mae: 0.005142, mean_q: 0.007217
 20309/100000: episode: 2293, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000069, mae: 0.003561, mean_q: 0.005260
 20319/100000: episode: 2294, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000031, mae: 0.003312, mean_q: 0.004997
 20329/100000: episode: 2295, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000237, mae: 0.005495, mean_q: 0.006555
 20339/100000: episode: 2296, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000082, mae: 0.005038, mean_q: 0.006132
 20349/100000: episode: 2297, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001561, mae: 0.006018, mean_q: 0.005480
 20359/100000: episode: 2298, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000093, mae: 0.007110, mean_q: 0.008967
 20369/100000: episode: 2299, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000082, mae: 0.004985, mean_q: 0.006647
 20379/100000: episode: 2300, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000019, mae: 0.002511, mean_q: 0.004139
 20389/100000: episode: 2301, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000077, mae: 0.004098, mean_q: 0.005429
 20399/100000: episode: 2302, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000096, mae: 0.004345, mean_q: 0.005764
 20409/100000: episode: 2303, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000140, mae: 0.006047, mean_q: 0.006570
 20419/100000: episode: 2304, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000101, mae: 0.005318, mean_q: 0.006735
 20429/100000: episode: 2305, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000075, mae: 0.003776, mean_q: 0.005106
 20439/100000: episode: 2306, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000068, mae: 0.006936, mean_q: 0.009096
 20449/100000: episode: 2307, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000131, mae: 0.006358, mean_q: 0.007536
 20459/100000: episode: 2308, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000048, mae: 0.003796, mean_q: 0.005691
 20469/100000: episode: 2309, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.004031, mean_q: 0.005772
 20479/100000: episode: 2310, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000049, mae: 0.003757, mean_q: 0.005245
 20489/100000: episode: 2311, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000103, mae: 0.005273, mean_q: 0.006391
 20499/100000: episode: 2312, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000113, mae: 0.006397, mean_q: 0.007452
 20509/100000: episode: 2313, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000043, mae: 0.003936, mean_q: 0.006159
[Info] Complete ISplit Iteration
[Info] Levels: [0.005548791]
[Info] Cond. Prob: [1.0]
[Info] Error Prob: 1.0

 20519/100000: episode: 2314, duration: 0.836s, episode steps: 10, steps per second: 12, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000050, mae: 0.003345, mean_q: 0.004749
 20529/100000: episode: 2315, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000028, mae: 0.004051, mean_q: 0.006264
 20539/100000: episode: 2316, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000025, mae: 0.003176, mean_q: 0.004975
 20549/100000: episode: 2317, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000088, mae: 0.004320, mean_q: 0.004930
 20559/100000: episode: 2318, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000308, mae: 0.007011, mean_q: 0.007204
 20569/100000: episode: 2319, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.004210, mean_q: 0.006581
 20579/100000: episode: 2320, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000105, mae: 0.004166, mean_q: 0.004763
 20589/100000: episode: 2321, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001616, mae: 0.008723, mean_q: 0.007462
 20599/100000: episode: 2322, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001585, mae: 0.009423, mean_q: 0.009428
 20609/100000: episode: 2323, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000107, mae: 0.006073, mean_q: 0.007551
 20619/100000: episode: 2324, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000136, mae: 0.005098, mean_q: 0.005599
 20629/100000: episode: 2325, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000078, mae: 0.004846, mean_q: 0.006480
 20639/100000: episode: 2326, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000033, mae: 0.004272, mean_q: 0.006231
 20649/100000: episode: 2327, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000083, mae: 0.004467, mean_q: 0.005628
 20659/100000: episode: 2328, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001671, mae: 0.008045, mean_q: 0.005719
 20669/100000: episode: 2329, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000074, mae: 0.007672, mean_q: 0.009872
 20679/100000: episode: 2330, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000049, mae: 0.004582, mean_q: 0.006603
 20689/100000: episode: 2331, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000074, mae: 0.003455, mean_q: 0.004585
 20699/100000: episode: 2332, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000038, mae: 0.003757, mean_q: 0.006049
 20709/100000: episode: 2333, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000079, mae: 0.004405, mean_q: 0.005527
 20719/100000: episode: 2334, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000052, mae: 0.003836, mean_q: 0.005682
 20729/100000: episode: 2335, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.003001, mean_q: 0.005282
 20739/100000: episode: 2336, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000056, mae: 0.003955, mean_q: 0.004820
 20749/100000: episode: 2337, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003930, mean_q: 0.005853
 20759/100000: episode: 2338, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000088, mae: 0.004758, mean_q: 0.005536
 20769/100000: episode: 2339, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000332, mae: 0.007040, mean_q: 0.007450
 20779/100000: episode: 2340, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003659, mean_q: 0.006123
 20789/100000: episode: 2341, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000021, mae: 0.002360, mean_q: 0.003720
 20799/100000: episode: 2342, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000048, mae: 0.003310, mean_q: 0.004999
 20809/100000: episode: 2343, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000074, mae: 0.004217, mean_q: 0.005483
 20819/100000: episode: 2344, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000048, mae: 0.004007, mean_q: 0.005973
 20829/100000: episode: 2345, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000043, mae: 0.003294, mean_q: 0.004927
 20839/100000: episode: 2346, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000102, mae: 0.004557, mean_q: 0.005259
 20849/100000: episode: 2347, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000088, mae: 0.005560, mean_q: 0.006425
 20859/100000: episode: 2348, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.003776, mean_q: 0.005657
 20869/100000: episode: 2349, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000078, mae: 0.003916, mean_q: 0.004557
 20879/100000: episode: 2350, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.003885, mean_q: 0.006168
 20889/100000: episode: 2351, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000076, mae: 0.004076, mean_q: 0.005320
 20899/100000: episode: 2352, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.003779, mean_q: 0.005031
 20909/100000: episode: 2353, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000255, mae: 0.005019, mean_q: 0.005572
 20919/100000: episode: 2354, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000078, mae: 0.005189, mean_q: 0.006654
 20929/100000: episode: 2355, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000061, mae: 0.004854, mean_q: 0.006053
 20939/100000: episode: 2356, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000101, mae: 0.005246, mean_q: 0.006031
 20949/100000: episode: 2357, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000081, mae: 0.004581, mean_q: 0.005661
 20959/100000: episode: 2358, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001648, mae: 0.009297, mean_q: 0.007418
 20969/100000: episode: 2359, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000276, mae: 0.006609, mean_q: 0.007757
 20979/100000: episode: 2360, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000011, mae: 0.002742, mean_q: 0.005056
 20989/100000: episode: 2361, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000143, mae: 0.005172, mean_q: 0.004597
 20999/100000: episode: 2362, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000026, mae: 0.005107, mean_q: 0.007641
 21009/100000: episode: 2363, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000072, mae: 0.003839, mean_q: 0.005501
 21019/100000: episode: 2364, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000056, mae: 0.003827, mean_q: 0.005092
 21029/100000: episode: 2365, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000041, mae: 0.003108, mean_q: 0.005188
 21039/100000: episode: 2366, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.003139, mean_q: 0.005060
 21049/100000: episode: 2367, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000039, mae: 0.003153, mean_q: 0.004883
 21059/100000: episode: 2368, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000233, mae: 0.004703, mean_q: 0.004965
 21069/100000: episode: 2369, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000022, mae: 0.003715, mean_q: 0.005956
 21079/100000: episode: 2370, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000075, mae: 0.003843, mean_q: 0.004752
 21089/100000: episode: 2371, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000068, mae: 0.004942, mean_q: 0.005784
 21099/100000: episode: 2372, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000020, mae: 0.003709, mean_q: 0.005755
 21109/100000: episode: 2373, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000084, mae: 0.004343, mean_q: 0.004744
 21119/100000: episode: 2374, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000071, mae: 0.004860, mean_q: 0.006453
 21129/100000: episode: 2375, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000033, mae: 0.003627, mean_q: 0.004914
 21139/100000: episode: 2376, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000025, mae: 0.003057, mean_q: 0.004499
 21149/100000: episode: 2377, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000039, mae: 0.003341, mean_q: 0.005036
 21159/100000: episode: 2378, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003200, mean_q: 0.004357
 21169/100000: episode: 2379, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.003364, mean_q: 0.005007
 21179/100000: episode: 2380, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000091, mae: 0.004126, mean_q: 0.005252
 21189/100000: episode: 2381, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000053, mae: 0.004474, mean_q: 0.005818
 21199/100000: episode: 2382, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000054, mae: 0.003873, mean_q: 0.004756
 21209/100000: episode: 2383, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000101, mae: 0.004446, mean_q: 0.005325
 21219/100000: episode: 2384, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000042, mae: 0.003804, mean_q: 0.005573
 21229/100000: episode: 2385, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000082, mae: 0.004174, mean_q: 0.004662
 21239/100000: episode: 2386, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000017, mae: 0.003684, mean_q: 0.005621
 21249/100000: episode: 2387, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000019, mae: 0.002749, mean_q: 0.004002
 21259/100000: episode: 2388, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000012, mae: 0.002755, mean_q: 0.004644
 21269/100000: episode: 2389, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000047, mae: 0.003758, mean_q: 0.005134
 21279/100000: episode: 2390, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000026, mae: 0.003707, mean_q: 0.005194
 21289/100000: episode: 2391, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000046, mae: 0.003379, mean_q: 0.004626
 21299/100000: episode: 2392, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000015, mae: 0.002925, mean_q: 0.004598
 21309/100000: episode: 2393, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000045, mae: 0.003274, mean_q: 0.004549
 21319/100000: episode: 2394, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000067, mae: 0.003546, mean_q: 0.004588
 21329/100000: episode: 2395, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.003943, mean_q: 0.005162
 21339/100000: episode: 2396, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000049, mae: 0.003876, mean_q: 0.005100
 21349/100000: episode: 2397, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001622, mae: 0.008462, mean_q: 0.006920
 21359/100000: episode: 2398, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000044, mae: 0.004326, mean_q: 0.006347
 21369/100000: episode: 2399, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000010, mae: 0.001810, mean_q: 0.003037
 21379/100000: episode: 2400, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000106, mae: 0.004527, mean_q: 0.004711
 21389/100000: episode: 2401, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000019, mae: 0.003864, mean_q: 0.005884
 21399/100000: episode: 2402, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000088, mae: 0.003955, mean_q: 0.004194
 21409/100000: episode: 2403, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000051, mae: 0.004302, mean_q: 0.005531
 21419/100000: episode: 2404, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000050, mae: 0.003707, mean_q: 0.004886
 21429/100000: episode: 2405, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.003282, mean_q: 0.004729
 21439/100000: episode: 2406, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000260, mae: 0.005242, mean_q: 0.005197
 21449/100000: episode: 2407, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000018, mae: 0.003970, mean_q: 0.006012
 21459/100000: episode: 2408, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000075, mae: 0.003856, mean_q: 0.004549
 21469/100000: episode: 2409, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000049, mae: 0.003656, mean_q: 0.005084
 21479/100000: episode: 2410, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000053, mae: 0.003819, mean_q: 0.005023
 21489/100000: episode: 2411, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000020, mae: 0.003369, mean_q: 0.005052
 21499/100000: episode: 2412, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000043, mae: 0.002994, mean_q: 0.003967
 21509/100000: episode: 2413, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000072, mae: 0.004157, mean_q: 0.004955
[Info] 1-TH LEVEL FOUND: 0.004884965717792511, Considering 100/100 traces
 21519/100000: episode: 2414, duration: 0.726s, episode steps: 10, steps per second: 14, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000044, mae: 0.004195, mean_q: 0.005813
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004884965717792511
 21529/100000: episode: 2415, duration: 0.506s, episode steps: 10, steps per second: 20, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000015, mae: 0.002637, mean_q: 0.004068
 21539/100000: episode: 2416, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001574, mae: 0.006359, mean_q: 0.004368
 21549/100000: episode: 2417, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000097, mae: 0.007517, mean_q: 0.008801
 21559/100000: episode: 2418, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000022, mae: 0.003599, mean_q: 0.005610
 21569/100000: episode: 2419, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000075, mae: 0.002950, mean_q: 0.003558
 21579/100000: episode: 2420, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000288, mae: 0.006548, mean_q: 0.006665
 21589/100000: episode: 2421, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000053, mae: 0.004934, mean_q: 0.006553
 21599/100000: episode: 2422, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002782, mean_q: 0.004365
 21609/100000: episode: 2423, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000055, mae: 0.003877, mean_q: 0.004877
 21619/100000: episode: 2424, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000114, mae: 0.005554, mean_q: 0.006010
 21629/100000: episode: 2425, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000071, mae: 0.005059, mean_q: 0.006780
 21639/100000: episode: 2426, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000093, mae: 0.004741, mean_q: 0.004926
 21649/100000: episode: 2427, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000070, mae: 0.004459, mean_q: 0.006100
 21659/100000: episode: 2428, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.003395, mean_q: 0.005437
 21669/100000: episode: 2429, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001622, mae: 0.007950, mean_q: 0.005927
 21679/100000: episode: 2430, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000253, mae: 0.005997, mean_q: 0.007181
 21689/100000: episode: 2431, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000080, mae: 0.004741, mean_q: 0.005978
 21699/100000: episode: 2432, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000080, mae: 0.004351, mean_q: 0.005447
 21709/100000: episode: 2433, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000051, mae: 0.004201, mean_q: 0.005668
 21719/100000: episode: 2434, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001627, mae: 0.008397, mean_q: 0.006456
 21729/100000: episode: 2435, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000101, mae: 0.007178, mean_q: 0.009341
 21739/100000: episode: 2436, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000086, mae: 0.004659, mean_q: 0.005607
 21749/100000: episode: 2437, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000230, mae: 0.004157, mean_q: 0.005080
 21759/100000: episode: 2438, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003956, mean_q: 0.005999
 21769/100000: episode: 2439, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000058, mae: 0.004187, mean_q: 0.005235
 21779/100000: episode: 2440, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000071, mae: 0.004293, mean_q: 0.005826
 21789/100000: episode: 2441, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003521, mean_q: 0.005839
 21799/100000: episode: 2442, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000317, mae: 0.006183, mean_q: 0.005879
 21809/100000: episode: 2443, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000233, mae: 0.006300, mean_q: 0.007719
 21819/100000: episode: 2444, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.003552, mean_q: 0.005143
 21829/100000: episode: 2445, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000049, mae: 0.002988, mean_q: 0.004068
 21839/100000: episode: 2446, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000027, mae: 0.004004, mean_q: 0.005921
 21849/100000: episode: 2447, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000025, mae: 0.003409, mean_q: 0.005325
 21859/100000: episode: 2448, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001624, mae: 0.007341, mean_q: 0.005216
 21869/100000: episode: 2449, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000064, mae: 0.007023, mean_q: 0.009528
 21879/100000: episode: 2450, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000082, mae: 0.004202, mean_q: 0.005098
 21889/100000: episode: 2451, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003053, mean_q: 0.004747
 21899/100000: episode: 2452, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000070, mae: 0.003836, mean_q: 0.005406
 21909/100000: episode: 2453, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000053, mae: 0.004144, mean_q: 0.005601
 21919/100000: episode: 2454, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000035, mae: 0.004028, mean_q: 0.005520
 21929/100000: episode: 2455, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000074, mae: 0.003922, mean_q: 0.005274
 21939/100000: episode: 2456, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000098, mae: 0.004723, mean_q: 0.005903
 21949/100000: episode: 2457, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000108, mae: 0.005509, mean_q: 0.006611
 21959/100000: episode: 2458, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.003561, mean_q: 0.006015
 21969/100000: episode: 2459, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000042, mae: 0.003177, mean_q: 0.004840
 21979/100000: episode: 2460, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000023, mae: 0.003108, mean_q: 0.004474
 21989/100000: episode: 2461, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.003892, mean_q: 0.005760
 21999/100000: episode: 2462, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000058, mae: 0.004425, mean_q: 0.005632
 22009/100000: episode: 2463, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003740, mean_q: 0.005670
 22019/100000: episode: 2464, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000025, mae: 0.003338, mean_q: 0.004968
 22029/100000: episode: 2465, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000049, mae: 0.003467, mean_q: 0.004347
 22039/100000: episode: 2466, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000049, mae: 0.003630, mean_q: 0.005070
 22049/100000: episode: 2467, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000247, mae: 0.004418, mean_q: 0.005237
 22059/100000: episode: 2468, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000071, mae: 0.004409, mean_q: 0.005916
 22069/100000: episode: 2469, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003669, mean_q: 0.005178
 22079/100000: episode: 2470, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000015, mae: 0.002856, mean_q: 0.004696
 22089/100000: episode: 2471, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000056, mae: 0.004269, mean_q: 0.005117
 22099/100000: episode: 2472, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000022, mae: 0.003662, mean_q: 0.005651
 22109/100000: episode: 2473, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.002644, mean_q: 0.004589
 22119/100000: episode: 2474, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000101, mae: 0.004031, mean_q: 0.004381
 22129/100000: episode: 2475, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000043, mae: 0.004188, mean_q: 0.006113
 22139/100000: episode: 2476, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000228, mae: 0.004441, mean_q: 0.005203
 22149/100000: episode: 2477, duration: 0.105s, episode steps: 10, steps per second: 95, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000045, mae: 0.003522, mean_q: 0.005058
 22159/100000: episode: 2478, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000093, mae: 0.004908, mean_q: 0.005044
 22169/100000: episode: 2479, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000079, mae: 0.004551, mean_q: 0.005903
 22179/100000: episode: 2480, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000020, mae: 0.003110, mean_q: 0.004811
 22189/100000: episode: 2481, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000043, mae: 0.003060, mean_q: 0.004342
 22199/100000: episode: 2482, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000343, mae: 0.006867, mean_q: 0.006209
 22209/100000: episode: 2483, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001591, mae: 0.009052, mean_q: 0.008303
 22219/100000: episode: 2484, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000052, mae: 0.004945, mean_q: 0.006906
 22229/100000: episode: 2485, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000062, mae: 0.003278, mean_q: 0.003857
 22239/100000: episode: 2486, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003626, mean_q: 0.005599
 22249/100000: episode: 2487, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000047, mae: 0.003556, mean_q: 0.005058
 22259/100000: episode: 2488, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000042, mae: 0.003297, mean_q: 0.004857
 22269/100000: episode: 2489, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000058, mae: 0.004101, mean_q: 0.004915
 22279/100000: episode: 2490, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000012, mae: 0.003097, mean_q: 0.005308
 22289/100000: episode: 2491, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000068, mae: 0.003518, mean_q: 0.004448
 22299/100000: episode: 2492, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000043, mae: 0.003638, mean_q: 0.005213
 22309/100000: episode: 2493, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000051, mae: 0.003932, mean_q: 0.005081
 22319/100000: episode: 2494, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000021, mae: 0.003359, mean_q: 0.005346
 22329/100000: episode: 2495, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003266, mean_q: 0.004482
 22339/100000: episode: 2496, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.003018, mean_q: 0.004785
 22349/100000: episode: 2497, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000058, mae: 0.004183, mean_q: 0.004802
 22359/100000: episode: 2498, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003633, mean_q: 0.005183
 22369/100000: episode: 2499, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000055, mae: 0.004977, mean_q: 0.006338
 22379/100000: episode: 2500, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.004484, mean_q: 0.005701
 22389/100000: episode: 2501, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000128, mae: 0.005317, mean_q: 0.005532
 22399/100000: episode: 2502, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000050, mae: 0.004226, mean_q: 0.005790
 22409/100000: episode: 2503, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000046, mae: 0.003603, mean_q: 0.005037
 22419/100000: episode: 2504, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000074, mae: 0.003863, mean_q: 0.004671
 22429/100000: episode: 2505, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000096, mae: 0.004181, mean_q: 0.004806
 22439/100000: episode: 2506, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000063, mae: 0.005061, mean_q: 0.006213
 22449/100000: episode: 2507, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000051, mae: 0.004726, mean_q: 0.006401
 22459/100000: episode: 2508, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000046, mae: 0.003255, mean_q: 0.004540
 22469/100000: episode: 2509, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000076, mae: 0.003928, mean_q: 0.004877
 22479/100000: episode: 2510, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000046, mae: 0.004421, mean_q: 0.006319
 22489/100000: episode: 2511, duration: 0.117s, episode steps: 10, steps per second: 85, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001569, mae: 0.007364, mean_q: 0.006447
 22499/100000: episode: 2512, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001590, mae: 0.009183, mean_q: 0.008523
 22509/100000: episode: 2513, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003843, mean_q: 0.006617
 22519/100000: episode: 2514, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000239, mae: 0.004154, mean_q: 0.003980
[Info] 1-TH LEVEL FOUND: 0.00599595857784152, Considering 100/100 traces
 22529/100000: episode: 2515, duration: 0.882s, episode steps: 10, steps per second: 11, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000030, mae: 0.004416, mean_q: 0.006425
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.00599595857784152
 22539/100000: episode: 2516, duration: 0.493s, episode steps: 10, steps per second: 20, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000066, mae: 0.003856, mean_q: 0.005508
 22549/100000: episode: 2517, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000072, mae: 0.003580, mean_q: 0.004837
 22559/100000: episode: 2518, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002975, mean_q: 0.004895
 22569/100000: episode: 2519, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000023, mae: 0.003128, mean_q: 0.004506
 22579/100000: episode: 2520, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000184, mae: 0.006299, mean_q: 0.006262
 22589/100000: episode: 2521, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000048, mae: 0.004720, mean_q: 0.006852
 22599/100000: episode: 2522, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000026, mae: 0.003216, mean_q: 0.004463
 22609/100000: episode: 2523, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000039, mae: 0.003349, mean_q: 0.005194
 22619/100000: episode: 2524, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000051, mae: 0.003637, mean_q: 0.005145
 22629/100000: episode: 2525, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000054, mae: 0.003967, mean_q: 0.005104
 22639/100000: episode: 2526, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000039, mae: 0.003259, mean_q: 0.004931
 22649/100000: episode: 2527, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.003161, mean_q: 0.004883
 22659/100000: episode: 2528, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000049, mae: 0.003745, mean_q: 0.004864
 22669/100000: episode: 2529, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000034, mae: 0.002795, mean_q: 0.004712
 22679/100000: episode: 2530, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000054, mae: 0.003634, mean_q: 0.004344
 22689/100000: episode: 2531, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000022, mae: 0.003949, mean_q: 0.005564
 22699/100000: episode: 2532, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000257, mae: 0.004788, mean_q: 0.004785
 22709/100000: episode: 2533, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000040, mae: 0.004091, mean_q: 0.006009
 22719/100000: episode: 2534, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000099, mae: 0.004228, mean_q: 0.005208
 22729/100000: episode: 2535, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000009, mae: 0.002349, mean_q: 0.004547
 22739/100000: episode: 2536, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000047, mae: 0.003322, mean_q: 0.004346
 22749/100000: episode: 2537, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000067, mae: 0.004731, mean_q: 0.005395
 22759/100000: episode: 2538, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001620, mae: 0.009604, mean_q: 0.008328
 22769/100000: episode: 2539, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.004282, mean_q: 0.006675
 22779/100000: episode: 2540, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000296, mae: 0.005028, mean_q: 0.002995
 22789/100000: episode: 2541, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000102, mae: 0.006471, mean_q: 0.007904
 22799/100000: episode: 2542, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.003384, mean_q: 0.005920
 22809/100000: episode: 2543, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000047, mae: 0.002679, mean_q: 0.002932
 22819/100000: episode: 2544, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.003465, mean_q: 0.005210
 22829/100000: episode: 2545, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.002981, mean_q: 0.004879
 22839/100000: episode: 2546, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003076, mean_q: 0.004198
 22849/100000: episode: 2547, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000042, mae: 0.003319, mean_q: 0.004962
 22859/100000: episode: 2548, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003521, mean_q: 0.004933
 22869/100000: episode: 2549, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001618, mae: 0.007945, mean_q: 0.005946
 22879/100000: episode: 2550, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000063, mae: 0.006750, mean_q: 0.008543
 22889/100000: episode: 2551, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000015, mae: 0.002819, mean_q: 0.004790
 22899/100000: episode: 2552, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000023, mae: 0.002778, mean_q: 0.003790
 22909/100000: episode: 2553, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000011, mae: 0.002890, mean_q: 0.005205
 22919/100000: episode: 2554, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000255, mae: 0.004968, mean_q: 0.005255
 22929/100000: episode: 2555, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000069, mae: 0.003895, mean_q: 0.005381
 22939/100000: episode: 2556, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003352, mean_q: 0.004681
 22949/100000: episode: 2557, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.003323, mean_q: 0.004911
 22959/100000: episode: 2558, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.003059, mean_q: 0.004490
 22969/100000: episode: 2559, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003048, mean_q: 0.004420
 22979/100000: episode: 2560, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000143, mae: 0.006125, mean_q: 0.005675
 22989/100000: episode: 2561, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000099, mae: 0.006181, mean_q: 0.007705
 22999/100000: episode: 2562, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000040, mae: 0.003971, mean_q: 0.005973
 23009/100000: episode: 2563, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000060, mae: 0.004046, mean_q: 0.004426
 23019/100000: episode: 2564, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.003770, mean_q: 0.005320
 23029/100000: episode: 2565, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000046, mae: 0.003628, mean_q: 0.004995
 23039/100000: episode: 2566, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001606, mae: 0.007518, mean_q: 0.005283
 23049/100000: episode: 2567, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001570, mae: 0.009325, mean_q: 0.008865
 23059/100000: episode: 2568, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000029, mae: 0.005751, mean_q: 0.008405
 23069/100000: episode: 2569, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000017, mae: 0.002578, mean_q: 0.004306
 23079/100000: episode: 2570, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002199, mean_q: 0.003689
 23089/100000: episode: 2571, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000050, mae: 0.003653, mean_q: 0.004958
 23099/100000: episode: 2572, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003480, mean_q: 0.005524
 23109/100000: episode: 2573, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000053, mae: 0.003601, mean_q: 0.004794
 23119/100000: episode: 2574, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003325, mean_q: 0.004495
 23129/100000: episode: 2575, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000027, mae: 0.003029, mean_q: 0.004483
 23139/100000: episode: 2576, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000008, mae: 0.002640, mean_q: 0.004680
 23149/100000: episode: 2577, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003113, mean_q: 0.004293
 23159/100000: episode: 2578, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000017, mae: 0.003051, mean_q: 0.005058
 23169/100000: episode: 2579, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.003218, mean_q: 0.004531
 23179/100000: episode: 2580, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003035, mean_q: 0.004464
 23189/100000: episode: 2581, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000043, mae: 0.003293, mean_q: 0.004521
 23199/100000: episode: 2582, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000012, mae: 0.002950, mean_q: 0.004870
 23209/100000: episode: 2583, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001604, mae: 0.007952, mean_q: 0.006157
 23219/100000: episode: 2584, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000031, mae: 0.006143, mean_q: 0.008552
 23229/100000: episode: 2585, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.002460, mean_q: 0.003453
 23239/100000: episode: 2586, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000075, mae: 0.003585, mean_q: 0.003895
 23249/100000: episode: 2587, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000044, mae: 0.004247, mean_q: 0.005942
 23259/100000: episode: 2588, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003284, mean_q: 0.004737
 23269/100000: episode: 2589, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003038, mean_q: 0.004158
 23279/100000: episode: 2590, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003406, mean_q: 0.004912
 23289/100000: episode: 2591, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000022, mae: 0.003702, mean_q: 0.005377
 23299/100000: episode: 2592, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000022, mae: 0.003169, mean_q: 0.004677
 23309/100000: episode: 2593, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000025, mae: 0.003065, mean_q: 0.004180
 23319/100000: episode: 2594, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000033, mae: 0.003885, mean_q: 0.004863
 23329/100000: episode: 2595, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000067, mae: 0.004502, mean_q: 0.005836
 23339/100000: episode: 2596, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000027, mae: 0.003518, mean_q: 0.004372
 23349/100000: episode: 2597, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000049, mae: 0.003857, mean_q: 0.004778
 23359/100000: episode: 2598, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000036, mae: 0.003634, mean_q: 0.005368
 23369/100000: episode: 2599, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.002861, mean_q: 0.004120
 23379/100000: episode: 2600, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000038, mae: 0.002878, mean_q: 0.004345
 23389/100000: episode: 2601, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000016, mae: 0.003132, mean_q: 0.004671
 23399/100000: episode: 2602, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000012, mae: 0.002682, mean_q: 0.004214
 23409/100000: episode: 2603, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001568, mae: 0.006114, mean_q: 0.004476
 23419/100000: episode: 2604, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000023, mae: 0.005156, mean_q: 0.007586
 23429/100000: episode: 2605, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000038, mae: 0.002820, mean_q: 0.004141
 23439/100000: episode: 2606, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001591, mae: 0.006503, mean_q: 0.004432
 23449/100000: episode: 2607, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001808, mae: 0.011762, mean_q: 0.009573
 23459/100000: episode: 2608, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.005178, mean_q: 0.008400
 23469/100000: episode: 2609, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000043, mae: 0.002749, mean_q: 0.003556
 23479/100000: episode: 2610, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000022, mae: 0.002985, mean_q: 0.004200
 23489/100000: episode: 2611, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003057, mean_q: 0.004897
 23499/100000: episode: 2612, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000046, mae: 0.003314, mean_q: 0.004470
 23509/100000: episode: 2613, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003553, mean_q: 0.005169
 23519/100000: episode: 2614, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000046, mae: 0.003766, mean_q: 0.005310
 23529/100000: episode: 2615, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000019, mae: 0.002866, mean_q: 0.004380
[Info] 1-TH LEVEL FOUND: 0.00466179708018899, Considering 100/100 traces
 23539/100000: episode: 2616, duration: 1.288s, episode steps: 10, steps per second: 8, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000020, mae: 0.002797, mean_q: 0.004382
[Info] 2-TH LEVEL FOUND: 0.005124200135469437, Considering 100/100 traces
 23549/100000: episode: 2617, duration: 1.144s, episode steps: 10, steps per second: 9, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000019, mae: 0.002997, mean_q: 0.004604
[Info] 3-TH LEVEL FOUND: 0.006107775028795004, Considering 100/100 traces
 23559/100000: episode: 2618, duration: 0.908s, episode steps: 10, steps per second: 11, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000021, mae: 0.004281, mean_q: 0.006305
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006107775028795004
 23569/100000: episode: 2619, duration: 0.551s, episode steps: 10, steps per second: 18, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000043, mae: 0.003386, mean_q: 0.004764
 23579/100000: episode: 2620, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000050, mae: 0.005323, mean_q: 0.007057
 23589/100000: episode: 2621, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.003886, mean_q: 0.006170
 23599/100000: episode: 2622, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000054, mae: 0.003211, mean_q: 0.003402
 23609/100000: episode: 2623, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000055, mae: 0.004348, mean_q: 0.005305
 23619/100000: episode: 2624, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.004144, mean_q: 0.005836
 23629/100000: episode: 2625, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000025, mae: 0.003300, mean_q: 0.004912
 23639/100000: episode: 2626, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000053, mae: 0.003687, mean_q: 0.004288
 23649/100000: episode: 2627, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000010, mae: 0.002922, mean_q: 0.005238
 23659/100000: episode: 2628, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000028, mae: 0.003212, mean_q: 0.004365
 23669/100000: episode: 2629, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.003086, mean_q: 0.004529
 23679/100000: episode: 2630, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003041, mean_q: 0.004382
 23689/100000: episode: 2631, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000036, mae: 0.003934, mean_q: 0.004964
 23699/100000: episode: 2632, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000019, mae: 0.003343, mean_q: 0.005048
 23709/100000: episode: 2633, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002527, mean_q: 0.003945
 23719/100000: episode: 2634, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000233, mae: 0.004703, mean_q: 0.004806
 23729/100000: episode: 2635, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000041, mae: 0.004024, mean_q: 0.005672
 23739/100000: episode: 2636, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003006, mean_q: 0.004307
 23749/100000: episode: 2637, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000011, mae: 0.002655, mean_q: 0.004241
 23759/100000: episode: 2638, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000040, mae: 0.003130, mean_q: 0.004222
 23769/100000: episode: 2639, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000045, mae: 0.003527, mean_q: 0.004953
 23779/100000: episode: 2640, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000282, mae: 0.005308, mean_q: 0.005040
 23789/100000: episode: 2641, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000025, mae: 0.004457, mean_q: 0.006223
 23799/100000: episode: 2642, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000018, mae: 0.003397, mean_q: 0.005200
 23809/100000: episode: 2643, duration: 0.062s, episode steps: 10, steps per second: 163, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000045, mae: 0.003291, mean_q: 0.004109
 23819/100000: episode: 2644, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000013, mae: 0.002675, mean_q: 0.004762
 23829/100000: episode: 2645, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000040, mae: 0.003161, mean_q: 0.004447
 23839/100000: episode: 2646, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000018, mae: 0.002925, mean_q: 0.004405
 23849/100000: episode: 2647, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000014, mae: 0.002682, mean_q: 0.004418
 23859/100000: episode: 2648, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000291, mae: 0.005780, mean_q: 0.005146
 23869/100000: episode: 2649, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000226, mae: 0.005363, mean_q: 0.006555
 23879/100000: episode: 2650, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000045, mae: 0.003652, mean_q: 0.004582
 23889/100000: episode: 2651, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000058, mae: 0.003915, mean_q: 0.004376
 23899/100000: episode: 2652, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000042, mae: 0.003756, mean_q: 0.005439
 23909/100000: episode: 2653, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000088, mae: 0.004303, mean_q: 0.004516
 23919/100000: episode: 2654, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000078, mae: 0.005090, mean_q: 0.006147
 23929/100000: episode: 2655, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000229, mae: 0.004720, mean_q: 0.005331
 23939/100000: episode: 2656, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000054, mae: 0.004135, mean_q: 0.005297
 23949/100000: episode: 2657, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000051, mae: 0.004131, mean_q: 0.005516
 23959/100000: episode: 2658, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000012, mae: 0.002854, mean_q: 0.004608
 23969/100000: episode: 2659, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003085, mean_q: 0.003942
 23979/100000: episode: 2660, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000019, mae: 0.003526, mean_q: 0.005331
 23989/100000: episode: 2661, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000044, mae: 0.003448, mean_q: 0.004640
 23999/100000: episode: 2662, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000221, mae: 0.003915, mean_q: 0.004436
 24009/100000: episode: 2663, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000254, mae: 0.005347, mean_q: 0.005825
 24019/100000: episode: 2664, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000056, mae: 0.005062, mean_q: 0.006368
 24029/100000: episode: 2665, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000231, mae: 0.004574, mean_q: 0.005216
 24039/100000: episode: 2666, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000014, mae: 0.003255, mean_q: 0.005525
 24049/100000: episode: 2667, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001569, mae: 0.006430, mean_q: 0.005177
 24059/100000: episode: 2668, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.004929, mean_q: 0.007621
 24069/100000: episode: 2669, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001563, mae: 0.006402, mean_q: 0.005334
 24079/100000: episode: 2670, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000072, mae: 0.005230, mean_q: 0.006916
 24089/100000: episode: 2671, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000010, mae: 0.002579, mean_q: 0.004653
 24099/100000: episode: 2672, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000050, mae: 0.003055, mean_q: 0.003750
 24109/100000: episode: 2673, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000017, mae: 0.003176, mean_q: 0.005212
 24119/100000: episode: 2674, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.002860, mean_q: 0.004632
 24129/100000: episode: 2675, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000079, mae: 0.003942, mean_q: 0.004409
 24139/100000: episode: 2676, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003777, mean_q: 0.005823
 24149/100000: episode: 2677, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000049, mae: 0.003633, mean_q: 0.004796
 24159/100000: episode: 2678, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000022, mae: 0.002892, mean_q: 0.004220
 24169/100000: episode: 2679, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002598, mean_q: 0.004438
 24179/100000: episode: 2680, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000020, mae: 0.003202, mean_q: 0.004687
 24189/100000: episode: 2681, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000017, mae: 0.002991, mean_q: 0.004869
 24199/100000: episode: 2682, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000047, mae: 0.003385, mean_q: 0.004511
 24209/100000: episode: 2683, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000037, mae: 0.002818, mean_q: 0.004426
 24219/100000: episode: 2684, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003182, mean_q: 0.004258
 24229/100000: episode: 2685, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003651, mean_q: 0.004994
 24239/100000: episode: 2686, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000056, mae: 0.004220, mean_q: 0.004918
 24249/100000: episode: 2687, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000054, mae: 0.004280, mean_q: 0.005389
 24259/100000: episode: 2688, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000084, mae: 0.005033, mean_q: 0.005627
 24269/100000: episode: 2689, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000046, mae: 0.003783, mean_q: 0.005087
 24279/100000: episode: 2690, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000279, mae: 0.004908, mean_q: 0.004794
 24289/100000: episode: 2691, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000014, mae: 0.003719, mean_q: 0.005862
 24299/100000: episode: 2692, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000234, mae: 0.004614, mean_q: 0.004698
 24309/100000: episode: 2693, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000229, mae: 0.004801, mean_q: 0.005691
 24319/100000: episode: 2694, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000042, mae: 0.004199, mean_q: 0.005688
 24329/100000: episode: 2695, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.003135, mean_q: 0.004933
 24339/100000: episode: 2696, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000025, mae: 0.003157, mean_q: 0.004531
 24349/100000: episode: 2697, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000082, mae: 0.004329, mean_q: 0.004883
 24359/100000: episode: 2698, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003976, mean_q: 0.005637
 24369/100000: episode: 2699, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000018, mae: 0.002980, mean_q: 0.004492
 24379/100000: episode: 2700, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000102, mae: 0.004355, mean_q: 0.004740
 24389/100000: episode: 2701, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.003505, mean_q: 0.005556
 24399/100000: episode: 2702, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000230, mae: 0.004293, mean_q: 0.004466
 24409/100000: episode: 2703, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000219, mae: 0.004718, mean_q: 0.005793
 24419/100000: episode: 2704, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000074, mae: 0.004126, mean_q: 0.005202
 24429/100000: episode: 2705, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000055, mae: 0.003771, mean_q: 0.004825
 24439/100000: episode: 2706, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000245, mae: 0.004662, mean_q: 0.005375
 24449/100000: episode: 2707, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000034, mae: 0.004092, mean_q: 0.005224
 24459/100000: episode: 2708, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000023, mae: 0.003278, mean_q: 0.004777
 24469/100000: episode: 2709, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000042, mae: 0.003319, mean_q: 0.004791
 24479/100000: episode: 2710, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000282, mae: 0.005813, mean_q: 0.005762
 24489/100000: episode: 2711, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000129, mae: 0.006541, mean_q: 0.007448
 24499/100000: episode: 2712, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000050, mae: 0.003803, mean_q: 0.005208
 24509/100000: episode: 2713, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.002862, mean_q: 0.004125
 24519/100000: episode: 2714, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000020, mae: 0.003893, mean_q: 0.005935
 24529/100000: episode: 2715, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000029, mae: 0.003480, mean_q: 0.005001
 24539/100000: episode: 2716, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000050, mae: 0.003727, mean_q: 0.004846
 24549/100000: episode: 2717, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000079, mae: 0.005126, mean_q: 0.006309
 24559/100000: episode: 2718, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000024, mae: 0.003125, mean_q: 0.004843
[Info] 1-TH LEVEL FOUND: 0.004530478268861771, Considering 100/100 traces
 24569/100000: episode: 2719, duration: 0.713s, episode steps: 10, steps per second: 14, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.002543, mean_q: 0.003944
[Info] 2-TH LEVEL FOUND: 0.007692691404372454, Considering 100/100 traces
 24579/100000: episode: 2720, duration: 1.064s, episode steps: 10, steps per second: 9, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000444, mae: 0.006917, mean_q: 0.006226
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007692691404372454
 24589/100000: episode: 2721, duration: 0.896s, episode steps: 10, steps per second: 11, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000030, mae: 0.004714, mean_q: 0.006786
 24599/100000: episode: 2722, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.002941, mean_q: 0.004588
 24609/100000: episode: 2723, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000024, mae: 0.003093, mean_q: 0.004560
 24619/100000: episode: 2724, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000019, mae: 0.003091, mean_q: 0.004584
 24629/100000: episode: 2725, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003764, mean_q: 0.004933
 24639/100000: episode: 2726, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000217, mae: 0.004518, mean_q: 0.005427
 24649/100000: episode: 2727, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000044, mae: 0.003514, mean_q: 0.004754
 24659/100000: episode: 2728, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000042, mae: 0.003215, mean_q: 0.004520
 24669/100000: episode: 2729, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000039, mae: 0.003368, mean_q: 0.005087
 24679/100000: episode: 2730, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000044, mae: 0.003118, mean_q: 0.004412
 24689/100000: episode: 2731, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000052, mae: 0.003944, mean_q: 0.004779
 24699/100000: episode: 2732, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000063, mae: 0.003658, mean_q: 0.005115
 24709/100000: episode: 2733, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000261, mae: 0.005414, mean_q: 0.005515
 24719/100000: episode: 2734, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000025, mae: 0.004448, mean_q: 0.006325
 24729/100000: episode: 2735, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.003064, mean_q: 0.004107
 24739/100000: episode: 2736, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000111, mae: 0.005167, mean_q: 0.005132
 24749/100000: episode: 2737, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000027, mae: 0.004622, mean_q: 0.006628
 24759/100000: episode: 2738, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000009, mae: 0.002108, mean_q: 0.003770
 24769/100000: episode: 2739, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.002063, mean_q: 0.003490
 24779/100000: episode: 2740, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000016, mae: 0.003089, mean_q: 0.004728
 24789/100000: episode: 2741, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000019, mae: 0.003111, mean_q: 0.004560
 24799/100000: episode: 2742, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000013, mae: 0.002842, mean_q: 0.004222
 24809/100000: episode: 2743, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000043, mae: 0.003295, mean_q: 0.004368
 24819/100000: episode: 2744, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000080, mae: 0.004512, mean_q: 0.005180
 24829/100000: episode: 2745, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000052, mae: 0.003998, mean_q: 0.005284
 24839/100000: episode: 2746, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000255, mae: 0.005153, mean_q: 0.005063
 24849/100000: episode: 2747, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000020, mae: 0.003925, mean_q: 0.005859
 24859/100000: episode: 2748, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000254, mae: 0.004698, mean_q: 0.004651
 24869/100000: episode: 2749, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000028, mae: 0.004503, mean_q: 0.006145
 24879/100000: episode: 2750, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000050, mae: 0.003759, mean_q: 0.004870
 24889/100000: episode: 2751, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003365, mean_q: 0.004766
 24899/100000: episode: 2752, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000054, mae: 0.003921, mean_q: 0.004992
 24909/100000: episode: 2753, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000280, mae: 0.006164, mean_q: 0.006120
 24919/100000: episode: 2754, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000032, mae: 0.005114, mean_q: 0.006989
 24929/100000: episode: 2755, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000014, mae: 0.002304, mean_q: 0.003745
 24939/100000: episode: 2756, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002446, mean_q: 0.004169
 24949/100000: episode: 2757, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000029, mae: 0.003810, mean_q: 0.005135
 24959/100000: episode: 2758, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000068, mae: 0.003697, mean_q: 0.005165
 24969/100000: episode: 2759, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.002972, mean_q: 0.004543
 24979/100000: episode: 2760, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000084, mae: 0.004474, mean_q: 0.005077
 24989/100000: episode: 2761, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000220, mae: 0.004845, mean_q: 0.005801
 24999/100000: episode: 2762, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000025, mae: 0.003676, mean_q: 0.005400
 25009/100000: episode: 2763, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000078, mae: 0.004239, mean_q: 0.004943
 25019/100000: episode: 2764, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000015, mae: 0.003066, mean_q: 0.004985
 25029/100000: episode: 2765, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000080, mae: 0.004053, mean_q: 0.004685
 25039/100000: episode: 2766, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000020, mae: 0.003866, mean_q: 0.005793
 25049/100000: episode: 2767, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000067, mae: 0.003278, mean_q: 0.004342
 25059/100000: episode: 2768, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003896, mean_q: 0.005167
 25069/100000: episode: 2769, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000231, mae: 0.005299, mean_q: 0.006195
 25079/100000: episode: 2770, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000043, mae: 0.003319, mean_q: 0.004593
 25089/100000: episode: 2771, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000025, mae: 0.003216, mean_q: 0.004372
 25099/100000: episode: 2772, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000310, mae: 0.006146, mean_q: 0.005852
 25109/100000: episode: 2773, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000059, mae: 0.005454, mean_q: 0.006793
 25119/100000: episode: 2774, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000038, mae: 0.003117, mean_q: 0.004841
 25129/100000: episode: 2775, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000084, mae: 0.004676, mean_q: 0.005405
 25139/100000: episode: 2776, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.003715, mean_q: 0.005500
 25149/100000: episode: 2777, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003058, mean_q: 0.004560
 25159/100000: episode: 2778, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000033, mae: 0.003489, mean_q: 0.004536
 25169/100000: episode: 2779, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000055, mae: 0.004755, mean_q: 0.006185
 25179/100000: episode: 2780, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003489, mean_q: 0.004951
 25189/100000: episode: 2781, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000077, mae: 0.004191, mean_q: 0.005055
 25199/100000: episode: 2782, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000013, mae: 0.003189, mean_q: 0.005187
 25209/100000: episode: 2783, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000039, mae: 0.003625, mean_q: 0.004290
 25219/100000: episode: 2784, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000068, mae: 0.004403, mean_q: 0.005832
 25229/100000: episode: 2785, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000060, mae: 0.004304, mean_q: 0.005288
 25239/100000: episode: 2786, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000070, mae: 0.004060, mean_q: 0.005255
 25249/100000: episode: 2787, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003334, mean_q: 0.005248
 25259/100000: episode: 2788, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000044, mae: 0.003493, mean_q: 0.004820
 25269/100000: episode: 2789, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002666, mean_q: 0.004091
 25279/100000: episode: 2790, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000072, mae: 0.003995, mean_q: 0.004694
 25289/100000: episode: 2791, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000256, mae: 0.006513, mean_q: 0.007412
 25299/100000: episode: 2792, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000045, mae: 0.003778, mean_q: 0.005000
 25309/100000: episode: 2793, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002834, mean_q: 0.004708
 25319/100000: episode: 2794, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000048, mae: 0.003568, mean_q: 0.004606
 25329/100000: episode: 2795, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000250, mae: 0.005369, mean_q: 0.005911
 25339/100000: episode: 2796, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000047, mae: 0.004017, mean_q: 0.005536
 25349/100000: episode: 2797, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000110, mae: 0.004918, mean_q: 0.005016
 25359/100000: episode: 2798, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000068, mae: 0.004508, mean_q: 0.006064
 25369/100000: episode: 2799, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000080, mae: 0.004316, mean_q: 0.004716
 25379/100000: episode: 2800, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000023, mae: 0.004011, mean_q: 0.005907
 25389/100000: episode: 2801, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000066, mae: 0.003422, mean_q: 0.004717
 25399/100000: episode: 2802, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000036, mae: 0.003997, mean_q: 0.005103
 25409/100000: episode: 2803, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000049, mae: 0.003645, mean_q: 0.004985
 25419/100000: episode: 2804, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000025, mae: 0.003619, mean_q: 0.005314
 25429/100000: episode: 2805, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000022, mae: 0.003144, mean_q: 0.004794
 25439/100000: episode: 2806, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000062, mae: 0.002971, mean_q: 0.004058
 25449/100000: episode: 2807, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.004079, mean_q: 0.006439
 25459/100000: episode: 2808, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000238, mae: 0.005005, mean_q: 0.005004
 25469/100000: episode: 2809, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000048, mae: 0.004789, mean_q: 0.006648
 25479/100000: episode: 2810, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000050, mae: 0.004035, mean_q: 0.005212
 25489/100000: episode: 2811, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000054, mae: 0.004673, mean_q: 0.005737
 25499/100000: episode: 2812, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000051, mae: 0.003907, mean_q: 0.005127
 25509/100000: episode: 2813, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000101, mae: 0.004868, mean_q: 0.005407
 25519/100000: episode: 2814, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.004245, mean_q: 0.006597
 25529/100000: episode: 2815, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000029, mae: 0.003038, mean_q: 0.004110
 25539/100000: episode: 2816, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000048, mae: 0.003339, mean_q: 0.004604
 25549/100000: episode: 2817, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000078, mae: 0.004685, mean_q: 0.005613
 25559/100000: episode: 2818, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000084, mae: 0.004904, mean_q: 0.005822
 25569/100000: episode: 2819, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000109, mae: 0.005691, mean_q: 0.006374
 25579/100000: episode: 2820, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000013, mae: 0.003505, mean_q: 0.005893
[Info] 1-TH LEVEL FOUND: 0.0053771911188960075, Considering 100/100 traces
 25589/100000: episode: 2821, duration: 0.762s, episode steps: 10, steps per second: 13, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000030, mae: 0.003417, mean_q: 0.004498
[Info] 2-TH LEVEL FOUND: 0.006310720928013325, Considering 100/100 traces
 25599/100000: episode: 2822, duration: 0.707s, episode steps: 10, steps per second: 14, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000055, mae: 0.004605, mean_q: 0.005815
[Info] 3-TH LEVEL FOUND: 0.006601935718208551, Considering 100/100 traces
 25609/100000: episode: 2823, duration: 0.762s, episode steps: 10, steps per second: 13, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000256, mae: 0.005460, mean_q: 0.005817
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006601935718208551
 25619/100000: episode: 2824, duration: 0.613s, episode steps: 10, steps per second: 16, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000064, mae: 0.005315, mean_q: 0.006483
 25629/100000: episode: 2825, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003592, mean_q: 0.005192
 25639/100000: episode: 2826, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000028, mae: 0.003394, mean_q: 0.004553
 25649/100000: episode: 2827, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000017, mae: 0.003180, mean_q: 0.005404
 25659/100000: episode: 2828, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.002727, mean_q: 0.004057
 25669/100000: episode: 2829, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000049, mae: 0.003779, mean_q: 0.005101
 25679/100000: episode: 2830, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000055, mae: 0.003970, mean_q: 0.005148
 25689/100000: episode: 2831, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000031, mae: 0.003789, mean_q: 0.005247
 25699/100000: episode: 2832, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003392, mean_q: 0.004835
 25709/100000: episode: 2833, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000023, mae: 0.003171, mean_q: 0.004442
 25719/100000: episode: 2834, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000228, mae: 0.004775, mean_q: 0.005475
 25729/100000: episode: 2835, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000057, mae: 0.005216, mean_q: 0.006314
 25739/100000: episode: 2836, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000023, mae: 0.003719, mean_q: 0.005378
 25749/100000: episode: 2837, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.003600, mean_q: 0.004918
 25759/100000: episode: 2838, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000015, mae: 0.003070, mean_q: 0.005172
 25769/100000: episode: 2839, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000015, mae: 0.002705, mean_q: 0.004125
 25779/100000: episode: 2840, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000459, mae: 0.005926, mean_q: 0.004966
 25789/100000: episode: 2841, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000056, mae: 0.005935, mean_q: 0.007974
 25799/100000: episode: 2842, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000085, mae: 0.004445, mean_q: 0.004887
 25809/100000: episode: 2843, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000242, mae: 0.006113, mean_q: 0.006808
 25819/100000: episode: 2844, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000257, mae: 0.005377, mean_q: 0.005634
 25829/100000: episode: 2845, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000041, mae: 0.003629, mean_q: 0.005388
 25839/100000: episode: 2846, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003498, mean_q: 0.004913
 25849/100000: episode: 2847, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000042, mae: 0.003547, mean_q: 0.005225
 25859/100000: episode: 2848, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000028, mae: 0.003150, mean_q: 0.004382
 25869/100000: episode: 2849, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000049, mae: 0.003590, mean_q: 0.004993
 25879/100000: episode: 2850, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000254, mae: 0.005356, mean_q: 0.006097
 25889/100000: episode: 2851, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000050, mae: 0.003840, mean_q: 0.005339
 25899/100000: episode: 2852, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003992, mean_q: 0.005731
 25909/100000: episode: 2853, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000072, mae: 0.003446, mean_q: 0.004452
 25919/100000: episode: 2854, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000016, mae: 0.002942, mean_q: 0.004646
 25929/100000: episode: 2855, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000056, mae: 0.004068, mean_q: 0.005194
 25939/100000: episode: 2856, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000078, mae: 0.004917, mean_q: 0.006033
 25949/100000: episode: 2857, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000029, mae: 0.003804, mean_q: 0.005346
 25959/100000: episode: 2858, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000027, mae: 0.003460, mean_q: 0.004530
 25969/100000: episode: 2859, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000011, mae: 0.003034, mean_q: 0.004924
 25979/100000: episode: 2860, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000081, mae: 0.004425, mean_q: 0.005166
 25989/100000: episode: 2861, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.003460, mean_q: 0.005441
 25999/100000: episode: 2862, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000085, mae: 0.004336, mean_q: 0.004583
 26009/100000: episode: 2863, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000025, mae: 0.004151, mean_q: 0.005691
 26019/100000: episode: 2864, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000057, mae: 0.004131, mean_q: 0.005147
 26029/100000: episode: 2865, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000043, mae: 0.003550, mean_q: 0.005132
 26039/100000: episode: 2866, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000098, mae: 0.004641, mean_q: 0.005535
 26049/100000: episode: 2867, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003702, mean_q: 0.005597
 26059/100000: episode: 2868, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000016, mae: 0.002608, mean_q: 0.003987
 26069/100000: episode: 2869, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000057, mae: 0.003993, mean_q: 0.004690
 26079/100000: episode: 2870, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000012, mae: 0.003503, mean_q: 0.005865
 26089/100000: episode: 2871, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000308, mae: 0.005489, mean_q: 0.004714
 26099/100000: episode: 2872, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000015, mae: 0.004212, mean_q: 0.006408
 26109/100000: episode: 2873, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003073, mean_q: 0.003609
 26119/100000: episode: 2874, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000063, mae: 0.004848, mean_q: 0.005617
 26129/100000: episode: 2875, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000056, mae: 0.005431, mean_q: 0.006801
 26139/100000: episode: 2876, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000081, mae: 0.004425, mean_q: 0.005292
 26149/100000: episode: 2877, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000079, mae: 0.005093, mean_q: 0.006109
 26159/100000: episode: 2878, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000051, mae: 0.004537, mean_q: 0.006049
 26169/100000: episode: 2879, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000264, mae: 0.005067, mean_q: 0.004880
 26179/100000: episode: 2880, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000040, mae: 0.005226, mean_q: 0.006514
 26189/100000: episode: 2881, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000033, mae: 0.004188, mean_q: 0.005709
 26199/100000: episode: 2882, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000059, mae: 0.004655, mean_q: 0.006077
 26209/100000: episode: 2883, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.003090, mean_q: 0.005107
 26219/100000: episode: 2884, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.003568, mean_q: 0.004375
 26229/100000: episode: 2885, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003799, mean_q: 0.005604
 26239/100000: episode: 2886, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000010, mae: 0.002315, mean_q: 0.004304
 26249/100000: episode: 2887, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000035, mae: 0.002763, mean_q: 0.004482
 26259/100000: episode: 2888, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000023, mae: 0.003325, mean_q: 0.004920
 26269/100000: episode: 2889, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000037, mae: 0.003796, mean_q: 0.005827
 26279/100000: episode: 2890, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000053, mae: 0.003697, mean_q: 0.004694
 26289/100000: episode: 2891, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000051, mae: 0.004099, mean_q: 0.005457
 26299/100000: episode: 2892, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000036, mae: 0.004182, mean_q: 0.005477
 26309/100000: episode: 2893, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000062, mae: 0.004923, mean_q: 0.005750
 26319/100000: episode: 2894, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000057, mae: 0.004794, mean_q: 0.006164
 26329/100000: episode: 2895, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000048, mae: 0.004066, mean_q: 0.005514
 26339/100000: episode: 2896, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000046, mae: 0.003809, mean_q: 0.005526
 26349/100000: episode: 2897, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000070, mae: 0.003808, mean_q: 0.005025
 26359/100000: episode: 2898, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000030, mae: 0.003782, mean_q: 0.005077
 26369/100000: episode: 2899, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003500, mean_q: 0.004792
 26379/100000: episode: 2900, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000028, mae: 0.003956, mean_q: 0.005317
 26389/100000: episode: 2901, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000047, mae: 0.004789, mean_q: 0.005670
 26399/100000: episode: 2902, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000223, mae: 0.005453, mean_q: 0.006895
 26409/100000: episode: 2903, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000029, mae: 0.002694, mean_q: 0.003666
 26419/100000: episode: 2904, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000022, mae: 0.003383, mean_q: 0.004834
 26429/100000: episode: 2905, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002624, mean_q: 0.004628
 26439/100000: episode: 2906, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000034, mae: 0.003880, mean_q: 0.004790
 26449/100000: episode: 2907, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000073, mae: 0.004391, mean_q: 0.005712
 26459/100000: episode: 2908, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000036, mae: 0.004065, mean_q: 0.005163
 26469/100000: episode: 2909, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000046, mae: 0.004030, mean_q: 0.005255
 26479/100000: episode: 2910, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000062, mae: 0.004431, mean_q: 0.005539
 26489/100000: episode: 2911, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000039, mae: 0.004556, mean_q: 0.005794
 26499/100000: episode: 2912, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000050, mae: 0.003982, mean_q: 0.005393
 26509/100000: episode: 2913, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000050, mae: 0.003777, mean_q: 0.004975
 26519/100000: episode: 2914, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000027, mae: 0.003569, mean_q: 0.004997
 26529/100000: episode: 2915, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003529, mean_q: 0.004951
 26539/100000: episode: 2916, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000232, mae: 0.005003, mean_q: 0.005635
 26549/100000: episode: 2917, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000048, mae: 0.003856, mean_q: 0.005117
 26559/100000: episode: 2918, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000029, mae: 0.003801, mean_q: 0.005222
 26569/100000: episode: 2919, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000040, mae: 0.003007, mean_q: 0.004397
 26579/100000: episode: 2920, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000104, mae: 0.005430, mean_q: 0.006015
 26589/100000: episode: 2921, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000067, mae: 0.005256, mean_q: 0.006273
 26599/100000: episode: 2922, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000091, mae: 0.004310, mean_q: 0.005610
 26609/100000: episode: 2923, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000280, mae: 0.005942, mean_q: 0.006392
[Info] 1-TH LEVEL FOUND: 0.006002089474350214, Considering 100/100 traces
 26619/100000: episode: 2924, duration: 0.681s, episode steps: 10, steps per second: 15, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000280, mae: 0.005590, mean_q: 0.005696
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006002089474350214
 26629/100000: episode: 2925, duration: 0.516s, episode steps: 10, steps per second: 19, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000048, mae: 0.004698, mean_q: 0.006635
 26639/100000: episode: 2926, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000054, mae: 0.003674, mean_q: 0.004684
 26649/100000: episode: 2927, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000052, mae: 0.004057, mean_q: 0.005242
 26659/100000: episode: 2928, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.004618, mean_q: 0.006399
 26669/100000: episode: 2929, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000055, mae: 0.003629, mean_q: 0.004361
 26679/100000: episode: 2930, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000023, mae: 0.003933, mean_q: 0.005569
 26689/100000: episode: 2931, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000671, mae: 0.008152, mean_q: 0.006672
 26699/100000: episode: 2932, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.005016, mean_q: 0.007928
 26709/100000: episode: 2933, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000032, mae: 0.003206, mean_q: 0.003999
 26719/100000: episode: 2934, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000030, mae: 0.003931, mean_q: 0.005401
 26729/100000: episode: 2935, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.004128, mean_q: 0.005984
 26739/100000: episode: 2936, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000053, mae: 0.004194, mean_q: 0.005474
 26749/100000: episode: 2937, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000081, mae: 0.004750, mean_q: 0.005581
 26759/100000: episode: 2938, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000099, mae: 0.006480, mean_q: 0.007216
 26769/100000: episode: 2939, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000067, mae: 0.004434, mean_q: 0.006359
 26779/100000: episode: 2940, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003103, mean_q: 0.004382
 26789/100000: episode: 2941, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003727, mean_q: 0.005366
 26799/100000: episode: 2942, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003504, mean_q: 0.005137
 26809/100000: episode: 2943, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000221, mae: 0.004266, mean_q: 0.004992
 26819/100000: episode: 2944, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000088, mae: 0.005785, mean_q: 0.007116
 26829/100000: episode: 2945, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000101, mae: 0.005348, mean_q: 0.006550
 26839/100000: episode: 2946, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000052, mae: 0.003670, mean_q: 0.004806
 26849/100000: episode: 2947, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003715, mean_q: 0.005550
 26859/100000: episode: 2948, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000310, mae: 0.006058, mean_q: 0.005951
 26869/100000: episode: 2949, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000280, mae: 0.006775, mean_q: 0.007561
 26879/100000: episode: 2950, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000065, mae: 0.005324, mean_q: 0.006603
 26889/100000: episode: 2951, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000019, mae: 0.003055, mean_q: 0.005021
 26899/100000: episode: 2952, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000290, mae: 0.006004, mean_q: 0.005875
 26909/100000: episode: 2953, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000231, mae: 0.006374, mean_q: 0.007836
 26919/100000: episode: 2954, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.003417, mean_q: 0.005469
 26929/100000: episode: 2955, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000074, mae: 0.004393, mean_q: 0.005460
 26939/100000: episode: 2956, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000057, mae: 0.004597, mean_q: 0.006031
 26949/100000: episode: 2957, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000028, mae: 0.003461, mean_q: 0.005235
 26959/100000: episode: 2958, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000046, mae: 0.003888, mean_q: 0.005346
 26969/100000: episode: 2959, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000041, mae: 0.003639, mean_q: 0.005521
 26979/100000: episode: 2960, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000288, mae: 0.005944, mean_q: 0.006097
 26989/100000: episode: 2961, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000031, mae: 0.005002, mean_q: 0.007526
 26999/100000: episode: 2962, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000081, mae: 0.004265, mean_q: 0.005055
 27009/100000: episode: 2963, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000074, mae: 0.004924, mean_q: 0.006291
 27019/100000: episode: 2964, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000055, mae: 0.004679, mean_q: 0.006631
 27029/100000: episode: 2965, duration: 0.073s, episode steps: 10, steps per second: 136, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000028, mae: 0.003665, mean_q: 0.004970
 27039/100000: episode: 2966, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000108, mae: 0.005167, mean_q: 0.006058
 27049/100000: episode: 2967, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000051, mae: 0.004592, mean_q: 0.006416
 27059/100000: episode: 2968, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000019, mae: 0.002976, mean_q: 0.004830
 27069/100000: episode: 2969, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000042, mae: 0.002818, mean_q: 0.004326
 27079/100000: episode: 2970, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.003957, mean_q: 0.005651
 27089/100000: episode: 2971, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000047, mae: 0.003850, mean_q: 0.005552
 27099/100000: episode: 2972, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000054, mae: 0.003805, mean_q: 0.004890
 27109/100000: episode: 2973, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000245, mae: 0.004839, mean_q: 0.005768
 27119/100000: episode: 2974, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000024, mae: 0.004194, mean_q: 0.006269
 27129/100000: episode: 2975, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000045, mae: 0.003682, mean_q: 0.005172
 27139/100000: episode: 2976, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000046, mae: 0.004039, mean_q: 0.005890
 27149/100000: episode: 2977, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003751, mean_q: 0.005322
 27159/100000: episode: 2978, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000102, mae: 0.004759, mean_q: 0.005554
 27169/100000: episode: 2979, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000039, mae: 0.004726, mean_q: 0.006206
 27179/100000: episode: 2980, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000033, mae: 0.003685, mean_q: 0.004997
 27189/100000: episode: 2981, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000227, mae: 0.004522, mean_q: 0.005155
 27199/100000: episode: 2982, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000041, mae: 0.004014, mean_q: 0.005944
 27209/100000: episode: 2983, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000236, mae: 0.005032, mean_q: 0.005449
 27219/100000: episode: 2984, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000052, mae: 0.005184, mean_q: 0.007397
 27229/100000: episode: 2985, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000024, mae: 0.002937, mean_q: 0.004139
 27239/100000: episode: 2986, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000226, mae: 0.004600, mean_q: 0.005633
 27249/100000: episode: 2987, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000027, mae: 0.003894, mean_q: 0.005700
 27259/100000: episode: 2988, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000038, mae: 0.003256, mean_q: 0.004696
 27269/100000: episode: 2989, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000075, mae: 0.004158, mean_q: 0.005295
 27279/100000: episode: 2990, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000105, mae: 0.005434, mean_q: 0.006334
 27289/100000: episode: 2991, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000028, mae: 0.004726, mean_q: 0.006852
 27299/100000: episode: 2992, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002390, mean_q: 0.003869
 27309/100000: episode: 2993, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000061, mae: 0.004006, mean_q: 0.004623
 27319/100000: episode: 2994, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000020, mae: 0.004183, mean_q: 0.006453
 27329/100000: episode: 2995, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000064, mae: 0.004593, mean_q: 0.005656
 27339/100000: episode: 2996, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000261, mae: 0.006007, mean_q: 0.006740
 27349/100000: episode: 2997, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000048, mae: 0.004111, mean_q: 0.005901
 27359/100000: episode: 2998, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000054, mae: 0.003758, mean_q: 0.004781
 27369/100000: episode: 2999, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000254, mae: 0.005906, mean_q: 0.006879
 27379/100000: episode: 3000, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000130, mae: 0.005798, mean_q: 0.006488
 27389/100000: episode: 3001, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000048, mae: 0.004105, mean_q: 0.005749
 27399/100000: episode: 3002, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000030, mae: 0.004117, mean_q: 0.005739
 27409/100000: episode: 3003, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000256, mae: 0.005535, mean_q: 0.006202
 27419/100000: episode: 3004, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000017, mae: 0.003163, mean_q: 0.005461
 27429/100000: episode: 3005, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002495, mean_q: 0.003881
 27439/100000: episode: 3006, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000020, mae: 0.002997, mean_q: 0.004921
 27449/100000: episode: 3007, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000055, mae: 0.003911, mean_q: 0.004863
 27459/100000: episode: 3008, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000054, mae: 0.004567, mean_q: 0.006018
 27469/100000: episode: 3009, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002767, mean_q: 0.004446
 27479/100000: episode: 3010, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000052, mae: 0.003753, mean_q: 0.004675
 27489/100000: episode: 3011, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000013, mae: 0.003605, mean_q: 0.005989
 27499/100000: episode: 3012, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000281, mae: 0.004952, mean_q: 0.004714
 27509/100000: episode: 3013, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000019, mae: 0.004415, mean_q: 0.006642
 27519/100000: episode: 3014, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000071, mae: 0.003324, mean_q: 0.003914
 27529/100000: episode: 3015, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003678, mean_q: 0.005578
 27539/100000: episode: 3016, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000063, mae: 0.004618, mean_q: 0.005351
 27549/100000: episode: 3017, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000069, mae: 0.005990, mean_q: 0.006968
 27559/100000: episode: 3018, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000057, mae: 0.004266, mean_q: 0.005011
 27569/100000: episode: 3019, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000281, mae: 0.005859, mean_q: 0.006379
 27579/100000: episode: 3020, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000068, mae: 0.005057, mean_q: 0.007389
 27589/100000: episode: 3021, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000023, mae: 0.002879, mean_q: 0.004326
 27599/100000: episode: 3022, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000052, mae: 0.003306, mean_q: 0.004463
 27609/100000: episode: 3023, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003516, mean_q: 0.005427
 27619/100000: episode: 3024, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000156, mae: 0.005619, mean_q: 0.005545
[Info] 1-TH LEVEL FOUND: 0.004805628210306168, Considering 100/100 traces
 27629/100000: episode: 3025, duration: 0.814s, episode steps: 10, steps per second: 12, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000028, mae: 0.004603, mean_q: 0.006568
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004805628210306168
 27639/100000: episode: 3026, duration: 0.579s, episode steps: 10, steps per second: 17, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.002877, mean_q: 0.004440
 27649/100000: episode: 3027, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003611, mean_q: 0.004762
 27659/100000: episode: 3028, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000010, mae: 0.003491, mean_q: 0.005875
 27669/100000: episode: 3029, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000053, mae: 0.003599, mean_q: 0.004600
 27679/100000: episode: 3030, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000071, mae: 0.004213, mean_q: 0.005250
 27689/100000: episode: 3031, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000054, mae: 0.004264, mean_q: 0.005556
 27699/100000: episode: 3032, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000015, mae: 0.003064, mean_q: 0.004827
 27709/100000: episode: 3033, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000068, mae: 0.004265, mean_q: 0.004440
 27719/100000: episode: 3034, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000032, mae: 0.004773, mean_q: 0.006774
 27729/100000: episode: 3035, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000027, mae: 0.003729, mean_q: 0.005195
 27739/100000: episode: 3036, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000032, mae: 0.003817, mean_q: 0.005128
 27749/100000: episode: 3037, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000052, mae: 0.004254, mean_q: 0.005560
 27759/100000: episode: 3038, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000056, mae: 0.003901, mean_q: 0.004897
 27769/100000: episode: 3039, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003334, mean_q: 0.005061
 27779/100000: episode: 3040, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000010, mae: 0.002393, mean_q: 0.004141
 27789/100000: episode: 3041, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000033, mae: 0.003529, mean_q: 0.004626
 27799/100000: episode: 3042, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000065, mae: 0.005768, mean_q: 0.006972
 27809/100000: episode: 3043, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000021, mae: 0.003460, mean_q: 0.005518
 27819/100000: episode: 3044, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000047, mae: 0.002759, mean_q: 0.003430
 27829/100000: episode: 3045, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003578, mean_q: 0.005431
 27839/100000: episode: 3046, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000304, mae: 0.006798, mean_q: 0.005660
 27849/100000: episode: 3047, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000020, mae: 0.004204, mean_q: 0.006591
 27859/100000: episode: 3048, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000016, mae: 0.002307, mean_q: 0.003277
 27869/100000: episode: 3049, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000020, mae: 0.003281, mean_q: 0.004777
 27879/100000: episode: 3050, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.003115, mean_q: 0.004585
 27889/100000: episode: 3051, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000031, mae: 0.003980, mean_q: 0.005239
 27899/100000: episode: 3052, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000070, mae: 0.004090, mean_q: 0.005338
 27909/100000: episode: 3053, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000011, mae: 0.002710, mean_q: 0.004569
 27919/100000: episode: 3054, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000026, mae: 0.003118, mean_q: 0.004641
 27929/100000: episode: 3055, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000022, mae: 0.003200, mean_q: 0.004653
 27939/100000: episode: 3056, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000041, mae: 0.004309, mean_q: 0.005230
 27949/100000: episode: 3057, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003404, mean_q: 0.005164
 27959/100000: episode: 3058, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000294, mae: 0.005766, mean_q: 0.004469
 27969/100000: episode: 3059, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000226, mae: 0.006256, mean_q: 0.007436
 27979/100000: episode: 3060, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000469, mae: 0.007274, mean_q: 0.006646
 27989/100000: episode: 3061, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000071, mae: 0.004931, mean_q: 0.006654
 27999/100000: episode: 3062, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000023, mae: 0.003179, mean_q: 0.004397
 28009/100000: episode: 3063, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000060, mae: 0.004472, mean_q: 0.005268
 28019/100000: episode: 3064, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000090, mae: 0.006032, mean_q: 0.006780
 28029/100000: episode: 3065, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000016, mae: 0.002657, mean_q: 0.004728
 28039/100000: episode: 3066, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000268, mae: 0.004880, mean_q: 0.004214
 28049/100000: episode: 3067, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000244, mae: 0.007038, mean_q: 0.008385
 28059/100000: episode: 3068, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000020, mae: 0.003231, mean_q: 0.005272
 28069/100000: episode: 3069, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000048, mae: 0.003049, mean_q: 0.003635
 28079/100000: episode: 3070, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.004136, mean_q: 0.006215
 28089/100000: episode: 3071, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000031, mae: 0.003613, mean_q: 0.004847
 28099/100000: episode: 3072, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003669, mean_q: 0.005248
 28109/100000: episode: 3073, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000027, mae: 0.004165, mean_q: 0.005774
 28119/100000: episode: 3074, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000057, mae: 0.003964, mean_q: 0.004899
 28129/100000: episode: 3075, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000010, mae: 0.002754, mean_q: 0.004984
 28139/100000: episode: 3076, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.002904, mean_q: 0.003893
 28149/100000: episode: 3077, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000043, mae: 0.003721, mean_q: 0.005532
 28159/100000: episode: 3078, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000264, mae: 0.005611, mean_q: 0.005755
 28169/100000: episode: 3079, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000227, mae: 0.005273, mean_q: 0.006295
 28179/100000: episode: 3080, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000021, mae: 0.003512, mean_q: 0.005246
 28189/100000: episode: 3081, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000029, mae: 0.003709, mean_q: 0.005142
 28199/100000: episode: 3082, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000072, mae: 0.004011, mean_q: 0.004950
 28209/100000: episode: 3083, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000050, mae: 0.004452, mean_q: 0.006090
 28219/100000: episode: 3084, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000035, mae: 0.003654, mean_q: 0.004303
 28229/100000: episode: 3085, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000050, mae: 0.004140, mean_q: 0.005623
 28239/100000: episode: 3086, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.003143, mean_q: 0.005103
 28249/100000: episode: 3087, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000077, mae: 0.003891, mean_q: 0.004532
 28259/100000: episode: 3088, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000027, mae: 0.004707, mean_q: 0.006554
 28269/100000: episode: 3089, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000013, mae: 0.002518, mean_q: 0.003830
 28279/100000: episode: 3090, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000046, mae: 0.003295, mean_q: 0.004435
 28289/100000: episode: 3091, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000079, mae: 0.004678, mean_q: 0.005780
 28299/100000: episode: 3092, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.003578, mean_q: 0.005258
 28309/100000: episode: 3093, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000052, mae: 0.003600, mean_q: 0.004600
 28319/100000: episode: 3094, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000042, mae: 0.003555, mean_q: 0.005247
 28329/100000: episode: 3095, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002670, mean_q: 0.004405
 28339/100000: episode: 3096, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000098, mae: 0.004613, mean_q: 0.005396
 28349/100000: episode: 3097, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000035, mae: 0.005273, mean_q: 0.006992
 28359/100000: episode: 3098, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000055, mae: 0.003669, mean_q: 0.004808
 28369/100000: episode: 3099, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000019, mae: 0.002656, mean_q: 0.004404
 28379/100000: episode: 3100, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000029, mae: 0.003760, mean_q: 0.004673
 28389/100000: episode: 3101, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000029, mae: 0.003776, mean_q: 0.005202
 28399/100000: episode: 3102, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000048, mae: 0.004013, mean_q: 0.005240
 28409/100000: episode: 3103, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000057, mae: 0.004288, mean_q: 0.005323
 28419/100000: episode: 3104, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000053, mae: 0.004497, mean_q: 0.005468
 28429/100000: episode: 3105, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000022, mae: 0.004253, mean_q: 0.006217
 28439/100000: episode: 3106, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000073, mae: 0.003567, mean_q: 0.004560
 28449/100000: episode: 3107, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.003599, mean_q: 0.005308
 28459/100000: episode: 3108, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000067, mae: 0.004652, mean_q: 0.005312
 28469/100000: episode: 3109, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.004475, mean_q: 0.005818
 28479/100000: episode: 3110, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000058, mae: 0.004433, mean_q: 0.005384
 28489/100000: episode: 3111, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000084, mae: 0.004560, mean_q: 0.005248
 28499/100000: episode: 3112, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000028, mae: 0.004054, mean_q: 0.005873
 28509/100000: episode: 3113, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000067, mae: 0.003636, mean_q: 0.004847
 28519/100000: episode: 3114, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000024, mae: 0.003329, mean_q: 0.004960
 28529/100000: episode: 3115, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000061, mae: 0.003981, mean_q: 0.004519
 28539/100000: episode: 3116, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.003962, mean_q: 0.005785
 28549/100000: episode: 3117, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003808, mean_q: 0.005284
 28559/100000: episode: 3118, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000084, mae: 0.004834, mean_q: 0.005691
 28569/100000: episode: 3119, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.003460, mean_q: 0.005216
 28579/100000: episode: 3120, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000018, mae: 0.003137, mean_q: 0.004651
 28589/100000: episode: 3121, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000076, mae: 0.004230, mean_q: 0.005101
 28599/100000: episode: 3122, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000028, mae: 0.004424, mean_q: 0.006175
 28609/100000: episode: 3123, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.002863, mean_q: 0.004328
 28619/100000: episode: 3124, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000097, mae: 0.004531, mean_q: 0.005428
 28629/100000: episode: 3125, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000067, mae: 0.004684, mean_q: 0.006561
[Info] 1-TH LEVEL FOUND: 0.004458253737539053, Considering 100/100 traces
 28639/100000: episode: 3126, duration: 0.767s, episode steps: 10, steps per second: 13, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.002942, mean_q: 0.003955
[Info] 2-TH LEVEL FOUND: 0.005994499195367098, Considering 100/100 traces
 28649/100000: episode: 3127, duration: 0.741s, episode steps: 10, steps per second: 13, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000051, mae: 0.004426, mean_q: 0.005641
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005994499195367098
 28659/100000: episode: 3128, duration: 0.571s, episode steps: 10, steps per second: 18, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000077, mae: 0.004274, mean_q: 0.005324
 28669/100000: episode: 3129, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000041, mae: 0.003046, mean_q: 0.004561
 28679/100000: episode: 3130, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.004023, mean_q: 0.005373
 28689/100000: episode: 3131, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000043, mae: 0.003417, mean_q: 0.004781
 28699/100000: episode: 3132, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003491, mean_q: 0.005155
 28709/100000: episode: 3133, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000020, mae: 0.002857, mean_q: 0.004489
 28719/100000: episode: 3134, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000025, mae: 0.003305, mean_q: 0.004709
 28729/100000: episode: 3135, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000088, mae: 0.004594, mean_q: 0.004848
 28739/100000: episode: 3136, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000012, mae: 0.003563, mean_q: 0.005881
 28749/100000: episode: 3137, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000013, mae: 0.002306, mean_q: 0.003075
 28759/100000: episode: 3138, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.003165, mean_q: 0.004918
 28769/100000: episode: 3139, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000133, mae: 0.005858, mean_q: 0.006423
 28779/100000: episode: 3140, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000033, mae: 0.003709, mean_q: 0.004755
 28789/100000: episode: 3141, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000014, mae: 0.002768, mean_q: 0.004373
 28799/100000: episode: 3142, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000025, mae: 0.002956, mean_q: 0.004205
 28809/100000: episode: 3143, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000107, mae: 0.005908, mean_q: 0.006573
 28819/100000: episode: 3144, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000044, mae: 0.003743, mean_q: 0.005061
 28829/100000: episode: 3145, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.003286, mean_q: 0.003978
 28839/100000: episode: 3146, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000070, mae: 0.004675, mean_q: 0.006200
 28849/100000: episode: 3147, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000047, mae: 0.003636, mean_q: 0.004820
 28859/100000: episode: 3148, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003002, mean_q: 0.004195
 28869/100000: episode: 3149, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000019, mae: 0.003171, mean_q: 0.004736
 28879/100000: episode: 3150, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000015, mae: 0.003450, mean_q: 0.004956
 28889/100000: episode: 3151, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000007, mae: 0.002244, mean_q: 0.004087
 28899/100000: episode: 3152, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000057, mae: 0.003852, mean_q: 0.004162
 28909/100000: episode: 3153, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.004076, mean_q: 0.005949
 28919/100000: episode: 3154, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000079, mae: 0.004146, mean_q: 0.004584
 28929/100000: episode: 3155, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000007, mae: 0.002551, mean_q: 0.004650
 28939/100000: episode: 3156, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002531, mean_q: 0.003462
 28949/100000: episode: 3157, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000010, mae: 0.002776, mean_q: 0.004665
 28959/100000: episode: 3158, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000016, mae: 0.002467, mean_q: 0.003594
 28969/100000: episode: 3159, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000048, mae: 0.003995, mean_q: 0.005047
 28979/100000: episode: 3160, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000024, mae: 0.004059, mean_q: 0.005499
 28989/100000: episode: 3161, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.002940, mean_q: 0.004296
 28999/100000: episode: 3162, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000025, mae: 0.003176, mean_q: 0.004325
 29009/100000: episode: 3163, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000056, mae: 0.004081, mean_q: 0.004519
 29019/100000: episode: 3164, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000040, mae: 0.003795, mean_q: 0.005400
 29029/100000: episode: 3165, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000021, mae: 0.002871, mean_q: 0.004179
 29039/100000: episode: 3166, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000070, mae: 0.003890, mean_q: 0.004939
 29049/100000: episode: 3167, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.003983, mean_q: 0.005220
 29059/100000: episode: 3168, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000083, mae: 0.004428, mean_q: 0.005078
 29069/100000: episode: 3169, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000105, mae: 0.005669, mean_q: 0.006177
 29079/100000: episode: 3170, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000075, mae: 0.004812, mean_q: 0.006178
 29089/100000: episode: 3171, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000052, mae: 0.003977, mean_q: 0.004636
 29099/100000: episode: 3172, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000028, mae: 0.003473, mean_q: 0.004955
 29109/100000: episode: 3173, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000014, mae: 0.002875, mean_q: 0.004650
 29119/100000: episode: 3174, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000027, mae: 0.003438, mean_q: 0.004367
 29129/100000: episode: 3175, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000043, mae: 0.003899, mean_q: 0.005474
 29139/100000: episode: 3176, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.002446, mean_q: 0.003505
 29149/100000: episode: 3177, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000038, mae: 0.003130, mean_q: 0.004476
 29159/100000: episode: 3178, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000015, mae: 0.002855, mean_q: 0.004479
 29169/100000: episode: 3179, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000014, mae: 0.002548, mean_q: 0.004076
 29179/100000: episode: 3180, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000038, mae: 0.002913, mean_q: 0.004054
 29189/100000: episode: 3181, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000011, mae: 0.002881, mean_q: 0.004631
 29199/100000: episode: 3182, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000056, mae: 0.003970, mean_q: 0.004611
 29209/100000: episode: 3183, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000068, mae: 0.004142, mean_q: 0.005503
 29219/100000: episode: 3184, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000038, mae: 0.002922, mean_q: 0.004266
 29229/100000: episode: 3185, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000012, mae: 0.002473, mean_q: 0.003848
 29239/100000: episode: 3186, duration: 0.137s, episode steps: 10, steps per second: 73, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000020, mae: 0.002902, mean_q: 0.004317
 29249/100000: episode: 3187, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000070, mae: 0.003730, mean_q: 0.004656
 29259/100000: episode: 3188, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000073, mae: 0.003615, mean_q: 0.004352
 29269/100000: episode: 3189, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000047, mae: 0.003830, mean_q: 0.004851
 29279/100000: episode: 3190, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000012, mae: 0.002252, mean_q: 0.003828
 29289/100000: episode: 3191, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000070, mae: 0.003594, mean_q: 0.004430
 29299/100000: episode: 3192, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000026, mae: 0.003815, mean_q: 0.005046
 29309/100000: episode: 3193, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.002620, mean_q: 0.003687
 29319/100000: episode: 3194, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002597, mean_q: 0.004086
 29329/100000: episode: 3195, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000107, mae: 0.005096, mean_q: 0.005012
 29339/100000: episode: 3196, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000038, mae: 0.004891, mean_q: 0.005961
 29349/100000: episode: 3197, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000077, mae: 0.003869, mean_q: 0.004318
 29359/100000: episode: 3198, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000074, mae: 0.004868, mean_q: 0.005823
 29369/100000: episode: 3199, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000058, mae: 0.004495, mean_q: 0.005138
 29379/100000: episode: 3200, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000028, mae: 0.003339, mean_q: 0.004403
 29389/100000: episode: 3201, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000053, mae: 0.004752, mean_q: 0.005806
 29399/100000: episode: 3202, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003124, mean_q: 0.004319
 29409/100000: episode: 3203, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000042, mae: 0.003255, mean_q: 0.004345
 29419/100000: episode: 3204, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000033, mae: 0.004008, mean_q: 0.005109
 29429/100000: episode: 3205, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000079, mae: 0.004679, mean_q: 0.005216
 29439/100000: episode: 3206, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000079, mae: 0.004401, mean_q: 0.005268
 29449/100000: episode: 3207, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000031, mae: 0.004054, mean_q: 0.005350
 29459/100000: episode: 3208, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000018, mae: 0.003105, mean_q: 0.004862
 29469/100000: episode: 3209, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000028, mae: 0.002801, mean_q: 0.003650
 29479/100000: episode: 3210, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000030, mae: 0.004223, mean_q: 0.005470
 29489/100000: episode: 3211, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000027, mae: 0.003710, mean_q: 0.004934
 29499/100000: episode: 3212, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000021, mae: 0.003053, mean_q: 0.004415
 29509/100000: episode: 3213, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000054, mae: 0.003871, mean_q: 0.004536
 29519/100000: episode: 3214, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002824, mean_q: 0.004508
 29529/100000: episode: 3215, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000041, mae: 0.002953, mean_q: 0.004097
 29539/100000: episode: 3216, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000037, mae: 0.002785, mean_q: 0.004107
 29549/100000: episode: 3217, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000009, mae: 0.002387, mean_q: 0.004195
 29559/100000: episode: 3218, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.002305, mean_q: 0.003517
 29569/100000: episode: 3219, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.003067, mean_q: 0.004359
 29579/100000: episode: 3220, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.003120, mean_q: 0.004544
 29589/100000: episode: 3221, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000032, mae: 0.003672, mean_q: 0.004596
 29599/100000: episode: 3222, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000057, mae: 0.004589, mean_q: 0.005394
 29609/100000: episode: 3223, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000068, mae: 0.003956, mean_q: 0.005264
 29619/100000: episode: 3224, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000025, mae: 0.003197, mean_q: 0.004444
 29629/100000: episode: 3225, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000017, mae: 0.002843, mean_q: 0.004389
 29639/100000: episode: 3226, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000057, mae: 0.004113, mean_q: 0.004963
 29649/100000: episode: 3227, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.003920, mean_q: 0.005324
[Info] 1-TH LEVEL FOUND: 0.004046615678817034, Considering 100/100 traces
 29659/100000: episode: 3228, duration: 0.917s, episode steps: 10, steps per second: 11, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.002640, mean_q: 0.003819
[Info] 2-TH LEVEL FOUND: 0.006488316226750612, Considering 100/100 traces
 29669/100000: episode: 3229, duration: 0.968s, episode steps: 10, steps per second: 10, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000091, mae: 0.005631, mean_q: 0.005857
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006488316226750612
 29679/100000: episode: 3230, duration: 0.820s, episode steps: 10, steps per second: 12, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003810, mean_q: 0.005045
 29689/100000: episode: 3231, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000012, mae: 0.002636, mean_q: 0.003882
 29699/100000: episode: 3232, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000030, mae: 0.003794, mean_q: 0.004759
 29709/100000: episode: 3233, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000032, mae: 0.004218, mean_q: 0.005062
 29719/100000: episode: 3234, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000029, mae: 0.003358, mean_q: 0.004356
 29729/100000: episode: 3235, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000046, mae: 0.003731, mean_q: 0.004849
 29739/100000: episode: 3236, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000102, mae: 0.005011, mean_q: 0.005391
 29749/100000: episode: 3237, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000074, mae: 0.004619, mean_q: 0.005795
 29759/100000: episode: 3238, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.003159, mean_q: 0.004398
 29769/100000: episode: 3239, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003468, mean_q: 0.004486
 29779/100000: episode: 3240, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000016, mae: 0.002825, mean_q: 0.004598
 29789/100000: episode: 3241, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000042, mae: 0.003053, mean_q: 0.004243
 29799/100000: episode: 3242, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003049, mean_q: 0.004593
 29809/100000: episode: 3243, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000018, mae: 0.003130, mean_q: 0.004225
 29819/100000: episode: 3244, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000044, mae: 0.003214, mean_q: 0.004261
 29829/100000: episode: 3245, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000019, mae: 0.002897, mean_q: 0.004608
 29839/100000: episode: 3246, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000058, mae: 0.003909, mean_q: 0.004196
 29849/100000: episode: 3247, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000024, mae: 0.004293, mean_q: 0.005743
 29859/100000: episode: 3248, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000048, mae: 0.003469, mean_q: 0.004318
 29869/100000: episode: 3249, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.003484, mean_q: 0.004713
 29879/100000: episode: 3250, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000010, mae: 0.002366, mean_q: 0.004028
 29889/100000: episode: 3251, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000027, mae: 0.002998, mean_q: 0.003754
 29899/100000: episode: 3252, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000022, mae: 0.003529, mean_q: 0.005067
 29909/100000: episode: 3253, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000044, mae: 0.003210, mean_q: 0.004056
 29919/100000: episode: 3254, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000044, mae: 0.003516, mean_q: 0.004469
 29929/100000: episode: 3255, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000019, mae: 0.003173, mean_q: 0.004452
 29939/100000: episode: 3256, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000053, mae: 0.003832, mean_q: 0.004497
 29949/100000: episode: 3257, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000017, mae: 0.002836, mean_q: 0.004438
 29959/100000: episode: 3258, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000043, mae: 0.002906, mean_q: 0.003649
 29969/100000: episode: 3259, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000019, mae: 0.003757, mean_q: 0.005478
 29979/100000: episode: 3260, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000060, mae: 0.003792, mean_q: 0.004018
 29989/100000: episode: 3261, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000080, mae: 0.004650, mean_q: 0.005347
 29999/100000: episode: 3262, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000058, mae: 0.005204, mean_q: 0.006217
 30009/100000: episode: 3263, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000011, mae: 0.002722, mean_q: 0.004534
 30019/100000: episode: 3264, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000033, mae: 0.003454, mean_q: 0.004169
 30029/100000: episode: 3265, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000029, mae: 0.004036, mean_q: 0.005478
 30039/100000: episode: 3266, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000058, mae: 0.004069, mean_q: 0.004573
 30049/100000: episode: 3267, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000053, mae: 0.004841, mean_q: 0.006224
 30059/100000: episode: 3268, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000019, mae: 0.002672, mean_q: 0.003599
 30069/100000: episode: 3269, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003220, mean_q: 0.004451
 30079/100000: episode: 3270, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000011, mae: 0.002809, mean_q: 0.004814
 30089/100000: episode: 3271, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003418, mean_q: 0.004414
 30099/100000: episode: 3272, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000054, mae: 0.003972, mean_q: 0.004755
 30109/100000: episode: 3273, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000082, mae: 0.005257, mean_q: 0.005920
 30119/100000: episode: 3274, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002908, mean_q: 0.004608
 30129/100000: episode: 3275, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000039, mae: 0.002734, mean_q: 0.003760
 30139/100000: episode: 3276, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000059, mae: 0.005413, mean_q: 0.006832
 30149/100000: episode: 3277, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000047, mae: 0.003140, mean_q: 0.003893
 30159/100000: episode: 3278, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000068, mae: 0.004126, mean_q: 0.005446
 30169/100000: episode: 3279, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000071, mae: 0.003402, mean_q: 0.003970
 30179/100000: episode: 3280, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000028, mae: 0.003806, mean_q: 0.005224
 30189/100000: episode: 3281, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000041, mae: 0.002933, mean_q: 0.003921
 30199/100000: episode: 3282, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000019, mae: 0.003015, mean_q: 0.004417
 30209/100000: episode: 3283, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000019, mae: 0.003123, mean_q: 0.004472
 30219/100000: episode: 3284, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000071, mae: 0.003904, mean_q: 0.004696
 30229/100000: episode: 3285, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000015, mae: 0.002908, mean_q: 0.004470
 30239/100000: episode: 3286, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000017, mae: 0.002452, mean_q: 0.003790
 30249/100000: episode: 3287, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002815, mean_q: 0.004452
 30259/100000: episode: 3288, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000047, mae: 0.003502, mean_q: 0.004349
 30269/100000: episode: 3289, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.003175, mean_q: 0.005004
 30279/100000: episode: 3290, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000042, mae: 0.002671, mean_q: 0.003181
 30289/100000: episode: 3291, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.003355, mean_q: 0.004801
 30299/100000: episode: 3292, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002550, mean_q: 0.003762
 30309/100000: episode: 3293, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003055, mean_q: 0.004365
 30319/100000: episode: 3294, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.002937, mean_q: 0.004320
 30329/100000: episode: 3295, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.002962, mean_q: 0.004407
 30339/100000: episode: 3296, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002548, mean_q: 0.003684
 30349/100000: episode: 3297, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000045, mae: 0.003321, mean_q: 0.004231
 30359/100000: episode: 3298, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000045, mae: 0.003588, mean_q: 0.004745
 30369/100000: episode: 3299, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000012, mae: 0.002417, mean_q: 0.003589
 30379/100000: episode: 3300, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000030, mae: 0.003243, mean_q: 0.004123
 30389/100000: episode: 3301, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000023, mae: 0.003530, mean_q: 0.004721
 30399/100000: episode: 3302, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.002758, mean_q: 0.003826
 30409/100000: episode: 3303, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000031, mae: 0.004031, mean_q: 0.004840
 30419/100000: episode: 3304, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000027, mae: 0.003235, mean_q: 0.003942
 30429/100000: episode: 3305, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000016, mae: 0.003212, mean_q: 0.004603
 30439/100000: episode: 3306, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000047, mae: 0.003681, mean_q: 0.004618
 30449/100000: episode: 3307, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000041, mae: 0.003053, mean_q: 0.004178
 30459/100000: episode: 3308, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000020, mae: 0.003475, mean_q: 0.004855
 30469/100000: episode: 3309, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000074, mae: 0.003452, mean_q: 0.003833
 30479/100000: episode: 3310, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000022, mae: 0.004026, mean_q: 0.005641
 30489/100000: episode: 3311, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000074, mae: 0.003630, mean_q: 0.003456
 30499/100000: episode: 3312, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000012, mae: 0.003352, mean_q: 0.005349
 30509/100000: episode: 3313, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003260, mean_q: 0.003978
 30519/100000: episode: 3314, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.002806, mean_q: 0.003919
 30529/100000: episode: 3315, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000030, mae: 0.003333, mean_q: 0.004162
 30539/100000: episode: 3316, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000030, mae: 0.003751, mean_q: 0.004591
 30549/100000: episode: 3317, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000045, mae: 0.003414, mean_q: 0.004567
 30559/100000: episode: 3318, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002765, mean_q: 0.004192
 30569/100000: episode: 3319, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.002206, mean_q: 0.003624
 30579/100000: episode: 3320, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000085, mae: 0.004801, mean_q: 0.005134
 30589/100000: episode: 3321, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000043, mae: 0.002977, mean_q: 0.003875
 30599/100000: episode: 3322, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000037, mae: 0.002907, mean_q: 0.004104
 30609/100000: episode: 3323, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000050, mae: 0.003898, mean_q: 0.004828
 30619/100000: episode: 3324, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000014, mae: 0.002772, mean_q: 0.004137
 30629/100000: episode: 3325, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000062, mae: 0.003296, mean_q: 0.004304
 30639/100000: episode: 3326, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003184, mean_q: 0.003889
 30649/100000: episode: 3327, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000049, mae: 0.004124, mean_q: 0.005246
 30659/100000: episode: 3328, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000038, mae: 0.002684, mean_q: 0.003677
 30669/100000: episode: 3329, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000029, mae: 0.003756, mean_q: 0.004875
[Info] 1-TH LEVEL FOUND: 0.0042066676542162895, Considering 100/100 traces
 30679/100000: episode: 3330, duration: 0.743s, episode steps: 10, steps per second: 13, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000028, mae: 0.003317, mean_q: 0.004492
[Info] 2-TH LEVEL FOUND: 0.004272626247256994, Considering 100/100 traces
 30689/100000: episode: 3331, duration: 0.671s, episode steps: 10, steps per second: 15, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.003007, mean_q: 0.004112
[Info] 3-TH LEVEL FOUND: 0.005654047708958387, Considering 100/100 traces
 30699/100000: episode: 3332, duration: 0.721s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000092, mae: 0.004395, mean_q: 0.005230
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005654047708958387
 30709/100000: episode: 3333, duration: 0.526s, episode steps: 10, steps per second: 19, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000010, mae: 0.002354, mean_q: 0.003760
 30719/100000: episode: 3334, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000053, mae: 0.003658, mean_q: 0.004079
 30729/100000: episode: 3335, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000037, mae: 0.003023, mean_q: 0.004703
 30739/100000: episode: 3336, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000026, mae: 0.002971, mean_q: 0.003610
 30749/100000: episode: 3337, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000019, mae: 0.003756, mean_q: 0.005359
 30759/100000: episode: 3338, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000075, mae: 0.003817, mean_q: 0.004192
 30769/100000: episode: 3339, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000027, mae: 0.003938, mean_q: 0.005565
 30779/100000: episode: 3340, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000009, mae: 0.002207, mean_q: 0.003437
 30789/100000: episode: 3341, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000068, mae: 0.003575, mean_q: 0.003949
 30799/100000: episode: 3342, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000077, mae: 0.004941, mean_q: 0.005970
 30809/100000: episode: 3343, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000058, mae: 0.004698, mean_q: 0.005510
 30819/100000: episode: 3344, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000052, mae: 0.003857, mean_q: 0.004884
 30829/100000: episode: 3345, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000016, mae: 0.002607, mean_q: 0.003607
 30839/100000: episode: 3346, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000018, mae: 0.002879, mean_q: 0.004277
 30849/100000: episode: 3347, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000018, mae: 0.002900, mean_q: 0.004216
 30859/100000: episode: 3348, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000010, mae: 0.002323, mean_q: 0.003693
 30869/100000: episode: 3349, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000053, mae: 0.003905, mean_q: 0.004552
 30879/100000: episode: 3350, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000014, mae: 0.003207, mean_q: 0.005046
 30889/100000: episode: 3351, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.002822, mean_q: 0.003346
 30899/100000: episode: 3352, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003588, mean_q: 0.004847
 30909/100000: episode: 3353, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000041, mae: 0.002768, mean_q: 0.003886
 30919/100000: episode: 3354, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000019, mae: 0.003414, mean_q: 0.005045
 30929/100000: episode: 3355, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000024, mae: 0.002868, mean_q: 0.003819
 30939/100000: episode: 3356, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000028, mae: 0.004003, mean_q: 0.004913
 30949/100000: episode: 3357, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000052, mae: 0.003478, mean_q: 0.004253
 30959/100000: episode: 3358, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.003512, mean_q: 0.005149
 30969/100000: episode: 3359, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000067, mae: 0.004294, mean_q: 0.004588
 30979/100000: episode: 3360, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003398, mean_q: 0.004556
 30989/100000: episode: 3361, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.003865, mean_q: 0.004760
 30999/100000: episode: 3362, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000076, mae: 0.004206, mean_q: 0.004619
 31009/100000: episode: 3363, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002977, mean_q: 0.004816
 31019/100000: episode: 3364, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000013, mae: 0.002273, mean_q: 0.003648
 31029/100000: episode: 3365, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000010, mae: 0.002554, mean_q: 0.004249
 31039/100000: episode: 3366, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000043, mae: 0.003101, mean_q: 0.003787
 31049/100000: episode: 3367, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000080, mae: 0.004282, mean_q: 0.004802
 31059/100000: episode: 3368, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000019, mae: 0.002976, mean_q: 0.004612
 31069/100000: episode: 3369, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000049, mae: 0.003599, mean_q: 0.004497
 31079/100000: episode: 3370, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000051, mae: 0.004610, mean_q: 0.005788
 31089/100000: episode: 3371, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000012, mae: 0.002227, mean_q: 0.003067
 31099/100000: episode: 3372, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000095, mae: 0.004695, mean_q: 0.005326
 31109/100000: episode: 3373, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000025, mae: 0.003586, mean_q: 0.005029
 31119/100000: episode: 3374, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000015, mae: 0.002631, mean_q: 0.003761
 31129/100000: episode: 3375, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000023, mae: 0.003167, mean_q: 0.004730
 31139/100000: episode: 3376, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000009, mae: 0.002313, mean_q: 0.003755
 31149/100000: episode: 3377, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000048, mae: 0.003390, mean_q: 0.003826
 31159/100000: episode: 3378, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000008, mae: 0.003038, mean_q: 0.005112
 31169/100000: episode: 3379, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000013, mae: 0.001976, mean_q: 0.003178
 31179/100000: episode: 3380, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000041, mae: 0.003138, mean_q: 0.004284
 31189/100000: episode: 3381, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000047, mae: 0.003786, mean_q: 0.004841
 31199/100000: episode: 3382, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000055, mae: 0.004572, mean_q: 0.005262
 31209/100000: episode: 3383, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000009, mae: 0.002571, mean_q: 0.003959
 31219/100000: episode: 3384, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000095, mae: 0.003561, mean_q: 0.004031
 31229/100000: episode: 3385, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.003848, mean_q: 0.005678
 31239/100000: episode: 3386, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000042, mae: 0.003036, mean_q: 0.004091
 31249/100000: episode: 3387, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000016, mae: 0.002617, mean_q: 0.003902
 31259/100000: episode: 3388, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.003222, mean_q: 0.004214
 31269/100000: episode: 3389, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000043, mae: 0.003273, mean_q: 0.004152
 31279/100000: episode: 3390, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000071, mae: 0.003983, mean_q: 0.004607
 31289/100000: episode: 3391, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002991, mean_q: 0.004533
 31299/100000: episode: 3392, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000019, mae: 0.002589, mean_q: 0.003311
 31309/100000: episode: 3393, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000038, mae: 0.003723, mean_q: 0.005422
 31319/100000: episode: 3394, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000019, mae: 0.002345, mean_q: 0.003125
 31329/100000: episode: 3395, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000042, mae: 0.003428, mean_q: 0.004574
 31339/100000: episode: 3396, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000100, mae: 0.005090, mean_q: 0.005829
 31349/100000: episode: 3397, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000132, mae: 0.005586, mean_q: 0.005503
 31359/100000: episode: 3398, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000037, mae: 0.003163, mean_q: 0.004792
 31369/100000: episode: 3399, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000013, mae: 0.002421, mean_q: 0.003164
 31379/100000: episode: 3400, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000047, mae: 0.003355, mean_q: 0.004649
 31389/100000: episode: 3401, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.003194, mean_q: 0.004692
 31399/100000: episode: 3402, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000027, mae: 0.003306, mean_q: 0.004099
 31409/100000: episode: 3403, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000106, mae: 0.005028, mean_q: 0.005170
 31419/100000: episode: 3404, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000016, mae: 0.003598, mean_q: 0.005259
 31429/100000: episode: 3405, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000043, mae: 0.003304, mean_q: 0.004377
 31439/100000: episode: 3406, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003875, mean_q: 0.005171
 31449/100000: episode: 3407, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000036, mae: 0.002599, mean_q: 0.004023
 31459/100000: episode: 3408, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.002858, mean_q: 0.004131
 31469/100000: episode: 3409, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000077, mae: 0.004717, mean_q: 0.005605
 31479/100000: episode: 3410, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000020, mae: 0.002771, mean_q: 0.004238
 31489/100000: episode: 3411, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.002800, mean_q: 0.004418
 31499/100000: episode: 3412, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000018, mae: 0.003092, mean_q: 0.004486
 31509/100000: episode: 3413, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002665, mean_q: 0.004093
 31519/100000: episode: 3414, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000013, mae: 0.002551, mean_q: 0.004217
 31529/100000: episode: 3415, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000034, mae: 0.002603, mean_q: 0.003810
 31539/100000: episode: 3416, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000009, mae: 0.002352, mean_q: 0.004122
 31549/100000: episode: 3417, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000022, mae: 0.003229, mean_q: 0.004558
 31559/100000: episode: 3418, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000079, mae: 0.004241, mean_q: 0.004823
 31569/100000: episode: 3419, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000015, mae: 0.002748, mean_q: 0.004165
 31579/100000: episode: 3420, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002455, mean_q: 0.003785
 31589/100000: episode: 3421, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000048, mae: 0.003367, mean_q: 0.003912
 31599/100000: episode: 3422, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000013, mae: 0.003310, mean_q: 0.005133
 31609/100000: episode: 3423, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000083, mae: 0.003776, mean_q: 0.003390
 31619/100000: episode: 3424, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000024, mae: 0.004731, mean_q: 0.006474
 31629/100000: episode: 3425, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000040, mae: 0.002555, mean_q: 0.002576
 31639/100000: episode: 3426, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000052, mae: 0.003719, mean_q: 0.004454
 31649/100000: episode: 3427, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.004119, mean_q: 0.005302
 31659/100000: episode: 3428, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000014, mae: 0.002422, mean_q: 0.003765
 31669/100000: episode: 3429, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000053, mae: 0.004124, mean_q: 0.004938
 31679/100000: episode: 3430, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000040, mae: 0.002944, mean_q: 0.003907
 31689/100000: episode: 3431, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000071, mae: 0.004432, mean_q: 0.005403
 31699/100000: episode: 3432, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000024, mae: 0.003361, mean_q: 0.004329
[Info] 1-TH LEVEL FOUND: 0.0048423404805362225, Considering 100/100 traces
 31709/100000: episode: 3433, duration: 0.705s, episode steps: 10, steps per second: 14, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000042, mae: 0.003369, mean_q: 0.004363
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0048423404805362225
 31719/100000: episode: 3434, duration: 0.491s, episode steps: 10, steps per second: 20, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003175, mean_q: 0.004342
 31729/100000: episode: 3435, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000038, mae: 0.003278, mean_q: 0.004508
 31739/100000: episode: 3436, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000014, mae: 0.002820, mean_q: 0.004293
 31749/100000: episode: 3437, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000011, mae: 0.002365, mean_q: 0.003771
 31759/100000: episode: 3438, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000058, mae: 0.004190, mean_q: 0.004698
 31769/100000: episode: 3439, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.003233, mean_q: 0.004727
 31779/100000: episode: 3440, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002663, mean_q: 0.003899
 31789/100000: episode: 3441, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000025, mae: 0.003786, mean_q: 0.004850
 31799/100000: episode: 3442, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000048, mae: 0.003741, mean_q: 0.004814
 31809/100000: episode: 3443, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000041, mae: 0.002820, mean_q: 0.003913
 31819/100000: episode: 3444, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000024, mae: 0.003077, mean_q: 0.004151
 31829/100000: episode: 3445, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000032, mae: 0.003863, mean_q: 0.004886
 31839/100000: episode: 3446, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002787, mean_q: 0.004157
 31849/100000: episode: 3447, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000048, mae: 0.003139, mean_q: 0.003973
 31859/100000: episode: 3448, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003548, mean_q: 0.004638
 31869/100000: episode: 3449, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000054, mae: 0.003865, mean_q: 0.004464
 31879/100000: episode: 3450, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000079, mae: 0.004480, mean_q: 0.005237
 31889/100000: episode: 3451, duration: 0.121s, episode steps: 10, steps per second: 82, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003567, mean_q: 0.004664
 31899/100000: episode: 3452, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000012, mae: 0.002643, mean_q: 0.003953
 31909/100000: episode: 3453, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003034, mean_q: 0.003948
 31919/100000: episode: 3454, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000013, mae: 0.003061, mean_q: 0.005027
 31929/100000: episode: 3455, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000078, mae: 0.003519, mean_q: 0.003533
 31939/100000: episode: 3456, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000052, mae: 0.004553, mean_q: 0.005807
 31949/100000: episode: 3457, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000054, mae: 0.003621, mean_q: 0.004051
 31959/100000: episode: 3458, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000009, mae: 0.002522, mean_q: 0.004326
 31969/100000: episode: 3459, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000014, mae: 0.002078, mean_q: 0.002806
 31979/100000: episode: 3460, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.003693, mean_q: 0.005045
 31989/100000: episode: 3461, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000015, mae: 0.002616, mean_q: 0.003767
 31999/100000: episode: 3462, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000034, mae: 0.003999, mean_q: 0.004618
 32009/100000: episode: 3463, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000040, mae: 0.003492, mean_q: 0.004586
 32019/100000: episode: 3464, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.002726, mean_q: 0.003671
 32029/100000: episode: 3465, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000014, mae: 0.003099, mean_q: 0.004765
 32039/100000: episode: 3466, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000133, mae: 0.004988, mean_q: 0.004481
 32049/100000: episode: 3467, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000046, mae: 0.004205, mean_q: 0.005580
 32059/100000: episode: 3468, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002545, mean_q: 0.003322
 32069/100000: episode: 3469, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000046, mae: 0.003653, mean_q: 0.004636
 32079/100000: episode: 3470, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000014, mae: 0.002716, mean_q: 0.004463
 32089/100000: episode: 3471, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000098, mae: 0.004826, mean_q: 0.005356
 32099/100000: episode: 3472, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000108, mae: 0.005441, mean_q: 0.005842
 32109/100000: episode: 3473, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000067, mae: 0.003807, mean_q: 0.004744
 32119/100000: episode: 3474, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000073, mae: 0.003631, mean_q: 0.004254
 32129/100000: episode: 3475, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000044, mae: 0.004458, mean_q: 0.005904
 32139/100000: episode: 3476, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.002710, mean_q: 0.003780
 32149/100000: episode: 3477, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000031, mae: 0.003693, mean_q: 0.004406
 32159/100000: episode: 3478, duration: 0.107s, episode steps: 10, steps per second: 94, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000072, mae: 0.004001, mean_q: 0.005096
 32169/100000: episode: 3479, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003604, mean_q: 0.004790
 32179/100000: episode: 3480, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000050, mae: 0.003456, mean_q: 0.004285
 32189/100000: episode: 3481, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.002936, mean_q: 0.004248
 32199/100000: episode: 3482, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000049, mae: 0.003723, mean_q: 0.004894
 32209/100000: episode: 3483, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000035, mae: 0.002963, mean_q: 0.004365
 32219/100000: episode: 3484, duration: 0.082s, episode steps: 10, steps per second: 121, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000034, mae: 0.003817, mean_q: 0.004382
 32229/100000: episode: 3485, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000052, mae: 0.004247, mean_q: 0.005441
 32239/100000: episode: 3486, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000045, mae: 0.004693, mean_q: 0.005331
 32249/100000: episode: 3487, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003411, mean_q: 0.004870
 32259/100000: episode: 3488, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000049, mae: 0.002916, mean_q: 0.003554
 32269/100000: episode: 3489, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000016, mae: 0.003393, mean_q: 0.005102
 32279/100000: episode: 3490, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000019, mae: 0.003207, mean_q: 0.004726
 32289/100000: episode: 3491, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003285, mean_q: 0.004393
 32299/100000: episode: 3492, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.002679, mean_q: 0.003955
 32309/100000: episode: 3493, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000085, mae: 0.004724, mean_q: 0.004988
 32319/100000: episode: 3494, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000049, mae: 0.003792, mean_q: 0.005101
 32329/100000: episode: 3495, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000080, mae: 0.004876, mean_q: 0.005341
 32339/100000: episode: 3496, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000028, mae: 0.003448, mean_q: 0.004709
 32349/100000: episode: 3497, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000037, mae: 0.002323, mean_q: 0.003343
 32359/100000: episode: 3498, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000010, mae: 0.002700, mean_q: 0.004650
 32369/100000: episode: 3499, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000027, mae: 0.003295, mean_q: 0.004013
 32379/100000: episode: 3500, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000059, mae: 0.004568, mean_q: 0.005222
 32389/100000: episode: 3501, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000017, mae: 0.003757, mean_q: 0.005452
 32399/100000: episode: 3502, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.002992, mean_q: 0.004334
 32409/100000: episode: 3503, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000050, mae: 0.003705, mean_q: 0.004740
 32419/100000: episode: 3504, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000023, mae: 0.003450, mean_q: 0.004830
 32429/100000: episode: 3505, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000012, mae: 0.002488, mean_q: 0.003791
 32439/100000: episode: 3506, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000028, mae: 0.003477, mean_q: 0.004297
 32449/100000: episode: 3507, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000105, mae: 0.005818, mean_q: 0.006493
 32459/100000: episode: 3508, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.002765, mean_q: 0.003807
 32469/100000: episode: 3509, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000083, mae: 0.005074, mean_q: 0.005769
 32479/100000: episode: 3510, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000019, mae: 0.003125, mean_q: 0.004564
 32489/100000: episode: 3511, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000053, mae: 0.003038, mean_q: 0.003182
 32499/100000: episode: 3512, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000017, mae: 0.004265, mean_q: 0.006582
 32509/100000: episode: 3513, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.002726, mean_q: 0.003042
 32519/100000: episode: 3514, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000051, mae: 0.004236, mean_q: 0.005297
 32529/100000: episode: 3515, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000081, mae: 0.004529, mean_q: 0.005136
 32539/100000: episode: 3516, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000052, mae: 0.003662, mean_q: 0.004772
 32549/100000: episode: 3517, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000253, mae: 0.005234, mean_q: 0.005338
 32559/100000: episode: 3518, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000079, mae: 0.005069, mean_q: 0.005955
 32569/100000: episode: 3519, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000253, mae: 0.004876, mean_q: 0.005108
 32579/100000: episode: 3520, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000011, mae: 0.002904, mean_q: 0.004994
 32589/100000: episode: 3521, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000044, mae: 0.003067, mean_q: 0.003902
 32599/100000: episode: 3522, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.004216, mean_q: 0.005690
 32609/100000: episode: 3523, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000049, mae: 0.004593, mean_q: 0.005777
 32619/100000: episode: 3524, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000222, mae: 0.004361, mean_q: 0.005285
 32629/100000: episode: 3525, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000031, mae: 0.004116, mean_q: 0.005762
 32639/100000: episode: 3526, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000087, mae: 0.004590, mean_q: 0.004555
 32649/100000: episode: 3527, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.004187, mean_q: 0.006312
 32659/100000: episode: 3528, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000080, mae: 0.003932, mean_q: 0.004169
 32669/100000: episode: 3529, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000027, mae: 0.004213, mean_q: 0.005881
 32679/100000: episode: 3530, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000078, mae: 0.004321, mean_q: 0.005155
 32689/100000: episode: 3531, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000074, mae: 0.004197, mean_q: 0.004994
 32699/100000: episode: 3532, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000039, mae: 0.004237, mean_q: 0.006572
 32709/100000: episode: 3533, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000080, mae: 0.003376, mean_q: 0.003884
[Info] 1-TH LEVEL FOUND: 0.0045758807100355625, Considering 100/100 traces
 32719/100000: episode: 3534, duration: 1.039s, episode steps: 10, steps per second: 10, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000039, mae: 0.003570, mean_q: 0.005423
[Info] 2-TH LEVEL FOUND: 0.007869260385632515, Considering 100/100 traces
 32729/100000: episode: 3535, duration: 0.907s, episode steps: 10, steps per second: 11, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000334, mae: 0.005316, mean_q: 0.004554
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007869260385632515
 32739/100000: episode: 3536, duration: 0.540s, episode steps: 10, steps per second: 19, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000113, mae: 0.007198, mean_q: 0.008488
 32749/100000: episode: 3537, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000053, mae: 0.003634, mean_q: 0.004407
 32759/100000: episode: 3538, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000027, mae: 0.003209, mean_q: 0.004547
 32769/100000: episode: 3539, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000101, mae: 0.004897, mean_q: 0.005801
 32779/100000: episode: 3540, duration: 0.117s, episode steps: 10, steps per second: 86, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000049, mae: 0.004435, mean_q: 0.005881
 32789/100000: episode: 3541, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.002911, mean_q: 0.004612
 32799/100000: episode: 3542, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000053, mae: 0.003724, mean_q: 0.004668
 32809/100000: episode: 3543, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000063, mae: 0.004109, mean_q: 0.005820
 32819/100000: episode: 3544, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000073, mae: 0.004081, mean_q: 0.005019
 32829/100000: episode: 3545, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000035, mae: 0.004432, mean_q: 0.005509
 32839/100000: episode: 3546, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000038, mae: 0.004176, mean_q: 0.005537
 32849/100000: episode: 3547, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000056, mae: 0.004779, mean_q: 0.006244
 32859/100000: episode: 3548, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000271, mae: 0.005236, mean_q: 0.005017
 32869/100000: episode: 3549, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000010, mae: 0.003820, mean_q: 0.006682
 32879/100000: episode: 3550, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000319, mae: 0.005216, mean_q: 0.003557
 32889/100000: episode: 3551, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000050, mae: 0.006014, mean_q: 0.008418
 32899/100000: episode: 3552, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003031, mean_q: 0.003736
 32909/100000: episode: 3553, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000098, mae: 0.004191, mean_q: 0.004920
 32919/100000: episode: 3554, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000061, mae: 0.005061, mean_q: 0.006215
 32929/100000: episode: 3555, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000079, mae: 0.004918, mean_q: 0.005964
 32939/100000: episode: 3556, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000012, mae: 0.002720, mean_q: 0.004686
 32949/100000: episode: 3557, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000020, mae: 0.002779, mean_q: 0.004073
 32959/100000: episode: 3558, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003401, mean_q: 0.005333
 32969/100000: episode: 3559, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000011, mae: 0.002487, mean_q: 0.004124
 32979/100000: episode: 3560, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000066, mae: 0.003477, mean_q: 0.004664
 32989/100000: episode: 3561, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000044, mae: 0.003463, mean_q: 0.004772
 32999/100000: episode: 3562, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000114, mae: 0.005378, mean_q: 0.005542
 33009/100000: episode: 3563, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000038, mae: 0.004193, mean_q: 0.006323
 33019/100000: episode: 3564, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.002445, mean_q: 0.002806
 33029/100000: episode: 3565, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000107, mae: 0.007138, mean_q: 0.007298
 33039/100000: episode: 3566, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000282, mae: 0.006435, mean_q: 0.006925
 33049/100000: episode: 3567, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000019, mae: 0.003178, mean_q: 0.005037
 33059/100000: episode: 3568, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.002923, mean_q: 0.004435
 33069/100000: episode: 3569, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000096, mae: 0.004524, mean_q: 0.005204
 33079/100000: episode: 3570, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000078, mae: 0.004393, mean_q: 0.005201
 33089/100000: episode: 3571, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000044, mae: 0.003489, mean_q: 0.004901
 33099/100000: episode: 3572, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000079, mae: 0.004805, mean_q: 0.005662
 33109/100000: episode: 3573, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000007, mae: 0.002865, mean_q: 0.005456
 33119/100000: episode: 3574, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000113, mae: 0.004256, mean_q: 0.003840
 33129/100000: episode: 3575, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000234, mae: 0.005739, mean_q: 0.006576
 33139/100000: episode: 3576, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000102, mae: 0.005075, mean_q: 0.005766
 33149/100000: episode: 3577, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.003091, mean_q: 0.005260
 33159/100000: episode: 3578, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000046, mae: 0.002980, mean_q: 0.004221
 33169/100000: episode: 3579, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000045, mae: 0.003816, mean_q: 0.005135
 33179/100000: episode: 3580, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002704, mean_q: 0.004354
 33189/100000: episode: 3581, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000018, mae: 0.002915, mean_q: 0.004656
 33199/100000: episode: 3582, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.002877, mean_q: 0.004490
 33209/100000: episode: 3583, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002742, mean_q: 0.004075
 33219/100000: episode: 3584, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000307, mae: 0.005892, mean_q: 0.005375
 33229/100000: episode: 3585, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000070, mae: 0.006008, mean_q: 0.007152
 33239/100000: episode: 3586, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000113, mae: 0.004736, mean_q: 0.004704
 33249/100000: episode: 3587, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.004246, mean_q: 0.005985
 33259/100000: episode: 3588, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000043, mae: 0.003165, mean_q: 0.004509
 33269/100000: episode: 3589, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000043, mae: 0.003268, mean_q: 0.004551
 33279/100000: episode: 3590, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000057, mae: 0.004178, mean_q: 0.004951
 33289/100000: episode: 3591, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000254, mae: 0.005258, mean_q: 0.005733
 33299/100000: episode: 3592, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000018, mae: 0.003350, mean_q: 0.005300
 33309/100000: episode: 3593, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000035, mae: 0.002212, mean_q: 0.003271
 33319/100000: episode: 3594, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000099, mae: 0.004928, mean_q: 0.005726
 33329/100000: episode: 3595, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000240, mae: 0.005680, mean_q: 0.005750
 33339/100000: episode: 3596, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000082, mae: 0.005780, mean_q: 0.007036
 33349/100000: episode: 3597, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000049, mae: 0.003761, mean_q: 0.005136
 33359/100000: episode: 3598, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000042, mae: 0.002965, mean_q: 0.004094
 33369/100000: episode: 3599, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000015, mae: 0.002989, mean_q: 0.004834
 33379/100000: episode: 3600, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000236, mae: 0.004377, mean_q: 0.004376
 33389/100000: episode: 3601, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.004285, mean_q: 0.006156
 33399/100000: episode: 3602, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.002982, mean_q: 0.004293
 33409/100000: episode: 3603, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000080, mae: 0.004426, mean_q: 0.004843
 33419/100000: episode: 3604, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000104, mae: 0.005460, mean_q: 0.006093
 33429/100000: episode: 3605, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000054, mae: 0.004033, mean_q: 0.005211
 33439/100000: episode: 3606, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003059, mean_q: 0.004668
 33449/100000: episode: 3607, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000312, mae: 0.006970, mean_q: 0.006775
 33459/100000: episode: 3608, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000085, mae: 0.005138, mean_q: 0.005901
 33469/100000: episode: 3609, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.003207, mean_q: 0.004328
 33479/100000: episode: 3610, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000053, mae: 0.004114, mean_q: 0.005541
 33489/100000: episode: 3611, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000025, mae: 0.003717, mean_q: 0.005058
 33499/100000: episode: 3612, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000060, mae: 0.004151, mean_q: 0.005063
 33509/100000: episode: 3613, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000057, mae: 0.005008, mean_q: 0.006417
 33519/100000: episode: 3614, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003427, mean_q: 0.004438
 33529/100000: episode: 3615, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000052, mae: 0.003728, mean_q: 0.005072
 33539/100000: episode: 3616, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000026, mae: 0.003653, mean_q: 0.005285
 33549/100000: episode: 3617, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000086, mae: 0.004862, mean_q: 0.005375
 33559/100000: episode: 3618, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000027, mae: 0.004100, mean_q: 0.005755
 33569/100000: episode: 3619, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000271, mae: 0.005484, mean_q: 0.004847
 33579/100000: episode: 3620, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000052, mae: 0.005434, mean_q: 0.007350
 33589/100000: episode: 3621, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000076, mae: 0.003901, mean_q: 0.004484
 33599/100000: episode: 3622, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000030, mae: 0.003940, mean_q: 0.005354
 33609/100000: episode: 3623, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000011, mae: 0.002796, mean_q: 0.005152
 33619/100000: episode: 3624, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000057, mae: 0.003777, mean_q: 0.004514
 33629/100000: episode: 3625, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.004094, mean_q: 0.005559
 33639/100000: episode: 3626, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000038, mae: 0.003304, mean_q: 0.005118
 33649/100000: episode: 3627, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000032, mae: 0.003628, mean_q: 0.004823
 33659/100000: episode: 3628, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000033, mae: 0.004344, mean_q: 0.005833
 33669/100000: episode: 3629, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000055, mae: 0.003967, mean_q: 0.005249
 33679/100000: episode: 3630, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000256, mae: 0.005372, mean_q: 0.006060
 33689/100000: episode: 3631, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000052, mae: 0.004009, mean_q: 0.004962
 33699/100000: episode: 3632, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.003996, mean_q: 0.005263
 33709/100000: episode: 3633, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000053, mae: 0.004038, mean_q: 0.005259
 33719/100000: episode: 3634, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000312, mae: 0.005853, mean_q: 0.004952
 33729/100000: episode: 3635, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000083, mae: 0.006383, mean_q: 0.007915
[Info] 1-TH LEVEL FOUND: 0.003673070576041937, Considering 100/100 traces
 33739/100000: episode: 3636, duration: 0.660s, episode steps: 10, steps per second: 15, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000049, mae: 0.003407, mean_q: 0.004586
[Info] 2-TH LEVEL FOUND: 0.005831056274473667, Considering 100/100 traces
 33749/100000: episode: 3637, duration: 0.848s, episode steps: 10, steps per second: 12, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000051, mae: 0.003676, mean_q: 0.004658
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005831056274473667
 33759/100000: episode: 3638, duration: 0.736s, episode steps: 10, steps per second: 14, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000026, mae: 0.004237, mean_q: 0.005904
 33769/100000: episode: 3639, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000071, mae: 0.003745, mean_q: 0.004818
 33779/100000: episode: 3640, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000055, mae: 0.004381, mean_q: 0.005451
 33789/100000: episode: 3641, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000052, mae: 0.004074, mean_q: 0.005341
 33799/100000: episode: 3642, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000035, mae: 0.003850, mean_q: 0.005148
 33809/100000: episode: 3643, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000048, mae: 0.004763, mean_q: 0.006509
 33819/100000: episode: 3644, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000085, mae: 0.004442, mean_q: 0.005013
 33829/100000: episode: 3645, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000051, mae: 0.004806, mean_q: 0.006357
 33839/100000: episode: 3646, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000049, mae: 0.003864, mean_q: 0.005041
 33849/100000: episode: 3647, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000263, mae: 0.005190, mean_q: 0.005225
 33859/100000: episode: 3648, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000032, mae: 0.004548, mean_q: 0.006163
 33869/100000: episode: 3649, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000056, mae: 0.003733, mean_q: 0.004823
 33879/100000: episode: 3650, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000022, mae: 0.003643, mean_q: 0.005612
 33889/100000: episode: 3651, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000048, mae: 0.003307, mean_q: 0.004651
 33899/100000: episode: 3652, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000051, mae: 0.004125, mean_q: 0.005356
 33909/100000: episode: 3653, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000279, mae: 0.006471, mean_q: 0.006760
 33919/100000: episode: 3654, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000084, mae: 0.004466, mean_q: 0.005398
 33929/100000: episode: 3655, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000259, mae: 0.006282, mean_q: 0.007059
 33939/100000: episode: 3656, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000048, mae: 0.003558, mean_q: 0.004801
 33949/100000: episode: 3657, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000051, mae: 0.003819, mean_q: 0.004881
 33959/100000: episode: 3658, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000024, mae: 0.003826, mean_q: 0.005504
 33969/100000: episode: 3659, duration: 0.107s, episode steps: 10, steps per second: 94, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000108, mae: 0.004933, mean_q: 0.005171
 33979/100000: episode: 3660, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000049, mae: 0.004903, mean_q: 0.006675
 33989/100000: episode: 3661, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000056, mae: 0.004174, mean_q: 0.005032
 33999/100000: episode: 3662, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000289, mae: 0.005912, mean_q: 0.005864
 34009/100000: episode: 3663, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000252, mae: 0.005797, mean_q: 0.006656
 34019/100000: episode: 3664, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000047, mae: 0.004118, mean_q: 0.006119
 34029/100000: episode: 3665, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000014, mae: 0.002752, mean_q: 0.004444
 34039/100000: episode: 3666, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000040, mae: 0.003078, mean_q: 0.004668
 34049/100000: episode: 3667, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000080, mae: 0.004552, mean_q: 0.005594
 34059/100000: episode: 3668, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000055, mae: 0.004766, mean_q: 0.005973
 34069/100000: episode: 3669, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000021, mae: 0.003278, mean_q: 0.005162
 34079/100000: episode: 3670, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000074, mae: 0.004018, mean_q: 0.004595
 34089/100000: episode: 3671, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000265, mae: 0.006279, mean_q: 0.006593
 34099/100000: episode: 3672, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000073, mae: 0.004681, mean_q: 0.006168
 34109/100000: episode: 3673, duration: 0.073s, episode steps: 10, steps per second: 136, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000030, mae: 0.004097, mean_q: 0.005697
 34119/100000: episode: 3674, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000015, mae: 0.002923, mean_q: 0.004629
 34129/100000: episode: 3675, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000061, mae: 0.004611, mean_q: 0.005439
 34139/100000: episode: 3676, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000074, mae: 0.004494, mean_q: 0.005872
 34149/100000: episode: 3677, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000037, mae: 0.004201, mean_q: 0.005543
 34159/100000: episode: 3678, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000077, mae: 0.004074, mean_q: 0.005187
 34169/100000: episode: 3679, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.004201, mean_q: 0.005522
 34179/100000: episode: 3680, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000134, mae: 0.004896, mean_q: 0.004874
 34189/100000: episode: 3681, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000064, mae: 0.005830, mean_q: 0.007363
 34199/100000: episode: 3682, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000048, mae: 0.003282, mean_q: 0.004350
 34209/100000: episode: 3683, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000024, mae: 0.003381, mean_q: 0.004772
 34219/100000: episode: 3684, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000047, mae: 0.003922, mean_q: 0.005508
 34229/100000: episode: 3685, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000086, mae: 0.004593, mean_q: 0.005051
 34239/100000: episode: 3686, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000081, mae: 0.005042, mean_q: 0.006275
 34249/100000: episode: 3687, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000069, mae: 0.004249, mean_q: 0.005757
 34259/100000: episode: 3688, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000229, mae: 0.004030, mean_q: 0.004460
 34269/100000: episode: 3689, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000109, mae: 0.006224, mean_q: 0.007458
 34279/100000: episode: 3690, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000046, mae: 0.003627, mean_q: 0.004968
 34289/100000: episode: 3691, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000044, mae: 0.002850, mean_q: 0.004431
 34299/100000: episode: 3692, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000019, mae: 0.003374, mean_q: 0.005084
 34309/100000: episode: 3693, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000010, mae: 0.002163, mean_q: 0.003902
 34319/100000: episode: 3694, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000059, mae: 0.004251, mean_q: 0.004901
 34329/100000: episode: 3695, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000075, mae: 0.005101, mean_q: 0.006301
 34339/100000: episode: 3696, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000027, mae: 0.003318, mean_q: 0.004528
 34349/100000: episode: 3697, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000079, mae: 0.004717, mean_q: 0.005377
 34359/100000: episode: 3698, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000026, mae: 0.003997, mean_q: 0.005765
 34369/100000: episode: 3699, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000241, mae: 0.004874, mean_q: 0.005108
 34379/100000: episode: 3700, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000076, mae: 0.005135, mean_q: 0.006413
 34389/100000: episode: 3701, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000076, mae: 0.004375, mean_q: 0.005229
 34399/100000: episode: 3702, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000029, mae: 0.003977, mean_q: 0.005686
 34409/100000: episode: 3703, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000028, mae: 0.004883, mean_q: 0.006809
 34419/100000: episode: 3704, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.002711, mean_q: 0.004087
 34429/100000: episode: 3705, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000240, mae: 0.005343, mean_q: 0.005499
 34439/100000: episode: 3706, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000062, mae: 0.006287, mean_q: 0.007707
 34449/100000: episode: 3707, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000037, mae: 0.004107, mean_q: 0.005360
 34459/100000: episode: 3708, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000233, mae: 0.005326, mean_q: 0.006180
 34469/100000: episode: 3709, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000067, mae: 0.004039, mean_q: 0.005733
 34479/100000: episode: 3710, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000051, mae: 0.003586, mean_q: 0.004439
 34489/100000: episode: 3711, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000080, mae: 0.005778, mean_q: 0.007179
 34499/100000: episode: 3712, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000059, mae: 0.004187, mean_q: 0.005068
 34509/100000: episode: 3713, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000077, mae: 0.003979, mean_q: 0.004989
 34519/100000: episode: 3714, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000078, mae: 0.005759, mean_q: 0.007181
 34529/100000: episode: 3715, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000088, mae: 0.005722, mean_q: 0.006825
 34539/100000: episode: 3716, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000028, mae: 0.003850, mean_q: 0.005443
 34549/100000: episode: 3717, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000023, mae: 0.003574, mean_q: 0.005483
 34559/100000: episode: 3718, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000058, mae: 0.004412, mean_q: 0.005692
 34569/100000: episode: 3719, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000069, mae: 0.004047, mean_q: 0.005648
 34579/100000: episode: 3720, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000030, mae: 0.004119, mean_q: 0.005830
 34589/100000: episode: 3721, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.003102, mean_q: 0.004976
 34599/100000: episode: 3722, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000078, mae: 0.003735, mean_q: 0.004394
 34609/100000: episode: 3723, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000057, mae: 0.004994, mean_q: 0.006523
 34619/100000: episode: 3724, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000064, mae: 0.004347, mean_q: 0.005061
 34629/100000: episode: 3725, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000022, mae: 0.003359, mean_q: 0.005341
 34639/100000: episode: 3726, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002896, mean_q: 0.004773
 34649/100000: episode: 3727, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000081, mae: 0.004426, mean_q: 0.005112
 34659/100000: episode: 3728, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000057, mae: 0.004352, mean_q: 0.005605
 34669/100000: episode: 3729, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000049, mae: 0.004107, mean_q: 0.005531
 34679/100000: episode: 3730, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000016, mae: 0.003160, mean_q: 0.005124
 34689/100000: episode: 3731, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000033, mae: 0.003360, mean_q: 0.004472
 34699/100000: episode: 3732, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000161, mae: 0.006490, mean_q: 0.006402
 34709/100000: episode: 3733, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000031, mae: 0.004898, mean_q: 0.006997
 34719/100000: episode: 3734, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000069, mae: 0.004534, mean_q: 0.004666
 34729/100000: episode: 3735, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000058, mae: 0.004500, mean_q: 0.005744
 34739/100000: episode: 3736, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000072, mae: 0.005622, mean_q: 0.006543
 34749/100000: episode: 3737, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000017, mae: 0.004063, mean_q: 0.006431
[Info] 1-TH LEVEL FOUND: 0.004386531189084053, Considering 100/100 traces
 34759/100000: episode: 3738, duration: 1.034s, episode steps: 10, steps per second: 10, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000024, mae: 0.002767, mean_q: 0.003712
[Info] 2-TH LEVEL FOUND: 0.005817492492496967, Considering 100/100 traces
 34769/100000: episode: 3739, duration: 1.083s, episode steps: 10, steps per second: 9, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000048, mae: 0.003753, mean_q: 0.005417
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005817492492496967
 34779/100000: episode: 3740, duration: 0.485s, episode steps: 10, steps per second: 21, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000075, mae: 0.004456, mean_q: 0.005597
 34789/100000: episode: 3741, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000077, mae: 0.004521, mean_q: 0.005820
 34799/100000: episode: 3742, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000036, mae: 0.002966, mean_q: 0.004533
 34809/100000: episode: 3743, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000096, mae: 0.005007, mean_q: 0.005104
 34819/100000: episode: 3744, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000072, mae: 0.005428, mean_q: 0.007138
 34829/100000: episode: 3745, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000076, mae: 0.003956, mean_q: 0.004612
 34839/100000: episode: 3746, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000021, mae: 0.003283, mean_q: 0.005172
 34849/100000: episode: 3747, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000021, mae: 0.002859, mean_q: 0.004348
 34859/100000: episode: 3748, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.003086, mean_q: 0.004581
 34869/100000: episode: 3749, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003570, mean_q: 0.004838
 34879/100000: episode: 3750, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000107, mae: 0.005028, mean_q: 0.005260
 34889/100000: episode: 3751, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.004745, mean_q: 0.007264
 34899/100000: episode: 3752, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000046, mae: 0.002649, mean_q: 0.003356
 34909/100000: episode: 3753, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000287, mae: 0.006676, mean_q: 0.006543
 34919/100000: episode: 3754, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.004055, mean_q: 0.006316
 34929/100000: episode: 3755, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000029, mae: 0.003220, mean_q: 0.003863
 34939/100000: episode: 3756, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000036, mae: 0.004100, mean_q: 0.005286
 34949/100000: episode: 3757, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003611, mean_q: 0.005277
 34959/100000: episode: 3758, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003141, mean_q: 0.004871
 34969/100000: episode: 3759, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000024, mae: 0.003202, mean_q: 0.004219
 34979/100000: episode: 3760, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.004258, mean_q: 0.005451
 34989/100000: episode: 3761, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000043, mae: 0.003748, mean_q: 0.005209
 34999/100000: episode: 3762, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000081, mae: 0.004021, mean_q: 0.004449
 35009/100000: episode: 3763, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000020, mae: 0.003459, mean_q: 0.005211
 35019/100000: episode: 3764, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000031, mae: 0.003811, mean_q: 0.004670
 35029/100000: episode: 3765, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000011, mae: 0.002684, mean_q: 0.004531
 35039/100000: episode: 3766, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000057, mae: 0.003748, mean_q: 0.004470
 35049/100000: episode: 3767, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000046, mae: 0.004136, mean_q: 0.005749
 35059/100000: episode: 3768, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000057, mae: 0.004015, mean_q: 0.004979
 35069/100000: episode: 3769, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000473, mae: 0.007597, mean_q: 0.006473
 35079/100000: episode: 3770, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000075, mae: 0.006251, mean_q: 0.008227
 35089/100000: episode: 3771, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.002421, mean_q: 0.004158
 35099/100000: episode: 3772, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000028, mae: 0.003463, mean_q: 0.004380
 35109/100000: episode: 3773, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000074, mae: 0.004613, mean_q: 0.005907
 35119/100000: episode: 3774, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000442, mae: 0.006740, mean_q: 0.006200
 35129/100000: episode: 3775, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000258, mae: 0.006178, mean_q: 0.006641
 35139/100000: episode: 3776, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000256, mae: 0.005140, mean_q: 0.005787
 35149/100000: episode: 3777, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.003543, mean_q: 0.005575
 35159/100000: episode: 3778, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000016, mae: 0.003024, mean_q: 0.004358
 35169/100000: episode: 3779, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.003870, mean_q: 0.005306
 35179/100000: episode: 3780, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.003258, mean_q: 0.004782
 35189/100000: episode: 3781, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000099, mae: 0.004301, mean_q: 0.005021
 35199/100000: episode: 3782, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000017, mae: 0.003433, mean_q: 0.005404
 35209/100000: episode: 3783, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000045, mae: 0.003236, mean_q: 0.004203
 35219/100000: episode: 3784, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000086, mae: 0.005241, mean_q: 0.005736
 35229/100000: episode: 3785, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000235, mae: 0.005727, mean_q: 0.006423
 35239/100000: episode: 3786, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000063, mae: 0.004767, mean_q: 0.005894
 35249/100000: episode: 3787, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000044, mae: 0.003210, mean_q: 0.004425
 35259/100000: episode: 3788, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000025, mae: 0.003339, mean_q: 0.004890
 35269/100000: episode: 3789, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000084, mae: 0.004505, mean_q: 0.004909
 35279/100000: episode: 3790, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000054, mae: 0.005313, mean_q: 0.006741
 35289/100000: episode: 3791, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000025, mae: 0.003491, mean_q: 0.004739
 35299/100000: episode: 3792, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000017, mae: 0.002769, mean_q: 0.004559
 35309/100000: episode: 3793, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.003445, mean_q: 0.005150
 35319/100000: episode: 3794, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000027, mae: 0.003183, mean_q: 0.004803
 35329/100000: episode: 3795, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000026, mae: 0.004110, mean_q: 0.005895
 35339/100000: episode: 3796, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000050, mae: 0.003607, mean_q: 0.004883
 35349/100000: episode: 3797, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003320, mean_q: 0.004796
 35359/100000: episode: 3798, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000068, mae: 0.003867, mean_q: 0.004993
 35369/100000: episode: 3799, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000269, mae: 0.006205, mean_q: 0.006071
 35379/100000: episode: 3800, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000056, mae: 0.005333, mean_q: 0.006787
 35389/100000: episode: 3801, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000057, mae: 0.003391, mean_q: 0.003531
 35399/100000: episode: 3802, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000293, mae: 0.007870, mean_q: 0.007990
 35409/100000: episode: 3803, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000061, mae: 0.004603, mean_q: 0.005515
 35419/100000: episode: 3804, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000035, mae: 0.003673, mean_q: 0.004399
 35429/100000: episode: 3805, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000008, mae: 0.002996, mean_q: 0.005484
 35439/100000: episode: 3806, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000093, mae: 0.003319, mean_q: 0.003679
 35449/100000: episode: 3807, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000055, mae: 0.004876, mean_q: 0.006348
 35459/100000: episode: 3808, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000103, mae: 0.005398, mean_q: 0.006288
 35469/100000: episode: 3809, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000023, mae: 0.003892, mean_q: 0.005872
 35479/100000: episode: 3810, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000040, mae: 0.003012, mean_q: 0.004373
 35489/100000: episode: 3811, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.002714, mean_q: 0.004554
 35499/100000: episode: 3812, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.003017, mean_q: 0.004651
 35509/100000: episode: 3813, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000067, mae: 0.004332, mean_q: 0.005047
 35519/100000: episode: 3814, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000019, mae: 0.003954, mean_q: 0.005821
 35529/100000: episode: 3815, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000018, mae: 0.002586, mean_q: 0.003963
 35539/100000: episode: 3816, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000012, mae: 0.002634, mean_q: 0.004130
 35549/100000: episode: 3817, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000243, mae: 0.005480, mean_q: 0.005607
 35559/100000: episode: 3818, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000054, mae: 0.004744, mean_q: 0.006213
 35569/100000: episode: 3819, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000031, mae: 0.003707, mean_q: 0.004591
 35579/100000: episode: 3820, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000043, mae: 0.003797, mean_q: 0.005433
 35589/100000: episode: 3821, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000011, mae: 0.002396, mean_q: 0.003937
 35599/100000: episode: 3822, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000020, mae: 0.002822, mean_q: 0.004011
 35609/100000: episode: 3823, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000024, mae: 0.003531, mean_q: 0.004943
 35619/100000: episode: 3824, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.002423, mean_q: 0.004004
 35629/100000: episode: 3825, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000077, mae: 0.004066, mean_q: 0.004875
 35639/100000: episode: 3826, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.004554, mean_q: 0.005305
 35649/100000: episode: 3827, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000043, mae: 0.004129, mean_q: 0.004931
 35659/100000: episode: 3828, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000013, mae: 0.003469, mean_q: 0.005493
 35669/100000: episode: 3829, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.003742, mean_q: 0.004770
 35679/100000: episode: 3830, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000025, mae: 0.003697, mean_q: 0.005164
 35689/100000: episode: 3831, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000070, mae: 0.003544, mean_q: 0.004281
 35699/100000: episode: 3832, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000055, mae: 0.004379, mean_q: 0.005278
 35709/100000: episode: 3833, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000072, mae: 0.004620, mean_q: 0.005725
 35719/100000: episode: 3834, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000057, mae: 0.004247, mean_q: 0.005198
 35729/100000: episode: 3835, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000028, mae: 0.003760, mean_q: 0.004999
 35739/100000: episode: 3836, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.004294, mean_q: 0.005953
 35749/100000: episode: 3837, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000027, mae: 0.003055, mean_q: 0.004441
 35759/100000: episode: 3838, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003853, mean_q: 0.004699
 35769/100000: episode: 3839, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000031, mae: 0.004460, mean_q: 0.005843
[Info] 1-TH LEVEL FOUND: 0.0049609956331551075, Considering 100/100 traces
 35779/100000: episode: 3840, duration: 0.665s, episode steps: 10, steps per second: 15, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000032, mae: 0.003858, mean_q: 0.004633
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0049609956331551075
 35789/100000: episode: 3841, duration: 0.491s, episode steps: 10, steps per second: 20, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000017, mae: 0.002980, mean_q: 0.004632
 35799/100000: episode: 3842, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.002761, mean_q: 0.004136
 35809/100000: episode: 3843, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000051, mae: 0.004209, mean_q: 0.005358
 35819/100000: episode: 3844, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000017, mae: 0.003379, mean_q: 0.005023
 35829/100000: episode: 3845, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000040, mae: 0.002736, mean_q: 0.003743
 35839/100000: episode: 3846, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000043, mae: 0.003442, mean_q: 0.004680
 35849/100000: episode: 3847, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000074, mae: 0.004459, mean_q: 0.005552
 35859/100000: episode: 3848, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000040, mae: 0.003158, mean_q: 0.004376
 35869/100000: episode: 3849, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000076, mae: 0.004085, mean_q: 0.004638
 35879/100000: episode: 3850, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000012, mae: 0.003537, mean_q: 0.005815
 35889/100000: episode: 3851, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000047, mae: 0.002819, mean_q: 0.003852
 35899/100000: episode: 3852, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000074, mae: 0.004427, mean_q: 0.005083
 35909/100000: episode: 3853, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000049, mae: 0.003948, mean_q: 0.004973
 35919/100000: episode: 3854, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000084, mae: 0.004517, mean_q: 0.004958
 35929/100000: episode: 3855, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000053, mae: 0.004901, mean_q: 0.006207
 35939/100000: episode: 3856, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.003155, mean_q: 0.004595
 35949/100000: episode: 3857, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000011, mae: 0.002532, mean_q: 0.003852
 35959/100000: episode: 3858, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.003927, mean_q: 0.005020
 35969/100000: episode: 3859, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000053, mae: 0.004451, mean_q: 0.005584
 35979/100000: episode: 3860, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000076, mae: 0.003793, mean_q: 0.004208
 35989/100000: episode: 3861, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000023, mae: 0.004227, mean_q: 0.006164
 35999/100000: episode: 3862, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000085, mae: 0.004551, mean_q: 0.005081
 36009/100000: episode: 3863, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000245, mae: 0.005611, mean_q: 0.005605
 36019/100000: episode: 3864, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000058, mae: 0.005422, mean_q: 0.006779
 36029/100000: episode: 3865, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.003817, mean_q: 0.005044
 36039/100000: episode: 3866, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000223, mae: 0.004371, mean_q: 0.004669
 36049/100000: episode: 3867, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.004156, mean_q: 0.006259
 36059/100000: episode: 3868, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000015, mae: 0.002535, mean_q: 0.004086
 36069/100000: episode: 3869, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000035, mae: 0.003972, mean_q: 0.004887
 36079/100000: episode: 3870, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000051, mae: 0.003897, mean_q: 0.005147
 36089/100000: episode: 3871, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000230, mae: 0.005203, mean_q: 0.006116
 36099/100000: episode: 3872, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000025, mae: 0.004699, mean_q: 0.006890
 36109/100000: episode: 3873, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000025, mae: 0.003190, mean_q: 0.004530
 36119/100000: episode: 3874, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000278, mae: 0.005428, mean_q: 0.005636
 36129/100000: episode: 3875, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000019, mae: 0.004605, mean_q: 0.007100
 36139/100000: episode: 3876, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000057, mae: 0.003439, mean_q: 0.003584
 36149/100000: episode: 3877, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000054, mae: 0.004661, mean_q: 0.006022
 36159/100000: episode: 3878, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.003062, mean_q: 0.005103
 36169/100000: episode: 3879, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000079, mae: 0.004205, mean_q: 0.004903
 36179/100000: episode: 3880, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000047, mae: 0.004772, mean_q: 0.006262
 36189/100000: episode: 3881, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000241, mae: 0.004571, mean_q: 0.005546
 36199/100000: episode: 3882, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000031, mae: 0.003599, mean_q: 0.005082
 36209/100000: episode: 3883, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000077, mae: 0.004883, mean_q: 0.005658
 36219/100000: episode: 3884, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000081, mae: 0.004657, mean_q: 0.005802
 36229/100000: episode: 3885, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000049, mae: 0.003906, mean_q: 0.005459
 36239/100000: episode: 3886, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000006, mae: 0.002199, mean_q: 0.004547
 36249/100000: episode: 3887, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000037, mae: 0.003583, mean_q: 0.004293
 36259/100000: episode: 3888, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003953, mean_q: 0.005676
 36269/100000: episode: 3889, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000010, mae: 0.002354, mean_q: 0.004198
 36279/100000: episode: 3890, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000010, mae: 0.001901, mean_q: 0.003378
 36289/100000: episode: 3891, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000037, mae: 0.002946, mean_q: 0.004472
 36299/100000: episode: 3892, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003677, mean_q: 0.005010
 36309/100000: episode: 3893, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000054, mae: 0.004292, mean_q: 0.005380
 36319/100000: episode: 3894, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000027, mae: 0.003516, mean_q: 0.005170
 36329/100000: episode: 3895, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000019, mae: 0.002639, mean_q: 0.003964
 36339/100000: episode: 3896, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000084, mae: 0.004732, mean_q: 0.005360
 36349/100000: episode: 3897, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000067, mae: 0.003947, mean_q: 0.005235
 36359/100000: episode: 3898, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000308, mae: 0.006555, mean_q: 0.006279
 36369/100000: episode: 3899, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000080, mae: 0.004988, mean_q: 0.006176
 36379/100000: episode: 3900, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.002913, mean_q: 0.004294
 36389/100000: episode: 3901, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000024, mae: 0.003343, mean_q: 0.004712
 36399/100000: episode: 3902, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000024, mae: 0.003601, mean_q: 0.005168
 36409/100000: episode: 3903, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000147, mae: 0.005679, mean_q: 0.005106
 36419/100000: episode: 3904, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000043, mae: 0.004563, mean_q: 0.006404
 36429/100000: episode: 3905, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000017, mae: 0.003285, mean_q: 0.005065
 36439/100000: episode: 3906, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000090, mae: 0.004749, mean_q: 0.004804
 36449/100000: episode: 3907, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000032, mae: 0.004790, mean_q: 0.006400
 36459/100000: episode: 3908, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.002856, mean_q: 0.004380
 36469/100000: episode: 3909, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000037, mae: 0.003050, mean_q: 0.004913
 36479/100000: episode: 3910, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002455, mean_q: 0.004182
 36489/100000: episode: 3911, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000291, mae: 0.005906, mean_q: 0.005238
 36499/100000: episode: 3912, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000087, mae: 0.006376, mean_q: 0.007171
 36509/100000: episode: 3913, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000048, mae: 0.003386, mean_q: 0.004426
 36519/100000: episode: 3914, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.003587, mean_q: 0.004822
 36529/100000: episode: 3915, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003916, mean_q: 0.005566
 36539/100000: episode: 3916, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000252, mae: 0.004453, mean_q: 0.004277
 36549/100000: episode: 3917, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000050, mae: 0.004700, mean_q: 0.006315
 36559/100000: episode: 3918, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000023, mae: 0.003444, mean_q: 0.005151
 36569/100000: episode: 3919, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000373, mae: 0.007587, mean_q: 0.005914
 36579/100000: episode: 3920, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000084, mae: 0.007222, mean_q: 0.008872
 36589/100000: episode: 3921, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000044, mae: 0.002928, mean_q: 0.002645
 36599/100000: episode: 3922, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000051, mae: 0.003629, mean_q: 0.004473
 36609/100000: episode: 3923, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000248, mae: 0.005553, mean_q: 0.006548
 36619/100000: episode: 3924, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.004303, mean_q: 0.005954
 36629/100000: episode: 3925, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000052, mae: 0.003305, mean_q: 0.004394
 36639/100000: episode: 3926, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000085, mae: 0.005422, mean_q: 0.006529
 36649/100000: episode: 3927, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000229, mae: 0.004653, mean_q: 0.005326
 36659/100000: episode: 3928, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.003238, mean_q: 0.005187
 36669/100000: episode: 3929, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000032, mae: 0.003775, mean_q: 0.004800
 36679/100000: episode: 3930, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000034, mae: 0.004343, mean_q: 0.005732
 36689/100000: episode: 3931, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003655, mean_q: 0.005357
 36699/100000: episode: 3932, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000260, mae: 0.005690, mean_q: 0.006079
 36709/100000: episode: 3933, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000458, mae: 0.006627, mean_q: 0.006082
 36719/100000: episode: 3934, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003802, mean_q: 0.006422
 36729/100000: episode: 3935, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.002486, mean_q: 0.003617
 36739/100000: episode: 3936, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000044, mae: 0.003680, mean_q: 0.005104
 36749/100000: episode: 3937, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000028, mae: 0.003876, mean_q: 0.005309
 36759/100000: episode: 3938, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000076, mae: 0.004079, mean_q: 0.004720
 36769/100000: episode: 3939, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000039, mae: 0.003606, mean_q: 0.005541
 36779/100000: episode: 3940, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000027, mae: 0.003531, mean_q: 0.004713
[Info] 1-TH LEVEL FOUND: 0.004649549722671509, Considering 100/100 traces
 36789/100000: episode: 3941, duration: 0.667s, episode steps: 10, steps per second: 15, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.002897, mean_q: 0.004820
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004649549722671509
 36799/100000: episode: 3942, duration: 0.487s, episode steps: 10, steps per second: 21, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000029, mae: 0.003211, mean_q: 0.004332
 36809/100000: episode: 3943, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000046, mae: 0.003387, mean_q: 0.004691
 36819/100000: episode: 3944, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000080, mae: 0.004546, mean_q: 0.005340
 36829/100000: episode: 3945, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.004423, mean_q: 0.005856
 36839/100000: episode: 3946, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000031, mae: 0.004067, mean_q: 0.005270
 36849/100000: episode: 3947, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000031, mae: 0.003611, mean_q: 0.004986
 36859/100000: episode: 3948, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000047, mae: 0.003993, mean_q: 0.005493
 36869/100000: episode: 3949, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000043, mae: 0.004278, mean_q: 0.005977
 36879/100000: episode: 3950, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000148, mae: 0.005319, mean_q: 0.005846
 36889/100000: episode: 3951, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.004370, mean_q: 0.005888
 36899/100000: episode: 3952, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000049, mae: 0.003661, mean_q: 0.005137
 36909/100000: episode: 3953, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000008, mae: 0.002579, mean_q: 0.004577
 36919/100000: episode: 3954, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000230, mae: 0.004086, mean_q: 0.004652
 36929/100000: episode: 3955, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000256, mae: 0.006248, mean_q: 0.006821
 36939/100000: episode: 3956, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000072, mae: 0.004210, mean_q: 0.005157
 36949/100000: episode: 3957, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000056, mae: 0.004611, mean_q: 0.005903
 36959/100000: episode: 3958, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000052, mae: 0.003990, mean_q: 0.005172
 36969/100000: episode: 3959, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000053, mae: 0.004206, mean_q: 0.005534
 36979/100000: episode: 3960, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000017, mae: 0.003059, mean_q: 0.005010
 36989/100000: episode: 3961, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.002824, mean_q: 0.003883
 36999/100000: episode: 3962, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.003268, mean_q: 0.004916
 37009/100000: episode: 3963, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000031, mae: 0.003715, mean_q: 0.004842
 37019/100000: episode: 3964, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000016, mae: 0.003044, mean_q: 0.004659
 37029/100000: episode: 3965, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000015, mae: 0.002770, mean_q: 0.004326
 37039/100000: episode: 3966, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000054, mae: 0.003913, mean_q: 0.004745
 37049/100000: episode: 3967, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000032, mae: 0.004059, mean_q: 0.005480
 37059/100000: episode: 3968, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000028, mae: 0.003470, mean_q: 0.004342
 37069/100000: episode: 3969, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.003871, mean_q: 0.005124
 37079/100000: episode: 3970, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000037, mae: 0.003706, mean_q: 0.005474
 37089/100000: episode: 3971, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000044, mae: 0.002957, mean_q: 0.004041
 37099/100000: episode: 3972, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000029, mae: 0.003511, mean_q: 0.004675
 37109/100000: episode: 3973, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003488, mean_q: 0.004936
 37119/100000: episode: 3974, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.002888, mean_q: 0.004007
 37129/100000: episode: 3975, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.003061, mean_q: 0.004532
 37139/100000: episode: 3976, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000039, mae: 0.003757, mean_q: 0.004528
 37149/100000: episode: 3977, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003780, mean_q: 0.005359
 37159/100000: episode: 3978, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.002572, mean_q: 0.004222
 37169/100000: episode: 3979, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000012, mae: 0.002374, mean_q: 0.004083
 37179/100000: episode: 3980, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000051, mae: 0.003218, mean_q: 0.004195
 37189/100000: episode: 3981, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000012, mae: 0.003071, mean_q: 0.004944
 37199/100000: episode: 3982, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000028, mae: 0.002916, mean_q: 0.003838
 37209/100000: episode: 3983, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000030, mae: 0.003894, mean_q: 0.004978
 37219/100000: episode: 3984, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002951, mean_q: 0.004639
 37229/100000: episode: 3985, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000052, mae: 0.003882, mean_q: 0.004413
 37239/100000: episode: 3986, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000030, mae: 0.004420, mean_q: 0.005802
 37249/100000: episode: 3987, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000023, mae: 0.003295, mean_q: 0.004415
 37259/100000: episode: 3988, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000044, mae: 0.004099, mean_q: 0.005602
 37269/100000: episode: 3989, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000078, mae: 0.004142, mean_q: 0.005025
 37279/100000: episode: 3990, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000042, mae: 0.003164, mean_q: 0.004389
 37289/100000: episode: 3991, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000070, mae: 0.003809, mean_q: 0.004861
 37299/100000: episode: 3992, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000015, mae: 0.002969, mean_q: 0.004512
 37309/100000: episode: 3993, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000031, mae: 0.003227, mean_q: 0.004184
 37319/100000: episode: 3994, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000035, mae: 0.004360, mean_q: 0.005279
 37329/100000: episode: 3995, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000047, mae: 0.003819, mean_q: 0.005013
 37339/100000: episode: 3996, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000051, mae: 0.003946, mean_q: 0.004893
 37349/100000: episode: 3997, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000049, mae: 0.003852, mean_q: 0.005128
 37359/100000: episode: 3998, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.003012, mean_q: 0.004552
 37369/100000: episode: 3999, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.003231, mean_q: 0.004536
 37379/100000: episode: 4000, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000018, mae: 0.002908, mean_q: 0.004230
 37389/100000: episode: 4001, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000054, mae: 0.004321, mean_q: 0.005107
 37399/100000: episode: 4002, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000053, mae: 0.004028, mean_q: 0.005042
 37409/100000: episode: 4003, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000027, mae: 0.003687, mean_q: 0.004737
 37419/100000: episode: 4004, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000044, mae: 0.003364, mean_q: 0.004503
 37429/100000: episode: 4005, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003427, mean_q: 0.004845
 37439/100000: episode: 4006, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000028, mae: 0.003377, mean_q: 0.004824
 37449/100000: episode: 4007, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.002906, mean_q: 0.004117
 37459/100000: episode: 4008, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000070, mae: 0.003817, mean_q: 0.004727
 37469/100000: episode: 4009, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000049, mae: 0.003802, mean_q: 0.005083
[Info] FALSIFICATION!
 37479/100000: episode: 4010, duration: 0.279s, episode steps: 10, steps per second: 36, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000066, mae: 0.003703, mean_q: 0.004830
 37489/100000: episode: 4011, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000053, mae: 0.003969, mean_q: 0.004972
 37499/100000: episode: 4012, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000036, mae: 0.003234, mean_q: 0.005011
 37509/100000: episode: 4013, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002496, mean_q: 0.003878
 37519/100000: episode: 4014, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.003578, mean_q: 0.004660
 37529/100000: episode: 4015, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000234, mae: 0.004658, mean_q: 0.004855
 37539/100000: episode: 4016, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000016, mae: 0.003699, mean_q: 0.005709
 37549/100000: episode: 4017, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.003193, mean_q: 0.004147
 37559/100000: episode: 4018, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000043, mae: 0.003526, mean_q: 0.004828
 37569/100000: episode: 4019, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.003110, mean_q: 0.004558
 37579/100000: episode: 4020, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.002871, mean_q: 0.004484
 37589/100000: episode: 4021, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000038, mae: 0.002861, mean_q: 0.004052
 37599/100000: episode: 4022, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000026, mae: 0.003623, mean_q: 0.004794
 37609/100000: episode: 4023, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000058, mae: 0.004449, mean_q: 0.005222
 37619/100000: episode: 4024, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000236, mae: 0.004715, mean_q: 0.005099
 37629/100000: episode: 4025, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000047, mae: 0.004334, mean_q: 0.005948
 37639/100000: episode: 4026, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000014, mae: 0.002136, mean_q: 0.003034
 37649/100000: episode: 4027, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003802, mean_q: 0.004507
 37659/100000: episode: 4028, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000031, mae: 0.004189, mean_q: 0.005510
 37669/100000: episode: 4029, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000052, mae: 0.003379, mean_q: 0.004198
 37679/100000: episode: 4030, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000019, mae: 0.003434, mean_q: 0.004988
 37689/100000: episode: 4031, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000061, mae: 0.004407, mean_q: 0.005021
 37699/100000: episode: 4032, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000047, mae: 0.004069, mean_q: 0.005351
 37709/100000: episode: 4033, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000025, mae: 0.003439, mean_q: 0.004481
 37719/100000: episode: 4034, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000229, mae: 0.004541, mean_q: 0.005116
 37729/100000: episode: 4035, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000058, mae: 0.004896, mean_q: 0.006105
 37739/100000: episode: 4036, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000219, mae: 0.003686, mean_q: 0.004257
 37749/100000: episode: 4037, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000047, mae: 0.003872, mean_q: 0.005156
 37759/100000: episode: 4038, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000031, mae: 0.004497, mean_q: 0.005894
 37769/100000: episode: 4039, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000011, mae: 0.002428, mean_q: 0.004045
 37779/100000: episode: 4040, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000021, mae: 0.003385, mean_q: 0.004560
 37789/100000: episode: 4041, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.003274, mean_q: 0.004846
[Info] Complete ISplit Iteration
[Info] Levels: [0.009432622]
[Info] Cond. Prob: [1.0]
[Info] Error Prob: 1.0

 37799/100000: episode: 4042, duration: 0.853s, episode steps: 10, steps per second: 12, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001574, mae: 0.006820, mean_q: 0.005161
 37809/100000: episode: 4043, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000057, mae: 0.005942, mean_q: 0.007948
 37819/100000: episode: 4044, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000027, mae: 0.003165, mean_q: 0.003973
 37829/100000: episode: 4045, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000286, mae: 0.005681, mean_q: 0.005139
 37839/100000: episode: 4046, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000025, mae: 0.004958, mean_q: 0.007249
 37849/100000: episode: 4047, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000237, mae: 0.004650, mean_q: 0.004498
 37859/100000: episode: 4048, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000033, mae: 0.005293, mean_q: 0.006903
 37869/100000: episode: 4049, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001593, mae: 0.008531, mean_q: 0.007682
 37879/100000: episode: 4050, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000236, mae: 0.005875, mean_q: 0.007105
 37889/100000: episode: 4051, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000221, mae: 0.003923, mean_q: 0.005169
 37899/100000: episode: 4052, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000019, mae: 0.003394, mean_q: 0.005213
 37909/100000: episode: 4053, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000014, mae: 0.002820, mean_q: 0.004375
 37919/100000: episode: 4054, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000076, mae: 0.004053, mean_q: 0.005245
 37929/100000: episode: 4055, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000034, mae: 0.004505, mean_q: 0.006152
 37939/100000: episode: 4056, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003462, mean_q: 0.004948
 37949/100000: episode: 4057, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000019, mae: 0.003136, mean_q: 0.004789
 37959/100000: episode: 4058, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000031, mae: 0.003669, mean_q: 0.004863
 37969/100000: episode: 4059, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000030, mae: 0.003849, mean_q: 0.005308
 37979/100000: episode: 4060, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000053, mae: 0.004208, mean_q: 0.005482
 37989/100000: episode: 4061, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000055, mae: 0.004769, mean_q: 0.006150
 37999/100000: episode: 4062, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000028, mae: 0.003765, mean_q: 0.005057
 38009/100000: episode: 4063, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000043, mae: 0.003714, mean_q: 0.005413
 38019/100000: episode: 4064, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000053, mae: 0.003623, mean_q: 0.004686
 38029/100000: episode: 4065, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003323, mean_q: 0.004876
 38039/100000: episode: 4066, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003661, mean_q: 0.005274
 38049/100000: episode: 4067, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000466, mae: 0.007196, mean_q: 0.006869
 38059/100000: episode: 4068, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000026, mae: 0.003898, mean_q: 0.005660
 38069/100000: episode: 4069, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000026, mae: 0.002891, mean_q: 0.003838
 38079/100000: episode: 4070, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000038, mae: 0.003434, mean_q: 0.005323
 38089/100000: episode: 4071, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000042, mae: 0.003123, mean_q: 0.004613
 38099/100000: episode: 4072, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000037, mae: 0.003280, mean_q: 0.005021
 38109/100000: episode: 4073, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001567, mae: 0.006574, mean_q: 0.005355
 38119/100000: episode: 4074, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000025, mae: 0.005300, mean_q: 0.007499
 38129/100000: episode: 4075, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000028, mae: 0.003152, mean_q: 0.003984
 38139/100000: episode: 4076, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000017, mae: 0.003377, mean_q: 0.005203
 38149/100000: episode: 4077, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000013, mae: 0.002772, mean_q: 0.005168
 38159/100000: episode: 4078, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.002958, mean_q: 0.004121
 38169/100000: episode: 4079, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000028, mae: 0.003905, mean_q: 0.005157
 38179/100000: episode: 4080, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000013, mae: 0.002904, mean_q: 0.005150
 38189/100000: episode: 4081, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001599, mae: 0.007561, mean_q: 0.005997
 38199/100000: episode: 4082, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000025, mae: 0.005211, mean_q: 0.007879
 38209/100000: episode: 4083, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000074, mae: 0.003775, mean_q: 0.004184
 38219/100000: episode: 4084, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000017, mae: 0.003615, mean_q: 0.005666
 38229/100000: episode: 4085, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.002889, mean_q: 0.004595
 38239/100000: episode: 4086, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000050, mae: 0.003171, mean_q: 0.004117
 38249/100000: episode: 4087, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000025, mae: 0.003722, mean_q: 0.005456
 38259/100000: episode: 4088, duration: 0.077s, episode steps: 10, steps per second: 131, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000024, mae: 0.003252, mean_q: 0.004788
 38269/100000: episode: 4089, duration: 0.082s, episode steps: 10, steps per second: 121, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000020, mae: 0.002594, mean_q: 0.004148
 38279/100000: episode: 4090, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000044, mae: 0.002981, mean_q: 0.004272
 38289/100000: episode: 4091, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000039, mae: 0.003612, mean_q: 0.005433
 38299/100000: episode: 4092, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000029, mae: 0.003691, mean_q: 0.004780
 38309/100000: episode: 4093, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000025, mae: 0.003247, mean_q: 0.004602
 38319/100000: episode: 4094, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000040, mae: 0.002889, mean_q: 0.004451
 38329/100000: episode: 4095, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000017, mae: 0.002647, mean_q: 0.004176
 38339/100000: episode: 4096, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000024, mae: 0.003620, mean_q: 0.004935
 38349/100000: episode: 4097, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000070, mae: 0.005565, mean_q: 0.005918
 38359/100000: episode: 4098, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000052, mae: 0.004792, mean_q: 0.006041
 38369/100000: episode: 4099, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000015, mae: 0.002614, mean_q: 0.004171
 38379/100000: episode: 4100, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000017, mae: 0.002281, mean_q: 0.003709
 38389/100000: episode: 4101, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000029, mae: 0.003664, mean_q: 0.004952
 38399/100000: episode: 4102, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000050, mae: 0.003962, mean_q: 0.005305
 38409/100000: episode: 4103, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003541, mean_q: 0.004841
 38419/100000: episode: 4104, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000039, mae: 0.003121, mean_q: 0.004416
 38429/100000: episode: 4105, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000056, mae: 0.004055, mean_q: 0.004936
 38439/100000: episode: 4106, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000044, mae: 0.003791, mean_q: 0.005236
 38449/100000: episode: 4107, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000097, mae: 0.004135, mean_q: 0.004878
 38459/100000: episode: 4108, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000017, mae: 0.003259, mean_q: 0.004656
 38469/100000: episode: 4109, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000053, mae: 0.003904, mean_q: 0.004963
 38479/100000: episode: 4110, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000018, mae: 0.003105, mean_q: 0.004866
 38489/100000: episode: 4111, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000020, mae: 0.003079, mean_q: 0.004389
 38499/100000: episode: 4112, duration: 0.120s, episode steps: 10, steps per second: 83, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000019, mae: 0.003302, mean_q: 0.004867
 38509/100000: episode: 4113, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001597, mae: 0.007471, mean_q: 0.005972
 38519/100000: episode: 4114, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000045, mae: 0.004924, mean_q: 0.007069
 38529/100000: episode: 4115, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000024, mae: 0.003088, mean_q: 0.003983
 38539/100000: episode: 4116, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.003057, mean_q: 0.004976
 38549/100000: episode: 4117, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000025, mae: 0.002940, mean_q: 0.004253
 38559/100000: episode: 4118, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000034, mae: 0.003893, mean_q: 0.004822
 38569/100000: episode: 4119, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000018, mae: 0.003211, mean_q: 0.004965
 38579/100000: episode: 4120, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000080, mae: 0.004149, mean_q: 0.004314
 38589/100000: episode: 4121, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000032, mae: 0.004630, mean_q: 0.005820
 38599/100000: episode: 4122, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000043, mae: 0.003706, mean_q: 0.005315
 38609/100000: episode: 4123, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002652, mean_q: 0.004147
 38619/100000: episode: 4124, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000024, mae: 0.003484, mean_q: 0.004587
 38629/100000: episode: 4125, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000049, mae: 0.003902, mean_q: 0.005297
 38639/100000: episode: 4126, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000035, mae: 0.004139, mean_q: 0.005152
 38649/100000: episode: 4127, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000047, mae: 0.003926, mean_q: 0.005300
 38659/100000: episode: 4128, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001592, mae: 0.008004, mean_q: 0.006934
 38669/100000: episode: 4129, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000031, mae: 0.004580, mean_q: 0.006474
 38679/100000: episode: 4130, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.002259, mean_q: 0.003457
 38689/100000: episode: 4131, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001563, mae: 0.006037, mean_q: 0.004637
 38699/100000: episode: 4132, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000030, mae: 0.005941, mean_q: 0.008500
 38709/100000: episode: 4133, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000313, mae: 0.006413, mean_q: 0.005843
 38719/100000: episode: 4134, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000019, mae: 0.003815, mean_q: 0.005906
 38729/100000: episode: 4135, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000031, mae: 0.003603, mean_q: 0.004598
 38739/100000: episode: 4136, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001603, mae: 0.008171, mean_q: 0.006362
 38749/100000: episode: 4137, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000028, mae: 0.005572, mean_q: 0.008425
 38759/100000: episode: 4138, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000013, mae: 0.002480, mean_q: 0.003760
 38769/100000: episode: 4139, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.003742, mean_q: 0.004168
 38779/100000: episode: 4140, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.004498, mean_q: 0.006462
 38789/100000: episode: 4141, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000264, mae: 0.004801, mean_q: 0.004680
[Info] 1-TH LEVEL FOUND: 0.00538172572851181, Considering 100/100 traces
 38799/100000: episode: 4142, duration: 0.701s, episode steps: 10, steps per second: 14, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.003408, mean_q: 0.005799
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.00538172572851181
 38809/100000: episode: 4143, duration: 0.493s, episode steps: 10, steps per second: 20, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000044, mae: 0.003599, mean_q: 0.005016
 38819/100000: episode: 4144, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000011, mae: 0.002859, mean_q: 0.004967
 38829/100000: episode: 4145, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000050, mae: 0.003902, mean_q: 0.005182
 38839/100000: episode: 4146, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000017, mae: 0.003179, mean_q: 0.005011
 38849/100000: episode: 4147, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000019, mae: 0.002615, mean_q: 0.004034
 38859/100000: episode: 4148, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000030, mae: 0.004221, mean_q: 0.005288
 38869/100000: episode: 4149, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001572, mae: 0.008627, mean_q: 0.007965
 38879/100000: episode: 4150, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000046, mae: 0.004205, mean_q: 0.006241
 38889/100000: episode: 4151, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000048, mae: 0.002967, mean_q: 0.003338
 38899/100000: episode: 4152, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.003943, mean_q: 0.005266
 38909/100000: episode: 4153, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000024, mae: 0.003554, mean_q: 0.005459
 38919/100000: episode: 4154, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000028, mae: 0.003193, mean_q: 0.004296
 38929/100000: episode: 4155, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000057, mae: 0.004413, mean_q: 0.005071
 38939/100000: episode: 4156, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000017, mae: 0.003925, mean_q: 0.005894
 38949/100000: episode: 4157, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001589, mae: 0.006470, mean_q: 0.005008
 38959/100000: episode: 4158, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000260, mae: 0.006756, mean_q: 0.007710
 38969/100000: episode: 4159, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000016, mae: 0.003685, mean_q: 0.005933
 38979/100000: episode: 4160, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000028, mae: 0.003312, mean_q: 0.004317
 38989/100000: episode: 4161, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000011, mae: 0.002799, mean_q: 0.004920
 38999/100000: episode: 4162, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000053, mae: 0.003747, mean_q: 0.004742
 39009/100000: episode: 4163, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000045, mae: 0.003267, mean_q: 0.004818
 39019/100000: episode: 4164, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000041, mae: 0.003298, mean_q: 0.004919
 39029/100000: episode: 4165, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000017, mae: 0.004748, mean_q: 0.007582
 39039/100000: episode: 4166, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.003506, mean_q: 0.005585
 39049/100000: episode: 4167, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.002709, mean_q: 0.003531
 39059/100000: episode: 4168, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000078, mae: 0.004493, mean_q: 0.005246
 39069/100000: episode: 4169, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000024, mae: 0.004331, mean_q: 0.006399
 39079/100000: episode: 4170, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000024, mae: 0.003434, mean_q: 0.004778
 39089/100000: episode: 4171, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000056, mae: 0.003589, mean_q: 0.004412
 39099/100000: episode: 4172, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003545, mean_q: 0.004983
 39109/100000: episode: 4173, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000010, mae: 0.002625, mean_q: 0.004778
 39119/100000: episode: 4174, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003699, mean_q: 0.005228
 39129/100000: episode: 4175, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000227, mae: 0.004904, mean_q: 0.005802
 39139/100000: episode: 4176, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000047, mae: 0.004002, mean_q: 0.005351
 39149/100000: episode: 4177, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000074, mae: 0.004314, mean_q: 0.005215
 39159/100000: episode: 4178, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000017, mae: 0.002977, mean_q: 0.004724
 39169/100000: episode: 4179, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000030, mae: 0.003211, mean_q: 0.004131
 39179/100000: episode: 4180, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001562, mae: 0.006605, mean_q: 0.005683
 39189/100000: episode: 4181, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000045, mae: 0.005040, mean_q: 0.007393
 39199/100000: episode: 4182, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.002755, mean_q: 0.003950
 39209/100000: episode: 4183, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000055, mae: 0.003676, mean_q: 0.004293
 39219/100000: episode: 4184, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000059, mae: 0.004805, mean_q: 0.006025
 39229/100000: episode: 4185, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000012, mae: 0.003072, mean_q: 0.005237
 39239/100000: episode: 4186, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.002355, mean_q: 0.003911
 39249/100000: episode: 4187, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000034, mae: 0.003663, mean_q: 0.004512
 39259/100000: episode: 4188, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000028, mae: 0.003848, mean_q: 0.005353
 39269/100000: episode: 4189, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.003236, mean_q: 0.004428
 39279/100000: episode: 4190, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000028, mae: 0.003587, mean_q: 0.004704
 39289/100000: episode: 4191, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000280, mae: 0.005885, mean_q: 0.005922
 39299/100000: episode: 4192, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000047, mae: 0.004562, mean_q: 0.006256
 39309/100000: episode: 4193, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000057, mae: 0.004006, mean_q: 0.004997
 39319/100000: episode: 4194, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000023, mae: 0.003177, mean_q: 0.004552
 39329/100000: episode: 4195, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000084, mae: 0.004665, mean_q: 0.005219
 39339/100000: episode: 4196, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.004239, mean_q: 0.005796
 39349/100000: episode: 4197, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000045, mae: 0.003116, mean_q: 0.004495
 39359/100000: episode: 4198, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000051, mae: 0.003940, mean_q: 0.005222
 39369/100000: episode: 4199, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000027, mae: 0.003774, mean_q: 0.005105
 39379/100000: episode: 4200, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000053, mae: 0.003687, mean_q: 0.004764
 39389/100000: episode: 4201, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000281, mae: 0.007354, mean_q: 0.006974
 39399/100000: episode: 4202, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001564, mae: 0.007709, mean_q: 0.007051
 39409/100000: episode: 4203, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000048, mae: 0.005107, mean_q: 0.007326
 39419/100000: episode: 4204, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000025, mae: 0.003088, mean_q: 0.004617
 39429/100000: episode: 4205, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.002529, mean_q: 0.004172
 39439/100000: episode: 4206, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000238, mae: 0.004772, mean_q: 0.004923
 39449/100000: episode: 4207, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000043, mae: 0.004327, mean_q: 0.006543
 39459/100000: episode: 4208, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003201, mean_q: 0.004687
 39469/100000: episode: 4209, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002527, mean_q: 0.004294
 39479/100000: episode: 4210, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000025, mae: 0.003413, mean_q: 0.004877
 39489/100000: episode: 4211, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002813, mean_q: 0.004653
 39499/100000: episode: 4212, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003031, mean_q: 0.004278
 39509/100000: episode: 4213, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000017, mae: 0.002715, mean_q: 0.004283
 39519/100000: episode: 4214, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.002899, mean_q: 0.004237
 39529/100000: episode: 4215, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000030, mae: 0.003783, mean_q: 0.004773
 39539/100000: episode: 4216, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000035, mae: 0.004099, mean_q: 0.004962
 39549/100000: episode: 4217, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000015, mae: 0.003653, mean_q: 0.005504
 39559/100000: episode: 4218, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000025, mae: 0.003088, mean_q: 0.004438
 39569/100000: episode: 4219, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003224, mean_q: 0.004684
 39579/100000: episode: 4220, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000026, mae: 0.003595, mean_q: 0.005024
 39589/100000: episode: 4221, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001561, mae: 0.006030, mean_q: 0.004811
 39599/100000: episode: 4222, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001769, mae: 0.009740, mean_q: 0.008265
 39609/100000: episode: 4223, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000025, mae: 0.005872, mean_q: 0.008830
 39619/100000: episode: 4224, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000233, mae: 0.003994, mean_q: 0.003416
 39629/100000: episode: 4225, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000020, mae: 0.003536, mean_q: 0.005478
 39639/100000: episode: 4226, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000020, mae: 0.003189, mean_q: 0.005321
 39649/100000: episode: 4227, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001571, mae: 0.005636, mean_q: 0.003892
 39659/100000: episode: 4228, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000016, mae: 0.004682, mean_q: 0.007412
 39669/100000: episode: 4229, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003386, mean_q: 0.005103
 39679/100000: episode: 4230, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000020, mae: 0.002472, mean_q: 0.003267
 39689/100000: episode: 4231, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000027, mae: 0.004033, mean_q: 0.005048
 39699/100000: episode: 4232, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000030, mae: 0.004160, mean_q: 0.005709
 39709/100000: episode: 4233, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000033, mae: 0.004095, mean_q: 0.005358
 39719/100000: episode: 4234, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000026, mae: 0.003277, mean_q: 0.004802
 39729/100000: episode: 4235, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000096, mae: 0.004060, mean_q: 0.004679
 39739/100000: episode: 4236, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003811, mean_q: 0.005518
 39749/100000: episode: 4237, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001558, mae: 0.005579, mean_q: 0.004451
 39759/100000: episode: 4238, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000065, mae: 0.006032, mean_q: 0.007593
 39769/100000: episode: 4239, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.003313, mean_q: 0.005352
 39779/100000: episode: 4240, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000029, mae: 0.002940, mean_q: 0.004065
 39789/100000: episode: 4241, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.004162, mean_q: 0.005244
 39799/100000: episode: 4242, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000038, mae: 0.004509, mean_q: 0.005653
[Info] 1-TH LEVEL FOUND: 0.0051387641578912735, Considering 100/100 traces
 39809/100000: episode: 4243, duration: 0.728s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000050, mae: 0.004060, mean_q: 0.005418
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0051387641578912735
 39819/100000: episode: 4244, duration: 0.597s, episode steps: 10, steps per second: 17, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003610, mean_q: 0.005015
 39829/100000: episode: 4245, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000055, mae: 0.004099, mean_q: 0.004882
 39839/100000: episode: 4246, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000024, mae: 0.004067, mean_q: 0.005671
 39849/100000: episode: 4247, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003831, mean_q: 0.005781
 39859/100000: episode: 4248, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000017, mae: 0.003025, mean_q: 0.004589
 39869/100000: episode: 4249, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000236, mae: 0.004969, mean_q: 0.004773
 39879/100000: episode: 4250, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000039, mae: 0.004757, mean_q: 0.006955
 39889/100000: episode: 4251, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000046, mae: 0.003268, mean_q: 0.004218
 39899/100000: episode: 4252, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002856, mean_q: 0.004301
 39909/100000: episode: 4253, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.003409, mean_q: 0.004918
 39919/100000: episode: 4254, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000018, mae: 0.003145, mean_q: 0.005049
 39929/100000: episode: 4255, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000013, mae: 0.002581, mean_q: 0.004413
 39939/100000: episode: 4256, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000023, mae: 0.002952, mean_q: 0.003975
 39949/100000: episode: 4257, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000239, mae: 0.005119, mean_q: 0.005352
 39959/100000: episode: 4258, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.004525, mean_q: 0.006402
 39969/100000: episode: 4259, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000010, mae: 0.002429, mean_q: 0.004127
 39979/100000: episode: 4260, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000010, mae: 0.001906, mean_q: 0.003604
 39989/100000: episode: 4261, duration: 0.074s, episode steps: 10, steps per second: 134, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.002905, mean_q: 0.004203
 39999/100000: episode: 4262, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000254, mae: 0.004306, mean_q: 0.004376
 40009/100000: episode: 4263, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000024, mae: 0.004104, mean_q: 0.005692
 40019/100000: episode: 4264, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000023, mae: 0.003466, mean_q: 0.004915
 40029/100000: episode: 4265, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.002970, mean_q: 0.004211
 40039/100000: episode: 4266, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000052, mae: 0.003750, mean_q: 0.004816
 40049/100000: episode: 4267, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003397, mean_q: 0.004989
 40059/100000: episode: 4268, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000008, mae: 0.002402, mean_q: 0.003945
 40069/100000: episode: 4269, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003025, mean_q: 0.003943
 40079/100000: episode: 4270, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000219, mae: 0.003761, mean_q: 0.004517
 40089/100000: episode: 4271, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000040, mae: 0.003792, mean_q: 0.005283
 40099/100000: episode: 4272, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000077, mae: 0.004439, mean_q: 0.005053
 40109/100000: episode: 4273, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.003267, mean_q: 0.005168
 40119/100000: episode: 4274, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000248, mae: 0.004021, mean_q: 0.004177
 40129/100000: episode: 4275, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000256, mae: 0.005996, mean_q: 0.006397
 40139/100000: episode: 4276, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000039, mae: 0.003489, mean_q: 0.005151
 40149/100000: episode: 4277, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.002915, mean_q: 0.003821
 40159/100000: episode: 4278, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000015, mae: 0.002706, mean_q: 0.004510
 40169/100000: episode: 4279, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000219, mae: 0.003658, mean_q: 0.003999
 40179/100000: episode: 4280, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000038, mae: 0.003457, mean_q: 0.005004
 40189/100000: episode: 4281, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000039, mae: 0.003223, mean_q: 0.004541
 40199/100000: episode: 4282, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000030, mae: 0.003475, mean_q: 0.004207
 40209/100000: episode: 4283, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000012, mae: 0.003230, mean_q: 0.005110
 40219/100000: episode: 4284, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000080, mae: 0.003897, mean_q: 0.004210
 40229/100000: episode: 4285, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000036, mae: 0.003482, mean_q: 0.005146
 40239/100000: episode: 4286, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000018, mae: 0.002949, mean_q: 0.004310
 40249/100000: episode: 4287, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000047, mae: 0.003586, mean_q: 0.004765
 40259/100000: episode: 4288, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000015, mae: 0.003120, mean_q: 0.004756
 40269/100000: episode: 4289, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000009, mae: 0.002211, mean_q: 0.003832
 40279/100000: episode: 4290, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003142, mean_q: 0.004205
 40289/100000: episode: 4291, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.003655, mean_q: 0.005187
 40299/100000: episode: 4292, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002778, mean_q: 0.004058
 40309/100000: episode: 4293, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002484, mean_q: 0.003891
 40319/100000: episode: 4294, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000054, mae: 0.004022, mean_q: 0.004786
 40329/100000: episode: 4295, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000052, mae: 0.004084, mean_q: 0.005237
 40339/100000: episode: 4296, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000094, mae: 0.004296, mean_q: 0.005055
 40349/100000: episode: 4297, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000030, mae: 0.004120, mean_q: 0.005295
 40359/100000: episode: 4298, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000042, mae: 0.003268, mean_q: 0.004576
 40369/100000: episode: 4299, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000012, mae: 0.002440, mean_q: 0.003780
 40379/100000: episode: 4300, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001595, mae: 0.007033, mean_q: 0.004970
 40389/100000: episode: 4301, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000033, mae: 0.006088, mean_q: 0.008148
 40399/100000: episode: 4302, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.003610, mean_q: 0.004530
 40409/100000: episode: 4303, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000032, mae: 0.003468, mean_q: 0.004359
 40419/100000: episode: 4304, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000038, mae: 0.003042, mean_q: 0.004604
 40429/100000: episode: 4305, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000027, mae: 0.003314, mean_q: 0.004282
 40439/100000: episode: 4306, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.003480, mean_q: 0.004870
 40449/100000: episode: 4307, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001567, mae: 0.005996, mean_q: 0.004455
 40459/100000: episode: 4308, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000015, mae: 0.004879, mean_q: 0.007555
 40469/100000: episode: 4309, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000045, mae: 0.003401, mean_q: 0.004744
 40479/100000: episode: 4310, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000249, mae: 0.003848, mean_q: 0.003655
 40489/100000: episode: 4311, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003860, mean_q: 0.005922
 40499/100000: episode: 4312, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000034, mae: 0.004209, mean_q: 0.005206
 40509/100000: episode: 4313, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000223, mae: 0.004232, mean_q: 0.004741
 40519/100000: episode: 4314, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000029, mae: 0.004726, mean_q: 0.006358
 40529/100000: episode: 4315, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000057, mae: 0.004379, mean_q: 0.005485
 40539/100000: episode: 4316, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.002499, mean_q: 0.004233
 40549/100000: episode: 4317, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.002485, mean_q: 0.004075
 40559/100000: episode: 4318, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000228, mae: 0.004793, mean_q: 0.005558
 40569/100000: episode: 4319, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003225, mean_q: 0.004700
 40579/100000: episode: 4320, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.003016, mean_q: 0.004004
 40589/100000: episode: 4321, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003176, mean_q: 0.004752
 40599/100000: episode: 4322, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.003068, mean_q: 0.004844
 40609/100000: episode: 4323, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002860, mean_q: 0.004280
 40619/100000: episode: 4324, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.002992, mean_q: 0.004282
 40629/100000: episode: 4325, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000015, mae: 0.002891, mean_q: 0.004459
 40639/100000: episode: 4326, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003056, mean_q: 0.004313
 40649/100000: episode: 4327, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000009, mae: 0.002309, mean_q: 0.004062
 40659/100000: episode: 4328, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000021, mae: 0.002875, mean_q: 0.003815
 40669/100000: episode: 4329, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000017, mae: 0.003641, mean_q: 0.005072
 40679/100000: episode: 4330, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000015, mae: 0.002900, mean_q: 0.004503
 40689/100000: episode: 4331, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001564, mae: 0.006011, mean_q: 0.004408
 40699/100000: episode: 4332, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000056, mae: 0.006335, mean_q: 0.008037
 40709/100000: episode: 4333, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000008, mae: 0.002381, mean_q: 0.004024
 40719/100000: episode: 4334, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000041, mae: 0.003509, mean_q: 0.003613
 40729/100000: episode: 4335, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000018, mae: 0.004136, mean_q: 0.005963
 40739/100000: episode: 4336, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000073, mae: 0.003691, mean_q: 0.004013
 40749/100000: episode: 4337, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000017, mae: 0.003359, mean_q: 0.004890
 40759/100000: episode: 4338, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.003295, mean_q: 0.004661
 40769/100000: episode: 4339, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.003339, mean_q: 0.004528
 40779/100000: episode: 4340, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000042, mae: 0.003253, mean_q: 0.004547
 40789/100000: episode: 4341, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000019, mae: 0.003367, mean_q: 0.004986
 40799/100000: episode: 4342, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000012, mae: 0.002541, mean_q: 0.003832
 40809/100000: episode: 4343, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001626, mae: 0.007889, mean_q: 0.005286
[Info] 1-TH LEVEL FOUND: 0.005744542460888624, Considering 100/100 traces
 40819/100000: episode: 4344, duration: 0.930s, episode steps: 10, steps per second: 11, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000025, mae: 0.005899, mean_q: 0.008495
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005744542460888624
 40829/100000: episode: 4345, duration: 0.649s, episode steps: 10, steps per second: 15, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000024, mae: 0.003133, mean_q: 0.004086
 40839/100000: episode: 4346, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001576, mae: 0.007792, mean_q: 0.006434
 40849/100000: episode: 4347, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001571, mae: 0.007891, mean_q: 0.007051
 40859/100000: episode: 4348, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001573, mae: 0.008829, mean_q: 0.008426
 40869/100000: episode: 4349, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.004826, mean_q: 0.007193
 40879/100000: episode: 4350, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000045, mae: 0.002699, mean_q: 0.003310
 40889/100000: episode: 4351, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000017, mae: 0.003010, mean_q: 0.004663
 40899/100000: episode: 4352, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.003645, mean_q: 0.005110
 40909/100000: episode: 4353, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000054, mae: 0.004030, mean_q: 0.005069
 40919/100000: episode: 4354, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003103, mean_q: 0.005081
 40929/100000: episode: 4355, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000027, mae: 0.003106, mean_q: 0.004193
 40939/100000: episode: 4356, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000031, mae: 0.003496, mean_q: 0.004808
 40949/100000: episode: 4357, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000023, mae: 0.003363, mean_q: 0.004725
 40959/100000: episode: 4358, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000026, mae: 0.003391, mean_q: 0.004711
 40969/100000: episode: 4359, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000020, mae: 0.003300, mean_q: 0.004760
 40979/100000: episode: 4360, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000231, mae: 0.004620, mean_q: 0.005118
 40989/100000: episode: 4361, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000042, mae: 0.003660, mean_q: 0.005309
 40999/100000: episode: 4362, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003181, mean_q: 0.004465
 41009/100000: episode: 4363, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002603, mean_q: 0.004231
 41019/100000: episode: 4364, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000290, mae: 0.006308, mean_q: 0.006101
 41029/100000: episode: 4365, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000054, mae: 0.004601, mean_q: 0.005980
 41039/100000: episode: 4366, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002689, mean_q: 0.003962
 41049/100000: episode: 4367, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000015, mae: 0.002556, mean_q: 0.003962
 41059/100000: episode: 4368, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000007, mae: 0.002529, mean_q: 0.004285
 41069/100000: episode: 4369, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000009, mae: 0.002219, mean_q: 0.003529
 41079/100000: episode: 4370, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000088, mae: 0.004057, mean_q: 0.004230
 41089/100000: episode: 4371, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000064, mae: 0.005221, mean_q: 0.005949
 41099/100000: episode: 4372, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000232, mae: 0.005147, mean_q: 0.005528
 41109/100000: episode: 4373, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000041, mae: 0.003801, mean_q: 0.005262
 41119/100000: episode: 4374, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000033, mae: 0.003762, mean_q: 0.004736
 41129/100000: episode: 4375, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003365, mean_q: 0.005083
 41139/100000: episode: 4376, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000014, mae: 0.002716, mean_q: 0.004443
 41149/100000: episode: 4377, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.003209, mean_q: 0.004389
 41159/100000: episode: 4378, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000014, mae: 0.002876, mean_q: 0.004740
 41169/100000: episode: 4379, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000061, mae: 0.004098, mean_q: 0.004400
 41179/100000: episode: 4380, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000014, mae: 0.003202, mean_q: 0.005160
 41189/100000: episode: 4381, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000055, mae: 0.003786, mean_q: 0.004238
 41199/100000: episode: 4382, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000038, mae: 0.002925, mean_q: 0.004497
 41209/100000: episode: 4383, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001836, mae: 0.010233, mean_q: 0.006867
 41219/100000: episode: 4384, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000042, mae: 0.007233, mean_q: 0.009519
 41229/100000: episode: 4385, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000075, mae: 0.003258, mean_q: 0.003530
 41239/100000: episode: 4386, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000018, mae: 0.003137, mean_q: 0.004437
 41249/100000: episode: 4387, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000050, mae: 0.004331, mean_q: 0.005673
 41259/100000: episode: 4388, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000040, mae: 0.003206, mean_q: 0.004660
 41269/100000: episode: 4389, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003056, mean_q: 0.004749
 41279/100000: episode: 4390, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.002447, mean_q: 0.004037
 41289/100000: episode: 4391, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003104, mean_q: 0.004223
 41299/100000: episode: 4392, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003435, mean_q: 0.005024
 41309/100000: episode: 4393, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000057, mae: 0.004078, mean_q: 0.004992
 41319/100000: episode: 4394, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000019, mae: 0.003516, mean_q: 0.005327
 41329/100000: episode: 4395, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000253, mae: 0.004629, mean_q: 0.004750
 41339/100000: episode: 4396, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000044, mae: 0.003904, mean_q: 0.005286
 41349/100000: episode: 4397, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.003104, mean_q: 0.004549
 41359/100000: episode: 4398, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000077, mae: 0.003984, mean_q: 0.004647
 41369/100000: episode: 4399, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000101, mae: 0.005440, mean_q: 0.006449
 41379/100000: episode: 4400, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000057, mae: 0.004414, mean_q: 0.005588
 41389/100000: episode: 4401, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001567, mae: 0.007886, mean_q: 0.007239
 41399/100000: episode: 4402, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000015, mae: 0.003300, mean_q: 0.005430
 41409/100000: episode: 4403, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000018, mae: 0.002509, mean_q: 0.003260
 41419/100000: episode: 4404, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003274, mean_q: 0.004690
 41429/100000: episode: 4405, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000041, mae: 0.003568, mean_q: 0.005338
 41439/100000: episode: 4406, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000015, mae: 0.002560, mean_q: 0.004207
 41449/100000: episode: 4407, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.002389, mean_q: 0.003623
 41459/100000: episode: 4408, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000017, mae: 0.002852, mean_q: 0.004292
 41469/100000: episode: 4409, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000016, mae: 0.003083, mean_q: 0.004399
 41479/100000: episode: 4410, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000012, mae: 0.002528, mean_q: 0.004022
 41489/100000: episode: 4411, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000018, mae: 0.002856, mean_q: 0.004444
 41499/100000: episode: 4412, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002720, mean_q: 0.004282
 41509/100000: episode: 4413, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003097, mean_q: 0.003903
 41519/100000: episode: 4414, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001770, mae: 0.007316, mean_q: 0.004909
 41529/100000: episode: 4415, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000033, mae: 0.006209, mean_q: 0.008639
 41539/100000: episode: 4416, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000022, mae: 0.003178, mean_q: 0.004426
 41549/100000: episode: 4417, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.002535, mean_q: 0.003356
 41559/100000: episode: 4418, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000076, mae: 0.004345, mean_q: 0.005230
 41569/100000: episode: 4419, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000012, mae: 0.002606, mean_q: 0.004631
 41579/100000: episode: 4420, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000046, mae: 0.003235, mean_q: 0.003693
 41589/100000: episode: 4421, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.003007, mean_q: 0.005028
 41599/100000: episode: 4422, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000248, mae: 0.004542, mean_q: 0.004982
 41609/100000: episode: 4423, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000077, mae: 0.004552, mean_q: 0.005475
 41619/100000: episode: 4424, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002890, mean_q: 0.004392
 41629/100000: episode: 4425, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000248, mae: 0.004259, mean_q: 0.004719
 41639/100000: episode: 4426, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001598, mae: 0.009147, mean_q: 0.008118
 41649/100000: episode: 4427, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000026, mae: 0.004373, mean_q: 0.006277
 41659/100000: episode: 4428, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000021, mae: 0.002411, mean_q: 0.003508
 41669/100000: episode: 4429, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002844, mean_q: 0.004571
 41679/100000: episode: 4430, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000011, mae: 0.002469, mean_q: 0.004419
 41689/100000: episode: 4431, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003266, mean_q: 0.004247
 41699/100000: episode: 4432, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002825, mean_q: 0.004734
 41709/100000: episode: 4433, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000037, mae: 0.002594, mean_q: 0.004065
 41719/100000: episode: 4434, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000017, mae: 0.003026, mean_q: 0.004223
 41729/100000: episode: 4435, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000046, mae: 0.003804, mean_q: 0.005153
 41739/100000: episode: 4436, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.001558, mae: 0.005588, mean_q: 0.004465
 41749/100000: episode: 4437, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.004485, mean_q: 0.006582
 41759/100000: episode: 4438, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003053, mean_q: 0.004367
 41769/100000: episode: 4439, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000008, mae: 0.002034, mean_q: 0.003589
 41779/100000: episode: 4440, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000047, mae: 0.003365, mean_q: 0.004151
 41789/100000: episode: 4441, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000045, mae: 0.003816, mean_q: 0.005368
 41799/100000: episode: 4442, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000010, mae: 0.002440, mean_q: 0.004283
 41809/100000: episode: 4443, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000038, mae: 0.002732, mean_q: 0.003410
 41819/100000: episode: 4444, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000011, mae: 0.002715, mean_q: 0.004432
[Info] 1-TH LEVEL FOUND: 0.003208486596122384, Considering 100/100 traces
 41829/100000: episode: 4445, duration: 0.750s, episode steps: 10, steps per second: 13, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000009, mae: 0.002175, mean_q: 0.003749
[Info] 2-TH LEVEL FOUND: 0.004634508863091469, Considering 100/100 traces
 41839/100000: episode: 4446, duration: 0.729s, episode steps: 10, steps per second: 14, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000022, mae: 0.002887, mean_q: 0.003730
[Info] 3-TH LEVEL FOUND: 0.0047807954251766205, Considering 100/100 traces
 41849/100000: episode: 4447, duration: 0.808s, episode steps: 10, steps per second: 12, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000023, mae: 0.003472, mean_q: 0.004732
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0047807954251766205
 41859/100000: episode: 4448, duration: 0.713s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000043, mae: 0.003497, mean_q: 0.004524
 41869/100000: episode: 4449, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000226, mae: 0.004002, mean_q: 0.004232
 41879/100000: episode: 4450, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000030, mae: 0.004429, mean_q: 0.005906
 41889/100000: episode: 4451, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001801, mae: 0.009708, mean_q: 0.007198
 41899/100000: episode: 4452, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.004897, mean_q: 0.007281
 41909/100000: episode: 4453, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001605, mae: 0.006272, mean_q: 0.003003
 41919/100000: episode: 4454, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000025, mae: 0.005295, mean_q: 0.007779
 41929/100000: episode: 4455, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003640, mean_q: 0.005496
 41939/100000: episode: 4456, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001600, mae: 0.006914, mean_q: 0.004834
 41949/100000: episode: 4457, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000026, mae: 0.005137, mean_q: 0.007275
 41959/100000: episode: 4458, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000018, mae: 0.002577, mean_q: 0.004004
 41969/100000: episode: 4459, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000044, mae: 0.003191, mean_q: 0.004383
 41979/100000: episode: 4460, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000072, mae: 0.004445, mean_q: 0.005494
 41989/100000: episode: 4461, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000051, mae: 0.004157, mean_q: 0.005737
 41999/100000: episode: 4462, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.003442, mean_q: 0.004595
 42009/100000: episode: 4463, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000021, mae: 0.002874, mean_q: 0.004501
 42019/100000: episode: 4464, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000032, mae: 0.003600, mean_q: 0.004653
 42029/100000: episode: 4465, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000011, mae: 0.002609, mean_q: 0.004513
 42039/100000: episode: 4466, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003348, mean_q: 0.004519
 42049/100000: episode: 4467, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002894, mean_q: 0.004710
 42059/100000: episode: 4468, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002481, mean_q: 0.004060
 42069/100000: episode: 4469, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003004, mean_q: 0.004107
 42079/100000: episode: 4470, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000010, mae: 0.002867, mean_q: 0.004913
 42089/100000: episode: 4471, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002874, mean_q: 0.004375
 42099/100000: episode: 4472, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000017, mae: 0.002433, mean_q: 0.003744
 42109/100000: episode: 4473, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000012, mae: 0.002273, mean_q: 0.004033
 42119/100000: episode: 4474, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000025, mae: 0.002989, mean_q: 0.003972
 42129/100000: episode: 4475, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000030, mae: 0.003580, mean_q: 0.004524
 42139/100000: episode: 4476, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000047, mae: 0.003658, mean_q: 0.004880
 42149/100000: episode: 4477, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000022, mae: 0.003600, mean_q: 0.004714
 42159/100000: episode: 4478, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000048, mae: 0.003665, mean_q: 0.004464
 42169/100000: episode: 4479, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000025, mae: 0.003428, mean_q: 0.004725
 42179/100000: episode: 4480, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.003354, mean_q: 0.004472
 42189/100000: episode: 4481, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002929, mean_q: 0.004388
 42199/100000: episode: 4482, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000045, mae: 0.002900, mean_q: 0.003767
 42209/100000: episode: 4483, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000049, mae: 0.003832, mean_q: 0.004865
 42219/100000: episode: 4484, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000018, mae: 0.003207, mean_q: 0.004806
 42229/100000: episode: 4485, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000070, mae: 0.003403, mean_q: 0.003876
 42239/100000: episode: 4486, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000042, mae: 0.003503, mean_q: 0.004763
 42249/100000: episode: 4487, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000031, mae: 0.003528, mean_q: 0.004401
 42259/100000: episode: 4488, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000029, mae: 0.003438, mean_q: 0.004434
 42269/100000: episode: 4489, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000022, mae: 0.003369, mean_q: 0.004662
 42279/100000: episode: 4490, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000051, mae: 0.003425, mean_q: 0.004299
 42289/100000: episode: 4491, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000028, mae: 0.003383, mean_q: 0.004470
 42299/100000: episode: 4492, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000015, mae: 0.002849, mean_q: 0.004352
 42309/100000: episode: 4493, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000049, mae: 0.003298, mean_q: 0.004077
 42319/100000: episode: 4494, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000018, mae: 0.003109, mean_q: 0.004682
 42329/100000: episode: 4495, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000036, mae: 0.002759, mean_q: 0.004045
 42339/100000: episode: 4496, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.002916, mean_q: 0.003836
 42349/100000: episode: 4497, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002804, mean_q: 0.004334
 42359/100000: episode: 4498, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000043, mae: 0.003526, mean_q: 0.004627
 42369/100000: episode: 4499, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000022, mae: 0.003109, mean_q: 0.004297
 42379/100000: episode: 4500, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000013, mae: 0.002462, mean_q: 0.003741
 42389/100000: episode: 4501, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000046, mae: 0.003237, mean_q: 0.003908
 42399/100000: episode: 4502, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000010, mae: 0.002533, mean_q: 0.004348
 42409/100000: episode: 4503, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000041, mae: 0.002982, mean_q: 0.004081
 42419/100000: episode: 4504, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000011, mae: 0.002428, mean_q: 0.003922
 42429/100000: episode: 4505, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000082, mae: 0.004027, mean_q: 0.004017
 42439/100000: episode: 4506, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000009, mae: 0.003306, mean_q: 0.005230
 42449/100000: episode: 4507, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003075, mean_q: 0.003898
 42459/100000: episode: 4508, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000042, mae: 0.003324, mean_q: 0.004516
 42469/100000: episode: 4509, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003229, mean_q: 0.004430
 42479/100000: episode: 4510, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003263, mean_q: 0.004390
 42489/100000: episode: 4511, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000026, mae: 0.003373, mean_q: 0.004134
 42499/100000: episode: 4512, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000042, mae: 0.003095, mean_q: 0.004283
 42509/100000: episode: 4513, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003372, mean_q: 0.004467
 42519/100000: episode: 4514, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000018, mae: 0.003291, mean_q: 0.004740
 42529/100000: episode: 4515, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000073, mae: 0.003580, mean_q: 0.004019
 42539/100000: episode: 4516, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000020, mae: 0.003032, mean_q: 0.004422
 42549/100000: episode: 4517, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000014, mae: 0.002732, mean_q: 0.004068
 42559/100000: episode: 4518, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000042, mae: 0.003004, mean_q: 0.003743
 42569/100000: episode: 4519, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000115, mae: 0.005513, mean_q: 0.005352
 42579/100000: episode: 4520, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000078, mae: 0.005026, mean_q: 0.005675
 42589/100000: episode: 4521, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000015, mae: 0.002868, mean_q: 0.004410
 42599/100000: episode: 4522, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000023, mae: 0.002674, mean_q: 0.003500
 42609/100000: episode: 4523, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002558, mean_q: 0.003985
 42619/100000: episode: 4524, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000038, mae: 0.002907, mean_q: 0.004015
 42629/100000: episode: 4525, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.002700, mean_q: 0.003921
 42639/100000: episode: 4526, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000024, mae: 0.003459, mean_q: 0.004733
 42649/100000: episode: 4527, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000020, mae: 0.002870, mean_q: 0.004214
 42659/100000: episode: 4528, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000020, mae: 0.003252, mean_q: 0.004333
 42669/100000: episode: 4529, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000030, mae: 0.003648, mean_q: 0.004495
 42679/100000: episode: 4530, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.003043, mean_q: 0.004524
 42689/100000: episode: 4531, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000046, mae: 0.003501, mean_q: 0.004085
 42699/100000: episode: 4532, duration: 0.066s, episode steps: 10, steps per second: 150, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000068, mae: 0.003822, mean_q: 0.004676
 42709/100000: episode: 4533, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000014, mae: 0.003297, mean_q: 0.004982
 42719/100000: episode: 4534, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000084, mae: 0.003728, mean_q: 0.003593
 42729/100000: episode: 4535, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.003029, mean_q: 0.004760
 42739/100000: episode: 4536, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000073, mae: 0.003967, mean_q: 0.004820
 42749/100000: episode: 4537, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000013, mae: 0.002801, mean_q: 0.004326
[Info] FALSIFICATION!
 42759/100000: episode: 4538, duration: 0.328s, episode steps: 10, steps per second: 30, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000072, mae: 0.003388, mean_q: 0.003674
 42769/100000: episode: 4539, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000251, mae: 0.005304, mean_q: 0.005539
 42779/100000: episode: 4540, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001592, mae: 0.009114, mean_q: 0.008359
 42789/100000: episode: 4541, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000077, mae: 0.004829, mean_q: 0.005990
 42799/100000: episode: 4542, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002435, mean_q: 0.003534
 42809/100000: episode: 4543, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000041, mae: 0.003095, mean_q: 0.004400
 42819/100000: episode: 4544, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003182, mean_q: 0.004421
 42829/100000: episode: 4545, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000023, mae: 0.003135, mean_q: 0.004676
 42839/100000: episode: 4546, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000099, mae: 0.004481, mean_q: 0.005049
 42849/100000: episode: 4547, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000018, mae: 0.003132, mean_q: 0.004898
[Info] Complete ISplit Iteration
[Info] Levels: [0.004428279]
[Info] Cond. Prob: [1.0]
[Info] Error Prob: 1.0

 42859/100000: episode: 4548, duration: 1.034s, episode steps: 10, steps per second: 10, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000013, mae: 0.002721, mean_q: 0.003998
 42869/100000: episode: 4549, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003815, mean_q: 0.005053
 42879/100000: episode: 4550, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002712, mean_q: 0.004435
 42889/100000: episode: 4551, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000047, mae: 0.003233, mean_q: 0.003960
 42899/100000: episode: 4552, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000057, mae: 0.004589, mean_q: 0.005429
 42909/100000: episode: 4553, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001598, mae: 0.006820, mean_q: 0.004786
 42919/100000: episode: 4554, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000253, mae: 0.007210, mean_q: 0.008197
 42929/100000: episode: 4555, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000040, mae: 0.003550, mean_q: 0.005113
 42939/100000: episode: 4556, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000221, mae: 0.003301, mean_q: 0.003815
 42949/100000: episode: 4557, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000018, mae: 0.004316, mean_q: 0.006508
 42959/100000: episode: 4558, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002760, mean_q: 0.004602
 42969/100000: episode: 4559, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000043, mae: 0.002534, mean_q: 0.003280
 42979/100000: episode: 4560, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000040, mae: 0.003438, mean_q: 0.004758
 42989/100000: episode: 4561, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000023, mae: 0.003681, mean_q: 0.005227
 42999/100000: episode: 4562, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000075, mae: 0.004232, mean_q: 0.005141
 43009/100000: episode: 4563, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000020, mae: 0.002916, mean_q: 0.004444
 43019/100000: episode: 4564, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000282, mae: 0.005595, mean_q: 0.005347
 43029/100000: episode: 4565, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001613, mae: 0.008697, mean_q: 0.007475
 43039/100000: episode: 4566, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.003665, mean_q: 0.005817
 43049/100000: episode: 4567, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000012, mae: 0.002094, mean_q: 0.002743
 43059/100000: episode: 4568, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000009, mae: 0.002312, mean_q: 0.004127
 43069/100000: episode: 4569, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000022, mae: 0.002921, mean_q: 0.004172
 43079/100000: episode: 4570, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000036, mae: 0.003102, mean_q: 0.004782
 43089/100000: episode: 4571, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.003493, mean_q: 0.004547
 43099/100000: episode: 4572, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003785, mean_q: 0.005007
 43109/100000: episode: 4573, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000074, mae: 0.004188, mean_q: 0.005107
 43119/100000: episode: 4574, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000011, mae: 0.002801, mean_q: 0.004727
 43129/100000: episode: 4575, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000023, mae: 0.002884, mean_q: 0.003633
 43139/100000: episode: 4576, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000052, mae: 0.003863, mean_q: 0.004855
 43149/100000: episode: 4577, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000075, mae: 0.004270, mean_q: 0.005375
 43159/100000: episode: 4578, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000009, mae: 0.002277, mean_q: 0.004300
 43169/100000: episode: 4579, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000098, mae: 0.003426, mean_q: 0.003151
 43179/100000: episode: 4580, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001569, mae: 0.008580, mean_q: 0.007989
 43189/100000: episode: 4581, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000240, mae: 0.006808, mean_q: 0.007671
 43199/100000: episode: 4582, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000072, mae: 0.003450, mean_q: 0.003975
 43209/100000: episode: 4583, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.002922, mean_q: 0.004525
 43219/100000: episode: 4584, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002753, mean_q: 0.004436
 43229/100000: episode: 4585, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000133, mae: 0.005031, mean_q: 0.004986
 43239/100000: episode: 4586, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.003499, mean_q: 0.005464
 43249/100000: episode: 4587, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000098, mae: 0.003825, mean_q: 0.004173
 43259/100000: episode: 4588, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000020, mae: 0.003124, mean_q: 0.004832
 43269/100000: episode: 4589, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000018, mae: 0.002674, mean_q: 0.003819
 43279/100000: episode: 4590, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000028, mae: 0.003461, mean_q: 0.004697
 43289/100000: episode: 4591, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003562, mean_q: 0.004829
 43299/100000: episode: 4592, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000019, mae: 0.003247, mean_q: 0.004782
 43309/100000: episode: 4593, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000021, mae: 0.002999, mean_q: 0.004454
 43319/100000: episode: 4594, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000028, mae: 0.003259, mean_q: 0.004266
 43329/100000: episode: 4595, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000120, mae: 0.005304, mean_q: 0.005263
 43339/100000: episode: 4596, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000045, mae: 0.004730, mean_q: 0.006512
 43349/100000: episode: 4597, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000229, mae: 0.003811, mean_q: 0.004253
 43359/100000: episode: 4598, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002718, mean_q: 0.004274
 43369/100000: episode: 4599, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000237, mae: 0.004422, mean_q: 0.004319
 43379/100000: episode: 4600, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000016, mae: 0.003893, mean_q: 0.005934
 43389/100000: episode: 4601, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002558, mean_q: 0.004130
 43399/100000: episode: 4602, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000009, mae: 0.001967, mean_q: 0.003572
[Info] FALSIFICATION!
 43409/100000: episode: 4603, duration: 0.249s, episode steps: 10, steps per second: 40, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000039, mae: 0.002514, mean_q: 0.003706
 43419/100000: episode: 4604, duration: 0.066s, episode steps: 10, steps per second: 153, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001592, mae: 0.007227, mean_q: 0.005408
 43429/100000: episode: 4605, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001590, mae: 0.009760, mean_q: 0.009160
 43439/100000: episode: 4606, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001984, mae: 0.010419, mean_q: 0.007412
 43449/100000: episode: 4607, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000047, mae: 0.005562, mean_q: 0.007957
 43459/100000: episode: 4608, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000016, mae: 0.002487, mean_q: 0.003800
 43469/100000: episode: 4609, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001571, mae: 0.006841, mean_q: 0.005660
 43479/100000: episode: 4610, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000260, mae: 0.006694, mean_q: 0.007612
 43489/100000: episode: 4611, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000014, mae: 0.003935, mean_q: 0.006445
 43499/100000: episode: 4612, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000061, mae: 0.003967, mean_q: 0.004862
 43509/100000: episode: 4613, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001563, mae: 0.006888, mean_q: 0.006310
 43519/100000: episode: 4614, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000045, mae: 0.004791, mean_q: 0.007109
 43529/100000: episode: 4615, duration: 0.093s, episode steps: 10, steps per second: 107, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001570, mae: 0.007058, mean_q: 0.006190
 43539/100000: episode: 4616, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000042, mae: 0.004036, mean_q: 0.006208
 43549/100000: episode: 4617, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000013, mae: 0.002303, mean_q: 0.003972
 43559/100000: episode: 4618, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001571, mae: 0.007125, mean_q: 0.006419
 43569/100000: episode: 4619, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000076, mae: 0.004939, mean_q: 0.006909
 43579/100000: episode: 4620, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000068, mae: 0.004022, mean_q: 0.005632
 43589/100000: episode: 4621, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000027, mae: 0.003301, mean_q: 0.004894
 43599/100000: episode: 4622, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.001593, mae: 0.006489, mean_q: 0.004774
 43609/100000: episode: 4623, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000028, mae: 0.005571, mean_q: 0.008021
 43619/100000: episode: 4624, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.003393, mean_q: 0.005380
 43629/100000: episode: 4625, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000026, mae: 0.002861, mean_q: 0.004192
 43639/100000: episode: 4626, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.003166, mean_q: 0.005028
 43649/100000: episode: 4627, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000049, mae: 0.003507, mean_q: 0.005015
 43659/100000: episode: 4628, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001586, mae: 0.006802, mean_q: 0.005646
 43669/100000: episode: 4629, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000026, mae: 0.005592, mean_q: 0.007952
 43679/100000: episode: 4630, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002546, mean_q: 0.004722
 43689/100000: episode: 4631, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001590, mae: 0.005716, mean_q: 0.003616
 43699/100000: episode: 4632, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000025, mae: 0.005047, mean_q: 0.007538
 43709/100000: episode: 4633, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001589, mae: 0.006915, mean_q: 0.006052
 43719/100000: episode: 4634, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001608, mae: 0.009908, mean_q: 0.008914
 43729/100000: episode: 4635, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000028, mae: 0.005671, mean_q: 0.008846
 43739/100000: episode: 4636, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002337, mean_q: 0.003545
 43749/100000: episode: 4637, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001605, mae: 0.006749, mean_q: 0.004157
 43759/100000: episode: 4638, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.005526, mean_q: 0.008423
 43769/100000: episode: 4639, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003743, mean_q: 0.005950
 43779/100000: episode: 4640, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000027, mae: 0.003050, mean_q: 0.004192
 43789/100000: episode: 4641, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000018, mae: 0.002703, mean_q: 0.004457
 43799/100000: episode: 4642, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001564, mae: 0.005792, mean_q: 0.004852
 43809/100000: episode: 4643, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000045, mae: 0.005031, mean_q: 0.007421
 43819/100000: episode: 4644, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000027, mae: 0.004203, mean_q: 0.006178
 43829/100000: episode: 4645, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001780, mae: 0.007898, mean_q: 0.005743
 43839/100000: episode: 4646, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000020, mae: 0.004932, mean_q: 0.007851
 43849/100000: episode: 4647, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.003108, mae: 0.011911, mean_q: 0.008719
[Info] Complete ISplit Iteration
[Info] Levels: [0.0047408724]
[Info] Cond. Prob: [1.0]
[Info] Error Prob: 1.0

 43859/100000: episode: 4648, duration: 0.731s, episode steps: 10, steps per second: 14, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.004983, mean_q: 0.007962
 43869/100000: episode: 4649, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000076, mae: 0.003407, mean_q: 0.003903
 43879/100000: episode: 4650, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.003506, mean_q: 0.005237
 43889/100000: episode: 4651, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001590, mae: 0.006901, mean_q: 0.006009
 43899/100000: episode: 4652, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000030, mae: 0.005406, mean_q: 0.007891
 43909/100000: episode: 4653, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000252, mae: 0.005861, mean_q: 0.007177
 43919/100000: episode: 4654, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000058, mae: 0.004271, mean_q: 0.005569
 43929/100000: episode: 4655, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.003401, mean_q: 0.005338
 43939/100000: episode: 4656, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001555, mae: 0.006394, mean_q: 0.006072
 43949/100000: episode: 4657, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001600, mae: 0.009244, mean_q: 0.008301
 43959/100000: episode: 4658, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000072, mae: 0.005796, mean_q: 0.008137
 43969/100000: episode: 4659, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000064, mae: 0.004299, mean_q: 0.005452
 43979/100000: episode: 4660, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000071, mae: 0.003620, mean_q: 0.005119
 43989/100000: episode: 4661, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000049, mae: 0.004175, mean_q: 0.005939
 43999/100000: episode: 4662, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000039, mae: 0.003622, mean_q: 0.005896
 44009/100000: episode: 4663, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001625, mae: 0.006961, mean_q: 0.005126
 44019/100000: episode: 4664, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000024, mae: 0.005287, mean_q: 0.007908
 44029/100000: episode: 4665, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000013, mae: 0.003368, mean_q: 0.006004
 44039/100000: episode: 4666, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000031, mae: 0.002901, mean_q: 0.003903
 44049/100000: episode: 4667, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000023, mae: 0.003177, mean_q: 0.004845
 44059/100000: episode: 4668, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000025, mae: 0.003441, mean_q: 0.005365
 44069/100000: episode: 4669, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000026, mae: 0.003413, mean_q: 0.005051
 44079/100000: episode: 4670, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000076, mae: 0.004081, mean_q: 0.005131
 44089/100000: episode: 4671, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003296, mean_q: 0.005558
 44099/100000: episode: 4672, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000077, mae: 0.003898, mean_q: 0.004756
 44109/100000: episode: 4673, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000040, mae: 0.003459, mean_q: 0.005159
 44119/100000: episode: 4674, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000014, mae: 0.002664, mean_q: 0.004925
 44129/100000: episode: 4675, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000053, mae: 0.003552, mean_q: 0.004634
 44139/100000: episode: 4676, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001599, mae: 0.007296, mean_q: 0.005225
 44149/100000: episode: 4677, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.004633, mae: 0.016417, mean_q: 0.010098
 44159/100000: episode: 4678, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000097, mae: 0.010096, mean_q: 0.013140
 44169/100000: episode: 4679, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.003302, mean_q: 0.005863
 44179/100000: episode: 4680, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000020, mae: 0.002524, mean_q: 0.002999
 44189/100000: episode: 4681, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.002316, mean_q: 0.004483
 44199/100000: episode: 4682, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000043, mae: 0.003545, mean_q: 0.005280
 44209/100000: episode: 4683, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003620, mean_q: 0.005203
 44219/100000: episode: 4684, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000044, mae: 0.003646, mean_q: 0.005472
 44229/100000: episode: 4685, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000056, mae: 0.003952, mean_q: 0.005359
 44239/100000: episode: 4686, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000022, mae: 0.003355, mean_q: 0.005308
 44249/100000: episode: 4687, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001615, mae: 0.006502, mean_q: 0.004699
 44259/100000: episode: 4688, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.004872, mean_q: 0.007159
 44269/100000: episode: 4689, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000033, mae: 0.004418, mean_q: 0.006021
 44279/100000: episode: 4690, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000025, mae: 0.002970, mean_q: 0.004405
 44289/100000: episode: 4691, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001641, mae: 0.008708, mean_q: 0.006352
 44299/100000: episode: 4692, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000029, mae: 0.005833, mean_q: 0.008629
 44309/100000: episode: 4693, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.003516, mean_q: 0.005389
 44319/100000: episode: 4694, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000074, mae: 0.003643, mean_q: 0.004354
 44329/100000: episode: 4695, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003982, mean_q: 0.005749
 44339/100000: episode: 4696, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.004035, mean_q: 0.005740
 44349/100000: episode: 4697, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000073, mae: 0.003918, mean_q: 0.005426
 44359/100000: episode: 4698, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000032, mae: 0.003697, mean_q: 0.005249
 44369/100000: episode: 4699, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001592, mae: 0.006469, mean_q: 0.005120
 44379/100000: episode: 4700, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.005251, mean_q: 0.007427
 44389/100000: episode: 4701, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000259, mae: 0.006030, mean_q: 0.006801
 44399/100000: episode: 4702, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000027, mae: 0.003612, mean_q: 0.005534
 44409/100000: episode: 4703, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000048, mae: 0.003426, mean_q: 0.005066
 44419/100000: episode: 4704, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000021, mae: 0.003202, mean_q: 0.005049
 44429/100000: episode: 4705, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000062, mae: 0.003242, mean_q: 0.004793
 44439/100000: episode: 4706, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000232, mae: 0.004210, mean_q: 0.004615
 44449/100000: episode: 4707, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001593, mae: 0.008354, mean_q: 0.007513
 44459/100000: episode: 4708, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000042, mae: 0.004866, mean_q: 0.007465
 44469/100000: episode: 4709, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000054, mae: 0.003233, mean_q: 0.004015
 44479/100000: episode: 4710, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000041, mae: 0.002747, mean_q: 0.004278
 44489/100000: episode: 4711, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000058, mae: 0.004217, mean_q: 0.005572
 44499/100000: episode: 4712, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000045, mae: 0.004149, mean_q: 0.005907
 44509/100000: episode: 4713, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000069, mae: 0.004911, mean_q: 0.005568
 44519/100000: episode: 4714, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000018, mae: 0.003463, mean_q: 0.005849
 44529/100000: episode: 4715, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001573, mae: 0.007004, mean_q: 0.005710
 44539/100000: episode: 4716, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000027, mae: 0.005260, mean_q: 0.007743
 44549/100000: episode: 4717, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000035, mae: 0.003908, mean_q: 0.005536
 44559/100000: episode: 4718, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000042, mae: 0.002947, mean_q: 0.004620
 44569/100000: episode: 4719, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000065, mae: 0.003328, mean_q: 0.004871
 44579/100000: episode: 4720, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000101, mae: 0.004371, mean_q: 0.005240
 44589/100000: episode: 4721, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000029, mae: 0.003995, mean_q: 0.005795
 44599/100000: episode: 4722, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.003607, mean_q: 0.005243
 44609/100000: episode: 4723, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000278, mae: 0.004946, mean_q: 0.004729
 44619/100000: episode: 4724, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000034, mae: 0.005123, mean_q: 0.007053
 44629/100000: episode: 4725, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000037, mae: 0.003826, mean_q: 0.006074
 44639/100000: episode: 4726, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000049, mae: 0.002759, mean_q: 0.003727
 44649/100000: episode: 4727, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000074, mae: 0.004276, mean_q: 0.005009
 44659/100000: episode: 4728, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000036, mae: 0.004303, mean_q: 0.005660
 44669/100000: episode: 4729, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000050, mae: 0.003808, mean_q: 0.005110
 44679/100000: episode: 4730, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003403, mean_q: 0.004919
 44689/100000: episode: 4731, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000084, mae: 0.004527, mean_q: 0.005192
 44699/100000: episode: 4732, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000277, mae: 0.005748, mean_q: 0.006333
 44709/100000: episode: 4733, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001601, mae: 0.007533, mean_q: 0.005766
 44719/100000: episode: 4734, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001587, mae: 0.010510, mean_q: 0.009816
 44729/100000: episode: 4735, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000059, mae: 0.006538, mean_q: 0.009061
 44739/100000: episode: 4736, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000027, mae: 0.003040, mean_q: 0.004198
 44749/100000: episode: 4737, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000035, mae: 0.002928, mean_q: 0.003968
 44759/100000: episode: 4738, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000293, mae: 0.006000, mean_q: 0.005720
 44769/100000: episode: 4739, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000063, mae: 0.005758, mean_q: 0.007163
 44779/100000: episode: 4740, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.004537, mean_q: 0.006309
 44789/100000: episode: 4741, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001600, mae: 0.007327, mean_q: 0.005708
 44799/100000: episode: 4742, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.001605, mae: 0.009152, mean_q: 0.008711
 44809/100000: episode: 4743, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000246, mae: 0.006396, mean_q: 0.008594
 44819/100000: episode: 4744, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003589, mean_q: 0.005329
 44829/100000: episode: 4745, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000227, mae: 0.004085, mean_q: 0.005416
 44839/100000: episode: 4746, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000039, mae: 0.003381, mean_q: 0.005579
 44849/100000: episode: 4747, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000130, mae: 0.004864, mean_q: 0.005240
[Info] 1-TH LEVEL FOUND: 0.007073462940752506, Considering 100/100 traces
 44859/100000: episode: 4748, duration: 0.682s, episode steps: 10, steps per second: 15, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000254, mae: 0.005326, mean_q: 0.006435
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007073462940752506
 44869/100000: episode: 4749, duration: 0.501s, episode steps: 10, steps per second: 20, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000043, mae: 0.004183, mean_q: 0.006664
 44879/100000: episode: 4750, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.002639, mean_q: 0.004569
 44889/100000: episode: 4751, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000075, mae: 0.003576, mean_q: 0.004542
 44899/100000: episode: 4752, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001604, mae: 0.007753, mean_q: 0.006108
 44909/100000: episode: 4753, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000052, mae: 0.005876, mean_q: 0.008341
 44919/100000: episode: 4754, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000061, mae: 0.004453, mean_q: 0.005788
 44929/100000: episode: 4755, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000455, mae: 0.005391, mean_q: 0.005399
 44939/100000: episode: 4756, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000084, mae: 0.005454, mean_q: 0.006926
 44949/100000: episode: 4757, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001613, mae: 0.008491, mean_q: 0.006769
 44959/100000: episode: 4758, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000065, mae: 0.006362, mean_q: 0.008684
 44969/100000: episode: 4759, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000023, mae: 0.003739, mean_q: 0.005994
 44979/100000: episode: 4760, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000083, mae: 0.003609, mean_q: 0.004095
 44989/100000: episode: 4761, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000063, mae: 0.004610, mean_q: 0.005916
 44999/100000: episode: 4762, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.004237, mean_q: 0.006498
 45009/100000: episode: 4763, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000283, mae: 0.005478, mean_q: 0.005865
 45019/100000: episode: 4764, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.003119, mae: 0.012825, mean_q: 0.009358
 45029/100000: episode: 4765, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000090, mae: 0.008754, mean_q: 0.011807
 45039/100000: episode: 4766, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000048, mae: 0.004773, mean_q: 0.007366
 45049/100000: episode: 4767, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000237, mae: 0.003807, mean_q: 0.004350
 45059/100000: episode: 4768, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000085, mae: 0.004649, mean_q: 0.005847
 45069/100000: episode: 4769, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000043, mae: 0.004087, mean_q: 0.006596
 45079/100000: episode: 4770, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000067, mae: 0.003761, mean_q: 0.005727
 45089/100000: episode: 4771, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000016, mae: 0.002911, mean_q: 0.005404
 45099/100000: episode: 4772, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000027, mae: 0.003165, mean_q: 0.005169
 45109/100000: episode: 4773, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.003174, mae: 0.013042, mean_q: 0.008928
 45119/100000: episode: 4774, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000079, mae: 0.006979, mean_q: 0.009830
 45129/100000: episode: 4775, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000024, mae: 0.003060, mean_q: 0.005160
 45139/100000: episode: 4776, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000028, mae: 0.003045, mean_q: 0.004442
 45149/100000: episode: 4777, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000082, mae: 0.004707, mean_q: 0.006164
 45159/100000: episode: 4778, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000281, mae: 0.006193, mean_q: 0.007195
 45169/100000: episode: 4779, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000029, mae: 0.004445, mean_q: 0.006857
 45179/100000: episode: 4780, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000070, mae: 0.004428, mean_q: 0.005631
 45189/100000: episode: 4781, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000056, mae: 0.004643, mean_q: 0.006228
 45199/100000: episode: 4782, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001560, mae: 0.007379, mean_q: 0.007241
 45209/100000: episode: 4783, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001559, mae: 0.007552, mean_q: 0.007487
 45219/100000: episode: 4784, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000315, mae: 0.007102, mean_q: 0.007448
 45229/100000: episode: 4785, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001565, mae: 0.007267, mean_q: 0.006936
 45239/100000: episode: 4786, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000018, mae: 0.004267, mean_q: 0.007287
 45249/100000: episode: 4787, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001573, mae: 0.006208, mean_q: 0.005201
 45259/100000: episode: 4788, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000053, mae: 0.005130, mean_q: 0.007431
 45269/100000: episode: 4789, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000246, mae: 0.005263, mean_q: 0.007161
 45279/100000: episode: 4790, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000050, mae: 0.003517, mean_q: 0.005620
 45289/100000: episode: 4791, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000133, mae: 0.005050, mean_q: 0.005580
 45299/100000: episode: 4792, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000025, mae: 0.003975, mean_q: 0.006451
 45309/100000: episode: 4793, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000238, mae: 0.004578, mean_q: 0.005514
 45319/100000: episode: 4794, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000053, mae: 0.004146, mean_q: 0.005935
 45329/100000: episode: 4795, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003462, mean_q: 0.005754
 45339/100000: episode: 4796, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000049, mae: 0.003719, mean_q: 0.005448
 45349/100000: episode: 4797, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000072, mae: 0.004056, mean_q: 0.005473
 45359/100000: episode: 4798, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000024, mae: 0.003698, mean_q: 0.006038
 45369/100000: episode: 4799, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000073, mae: 0.003999, mean_q: 0.005457
 45379/100000: episode: 4800, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000228, mae: 0.003806, mean_q: 0.004826
 45389/100000: episode: 4801, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000034, mae: 0.004193, mean_q: 0.005527
 45399/100000: episode: 4802, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000069, mae: 0.004251, mean_q: 0.006156
 45409/100000: episode: 4803, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000077, mae: 0.004447, mean_q: 0.005498
 45419/100000: episode: 4804, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000079, mae: 0.004381, mean_q: 0.005853
 45429/100000: episode: 4805, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000079, mae: 0.004247, mean_q: 0.005616
 45439/100000: episode: 4806, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000012, mae: 0.002746, mean_q: 0.004917
 45449/100000: episode: 4807, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000029, mae: 0.003212, mean_q: 0.004492
 45459/100000: episode: 4808, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000039, mae: 0.003102, mean_q: 0.004741
 45469/100000: episode: 4809, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001566, mae: 0.006032, mean_q: 0.004718
 45479/100000: episode: 4810, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000086, mae: 0.006290, mean_q: 0.007545
 45489/100000: episode: 4811, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001803, mae: 0.010303, mean_q: 0.008290
 45499/100000: episode: 4812, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000057, mae: 0.006025, mean_q: 0.008491
 45509/100000: episode: 4813, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003073, mean_q: 0.004920
 45519/100000: episode: 4814, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002240, mean_q: 0.003893
 45529/100000: episode: 4815, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000032, mae: 0.002321, mean_q: 0.004409
 45539/100000: episode: 4816, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000032, mae: 0.003414, mean_q: 0.004728
 45549/100000: episode: 4817, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000038, mae: 0.003356, mean_q: 0.005272
 45559/100000: episode: 4818, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000265, mae: 0.005171, mean_q: 0.005430
 45569/100000: episode: 4819, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000055, mae: 0.004368, mean_q: 0.005911
 45579/100000: episode: 4820, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001802, mae: 0.009283, mean_q: 0.007199
 45589/100000: episode: 4821, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000106, mae: 0.006669, mean_q: 0.008273
 45599/100000: episode: 4822, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001565, mae: 0.006702, mean_q: 0.005790
 45609/100000: episode: 4823, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000046, mae: 0.005216, mean_q: 0.006645
 45619/100000: episode: 4824, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000053, mae: 0.004327, mean_q: 0.006186
 45629/100000: episode: 4825, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001610, mae: 0.008908, mean_q: 0.007555
 45639/100000: episode: 4826, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000471, mae: 0.007700, mean_q: 0.007395
 45649/100000: episode: 4827, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000051, mae: 0.004889, mean_q: 0.007160
 45659/100000: episode: 4828, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.004043, mean_q: 0.005777
 45669/100000: episode: 4829, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003284, mean_q: 0.004891
 45679/100000: episode: 4830, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.003060, mean_q: 0.005146
 45689/100000: episode: 4831, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003393, mean_q: 0.005335
 45699/100000: episode: 4832, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000015, mae: 0.002755, mean_q: 0.004796
 45709/100000: episode: 4833, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000028, mae: 0.002985, mean_q: 0.004339
 45719/100000: episode: 4834, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003326, mean_q: 0.004995
 45729/100000: episode: 4835, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000090, mae: 0.005199, mean_q: 0.005471
 45739/100000: episode: 4836, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000040, mae: 0.004127, mean_q: 0.006261
 45749/100000: episode: 4837, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001658, mae: 0.008104, mean_q: 0.005378
 45759/100000: episode: 4838, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000076, mae: 0.006324, mean_q: 0.008592
 45769/100000: episode: 4839, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000133, mae: 0.006239, mean_q: 0.007234
 45779/100000: episode: 4840, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000129, mae: 0.005763, mean_q: 0.006652
 45789/100000: episode: 4841, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000048, mae: 0.004073, mean_q: 0.005985
 45799/100000: episode: 4842, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000021, mae: 0.003152, mean_q: 0.005180
 45809/100000: episode: 4843, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003251, mean_q: 0.004779
 45819/100000: episode: 4844, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003471, mean_q: 0.005173
 45829/100000: episode: 4845, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000083, mae: 0.004375, mean_q: 0.005416
 45839/100000: episode: 4846, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000053, mae: 0.004105, mean_q: 0.005754
 45849/100000: episode: 4847, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000052, mae: 0.004278, mean_q: 0.005832
 45859/100000: episode: 4848, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000071, mae: 0.003736, mean_q: 0.004870
[Info] 1-TH LEVEL FOUND: 0.005641839932650328, Considering 100/100 traces
 45869/100000: episode: 4849, duration: 0.776s, episode steps: 10, steps per second: 13, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000027, mae: 0.003618, mean_q: 0.005423
[Info] 2-TH LEVEL FOUND: 0.008433360606431961, Considering 100/100 traces
 45879/100000: episode: 4850, duration: 0.881s, episode steps: 10, steps per second: 11, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001623, mae: 0.008007, mean_q: 0.006309
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.008433360606431961
 45889/100000: episode: 4851, duration: 0.886s, episode steps: 10, steps per second: 11, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000040, mae: 0.006052, mean_q: 0.008111
 45899/100000: episode: 4852, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000067, mae: 0.004068, mean_q: 0.005724
 45909/100000: episode: 4853, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000255, mae: 0.004437, mean_q: 0.004986
 45919/100000: episode: 4854, duration: 0.124s, episode steps: 10, steps per second: 80, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000055, mae: 0.004488, mean_q: 0.005928
 45929/100000: episode: 4855, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000116, mae: 0.005406, mean_q: 0.005774
 45939/100000: episode: 4856, duration: 0.077s, episode steps: 10, steps per second: 131, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001653, mae: 0.008485, mean_q: 0.006249
 45949/100000: episode: 4857, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000054, mae: 0.006427, mean_q: 0.008989
 45959/100000: episode: 4858, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000227, mae: 0.005722, mean_q: 0.006935
 45969/100000: episode: 4859, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000041, mae: 0.003609, mean_q: 0.004710
 45979/100000: episode: 4860, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000029, mae: 0.003724, mean_q: 0.005587
 45989/100000: episode: 4861, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000051, mae: 0.004519, mean_q: 0.006536
 45999/100000: episode: 4862, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000049, mae: 0.003567, mean_q: 0.005419
 46009/100000: episode: 4863, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000164, mae: 0.005669, mean_q: 0.005491
 46019/100000: episode: 4864, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000043, mae: 0.004646, mean_q: 0.007134
 46029/100000: episode: 4865, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.003734, mean_q: 0.005221
 46039/100000: episode: 4866, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000042, mae: 0.002762, mean_q: 0.004295
 46049/100000: episode: 4867, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.003678, mean_q: 0.005044
 46059/100000: episode: 4868, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000031, mae: 0.004035, mean_q: 0.005579
 46069/100000: episode: 4869, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003015, mean_q: 0.004890
 46079/100000: episode: 4870, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001571, mae: 0.006504, mean_q: 0.005127
 46089/100000: episode: 4871, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000026, mae: 0.005133, mean_q: 0.007775
 46099/100000: episode: 4872, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000063, mae: 0.004532, mean_q: 0.005780
 46109/100000: episode: 4873, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000242, mae: 0.005279, mean_q: 0.005684
 46119/100000: episode: 4874, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000034, mae: 0.005014, mean_q: 0.006948
 46129/100000: episode: 4875, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000083, mae: 0.004765, mean_q: 0.006148
 46139/100000: episode: 4876, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001640, mae: 0.008427, mean_q: 0.006004
 46149/100000: episode: 4877, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000055, mae: 0.006607, mean_q: 0.009405
 46159/100000: episode: 4878, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000054, mae: 0.004157, mean_q: 0.005774
 46169/100000: episode: 4879, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000284, mae: 0.004518, mean_q: 0.004382
 46179/100000: episode: 4880, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000256, mae: 0.005898, mean_q: 0.006906
 46189/100000: episode: 4881, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000025, mae: 0.004290, mean_q: 0.006843
 46199/100000: episode: 4882, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001613, mae: 0.007207, mean_q: 0.005950
 46209/100000: episode: 4883, duration: 0.073s, episode steps: 10, steps per second: 136, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000225, mae: 0.005867, mean_q: 0.007560
 46219/100000: episode: 4884, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000015, mae: 0.002764, mean_q: 0.005078
 46229/100000: episode: 4885, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000040, mae: 0.002591, mean_q: 0.004087
 46239/100000: episode: 4886, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000066, mae: 0.004730, mean_q: 0.005480
 46249/100000: episode: 4887, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000086, mae: 0.005512, mean_q: 0.006509
 46259/100000: episode: 4888, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000047, mae: 0.004300, mean_q: 0.006253
 46269/100000: episode: 4889, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000084, mae: 0.004252, mean_q: 0.005085
 46279/100000: episode: 4890, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000067, mae: 0.003893, mean_q: 0.005535
 46289/100000: episode: 4891, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000045, mae: 0.004209, mean_q: 0.005991
 46299/100000: episode: 4892, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.003235, mean_q: 0.005337
 46309/100000: episode: 4893, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.001602, mae: 0.006335, mean_q: 0.004309
 46319/100000: episode: 4894, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000054, mae: 0.005925, mean_q: 0.008024
 46329/100000: episode: 4895, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000056, mae: 0.004782, mean_q: 0.006281
 46339/100000: episode: 4896, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000261, mae: 0.004581, mean_q: 0.004846
 46349/100000: episode: 4897, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000108, mae: 0.005603, mean_q: 0.006453
 46359/100000: episode: 4898, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000056, mae: 0.004837, mean_q: 0.006554
 46369/100000: episode: 4899, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000037, mae: 0.002878, mean_q: 0.004935
 46379/100000: episode: 4900, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000075, mae: 0.003771, mean_q: 0.004592
 46389/100000: episode: 4901, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000053, mae: 0.003901, mean_q: 0.005292
 46399/100000: episode: 4902, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000047, mae: 0.003509, mean_q: 0.005471
 46409/100000: episode: 4903, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001586, mae: 0.006514, mean_q: 0.005310
 46419/100000: episode: 4904, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001774, mae: 0.009389, mean_q: 0.007506
 46429/100000: episode: 4905, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000025, mae: 0.005636, mean_q: 0.008824
 46439/100000: episode: 4906, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002935, mean_q: 0.005352
 46449/100000: episode: 4907, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000135, mae: 0.004180, mean_q: 0.003921
 46459/100000: episode: 4908, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001562, mae: 0.006855, mean_q: 0.006199
 46469/100000: episode: 4909, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000019, mae: 0.004924, mean_q: 0.007837
 46479/100000: episode: 4910, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000078, mae: 0.003809, mean_q: 0.005217
 46489/100000: episode: 4911, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000042, mae: 0.003021, mean_q: 0.004494
 46499/100000: episode: 4912, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000057, mae: 0.004077, mean_q: 0.005337
 46509/100000: episode: 4913, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000075, mae: 0.004898, mean_q: 0.006229
 46519/100000: episode: 4914, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000072, mae: 0.003587, mean_q: 0.004989
 46529/100000: episode: 4915, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000025, mae: 0.003171, mean_q: 0.004966
 46539/100000: episode: 4916, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000059, mae: 0.003937, mean_q: 0.005165
 46549/100000: episode: 4917, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000056, mae: 0.004295, mean_q: 0.005616
 46559/100000: episode: 4918, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000069, mae: 0.003959, mean_q: 0.005307
 46569/100000: episode: 4919, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000066, mae: 0.004291, mean_q: 0.005226
 46579/100000: episode: 4920, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001577, mae: 0.007204, mean_q: 0.005780
 46589/100000: episode: 4921, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000261, mae: 0.006745, mean_q: 0.007781
 46599/100000: episode: 4922, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000047, mae: 0.004848, mean_q: 0.006967
 46609/100000: episode: 4923, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000052, mae: 0.003727, mean_q: 0.004908
 46619/100000: episode: 4924, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000056, mae: 0.003692, mean_q: 0.004865
 46629/100000: episode: 4925, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000030, mae: 0.003729, mean_q: 0.005369
 46639/100000: episode: 4926, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000056, mae: 0.004154, mean_q: 0.005503
 46649/100000: episode: 4927, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000055, mae: 0.004076, mean_q: 0.005083
 46659/100000: episode: 4928, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.003060, mean_q: 0.004879
 46669/100000: episode: 4929, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000055, mae: 0.003555, mean_q: 0.004628
 46679/100000: episode: 4930, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.004185, mean_q: 0.005709
 46689/100000: episode: 4931, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000046, mae: 0.003923, mean_q: 0.005765
 46699/100000: episode: 4932, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000036, mae: 0.003533, mean_q: 0.004593
 46709/100000: episode: 4933, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000018, mae: 0.002877, mean_q: 0.004565
 46719/100000: episode: 4934, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001571, mae: 0.006696, mean_q: 0.005507
 46729/100000: episode: 4935, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001854, mae: 0.010624, mean_q: 0.007746
 46739/100000: episode: 4936, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000065, mae: 0.007217, mean_q: 0.009810
 46749/100000: episode: 4937, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000232, mae: 0.004935, mean_q: 0.005946
 46759/100000: episode: 4938, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000025, mae: 0.003390, mean_q: 0.005281
 46769/100000: episode: 4939, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000055, mae: 0.004209, mean_q: 0.005481
 46779/100000: episode: 4940, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000087, mae: 0.005042, mean_q: 0.006020
 46789/100000: episode: 4941, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000083, mae: 0.005075, mean_q: 0.006504
 46799/100000: episode: 4942, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003344, mean_q: 0.005117
 46809/100000: episode: 4943, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001582, mae: 0.008342, mean_q: 0.007168
 46819/100000: episode: 4944, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.001561, mae: 0.008543, mean_q: 0.008785
 46829/100000: episode: 4945, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000100, mae: 0.005239, mean_q: 0.006411
 46839/100000: episode: 4946, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000084, mae: 0.004680, mean_q: 0.006068
 46849/100000: episode: 4947, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001615, mae: 0.008334, mean_q: 0.007445
 46859/100000: episode: 4948, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000062, mae: 0.005937, mean_q: 0.008161
 46869/100000: episode: 4949, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000261, mae: 0.005366, mean_q: 0.005825
 46879/100000: episode: 4950, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000295, mae: 0.006268, mean_q: 0.006381
[Info] 1-TH LEVEL FOUND: 0.0066269137896597385, Considering 100/100 traces
 46889/100000: episode: 4951, duration: 0.698s, episode steps: 10, steps per second: 14, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000053, mae: 0.005339, mean_q: 0.007505
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0066269137896597385
 46899/100000: episode: 4952, duration: 0.509s, episode steps: 10, steps per second: 20, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000052, mae: 0.003814, mean_q: 0.005608
 46909/100000: episode: 4953, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000037, mae: 0.002584, mean_q: 0.004600
 46919/100000: episode: 4954, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000222, mae: 0.003492, mean_q: 0.004766
 46929/100000: episode: 4955, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000072, mae: 0.004514, mean_q: 0.006029
 46939/100000: episode: 4956, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000095, mae: 0.004814, mean_q: 0.006250
 46949/100000: episode: 4957, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000104, mae: 0.005025, mean_q: 0.005944
 46959/100000: episode: 4958, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000023, mae: 0.003731, mean_q: 0.005938
 46969/100000: episode: 4959, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000109, mae: 0.004595, mean_q: 0.005154
 46979/100000: episode: 4960, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000029, mae: 0.004257, mean_q: 0.006016
 46989/100000: episode: 4961, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000020, mae: 0.003474, mean_q: 0.005463
 46999/100000: episode: 4962, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.003102, mean_q: 0.004808
 47009/100000: episode: 4963, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000304, mae: 0.006369, mean_q: 0.005464
 47019/100000: episode: 4964, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000062, mae: 0.005991, mean_q: 0.007755
 47029/100000: episode: 4965, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001564, mae: 0.007454, mean_q: 0.006799
 47039/100000: episode: 4966, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000068, mae: 0.006243, mean_q: 0.007905
 47049/100000: episode: 4967, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000110, mae: 0.005628, mean_q: 0.006876
 47059/100000: episode: 4968, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.003165, mean_q: 0.005029
 47069/100000: episode: 4969, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000030, mae: 0.003090, mean_q: 0.004331
 47079/100000: episode: 4970, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001779, mae: 0.009064, mean_q: 0.007281
 47089/100000: episode: 4971, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000474, mae: 0.008681, mean_q: 0.008776
 47099/100000: episode: 4972, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.005027, mean_q: 0.007344
 47109/100000: episode: 4973, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000230, mae: 0.004373, mean_q: 0.005701
 47119/100000: episode: 4974, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000053, mae: 0.004141, mean_q: 0.005927
 47129/100000: episode: 4975, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000084, mae: 0.004709, mean_q: 0.005820
 47139/100000: episode: 4976, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000121, mae: 0.005503, mean_q: 0.006012
 47149/100000: episode: 4977, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.004308, mean_q: 0.006701
 47159/100000: episode: 4978, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000032, mae: 0.003729, mean_q: 0.005553
 47169/100000: episode: 4979, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000118, mae: 0.005380, mean_q: 0.005936
 47179/100000: episode: 4980, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000097, mae: 0.005256, mean_q: 0.007076
 47189/100000: episode: 4981, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000014, mae: 0.002994, mean_q: 0.005646
 47199/100000: episode: 4982, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001567, mae: 0.006092, mean_q: 0.005037
 47209/100000: episode: 4983, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000044, mae: 0.004630, mean_q: 0.007081
 47219/100000: episode: 4984, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001588, mae: 0.006113, mean_q: 0.005182
 47229/100000: episode: 4985, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001624, mae: 0.011299, mean_q: 0.010839
 47239/100000: episode: 4986, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000067, mae: 0.007684, mean_q: 0.010614
 47249/100000: episode: 4987, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.003103, mae: 0.009947, mean_q: 0.006524
 47259/100000: episode: 4988, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000053, mae: 0.005391, mean_q: 0.007831
 47269/100000: episode: 4989, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001574, mae: 0.007651, mean_q: 0.007050
 47279/100000: episode: 4990, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.004286, mean_q: 0.007731
 47289/100000: episode: 4991, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000469, mae: 0.006268, mean_q: 0.006220
 47299/100000: episode: 4992, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.004273, mean_q: 0.007446
 47309/100000: episode: 4993, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000064, mae: 0.004330, mean_q: 0.005887
 47319/100000: episode: 4994, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000056, mae: 0.003703, mean_q: 0.005570
 47329/100000: episode: 4995, duration: 0.055s, episode steps: 10, steps per second: 180, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000081, mae: 0.004130, mean_q: 0.006005
 47339/100000: episode: 4996, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000103, mae: 0.004887, mean_q: 0.006322
 47349/100000: episode: 4997, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000047, mae: 0.004310, mean_q: 0.006561
 47359/100000: episode: 4998, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003202, mean_q: 0.005163
 47369/100000: episode: 4999, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000097, mae: 0.004620, mean_q: 0.004953
 47379/100000: episode: 5000, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000059, mae: 0.005365, mean_q: 0.007098
 47389/100000: episode: 5001, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000019, mae: 0.003703, mean_q: 0.006321
 47399/100000: episode: 5002, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000053, mae: 0.003475, mean_q: 0.004810
 47409/100000: episode: 5003, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000017, mae: 0.002669, mean_q: 0.004788
 47419/100000: episode: 5004, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003096, mean_q: 0.004941
 47429/100000: episode: 5005, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000038, mae: 0.003336, mean_q: 0.005359
 47439/100000: episode: 5006, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.003272, mean_q: 0.004589
 47449/100000: episode: 5007, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001638, mae: 0.008965, mean_q: 0.007116
 47459/100000: episode: 5008, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000032, mae: 0.005168, mean_q: 0.007504
 47469/100000: episode: 5009, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000139, mae: 0.005048, mean_q: 0.004718
 47479/100000: episode: 5010, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.003108, mae: 0.010625, mean_q: 0.006615
 47489/100000: episode: 5011, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000076, mae: 0.008615, mean_q: 0.011275
 47499/100000: episode: 5012, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003918, mean_q: 0.006363
 47509/100000: episode: 5013, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000056, mae: 0.003097, mean_q: 0.003412
 47519/100000: episode: 5014, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000048, mae: 0.003708, mean_q: 0.005200
 47529/100000: episode: 5015, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003533, mean_q: 0.005520
 47539/100000: episode: 5016, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000016, mae: 0.002996, mean_q: 0.005039
 47549/100000: episode: 5017, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000048, mae: 0.003603, mean_q: 0.005484
 47559/100000: episode: 5018, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000063, mae: 0.004598, mean_q: 0.005695
 47569/100000: episode: 5019, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000092, mae: 0.005543, mean_q: 0.006194
 47579/100000: episode: 5020, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000081, mae: 0.004865, mean_q: 0.006119
 47589/100000: episode: 5021, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000233, mae: 0.004850, mean_q: 0.005953
 47599/100000: episode: 5022, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.003381, mean_q: 0.005651
 47609/100000: episode: 5023, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.003265, mae: 0.013146, mean_q: 0.007467
 47619/100000: episode: 5024, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000055, mae: 0.008570, mean_q: 0.011534
 47629/100000: episode: 5025, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000289, mae: 0.006294, mean_q: 0.007103
 47639/100000: episode: 5026, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000077, mae: 0.003910, mean_q: 0.005385
 47649/100000: episode: 5027, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.002874, mean_q: 0.005282
 47659/100000: episode: 5028, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000036, mae: 0.003011, mean_q: 0.005143
 47669/100000: episode: 5029, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000015, mae: 0.002649, mean_q: 0.004781
 47679/100000: episode: 5030, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000116, mae: 0.004850, mean_q: 0.005206
 47689/100000: episode: 5031, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000077, mae: 0.004927, mean_q: 0.006556
 47699/100000: episode: 5032, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000107, mae: 0.004914, mean_q: 0.006024
 47709/100000: episode: 5033, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000083, mae: 0.004641, mean_q: 0.006054
 47719/100000: episode: 5034, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000046, mae: 0.004028, mean_q: 0.005976
 47729/100000: episode: 5035, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000029, mae: 0.003643, mean_q: 0.005309
 47739/100000: episode: 5036, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000068, mae: 0.004459, mean_q: 0.005308
 47749/100000: episode: 5037, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000060, mae: 0.004623, mean_q: 0.006059
 47759/100000: episode: 5038, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001571, mae: 0.006784, mean_q: 0.005743
 47769/100000: episode: 5039, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000026, mae: 0.004669, mean_q: 0.007296
 47779/100000: episode: 5040, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000020, mae: 0.003508, mean_q: 0.005667
 47789/100000: episode: 5041, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003149, mae: 0.011175, mean_q: 0.006593
 47799/100000: episode: 5042, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000267, mae: 0.008533, mean_q: 0.010395
 47809/100000: episode: 5043, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000116, mae: 0.005844, mean_q: 0.006909
 47819/100000: episode: 5044, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000031, mae: 0.003960, mean_q: 0.005787
 47829/100000: episode: 5045, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000023, mae: 0.003697, mean_q: 0.006005
 47839/100000: episode: 5046, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000088, mae: 0.004498, mean_q: 0.005453
 47849/100000: episode: 5047, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000059, mae: 0.004628, mean_q: 0.006207
 47859/100000: episode: 5048, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000014, mae: 0.003256, mean_q: 0.006112
 47869/100000: episode: 5049, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000049, mae: 0.003375, mean_q: 0.004928
 47879/100000: episode: 5050, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001577, mae: 0.006393, mean_q: 0.004718
 47889/100000: episode: 5051, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000061, mae: 0.005889, mean_q: 0.008087
[Info] 1-TH LEVEL FOUND: 0.005549567751586437, Considering 100/100 traces
 47899/100000: episode: 5052, duration: 0.726s, episode steps: 10, steps per second: 14, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000060, mae: 0.005513, mean_q: 0.007293
[Info] 2-TH LEVEL FOUND: 0.007672026753425598, Considering 100/100 traces
 47909/100000: episode: 5053, duration: 0.726s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001560, mae: 0.006933, mean_q: 0.006557
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007672026753425598
 47919/100000: episode: 5054, duration: 0.518s, episode steps: 10, steps per second: 19, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.004501, mean_q: 0.007085
 47929/100000: episode: 5055, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000052, mae: 0.003703, mean_q: 0.004990
 47939/100000: episode: 5056, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000035, mae: 0.002933, mean_q: 0.005276
 47949/100000: episode: 5057, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000053, mae: 0.003735, mean_q: 0.005328
 47959/100000: episode: 5058, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000103, mae: 0.004722, mean_q: 0.005940
 47969/100000: episode: 5059, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.003760, mean_q: 0.005625
 47979/100000: episode: 5060, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000073, mae: 0.004647, mean_q: 0.005553
 47989/100000: episode: 5061, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000028, mae: 0.003717, mean_q: 0.005789
 47999/100000: episode: 5062, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000015, mae: 0.002853, mean_q: 0.005020
 48009/100000: episode: 5063, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000068, mae: 0.004259, mean_q: 0.004807
 48019/100000: episode: 5064, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000032, mae: 0.004402, mean_q: 0.005781
 48029/100000: episode: 5065, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000013, mae: 0.003337, mean_q: 0.005604
 48039/100000: episode: 5066, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000048, mae: 0.003345, mean_q: 0.004748
 48049/100000: episode: 5067, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002601, mean_q: 0.004681
 48059/100000: episode: 5068, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002391, mean_q: 0.004168
 48069/100000: episode: 5069, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000032, mae: 0.003343, mean_q: 0.004519
 48079/100000: episode: 5070, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000014, mae: 0.003062, mean_q: 0.005196
 48089/100000: episode: 5071, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.002889, mean_q: 0.004531
 48099/100000: episode: 5072, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000025, mae: 0.003141, mean_q: 0.004620
 48109/100000: episode: 5073, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000024, mae: 0.003568, mean_q: 0.004883
 48119/100000: episode: 5074, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000046, mae: 0.003831, mean_q: 0.005420
 48129/100000: episode: 5075, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000070, mae: 0.003595, mean_q: 0.004675
 48139/100000: episode: 5076, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000041, mae: 0.002969, mean_q: 0.004397
 48149/100000: episode: 5077, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000024, mae: 0.003163, mean_q: 0.004483
 48159/100000: episode: 5078, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000038, mae: 0.003760, mean_q: 0.004707
 48169/100000: episode: 5079, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000058, mae: 0.005006, mean_q: 0.006143
 48179/100000: episode: 5080, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000052, mae: 0.004243, mean_q: 0.005625
 48189/100000: episode: 5081, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000062, mae: 0.004083, mean_q: 0.004615
 48199/100000: episode: 5082, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000053, mae: 0.004393, mean_q: 0.005815
 48209/100000: episode: 5083, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003649, mean_q: 0.005391
 48219/100000: episode: 5084, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000015, mae: 0.002683, mean_q: 0.004281
 48229/100000: episode: 5085, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000048, mae: 0.003155, mean_q: 0.004222
 48239/100000: episode: 5086, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002926, mean_q: 0.004803
 48249/100000: episode: 5087, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000140, mae: 0.005304, mean_q: 0.004791
 48259/100000: episode: 5088, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000021, mae: 0.004502, mean_q: 0.006737
 48269/100000: episode: 5089, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000051, mae: 0.003884, mean_q: 0.005250
 48279/100000: episode: 5090, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000033, mae: 0.003840, mean_q: 0.004486
 48289/100000: episode: 5091, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000155, mae: 0.005425, mean_q: 0.005245
 48299/100000: episode: 5092, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000080, mae: 0.005342, mean_q: 0.006564
 48309/100000: episode: 5093, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000027, mae: 0.004073, mean_q: 0.005640
 48319/100000: episode: 5094, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000063, mae: 0.004202, mean_q: 0.004915
 48329/100000: episode: 5095, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000051, mae: 0.004324, mean_q: 0.005603
 48339/100000: episode: 5096, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000030, mae: 0.004018, mean_q: 0.005615
 48349/100000: episode: 5097, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000049, mae: 0.004022, mean_q: 0.005503
 48359/100000: episode: 5098, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000039, mae: 0.003214, mean_q: 0.005105
 48369/100000: episode: 5099, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000061, mae: 0.004313, mean_q: 0.004800
 48379/100000: episode: 5100, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000068, mae: 0.003879, mean_q: 0.005341
 48389/100000: episode: 5101, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000064, mae: 0.004413, mean_q: 0.005028
 48399/100000: episode: 5102, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000045, mae: 0.004053, mean_q: 0.005931
 48409/100000: episode: 5103, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000059, mae: 0.003950, mean_q: 0.004785
 48419/100000: episode: 5104, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000049, mae: 0.004399, mean_q: 0.005646
 48429/100000: episode: 5105, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000081, mae: 0.005099, mean_q: 0.006124
 48439/100000: episode: 5106, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000017, mae: 0.003078, mean_q: 0.005123
 48449/100000: episode: 5107, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000081, mae: 0.003808, mean_q: 0.004249
 48459/100000: episode: 5108, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000034, mae: 0.004167, mean_q: 0.005651
 48469/100000: episode: 5109, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000047, mae: 0.003807, mean_q: 0.005574
 48479/100000: episode: 5110, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000044, mae: 0.003096, mean_q: 0.004624
 48489/100000: episode: 5111, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000025, mae: 0.003155, mean_q: 0.004513
 48499/100000: episode: 5112, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000070, mae: 0.004388, mean_q: 0.004866
 48509/100000: episode: 5113, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000066, mae: 0.005155, mean_q: 0.006267
 48519/100000: episode: 5114, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000103, mae: 0.004748, mean_q: 0.005615
 48529/100000: episode: 5115, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000028, mae: 0.003666, mean_q: 0.005217
 48539/100000: episode: 5116, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000048, mae: 0.003329, mean_q: 0.004546
 48549/100000: episode: 5117, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000035, mae: 0.003774, mean_q: 0.004983
 48559/100000: episode: 5118, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000099, mae: 0.004505, mean_q: 0.005074
 48569/100000: episode: 5119, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000012, mae: 0.003424, mean_q: 0.005911
 48579/100000: episode: 5120, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000058, mae: 0.003922, mean_q: 0.004623
 48589/100000: episode: 5121, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003319, mean_q: 0.004909
 48599/100000: episode: 5122, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000056, mae: 0.003831, mean_q: 0.004922
 48609/100000: episode: 5123, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000048, mae: 0.003965, mean_q: 0.005710
 48619/100000: episode: 5124, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000051, mae: 0.003861, mean_q: 0.005013
 48629/100000: episode: 5125, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000033, mae: 0.003829, mean_q: 0.005007
 48639/100000: episode: 5126, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000032, mae: 0.004186, mean_q: 0.005544
 48649/100000: episode: 5127, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000042, mae: 0.003397, mean_q: 0.004924
 48659/100000: episode: 5128, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000051, mae: 0.003700, mean_q: 0.004524
 48669/100000: episode: 5129, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000118, mae: 0.005370, mean_q: 0.005393
 48679/100000: episode: 5130, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000106, mae: 0.006133, mean_q: 0.007045
 48689/100000: episode: 5131, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000074, mae: 0.004536, mean_q: 0.005716
 48699/100000: episode: 5132, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000069, mae: 0.004563, mean_q: 0.004948
 48709/100000: episode: 5133, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000051, mae: 0.004161, mean_q: 0.005531
 48719/100000: episode: 5134, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000056, mae: 0.004083, mean_q: 0.005338
 48729/100000: episode: 5135, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000030, mae: 0.003750, mean_q: 0.005204
 48739/100000: episode: 5136, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000035, mae: 0.003741, mean_q: 0.004886
 48749/100000: episode: 5137, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000011, mae: 0.002669, mean_q: 0.004672
 48759/100000: episode: 5138, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000057, mae: 0.003632, mean_q: 0.004378
 48769/100000: episode: 5139, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.003424, mean_q: 0.005389
 48779/100000: episode: 5140, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000028, mae: 0.003184, mean_q: 0.004407
 48789/100000: episode: 5141, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000060, mae: 0.004010, mean_q: 0.004660
 48799/100000: episode: 5142, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000041, mae: 0.003664, mean_q: 0.005573
 48809/100000: episode: 5143, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000053, mae: 0.003897, mean_q: 0.004617
 48819/100000: episode: 5144, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000050, mae: 0.004106, mean_q: 0.005232
 48829/100000: episode: 5145, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000078, mae: 0.004644, mean_q: 0.005573
 48839/100000: episode: 5146, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003761, mean_q: 0.005243
 48849/100000: episode: 5147, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000030, mae: 0.003723, mean_q: 0.004879
 48859/100000: episode: 5148, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.002973, mean_q: 0.004580
 48869/100000: episode: 5149, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000018, mae: 0.003034, mean_q: 0.004501
 48879/100000: episode: 5150, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000074, mae: 0.003892, mean_q: 0.004757
 48889/100000: episode: 5151, duration: 0.068s, episode steps: 10, steps per second: 146, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000018, mae: 0.002990, mean_q: 0.004675
 48899/100000: episode: 5152, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000061, mae: 0.003913, mean_q: 0.004962
 48909/100000: episode: 5153, duration: 0.083s, episode steps: 10, steps per second: 121, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000088, mae: 0.005116, mean_q: 0.005626
[Info] 1-TH LEVEL FOUND: 0.0050359428860247135, Considering 100/100 traces
 48919/100000: episode: 5154, duration: 1.204s, episode steps: 10, steps per second: 8, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000056, mae: 0.004431, mean_q: 0.005543
[Info] 2-TH LEVEL FOUND: 0.005213460884988308, Considering 100/100 traces
 48929/100000: episode: 5155, duration: 0.937s, episode steps: 10, steps per second: 11, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000053, mae: 0.003944, mean_q: 0.004988
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005213460884988308
 48939/100000: episode: 5156, duration: 0.634s, episode steps: 10, steps per second: 16, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000042, mae: 0.003342, mean_q: 0.004914
 48949/100000: episode: 5157, duration: 0.072s, episode steps: 10, steps per second: 140, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002747, mean_q: 0.004434
 48959/100000: episode: 5158, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003141, mean_q: 0.004061
 48969/100000: episode: 5159, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000044, mae: 0.003411, mean_q: 0.004964
 48979/100000: episode: 5160, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000094, mae: 0.004205, mean_q: 0.005024
 48989/100000: episode: 5161, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000013, mae: 0.002760, mean_q: 0.004895
 48999/100000: episode: 5162, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000051, mae: 0.003160, mean_q: 0.003857
 49009/100000: episode: 5163, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000010, mae: 0.002516, mean_q: 0.004370
 49019/100000: episode: 5164, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000018, mae: 0.003022, mean_q: 0.004458
 49029/100000: episode: 5165, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000038, mae: 0.002663, mean_q: 0.003772
 49039/100000: episode: 5166, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002719, mean_q: 0.004323
 49049/100000: episode: 5167, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000060, mae: 0.004319, mean_q: 0.004949
 49059/100000: episode: 5168, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000040, mae: 0.002964, mean_q: 0.004689
 49069/100000: episode: 5169, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000026, mae: 0.002732, mean_q: 0.003756
 49079/100000: episode: 5170, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.002755, mean_q: 0.004437
 49089/100000: episode: 5171, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000031, mae: 0.003564, mean_q: 0.004425
 49099/100000: episode: 5172, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003520, mean_q: 0.004812
 49109/100000: episode: 5173, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000048, mae: 0.003427, mean_q: 0.004446
 49119/100000: episode: 5174, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000042, mae: 0.003205, mean_q: 0.004490
 49129/100000: episode: 5175, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000041, mae: 0.002951, mean_q: 0.004100
 49139/100000: episode: 5176, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000018, mae: 0.002848, mean_q: 0.004103
 49149/100000: episode: 5177, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000044, mae: 0.003055, mean_q: 0.004189
 49159/100000: episode: 5178, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000035, mae: 0.003718, mean_q: 0.004752
 49169/100000: episode: 5179, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000048, mae: 0.003746, mean_q: 0.004967
 49179/100000: episode: 5180, duration: 0.093s, episode steps: 10, steps per second: 107, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000023, mae: 0.002989, mean_q: 0.004050
 49189/100000: episode: 5181, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000071, mae: 0.004271, mean_q: 0.005095
 49199/100000: episode: 5182, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000028, mae: 0.003711, mean_q: 0.004921
 49209/100000: episode: 5183, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000045, mae: 0.002934, mean_q: 0.003804
 49219/100000: episode: 5184, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000010, mae: 0.002532, mean_q: 0.004212
 49229/100000: episode: 5185, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003302, mean_q: 0.004345
 49239/100000: episode: 5186, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000013, mae: 0.002949, mean_q: 0.004876
 49249/100000: episode: 5187, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000021, mae: 0.002827, mean_q: 0.003866
 49259/100000: episode: 5188, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000038, mae: 0.003197, mean_q: 0.004527
 49269/100000: episode: 5189, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000041, mae: 0.003144, mean_q: 0.004140
 49279/100000: episode: 5190, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003403, mean_q: 0.004445
 49289/100000: episode: 5191, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000046, mae: 0.003363, mean_q: 0.004458
 49299/100000: episode: 5192, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000038, mae: 0.003503, mean_q: 0.005110
 49309/100000: episode: 5193, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000098, mae: 0.004438, mean_q: 0.004958
 49319/100000: episode: 5194, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003629, mean_q: 0.005089
 49329/100000: episode: 5195, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000083, mae: 0.003774, mean_q: 0.003820
 49339/100000: episode: 5196, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.003582, mean_q: 0.005485
 49349/100000: episode: 5197, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000077, mae: 0.003743, mean_q: 0.004153
 49359/100000: episode: 5198, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000131, mae: 0.005184, mean_q: 0.005234
 49369/100000: episode: 5199, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000051, mae: 0.004303, mean_q: 0.005697
 49379/100000: episode: 5200, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000035, mae: 0.002504, mean_q: 0.003582
 49389/100000: episode: 5201, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000052, mae: 0.003325, mean_q: 0.004201
 49399/100000: episode: 5202, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000024, mae: 0.003492, mean_q: 0.005082
 49409/100000: episode: 5203, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000078, mae: 0.003998, mean_q: 0.004458
 49419/100000: episode: 5204, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000017, mae: 0.003203, mean_q: 0.005045
 49429/100000: episode: 5205, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000054, mae: 0.004047, mean_q: 0.004733
 49439/100000: episode: 5206, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000019, mae: 0.003327, mean_q: 0.004689
 49449/100000: episode: 5207, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000024, mae: 0.002833, mean_q: 0.003941
 49459/100000: episode: 5208, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000046, mae: 0.003246, mean_q: 0.004101
 49469/100000: episode: 5209, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003251, mean_q: 0.004688
 49479/100000: episode: 5210, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000020, mae: 0.002866, mean_q: 0.004203
 49489/100000: episode: 5211, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000050, mae: 0.003285, mean_q: 0.003973
 49499/100000: episode: 5212, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000015, mae: 0.003384, mean_q: 0.005168
 49509/100000: episode: 5213, duration: 0.108s, episode steps: 10, steps per second: 92, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.002795, mean_q: 0.003716
 49519/100000: episode: 5214, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000021, mae: 0.003286, mean_q: 0.004531
 49529/100000: episode: 5215, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000052, mae: 0.003679, mean_q: 0.004607
 49539/100000: episode: 5216, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000010, mae: 0.002566, mean_q: 0.004360
 49549/100000: episode: 5217, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000053, mae: 0.003233, mean_q: 0.003661
 49559/100000: episode: 5218, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002960, mean_q: 0.004642
 49569/100000: episode: 5219, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000010, mae: 0.002308, mean_q: 0.003696
 49579/100000: episode: 5220, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000074, mae: 0.004073, mean_q: 0.004753
 49589/100000: episode: 5221, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000038, mae: 0.004308, mean_q: 0.005153
 49599/100000: episode: 5222, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000040, mae: 0.003196, mean_q: 0.004593
 49609/100000: episode: 5223, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000042, mae: 0.002814, mean_q: 0.003540
 49619/100000: episode: 5224, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000039, mae: 0.003011, mean_q: 0.004168
 49629/100000: episode: 5225, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000076, mae: 0.004149, mean_q: 0.004825
 49639/100000: episode: 5226, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000044, mae: 0.003571, mean_q: 0.004995
 49649/100000: episode: 5227, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000042, mae: 0.003132, mean_q: 0.004112
 49659/100000: episode: 5228, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002823, mean_q: 0.004165
 49669/100000: episode: 5229, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000074, mae: 0.003818, mean_q: 0.004319
 49679/100000: episode: 5230, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000015, mae: 0.003230, mean_q: 0.004923
 49689/100000: episode: 5231, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000071, mae: 0.003474, mean_q: 0.004071
 49699/100000: episode: 5232, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000107, mae: 0.004639, mean_q: 0.004700
 49709/100000: episode: 5233, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003740, mean_q: 0.005354
 49719/100000: episode: 5234, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000078, mae: 0.004093, mean_q: 0.004483
 49729/100000: episode: 5235, duration: 0.094s, episode steps: 10, steps per second: 107, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000102, mae: 0.004863, mean_q: 0.005565
 49739/100000: episode: 5236, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000011, mae: 0.002506, mean_q: 0.004111
 49749/100000: episode: 5237, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000021, mae: 0.002497, mean_q: 0.003360
 49759/100000: episode: 5238, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000012, mae: 0.002761, mean_q: 0.004344
 49769/100000: episode: 5239, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000086, mae: 0.004331, mean_q: 0.004699
 49779/100000: episode: 5240, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002798, mean_q: 0.004397
 49789/100000: episode: 5241, duration: 0.082s, episode steps: 10, steps per second: 123, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000043, mae: 0.002916, mean_q: 0.004022
 49799/100000: episode: 5242, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000076, mae: 0.003915, mean_q: 0.004371
 49809/100000: episode: 5243, duration: 0.106s, episode steps: 10, steps per second: 94, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.003827, mean_q: 0.005594
 49819/100000: episode: 5244, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000071, mae: 0.003593, mean_q: 0.004190
 49829/100000: episode: 5245, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000046, mae: 0.003483, mean_q: 0.004649
 49839/100000: episode: 5246, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000073, mae: 0.004062, mean_q: 0.005023
 49849/100000: episode: 5247, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003459, mean_q: 0.004771
 49859/100000: episode: 5248, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.003883, mean_q: 0.004520
 49869/100000: episode: 5249, duration: 0.077s, episode steps: 10, steps per second: 131, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000041, mae: 0.003587, mean_q: 0.005178
 49879/100000: episode: 5250, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000018, mae: 0.002652, mean_q: 0.003614
 49889/100000: episode: 5251, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000040, mae: 0.003107, mean_q: 0.004161
 49899/100000: episode: 5252, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003692, mean_q: 0.004948
 49909/100000: episode: 5253, duration: 0.114s, episode steps: 10, steps per second: 88, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000029, mae: 0.003351, mean_q: 0.004359
 49919/100000: episode: 5254, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000043, mae: 0.003207, mean_q: 0.004606
 49929/100000: episode: 5255, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000043, mae: 0.002969, mean_q: 0.003713
[Info] 1-TH LEVEL FOUND: 0.005333379376679659, Considering 100/100 traces
 49939/100000: episode: 5256, duration: 1.226s, episode steps: 10, steps per second: 8, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000072, mae: 0.003924, mean_q: 0.004918
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005333379376679659
 49949/100000: episode: 5257, duration: 0.701s, episode steps: 10, steps per second: 14, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000022, mae: 0.003135, mean_q: 0.004372
 49959/100000: episode: 5258, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.002771, mean_q: 0.004176
 49969/100000: episode: 5259, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000039, mae: 0.003242, mean_q: 0.004507
 49979/100000: episode: 5260, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000040, mae: 0.003418, mean_q: 0.004762
 49989/100000: episode: 5261, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000013, mae: 0.002452, mean_q: 0.003937
 49999/100000: episode: 5262, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000024, mae: 0.003145, mean_q: 0.004311
 50009/100000: episode: 5263, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000036, mae: 0.003116, mean_q: 0.004408
 50019/100000: episode: 5264, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000049, mae: 0.003414, mean_q: 0.004145
 50029/100000: episode: 5265, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003767, mean_q: 0.004987
 50039/100000: episode: 5266, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000032, mae: 0.003728, mean_q: 0.004644
 50049/100000: episode: 5267, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000038, mae: 0.003454, mean_q: 0.005031
 50059/100000: episode: 5268, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000071, mae: 0.003180, mean_q: 0.003894
 50069/100000: episode: 5269, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003299, mean_q: 0.004550
 50079/100000: episode: 5270, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000068, mae: 0.003692, mean_q: 0.004409
 50089/100000: episode: 5271, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000016, mae: 0.002780, mean_q: 0.004315
 50099/100000: episode: 5272, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000010, mae: 0.002613, mean_q: 0.004258
 50109/100000: episode: 5273, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000010, mae: 0.002097, mean_q: 0.003168
 50119/100000: episode: 5274, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000058, mae: 0.003965, mean_q: 0.004653
 50129/100000: episode: 5275, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000050, mae: 0.004030, mean_q: 0.004936
 50139/100000: episode: 5276, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.003136, mean_q: 0.004318
 50149/100000: episode: 5277, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000072, mae: 0.004228, mean_q: 0.005346
 50159/100000: episode: 5278, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000010, mae: 0.002281, mean_q: 0.003859
 50169/100000: episode: 5279, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000068, mae: 0.003133, mean_q: 0.003869
 50179/100000: episode: 5280, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000029, mae: 0.003763, mean_q: 0.004952
 50189/100000: episode: 5281, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000026, mae: 0.003327, mean_q: 0.004388
 50199/100000: episode: 5282, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000012, mae: 0.003168, mean_q: 0.005061
 50209/100000: episode: 5283, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000013, mae: 0.002678, mean_q: 0.004173
 50219/100000: episode: 5284, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000073, mae: 0.004006, mean_q: 0.004810
 50229/100000: episode: 5285, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000076, mae: 0.004133, mean_q: 0.004779
 50239/100000: episode: 5286, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000089, mae: 0.005249, mean_q: 0.005430
 50249/100000: episode: 5287, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.003375, mean_q: 0.005119
 50259/100000: episode: 5288, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000038, mae: 0.002343, mean_q: 0.003061
 50269/100000: episode: 5289, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000018, mae: 0.003292, mean_q: 0.004944
 50279/100000: episode: 5290, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.002701, mean_q: 0.003821
 50289/100000: episode: 5291, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000043, mae: 0.002931, mean_q: 0.003784
 50299/100000: episode: 5292, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000008, mae: 0.002296, mean_q: 0.004353
 50309/100000: episode: 5293, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000027, mae: 0.002985, mean_q: 0.003525
 50319/100000: episode: 5294, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000027, mae: 0.004007, mean_q: 0.005218
 50329/100000: episode: 5295, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000075, mae: 0.003780, mean_q: 0.004325
 50339/100000: episode: 5296, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.003013, mean_q: 0.004523
 50349/100000: episode: 5297, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000056, mae: 0.003948, mean_q: 0.004686
 50359/100000: episode: 5298, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000063, mae: 0.004746, mean_q: 0.005452
 50369/100000: episode: 5299, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000014, mae: 0.002602, mean_q: 0.004130
 50379/100000: episode: 5300, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000078, mae: 0.003782, mean_q: 0.003986
 50389/100000: episode: 5301, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000054, mae: 0.004680, mean_q: 0.005870
 50399/100000: episode: 5302, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000066, mae: 0.003577, mean_q: 0.004603
 50409/100000: episode: 5303, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000051, mae: 0.003673, mean_q: 0.004780
 50419/100000: episode: 5304, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000012, mae: 0.002717, mean_q: 0.004185
 50429/100000: episode: 5305, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000048, mae: 0.003117, mean_q: 0.003897
 50439/100000: episode: 5306, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000049, mae: 0.003797, mean_q: 0.004750
 50449/100000: episode: 5307, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000035, mae: 0.003095, mean_q: 0.004782
 50459/100000: episode: 5308, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002371, mean_q: 0.003459
 50469/100000: episode: 5309, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000028, mae: 0.003672, mean_q: 0.004898
 50479/100000: episode: 5310, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000012, mae: 0.002495, mean_q: 0.004088
 50489/100000: episode: 5311, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000045, mae: 0.002882, mean_q: 0.003556
 50499/100000: episode: 5312, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000032, mae: 0.003854, mean_q: 0.004883
 50509/100000: episode: 5313, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000012, mae: 0.002834, mean_q: 0.004288
 50519/100000: episode: 5314, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000007, mae: 0.001886, mean_q: 0.003230
 50529/100000: episode: 5315, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.002625, mean_q: 0.003994
 50539/100000: episode: 5316, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000029, mae: 0.003491, mean_q: 0.004155
 50549/100000: episode: 5317, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.004311, mean_q: 0.005216
 50559/100000: episode: 5318, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000040, mae: 0.003272, mean_q: 0.004592
 50569/100000: episode: 5319, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000047, mae: 0.003379, mean_q: 0.003947
 50579/100000: episode: 5320, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002852, mean_q: 0.004499
 50589/100000: episode: 5321, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000093, mae: 0.004991, mean_q: 0.005106
 50599/100000: episode: 5322, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000014, mae: 0.002845, mean_q: 0.004669
 50609/100000: episode: 5323, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003091, mean_q: 0.003422
 50619/100000: episode: 5324, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000016, mae: 0.003123, mean_q: 0.004577
 50629/100000: episode: 5325, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000045, mae: 0.003004, mean_q: 0.003710
 50639/100000: episode: 5326, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000010, mae: 0.002717, mean_q: 0.004492
 50649/100000: episode: 5327, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000038, mae: 0.002407, mean_q: 0.003217
 50659/100000: episode: 5328, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003707, mean_q: 0.005145
 50669/100000: episode: 5329, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000012, mae: 0.002404, mean_q: 0.003812
 50679/100000: episode: 5330, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003101, mean_q: 0.003939
 50689/100000: episode: 5331, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000010, mae: 0.002610, mean_q: 0.004314
 50699/100000: episode: 5332, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002681, mean_q: 0.003652
 50709/100000: episode: 5333, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000029, mae: 0.003594, mean_q: 0.004439
 50719/100000: episode: 5334, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002702, mean_q: 0.004092
 50729/100000: episode: 5335, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.003096, mean_q: 0.004344
 50739/100000: episode: 5336, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000009, mae: 0.002002, mean_q: 0.003279
 50749/100000: episode: 5337, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000011, mae: 0.002505, mean_q: 0.003972
 50759/100000: episode: 5338, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002578, mean_q: 0.004023
 50769/100000: episode: 5339, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000020, mae: 0.002443, mean_q: 0.003218
 50779/100000: episode: 5340, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.004098, mean_q: 0.005369
 50789/100000: episode: 5341, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002457, mean_q: 0.003529
 50799/100000: episode: 5342, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000031, mae: 0.003226, mean_q: 0.004042
 50809/100000: episode: 5343, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000041, mae: 0.003122, mean_q: 0.004286
 50819/100000: episode: 5344, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000036, mae: 0.003949, mean_q: 0.004603
 50829/100000: episode: 5345, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000011, mae: 0.002736, mean_q: 0.004465
 50839/100000: episode: 5346, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000022, mae: 0.003100, mean_q: 0.003641
 50849/100000: episode: 5347, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000018, mae: 0.002999, mean_q: 0.004239
 50859/100000: episode: 5348, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000046, mae: 0.003092, mean_q: 0.003594
 50869/100000: episode: 5349, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000009, mae: 0.002407, mean_q: 0.004110
 50879/100000: episode: 5350, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.003098, mean_q: 0.003408
 50889/100000: episode: 5351, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000011, mae: 0.002890, mean_q: 0.004432
 50899/100000: episode: 5352, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000010, mae: 0.002201, mean_q: 0.003363
 50909/100000: episode: 5353, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000020, mae: 0.002856, mean_q: 0.003965
 50919/100000: episode: 5354, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000035, mae: 0.002908, mean_q: 0.003885
 50929/100000: episode: 5355, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000035, mae: 0.002976, mean_q: 0.004100
 50939/100000: episode: 5356, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003447, mean_q: 0.004169
[Info] 1-TH LEVEL FOUND: 0.003676437307149172, Considering 100/100 traces
 50949/100000: episode: 5357, duration: 1.265s, episode steps: 10, steps per second: 8, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003038, mean_q: 0.003969
[Info] 2-TH LEVEL FOUND: 0.0036947119515389204, Considering 100/100 traces
 50959/100000: episode: 5358, duration: 0.815s, episode steps: 10, steps per second: 12, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.002788, mean_q: 0.003985
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0036947119515389204
 50969/100000: episode: 5359, duration: 0.480s, episode steps: 10, steps per second: 21, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000008, mae: 0.002224, mean_q: 0.003376
 50979/100000: episode: 5360, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000034, mae: 0.003367, mean_q: 0.003944
 50989/100000: episode: 5361, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003381, mean_q: 0.004599
 50999/100000: episode: 5362, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000006, mae: 0.001797, mean_q: 0.003103
 51009/100000: episode: 5363, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000019, mae: 0.002879, mean_q: 0.003524
 51019/100000: episode: 5364, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000072, mae: 0.004297, mean_q: 0.005127
 51029/100000: episode: 5365, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000016, mae: 0.002533, mean_q: 0.003789
 51039/100000: episode: 5366, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000020, mae: 0.002353, mean_q: 0.002982
 51049/100000: episode: 5367, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000032, mae: 0.004164, mean_q: 0.005239
 51059/100000: episode: 5368, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000032, mae: 0.003246, mean_q: 0.003440
 51069/100000: episode: 5369, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000053, mae: 0.003900, mean_q: 0.004892
 51079/100000: episode: 5370, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000052, mae: 0.003530, mean_q: 0.003837
 51089/100000: episode: 5371, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000048, mae: 0.004227, mean_q: 0.005484
 51099/100000: episode: 5372, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000009, mae: 0.002753, mean_q: 0.004135
 51109/100000: episode: 5373, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000036, mae: 0.002542, mean_q: 0.003181
 51119/100000: episode: 5374, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000027, mae: 0.004098, mean_q: 0.005211
 51129/100000: episode: 5375, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000026, mae: 0.002988, mean_q: 0.003544
 51139/100000: episode: 5376, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000028, mae: 0.003457, mean_q: 0.004483
 51149/100000: episode: 5377, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000082, mae: 0.004783, mean_q: 0.005380
 51159/100000: episode: 5378, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.002928, mean_q: 0.003832
 51169/100000: episode: 5379, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000047, mae: 0.003611, mean_q: 0.004496
 51179/100000: episode: 5380, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003420, mean_q: 0.004958
 51189/100000: episode: 5381, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000044, mae: 0.003405, mean_q: 0.004094
 51199/100000: episode: 5382, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003623, mean_q: 0.004593
 51209/100000: episode: 5383, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000017, mae: 0.002494, mean_q: 0.003617
 51219/100000: episode: 5384, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000046, mae: 0.003508, mean_q: 0.004287
 51229/100000: episode: 5385, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000013, mae: 0.002630, mean_q: 0.004264
 51239/100000: episode: 5386, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000034, mae: 0.002127, mean_q: 0.002934
 51249/100000: episode: 5387, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000030, mae: 0.004044, mean_q: 0.005040
 51259/100000: episode: 5388, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000082, mae: 0.004409, mean_q: 0.004775
 51269/100000: episode: 5389, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002735, mean_q: 0.004084
 51279/100000: episode: 5390, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000053, mae: 0.003720, mean_q: 0.004168
 51289/100000: episode: 5391, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000075, mae: 0.004619, mean_q: 0.005541
 51299/100000: episode: 5392, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000048, mae: 0.003079, mean_q: 0.003922
 51309/100000: episode: 5393, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000024, mae: 0.003384, mean_q: 0.004378
 51319/100000: episode: 5394, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000010, mae: 0.002608, mean_q: 0.004243
 51329/100000: episode: 5395, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000054, mae: 0.003315, mean_q: 0.003825
 51339/100000: episode: 5396, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000041, mae: 0.003306, mean_q: 0.004631
 51349/100000: episode: 5397, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000031, mae: 0.003520, mean_q: 0.003876
 51359/100000: episode: 5398, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.004334, mean_q: 0.005433
 51369/100000: episode: 5399, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000016, mae: 0.002977, mean_q: 0.004399
 51379/100000: episode: 5400, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000013, mae: 0.002573, mean_q: 0.004106
 51389/100000: episode: 5401, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000020, mae: 0.002518, mean_q: 0.003590
 51399/100000: episode: 5402, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.003533, mean_q: 0.004591
 51409/100000: episode: 5403, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000013, mae: 0.002327, mean_q: 0.003681
 51419/100000: episode: 5404, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000041, mae: 0.003146, mean_q: 0.004179
 51429/100000: episode: 5405, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.002778, mean_q: 0.003942
 51439/100000: episode: 5406, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000013, mae: 0.002386, mean_q: 0.003752
 51449/100000: episode: 5407, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000040, mae: 0.002925, mean_q: 0.004212
 51459/100000: episode: 5408, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000035, mae: 0.002386, mean_q: 0.003133
 51469/100000: episode: 5409, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000048, mae: 0.003982, mean_q: 0.004984
 51479/100000: episode: 5410, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000059, mae: 0.004273, mean_q: 0.004853
 51489/100000: episode: 5411, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000047, mae: 0.003629, mean_q: 0.004404
 51499/100000: episode: 5412, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000044, mae: 0.003544, mean_q: 0.004428
 51509/100000: episode: 5413, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000028, mae: 0.003609, mean_q: 0.004828
 51519/100000: episode: 5414, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000060, mae: 0.004356, mean_q: 0.004957
 51529/100000: episode: 5415, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.002523, mean_q: 0.003721
 51539/100000: episode: 5416, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000013, mae: 0.002506, mean_q: 0.003942
 51549/100000: episode: 5417, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000056, mae: 0.004005, mean_q: 0.004728
 51559/100000: episode: 5418, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002507, mean_q: 0.004000
 51569/100000: episode: 5419, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000024, mae: 0.002759, mean_q: 0.003733
 51579/100000: episode: 5420, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000008, mae: 0.002176, mean_q: 0.004012
 51589/100000: episode: 5421, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.002601, mean_q: 0.003676
 51599/100000: episode: 5422, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.002492, mean_q: 0.003555
 51609/100000: episode: 5423, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000020, mae: 0.002789, mean_q: 0.004011
 51619/100000: episode: 5424, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000026, mae: 0.003521, mean_q: 0.004509
 51629/100000: episode: 5425, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000018, mae: 0.003100, mean_q: 0.004451
 51639/100000: episode: 5426, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000040, mae: 0.002968, mean_q: 0.003655
 51649/100000: episode: 5427, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003266, mean_q: 0.004635
 51659/100000: episode: 5428, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.002462, mean_q: 0.003484
 51669/100000: episode: 5429, duration: 0.093s, episode steps: 10, steps per second: 107, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000058, mae: 0.004266, mean_q: 0.004643
 51679/100000: episode: 5430, duration: 0.123s, episode steps: 10, steps per second: 82, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000019, mae: 0.003752, mean_q: 0.005343
 51689/100000: episode: 5431, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000030, mae: 0.003176, mean_q: 0.003368
 51699/100000: episode: 5432, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000010, mae: 0.003253, mean_q: 0.005010
 51709/100000: episode: 5433, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000018, mae: 0.002423, mean_q: 0.003305
 51719/100000: episode: 5434, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000014, mae: 0.002590, mean_q: 0.004028
 51729/100000: episode: 5435, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000011, mae: 0.002424, mean_q: 0.003808
 51739/100000: episode: 5436, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000011, mae: 0.002845, mean_q: 0.004240
 51749/100000: episode: 5437, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000029, mae: 0.003377, mean_q: 0.004214
 51759/100000: episode: 5438, duration: 0.074s, episode steps: 10, steps per second: 134, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002558, mean_q: 0.003699
 51769/100000: episode: 5439, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000021, mae: 0.002919, mean_q: 0.003932
 51779/100000: episode: 5440, duration: 0.091s, episode steps: 10, steps per second: 109, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000010, mae: 0.002523, mean_q: 0.003957
 51789/100000: episode: 5441, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000067, mae: 0.003360, mean_q: 0.003955
 51799/100000: episode: 5442, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000044, mae: 0.003038, mean_q: 0.003974
 51809/100000: episode: 5443, duration: 0.123s, episode steps: 10, steps per second: 82, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000045, mae: 0.003162, mean_q: 0.003984
 51819/100000: episode: 5444, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000023, mae: 0.003324, mean_q: 0.004355
 51829/100000: episode: 5445, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000040, mae: 0.003329, mean_q: 0.004442
 51839/100000: episode: 5446, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000009, mae: 0.002331, mean_q: 0.003540
 51849/100000: episode: 5447, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000015, mae: 0.003093, mean_q: 0.004428
 51859/100000: episode: 5448, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.003898, mean_q: 0.004527
 51869/100000: episode: 5449, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000047, mae: 0.003474, mean_q: 0.004631
 51879/100000: episode: 5450, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000021, mae: 0.003197, mean_q: 0.004650
 51889/100000: episode: 5451, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002366, mean_q: 0.003419
 51899/100000: episode: 5452, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000041, mae: 0.003088, mean_q: 0.004154
 51909/100000: episode: 5453, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000039, mae: 0.002896, mean_q: 0.003937
 51919/100000: episode: 5454, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000081, mae: 0.004564, mean_q: 0.004930
 51929/100000: episode: 5455, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000031, mae: 0.003852, mean_q: 0.005043
 51939/100000: episode: 5456, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000068, mae: 0.003512, mean_q: 0.004434
 51949/100000: episode: 5457, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000052, mae: 0.004269, mean_q: 0.005037
 51959/100000: episode: 5458, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000010, mae: 0.002386, mean_q: 0.003903
[Info] 1-TH LEVEL FOUND: 0.0047148047015070915, Considering 100/100 traces
 51969/100000: episode: 5459, duration: 0.698s, episode steps: 10, steps per second: 14, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000021, mae: 0.002799, mean_q: 0.003611
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0047148047015070915
 51979/100000: episode: 5460, duration: 0.477s, episode steps: 10, steps per second: 21, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000027, mae: 0.004247, mean_q: 0.005594
 51989/100000: episode: 5461, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000007, mae: 0.001997, mean_q: 0.003183
 51999/100000: episode: 5462, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002657, mean_q: 0.003960
 52009/100000: episode: 5463, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000013, mae: 0.002293, mean_q: 0.003451
 52019/100000: episode: 5464, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000039, mae: 0.003136, mean_q: 0.004309
 52029/100000: episode: 5465, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000010, mae: 0.002240, mean_q: 0.003659
 52039/100000: episode: 5466, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000008, mae: 0.002328, mean_q: 0.003643
 52049/100000: episode: 5467, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000073, mae: 0.003778, mean_q: 0.004186
 52059/100000: episode: 5468, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000029, mae: 0.004204, mean_q: 0.005368
 52069/100000: episode: 5469, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000007, mae: 0.001777, mean_q: 0.003065
 52079/100000: episode: 5470, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002341, mean_q: 0.003324
 52089/100000: episode: 5471, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002653, mean_q: 0.004188
 52099/100000: episode: 5472, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000018, mae: 0.003016, mean_q: 0.004181
 52109/100000: episode: 5473, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002642, mean_q: 0.003888
 52119/100000: episode: 5474, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000067, mae: 0.004218, mean_q: 0.005193
 52129/100000: episode: 5475, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000025, mae: 0.003022, mean_q: 0.003855
 52139/100000: episode: 5476, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000053, mae: 0.003888, mean_q: 0.004502
 52149/100000: episode: 5477, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000072, mae: 0.003910, mean_q: 0.004656
 52159/100000: episode: 5478, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000047, mae: 0.003841, mean_q: 0.004803
 52169/100000: episode: 5479, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000042, mae: 0.003131, mean_q: 0.004110
 52179/100000: episode: 5480, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000025, mae: 0.002853, mean_q: 0.003757
 52189/100000: episode: 5481, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000013, mae: 0.002810, mean_q: 0.004279
 52199/100000: episode: 5482, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000046, mae: 0.002953, mean_q: 0.003524
 52209/100000: episode: 5483, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002983, mean_q: 0.004505
 52219/100000: episode: 5484, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000077, mae: 0.004737, mean_q: 0.005236
 52229/100000: episode: 5485, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002306, mean_q: 0.003395
 52239/100000: episode: 5486, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000008, mae: 0.002339, mean_q: 0.003600
 52249/100000: episode: 5487, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002773, mean_q: 0.004197
 52259/100000: episode: 5488, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002562, mean_q: 0.003657
 52269/100000: episode: 5489, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000039, mae: 0.002805, mean_q: 0.004066
 52279/100000: episode: 5490, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000013, mae: 0.002420, mean_q: 0.003732
 52289/100000: episode: 5491, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003099, mean_q: 0.003814
 52299/100000: episode: 5492, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000046, mae: 0.003329, mean_q: 0.003871
 52309/100000: episode: 5493, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000094, mae: 0.004435, mean_q: 0.005129
 52319/100000: episode: 5494, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.003120, mean_q: 0.004458
 52329/100000: episode: 5495, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000069, mae: 0.003490, mean_q: 0.004035
 52339/100000: episode: 5496, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.002806, mean_q: 0.004122
 52349/100000: episode: 5497, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000039, mae: 0.003090, mean_q: 0.004285
 52359/100000: episode: 5498, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000052, mae: 0.003548, mean_q: 0.004259
 52369/100000: episode: 5499, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000023, mae: 0.003403, mean_q: 0.004438
 52379/100000: episode: 5500, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.003135, mean_q: 0.004048
 52389/100000: episode: 5501, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.003052, mean_q: 0.004674
 52399/100000: episode: 5502, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000039, mae: 0.003005, mean_q: 0.003872
 52409/100000: episode: 5503, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000017, mae: 0.002479, mean_q: 0.003770
 52419/100000: episode: 5504, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000006, mae: 0.002242, mean_q: 0.004054
 52429/100000: episode: 5505, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.002330, mean_q: 0.002730
 52439/100000: episode: 5506, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000012, mae: 0.003014, mean_q: 0.004534
 52449/100000: episode: 5507, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000018, mae: 0.002875, mean_q: 0.003962
 52459/100000: episode: 5508, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.002777, mean_q: 0.003763
 52469/100000: episode: 5509, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000013, mae: 0.002454, mean_q: 0.003758
 52479/100000: episode: 5510, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000009, mae: 0.002268, mean_q: 0.003536
 52489/100000: episode: 5511, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000011, mae: 0.002727, mean_q: 0.003620
 52499/100000: episode: 5512, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.002892, mean_q: 0.003910
 52509/100000: episode: 5513, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002665, mean_q: 0.003781
 52519/100000: episode: 5514, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000006, mae: 0.002066, mean_q: 0.003518
 52529/100000: episode: 5515, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000018, mae: 0.002531, mean_q: 0.003429
 52539/100000: episode: 5516, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000010, mae: 0.002504, mean_q: 0.003961
 52549/100000: episode: 5517, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000074, mae: 0.003405, mean_q: 0.003379
 52559/100000: episode: 5518, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000022, mae: 0.003794, mean_q: 0.005210
 52569/100000: episode: 5519, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002413, mean_q: 0.003159
 52579/100000: episode: 5520, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003428, mean_q: 0.004466
 52589/100000: episode: 5521, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000038, mae: 0.002782, mean_q: 0.003654
 52599/100000: episode: 5522, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000015, mae: 0.002136, mean_q: 0.003100
 52609/100000: episode: 5523, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000047, mae: 0.003583, mean_q: 0.004281
 52619/100000: episode: 5524, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.002767, mean_q: 0.004064
 52629/100000: episode: 5525, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000053, mae: 0.003459, mean_q: 0.003753
 52639/100000: episode: 5526, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000011, mae: 0.002731, mean_q: 0.004301
 52649/100000: episode: 5527, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000053, mae: 0.003602, mean_q: 0.003968
 52659/100000: episode: 5528, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000032, mae: 0.003929, mean_q: 0.004830
 52669/100000: episode: 5529, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000010, mae: 0.002544, mean_q: 0.004054
 52679/100000: episode: 5530, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000042, mae: 0.002948, mean_q: 0.003576
 52689/100000: episode: 5531, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000021, mae: 0.002931, mean_q: 0.004065
 52699/100000: episode: 5532, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000048, mae: 0.003455, mean_q: 0.004391
 52709/100000: episode: 5533, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002297, mean_q: 0.003838
 52719/100000: episode: 5534, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000058, mae: 0.003661, mean_q: 0.003588
 52729/100000: episode: 5535, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.004337, mean_q: 0.005782
 52739/100000: episode: 5536, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000057, mae: 0.003573, mean_q: 0.003773
 52749/100000: episode: 5537, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000041, mae: 0.003429, mean_q: 0.004834
 52759/100000: episode: 5538, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000047, mae: 0.003146, mean_q: 0.003507
 52769/100000: episode: 5539, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000024, mae: 0.003357, mean_q: 0.004604
 52779/100000: episode: 5540, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000043, mae: 0.002813, mean_q: 0.003400
 52789/100000: episode: 5541, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000012, mae: 0.002959, mean_q: 0.004329
 52799/100000: episode: 5542, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000010, mae: 0.002022, mean_q: 0.003213
 52809/100000: episode: 5543, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000039, mae: 0.003372, mean_q: 0.004450
 52819/100000: episode: 5544, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000043, mae: 0.003060, mean_q: 0.004124
 52829/100000: episode: 5545, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002279, mean_q: 0.003421
 52839/100000: episode: 5546, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000024, mae: 0.003157, mean_q: 0.004136
 52849/100000: episode: 5547, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000008, mae: 0.002016, mean_q: 0.003590
 52859/100000: episode: 5548, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000052, mae: 0.002938, mean_q: 0.003075
 52869/100000: episode: 5549, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000041, mae: 0.003832, mean_q: 0.004988
 52879/100000: episode: 5550, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000026, mae: 0.003334, mean_q: 0.004159
 52889/100000: episode: 5551, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000012, mae: 0.002453, mean_q: 0.003475
 52899/100000: episode: 5552, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000097, mae: 0.004350, mean_q: 0.004519
 52909/100000: episode: 5553, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.003067, mean_q: 0.004604
 52919/100000: episode: 5554, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.002885, mean_q: 0.003010
 52929/100000: episode: 5555, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000036, mae: 0.003576, mean_q: 0.005101
 52939/100000: episode: 5556, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000036, mae: 0.002439, mean_q: 0.003070
 52949/100000: episode: 5557, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000010, mae: 0.002762, mean_q: 0.004381
 52959/100000: episode: 5558, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000027, mae: 0.003434, mean_q: 0.004477
 52969/100000: episode: 5559, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002800, mean_q: 0.004090
[Info] 1-TH LEVEL FOUND: 0.003956177271902561, Considering 100/100 traces
 52979/100000: episode: 5560, duration: 0.656s, episode steps: 10, steps per second: 15, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000016, mae: 0.003150, mean_q: 0.004385
[Info] 2-TH LEVEL FOUND: 0.004696022253483534, Considering 100/100 traces
 52989/100000: episode: 5561, duration: 0.971s, episode steps: 10, steps per second: 10, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000074, mae: 0.004118, mean_q: 0.004668
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004696022253483534
 52999/100000: episode: 5562, duration: 0.838s, episode steps: 10, steps per second: 12, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000019, mae: 0.002798, mean_q: 0.003562
 53009/100000: episode: 5563, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000011, mae: 0.002596, mean_q: 0.004024
 53019/100000: episode: 5564, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000025, mae: 0.002985, mean_q: 0.003777
 53029/100000: episode: 5565, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000007, mae: 0.002165, mean_q: 0.003553
 53039/100000: episode: 5566, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.002983, mean_q: 0.004016
 53049/100000: episode: 5567, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000044, mae: 0.003234, mean_q: 0.003937
 53059/100000: episode: 5568, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000018, mae: 0.003237, mean_q: 0.004787
 53069/100000: episode: 5569, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002382, mean_q: 0.003527
 53079/100000: episode: 5570, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000015, mae: 0.002878, mean_q: 0.004390
 53089/100000: episode: 5571, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000009, mae: 0.001841, mean_q: 0.002920
 53099/100000: episode: 5572, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000008, mae: 0.001826, mean_q: 0.003234
 53109/100000: episode: 5573, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.003688, mean_q: 0.004282
 53119/100000: episode: 5574, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.003137, mean_q: 0.004286
 53129/100000: episode: 5575, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000024, mae: 0.003099, mean_q: 0.003919
 53139/100000: episode: 5576, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003288, mean_q: 0.003928
 53149/100000: episode: 5577, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003411, mean_q: 0.004332
 53159/100000: episode: 5578, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000011, mae: 0.002413, mean_q: 0.003658
 53169/100000: episode: 5579, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000029, mae: 0.003548, mean_q: 0.004292
 53179/100000: episode: 5580, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000018, mae: 0.002801, mean_q: 0.003921
 53189/100000: episode: 5581, duration: 0.124s, episode steps: 10, steps per second: 81, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000013, mae: 0.002174, mean_q: 0.003236
 53199/100000: episode: 5582, duration: 0.161s, episode steps: 10, steps per second: 62, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.002890, mean_q: 0.004047
 53209/100000: episode: 5583, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000013, mae: 0.002553, mean_q: 0.003934
 53219/100000: episode: 5584, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003198, mean_q: 0.003616
 53229/100000: episode: 5585, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000017, mae: 0.003021, mean_q: 0.004378
 53239/100000: episode: 5586, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000008, mae: 0.002035, mean_q: 0.003114
 53249/100000: episode: 5587, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000052, mae: 0.003894, mean_q: 0.004179
 53259/100000: episode: 5588, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003792, mean_q: 0.004811
 53269/100000: episode: 5589, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.002277, mean_q: 0.003394
 53279/100000: episode: 5590, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003065, mean_q: 0.004025
 53289/100000: episode: 5591, duration: 0.105s, episode steps: 10, steps per second: 95, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000032, mae: 0.003406, mean_q: 0.003851
 53299/100000: episode: 5592, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000073, mae: 0.004154, mean_q: 0.004674
 53309/100000: episode: 5593, duration: 0.118s, episode steps: 10, steps per second: 85, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000040, mae: 0.003248, mean_q: 0.004379
 53319/100000: episode: 5594, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000019, mae: 0.002951, mean_q: 0.003873
 53329/100000: episode: 5595, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000032, mae: 0.004065, mean_q: 0.004958
 53339/100000: episode: 5596, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000052, mae: 0.003632, mean_q: 0.004418
 53349/100000: episode: 5597, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000048, mae: 0.003463, mean_q: 0.004474
 53359/100000: episode: 5598, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000066, mae: 0.004415, mean_q: 0.004680
 53369/100000: episode: 5599, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.002998, mean_q: 0.004449
 53379/100000: episode: 5600, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000074, mae: 0.003970, mean_q: 0.004397
 53389/100000: episode: 5601, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000051, mae: 0.004267, mean_q: 0.005437
 53399/100000: episode: 5602, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000025, mae: 0.002763, mean_q: 0.003474
 53409/100000: episode: 5603, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003380, mean_q: 0.004599
 53419/100000: episode: 5604, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000024, mae: 0.003639, mean_q: 0.005134
 53429/100000: episode: 5605, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000051, mae: 0.004162, mean_q: 0.005157
 53439/100000: episode: 5606, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003180, mean_q: 0.004319
 53449/100000: episode: 5607, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002527, mean_q: 0.003989
 53459/100000: episode: 5608, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000076, mae: 0.004071, mean_q: 0.004798
 53469/100000: episode: 5609, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000050, mae: 0.004064, mean_q: 0.005088
 53479/100000: episode: 5610, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002807, mean_q: 0.004416
 53489/100000: episode: 5611, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.002789, mean_q: 0.003754
 53499/100000: episode: 5612, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.003349, mean_q: 0.004816
 53509/100000: episode: 5613, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000037, mae: 0.002470, mean_q: 0.003597
 53519/100000: episode: 5614, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.002775, mean_q: 0.003831
 53529/100000: episode: 5615, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000028, mae: 0.003437, mean_q: 0.004503
 53539/100000: episode: 5616, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000013, mae: 0.002340, mean_q: 0.003789
 53549/100000: episode: 5617, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000038, mae: 0.002857, mean_q: 0.003994
 53559/100000: episode: 5618, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.003605, mean_q: 0.004439
 53569/100000: episode: 5619, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002781, mean_q: 0.004125
 53579/100000: episode: 5620, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000027, mae: 0.003375, mean_q: 0.003863
 53589/100000: episode: 5621, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000023, mae: 0.003246, mean_q: 0.004278
 53599/100000: episode: 5622, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000033, mae: 0.004102, mean_q: 0.005027
 53609/100000: episode: 5623, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000058, mae: 0.004145, mean_q: 0.004504
 53619/100000: episode: 5624, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.003664, mean_q: 0.005396
 53629/100000: episode: 5625, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000030, mae: 0.002870, mean_q: 0.003602
 53639/100000: episode: 5626, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000042, mae: 0.003514, mean_q: 0.004801
 53649/100000: episode: 5627, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000060, mae: 0.004055, mean_q: 0.004508
 53659/100000: episode: 5628, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.002853, mean_q: 0.003846
 53669/100000: episode: 5629, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000018, mae: 0.003054, mean_q: 0.004550
 53679/100000: episode: 5630, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.002911, mean_q: 0.004415
 53689/100000: episode: 5631, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000024, mae: 0.003264, mean_q: 0.004601
 53699/100000: episode: 5632, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000024, mae: 0.002920, mean_q: 0.003917
 53709/100000: episode: 5633, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000027, mae: 0.003462, mean_q: 0.004648
 53719/100000: episode: 5634, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000017, mae: 0.002704, mean_q: 0.004113
 53729/100000: episode: 5635, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000015, mae: 0.002371, mean_q: 0.003722
 53739/100000: episode: 5636, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000068, mae: 0.003165, mean_q: 0.003925
 53749/100000: episode: 5637, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.003474, mean_q: 0.004761
 53759/100000: episode: 5638, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002827, mean_q: 0.003998
 53769/100000: episode: 5639, duration: 0.133s, episode steps: 10, steps per second: 75, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000019, mae: 0.003000, mean_q: 0.004003
 53779/100000: episode: 5640, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000070, mae: 0.003470, mean_q: 0.004276
 53789/100000: episode: 5641, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000027, mae: 0.004100, mean_q: 0.005286
 53799/100000: episode: 5642, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000027, mae: 0.003631, mean_q: 0.004599
 53809/100000: episode: 5643, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003534, mean_q: 0.004784
 53819/100000: episode: 5644, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000013, mae: 0.002492, mean_q: 0.003873
 53829/100000: episode: 5645, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002534, mean_q: 0.003715
 53839/100000: episode: 5646, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000044, mae: 0.003221, mean_q: 0.004324
 53849/100000: episode: 5647, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.002935, mean_q: 0.003833
 53859/100000: episode: 5648, duration: 0.128s, episode steps: 10, steps per second: 78, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000020, mae: 0.003241, mean_q: 0.004430
 53869/100000: episode: 5649, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000032, mae: 0.003511, mean_q: 0.004259
 53879/100000: episode: 5650, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000014, mae: 0.002514, mean_q: 0.003733
 53889/100000: episode: 5651, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000039, mae: 0.003135, mean_q: 0.004425
 53899/100000: episode: 5652, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003112, mean_q: 0.004372
 53909/100000: episode: 5653, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000013, mae: 0.002450, mean_q: 0.003778
 53919/100000: episode: 5654, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000027, mae: 0.003648, mean_q: 0.004496
 53929/100000: episode: 5655, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.002944, mean_q: 0.003865
 53939/100000: episode: 5656, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000085, mae: 0.004861, mean_q: 0.005033
 53949/100000: episode: 5657, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003709, mean_q: 0.005039
 53959/100000: episode: 5658, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000028, mae: 0.002918, mean_q: 0.003608
 53969/100000: episode: 5659, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000007, mae: 0.002394, mean_q: 0.004255
 53979/100000: episode: 5660, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.002647, mean_q: 0.003411
 53989/100000: episode: 5661, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003998, mean_q: 0.005286
[Info] 1-TH LEVEL FOUND: 0.005293495953083038, Considering 100/100 traces
 53999/100000: episode: 5662, duration: 0.704s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000077, mae: 0.003611, mean_q: 0.003969
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005293495953083038
 54009/100000: episode: 5663, duration: 0.476s, episode steps: 10, steps per second: 21, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003844, mean_q: 0.005081
 54019/100000: episode: 5664, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000080, mae: 0.004076, mean_q: 0.004385
 54029/100000: episode: 5665, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000022, mae: 0.004080, mean_q: 0.005474
 54039/100000: episode: 5666, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000045, mae: 0.003271, mean_q: 0.003956
 54049/100000: episode: 5667, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000027, mae: 0.004081, mean_q: 0.005303
 54059/100000: episode: 5668, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.002460, mean_q: 0.003644
 54069/100000: episode: 5669, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000041, mae: 0.002957, mean_q: 0.004041
 54079/100000: episode: 5670, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003487, mean_q: 0.004984
 54089/100000: episode: 5671, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000054, mae: 0.003862, mean_q: 0.004453
 54099/100000: episode: 5672, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000046, mae: 0.003520, mean_q: 0.004685
 54109/100000: episode: 5673, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.002699, mean_q: 0.003622
 54119/100000: episode: 5674, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000026, mae: 0.003515, mean_q: 0.004522
 54129/100000: episode: 5675, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000022, mae: 0.003317, mean_q: 0.004591
 54139/100000: episode: 5676, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000041, mae: 0.002834, mean_q: 0.003955
 54149/100000: episode: 5677, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002891, mean_q: 0.004078
 54159/100000: episode: 5678, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000033, mae: 0.003925, mean_q: 0.004837
 54169/100000: episode: 5679, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002634, mean_q: 0.003757
 54179/100000: episode: 5680, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000021, mae: 0.002947, mean_q: 0.004103
 54189/100000: episode: 5681, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000025, mae: 0.004568, mean_q: 0.005963
 54199/100000: episode: 5682, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000018, mae: 0.002416, mean_q: 0.003197
 54209/100000: episode: 5683, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000020, mae: 0.002815, mean_q: 0.003973
 54219/100000: episode: 5684, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000027, mae: 0.003554, mean_q: 0.004389
 54229/100000: episode: 5685, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000017, mae: 0.002929, mean_q: 0.004406
 54239/100000: episode: 5686, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002374, mean_q: 0.003564
 54249/100000: episode: 5687, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000035, mae: 0.002791, mean_q: 0.003971
 54259/100000: episode: 5688, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000056, mae: 0.004886, mean_q: 0.005396
 54269/100000: episode: 5689, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.002663, mean_q: 0.003851
 54279/100000: episode: 5690, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000029, mae: 0.004054, mean_q: 0.004811
 54289/100000: episode: 5691, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002609, mean_q: 0.003732
 54299/100000: episode: 5692, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000032, mae: 0.003331, mean_q: 0.004032
 54309/100000: episode: 5693, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003162, mean_q: 0.004697
 54319/100000: episode: 5694, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000012, mae: 0.002533, mean_q: 0.003751
 54329/100000: episode: 5695, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000025, mae: 0.002789, mean_q: 0.003583
 54339/100000: episode: 5696, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.003108, mean_q: 0.004822
 54349/100000: episode: 5697, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000018, mae: 0.002552, mean_q: 0.003383
 54359/100000: episode: 5698, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.003003, mean_q: 0.004191
 54369/100000: episode: 5699, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000085, mae: 0.004893, mean_q: 0.005213
 54379/100000: episode: 5700, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000024, mae: 0.003773, mean_q: 0.004983
 54389/100000: episode: 5701, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000030, mae: 0.003555, mean_q: 0.004353
 54399/100000: episode: 5702, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003551, mean_q: 0.004721
 54409/100000: episode: 5703, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000018, mae: 0.003050, mean_q: 0.004413
 54419/100000: episode: 5704, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.003231, mean_q: 0.004110
 54429/100000: episode: 5705, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002918, mean_q: 0.004377
 54439/100000: episode: 5706, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000028, mae: 0.003491, mean_q: 0.004228
 54449/100000: episode: 5707, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000029, mae: 0.004328, mean_q: 0.005454
 54459/100000: episode: 5708, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003224, mean_q: 0.004204
 54469/100000: episode: 5709, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000051, mae: 0.003933, mean_q: 0.004673
 54479/100000: episode: 5710, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000015, mae: 0.003239, mean_q: 0.005146
 54489/100000: episode: 5711, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000025, mae: 0.003197, mean_q: 0.003833
 54499/100000: episode: 5712, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000009, mae: 0.003003, mean_q: 0.005066
 54509/100000: episode: 5713, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003468, mean_q: 0.003838
 54519/100000: episode: 5714, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003687, mean_q: 0.004740
 54529/100000: episode: 5715, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000019, mae: 0.002703, mean_q: 0.003834
 54539/100000: episode: 5716, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000045, mae: 0.003247, mean_q: 0.004279
 54549/100000: episode: 5717, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003524, mean_q: 0.004914
 54559/100000: episode: 5718, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000009, mae: 0.002013, mean_q: 0.003225
 54569/100000: episode: 5719, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000010, mae: 0.002585, mean_q: 0.004346
 54579/100000: episode: 5720, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000023, mae: 0.003247, mean_q: 0.004315
 54589/100000: episode: 5721, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003271, mean_q: 0.004536
 54599/100000: episode: 5722, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000014, mae: 0.002649, mean_q: 0.004083
 54609/100000: episode: 5723, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000036, mae: 0.003684, mean_q: 0.004365
 54619/100000: episode: 5724, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000077, mae: 0.003940, mean_q: 0.004509
 54629/100000: episode: 5725, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000031, mae: 0.003403, mean_q: 0.004414
 54639/100000: episode: 5726, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000008, mae: 0.002570, mean_q: 0.004043
 54649/100000: episode: 5727, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000030, mae: 0.003788, mean_q: 0.004706
 54659/100000: episode: 5728, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002614, mean_q: 0.003487
 54669/100000: episode: 5729, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000023, mae: 0.003396, mean_q: 0.004399
 54679/100000: episode: 5730, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000013, mae: 0.002300, mean_q: 0.003707
 54689/100000: episode: 5731, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003016, mean_q: 0.004175
 54699/100000: episode: 5732, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.003074, mean_q: 0.004261
 54709/100000: episode: 5733, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003107, mean_q: 0.003997
 54719/100000: episode: 5734, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000042, mae: 0.003589, mean_q: 0.004904
 54729/100000: episode: 5735, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000030, mae: 0.003148, mean_q: 0.003982
 54739/100000: episode: 5736, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002557, mean_q: 0.004011
 54749/100000: episode: 5737, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000014, mae: 0.002373, mean_q: 0.003498
 54759/100000: episode: 5738, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000026, mae: 0.002774, mean_q: 0.003742
 54769/100000: episode: 5739, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002937, mean_q: 0.004396
 54779/100000: episode: 5740, duration: 0.045s, episode steps: 10, steps per second: 225, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000023, mae: 0.002951, mean_q: 0.003657
 54789/100000: episode: 5741, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000014, mae: 0.002639, mean_q: 0.003911
 54799/100000: episode: 5742, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000024, mae: 0.003276, mean_q: 0.003953
 54809/100000: episode: 5743, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.003074, mean_q: 0.004446
 54819/100000: episode: 5744, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000041, mae: 0.003982, mean_q: 0.004212
 54829/100000: episode: 5745, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000044, mae: 0.003865, mean_q: 0.004976
 54839/100000: episode: 5746, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000024, mae: 0.003189, mean_q: 0.003792
 54849/100000: episode: 5747, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000014, mae: 0.002848, mean_q: 0.004179
 54859/100000: episode: 5748, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000060, mae: 0.004421, mean_q: 0.004984
 54869/100000: episode: 5749, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000032, mae: 0.003740, mean_q: 0.004282
 54879/100000: episode: 5750, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002983, mean_q: 0.004313
 54889/100000: episode: 5751, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000084, mae: 0.004955, mean_q: 0.004994
 54899/100000: episode: 5752, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.003105, mean_q: 0.004807
 54909/100000: episode: 5753, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000031, mae: 0.003592, mean_q: 0.004011
 54919/100000: episode: 5754, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000035, mae: 0.004380, mean_q: 0.005100
 54929/100000: episode: 5755, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000032, mae: 0.003792, mean_q: 0.004899
 54939/100000: episode: 5756, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000054, mae: 0.003616, mean_q: 0.004163
 54949/100000: episode: 5757, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000012, mae: 0.002864, mean_q: 0.004310
 54959/100000: episode: 5758, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000078, mae: 0.003950, mean_q: 0.004218
 54969/100000: episode: 5759, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.003850, mean_q: 0.005116
 54979/100000: episode: 5760, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000048, mae: 0.003447, mean_q: 0.004014
 54989/100000: episode: 5761, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003531, mean_q: 0.004854
 54999/100000: episode: 5762, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000056, mae: 0.003395, mean_q: 0.003853
[Info] 1-TH LEVEL FOUND: 0.0032871877774596214, Considering 100/100 traces
 55009/100000: episode: 5763, duration: 0.703s, episode steps: 10, steps per second: 14, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000011, mae: 0.003097, mean_q: 0.005059
[Info] 2-TH LEVEL FOUND: 0.004409519024193287, Considering 100/100 traces
 55019/100000: episode: 5764, duration: 1.019s, episode steps: 10, steps per second: 10, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.002519, mean_q: 0.003841
[Info] 3-TH LEVEL FOUND: 0.00576770631596446, Considering 100/100 traces
 55029/100000: episode: 5765, duration: 1.187s, episode steps: 10, steps per second: 8, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000056, mae: 0.004332, mean_q: 0.004772
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.00576770631596446
 55039/100000: episode: 5766, duration: 0.478s, episode steps: 10, steps per second: 21, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000012, mae: 0.003043, mean_q: 0.004743
 55049/100000: episode: 5767, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.003670, mean_q: 0.004406
 55059/100000: episode: 5768, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000021, mae: 0.003518, mean_q: 0.004766
 55069/100000: episode: 5769, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000025, mae: 0.003227, mean_q: 0.003888
 55079/100000: episode: 5770, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003191, mean_q: 0.004461
 55089/100000: episode: 5771, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000055, mae: 0.004284, mean_q: 0.005015
 55099/100000: episode: 5772, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000018, mae: 0.003082, mean_q: 0.004706
 55109/100000: episode: 5773, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000018, mae: 0.002790, mean_q: 0.004141
 55119/100000: episode: 5774, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000013, mae: 0.002705, mean_q: 0.004379
 55129/100000: episode: 5775, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000024, mae: 0.002536, mean_q: 0.003293
 55139/100000: episode: 5776, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000017, mae: 0.003175, mean_q: 0.004771
 55149/100000: episode: 5777, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003309, mean_q: 0.003675
 55159/100000: episode: 5778, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000025, mae: 0.003729, mean_q: 0.005104
 55169/100000: episode: 5779, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000016, mae: 0.002925, mean_q: 0.004113
 55179/100000: episode: 5780, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000023, mae: 0.002966, mean_q: 0.004154
 55189/100000: episode: 5781, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003777, mean_q: 0.004913
 55199/100000: episode: 5782, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000020, mae: 0.003051, mean_q: 0.004424
 55209/100000: episode: 5783, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000034, mae: 0.003897, mean_q: 0.004602
 55219/100000: episode: 5784, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000052, mae: 0.003586, mean_q: 0.004416
 55229/100000: episode: 5785, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000028, mae: 0.003615, mean_q: 0.004773
 55239/100000: episode: 5786, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000041, mae: 0.005332, mean_q: 0.006325
 55249/100000: episode: 5787, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000034, mae: 0.004290, mean_q: 0.005280
 55259/100000: episode: 5788, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000045, mae: 0.002812, mean_q: 0.003806
 55269/100000: episode: 5789, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000027, mae: 0.004002, mean_q: 0.005299
 55279/100000: episode: 5790, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000009, mae: 0.002526, mean_q: 0.004146
 55289/100000: episode: 5791, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000019, mae: 0.003002, mean_q: 0.004254
 55299/100000: episode: 5792, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000032, mae: 0.003897, mean_q: 0.005061
 55309/100000: episode: 5793, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002654, mean_q: 0.003848
 55319/100000: episode: 5794, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000021, mae: 0.003825, mean_q: 0.005293
 55329/100000: episode: 5795, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003641, mean_q: 0.004331
 55339/100000: episode: 5796, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003109, mean_q: 0.004696
 55349/100000: episode: 5797, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000024, mae: 0.003306, mean_q: 0.004794
 55359/100000: episode: 5798, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003058, mean_q: 0.003984
 55369/100000: episode: 5799, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000049, mae: 0.004029, mean_q: 0.004837
 55379/100000: episode: 5800, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003098, mean_q: 0.004406
 55389/100000: episode: 5801, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000028, mae: 0.003261, mean_q: 0.004053
 55399/100000: episode: 5802, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000083, mae: 0.004690, mean_q: 0.005151
 55409/100000: episode: 5803, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.003208, mean_q: 0.004845
 55419/100000: episode: 5804, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000026, mae: 0.003444, mean_q: 0.004621
 55429/100000: episode: 5805, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000052, mae: 0.004383, mean_q: 0.005296
 55439/100000: episode: 5806, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000018, mae: 0.002478, mean_q: 0.003698
 55449/100000: episode: 5807, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000029, mae: 0.003677, mean_q: 0.004689
 55459/100000: episode: 5808, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000049, mae: 0.003930, mean_q: 0.004916
 55469/100000: episode: 5809, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000056, mae: 0.004894, mean_q: 0.005912
 55479/100000: episode: 5810, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000078, mae: 0.004353, mean_q: 0.004938
 55489/100000: episode: 5811, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000017, mae: 0.003233, mean_q: 0.004795
 55499/100000: episode: 5812, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000050, mae: 0.003412, mean_q: 0.004236
 55509/100000: episode: 5813, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000027, mae: 0.004517, mean_q: 0.006403
 55519/100000: episode: 5814, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000030, mae: 0.003145, mean_q: 0.003620
 55529/100000: episode: 5815, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000028, mae: 0.004074, mean_q: 0.005146
 55539/100000: episode: 5816, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000016, mae: 0.003081, mean_q: 0.004575
 55549/100000: episode: 5817, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000058, mae: 0.004003, mean_q: 0.004530
 55559/100000: episode: 5818, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003562, mean_q: 0.004974
 55569/100000: episode: 5819, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000056, mae: 0.004539, mean_q: 0.004855
 55579/100000: episode: 5820, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000039, mae: 0.004811, mean_q: 0.005549
 55589/100000: episode: 5821, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003367, mean_q: 0.005032
 55599/100000: episode: 5822, duration: 0.087s, episode steps: 10, steps per second: 114, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003036, mean_q: 0.004323
 55609/100000: episode: 5823, duration: 0.096s, episode steps: 10, steps per second: 105, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000022, mae: 0.003319, mean_q: 0.004807
 55619/100000: episode: 5824, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000020, mae: 0.002754, mean_q: 0.004142
 55629/100000: episode: 5825, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000019, mae: 0.002882, mean_q: 0.004157
 55639/100000: episode: 5826, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000014, mae: 0.002793, mean_q: 0.003907
 55649/100000: episode: 5827, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000027, mae: 0.003802, mean_q: 0.005039
 55659/100000: episode: 5828, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000034, mae: 0.004062, mean_q: 0.004949
 55669/100000: episode: 5829, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000029, mae: 0.003957, mean_q: 0.005011
 55679/100000: episode: 5830, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.003124, mean_q: 0.004794
 55689/100000: episode: 5831, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000018, mae: 0.002946, mean_q: 0.003979
 55699/100000: episode: 5832, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000048, mae: 0.003974, mean_q: 0.005274
 55709/100000: episode: 5833, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000020, mae: 0.002589, mean_q: 0.003242
 55719/100000: episode: 5834, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000019, mae: 0.003781, mean_q: 0.005330
 55729/100000: episode: 5835, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000030, mae: 0.004083, mean_q: 0.005040
 55739/100000: episode: 5836, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000017, mae: 0.002963, mean_q: 0.004035
 55749/100000: episode: 5837, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000011, mae: 0.002918, mean_q: 0.004649
 55759/100000: episode: 5838, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000030, mae: 0.003401, mean_q: 0.004173
 55769/100000: episode: 5839, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000020, mae: 0.003727, mean_q: 0.005256
 55779/100000: episode: 5840, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.002725, mean_q: 0.003807
 55789/100000: episode: 5841, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000047, mae: 0.003758, mean_q: 0.004897
 55799/100000: episode: 5842, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000052, mae: 0.004256, mean_q: 0.005176
 55809/100000: episode: 5843, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000031, mae: 0.003689, mean_q: 0.004555
 55819/100000: episode: 5844, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000036, mae: 0.004319, mean_q: 0.005425
 55829/100000: episode: 5845, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000047, mae: 0.003843, mean_q: 0.005005
 55839/100000: episode: 5846, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000023, mae: 0.003270, mean_q: 0.004549
 55849/100000: episode: 5847, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000047, mae: 0.004061, mean_q: 0.005591
 55859/100000: episode: 5848, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000026, mae: 0.003623, mean_q: 0.004428
 55869/100000: episode: 5849, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000051, mae: 0.003927, mean_q: 0.004822
 55879/100000: episode: 5850, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003507, mean_q: 0.004865
 55889/100000: episode: 5851, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003036, mean_q: 0.003941
 55899/100000: episode: 5852, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003869, mean_q: 0.005227
 55909/100000: episode: 5853, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003661, mean_q: 0.004456
 55919/100000: episode: 5854, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003331, mean_q: 0.004286
 55929/100000: episode: 5855, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000024, mae: 0.003650, mean_q: 0.005098
 55939/100000: episode: 5856, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.003010, mean_q: 0.004524
 55949/100000: episode: 5857, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.002864, mean_q: 0.004066
 55959/100000: episode: 5858, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003638, mean_q: 0.005028
 55969/100000: episode: 5859, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002717, mean_q: 0.003829
 55979/100000: episode: 5860, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003800, mean_q: 0.005053
 55989/100000: episode: 5861, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003405, mean_q: 0.004599
 55999/100000: episode: 5862, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000056, mae: 0.003782, mean_q: 0.004390
 56009/100000: episode: 5863, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000031, mae: 0.004164, mean_q: 0.005309
 56019/100000: episode: 5864, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.003974, mean_q: 0.005088
 56029/100000: episode: 5865, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.002731, mean_q: 0.003835
[Info] 1-TH LEVEL FOUND: 0.004846598487347364, Considering 100/100 traces
 56039/100000: episode: 5866, duration: 0.754s, episode steps: 10, steps per second: 13, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.003711, mean_q: 0.005012
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004846598487347364
 56049/100000: episode: 5867, duration: 0.492s, episode steps: 10, steps per second: 20, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000029, mae: 0.003499, mean_q: 0.004634
 56059/100000: episode: 5868, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003703, mean_q: 0.005304
 56069/100000: episode: 5869, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000029, mae: 0.003075, mean_q: 0.004041
 56079/100000: episode: 5870, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000028, mae: 0.003736, mean_q: 0.005164
 56089/100000: episode: 5871, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000024, mae: 0.003360, mean_q: 0.004501
 56099/100000: episode: 5872, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000028, mae: 0.003916, mean_q: 0.004992
 56109/100000: episode: 5873, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000037, mae: 0.004346, mean_q: 0.005222
 56119/100000: episode: 5874, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000093, mae: 0.005547, mean_q: 0.005883
 56129/100000: episode: 5875, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000017, mae: 0.002776, mean_q: 0.004449
 56139/100000: episode: 5876, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000087, mae: 0.004211, mean_q: 0.004096
 56149/100000: episode: 5877, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000016, mae: 0.004260, mean_q: 0.006353
 56159/100000: episode: 5878, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000096, mae: 0.004735, mean_q: 0.003998
 56169/100000: episode: 5879, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000030, mae: 0.004890, mean_q: 0.006589
 56179/100000: episode: 5880, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000029, mae: 0.003388, mean_q: 0.003998
 56189/100000: episode: 5881, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000027, mae: 0.003953, mean_q: 0.005151
 56199/100000: episode: 5882, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000024, mae: 0.004090, mean_q: 0.005729
 56209/100000: episode: 5883, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000022, mae: 0.002945, mean_q: 0.004146
 56219/100000: episode: 5884, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000051, mae: 0.003870, mean_q: 0.004974
 56229/100000: episode: 5885, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000019, mae: 0.003068, mean_q: 0.004630
 56239/100000: episode: 5886, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000025, mae: 0.003358, mean_q: 0.004764
 56249/100000: episode: 5887, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000022, mae: 0.003353, mean_q: 0.004752
 56259/100000: episode: 5888, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003291, mean_q: 0.004692
 56269/100000: episode: 5889, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000044, mae: 0.002971, mean_q: 0.004061
 56279/100000: episode: 5890, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000032, mae: 0.004324, mean_q: 0.005301
 56289/100000: episode: 5891, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003957, mean_q: 0.005283
 56299/100000: episode: 5892, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002601, mean_q: 0.004086
 56309/100000: episode: 5893, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000014, mae: 0.002601, mean_q: 0.003936
 56319/100000: episode: 5894, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002893, mean_q: 0.004139
 56329/100000: episode: 5895, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000052, mae: 0.004142, mean_q: 0.004780
 56339/100000: episode: 5896, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000029, mae: 0.003658, mean_q: 0.004714
 56349/100000: episode: 5897, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000030, mae: 0.003695, mean_q: 0.004627
 56359/100000: episode: 5898, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000020, mae: 0.003732, mean_q: 0.005449
 56369/100000: episode: 5899, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000043, mae: 0.003460, mean_q: 0.004704
 56379/100000: episode: 5900, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000019, mae: 0.002964, mean_q: 0.004255
 56389/100000: episode: 5901, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000032, mae: 0.004285, mean_q: 0.005123
 56399/100000: episode: 5902, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000038, mae: 0.004671, mean_q: 0.005554
 56409/100000: episode: 5903, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000027, mae: 0.003603, mean_q: 0.004573
 56419/100000: episode: 5904, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.003352, mean_q: 0.004966
 56429/100000: episode: 5905, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000062, mae: 0.004779, mean_q: 0.005428
 56439/100000: episode: 5906, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003689, mean_q: 0.005013
 56449/100000: episode: 5907, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000047, mae: 0.003403, mean_q: 0.004385
 56459/100000: episode: 5908, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000037, mae: 0.004875, mean_q: 0.006120
 56469/100000: episode: 5909, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000028, mae: 0.003461, mean_q: 0.004363
 56479/100000: episode: 5910, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000026, mae: 0.003567, mean_q: 0.004808
 56489/100000: episode: 5911, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000037, mae: 0.004543, mean_q: 0.005556
 56499/100000: episode: 5912, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000032, mae: 0.003487, mean_q: 0.004478
 56509/100000: episode: 5913, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000025, mae: 0.003479, mean_q: 0.005113
 56519/100000: episode: 5914, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000013, mae: 0.002314, mean_q: 0.003685
 56529/100000: episode: 5915, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000012, mae: 0.002667, mean_q: 0.004013
 56539/100000: episode: 5916, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003054, mean_q: 0.004245
 56549/100000: episode: 5917, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.003368, mean_q: 0.004670
 56559/100000: episode: 5918, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003013, mean_q: 0.004141
 56569/100000: episode: 5919, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003118, mean_q: 0.004484
 56579/100000: episode: 5920, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003155, mean_q: 0.004374
 56589/100000: episode: 5921, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000053, mae: 0.004228, mean_q: 0.004913
 56599/100000: episode: 5922, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000029, mae: 0.003875, mean_q: 0.005167
 56609/100000: episode: 5923, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003003, mean_q: 0.004095
 56619/100000: episode: 5924, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003790, mean_q: 0.004951
 56629/100000: episode: 5925, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000012, mae: 0.002379, mean_q: 0.003610
 56639/100000: episode: 5926, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000095, mae: 0.005546, mean_q: 0.005565
 56649/100000: episode: 5927, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003833, mean_q: 0.005354
 56659/100000: episode: 5928, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000049, mae: 0.003348, mean_q: 0.004158
 56669/100000: episode: 5929, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002968, mean_q: 0.004548
 56679/100000: episode: 5930, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000015, mae: 0.002614, mean_q: 0.004043
 56689/100000: episode: 5931, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000027, mae: 0.003576, mean_q: 0.004685
 56699/100000: episode: 5932, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003728, mean_q: 0.004811
 56709/100000: episode: 5933, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003147, mean_q: 0.004260
 56719/100000: episode: 5934, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003756, mean_q: 0.004854
 56729/100000: episode: 5935, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000074, mae: 0.004522, mean_q: 0.005060
 56739/100000: episode: 5936, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000017, mae: 0.003416, mean_q: 0.004994
 56749/100000: episode: 5937, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000046, mae: 0.003371, mean_q: 0.004127
 56759/100000: episode: 5938, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000031, mae: 0.004067, mean_q: 0.004935
 56769/100000: episode: 5939, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000053, mae: 0.004504, mean_q: 0.005404
 56779/100000: episode: 5940, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000059, mae: 0.004570, mean_q: 0.005324
 56789/100000: episode: 5941, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000026, mae: 0.003669, mean_q: 0.005029
 56799/100000: episode: 5942, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002663, mean_q: 0.004064
 56809/100000: episode: 5943, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000037, mae: 0.004081, mean_q: 0.004848
 56819/100000: episode: 5944, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000042, mae: 0.003938, mean_q: 0.005572
 56829/100000: episode: 5945, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.003227, mean_q: 0.004136
 56839/100000: episode: 5946, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000085, mae: 0.004893, mean_q: 0.005239
 56849/100000: episode: 5947, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000033, mae: 0.004405, mean_q: 0.005646
 56859/100000: episode: 5948, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000059, mae: 0.003756, mean_q: 0.004418
 56869/100000: episode: 5949, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000098, mae: 0.006581, mean_q: 0.006953
 56879/100000: episode: 5950, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000027, mae: 0.003524, mean_q: 0.004750
 56889/100000: episode: 5951, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000018, mae: 0.002851, mean_q: 0.004374
 56899/100000: episode: 5952, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000023, mae: 0.003197, mean_q: 0.004442
 56909/100000: episode: 5953, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003085, mean_q: 0.004346
 56919/100000: episode: 5954, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000048, mae: 0.004007, mean_q: 0.005079
 56929/100000: episode: 5955, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000017, mae: 0.002780, mean_q: 0.004662
 56939/100000: episode: 5956, duration: 0.118s, episode steps: 10, steps per second: 85, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000054, mae: 0.004001, mean_q: 0.004896
 56949/100000: episode: 5957, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000022, mae: 0.003665, mean_q: 0.005281
 56959/100000: episode: 5958, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000045, mae: 0.003263, mean_q: 0.003990
 56969/100000: episode: 5959, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000093, mae: 0.005764, mean_q: 0.006172
 56979/100000: episode: 5960, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000013, mae: 0.002765, mean_q: 0.004566
 56989/100000: episode: 5961, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000019, mae: 0.002694, mean_q: 0.003426
 56999/100000: episode: 5962, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000051, mae: 0.004519, mean_q: 0.005814
 57009/100000: episode: 5963, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000082, mae: 0.004539, mean_q: 0.004985
 57019/100000: episode: 5964, duration: 0.122s, episode steps: 10, steps per second: 82, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.003207, mean_q: 0.004666
 57029/100000: episode: 5965, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000051, mae: 0.003890, mean_q: 0.004959
 57039/100000: episode: 5966, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000046, mae: 0.003465, mean_q: 0.004518
[Info] 1-TH LEVEL FOUND: 0.006118737161159515, Considering 100/100 traces
 57049/100000: episode: 5967, duration: 0.877s, episode steps: 10, steps per second: 11, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000065, mae: 0.004898, mean_q: 0.005500
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006118737161159515
 57059/100000: episode: 5968, duration: 0.493s, episode steps: 10, steps per second: 20, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003184, mean_q: 0.004745
 57069/100000: episode: 5969, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000032, mae: 0.003987, mean_q: 0.004940
 57079/100000: episode: 5970, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000063, mae: 0.004693, mean_q: 0.005224
 57089/100000: episode: 5971, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000021, mae: 0.003807, mean_q: 0.005487
 57099/100000: episode: 5972, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000024, mae: 0.003290, mean_q: 0.004353
 57109/100000: episode: 5973, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000037, mae: 0.004192, mean_q: 0.005146
 57119/100000: episode: 5974, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000050, mae: 0.003584, mean_q: 0.004591
 57129/100000: episode: 5975, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003834, mean_q: 0.005260
 57139/100000: episode: 5976, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000032, mae: 0.004004, mean_q: 0.004807
 57149/100000: episode: 5977, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.004723, mean_q: 0.005259
 57159/100000: episode: 5978, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000047, mae: 0.003964, mean_q: 0.005296
 57169/100000: episode: 5979, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000022, mae: 0.003683, mean_q: 0.005030
 57179/100000: episode: 5980, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000045, mae: 0.003524, mean_q: 0.004932
 57189/100000: episode: 5981, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000016, mae: 0.002390, mean_q: 0.003856
 57199/100000: episode: 5982, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.003334, mean_q: 0.004615
 57209/100000: episode: 5983, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.003188, mean_q: 0.005031
 57219/100000: episode: 5984, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000022, mae: 0.002818, mean_q: 0.004032
 57229/100000: episode: 5985, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000030, mae: 0.003737, mean_q: 0.004870
 57239/100000: episode: 5986, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002914, mean_q: 0.004540
 57249/100000: episode: 5987, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000051, mae: 0.004032, mean_q: 0.004957
 57259/100000: episode: 5988, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000079, mae: 0.004594, mean_q: 0.005546
 57269/100000: episode: 5989, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000012, mae: 0.002850, mean_q: 0.004392
 57279/100000: episode: 5990, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000063, mae: 0.004250, mean_q: 0.004731
 57289/100000: episode: 5991, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000070, mae: 0.004349, mean_q: 0.005732
 57299/100000: episode: 5992, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000088, mae: 0.004819, mean_q: 0.005116
 57309/100000: episode: 5993, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000033, mae: 0.004395, mean_q: 0.005683
 57319/100000: episode: 5994, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000025, mae: 0.003161, mean_q: 0.004319
 57329/100000: episode: 5995, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000011, mae: 0.003175, mean_q: 0.005088
 57339/100000: episode: 5996, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.002736, mean_q: 0.003956
 57349/100000: episode: 5997, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000037, mae: 0.003275, mean_q: 0.004750
 57359/100000: episode: 5998, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000008, mae: 0.002357, mean_q: 0.003929
 57369/100000: episode: 5999, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003391, mean_q: 0.004503
 57379/100000: episode: 6000, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000016, mae: 0.003138, mean_q: 0.004667
 57389/100000: episode: 6001, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000043, mae: 0.004862, mean_q: 0.005519
 57399/100000: episode: 6002, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000034, mae: 0.004111, mean_q: 0.005081
 57409/100000: episode: 6003, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000043, mae: 0.003390, mean_q: 0.004562
 57419/100000: episode: 6004, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000051, mae: 0.004144, mean_q: 0.005196
 57429/100000: episode: 6005, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000027, mae: 0.004167, mean_q: 0.005651
 57439/100000: episode: 6006, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000044, mae: 0.003472, mean_q: 0.004755
 57449/100000: episode: 6007, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.003029, mean_q: 0.004807
 57459/100000: episode: 6008, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000054, mae: 0.004366, mean_q: 0.005085
 57469/100000: episode: 6009, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002785, mean_q: 0.004139
 57479/100000: episode: 6010, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003308, mean_q: 0.004435
 57489/100000: episode: 6011, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003736, mean_q: 0.005270
 57499/100000: episode: 6012, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000081, mae: 0.004361, mean_q: 0.004875
 57509/100000: episode: 6013, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003337, mean_q: 0.004574
 57519/100000: episode: 6014, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000068, mae: 0.003634, mean_q: 0.004592
 57529/100000: episode: 6015, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000012, mae: 0.003102, mean_q: 0.005125
 57539/100000: episode: 6016, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000046, mae: 0.003711, mean_q: 0.005137
 57549/100000: episode: 6017, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000041, mae: 0.003415, mean_q: 0.004510
 57559/100000: episode: 6018, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003460, mean_q: 0.004966
 57569/100000: episode: 6019, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000047, mae: 0.003368, mean_q: 0.004289
 57579/100000: episode: 6020, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.003299, mean_q: 0.005031
 57589/100000: episode: 6021, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000012, mae: 0.002695, mean_q: 0.004132
 57599/100000: episode: 6022, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000028, mae: 0.003728, mean_q: 0.004615
 57609/100000: episode: 6023, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000032, mae: 0.004363, mean_q: 0.005341
 57619/100000: episode: 6024, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000032, mae: 0.004226, mean_q: 0.005229
 57629/100000: episode: 6025, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003969, mean_q: 0.005515
 57639/100000: episode: 6026, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002451, mean_q: 0.003764
 57649/100000: episode: 6027, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000020, mae: 0.003234, mean_q: 0.004617
 57659/100000: episode: 6028, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000044, mae: 0.003708, mean_q: 0.005057
 57669/100000: episode: 6029, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000050, mae: 0.003967, mean_q: 0.004727
 57679/100000: episode: 6030, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000029, mae: 0.003852, mean_q: 0.005147
 57689/100000: episode: 6031, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000022, mae: 0.003291, mean_q: 0.004900
 57699/100000: episode: 6032, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000041, mae: 0.003330, mean_q: 0.004441
 57709/100000: episode: 6033, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000051, mae: 0.004104, mean_q: 0.005152
 57719/100000: episode: 6034, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000052, mae: 0.004084, mean_q: 0.005020
 57729/100000: episode: 6035, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000015, mae: 0.003236, mean_q: 0.005106
 57739/100000: episode: 6036, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000022, mae: 0.002650, mean_q: 0.003665
 57749/100000: episode: 6037, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000061, mae: 0.005156, mean_q: 0.006126
 57759/100000: episode: 6038, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000038, mae: 0.002856, mean_q: 0.004173
 57769/100000: episode: 6039, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000021, mae: 0.002583, mean_q: 0.003674
 57779/100000: episode: 6040, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000020, mae: 0.003715, mean_q: 0.005376
 57789/100000: episode: 6041, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000053, mae: 0.003906, mean_q: 0.004776
 57799/100000: episode: 6042, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.003751, mean_q: 0.004437
 57809/100000: episode: 6043, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000063, mae: 0.005061, mean_q: 0.006063
 57819/100000: episode: 6044, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000031, mae: 0.004205, mean_q: 0.005447
 57829/100000: episode: 6045, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000042, mae: 0.003844, mean_q: 0.005281
 57839/100000: episode: 6046, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000090, mae: 0.005361, mean_q: 0.005504
 57849/100000: episode: 6047, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003645, mean_q: 0.005245
 57859/100000: episode: 6048, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000055, mae: 0.004036, mean_q: 0.004699
 57869/100000: episode: 6049, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000047, mae: 0.004152, mean_q: 0.005649
 57879/100000: episode: 6050, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000045, mae: 0.003342, mean_q: 0.004459
 57889/100000: episode: 6051, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000042, mae: 0.002875, mean_q: 0.004097
 57899/100000: episode: 6052, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000046, mae: 0.003972, mean_q: 0.005381
 57909/100000: episode: 6053, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000056, mae: 0.004317, mean_q: 0.005458
 57919/100000: episode: 6054, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002511, mean_q: 0.003793
 57929/100000: episode: 6055, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000055, mae: 0.004106, mean_q: 0.004825
 57939/100000: episode: 6056, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000009, mae: 0.003106, mean_q: 0.005210
 57949/100000: episode: 6057, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000041, mae: 0.003011, mean_q: 0.003893
 57959/100000: episode: 6058, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000050, mae: 0.004208, mean_q: 0.005405
 57969/100000: episode: 6059, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000013, mae: 0.002558, mean_q: 0.003929
 57979/100000: episode: 6060, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000052, mae: 0.004160, mean_q: 0.004971
 57989/100000: episode: 6061, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000024, mae: 0.003597, mean_q: 0.004895
 57999/100000: episode: 6062, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000021, mae: 0.002801, mean_q: 0.004233
 58009/100000: episode: 6063, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000025, mae: 0.003860, mean_q: 0.005095
 58019/100000: episode: 6064, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.003159, mean_q: 0.004433
 58029/100000: episode: 6065, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000016, mae: 0.002814, mean_q: 0.004170
 58039/100000: episode: 6066, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000051, mae: 0.003934, mean_q: 0.004667
 58049/100000: episode: 6067, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000051, mae: 0.004543, mean_q: 0.005760
[Info] 1-TH LEVEL FOUND: 0.004144812934100628, Considering 100/100 traces
 58059/100000: episode: 6068, duration: 0.741s, episode steps: 10, steps per second: 13, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000026, mae: 0.002991, mean_q: 0.003820
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004144812934100628
 58069/100000: episode: 6069, duration: 0.502s, episode steps: 10, steps per second: 20, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000018, mae: 0.003000, mean_q: 0.004454
 58079/100000: episode: 6070, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000058, mae: 0.003783, mean_q: 0.004063
 58089/100000: episode: 6071, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000043, mae: 0.004173, mean_q: 0.005861
 58099/100000: episode: 6072, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000019, mae: 0.002457, mean_q: 0.003137
 58109/100000: episode: 6073, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000036, mae: 0.003112, mean_q: 0.004365
 58119/100000: episode: 6074, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.004122, mean_q: 0.005197
 58129/100000: episode: 6075, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000027, mae: 0.003571, mean_q: 0.004450
 58139/100000: episode: 6076, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000035, mae: 0.003052, mean_q: 0.004566
 58149/100000: episode: 6077, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000018, mae: 0.002836, mean_q: 0.003719
 58159/100000: episode: 6078, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000017, mae: 0.002845, mean_q: 0.004432
 58169/100000: episode: 6079, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002727, mean_q: 0.004085
 58179/100000: episode: 6080, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000089, mae: 0.005106, mean_q: 0.005529
 58189/100000: episode: 6081, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.003159, mean_q: 0.004407
 58199/100000: episode: 6082, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000048, mae: 0.003128, mean_q: 0.003556
 58209/100000: episode: 6083, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000050, mae: 0.004607, mean_q: 0.005873
 58219/100000: episode: 6084, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000020, mae: 0.002763, mean_q: 0.003544
 58229/100000: episode: 6085, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.003361, mean_q: 0.004857
 58239/100000: episode: 6086, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002317, mean_q: 0.003696
 58249/100000: episode: 6087, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000032, mae: 0.004281, mean_q: 0.005291
 58259/100000: episode: 6088, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000032, mae: 0.004042, mean_q: 0.005137
 58269/100000: episode: 6089, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000033, mae: 0.003822, mean_q: 0.004624
 58279/100000: episode: 6090, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000015, mae: 0.003122, mean_q: 0.004848
 58289/100000: episode: 6091, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000031, mae: 0.003388, mean_q: 0.004378
 58299/100000: episode: 6092, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000051, mae: 0.004087, mean_q: 0.005068
 58309/100000: episode: 6093, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.003017, mean_q: 0.004353
 58319/100000: episode: 6094, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000045, mae: 0.003344, mean_q: 0.004631
 58329/100000: episode: 6095, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003369, mean_q: 0.004547
 58339/100000: episode: 6096, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000025, mae: 0.003780, mean_q: 0.004916
 58349/100000: episode: 6097, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000043, mae: 0.003163, mean_q: 0.004208
 58359/100000: episode: 6098, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000044, mae: 0.003663, mean_q: 0.004910
 58369/100000: episode: 6099, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.003169, mean_q: 0.004427
 58379/100000: episode: 6100, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000036, mae: 0.002828, mean_q: 0.004561
 58389/100000: episode: 6101, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000015, mae: 0.002367, mean_q: 0.003346
 58399/100000: episode: 6102, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002878, mean_q: 0.004325
[Info] FALSIFICATION!
 58409/100000: episode: 6103, duration: 0.216s, episode steps: 10, steps per second: 46, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000023, mae: 0.003406, mean_q: 0.004592
 58419/100000: episode: 6104, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000039, mae: 0.002862, mean_q: 0.003869
 58429/100000: episode: 6105, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000026, mae: 0.003148, mean_q: 0.004331
 58439/100000: episode: 6106, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000023, mae: 0.003103, mean_q: 0.004348
 58449/100000: episode: 6107, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.002573, mean_q: 0.003489
 58459/100000: episode: 6108, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000257, mae: 0.005773, mean_q: 0.005857
 58469/100000: episode: 6109, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000050, mae: 0.004557, mean_q: 0.006057
 58479/100000: episode: 6110, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000019, mae: 0.002628, mean_q: 0.003500
 58489/100000: episode: 6111, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001597, mae: 0.008510, mean_q: 0.006528
 58499/100000: episode: 6112, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000048, mae: 0.005835, mean_q: 0.008428
 58509/100000: episode: 6113, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.002887, mean_q: 0.002502
 58519/100000: episode: 6114, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000050, mae: 0.003996, mean_q: 0.005169
 58529/100000: episode: 6115, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001599, mae: 0.009280, mean_q: 0.008196
 58539/100000: episode: 6116, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000078, mae: 0.004916, mean_q: 0.005799
 58549/100000: episode: 6117, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.002812, mean_q: 0.003653
 58559/100000: episode: 6118, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002946, mean_q: 0.005178
 58569/100000: episode: 6119, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000047, mae: 0.003186, mean_q: 0.003936
 58579/100000: episode: 6120, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.003042, mean_q: 0.004852
 58589/100000: episode: 6121, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000027, mae: 0.003087, mean_q: 0.004263
 58599/100000: episode: 6122, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000228, mae: 0.004642, mean_q: 0.005256
 58609/100000: episode: 6123, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000020, mae: 0.003475, mean_q: 0.005043
 58619/100000: episode: 6124, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001593, mae: 0.007026, mean_q: 0.005229
 58629/100000: episode: 6125, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000057, mae: 0.006404, mean_q: 0.008432
 58639/100000: episode: 6126, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000120, mae: 0.005934, mean_q: 0.005862
 58649/100000: episode: 6127, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000084, mae: 0.004893, mean_q: 0.005781
 58659/100000: episode: 6128, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000037, mae: 0.003343, mean_q: 0.005110
 58669/100000: episode: 6129, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000020, mae: 0.002939, mean_q: 0.004202
 58679/100000: episode: 6130, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000009, mae: 0.002873, mean_q: 0.004868
 58689/100000: episode: 6131, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000074, mae: 0.003602, mean_q: 0.004425
 58699/100000: episode: 6132, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000035, mae: 0.004815, mean_q: 0.006144
 58709/100000: episode: 6133, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000248, mae: 0.005084, mean_q: 0.004990
 58719/100000: episode: 6134, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000023, mae: 0.004337, mean_q: 0.006517
 58729/100000: episode: 6135, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000220, mae: 0.003648, mean_q: 0.004074
 58739/100000: episode: 6136, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000233, mae: 0.004954, mean_q: 0.005502
 58749/100000: episode: 6137, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000017, mae: 0.004078, mean_q: 0.006422
 58759/100000: episode: 6138, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000255, mae: 0.004799, mean_q: 0.004767
 58769/100000: episode: 6139, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001603, mae: 0.009539, mean_q: 0.008420
 58779/100000: episode: 6140, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000258, mae: 0.006070, mean_q: 0.006980
 58789/100000: episode: 6141, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000041, mae: 0.002995, mean_q: 0.004756
 58799/100000: episode: 6142, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000033, mae: 0.003739, mean_q: 0.005224
 58809/100000: episode: 6143, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000029, mae: 0.003975, mean_q: 0.005653
 58819/100000: episode: 6144, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000019, mae: 0.003260, mean_q: 0.005149
 58829/100000: episode: 6145, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000029, mae: 0.003281, mean_q: 0.004312
 58839/100000: episode: 6146, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000047, mae: 0.003581, mean_q: 0.005169
 58849/100000: episode: 6147, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000025, mae: 0.003639, mean_q: 0.004972
 58859/100000: episode: 6148, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000077, mae: 0.004688, mean_q: 0.006059
 58869/100000: episode: 6149, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000039, mae: 0.003673, mean_q: 0.004617
 58879/100000: episode: 6150, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000058, mae: 0.004175, mean_q: 0.005105
 58889/100000: episode: 6151, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000052, mae: 0.004649, mean_q: 0.005991
 58899/100000: episode: 6152, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.003745, mean_q: 0.005246
 58909/100000: episode: 6153, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001781, mae: 0.009849, mean_q: 0.008219
 58919/100000: episode: 6154, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000236, mae: 0.006067, mean_q: 0.006924
 58929/100000: episode: 6155, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000047, mae: 0.003671, mean_q: 0.005170
 58939/100000: episode: 6156, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000059, mae: 0.004075, mean_q: 0.005310
 58949/100000: episode: 6157, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000069, mae: 0.003957, mean_q: 0.005297
 58959/100000: episode: 6158, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000024, mae: 0.003693, mean_q: 0.005424
 58969/100000: episode: 6159, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000233, mae: 0.004008, mean_q: 0.004602
 58979/100000: episode: 6160, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000230, mae: 0.005709, mean_q: 0.006918
 58989/100000: episode: 6161, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000050, mae: 0.004000, mean_q: 0.005508
 58999/100000: episode: 6162, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000239, mae: 0.004956, mean_q: 0.005514
 59009/100000: episode: 6163, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000013, mae: 0.003477, mean_q: 0.005752
 59019/100000: episode: 6164, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000031, mae: 0.002964, mean_q: 0.003921
 59029/100000: episode: 6165, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000028, mae: 0.003432, mean_q: 0.005030
 59039/100000: episode: 6166, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000226, mae: 0.005292, mean_q: 0.006253
 59049/100000: episode: 6167, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000034, mae: 0.004444, mean_q: 0.005972
 59059/100000: episode: 6168, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000084, mae: 0.004324, mean_q: 0.005106
[Info] Complete ISplit Iteration
[Info] Levels: [0.0066909]
[Info] Cond. Prob: [1.0]
[Info] Error Prob: 1.0

 59069/100000: episode: 6169, duration: 0.830s, episode steps: 10, steps per second: 12, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000254, mae: 0.005627, mean_q: 0.006544
 59079/100000: episode: 6170, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003463, mean_q: 0.005393
 59089/100000: episode: 6171, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000093, mae: 0.004969, mean_q: 0.005333
 59099/100000: episode: 6172, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000052, mae: 0.004789, mean_q: 0.006453
 59109/100000: episode: 6173, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000018, mae: 0.003172, mean_q: 0.005281
 59119/100000: episode: 6174, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000014, mae: 0.002299, mean_q: 0.003841
 59129/100000: episode: 6175, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000315, mae: 0.006197, mean_q: 0.005317
 59139/100000: episode: 6176, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000045, mae: 0.005309, mean_q: 0.007652
 59149/100000: episode: 6177, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000033, mae: 0.003405, mean_q: 0.004088
 59159/100000: episode: 6178, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000051, mae: 0.004016, mean_q: 0.005432
 59169/100000: episode: 6179, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000223, mae: 0.004629, mean_q: 0.005983
 59179/100000: episode: 6180, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000222, mae: 0.004586, mean_q: 0.005539
 59189/100000: episode: 6181, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000055, mae: 0.005316, mean_q: 0.006717
 59199/100000: episode: 6182, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000015, mae: 0.003207, mean_q: 0.005353
 59209/100000: episode: 6183, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000076, mae: 0.003401, mean_q: 0.003622
 59219/100000: episode: 6184, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001641, mae: 0.010691, mean_q: 0.009332
 59229/100000: episode: 6185, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000040, mae: 0.005492, mean_q: 0.007466
 59239/100000: episode: 6186, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000042, mae: 0.002937, mean_q: 0.004080
 59249/100000: episode: 6187, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001771, mae: 0.008425, mean_q: 0.007188
 59259/100000: episode: 6188, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000025, mae: 0.005271, mean_q: 0.008093
 59269/100000: episode: 6189, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.002546, mean_q: 0.003600
 59279/100000: episode: 6190, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000259, mae: 0.005315, mean_q: 0.005631
 59289/100000: episode: 6191, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000029, mae: 0.004233, mean_q: 0.006283
 59299/100000: episode: 6192, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000062, mae: 0.003935, mean_q: 0.004654
 59309/100000: episode: 6193, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001600, mae: 0.009013, mean_q: 0.008276
 59319/100000: episode: 6194, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000013, mae: 0.004119, mean_q: 0.006996
 59329/100000: episode: 6195, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000024, mae: 0.002573, mean_q: 0.003019
 59339/100000: episode: 6196, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002676, mean_q: 0.004778
 59349/100000: episode: 6197, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000241, mae: 0.005578, mean_q: 0.005965
 59359/100000: episode: 6198, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000052, mae: 0.005126, mean_q: 0.007063
 59369/100000: episode: 6199, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000050, mae: 0.003657, mean_q: 0.005185
 59379/100000: episode: 6200, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000048, mae: 0.003513, mean_q: 0.004989
 59389/100000: episode: 6201, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000025, mae: 0.003442, mean_q: 0.005290
 59399/100000: episode: 6202, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003293, mean_q: 0.004540
 59409/100000: episode: 6203, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000028, mae: 0.003095, mean_q: 0.004215
 59419/100000: episode: 6204, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000050, mae: 0.003694, mean_q: 0.005051
 59429/100000: episode: 6205, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003938, mean_q: 0.005903
 59439/100000: episode: 6206, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000258, mae: 0.005045, mean_q: 0.005450
 59449/100000: episode: 6207, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000037, mae: 0.003170, mean_q: 0.005268
 59459/100000: episode: 6208, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000060, mae: 0.003863, mean_q: 0.004724
 59469/100000: episode: 6209, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003747, mean_q: 0.005428
 59479/100000: episode: 6210, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000057, mae: 0.003965, mean_q: 0.004859
 59489/100000: episode: 6211, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000018, mae: 0.003092, mean_q: 0.004861
 59499/100000: episode: 6212, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000466, mae: 0.006891, mean_q: 0.006289
 59509/100000: episode: 6213, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.004385, mean_q: 0.006450
 59519/100000: episode: 6214, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.002790, mean_q: 0.003797
 59529/100000: episode: 6215, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000036, mae: 0.003534, mean_q: 0.004319
 59539/100000: episode: 6216, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000045, mae: 0.004342, mean_q: 0.006060
 59549/100000: episode: 6217, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003509, mean_q: 0.005256
 59559/100000: episode: 6218, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003668, mean_q: 0.004876
 59569/100000: episode: 6219, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002721, mean_q: 0.004653
 59579/100000: episode: 6220, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.002538, mean_q: 0.004039
 59589/100000: episode: 6221, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000030, mae: 0.003846, mean_q: 0.004957
 59599/100000: episode: 6222, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000033, mae: 0.003916, mean_q: 0.005107
 59609/100000: episode: 6223, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.003111, mean_q: 0.004735
 59619/100000: episode: 6224, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001577, mae: 0.008424, mean_q: 0.007315
 59629/100000: episode: 6225, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000029, mae: 0.004466, mean_q: 0.006125
 59639/100000: episode: 6226, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000106, mae: 0.004045, mean_q: 0.003632
 59649/100000: episode: 6227, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000030, mae: 0.004585, mean_q: 0.006521
 59659/100000: episode: 6228, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000049, mae: 0.003788, mean_q: 0.004816
 59669/100000: episode: 6229, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003321, mean_q: 0.004782
 59679/100000: episode: 6230, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000056, mae: 0.004086, mean_q: 0.005071
 59689/100000: episode: 6231, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003341, mean_q: 0.004879
 59699/100000: episode: 6232, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000055, mae: 0.003749, mean_q: 0.004619
 59709/100000: episode: 6233, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000268, mae: 0.005824, mean_q: 0.005705
 59719/100000: episode: 6234, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000080, mae: 0.004977, mean_q: 0.006176
 59729/100000: episode: 6235, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000045, mae: 0.003403, mean_q: 0.004817
 59739/100000: episode: 6236, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000048, mae: 0.003435, mean_q: 0.004556
 59749/100000: episode: 6237, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000029, mae: 0.003491, mean_q: 0.004789
 59759/100000: episode: 6238, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000257, mae: 0.005762, mean_q: 0.006456
 59769/100000: episode: 6239, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000022, mae: 0.003537, mean_q: 0.005249
 59779/100000: episode: 6240, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000023, mae: 0.002844, mean_q: 0.003879
 59789/100000: episode: 6241, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001774, mae: 0.007972, mean_q: 0.005542
 59799/100000: episode: 6242, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000295, mae: 0.008902, mean_q: 0.009822
 59809/100000: episode: 6243, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.004650, mean_q: 0.006366
 59819/100000: episode: 6244, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000044, mae: 0.002773, mean_q: 0.003259
 59829/100000: episode: 6245, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.002858, mean_q: 0.005074
 59839/100000: episode: 6246, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000032, mae: 0.003601, mean_q: 0.004928
 59849/100000: episode: 6247, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000227, mae: 0.004962, mean_q: 0.005736
 59859/100000: episode: 6248, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000016, mae: 0.003219, mean_q: 0.005141
 59869/100000: episode: 6249, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000639, mae: 0.005924, mean_q: 0.003944
 59879/100000: episode: 6250, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000256, mae: 0.007583, mean_q: 0.008732
 59889/100000: episode: 6251, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001641, mae: 0.010862, mean_q: 0.009772
 59899/100000: episode: 6252, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000320, mae: 0.008393, mean_q: 0.008810
 59909/100000: episode: 6253, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000043, mae: 0.003436, mean_q: 0.005391
 59919/100000: episode: 6254, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000060, mae: 0.003691, mean_q: 0.004557
 59929/100000: episode: 6255, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001776, mae: 0.008276, mean_q: 0.006099
 59939/100000: episode: 6256, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000236, mae: 0.006828, mean_q: 0.008544
 59949/100000: episode: 6257, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000035, mae: 0.004669, mean_q: 0.006577
 59959/100000: episode: 6258, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000106, mae: 0.004957, mean_q: 0.005717
 59969/100000: episode: 6259, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000051, mae: 0.004224, mean_q: 0.006068
 59979/100000: episode: 6260, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000024, mae: 0.003609, mean_q: 0.005370
 59989/100000: episode: 6261, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000026, mae: 0.003488, mean_q: 0.005268
 59999/100000: episode: 6262, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000074, mae: 0.004164, mean_q: 0.005616
 60009/100000: episode: 6263, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000225, mae: 0.004335, mean_q: 0.005434
 60019/100000: episode: 6264, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000022, mae: 0.003311, mean_q: 0.005232
 60029/100000: episode: 6265, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000031, mae: 0.003254, mean_q: 0.004637
 60039/100000: episode: 6266, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001565, mae: 0.006952, mean_q: 0.006069
 60049/100000: episode: 6267, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000057, mae: 0.006684, mean_q: 0.008827
 60059/100000: episode: 6268, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000225, mae: 0.004116, mean_q: 0.004952
[Info] 1-TH LEVEL FOUND: 0.006558626424521208, Considering 100/100 traces
 60069/100000: episode: 6269, duration: 0.715s, episode steps: 10, steps per second: 14, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000058, mae: 0.003730, mean_q: 0.005010
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006558626424521208
 60079/100000: episode: 6270, duration: 0.476s, episode steps: 10, steps per second: 21, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000218, mae: 0.005332, mean_q: 0.007105
 60089/100000: episode: 6271, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000217, mae: 0.003459, mean_q: 0.004861
 60099/100000: episode: 6272, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003220, mean_q: 0.004997
 60109/100000: episode: 6273, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000053, mae: 0.004529, mean_q: 0.005863
 60119/100000: episode: 6274, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000226, mae: 0.005014, mean_q: 0.006169
 60129/100000: episode: 6275, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000054, mae: 0.004391, mean_q: 0.005924
 60139/100000: episode: 6276, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000082, mae: 0.004579, mean_q: 0.005632
 60149/100000: episode: 6277, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000061, mae: 0.004885, mean_q: 0.006200
 60159/100000: episode: 6278, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000016, mae: 0.002960, mean_q: 0.005323
 60169/100000: episode: 6279, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001575, mae: 0.007245, mean_q: 0.006375
 60179/100000: episode: 6280, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000024, mae: 0.004600, mean_q: 0.007167
 60189/100000: episode: 6281, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000064, mae: 0.003428, mean_q: 0.003847
 60199/100000: episode: 6282, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003371, mean_q: 0.005354
 60209/100000: episode: 6283, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000043, mae: 0.003557, mean_q: 0.005451
 60219/100000: episode: 6284, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000018, mae: 0.002871, mean_q: 0.004612
 60229/100000: episode: 6285, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000046, mae: 0.003478, mean_q: 0.004535
 60239/100000: episode: 6286, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000060, mae: 0.004773, mean_q: 0.006062
 60249/100000: episode: 6287, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000260, mae: 0.005587, mean_q: 0.005796
 60259/100000: episode: 6288, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.004025, mean_q: 0.005981
 60269/100000: episode: 6289, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000258, mae: 0.005869, mean_q: 0.006470
 60279/100000: episode: 6290, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001588, mae: 0.007998, mean_q: 0.007007
 60289/100000: episode: 6291, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001571, mae: 0.008569, mean_q: 0.007891
 60299/100000: episode: 6292, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000434, mae: 0.007347, mean_q: 0.008084
 60309/100000: episode: 6293, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000428, mae: 0.006617, mean_q: 0.007604
 60319/100000: episode: 6294, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000014, mae: 0.003470, mean_q: 0.006061
 60329/100000: episode: 6295, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000229, mae: 0.003978, mean_q: 0.004756
 60339/100000: episode: 6296, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000025, mae: 0.003717, mean_q: 0.005797
 60349/100000: episode: 6297, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001627, mae: 0.008297, mean_q: 0.006604
 60359/100000: episode: 6298, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001581, mae: 0.008841, mean_q: 0.009132
 60369/100000: episode: 6299, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.005308, mean_q: 0.007818
 60379/100000: episode: 6300, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001572, mae: 0.006099, mean_q: 0.004879
 60389/100000: episode: 6301, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000049, mae: 0.005089, mean_q: 0.007548
 60399/100000: episode: 6302, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000040, mae: 0.003726, mean_q: 0.006048
 60409/100000: episode: 6303, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.001885, mae: 0.010543, mean_q: 0.007722
 60419/100000: episode: 6304, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000224, mae: 0.006743, mean_q: 0.009075
 60429/100000: episode: 6305, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000014, mae: 0.003065, mean_q: 0.005933
 60439/100000: episode: 6306, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000256, mae: 0.004224, mean_q: 0.004966
 60449/100000: episode: 6307, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000256, mae: 0.006011, mean_q: 0.007127
 60459/100000: episode: 6308, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000032, mae: 0.004311, mean_q: 0.006819
 60469/100000: episode: 6309, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003771, mean_q: 0.005310
 60479/100000: episode: 6310, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000018, mae: 0.002661, mean_q: 0.004855
 60489/100000: episode: 6311, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000015, mae: 0.003334, mean_q: 0.006013
 60499/100000: episode: 6312, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000055, mae: 0.003907, mean_q: 0.005596
 60509/100000: episode: 6313, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000024, mae: 0.003081, mean_q: 0.004851
 60519/100000: episode: 6314, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.003117, mean_q: 0.004631
 60529/100000: episode: 6315, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001567, mae: 0.006326, mean_q: 0.005208
 60539/100000: episode: 6316, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000261, mae: 0.007412, mean_q: 0.009111
 60549/100000: episode: 6317, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000024, mae: 0.004241, mean_q: 0.006834
 60559/100000: episode: 6318, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000227, mae: 0.003714, mean_q: 0.004055
 60569/100000: episode: 6319, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.002810, mean_q: 0.004884
 60579/100000: episode: 6320, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000076, mae: 0.003718, mean_q: 0.004989
 60589/100000: episode: 6321, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.003344, mean_q: 0.005539
 60599/100000: episode: 6322, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000235, mae: 0.004721, mean_q: 0.005466
 60609/100000: episode: 6323, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000047, mae: 0.004210, mean_q: 0.006054
 60619/100000: episode: 6324, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000037, mae: 0.002995, mean_q: 0.004832
 60629/100000: episode: 6325, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000037, mae: 0.003518, mean_q: 0.004116
 60639/100000: episode: 6326, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000283, mae: 0.005877, mean_q: 0.006304
 60649/100000: episode: 6327, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000051, mae: 0.004468, mean_q: 0.006279
 60659/100000: episode: 6328, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001622, mae: 0.008073, mean_q: 0.006363
 60669/100000: episode: 6329, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000049, mae: 0.005165, mean_q: 0.007317
 60679/100000: episode: 6330, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000035, mae: 0.003561, mean_q: 0.004420
 60689/100000: episode: 6331, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000494, mae: 0.006603, mean_q: 0.005429
 60699/100000: episode: 6332, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000028, mae: 0.005033, mean_q: 0.007437
 60709/100000: episode: 6333, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000069, mae: 0.003984, mean_q: 0.005552
 60719/100000: episode: 6334, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002470, mean_q: 0.004379
 60729/100000: episode: 6335, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000298, mae: 0.005879, mean_q: 0.005401
 60739/100000: episode: 6336, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000232, mae: 0.005700, mean_q: 0.006715
 60749/100000: episode: 6337, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000071, mae: 0.004401, mean_q: 0.005960
 60759/100000: episode: 6338, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002987, mean_q: 0.005098
 60769/100000: episode: 6339, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000221, mae: 0.004225, mean_q: 0.005282
 60779/100000: episode: 6340, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000491, mae: 0.006990, mean_q: 0.006241
 60789/100000: episode: 6341, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000013, mae: 0.003978, mean_q: 0.007123
 60799/100000: episode: 6342, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000088, mae: 0.004180, mean_q: 0.004418
 60809/100000: episode: 6343, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000070, mae: 0.004065, mean_q: 0.005689
 60819/100000: episode: 6344, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000055, mae: 0.004276, mean_q: 0.005596
 60829/100000: episode: 6345, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003366, mean_q: 0.005337
 60839/100000: episode: 6346, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000263, mae: 0.004870, mean_q: 0.005011
 60849/100000: episode: 6347, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000047, mae: 0.004493, mean_q: 0.006354
 60859/100000: episode: 6348, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000046, mae: 0.003863, mean_q: 0.005725
 60869/100000: episode: 6349, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001780, mae: 0.007875, mean_q: 0.005337
 60879/100000: episode: 6350, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000056, mae: 0.006367, mean_q: 0.008812
 60889/100000: episode: 6351, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000240, mae: 0.004872, mean_q: 0.005574
 60899/100000: episode: 6352, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000509, mae: 0.007099, mean_q: 0.006172
 60909/100000: episode: 6353, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.005099, mean_q: 0.007693
 60919/100000: episode: 6354, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000048, mae: 0.003360, mean_q: 0.004721
 60929/100000: episode: 6355, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000029, mae: 0.003466, mean_q: 0.004673
 60939/100000: episode: 6356, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000058, mae: 0.004074, mean_q: 0.005391
 60949/100000: episode: 6357, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000043, mae: 0.003528, mean_q: 0.005392
 60959/100000: episode: 6358, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000021, mae: 0.003229, mean_q: 0.005293
 60969/100000: episode: 6359, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000043, mae: 0.003240, mean_q: 0.004777
 60979/100000: episode: 6360, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000299, mae: 0.006023, mean_q: 0.005676
 60989/100000: episode: 6361, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.004457, mean_q: 0.006748
 60999/100000: episode: 6362, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000051, mae: 0.003585, mean_q: 0.004759
 61009/100000: episode: 6363, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001559, mae: 0.006479, mean_q: 0.006072
 61019/100000: episode: 6364, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000256, mae: 0.005841, mean_q: 0.006988
 61029/100000: episode: 6365, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000028, mae: 0.003853, mean_q: 0.005834
 61039/100000: episode: 6366, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000236, mae: 0.004734, mean_q: 0.005144
 61049/100000: episode: 6367, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000018, mae: 0.003482, mean_q: 0.005859
 61059/100000: episode: 6368, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000069, mae: 0.005463, mean_q: 0.007620
 61069/100000: episode: 6369, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000273, mae: 0.005699, mean_q: 0.006683
[Info] 1-TH LEVEL FOUND: 0.00526046846061945, Considering 100/100 traces
 61079/100000: episode: 6370, duration: 0.731s, episode steps: 10, steps per second: 14, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000023, mae: 0.003340, mean_q: 0.005616
[Info] 2-TH LEVEL FOUND: 0.0054210699163377285, Considering 100/100 traces
 61089/100000: episode: 6371, duration: 0.685s, episode steps: 10, steps per second: 15, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000025, mae: 0.003388, mean_q: 0.005315
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0054210699163377285
 61099/100000: episode: 6372, duration: 0.482s, episode steps: 10, steps per second: 21, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000013, mae: 0.003060, mean_q: 0.005210
 61109/100000: episode: 6373, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000224, mae: 0.004056, mean_q: 0.005167
 61119/100000: episode: 6374, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003163, mean_q: 0.005212
 61129/100000: episode: 6375, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001565, mae: 0.006783, mean_q: 0.005689
 61139/100000: episode: 6376, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000059, mae: 0.006429, mean_q: 0.008828
 61149/100000: episode: 6377, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000029, mae: 0.003848, mean_q: 0.005778
 61159/100000: episode: 6378, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000068, mae: 0.003694, mean_q: 0.003870
 61169/100000: episode: 6379, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000044, mae: 0.003742, mean_q: 0.005786
 61179/100000: episode: 6380, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000034, mae: 0.004171, mean_q: 0.005577
 61189/100000: episode: 6381, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000072, mae: 0.004093, mean_q: 0.005479
 61199/100000: episode: 6382, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000042, mae: 0.003495, mean_q: 0.005354
 61209/100000: episode: 6383, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000254, mae: 0.004385, mean_q: 0.004674
 61219/100000: episode: 6384, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000042, mae: 0.003845, mean_q: 0.005911
 61229/100000: episode: 6385, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000040, mae: 0.003415, mean_q: 0.005021
 61239/100000: episode: 6386, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.002833, mean_q: 0.004198
 61249/100000: episode: 6387, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000069, mae: 0.003579, mean_q: 0.004801
 61259/100000: episode: 6388, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000264, mae: 0.005681, mean_q: 0.005928
 61269/100000: episode: 6389, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000026, mae: 0.004280, mean_q: 0.006334
 61279/100000: episode: 6390, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000263, mae: 0.005600, mean_q: 0.005793
 61289/100000: episode: 6391, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000432, mae: 0.006782, mean_q: 0.007136
 61299/100000: episode: 6392, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000011, mae: 0.003093, mean_q: 0.005654
 61309/100000: episode: 6393, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000260, mae: 0.004522, mean_q: 0.004470
 61319/100000: episode: 6394, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000135, mae: 0.005896, mean_q: 0.006400
 61329/100000: episode: 6395, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000017, mae: 0.003798, mean_q: 0.006124
 61339/100000: episode: 6396, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000249, mae: 0.003940, mean_q: 0.004565
 61349/100000: episode: 6397, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000041, mae: 0.003339, mean_q: 0.005270
 61359/100000: episode: 6398, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003416, mean_q: 0.004973
 61369/100000: episode: 6399, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000012, mae: 0.002560, mean_q: 0.004560
 61379/100000: episode: 6400, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000111, mae: 0.004679, mean_q: 0.005088
 61389/100000: episode: 6401, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.001570, mae: 0.008764, mean_q: 0.008274
 61399/100000: episode: 6402, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.003315, mean_q: 0.005936
 61409/100000: episode: 6403, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000103, mae: 0.003558, mean_q: 0.003384
 61419/100000: episode: 6404, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000091, mae: 0.005562, mean_q: 0.006421
 61429/100000: episode: 6405, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000058, mae: 0.005248, mean_q: 0.006790
 61439/100000: episode: 6406, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000261, mae: 0.005439, mean_q: 0.005608
 61449/100000: episode: 6407, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000035, mae: 0.004621, mean_q: 0.006363
 61459/100000: episode: 6408, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000076, mae: 0.003808, mean_q: 0.004952
 61469/100000: episode: 6409, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000016, mae: 0.002864, mean_q: 0.004671
 61479/100000: episode: 6410, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000228, mae: 0.004335, mean_q: 0.004959
 61489/100000: episode: 6411, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000272, mae: 0.006156, mean_q: 0.006313
 61499/100000: episode: 6412, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000240, mae: 0.006540, mean_q: 0.007713
 61509/100000: episode: 6413, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000010, mae: 0.002663, mean_q: 0.005010
 61519/100000: episode: 6414, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000033, mae: 0.002806, mean_q: 0.003389
 61529/100000: episode: 6415, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000427, mae: 0.006072, mean_q: 0.006208
 61539/100000: episode: 6416, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000046, mae: 0.005172, mean_q: 0.007574
 61549/100000: episode: 6417, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000015, mae: 0.002615, mean_q: 0.004325
 61559/100000: episode: 6418, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000489, mae: 0.005846, mean_q: 0.004529
 61569/100000: episode: 6419, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.004445, mean_q: 0.007034
 61579/100000: episode: 6420, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000066, mae: 0.003301, mean_q: 0.004638
 61589/100000: episode: 6421, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.002940, mean_q: 0.004236
 61599/100000: episode: 6422, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000234, mae: 0.004939, mean_q: 0.005830
 61609/100000: episode: 6423, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000266, mae: 0.006112, mean_q: 0.006256
 61619/100000: episode: 6424, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000056, mae: 0.004880, mean_q: 0.006632
 61629/100000: episode: 6425, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000021, mae: 0.003427, mean_q: 0.005158
 61639/100000: episode: 6426, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000017, mae: 0.002814, mean_q: 0.004268
 61649/100000: episode: 6427, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000097, mae: 0.004683, mean_q: 0.005716
 61659/100000: episode: 6428, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000424, mae: 0.005794, mean_q: 0.006212
 61669/100000: episode: 6429, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000234, mae: 0.005531, mean_q: 0.006420
 61679/100000: episode: 6430, duration: 0.112s, episode steps: 10, steps per second: 90, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000255, mae: 0.005283, mean_q: 0.005862
 61689/100000: episode: 6431, duration: 0.113s, episode steps: 10, steps per second: 89, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000305, mae: 0.006617, mean_q: 0.006917
 61699/100000: episode: 6432, duration: 0.105s, episode steps: 10, steps per second: 95, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000018, mae: 0.003195, mean_q: 0.005393
 61709/100000: episode: 6433, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000253, mae: 0.004069, mean_q: 0.004282
 61719/100000: episode: 6434, duration: 0.119s, episode steps: 10, steps per second: 84, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000082, mae: 0.005318, mean_q: 0.006424
 61729/100000: episode: 6435, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000234, mae: 0.005069, mean_q: 0.006024
 61739/100000: episode: 6436, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000259, mae: 0.005613, mean_q: 0.006293
 61749/100000: episode: 6437, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000053, mae: 0.004031, mean_q: 0.005719
 61759/100000: episode: 6438, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000050, mae: 0.003396, mean_q: 0.004702
 61769/100000: episode: 6439, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000229, mae: 0.004707, mean_q: 0.005378
 61779/100000: episode: 6440, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000018, mae: 0.003742, mean_q: 0.006139
 61789/100000: episode: 6441, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000011, mae: 0.002333, mean_q: 0.004201
 61799/100000: episode: 6442, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000031, mae: 0.003604, mean_q: 0.005066
 61809/100000: episode: 6443, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000047, mae: 0.004236, mean_q: 0.005849
 61819/100000: episode: 6444, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000057, mae: 0.004007, mean_q: 0.005013
 61829/100000: episode: 6445, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000255, mae: 0.004943, mean_q: 0.005485
 61839/100000: episode: 6446, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000231, mae: 0.005687, mean_q: 0.006884
 61849/100000: episode: 6447, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000043, mae: 0.003765, mean_q: 0.005553
 61859/100000: episode: 6448, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000225, mae: 0.005419, mean_q: 0.006852
 61869/100000: episode: 6449, duration: 0.071s, episode steps: 10, steps per second: 142, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000231, mae: 0.005614, mean_q: 0.006807
 61879/100000: episode: 6450, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003415, mean_q: 0.005257
 61889/100000: episode: 6451, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000016, mae: 0.002492, mean_q: 0.004389
 61899/100000: episode: 6452, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000280, mae: 0.004789, mean_q: 0.004622
 61909/100000: episode: 6453, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000105, mae: 0.005740, mean_q: 0.006690
 61919/100000: episode: 6454, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000234, mae: 0.005627, mean_q: 0.006767
 61929/100000: episode: 6455, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000026, mae: 0.003994, mean_q: 0.005923
 61939/100000: episode: 6456, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000034, mae: 0.002495, mean_q: 0.004201
 61949/100000: episode: 6457, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000017, mae: 0.004150, mean_q: 0.006923
 61959/100000: episode: 6458, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000255, mae: 0.004961, mean_q: 0.005601
 61969/100000: episode: 6459, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.001618, mae: 0.008082, mean_q: 0.007042
 61979/100000: episode: 6460, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000017, mae: 0.004424, mean_q: 0.007375
 61989/100000: episode: 6461, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000016, mae: 0.002232, mean_q: 0.003471
 61999/100000: episode: 6462, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000229, mae: 0.003482, mean_q: 0.004133
 62009/100000: episode: 6463, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.003891, mean_q: 0.005877
 62019/100000: episode: 6464, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000047, mae: 0.003578, mean_q: 0.005035
 62029/100000: episode: 6465, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000019, mae: 0.003551, mean_q: 0.005748
 62039/100000: episode: 6466, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000436, mae: 0.005509, mean_q: 0.005289
 62049/100000: episode: 6467, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.003928, mean_q: 0.006329
 62059/100000: episode: 6468, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000252, mae: 0.004792, mean_q: 0.005058
 62069/100000: episode: 6469, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000103, mae: 0.004870, mean_q: 0.006060
 62079/100000: episode: 6470, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000220, mae: 0.004887, mean_q: 0.006368
 62089/100000: episode: 6471, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000045, mae: 0.003591, mean_q: 0.005390
[Info] 1-TH LEVEL FOUND: 0.004170198459178209, Considering 100/100 traces
 62099/100000: episode: 6472, duration: 0.767s, episode steps: 10, steps per second: 13, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000022, mae: 0.002677, mean_q: 0.004368
[Info] 2-TH LEVEL FOUND: 0.005648958496749401, Considering 100/100 traces
 62109/100000: episode: 6473, duration: 0.796s, episode steps: 10, steps per second: 13, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000247, mae: 0.003902, mean_q: 0.004356
[Info] 3-TH LEVEL FOUND: 0.006172893103212118, Considering 100/100 traces
 62119/100000: episode: 6474, duration: 0.761s, episode steps: 10, steps per second: 13, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.004180, mean_q: 0.006460
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006172893103212118
 62129/100000: episode: 6475, duration: 0.517s, episode steps: 10, steps per second: 19, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000254, mae: 0.004916, mean_q: 0.005237
 62139/100000: episode: 6476, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000027, mae: 0.003668, mean_q: 0.005423
 62149/100000: episode: 6477, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000303, mae: 0.006458, mean_q: 0.006417
 62159/100000: episode: 6478, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000042, mae: 0.003920, mean_q: 0.005987
 62169/100000: episode: 6479, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000029, mae: 0.003332, mean_q: 0.004346
 62179/100000: episode: 6480, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000074, mae: 0.003891, mean_q: 0.004759
 62189/100000: episode: 6481, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000068, mae: 0.004439, mean_q: 0.005961
 62199/100000: episode: 6482, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000013, mae: 0.002673, mean_q: 0.004951
 62209/100000: episode: 6483, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000103, mae: 0.003992, mean_q: 0.004106
 62219/100000: episode: 6484, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000308, mae: 0.006683, mean_q: 0.006869
 62229/100000: episode: 6485, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000087, mae: 0.005459, mean_q: 0.006455
 62239/100000: episode: 6486, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000025, mae: 0.003286, mean_q: 0.005080
 62249/100000: episode: 6487, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.002027, mae: 0.010552, mean_q: 0.006543
 62259/100000: episode: 6488, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000040, mae: 0.006996, mean_q: 0.009841
 62269/100000: episode: 6489, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001596, mae: 0.007059, mean_q: 0.005688
 62279/100000: episode: 6490, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000042, mae: 0.004151, mean_q: 0.006609
 62289/100000: episode: 6491, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000432, mae: 0.006272, mean_q: 0.006669
 62299/100000: episode: 6492, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000012, mae: 0.004138, mean_q: 0.007144
 62309/100000: episode: 6493, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000046, mae: 0.003569, mean_q: 0.005716
 62319/100000: episode: 6494, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001802, mae: 0.009052, mean_q: 0.006845
 62329/100000: episode: 6495, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000052, mae: 0.006649, mean_q: 0.009731
 62339/100000: episode: 6496, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000079, mae: 0.004212, mean_q: 0.005488
 62349/100000: episode: 6497, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000012, mae: 0.002100, mean_q: 0.004480
 62359/100000: episode: 6498, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001976, mae: 0.009565, mean_q: 0.006830
 62369/100000: episode: 6499, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000243, mae: 0.008190, mean_q: 0.010502
 62379/100000: episode: 6500, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000256, mae: 0.006547, mean_q: 0.008016
 62389/100000: episode: 6501, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000055, mae: 0.003284, mean_q: 0.004853
 62399/100000: episode: 6502, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000097, mae: 0.004342, mean_q: 0.005397
 62409/100000: episode: 6503, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000046, mae: 0.003961, mean_q: 0.006182
 62419/100000: episode: 6504, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001569, mae: 0.006885, mean_q: 0.005715
 62429/100000: episode: 6505, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000052, mae: 0.005596, mean_q: 0.008172
 62439/100000: episode: 6506, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000229, mae: 0.005357, mean_q: 0.007161
 62449/100000: episode: 6507, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000239, mae: 0.004099, mean_q: 0.004684
 62459/100000: episode: 6508, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000054, mae: 0.004703, mean_q: 0.006868
 62469/100000: episode: 6509, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000054, mae: 0.004719, mean_q: 0.006714
 62479/100000: episode: 6510, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000228, mae: 0.004260, mean_q: 0.005317
 62489/100000: episode: 6511, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000045, mae: 0.003613, mean_q: 0.005712
 62499/100000: episode: 6512, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000048, mae: 0.003536, mean_q: 0.005643
 62509/100000: episode: 6513, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001593, mae: 0.006577, mean_q: 0.005240
 62519/100000: episode: 6514, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000226, mae: 0.006167, mean_q: 0.008150
 62529/100000: episode: 6515, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000051, mae: 0.005342, mean_q: 0.007498
 62539/100000: episode: 6516, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000236, mae: 0.005037, mean_q: 0.005568
 62549/100000: episode: 6517, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000069, mae: 0.003989, mean_q: 0.005857
 62559/100000: episode: 6518, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000220, mae: 0.003734, mean_q: 0.005090
 62569/100000: episode: 6519, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000230, mae: 0.004474, mean_q: 0.005355
 62579/100000: episode: 6520, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000075, mae: 0.004764, mean_q: 0.006410
 62589/100000: episode: 6521, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000051, mae: 0.004087, mean_q: 0.005746
 62599/100000: episode: 6522, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002652, mean_q: 0.005114
 62609/100000: episode: 6523, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000070, mae: 0.003467, mean_q: 0.004485
 62619/100000: episode: 6524, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001573, mae: 0.006627, mean_q: 0.005367
 62629/100000: episode: 6525, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001826, mae: 0.011641, mean_q: 0.009622
 62639/100000: episode: 6526, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001621, mae: 0.011547, mean_q: 0.011209
 62649/100000: episode: 6527, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.004602, mean_q: 0.007349
 62659/100000: episode: 6528, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000242, mae: 0.004113, mean_q: 0.004165
 62669/100000: episode: 6529, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000259, mae: 0.005312, mean_q: 0.006275
 62679/100000: episode: 6530, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000065, mae: 0.004857, mean_q: 0.007299
 62689/100000: episode: 6531, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000042, mae: 0.003123, mean_q: 0.005179
 62699/100000: episode: 6532, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001569, mae: 0.006950, mean_q: 0.006666
 62709/100000: episode: 6533, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000225, mae: 0.004979, mean_q: 0.006664
 62719/100000: episode: 6534, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000044, mae: 0.004936, mean_q: 0.007832
 62729/100000: episode: 6535, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000227, mae: 0.005663, mean_q: 0.007511
 62739/100000: episode: 6536, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000069, mae: 0.003437, mean_q: 0.005152
 62749/100000: episode: 6537, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000037, mae: 0.002711, mean_q: 0.004835
 62759/100000: episode: 6538, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002677, mean_q: 0.005185
 62769/100000: episode: 6539, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000052, mae: 0.003393, mean_q: 0.004858
 62779/100000: episode: 6540, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000009, mae: 0.002283, mean_q: 0.004897
 62789/100000: episode: 6541, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000230, mae: 0.003968, mean_q: 0.004548
 62799/100000: episode: 6542, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000071, mae: 0.004539, mean_q: 0.006173
 62809/100000: episode: 6543, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000259, mae: 0.005535, mean_q: 0.006455
 62819/100000: episode: 6544, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000303, mae: 0.006203, mean_q: 0.006898
 62829/100000: episode: 6545, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000022, mae: 0.003721, mean_q: 0.006110
 62839/100000: episode: 6546, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000037, mae: 0.002515, mean_q: 0.004294
 62849/100000: episode: 6547, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000084, mae: 0.004283, mean_q: 0.004611
 62859/100000: episode: 6548, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000066, mae: 0.004455, mean_q: 0.006211
 62869/100000: episode: 6549, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.002998, mean_q: 0.004989
 62879/100000: episode: 6550, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000018, mae: 0.002581, mean_q: 0.003969
 62889/100000: episode: 6551, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000220, mae: 0.003671, mean_q: 0.004750
 62899/100000: episode: 6552, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000022, mae: 0.003210, mean_q: 0.004891
 62909/100000: episode: 6553, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000266, mae: 0.005125, mean_q: 0.005034
 62919/100000: episode: 6554, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000042, mae: 0.004071, mean_q: 0.006075
 62929/100000: episode: 6555, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000027, mae: 0.003220, mean_q: 0.004746
 62939/100000: episode: 6556, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000020, mae: 0.002678, mean_q: 0.004183
 62949/100000: episode: 6557, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000276, mae: 0.004692, mean_q: 0.004563
 62959/100000: episode: 6558, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000039, mae: 0.003979, mean_q: 0.006012
 62969/100000: episode: 6559, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000225, mae: 0.004125, mean_q: 0.005083
 62979/100000: episode: 6560, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.002746, mean_q: 0.004202
 62989/100000: episode: 6561, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000225, mae: 0.003868, mean_q: 0.004551
 62999/100000: episode: 6562, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000469, mae: 0.007230, mean_q: 0.006382
 63009/100000: episode: 6563, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000049, mae: 0.005481, mean_q: 0.007710
 63019/100000: episode: 6564, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000007, mae: 0.002345, mean_q: 0.004468
 63029/100000: episode: 6565, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000024, mae: 0.002689, mean_q: 0.003403
 63039/100000: episode: 6566, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000222, mae: 0.004652, mean_q: 0.005422
 63049/100000: episode: 6567, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000070, mae: 0.004408, mean_q: 0.005865
 63059/100000: episode: 6568, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003142, mean_q: 0.004569
 63069/100000: episode: 6569, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000071, mae: 0.003886, mean_q: 0.004935
 63079/100000: episode: 6570, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.003837, mean_q: 0.005135
 63089/100000: episode: 6571, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003676, mean_q: 0.005523
 63099/100000: episode: 6572, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000041, mae: 0.003164, mean_q: 0.004887
 63109/100000: episode: 6573, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000037, mae: 0.003069, mean_q: 0.004503
 63119/100000: episode: 6574, duration: 0.094s, episode steps: 10, steps per second: 107, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000016, mae: 0.003056, mean_q: 0.004486
[Info] 1-TH LEVEL FOUND: 0.006195618771016598, Considering 100/100 traces
 63129/100000: episode: 6575, duration: 1.418s, episode steps: 10, steps per second: 7, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000259, mae: 0.005291, mean_q: 0.005542
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006195618771016598
 63139/100000: episode: 6576, duration: 0.687s, episode steps: 10, steps per second: 15, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003679, mean_q: 0.005446
 63149/100000: episode: 6577, duration: 0.065s, episode steps: 10, steps per second: 155, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000221, mae: 0.004003, mean_q: 0.004830
 63159/100000: episode: 6578, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000106, mae: 0.005100, mean_q: 0.005535
 63169/100000: episode: 6579, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.004247, mean_q: 0.005784
 63179/100000: episode: 6580, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000076, mae: 0.003854, mean_q: 0.004676
 63189/100000: episode: 6581, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003051, mean_q: 0.004907
 63199/100000: episode: 6582, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002542, mean_q: 0.004159
 63209/100000: episode: 6583, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000051, mae: 0.003500, mean_q: 0.004444
 63219/100000: episode: 6584, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000068, mae: 0.004041, mean_q: 0.005324
 63229/100000: episode: 6585, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000034, mae: 0.002890, mean_q: 0.004629
 63239/100000: episode: 6586, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000011, mae: 0.002481, mean_q: 0.004287
 63249/100000: episode: 6587, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002230, mean_q: 0.003859
 63259/100000: episode: 6588, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000039, mae: 0.002797, mean_q: 0.004047
 63269/100000: episode: 6589, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000067, mae: 0.003650, mean_q: 0.004566
 63279/100000: episode: 6590, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003329, mean_q: 0.004913
 63289/100000: episode: 6591, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003016, mean_q: 0.004270
 63299/100000: episode: 6592, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000090, mae: 0.005076, mean_q: 0.004916
 63309/100000: episode: 6593, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000046, mae: 0.004362, mean_q: 0.005928
 63319/100000: episode: 6594, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000028, mae: 0.003670, mean_q: 0.004499
 63329/100000: episode: 6595, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000074, mae: 0.003996, mean_q: 0.004750
 63339/100000: episode: 6596, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000268, mae: 0.004423, mean_q: 0.004710
 63349/100000: episode: 6597, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000080, mae: 0.004672, mean_q: 0.005427
 63359/100000: episode: 6598, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.003244, mean_q: 0.005124
 63369/100000: episode: 6599, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.002952, mean_q: 0.003944
 63379/100000: episode: 6600, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000079, mae: 0.003867, mean_q: 0.004200
 63389/100000: episode: 6601, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000076, mae: 0.004390, mean_q: 0.005410
 63399/100000: episode: 6602, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000028, mae: 0.003523, mean_q: 0.004690
 63409/100000: episode: 6603, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000076, mae: 0.004159, mean_q: 0.004953
 63419/100000: episode: 6604, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000038, mae: 0.003377, mean_q: 0.004972
 63429/100000: episode: 6605, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000076, mae: 0.003462, mean_q: 0.004049
 63439/100000: episode: 6606, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000077, mae: 0.004065, mean_q: 0.004627
 63449/100000: episode: 6607, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000013, mae: 0.003012, mean_q: 0.005133
 63459/100000: episode: 6608, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000048, mae: 0.003191, mean_q: 0.004377
 63469/100000: episode: 6609, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002525, mean_q: 0.004166
 63479/100000: episode: 6610, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000043, mae: 0.003216, mean_q: 0.004359
 63489/100000: episode: 6611, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.003009, mean_q: 0.004643
 63499/100000: episode: 6612, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000009, mae: 0.002214, mean_q: 0.003800
 63509/100000: episode: 6613, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000073, mae: 0.003474, mean_q: 0.003968
 63519/100000: episode: 6614, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000022, mae: 0.003722, mean_q: 0.005306
 63529/100000: episode: 6615, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000008, mae: 0.001995, mean_q: 0.003848
 63539/100000: episode: 6616, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000231, mae: 0.004078, mean_q: 0.003848
 63549/100000: episode: 6617, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000073, mae: 0.004791, mean_q: 0.005895
 63559/100000: episode: 6618, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000241, mae: 0.004495, mean_q: 0.005153
 63569/100000: episode: 6619, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000041, mae: 0.003494, mean_q: 0.004579
 63579/100000: episode: 6620, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000011, mae: 0.002487, mean_q: 0.004154
 63589/100000: episode: 6621, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000055, mae: 0.003366, mean_q: 0.003957
 63599/100000: episode: 6622, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000070, mae: 0.004364, mean_q: 0.005335
 63609/100000: episode: 6623, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000223, mae: 0.003921, mean_q: 0.004718
 63619/100000: episode: 6624, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000018, mae: 0.003061, mean_q: 0.004578
 63629/100000: episode: 6625, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000011, mae: 0.002686, mean_q: 0.004351
 63639/100000: episode: 6626, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000042, mae: 0.002751, mean_q: 0.003676
 63649/100000: episode: 6627, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000038, mae: 0.002918, mean_q: 0.004240
 63659/100000: episode: 6628, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000082, mae: 0.004601, mean_q: 0.004936
 63669/100000: episode: 6629, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.003520, mean_q: 0.005444
 63679/100000: episode: 6630, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000226, mae: 0.003814, mean_q: 0.004129
 63689/100000: episode: 6631, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000312, mae: 0.006864, mean_q: 0.006338
 63699/100000: episode: 6632, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000021, mae: 0.003770, mean_q: 0.005444
 63709/100000: episode: 6633, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000026, mae: 0.002890, mean_q: 0.003603
 63719/100000: episode: 6634, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000020, mae: 0.003039, mean_q: 0.004270
 63729/100000: episode: 6635, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000290, mae: 0.006114, mean_q: 0.005658
 63739/100000: episode: 6636, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000013, mae: 0.003420, mean_q: 0.005284
 63749/100000: episode: 6637, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000025, mae: 0.002548, mean_q: 0.003209
 63759/100000: episode: 6638, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.002840, mean_q: 0.004112
 63769/100000: episode: 6639, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000227, mae: 0.004494, mean_q: 0.004868
 63779/100000: episode: 6640, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000078, mae: 0.004496, mean_q: 0.005177
 63789/100000: episode: 6641, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000460, mae: 0.006161, mean_q: 0.005191
 63799/100000: episode: 6642, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000051, mae: 0.005004, mean_q: 0.006659
 63809/100000: episode: 6643, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000016, mae: 0.002461, mean_q: 0.004253
 63819/100000: episode: 6644, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000087, mae: 0.004460, mean_q: 0.004703
 63829/100000: episode: 6645, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000049, mae: 0.003816, mean_q: 0.005079
 63839/100000: episode: 6646, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.002895, mean_q: 0.004304
 63849/100000: episode: 6647, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000092, mae: 0.004158, mean_q: 0.004771
 63859/100000: episode: 6648, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000073, mae: 0.004048, mean_q: 0.005049
 63869/100000: episode: 6649, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003287, mean_q: 0.004881
 63879/100000: episode: 6650, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000007, mae: 0.001982, mean_q: 0.003666
 63889/100000: episode: 6651, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000019, mae: 0.002820, mean_q: 0.003977
 63899/100000: episode: 6652, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000046, mae: 0.003681, mean_q: 0.004901
 63909/100000: episode: 6653, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000048, mae: 0.003672, mean_q: 0.004651
 63919/100000: episode: 6654, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000051, mae: 0.003335, mean_q: 0.004259
 63929/100000: episode: 6655, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000043, mae: 0.003366, mean_q: 0.004670
 63939/100000: episode: 6656, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000248, mae: 0.004119, mean_q: 0.004271
 63949/100000: episode: 6657, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000010, mae: 0.003161, mean_q: 0.005262
 63959/100000: episode: 6658, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000019, mae: 0.002312, mean_q: 0.003579
 63969/100000: episode: 6659, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000279, mae: 0.005041, mean_q: 0.004735
 63979/100000: episode: 6660, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000068, mae: 0.004535, mean_q: 0.006182
 63989/100000: episode: 6661, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000017, mae: 0.002428, mean_q: 0.003644
 63999/100000: episode: 6662, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000040, mae: 0.002487, mean_q: 0.003639
 64009/100000: episode: 6663, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000226, mae: 0.004198, mean_q: 0.004708
 64019/100000: episode: 6664, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000018, mae: 0.003591, mean_q: 0.005455
 64029/100000: episode: 6665, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000040, mae: 0.003565, mean_q: 0.004805
 64039/100000: episode: 6666, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.002766, mean_q: 0.003873
 64049/100000: episode: 6667, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000078, mae: 0.003870, mean_q: 0.004525
 64059/100000: episode: 6668, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000085, mae: 0.005271, mean_q: 0.005786
 64069/100000: episode: 6669, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000076, mae: 0.004156, mean_q: 0.004992
 64079/100000: episode: 6670, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000015, mae: 0.002903, mean_q: 0.004466
 64089/100000: episode: 6671, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000083, mae: 0.003734, mean_q: 0.004024
 64099/100000: episode: 6672, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000068, mae: 0.004621, mean_q: 0.006105
 64109/100000: episode: 6673, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000247, mae: 0.004189, mean_q: 0.004705
 64119/100000: episode: 6674, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000045, mae: 0.003501, mean_q: 0.004956
 64129/100000: episode: 6675, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000043, mae: 0.003708, mean_q: 0.005181
[Info] 1-TH LEVEL FOUND: 0.004558975342661142, Considering 100/100 traces
 64139/100000: episode: 6676, duration: 0.879s, episode steps: 10, steps per second: 11, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000096, mae: 0.003693, mean_q: 0.004247
[Info] 2-TH LEVEL FOUND: 0.0052865976467728615, Considering 100/100 traces
 64149/100000: episode: 6677, duration: 1.079s, episode steps: 10, steps per second: 9, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000050, mae: 0.003670, mean_q: 0.004693
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0052865976467728615
 64159/100000: episode: 6678, duration: 0.573s, episode steps: 10, steps per second: 17, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002895, mean_q: 0.004817
 64169/100000: episode: 6679, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.003537, mean_q: 0.003958
 64179/100000: episode: 6680, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000016, mae: 0.003092, mean_q: 0.005130
 64189/100000: episode: 6681, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000082, mae: 0.004003, mean_q: 0.004153
 64199/100000: episode: 6682, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000093, mae: 0.004319, mean_q: 0.005293
 64209/100000: episode: 6683, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000160, mae: 0.006289, mean_q: 0.005993
 64219/100000: episode: 6684, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000077, mae: 0.004834, mean_q: 0.005946
 64229/100000: episode: 6685, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000049, mae: 0.003415, mean_q: 0.004571
 64239/100000: episode: 6686, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000078, mae: 0.004720, mean_q: 0.005716
 64249/100000: episode: 6687, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.003199, mean_q: 0.005078
 64259/100000: episode: 6688, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000069, mae: 0.003491, mean_q: 0.004399
 64269/100000: episode: 6689, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003581, mean_q: 0.005005
 64279/100000: episode: 6690, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.003004, mean_q: 0.004626
 64289/100000: episode: 6691, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000080, mae: 0.003763, mean_q: 0.004260
 64299/100000: episode: 6692, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000019, mae: 0.003435, mean_q: 0.005236
 64309/100000: episode: 6693, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000040, mae: 0.003045, mean_q: 0.004547
 64319/100000: episode: 6694, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003422, mean_q: 0.004342
 64329/100000: episode: 6695, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003118, mean_q: 0.004741
 64339/100000: episode: 6696, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002931, mean_q: 0.004357
 64349/100000: episode: 6697, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000012, mae: 0.002677, mean_q: 0.004124
 64359/100000: episode: 6698, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003307, mean_q: 0.004363
 64369/100000: episode: 6699, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000052, mae: 0.003630, mean_q: 0.004572
 64379/100000: episode: 6700, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000011, mae: 0.002911, mean_q: 0.004791
 64389/100000: episode: 6701, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000097, mae: 0.003364, mean_q: 0.003583
 64399/100000: episode: 6702, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000045, mae: 0.003706, mean_q: 0.004935
 64409/100000: episode: 6703, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000106, mae: 0.004624, mean_q: 0.004912
 64419/100000: episode: 6704, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.003737, mean_q: 0.005568
 64429/100000: episode: 6705, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000044, mae: 0.002993, mean_q: 0.004218
 64439/100000: episode: 6706, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.003171, mean_q: 0.004589
 64449/100000: episode: 6707, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002902, mean_q: 0.004538
 64459/100000: episode: 6708, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000097, mae: 0.003700, mean_q: 0.004121
 64469/100000: episode: 6709, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000016, mae: 0.003675, mean_q: 0.005487
 64479/100000: episode: 6710, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000075, mae: 0.003648, mean_q: 0.004289
 64489/100000: episode: 6711, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000008, mae: 0.002540, mean_q: 0.004357
 64499/100000: episode: 6712, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002355, mean_q: 0.003667
 64509/100000: episode: 6713, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000040, mae: 0.002541, mean_q: 0.003521
 64519/100000: episode: 6714, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.003125, mean_q: 0.004494
 64529/100000: episode: 6715, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000066, mae: 0.003417, mean_q: 0.004202
 64539/100000: episode: 6716, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000046, mae: 0.003510, mean_q: 0.004633
 64549/100000: episode: 6717, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000026, mae: 0.003645, mean_q: 0.004777
 64559/100000: episode: 6718, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000045, mae: 0.003129, mean_q: 0.004068
 64569/100000: episode: 6719, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000022, mae: 0.003226, mean_q: 0.004506
 64579/100000: episode: 6720, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000031, mae: 0.003477, mean_q: 0.004479
 64589/100000: episode: 6721, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.003045, mean_q: 0.004048
 64599/100000: episode: 6722, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.002982, mean_q: 0.004048
 64609/100000: episode: 6723, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.003313, mean_q: 0.004604
 64619/100000: episode: 6724, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000070, mae: 0.003497, mean_q: 0.004155
 64629/100000: episode: 6725, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000026, mae: 0.003553, mean_q: 0.004738
 64639/100000: episode: 6726, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000055, mae: 0.004083, mean_q: 0.004600
 64649/100000: episode: 6727, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003489, mean_q: 0.004747
 64659/100000: episode: 6728, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000049, mae: 0.003583, mean_q: 0.004488
 64669/100000: episode: 6729, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000025, mae: 0.003266, mean_q: 0.004498
 64679/100000: episode: 6730, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000016, mae: 0.002814, mean_q: 0.004467
 64689/100000: episode: 6731, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000034, mae: 0.002371, mean_q: 0.003335
 64699/100000: episode: 6732, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000073, mae: 0.003720, mean_q: 0.004293
 64709/100000: episode: 6733, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000045, mae: 0.003848, mean_q: 0.005203
 64719/100000: episode: 6734, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000080, mae: 0.004182, mean_q: 0.004620
 64729/100000: episode: 6735, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000056, mae: 0.004540, mean_q: 0.005544
 64739/100000: episode: 6736, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000043, mae: 0.003764, mean_q: 0.005083
 64749/100000: episode: 6737, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000035, mae: 0.002907, mean_q: 0.004219
 64759/100000: episode: 6738, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000072, mae: 0.004087, mean_q: 0.004678
 64769/100000: episode: 6739, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000040, mae: 0.003456, mean_q: 0.004714
 64779/100000: episode: 6740, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000069, mae: 0.003623, mean_q: 0.004599
 64789/100000: episode: 6741, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000040, mae: 0.003397, mean_q: 0.004774
 64799/100000: episode: 6742, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000049, mae: 0.003572, mean_q: 0.004420
 64809/100000: episode: 6743, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000046, mae: 0.003437, mean_q: 0.004604
 64819/100000: episode: 6744, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000067, mae: 0.004001, mean_q: 0.005181
 64829/100000: episode: 6745, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000038, mae: 0.003162, mean_q: 0.004681
 64839/100000: episode: 6746, duration: 0.044s, episode steps: 10, steps per second: 226, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000019, mae: 0.002501, mean_q: 0.003418
 64849/100000: episode: 6747, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000015, mae: 0.003026, mean_q: 0.004577
 64859/100000: episode: 6748, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000041, mae: 0.003269, mean_q: 0.004722
 64869/100000: episode: 6749, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000104, mae: 0.004229, mean_q: 0.004377
 64879/100000: episode: 6750, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000014, mae: 0.003045, mean_q: 0.004864
 64889/100000: episode: 6751, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000085, mae: 0.004547, mean_q: 0.004727
 64899/100000: episode: 6752, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000028, mae: 0.003801, mean_q: 0.005124
 64909/100000: episode: 6753, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.002647, mean_q: 0.003871
 64919/100000: episode: 6754, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002656, mean_q: 0.004014
 64929/100000: episode: 6755, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000036, mae: 0.003097, mean_q: 0.004568
 64939/100000: episode: 6756, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000011, mae: 0.002631, mean_q: 0.004134
 64949/100000: episode: 6757, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000048, mae: 0.003468, mean_q: 0.004411
 64959/100000: episode: 6758, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000029, mae: 0.003843, mean_q: 0.004951
 64969/100000: episode: 6759, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000017, mae: 0.002685, mean_q: 0.004059
 64979/100000: episode: 6760, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000011, mae: 0.002310, mean_q: 0.003628
 64989/100000: episode: 6761, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000022, mae: 0.003442, mean_q: 0.004780
 64999/100000: episode: 6762, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000031, mae: 0.004098, mean_q: 0.004886
 65009/100000: episode: 6763, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000019, mae: 0.003286, mean_q: 0.004716
 65019/100000: episode: 6764, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003213, mean_q: 0.003857
 65029/100000: episode: 6765, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002866, mean_q: 0.004711
 65039/100000: episode: 6766, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000027, mae: 0.003351, mean_q: 0.003884
 65049/100000: episode: 6767, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000028, mae: 0.003865, mean_q: 0.004740
 65059/100000: episode: 6768, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000052, mae: 0.003889, mean_q: 0.004760
 65069/100000: episode: 6769, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000006, mae: 0.002371, mean_q: 0.004280
 65079/100000: episode: 6770, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000012, mae: 0.002145, mean_q: 0.003302
 65089/100000: episode: 6771, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000041, mae: 0.003010, mean_q: 0.004237
 65099/100000: episode: 6772, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.003011, mean_q: 0.004147
 65109/100000: episode: 6773, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000059, mae: 0.004166, mean_q: 0.004662
 65119/100000: episode: 6774, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000074, mae: 0.004149, mean_q: 0.004833
 65129/100000: episode: 6775, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000073, mae: 0.004195, mean_q: 0.004621
 65139/100000: episode: 6776, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.003762, mean_q: 0.005275
 65149/100000: episode: 6777, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000044, mae: 0.003838, mean_q: 0.004875
[Info] 1-TH LEVEL FOUND: 0.005062315613031387, Considering 100/100 traces
 65159/100000: episode: 6778, duration: 0.670s, episode steps: 10, steps per second: 15, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000068, mae: 0.003989, mean_q: 0.004866
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005062315613031387
 65169/100000: episode: 6779, duration: 0.491s, episode steps: 10, steps per second: 20, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000013, mae: 0.002697, mean_q: 0.004381
 65179/100000: episode: 6780, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000009, mae: 0.001945, mean_q: 0.003339
 65189/100000: episode: 6781, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003288, mean_q: 0.004083
 65199/100000: episode: 6782, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000047, mae: 0.004345, mean_q: 0.005717
 65209/100000: episode: 6783, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000079, mae: 0.004129, mean_q: 0.004314
 65219/100000: episode: 6784, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000044, mae: 0.003745, mean_q: 0.005041
 65229/100000: episode: 6785, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000050, mae: 0.003666, mean_q: 0.004494
 65239/100000: episode: 6786, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000013, mae: 0.002872, mean_q: 0.004553
 65249/100000: episode: 6787, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000018, mae: 0.002624, mean_q: 0.003816
 65259/100000: episode: 6788, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000043, mae: 0.003019, mean_q: 0.004092
 65269/100000: episode: 6789, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000044, mae: 0.003583, mean_q: 0.004695
 65279/100000: episode: 6790, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000018, mae: 0.002990, mean_q: 0.004430
 65289/100000: episode: 6791, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000007, mae: 0.002267, mean_q: 0.003704
 65299/100000: episode: 6792, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000056, mae: 0.004164, mean_q: 0.004546
 65309/100000: episode: 6793, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000064, mae: 0.004147, mean_q: 0.005197
 65319/100000: episode: 6794, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000034, mae: 0.003478, mean_q: 0.004343
 65329/100000: episode: 6795, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000025, mae: 0.003349, mean_q: 0.004427
 65339/100000: episode: 6796, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000075, mae: 0.003724, mean_q: 0.004332
 65349/100000: episode: 6797, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003472, mean_q: 0.004988
 65359/100000: episode: 6798, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000049, mae: 0.003332, mean_q: 0.004044
 65369/100000: episode: 6799, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000030, mae: 0.003589, mean_q: 0.004417
 65379/100000: episode: 6800, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000036, mae: 0.003273, mean_q: 0.004719
 65389/100000: episode: 6801, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000011, mae: 0.002262, mean_q: 0.003531
 65399/100000: episode: 6802, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.002859, mean_q: 0.004007
 65409/100000: episode: 6803, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000010, mae: 0.002432, mean_q: 0.003856
 65419/100000: episode: 6804, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000071, mae: 0.003165, mean_q: 0.003850
 65429/100000: episode: 6805, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000035, mae: 0.003126, mean_q: 0.004515
 65439/100000: episode: 6806, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000029, mae: 0.003391, mean_q: 0.004252
 65449/100000: episode: 6807, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000045, mae: 0.003923, mean_q: 0.005310
 65459/100000: episode: 6808, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000074, mae: 0.003822, mean_q: 0.004322
 65469/100000: episode: 6809, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000072, mae: 0.004167, mean_q: 0.004780
 65479/100000: episode: 6810, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000016, mae: 0.002978, mean_q: 0.004665
 65489/100000: episode: 6811, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000047, mae: 0.002927, mean_q: 0.003758
 65499/100000: episode: 6812, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000014, mae: 0.003149, mean_q: 0.004859
 65509/100000: episode: 6813, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.003217, mean_q: 0.004360
 65519/100000: episode: 6814, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000126, mae: 0.004899, mean_q: 0.004858
 65529/100000: episode: 6815, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000131, mae: 0.006401, mean_q: 0.006545
 65539/100000: episode: 6816, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000049, mae: 0.003904, mean_q: 0.005156
 65549/100000: episode: 6817, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000074, mae: 0.003970, mean_q: 0.004532
 65559/100000: episode: 6818, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000018, mae: 0.003249, mean_q: 0.004934
 65569/100000: episode: 6819, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000039, mae: 0.003051, mean_q: 0.004184
 65579/100000: episode: 6820, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000040, mae: 0.003686, mean_q: 0.005118
 65589/100000: episode: 6821, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000042, mae: 0.003058, mean_q: 0.004089
 65599/100000: episode: 6822, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000053, mae: 0.003979, mean_q: 0.005073
 65609/100000: episode: 6823, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000018, mae: 0.002900, mean_q: 0.004277
 65619/100000: episode: 6824, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000081, mae: 0.004324, mean_q: 0.004517
 65629/100000: episode: 6825, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000032, mae: 0.004123, mean_q: 0.005478
 65639/100000: episode: 6826, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000006, mae: 0.002580, mean_q: 0.004768
 65649/100000: episode: 6827, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000127, mae: 0.004824, mean_q: 0.004573
 65659/100000: episode: 6828, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000084, mae: 0.005694, mean_q: 0.006888
 65669/100000: episode: 6829, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000085, mae: 0.004492, mean_q: 0.004796
 65679/100000: episode: 6830, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000035, mae: 0.003408, mean_q: 0.005425
 65689/100000: episode: 6831, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000053, mae: 0.003309, mean_q: 0.003547
 65699/100000: episode: 6832, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000021, mae: 0.003853, mean_q: 0.005980
 65709/100000: episode: 6833, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.002954, mean_q: 0.003869
 65719/100000: episode: 6834, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000023, mae: 0.003424, mean_q: 0.004747
 65729/100000: episode: 6835, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002998, mean_q: 0.004827
 65739/100000: episode: 6836, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002462, mean_q: 0.003687
 65749/100000: episode: 6837, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000051, mae: 0.003957, mean_q: 0.004917
 65759/100000: episode: 6838, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000090, mae: 0.005635, mean_q: 0.005955
 65769/100000: episode: 6839, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000096, mae: 0.004033, mean_q: 0.004599
 65779/100000: episode: 6840, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000097, mae: 0.004616, mean_q: 0.005403
 65789/100000: episode: 6841, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000049, mae: 0.004118, mean_q: 0.005497
 65799/100000: episode: 6842, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003714, mean_q: 0.004760
 65809/100000: episode: 6843, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000042, mae: 0.003431, mean_q: 0.005080
 65819/100000: episode: 6844, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000083, mae: 0.004191, mean_q: 0.004336
 65829/100000: episode: 6845, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000076, mae: 0.005015, mean_q: 0.005920
 65839/100000: episode: 6846, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000070, mae: 0.004349, mean_q: 0.005565
 65849/100000: episode: 6847, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000077, mae: 0.003651, mean_q: 0.004272
 65859/100000: episode: 6848, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000069, mae: 0.004704, mean_q: 0.006271
 65869/100000: episode: 6849, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000011, mae: 0.002495, mean_q: 0.004146
 65879/100000: episode: 6850, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003146, mean_q: 0.003712
 65889/100000: episode: 6851, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.004299, mean_q: 0.006108
 65899/100000: episode: 6852, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000076, mae: 0.003563, mean_q: 0.003856
 65909/100000: episode: 6853, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000058, mae: 0.005118, mean_q: 0.006292
 65919/100000: episode: 6854, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000042, mae: 0.003538, mean_q: 0.004636
 65929/100000: episode: 6855, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002397, mean_q: 0.003855
 65939/100000: episode: 6856, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000067, mae: 0.004055, mean_q: 0.005384
 65949/100000: episode: 6857, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000010, mae: 0.002269, mean_q: 0.003883
 65959/100000: episode: 6858, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000076, mae: 0.003964, mean_q: 0.004270
 65969/100000: episode: 6859, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000024, mae: 0.004307, mean_q: 0.006071
 65979/100000: episode: 6860, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000020, mae: 0.002752, mean_q: 0.004108
 65989/100000: episode: 6861, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000034, mae: 0.003735, mean_q: 0.004294
 65999/100000: episode: 6862, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000024, mae: 0.003914, mean_q: 0.005418
 66009/100000: episode: 6863, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000135, mae: 0.005057, mean_q: 0.004230
 66019/100000: episode: 6864, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.004580, mean_q: 0.006855
 66029/100000: episode: 6865, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000059, mae: 0.003642, mean_q: 0.003682
 66039/100000: episode: 6866, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000110, mae: 0.006097, mean_q: 0.006732
 66049/100000: episode: 6867, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000048, mae: 0.004311, mean_q: 0.005763
 66059/100000: episode: 6868, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000013, mae: 0.002903, mean_q: 0.004522
 66069/100000: episode: 6869, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000009, mae: 0.002394, mean_q: 0.004351
 66079/100000: episode: 6870, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000029, mae: 0.003153, mean_q: 0.004051
 66089/100000: episode: 6871, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000069, mae: 0.003986, mean_q: 0.005274
 66099/100000: episode: 6872, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000016, mae: 0.003052, mean_q: 0.004704
 66109/100000: episode: 6873, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000047, mae: 0.003901, mean_q: 0.005219
 66119/100000: episode: 6874, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000012, mae: 0.002304, mean_q: 0.003938
 66129/100000: episode: 6875, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000116, mae: 0.005124, mean_q: 0.004949
 66139/100000: episode: 6876, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.004333, mean_q: 0.006354
 66149/100000: episode: 6877, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000049, mae: 0.002897, mean_q: 0.003611
 66159/100000: episode: 6878, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.004659, mean_q: 0.005947
[Info] 1-TH LEVEL FOUND: 0.004318224266171455, Considering 100/100 traces
 66169/100000: episode: 6879, duration: 0.697s, episode steps: 10, steps per second: 14, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000054, mae: 0.003589, mean_q: 0.004245
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004318224266171455
 66179/100000: episode: 6880, duration: 0.476s, episode steps: 10, steps per second: 21, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000015, mae: 0.003105, mean_q: 0.004939
 66189/100000: episode: 6881, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000018, mae: 0.002734, mean_q: 0.003938
 66199/100000: episode: 6882, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000011, mae: 0.002485, mean_q: 0.004140
 66209/100000: episode: 6883, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000116, mae: 0.005680, mean_q: 0.005676
 66219/100000: episode: 6884, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000092, mae: 0.005609, mean_q: 0.005918
 66229/100000: episode: 6885, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000047, mae: 0.003839, mean_q: 0.004931
 66239/100000: episode: 6886, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000050, mae: 0.003841, mean_q: 0.004742
 66249/100000: episode: 6887, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000015, mae: 0.003024, mean_q: 0.004824
 66259/100000: episode: 6888, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002685, mean_q: 0.004086
 66269/100000: episode: 6889, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000036, mae: 0.003245, mean_q: 0.004718
 66279/100000: episode: 6890, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000079, mae: 0.004661, mean_q: 0.005206
 66289/100000: episode: 6891, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000064, mae: 0.004838, mean_q: 0.005632
[Info] FALSIFICATION!
 66299/100000: episode: 6892, duration: 0.280s, episode steps: 10, steps per second: 36, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000067, mae: 0.005722, mean_q: 0.006839
 66309/100000: episode: 6893, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000106, mae: 0.004302, mean_q: 0.004602
 66319/100000: episode: 6894, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000078, mae: 0.005191, mean_q: 0.006379
 66329/100000: episode: 6895, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000059, mae: 0.004305, mean_q: 0.005070
 66339/100000: episode: 6896, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000042, mae: 0.006968, mean_q: 0.009568
 66349/100000: episode: 6897, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000023, mae: 0.003297, mean_q: 0.004206
 66359/100000: episode: 6898, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003238, mean_q: 0.004000
 66369/100000: episode: 6899, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000107, mae: 0.005761, mean_q: 0.006426
 66379/100000: episode: 6900, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000052, mae: 0.004323, mean_q: 0.005537
 66389/100000: episode: 6901, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000073, mae: 0.003802, mean_q: 0.004807
 66399/100000: episode: 6902, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000247, mae: 0.005245, mean_q: 0.006273
 66409/100000: episode: 6903, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000011, mae: 0.002792, mean_q: 0.004688
 66419/100000: episode: 6904, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000265, mae: 0.005154, mean_q: 0.005144
 66429/100000: episode: 6905, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000075, mae: 0.004751, mean_q: 0.006128
 66439/100000: episode: 6906, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000071, mae: 0.003926, mean_q: 0.005089
 66449/100000: episode: 6907, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.003522, mean_q: 0.005382
 66459/100000: episode: 6908, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000047, mae: 0.003715, mean_q: 0.005034
 66469/100000: episode: 6909, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000281, mae: 0.005204, mean_q: 0.005423
 66479/100000: episode: 6910, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000282, mae: 0.006465, mean_q: 0.007037
 66489/100000: episode: 6911, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000077, mae: 0.004849, mean_q: 0.006210
 66499/100000: episode: 6912, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000259, mae: 0.005987, mean_q: 0.006542
 66509/100000: episode: 6913, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.003703, mean_q: 0.005678
 66519/100000: episode: 6914, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000027, mae: 0.003105, mean_q: 0.004365
 66529/100000: episode: 6915, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000273, mae: 0.005285, mean_q: 0.005667
 66539/100000: episode: 6916, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000064, mae: 0.005983, mean_q: 0.007570
 66549/100000: episode: 6917, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001587, mae: 0.006362, mean_q: 0.005058
 66559/100000: episode: 6918, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.004867, mean_q: 0.007773
 66569/100000: episode: 6919, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002285, mean_q: 0.003728
 66579/100000: episode: 6920, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.002272, mean_q: 0.003786
 66589/100000: episode: 6921, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000304, mae: 0.006157, mean_q: 0.006097
 66599/100000: episode: 6922, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000042, mae: 0.004121, mean_q: 0.006253
 66609/100000: episode: 6923, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000242, mae: 0.005323, mean_q: 0.005736
 66619/100000: episode: 6924, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001591, mae: 0.007335, mean_q: 0.005963
 66629/100000: episode: 6925, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000059, mae: 0.006431, mean_q: 0.009120
 66639/100000: episode: 6926, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001980, mae: 0.010206, mean_q: 0.007686
 66649/100000: episode: 6927, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000260, mae: 0.007314, mean_q: 0.008732
 66659/100000: episode: 6928, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000045, mae: 0.004041, mean_q: 0.005964
 66669/100000: episode: 6929, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000081, mae: 0.003975, mean_q: 0.005118
 66679/100000: episode: 6930, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000043, mae: 0.003684, mean_q: 0.005832
 66689/100000: episode: 6931, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000077, mae: 0.004234, mean_q: 0.005703
 66699/100000: episode: 6932, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000166, mae: 0.006726, mean_q: 0.007067
 66709/100000: episode: 6933, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000034, mae: 0.004850, mean_q: 0.007161
 66719/100000: episode: 6934, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003322, mean_q: 0.005021
 66729/100000: episode: 6935, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001788, mae: 0.009050, mean_q: 0.006920
 66739/100000: episode: 6936, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000082, mae: 0.006924, mean_q: 0.009660
 66749/100000: episode: 6937, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000057, mae: 0.003881, mean_q: 0.004816
 66759/100000: episode: 6938, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000017, mae: 0.003155, mean_q: 0.005249
 66769/100000: episode: 6939, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001593, mae: 0.007643, mean_q: 0.006607
 66779/100000: episode: 6940, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.005258, mean_q: 0.007946
 66789/100000: episode: 6941, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000077, mae: 0.003908, mean_q: 0.005196
 66799/100000: episode: 6942, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000038, mae: 0.002932, mean_q: 0.004942
 66809/100000: episode: 6943, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.003264, mean_q: 0.005029
 66819/100000: episode: 6944, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000258, mae: 0.005505, mean_q: 0.006268
 66829/100000: episode: 6945, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001627, mae: 0.008844, mean_q: 0.007199
 66839/100000: episode: 6946, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000020, mae: 0.005324, mean_q: 0.008748
 66849/100000: episode: 6947, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000038, mae: 0.002685, mean_q: 0.004341
 66859/100000: episode: 6948, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001581, mae: 0.006591, mean_q: 0.004588
 66869/100000: episode: 6949, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000062, mae: 0.007084, mean_q: 0.009684
 66879/100000: episode: 6950, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000028, mae: 0.003721, mean_q: 0.005498
 66889/100000: episode: 6951, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000024, mae: 0.003069, mean_q: 0.004573
 66899/100000: episode: 6952, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000021, mae: 0.003983, mean_q: 0.006188
 66909/100000: episode: 6953, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000023, mae: 0.003283, mean_q: 0.005018
 66919/100000: episode: 6954, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000056, mae: 0.003704, mean_q: 0.004850
 66929/100000: episode: 6955, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000072, mae: 0.004407, mean_q: 0.005897
 66939/100000: episode: 6956, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000014, mae: 0.003037, mean_q: 0.005441
 66949/100000: episode: 6957, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002649, mean_q: 0.004184
 66959/100000: episode: 6958, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000043, mae: 0.003371, mean_q: 0.004843
 66969/100000: episode: 6959, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000044, mae: 0.003792, mean_q: 0.005431
 66979/100000: episode: 6960, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000081, mae: 0.004519, mean_q: 0.005357
 66989/100000: episode: 6961, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000230, mae: 0.004805, mean_q: 0.005621
 66999/100000: episode: 6962, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000228, mae: 0.004909, mean_q: 0.006042
 67009/100000: episode: 6963, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000030, mae: 0.004307, mean_q: 0.006073
 67019/100000: episode: 6964, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000233, mae: 0.004630, mean_q: 0.005013
 67029/100000: episode: 6965, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000029, mae: 0.004315, mean_q: 0.006207
 67039/100000: episode: 6966, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003699, mean_q: 0.005814
 67049/100000: episode: 6967, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000073, mae: 0.004152, mean_q: 0.005085
 67059/100000: episode: 6968, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003482, mean_q: 0.005495
 67069/100000: episode: 6969, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000074, mae: 0.004059, mean_q: 0.005147
 67079/100000: episode: 6970, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000087, mae: 0.004917, mean_q: 0.005842
 67089/100000: episode: 6971, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000020, mae: 0.003631, mean_q: 0.005628
 67099/100000: episode: 6972, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000282, mae: 0.005250, mean_q: 0.005351
 67109/100000: episode: 6973, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000054, mae: 0.004914, mean_q: 0.006482
 67119/100000: episode: 6974, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000071, mae: 0.004594, mean_q: 0.006248
 67129/100000: episode: 6975, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000282, mae: 0.005713, mean_q: 0.005637
 67139/100000: episode: 6976, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000049, mae: 0.005120, mean_q: 0.007284
 67149/100000: episode: 6977, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000046, mae: 0.003999, mean_q: 0.005551
 67159/100000: episode: 6978, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003212, mean_q: 0.004766
 67169/100000: episode: 6979, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000258, mae: 0.005515, mean_q: 0.005772
[Info] Complete ISplit Iteration
[Info] Levels: [0.0052231713]
[Info] Cond. Prob: [1.0]
[Info] Error Prob: 1.0

 67179/100000: episode: 6980, duration: 0.825s, episode steps: 10, steps per second: 12, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000031, mae: 0.004371, mean_q: 0.005897
 67189/100000: episode: 6981, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.003443, mean_q: 0.005486
 67199/100000: episode: 6982, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000047, mae: 0.003790, mean_q: 0.005267
 67209/100000: episode: 6983, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000076, mae: 0.004217, mean_q: 0.005421
 67219/100000: episode: 6984, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.003620, mean_q: 0.005972
 67229/100000: episode: 6985, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001593, mae: 0.006603, mean_q: 0.004870
 67239/100000: episode: 6986, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000051, mae: 0.005933, mean_q: 0.008345
 67249/100000: episode: 6987, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000072, mae: 0.004266, mean_q: 0.005489
 67259/100000: episode: 6988, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000288, mae: 0.005454, mean_q: 0.005198
 67269/100000: episode: 6989, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000055, mae: 0.005544, mean_q: 0.007377
 67279/100000: episode: 6990, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001569, mae: 0.007744, mean_q: 0.007108
 67289/100000: episode: 6991, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000023, mae: 0.004779, mean_q: 0.007402
 67299/100000: episode: 6992, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000056, mae: 0.003814, mean_q: 0.004977
 67309/100000: episode: 6993, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000071, mae: 0.004325, mean_q: 0.005955
 67319/100000: episode: 6994, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000033, mae: 0.004253, mean_q: 0.005684
 67329/100000: episode: 6995, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000054, mae: 0.004131, mean_q: 0.005472
 67339/100000: episode: 6996, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000057, mae: 0.005023, mean_q: 0.006392
 67349/100000: episode: 6997, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000047, mae: 0.004167, mean_q: 0.006114
 67359/100000: episode: 6998, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000226, mae: 0.004078, mean_q: 0.004732
 67369/100000: episode: 6999, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000052, mae: 0.004738, mean_q: 0.006493
 67379/100000: episode: 7000, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000049, mae: 0.004178, mean_q: 0.005578
 67389/100000: episode: 7001, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000103, mae: 0.004508, mean_q: 0.005076
 67399/100000: episode: 7002, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000030, mae: 0.004344, mean_q: 0.006343
 67409/100000: episode: 7003, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000041, mae: 0.003301, mean_q: 0.005448
 67419/100000: episode: 7004, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000056, mae: 0.004013, mean_q: 0.004973
 67429/100000: episode: 7005, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000225, mae: 0.005035, mean_q: 0.006027
 67439/100000: episode: 7006, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000291, mae: 0.006566, mean_q: 0.006337
 67449/100000: episode: 7007, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000029, mae: 0.004978, mean_q: 0.007279
 67459/100000: episode: 7008, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000054, mae: 0.003937, mean_q: 0.004872
 67469/100000: episode: 7009, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000258, mae: 0.005109, mean_q: 0.005687
 67479/100000: episode: 7010, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001622, mae: 0.008517, mean_q: 0.007002
 67489/100000: episode: 7011, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001574, mae: 0.009270, mean_q: 0.009082
 67499/100000: episode: 7012, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000077, mae: 0.005706, mean_q: 0.007771
 67509/100000: episode: 7013, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000015, mae: 0.003182, mean_q: 0.005621
 67519/100000: episode: 7014, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000016, mae: 0.002625, mean_q: 0.004404
 67529/100000: episode: 7015, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000023, mae: 0.003377, mean_q: 0.005309
 67539/100000: episode: 7016, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000262, mae: 0.005651, mean_q: 0.006319
 67549/100000: episode: 7017, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000078, mae: 0.005325, mean_q: 0.006951
 67559/100000: episode: 7018, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.004625, mean_q: 0.006488
 67569/100000: episode: 7019, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000042, mae: 0.003296, mean_q: 0.005024
 67579/100000: episode: 7020, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000021, mae: 0.003764, mean_q: 0.005921
 67589/100000: episode: 7021, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000059, mae: 0.005425, mean_q: 0.007191
 67599/100000: episode: 7022, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000067, mae: 0.003836, mean_q: 0.005400
 67609/100000: episode: 7023, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003066, mean_q: 0.004942
 67619/100000: episode: 7024, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000044, mae: 0.003785, mean_q: 0.005465
 67629/100000: episode: 7025, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000053, mae: 0.004312, mean_q: 0.005970
 67639/100000: episode: 7026, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000252, mae: 0.004804, mean_q: 0.005650
 67649/100000: episode: 7027, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000109, mae: 0.005381, mean_q: 0.006368
 67659/100000: episode: 7028, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000061, mae: 0.005603, mean_q: 0.007098
 67669/100000: episode: 7029, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000043, mae: 0.003774, mean_q: 0.005866
 67679/100000: episode: 7030, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000081, mae: 0.004363, mean_q: 0.005606
 67689/100000: episode: 7031, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000026, mae: 0.004196, mean_q: 0.005961
 67699/100000: episode: 7032, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000129, mae: 0.004945, mean_q: 0.005549
 67709/100000: episode: 7033, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.003523, mean_q: 0.005883
 67719/100000: episode: 7034, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003102, mean_q: 0.004710
 67729/100000: episode: 7035, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000252, mae: 0.004830, mean_q: 0.005643
 67739/100000: episode: 7036, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001565, mae: 0.008000, mean_q: 0.007724
 67749/100000: episode: 7037, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000096, mae: 0.006634, mean_q: 0.007903
 67759/100000: episode: 7038, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.003955, mean_q: 0.005738
 67769/100000: episode: 7039, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000218, mae: 0.003550, mean_q: 0.004470
 67779/100000: episode: 7040, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000019, mae: 0.003455, mean_q: 0.005694
 67789/100000: episode: 7041, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000055, mae: 0.004534, mean_q: 0.006097
 67799/100000: episode: 7042, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000237, mae: 0.004932, mean_q: 0.005624
 67809/100000: episode: 7043, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000059, mae: 0.005170, mean_q: 0.006524
 67819/100000: episode: 7044, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000044, mae: 0.003524, mean_q: 0.005367
 67829/100000: episode: 7045, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000074, mae: 0.003907, mean_q: 0.005084
 67839/100000: episode: 7046, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003625, mean_q: 0.005788
 67849/100000: episode: 7047, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.001627, mae: 0.008483, mean_q: 0.006769
 67859/100000: episode: 7048, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.005025, mean_q: 0.007937
 67869/100000: episode: 7049, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.002725, mean_q: 0.004376
 67879/100000: episode: 7050, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000046, mae: 0.003031, mean_q: 0.004543
 67889/100000: episode: 7051, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003839, mean_q: 0.005669
 67899/100000: episode: 7052, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000075, mae: 0.004351, mean_q: 0.005521
 67909/100000: episode: 7053, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000017, mae: 0.003412, mean_q: 0.005403
 67919/100000: episode: 7054, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000022, mae: 0.003150, mean_q: 0.004790
 67929/100000: episode: 7055, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000232, mae: 0.004945, mean_q: 0.005550
 67939/100000: episode: 7056, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000052, mae: 0.004718, mean_q: 0.006480
 67949/100000: episode: 7057, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003832, mean_q: 0.005909
 67959/100000: episode: 7058, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003468, mean_q: 0.005108
 67969/100000: episode: 7059, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001598, mae: 0.007538, mean_q: 0.006114
 67979/100000: episode: 7060, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000060, mae: 0.006951, mean_q: 0.009341
 67989/100000: episode: 7061, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000025, mae: 0.003328, mean_q: 0.005137
 67999/100000: episode: 7062, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000040, mae: 0.002707, mean_q: 0.003774
 68009/100000: episode: 7063, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000019, mae: 0.003100, mean_q: 0.005100
 68019/100000: episode: 7064, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000257, mae: 0.005516, mean_q: 0.005970
 68029/100000: episode: 7065, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000221, mae: 0.004925, mean_q: 0.006337
 68039/100000: episode: 7066, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001623, mae: 0.007756, mean_q: 0.005967
 68049/100000: episode: 7067, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000023, mae: 0.005599, mean_q: 0.008591
 68059/100000: episode: 7068, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.003669, mean_q: 0.005533
 68069/100000: episode: 7069, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000029, mae: 0.003388, mean_q: 0.004102
 68079/100000: episode: 7070, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000032, mae: 0.004386, mean_q: 0.006291
 68089/100000: episode: 7071, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000070, mae: 0.004265, mean_q: 0.005965
 68099/100000: episode: 7072, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000075, mae: 0.004520, mean_q: 0.005844
 68109/100000: episode: 7073, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000016, mae: 0.003680, mean_q: 0.005939
 68119/100000: episode: 7074, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000043, mae: 0.003241, mean_q: 0.004482
 68129/100000: episode: 7075, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001582, mae: 0.007607, mean_q: 0.005951
 68139/100000: episode: 7076, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.005917, mean_q: 0.008457
 68149/100000: episode: 7077, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000047, mae: 0.003569, mean_q: 0.005218
 68159/100000: episode: 7078, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000263, mae: 0.005349, mean_q: 0.005014
 68169/100000: episode: 7079, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.004597, mean_q: 0.007028
[Info] 1-TH LEVEL FOUND: 0.004440481774508953, Considering 100/100 traces
 68179/100000: episode: 7080, duration: 0.790s, episode steps: 10, steps per second: 13, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000016, mae: 0.003223, mean_q: 0.005286
[Info] 2-TH LEVEL FOUND: 0.005527293309569359, Considering 100/100 traces
 68189/100000: episode: 7081, duration: 0.728s, episode steps: 10, steps per second: 14, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000027, mae: 0.003355, mean_q: 0.004830
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005527293309569359
 68199/100000: episode: 7082, duration: 0.491s, episode steps: 10, steps per second: 20, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003515, mean_q: 0.005589
 68209/100000: episode: 7083, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000026, mae: 0.003495, mean_q: 0.005038
 68219/100000: episode: 7084, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000045, mae: 0.003290, mean_q: 0.004940
 68229/100000: episode: 7085, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000070, mae: 0.003892, mean_q: 0.005306
 68239/100000: episode: 7086, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.002950, mean_q: 0.004952
 68249/100000: episode: 7087, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000051, mae: 0.003847, mean_q: 0.004940
 68259/100000: episode: 7088, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000020, mae: 0.002984, mean_q: 0.004868
 68269/100000: episode: 7089, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001626, mae: 0.007970, mean_q: 0.005973
 68279/100000: episode: 7090, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000089, mae: 0.007205, mean_q: 0.008867
 68289/100000: episode: 7091, duration: 0.044s, episode steps: 10, steps per second: 225, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.003879, mean_q: 0.005472
 68299/100000: episode: 7092, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000262, mae: 0.004437, mean_q: 0.004327
 68309/100000: episode: 7093, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.004061, mean_q: 0.006577
 68319/100000: episode: 7094, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000110, mae: 0.005091, mean_q: 0.005723
 68329/100000: episode: 7095, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000051, mae: 0.003977, mean_q: 0.005339
 68339/100000: episode: 7096, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000048, mae: 0.003664, mean_q: 0.005435
 68349/100000: episode: 7097, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000057, mae: 0.003878, mean_q: 0.004879
 68359/100000: episode: 7098, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000088, mae: 0.005234, mean_q: 0.006150
 68369/100000: episode: 7099, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.003921, mean_q: 0.005831
 68379/100000: episode: 7100, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000031, mae: 0.003618, mean_q: 0.004635
 68389/100000: episode: 7101, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000037, mae: 0.002909, mean_q: 0.004601
 68399/100000: episode: 7102, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000055, mae: 0.004039, mean_q: 0.004914
 68409/100000: episode: 7103, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000251, mae: 0.005378, mean_q: 0.005895
 68419/100000: episode: 7104, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000028, mae: 0.004821, mean_q: 0.007082
 68429/100000: episode: 7105, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000031, mae: 0.003848, mean_q: 0.005273
 68439/100000: episode: 7106, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000016, mae: 0.003013, mean_q: 0.004723
 68449/100000: episode: 7107, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000088, mae: 0.004877, mean_q: 0.005473
 68459/100000: episode: 7108, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.004189, mean_q: 0.006255
 68469/100000: episode: 7109, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001592, mae: 0.007109, mean_q: 0.005708
 68479/100000: episode: 7110, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000119, mae: 0.007325, mean_q: 0.008369
 68489/100000: episode: 7111, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000062, mae: 0.004905, mean_q: 0.006219
 68499/100000: episode: 7112, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000288, mae: 0.005159, mean_q: 0.005100
 68509/100000: episode: 7113, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000016, mae: 0.004011, mean_q: 0.006701
 68519/100000: episode: 7114, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000026, mae: 0.003414, mean_q: 0.004971
 68529/100000: episode: 7115, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000073, mae: 0.004118, mean_q: 0.005462
 68539/100000: episode: 7116, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000056, mae: 0.004722, mean_q: 0.006409
 68549/100000: episode: 7117, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000034, mae: 0.004596, mean_q: 0.006312
 68559/100000: episode: 7118, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003416, mean_q: 0.005068
 68569/100000: episode: 7119, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000134, mae: 0.005618, mean_q: 0.005845
 68579/100000: episode: 7120, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000083, mae: 0.006731, mean_q: 0.008651
 68589/100000: episode: 7121, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003400, mean_q: 0.005210
 68599/100000: episode: 7122, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000040, mae: 0.002814, mean_q: 0.004123
 68609/100000: episode: 7123, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000257, mae: 0.005563, mean_q: 0.006143
 68619/100000: episode: 7124, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000023, mae: 0.005586, mean_q: 0.008638
 68629/100000: episode: 7125, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000237, mae: 0.004919, mean_q: 0.005239
 68639/100000: episode: 7126, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000238, mae: 0.005115, mean_q: 0.005587
 68649/100000: episode: 7127, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000043, mae: 0.004398, mean_q: 0.006980
 68659/100000: episode: 7128, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000050, mae: 0.003349, mean_q: 0.004637
 68669/100000: episode: 7129, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000231, mae: 0.004919, mean_q: 0.005822
 68679/100000: episode: 7130, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003962, mean_q: 0.006225
 68689/100000: episode: 7131, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000020, mae: 0.002764, mean_q: 0.004300
 68699/100000: episode: 7132, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000058, mae: 0.004266, mean_q: 0.005429
 68709/100000: episode: 7133, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000224, mae: 0.004213, mean_q: 0.005220
 68719/100000: episode: 7134, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000242, mae: 0.005428, mean_q: 0.005926
 68729/100000: episode: 7135, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001832, mae: 0.011552, mean_q: 0.009350
 68739/100000: episode: 7136, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000054, mae: 0.006053, mean_q: 0.009039
 68749/100000: episode: 7137, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000107, mae: 0.004357, mean_q: 0.004904
 68759/100000: episode: 7138, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000159, mae: 0.005655, mean_q: 0.005895
 68769/100000: episode: 7139, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000074, mae: 0.004965, mean_q: 0.006885
 68779/100000: episode: 7140, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000044, mae: 0.003163, mean_q: 0.005219
 68789/100000: episode: 7141, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000025, mae: 0.003388, mean_q: 0.005031
 68799/100000: episode: 7142, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000221, mae: 0.004404, mean_q: 0.005674
 68809/100000: episode: 7143, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001640, mae: 0.008405, mean_q: 0.007020
 68819/100000: episode: 7144, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000072, mae: 0.006256, mean_q: 0.009272
 68829/100000: episode: 7145, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.003144, mean_q: 0.005233
 68839/100000: episode: 7146, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000097, mae: 0.003617, mean_q: 0.004564
 68849/100000: episode: 7147, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000036, mae: 0.004430, mean_q: 0.005882
 68859/100000: episode: 7148, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.003808, mean_q: 0.006697
 68869/100000: episode: 7149, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000041, mae: 0.003307, mean_q: 0.004975
 68879/100000: episode: 7150, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000245, mae: 0.005637, mean_q: 0.005983
 68889/100000: episode: 7151, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000109, mae: 0.005821, mean_q: 0.006948
 68899/100000: episode: 7152, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000247, mae: 0.004944, mean_q: 0.006220
 68909/100000: episode: 7153, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000078, mae: 0.004651, mean_q: 0.006012
 68919/100000: episode: 7154, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003882, mean_q: 0.005949
 68929/100000: episode: 7155, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000047, mae: 0.003459, mean_q: 0.005047
 68939/100000: episode: 7156, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000012, mae: 0.002834, mean_q: 0.005012
 68949/100000: episode: 7157, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000056, mae: 0.004355, mean_q: 0.005866
 68959/100000: episode: 7158, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000009, mae: 0.003152, mean_q: 0.005906
 68969/100000: episode: 7159, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000022, mae: 0.002767, mean_q: 0.004074
 68979/100000: episode: 7160, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000027, mae: 0.003342, mean_q: 0.005048
 68989/100000: episode: 7161, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.003041, mean_q: 0.005298
 68999/100000: episode: 7162, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000071, mae: 0.003768, mean_q: 0.004976
 69009/100000: episode: 7163, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000039, mae: 0.003226, mean_q: 0.005102
 69019/100000: episode: 7164, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000472, mae: 0.007124, mean_q: 0.005948
 69029/100000: episode: 7165, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000052, mae: 0.006067, mean_q: 0.008427
 69039/100000: episode: 7166, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000048, mae: 0.003627, mean_q: 0.005191
 69049/100000: episode: 7167, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003139, mean_q: 0.004407
 69059/100000: episode: 7168, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003662, mean_q: 0.005295
 69069/100000: episode: 7169, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000469, mae: 0.006330, mean_q: 0.005380
 69079/100000: episode: 7170, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000053, mae: 0.005731, mean_q: 0.008023
 69089/100000: episode: 7171, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000231, mae: 0.004069, mean_q: 0.004719
 69099/100000: episode: 7172, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000046, mae: 0.003614, mean_q: 0.004946
 69109/100000: episode: 7173, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000025, mae: 0.003731, mean_q: 0.005811
 69119/100000: episode: 7174, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000069, mae: 0.003755, mean_q: 0.005256
 69129/100000: episode: 7175, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001596, mae: 0.007471, mean_q: 0.006149
 69139/100000: episode: 7176, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000255, mae: 0.007196, mean_q: 0.008373
 69149/100000: episode: 7177, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000077, mae: 0.004582, mean_q: 0.006079
 69159/100000: episode: 7178, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000047, mae: 0.003445, mean_q: 0.004786
 69169/100000: episode: 7179, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000049, mae: 0.003577, mean_q: 0.005131
 69179/100000: episode: 7180, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000052, mae: 0.004348, mean_q: 0.005712
 69189/100000: episode: 7181, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000110, mae: 0.005133, mean_q: 0.005635
[Info] 1-TH LEVEL FOUND: 0.007308095693588257, Considering 100/100 traces
 69199/100000: episode: 7182, duration: 0.731s, episode steps: 10, steps per second: 14, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000464, mae: 0.006735, mean_q: 0.006329
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007308095693588257
 69209/100000: episode: 7183, duration: 0.655s, episode steps: 10, steps per second: 15, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000048, mae: 0.005097, mean_q: 0.007369
 69219/100000: episode: 7184, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000272, mae: 0.006040, mean_q: 0.006191
 69229/100000: episode: 7185, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.004329, mean_q: 0.006150
 69239/100000: episode: 7186, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000094, mae: 0.004291, mean_q: 0.005353
 69249/100000: episode: 7187, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000051, mae: 0.004459, mean_q: 0.006189
 69259/100000: episode: 7188, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000044, mae: 0.003667, mean_q: 0.005535
 69269/100000: episode: 7189, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.003238, mean_q: 0.004730
 69279/100000: episode: 7190, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000042, mae: 0.003416, mean_q: 0.004955
 69289/100000: episode: 7191, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000245, mae: 0.004469, mean_q: 0.005178
 69299/100000: episode: 7192, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000070, mae: 0.004379, mean_q: 0.006135
 69309/100000: episode: 7193, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000124, mae: 0.005041, mean_q: 0.006054
 69319/100000: episode: 7194, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001597, mae: 0.008911, mean_q: 0.008224
 69329/100000: episode: 7195, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000051, mae: 0.005085, mean_q: 0.007139
 69339/100000: episode: 7196, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000255, mae: 0.004505, mean_q: 0.004843
 69349/100000: episode: 7197, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000026, mae: 0.004282, mean_q: 0.006635
 69359/100000: episode: 7198, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000120, mae: 0.005684, mean_q: 0.006255
 69369/100000: episode: 7199, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000025, mae: 0.003674, mean_q: 0.005903
 69379/100000: episode: 7200, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000075, mae: 0.004196, mean_q: 0.005268
 69389/100000: episode: 7201, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000087, mae: 0.005336, mean_q: 0.006188
 69399/100000: episode: 7202, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.004041, mean_q: 0.006233
 69409/100000: episode: 7203, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000071, mae: 0.004151, mean_q: 0.005750
 69419/100000: episode: 7204, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001560, mae: 0.005894, mean_q: 0.004965
 69429/100000: episode: 7205, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000082, mae: 0.005840, mean_q: 0.007535
 69439/100000: episode: 7206, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000041, mae: 0.004449, mean_q: 0.006716
 69449/100000: episode: 7207, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000054, mae: 0.003478, mean_q: 0.004582
 69459/100000: episode: 7208, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000079, mae: 0.004778, mean_q: 0.006002
 69469/100000: episode: 7209, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.001783, mae: 0.009659, mean_q: 0.007629
 69479/100000: episode: 7210, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000082, mae: 0.006897, mean_q: 0.009310
 69489/100000: episode: 7211, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000094, mae: 0.004906, mean_q: 0.005706
 69499/100000: episode: 7212, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000046, mae: 0.003483, mean_q: 0.005501
 69509/100000: episode: 7213, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000264, mae: 0.006001, mean_q: 0.006801
 69519/100000: episode: 7214, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000052, mae: 0.004273, mean_q: 0.006428
 69529/100000: episode: 7215, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.003955, mean_q: 0.005634
 69539/100000: episode: 7216, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000064, mae: 0.004511, mean_q: 0.005827
 69549/100000: episode: 7217, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001566, mae: 0.007133, mean_q: 0.006537
 69559/100000: episode: 7218, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000237, mae: 0.006822, mean_q: 0.008497
 69569/100000: episode: 7219, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000053, mae: 0.005095, mean_q: 0.007355
 69579/100000: episode: 7220, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002491, mean_q: 0.004652
 69589/100000: episode: 7221, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002533, mean_q: 0.004559
 69599/100000: episode: 7222, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000025, mae: 0.003609, mean_q: 0.005371
 69609/100000: episode: 7223, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000042, mae: 0.003361, mean_q: 0.005471
 69619/100000: episode: 7224, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000264, mae: 0.005315, mean_q: 0.005337
 69629/100000: episode: 7225, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000017, mae: 0.003999, mean_q: 0.006630
 69639/100000: episode: 7226, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000035, mae: 0.004081, mean_q: 0.005527
 69649/100000: episode: 7227, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000036, mae: 0.003782, mean_q: 0.005127
 69659/100000: episode: 7228, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003343, mean_q: 0.005283
 69669/100000: episode: 7229, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000011, mae: 0.002754, mean_q: 0.005106
 69679/100000: episode: 7230, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000025, mae: 0.003025, mean_q: 0.004403
 69689/100000: episode: 7231, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000047, mae: 0.003845, mean_q: 0.005324
 69699/100000: episode: 7232, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003772, mean_q: 0.005447
 69709/100000: episode: 7233, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000036, mae: 0.003951, mean_q: 0.005075
 69719/100000: episode: 7234, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000027, mae: 0.003639, mean_q: 0.005464
 69729/100000: episode: 7235, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000044, mae: 0.003659, mean_q: 0.004776
 69739/100000: episode: 7236, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000039, mae: 0.003199, mean_q: 0.005036
 69749/100000: episode: 7237, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000049, mae: 0.003667, mean_q: 0.004973
 69759/100000: episode: 7238, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000310, mae: 0.007330, mean_q: 0.006356
 69769/100000: episode: 7239, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000031, mae: 0.005215, mean_q: 0.007488
 69779/100000: episode: 7240, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001600, mae: 0.006712, mean_q: 0.004568
 69789/100000: episode: 7241, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000024, mae: 0.005034, mean_q: 0.007414
 69799/100000: episode: 7242, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000052, mae: 0.004598, mean_q: 0.006114
 69809/100000: episode: 7243, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000041, mae: 0.004338, mean_q: 0.005270
 69819/100000: episode: 7244, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.003853, mean_q: 0.005744
 69829/100000: episode: 7245, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000035, mae: 0.002931, mean_q: 0.004874
 69839/100000: episode: 7246, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000051, mae: 0.003496, mean_q: 0.004396
 69849/100000: episode: 7247, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000024, mae: 0.003625, mean_q: 0.005281
 69859/100000: episode: 7248, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.003455, mean_q: 0.005068
 69869/100000: episode: 7249, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000052, mae: 0.003848, mean_q: 0.005229
 69879/100000: episode: 7250, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000059, mae: 0.004227, mean_q: 0.005347
 69889/100000: episode: 7251, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000462, mae: 0.006793, mean_q: 0.006581
 69899/100000: episode: 7252, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000089, mae: 0.006143, mean_q: 0.007333
 69909/100000: episode: 7253, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000264, mae: 0.005749, mean_q: 0.006331
 69919/100000: episode: 7254, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000305, mae: 0.005934, mean_q: 0.006186
 69929/100000: episode: 7255, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000049, mae: 0.004503, mean_q: 0.006451
 69939/100000: episode: 7256, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000042, mae: 0.004232, mean_q: 0.005225
 69949/100000: episode: 7257, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000031, mae: 0.004087, mean_q: 0.005654
 69959/100000: episode: 7258, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.003923, mean_q: 0.005479
 69969/100000: episode: 7259, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000085, mae: 0.004711, mean_q: 0.005587
 69979/100000: episode: 7260, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000269, mae: 0.006621, mean_q: 0.007008
 69989/100000: episode: 7261, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000083, mae: 0.005729, mean_q: 0.007376
 69999/100000: episode: 7262, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003295, mean_q: 0.005191
 70009/100000: episode: 7263, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000320, mae: 0.006039, mean_q: 0.005387
 70019/100000: episode: 7264, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000233, mae: 0.006634, mean_q: 0.008000
 70029/100000: episode: 7265, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000230, mae: 0.005555, mean_q: 0.006542
 70039/100000: episode: 7266, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000225, mae: 0.004253, mean_q: 0.005184
 70049/100000: episode: 7267, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000087, mae: 0.005718, mean_q: 0.006901
 70059/100000: episode: 7268, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000020, mae: 0.003588, mean_q: 0.005785
 70069/100000: episode: 7269, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000231, mae: 0.003985, mean_q: 0.004556
 70079/100000: episode: 7270, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000230, mae: 0.006064, mean_q: 0.007402
 70089/100000: episode: 7271, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000265, mae: 0.006266, mean_q: 0.006923
 70099/100000: episode: 7272, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000056, mae: 0.004322, mean_q: 0.005577
 70109/100000: episode: 7273, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001984, mae: 0.010484, mean_q: 0.007176
 70119/100000: episode: 7274, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000058, mae: 0.007003, mean_q: 0.010421
 70129/100000: episode: 7275, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001563, mae: 0.007711, mean_q: 0.007410
 70139/100000: episode: 7276, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000108, mae: 0.004901, mean_q: 0.005792
 70149/100000: episode: 7277, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000077, mae: 0.004872, mean_q: 0.006494
 70159/100000: episode: 7278, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000030, mae: 0.004673, mean_q: 0.007108
 70169/100000: episode: 7279, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000048, mae: 0.003744, mean_q: 0.005506
 70179/100000: episode: 7280, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.002864, mean_q: 0.004936
 70189/100000: episode: 7281, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000106, mae: 0.004738, mean_q: 0.005534
 70199/100000: episode: 7282, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000022, mae: 0.004205, mean_q: 0.006608
[Info] 1-TH LEVEL FOUND: 0.007677845656871796, Considering 100/100 traces
 70209/100000: episode: 7283, duration: 0.712s, episode steps: 10, steps per second: 14, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000296, mae: 0.006347, mean_q: 0.006486
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007677845656871796
 70219/100000: episode: 7284, duration: 0.485s, episode steps: 10, steps per second: 21, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000027, mae: 0.004509, mean_q: 0.006988
 70229/100000: episode: 7285, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000009, mae: 0.002436, mean_q: 0.004733
 70239/100000: episode: 7286, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000232, mae: 0.004067, mean_q: 0.004562
 70249/100000: episode: 7287, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000036, mae: 0.003874, mean_q: 0.006447
 70259/100000: episode: 7288, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000049, mae: 0.003761, mean_q: 0.005416
 70269/100000: episode: 7289, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000063, mae: 0.003198, mean_q: 0.004612
 70279/100000: episode: 7290, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000058, mae: 0.004294, mean_q: 0.005591
 70289/100000: episode: 7291, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000051, mae: 0.004294, mean_q: 0.006026
 70299/100000: episode: 7292, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000079, mae: 0.004345, mean_q: 0.005259
 70309/100000: episode: 7293, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000050, mae: 0.004202, mean_q: 0.006072
 70319/100000: episode: 7294, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000115, mae: 0.005353, mean_q: 0.005936
 70329/100000: episode: 7295, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000030, mae: 0.006086, mean_q: 0.008982
 70339/100000: episode: 7296, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000080, mae: 0.005011, mean_q: 0.006265
 70349/100000: episode: 7297, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000027, mae: 0.002952, mean_q: 0.004703
 70359/100000: episode: 7298, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000025, mae: 0.003157, mean_q: 0.004946
 70369/100000: episode: 7299, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000051, mae: 0.003788, mean_q: 0.005239
 70379/100000: episode: 7300, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000039, mae: 0.003384, mean_q: 0.005478
 70389/100000: episode: 7301, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003260, mean_q: 0.004903
 70399/100000: episode: 7302, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000059, mae: 0.004007, mean_q: 0.005161
 70409/100000: episode: 7303, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000061, mae: 0.005034, mean_q: 0.006312
 70419/100000: episode: 7304, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000033, mae: 0.004306, mean_q: 0.005788
 70429/100000: episode: 7305, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000029, mae: 0.003314, mean_q: 0.004752
 70439/100000: episode: 7306, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000030, mae: 0.003802, mean_q: 0.005248
 70449/100000: episode: 7307, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002991, mean_q: 0.005055
 70459/100000: episode: 7308, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000028, mae: 0.002896, mean_q: 0.004138
 70469/100000: episode: 7309, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000263, mae: 0.005894, mean_q: 0.006112
 70479/100000: episode: 7310, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000256, mae: 0.005645, mean_q: 0.006607
 70489/100000: episode: 7311, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000020, mae: 0.003595, mean_q: 0.005536
 70499/100000: episode: 7312, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000264, mae: 0.005212, mean_q: 0.005478
 70509/100000: episode: 7313, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000044, mae: 0.004145, mean_q: 0.005980
 70519/100000: episode: 7314, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000024, mae: 0.003266, mean_q: 0.004530
 70529/100000: episode: 7315, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000020, mae: 0.002685, mean_q: 0.004319
 70539/100000: episode: 7316, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000041, mae: 0.003102, mean_q: 0.004743
 70549/100000: episode: 7317, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003192, mean_q: 0.004990
 70559/100000: episode: 7318, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002774, mean_q: 0.004816
 70569/100000: episode: 7319, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000026, mae: 0.003400, mean_q: 0.004729
 70579/100000: episode: 7320, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000063, mae: 0.004526, mean_q: 0.005267
 70589/100000: episode: 7321, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000231, mae: 0.005045, mean_q: 0.005705
 70599/100000: episode: 7322, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.003934, mean_q: 0.005648
 70609/100000: episode: 7323, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003217, mean_q: 0.005056
 70619/100000: episode: 7324, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000049, mae: 0.003496, mean_q: 0.004462
 70629/100000: episode: 7325, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001622, mae: 0.007687, mean_q: 0.005660
 70639/100000: episode: 7326, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000043, mae: 0.006810, mean_q: 0.009307
 70649/100000: episode: 7327, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000068, mae: 0.004709, mean_q: 0.005418
 70659/100000: episode: 7328, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000024, mae: 0.002847, mean_q: 0.004317
 70669/100000: episode: 7329, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003163, mean_q: 0.004873
 70679/100000: episode: 7330, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003648, mean_q: 0.005368
 70689/100000: episode: 7331, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000008, mae: 0.002438, mean_q: 0.004495
 70699/100000: episode: 7332, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000057, mae: 0.003597, mean_q: 0.004014
 70709/100000: episode: 7333, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000219, mae: 0.004685, mean_q: 0.005859
 70719/100000: episode: 7334, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000104, mae: 0.004737, mean_q: 0.005506
 70729/100000: episode: 7335, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000013, mae: 0.003224, mean_q: 0.005319
 70739/100000: episode: 7336, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000358, mae: 0.006800, mean_q: 0.005132
 70749/100000: episode: 7337, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000052, mae: 0.005663, mean_q: 0.007897
 70759/100000: episode: 7338, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000048, mae: 0.003676, mean_q: 0.004787
 70769/100000: episode: 7339, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000244, mae: 0.003856, mean_q: 0.004580
 70779/100000: episode: 7340, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000223, mae: 0.005787, mean_q: 0.007351
 70789/100000: episode: 7341, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000021, mae: 0.003122, mean_q: 0.005057
 70799/100000: episode: 7342, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002382, mean_q: 0.003536
 70809/100000: episode: 7343, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000024, mae: 0.003332, mean_q: 0.005060
 70819/100000: episode: 7344, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000083, mae: 0.004822, mean_q: 0.005374
 70829/100000: episode: 7345, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000026, mae: 0.003956, mean_q: 0.005781
 70839/100000: episode: 7346, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000054, mae: 0.004056, mean_q: 0.005145
 70849/100000: episode: 7347, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000252, mae: 0.005372, mean_q: 0.006214
 70859/100000: episode: 7348, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000041, mae: 0.003000, mean_q: 0.004575
 70869/100000: episode: 7349, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003379, mean_q: 0.004562
 70879/100000: episode: 7350, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000012, mae: 0.003210, mean_q: 0.005210
 70889/100000: episode: 7351, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.002441, mean_q: 0.003636
 70899/100000: episode: 7352, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000074, mae: 0.003766, mean_q: 0.004529
 70909/100000: episode: 7353, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000052, mae: 0.004263, mean_q: 0.005656
 70919/100000: episode: 7354, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000160, mae: 0.005332, mean_q: 0.004938
 70929/100000: episode: 7355, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000096, mae: 0.005508, mean_q: 0.006764
 70939/100000: episode: 7356, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000059, mae: 0.004752, mean_q: 0.005619
 70949/100000: episode: 7357, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003353, mean_q: 0.004737
 70959/100000: episode: 7358, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.002671, mean_q: 0.004599
 70969/100000: episode: 7359, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000049, mae: 0.002905, mean_q: 0.003811
 70979/100000: episode: 7360, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000048, mae: 0.003675, mean_q: 0.005037
 70989/100000: episode: 7361, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000008, mae: 0.002774, mean_q: 0.004878
 70999/100000: episode: 7362, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000042, mae: 0.003077, mean_q: 0.004409
 71009/100000: episode: 7363, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000229, mae: 0.004340, mean_q: 0.004916
 71019/100000: episode: 7364, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000019, mae: 0.003691, mean_q: 0.005741
 71029/100000: episode: 7365, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000057, mae: 0.003992, mean_q: 0.004727
 71039/100000: episode: 7366, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000019, mae: 0.003096, mean_q: 0.004576
 71049/100000: episode: 7367, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002410, mean_q: 0.004019
 71059/100000: episode: 7368, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.003059, mean_q: 0.004257
 71069/100000: episode: 7369, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000028, mae: 0.003376, mean_q: 0.004495
 71079/100000: episode: 7370, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000022, mae: 0.003297, mean_q: 0.004857
 71089/100000: episode: 7371, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000094, mae: 0.004259, mean_q: 0.005134
 71099/100000: episode: 7372, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000055, mae: 0.003720, mean_q: 0.004685
 71109/100000: episode: 7373, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000057, mae: 0.004275, mean_q: 0.005165
 71119/100000: episode: 7374, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000015, mae: 0.003032, mean_q: 0.004645
 71129/100000: episode: 7375, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000070, mae: 0.003230, mean_q: 0.003717
 71139/100000: episode: 7376, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000075, mae: 0.004441, mean_q: 0.005337
 71149/100000: episode: 7377, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000031, mae: 0.004492, mean_q: 0.005798
 71159/100000: episode: 7378, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000062, mae: 0.004350, mean_q: 0.004880
 71169/100000: episode: 7379, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000033, mae: 0.003999, mean_q: 0.005072
 71179/100000: episode: 7380, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000022, mae: 0.003250, mean_q: 0.004711
 71189/100000: episode: 7381, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000034, mae: 0.003920, mean_q: 0.004817
 71199/100000: episode: 7382, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000017, mae: 0.003283, mean_q: 0.005172
 71209/100000: episode: 7383, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.002995, mean_q: 0.003864
[Info] 1-TH LEVEL FOUND: 0.004933963995426893, Considering 100/100 traces
 71219/100000: episode: 7384, duration: 0.704s, episode steps: 10, steps per second: 14, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000071, mae: 0.003666, mean_q: 0.004707
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004933963995426893
 71229/100000: episode: 7385, duration: 0.712s, episode steps: 10, steps per second: 14, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000025, mae: 0.003467, mean_q: 0.004963
 71239/100000: episode: 7386, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000029, mae: 0.003492, mean_q: 0.004620
 71249/100000: episode: 7387, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000022, mae: 0.003322, mean_q: 0.004647
 71259/100000: episode: 7388, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000011, mae: 0.002461, mean_q: 0.004083
 71269/100000: episode: 7389, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000046, mae: 0.003673, mean_q: 0.004530
 71279/100000: episode: 7390, duration: 0.066s, episode steps: 10, steps per second: 153, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000057, mae: 0.004592, mean_q: 0.005468
 71289/100000: episode: 7391, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000010, mae: 0.002347, mean_q: 0.004093
 71299/100000: episode: 7392, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000052, mae: 0.003157, mean_q: 0.003759
 71309/100000: episode: 7393, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003394, mean_q: 0.005003
 71319/100000: episode: 7394, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000109, mae: 0.004801, mean_q: 0.004852
 71329/100000: episode: 7395, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000042, mae: 0.003733, mean_q: 0.005238
 71339/100000: episode: 7396, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000023, mae: 0.003277, mean_q: 0.004399
 71349/100000: episode: 7397, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000026, mae: 0.002859, mean_q: 0.004082
 71359/100000: episode: 7398, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003120, mean_q: 0.004060
 71369/100000: episode: 7399, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000044, mae: 0.003501, mean_q: 0.004996
 71379/100000: episode: 7400, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000025, mae: 0.003176, mean_q: 0.004199
 71389/100000: episode: 7401, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003581, mean_q: 0.004804
 71399/100000: episode: 7402, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000036, mae: 0.004243, mean_q: 0.005201
 71409/100000: episode: 7403, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000027, mae: 0.003565, mean_q: 0.004697
 71419/100000: episode: 7404, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000013, mae: 0.002695, mean_q: 0.004282
 71429/100000: episode: 7405, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000064, mae: 0.004509, mean_q: 0.004893
 71439/100000: episode: 7406, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003776, mean_q: 0.005590
 71449/100000: episode: 7407, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000009, mae: 0.001915, mean_q: 0.003445
 71459/100000: episode: 7408, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.002949, mean_q: 0.003963
 71469/100000: episode: 7409, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000070, mae: 0.003962, mean_q: 0.004883
 71479/100000: episode: 7410, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000027, mae: 0.003500, mean_q: 0.004772
 71489/100000: episode: 7411, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000028, mae: 0.003354, mean_q: 0.004376
 71499/100000: episode: 7412, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002474, mean_q: 0.003735
 71509/100000: episode: 7413, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000071, mae: 0.003628, mean_q: 0.004492
 71519/100000: episode: 7414, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000043, mae: 0.003354, mean_q: 0.004606
 71529/100000: episode: 7415, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000031, mae: 0.003443, mean_q: 0.004394
 71539/100000: episode: 7416, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003003, mean_q: 0.004448
 71549/100000: episode: 7417, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000045, mae: 0.003089, mean_q: 0.003853
 71559/100000: episode: 7418, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000021, mae: 0.003213, mean_q: 0.004434
 71569/100000: episode: 7419, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000006, mae: 0.002420, mean_q: 0.004461
 71579/100000: episode: 7420, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000045, mae: 0.002817, mean_q: 0.003380
 71589/100000: episode: 7421, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000026, mae: 0.003273, mean_q: 0.004455
 71599/100000: episode: 7422, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000029, mae: 0.003165, mean_q: 0.004045
 71609/100000: episode: 7423, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002900, mean_q: 0.004444
 71619/100000: episode: 7424, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000052, mae: 0.003564, mean_q: 0.004333
 71629/100000: episode: 7425, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000069, mae: 0.003792, mean_q: 0.004319
 71639/100000: episode: 7426, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000054, mae: 0.004213, mean_q: 0.004915
 71649/100000: episode: 7427, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000015, mae: 0.003063, mean_q: 0.004736
 71659/100000: episode: 7428, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002461, mean_q: 0.003848
 71669/100000: episode: 7429, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002769, mean_q: 0.004059
 71679/100000: episode: 7430, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000072, mae: 0.003992, mean_q: 0.004143
 71689/100000: episode: 7431, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000017, mae: 0.003383, mean_q: 0.005348
 71699/100000: episode: 7432, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000041, mae: 0.002436, mean_q: 0.003069
 71709/100000: episode: 7433, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000020, mae: 0.003079, mean_q: 0.004466
 71719/100000: episode: 7434, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.002968, mean_q: 0.004231
 71729/100000: episode: 7435, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000006, mae: 0.002173, mean_q: 0.003829
 71739/100000: episode: 7436, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000030, mae: 0.002847, mean_q: 0.003627
 71749/100000: episode: 7437, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003130, mean_q: 0.004589
 71759/100000: episode: 7438, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000081, mae: 0.004204, mean_q: 0.004379
 71769/100000: episode: 7439, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000060, mae: 0.005062, mean_q: 0.006002
 71779/100000: episode: 7440, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.003768, mean_q: 0.005278
 71789/100000: episode: 7441, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000043, mae: 0.003021, mean_q: 0.003843
 71799/100000: episode: 7442, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003727, mean_q: 0.005054
 71809/100000: episode: 7443, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000012, mae: 0.002736, mean_q: 0.004326
 71819/100000: episode: 7444, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000076, mae: 0.003732, mean_q: 0.003846
 71829/100000: episode: 7445, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000009, mae: 0.002895, mean_q: 0.005116
 71839/100000: episode: 7446, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000011, mae: 0.002275, mean_q: 0.003510
 71849/100000: episode: 7447, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003072, mean_q: 0.003814
 71859/100000: episode: 7448, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000029, mae: 0.003667, mean_q: 0.004832
 71869/100000: episode: 7449, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000010, mae: 0.002440, mean_q: 0.003975
 71879/100000: episode: 7450, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000075, mae: 0.003419, mean_q: 0.003804
 71889/100000: episode: 7451, duration: 0.045s, episode steps: 10, steps per second: 224, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000068, mae: 0.003969, mean_q: 0.005090
 71899/100000: episode: 7452, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003660, mean_q: 0.004854
 71909/100000: episode: 7453, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000066, mae: 0.003073, mean_q: 0.003902
 71919/100000: episode: 7454, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000079, mae: 0.005456, mean_q: 0.006429
 71929/100000: episode: 7455, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000102, mae: 0.004444, mean_q: 0.004637
 71939/100000: episode: 7456, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000075, mae: 0.004189, mean_q: 0.004999
 71949/100000: episode: 7457, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000047, mae: 0.004163, mean_q: 0.005519
 71959/100000: episode: 7458, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000019, mae: 0.003374, mean_q: 0.004903
 71969/100000: episode: 7459, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000049, mae: 0.003274, mean_q: 0.003963
 71979/100000: episode: 7460, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000014, mae: 0.002725, mean_q: 0.004189
 71989/100000: episode: 7461, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000017, mae: 0.002821, mean_q: 0.004529
 71999/100000: episode: 7462, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000021, mae: 0.003157, mean_q: 0.004560
 72009/100000: episode: 7463, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000052, mae: 0.003430, mean_q: 0.004044
 72019/100000: episode: 7464, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000045, mae: 0.003562, mean_q: 0.004852
 72029/100000: episode: 7465, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000077, mae: 0.004105, mean_q: 0.004716
 72039/100000: episode: 7466, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000121, mae: 0.005154, mean_q: 0.005723
 72049/100000: episode: 7467, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000075, mae: 0.005560, mean_q: 0.005889
 72059/100000: episode: 7468, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000034, mae: 0.004404, mean_q: 0.005510
 72069/100000: episode: 7469, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000051, mae: 0.003589, mean_q: 0.004852
 72079/100000: episode: 7470, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000051, mae: 0.003855, mean_q: 0.004826
 72089/100000: episode: 7471, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000019, mae: 0.002909, mean_q: 0.004314
 72099/100000: episode: 7472, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003730, mean_q: 0.004901
 72109/100000: episode: 7473, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000059, mae: 0.004574, mean_q: 0.005257
 72119/100000: episode: 7474, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000017, mae: 0.003052, mean_q: 0.004988
 72129/100000: episode: 7475, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000058, mae: 0.003435, mean_q: 0.003695
 72139/100000: episode: 7476, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000058, mae: 0.004886, mean_q: 0.005916
 72149/100000: episode: 7477, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000021, mae: 0.003494, mean_q: 0.005366
 72159/100000: episode: 7478, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000103, mae: 0.004097, mean_q: 0.004232
 72169/100000: episode: 7479, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000050, mae: 0.004314, mean_q: 0.005545
 72179/100000: episode: 7480, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000009, mae: 0.002337, mean_q: 0.004233
 72189/100000: episode: 7481, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000023, mae: 0.002846, mean_q: 0.003637
 72199/100000: episode: 7482, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000050, mae: 0.005052, mean_q: 0.006314
 72209/100000: episode: 7483, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.002803, mean_q: 0.004341
 72219/100000: episode: 7484, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000074, mae: 0.003689, mean_q: 0.004182
[Info] 1-TH LEVEL FOUND: 0.005634216126054525, Considering 100/100 traces
 72229/100000: episode: 7485, duration: 0.709s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000099, mae: 0.004755, mean_q: 0.005251
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005634216126054525
 72239/100000: episode: 7486, duration: 0.486s, episode steps: 10, steps per second: 21, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000015, mae: 0.003068, mean_q: 0.004830
 72249/100000: episode: 7487, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000049, mae: 0.003746, mean_q: 0.004955
 72259/100000: episode: 7488, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000046, mae: 0.003693, mean_q: 0.004493
 72269/100000: episode: 7489, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000159, mae: 0.006439, mean_q: 0.006366
 72279/100000: episode: 7490, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000054, mae: 0.004677, mean_q: 0.006256
 72289/100000: episode: 7491, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000082, mae: 0.003892, mean_q: 0.004056
 72299/100000: episode: 7492, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000042, mae: 0.003982, mean_q: 0.005632
 72309/100000: episode: 7493, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000048, mae: 0.003272, mean_q: 0.004222
 72319/100000: episode: 7494, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000073, mae: 0.003877, mean_q: 0.004769
 72329/100000: episode: 7495, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000054, mae: 0.005081, mean_q: 0.006594
 72339/100000: episode: 7496, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000026, mae: 0.002778, mean_q: 0.003571
 72349/100000: episode: 7497, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003527, mean_q: 0.004464
 72359/100000: episode: 7498, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000043, mae: 0.003710, mean_q: 0.005055
 72369/100000: episode: 7499, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.002646, mean_q: 0.004080
 72379/100000: episode: 7500, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003466, mean_q: 0.004565
 72389/100000: episode: 7501, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003141, mean_q: 0.004281
 72399/100000: episode: 7502, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000018, mae: 0.003286, mean_q: 0.004515
 72409/100000: episode: 7503, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000098, mae: 0.004303, mean_q: 0.004873
 72419/100000: episode: 7504, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000025, mae: 0.003470, mean_q: 0.004923
 72429/100000: episode: 7505, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003631, mean_q: 0.004324
 72439/100000: episode: 7506, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000076, mae: 0.004011, mean_q: 0.004879
 72449/100000: episode: 7507, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000050, mae: 0.004112, mean_q: 0.005259
 72459/100000: episode: 7508, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003447, mean_q: 0.004676
 72469/100000: episode: 7509, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000052, mae: 0.004005, mean_q: 0.004767
 72479/100000: episode: 7510, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000020, mae: 0.003654, mean_q: 0.005287
 72489/100000: episode: 7511, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000039, mae: 0.002839, mean_q: 0.003972
 72499/100000: episode: 7512, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000044, mae: 0.003617, mean_q: 0.004771
 72509/100000: episode: 7513, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000035, mae: 0.002876, mean_q: 0.004284
 72519/100000: episode: 7514, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000029, mae: 0.003568, mean_q: 0.004574
 72529/100000: episode: 7515, duration: 0.073s, episode steps: 10, steps per second: 138, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000009, mae: 0.002743, mean_q: 0.004806
 72539/100000: episode: 7516, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000043, mae: 0.003912, mean_q: 0.003930
 72549/100000: episode: 7517, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000061, mae: 0.005160, mean_q: 0.005959
 72559/100000: episode: 7518, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000054, mae: 0.004022, mean_q: 0.004880
 72569/100000: episode: 7519, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000087, mae: 0.005361, mean_q: 0.005855
 72579/100000: episode: 7520, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003673, mean_q: 0.005170
 72589/100000: episode: 7521, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000034, mae: 0.003595, mean_q: 0.004161
 72599/100000: episode: 7522, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000046, mae: 0.004077, mean_q: 0.005663
 72609/100000: episode: 7523, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000040, mae: 0.002477, mean_q: 0.003124
 72619/100000: episode: 7524, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000044, mae: 0.003845, mean_q: 0.005063
 72629/100000: episode: 7525, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000071, mae: 0.004183, mean_q: 0.005065
 72639/100000: episode: 7526, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000049, mae: 0.003715, mean_q: 0.004948
 72649/100000: episode: 7527, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000048, mae: 0.003713, mean_q: 0.004513
 72659/100000: episode: 7528, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000054, mae: 0.004523, mean_q: 0.005554
 72669/100000: episode: 7529, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000030, mae: 0.003565, mean_q: 0.004600
 72679/100000: episode: 7530, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000056, mae: 0.004152, mean_q: 0.005243
 72689/100000: episode: 7531, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.003255, mean_q: 0.004584
 72699/100000: episode: 7532, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000026, mae: 0.003585, mean_q: 0.004807
 72709/100000: episode: 7533, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000040, mae: 0.002752, mean_q: 0.004063
 72719/100000: episode: 7534, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000072, mae: 0.004262, mean_q: 0.005023
 72729/100000: episode: 7535, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.003786, mean_q: 0.005320
 72739/100000: episode: 7536, duration: 0.114s, episode steps: 10, steps per second: 88, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.003515, mean_q: 0.004587
 72749/100000: episode: 7537, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000045, mae: 0.003391, mean_q: 0.004787
 72759/100000: episode: 7538, duration: 0.059s, episode steps: 10, steps per second: 171, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000014, mae: 0.002906, mean_q: 0.004758
 72769/100000: episode: 7539, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000057, mae: 0.003902, mean_q: 0.004384
 72779/100000: episode: 7540, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000051, mae: 0.004284, mean_q: 0.005393
 72789/100000: episode: 7541, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000060, mae: 0.004312, mean_q: 0.005164
 72799/100000: episode: 7542, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000105, mae: 0.004639, mean_q: 0.005017
 72809/100000: episode: 7543, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000020, mae: 0.004268, mean_q: 0.006398
 72819/100000: episode: 7544, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000011, mae: 0.002301, mean_q: 0.003723
 72829/100000: episode: 7545, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000079, mae: 0.004375, mean_q: 0.004817
 72839/100000: episode: 7546, duration: 0.130s, episode steps: 10, steps per second: 77, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000095, mae: 0.004529, mean_q: 0.005367
 72849/100000: episode: 7547, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003660, mean_q: 0.005157
 72859/100000: episode: 7548, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000064, mae: 0.004026, mean_q: 0.005417
 72869/100000: episode: 7549, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000036, mae: 0.002575, mean_q: 0.003843
 72879/100000: episode: 7550, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000021, mae: 0.003009, mean_q: 0.004387
 72889/100000: episode: 7551, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002895, mean_q: 0.004428
 72899/100000: episode: 7552, duration: 0.066s, episode steps: 10, steps per second: 150, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000075, mae: 0.004464, mean_q: 0.005328
 72909/100000: episode: 7553, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000014, mae: 0.002622, mean_q: 0.004100
 72919/100000: episode: 7554, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000039, mae: 0.004177, mean_q: 0.004629
 72929/100000: episode: 7555, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000110, mae: 0.006522, mean_q: 0.007168
 72939/100000: episode: 7556, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002515, mean_q: 0.003825
 72949/100000: episode: 7557, duration: 0.074s, episode steps: 10, steps per second: 136, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000110, mae: 0.004554, mean_q: 0.004333
 72959/100000: episode: 7558, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000104, mae: 0.005684, mean_q: 0.006486
 72969/100000: episode: 7559, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000029, mae: 0.003622, mean_q: 0.004988
 72979/100000: episode: 7560, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000083, mae: 0.004808, mean_q: 0.005423
 72989/100000: episode: 7561, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003647, mean_q: 0.005637
 72999/100000: episode: 7562, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.002531, mean_q: 0.003600
 73009/100000: episode: 7563, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000041, mae: 0.003839, mean_q: 0.005132
 73019/100000: episode: 7564, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000027, mae: 0.003440, mean_q: 0.004443
 73029/100000: episode: 7565, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000080, mae: 0.004525, mean_q: 0.005196
 73039/100000: episode: 7566, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000103, mae: 0.004944, mean_q: 0.005558
 73049/100000: episode: 7567, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003956, mean_q: 0.005921
 73059/100000: episode: 7568, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000070, mae: 0.005195, mean_q: 0.005542
 73069/100000: episode: 7569, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.003777, mean_q: 0.005590
 73079/100000: episode: 7570, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000084, mae: 0.004330, mean_q: 0.004451
 73089/100000: episode: 7571, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000021, mae: 0.004382, mean_q: 0.006470
 73099/100000: episode: 7572, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000050, mae: 0.003510, mean_q: 0.004196
 73109/100000: episode: 7573, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000028, mae: 0.004007, mean_q: 0.005752
 73119/100000: episode: 7574, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000041, mae: 0.003019, mean_q: 0.004483
 73129/100000: episode: 7575, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000074, mae: 0.004185, mean_q: 0.004981
 73139/100000: episode: 7576, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000013, mae: 0.003391, mean_q: 0.005611
 73149/100000: episode: 7577, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000050, mae: 0.003104, mean_q: 0.003763
 73159/100000: episode: 7578, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000045, mae: 0.004370, mean_q: 0.005944
 73169/100000: episode: 7579, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000049, mae: 0.003993, mean_q: 0.004983
 73179/100000: episode: 7580, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003407, mean_q: 0.004816
 73189/100000: episode: 7581, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000041, mae: 0.004582, mean_q: 0.005346
 73199/100000: episode: 7582, duration: 0.045s, episode steps: 10, steps per second: 223, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000071, mae: 0.004647, mean_q: 0.005961
 73209/100000: episode: 7583, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000024, mae: 0.003277, mean_q: 0.004686
 73219/100000: episode: 7584, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000099, mae: 0.004357, mean_q: 0.005028
 73229/100000: episode: 7585, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000050, mae: 0.004275, mean_q: 0.005650
[Info] 1-TH LEVEL FOUND: 0.005339601542800665, Considering 100/100 traces
 73239/100000: episode: 7586, duration: 0.706s, episode steps: 10, steps per second: 14, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000055, mae: 0.004413, mean_q: 0.005456
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005339601542800665
 73249/100000: episode: 7587, duration: 0.478s, episode steps: 10, steps per second: 21, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000052, mae: 0.004336, mean_q: 0.005465
 73259/100000: episode: 7588, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000069, mae: 0.003850, mean_q: 0.005253
 73269/100000: episode: 7589, duration: 0.045s, episode steps: 10, steps per second: 222, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000056, mae: 0.003987, mean_q: 0.005123
 73279/100000: episode: 7590, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000077, mae: 0.004690, mean_q: 0.005739
 73289/100000: episode: 7591, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000019, mae: 0.003358, mean_q: 0.005026
 73299/100000: episode: 7592, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000024, mae: 0.003102, mean_q: 0.004245
 73309/100000: episode: 7593, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000037, mae: 0.003353, mean_q: 0.005104
 73319/100000: episode: 7594, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000059, mae: 0.004518, mean_q: 0.005388
 73329/100000: episode: 7595, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000049, mae: 0.003872, mean_q: 0.004959
 73339/100000: episode: 7596, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000025, mae: 0.003809, mean_q: 0.005297
 73349/100000: episode: 7597, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000068, mae: 0.004391, mean_q: 0.005770
 73359/100000: episode: 7598, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000054, mae: 0.003913, mean_q: 0.005041
 73369/100000: episode: 7599, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000014, mae: 0.002606, mean_q: 0.004393
 73379/100000: episode: 7600, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000099, mae: 0.004773, mean_q: 0.005427
 73389/100000: episode: 7601, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000075, mae: 0.004393, mean_q: 0.005498
 73399/100000: episode: 7602, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003843, mean_q: 0.005149
 73409/100000: episode: 7603, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000025, mae: 0.003896, mean_q: 0.005381
 73419/100000: episode: 7604, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000087, mae: 0.004770, mean_q: 0.005459
 73429/100000: episode: 7605, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000134, mae: 0.005635, mean_q: 0.005729
 73439/100000: episode: 7606, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000054, mae: 0.005154, mean_q: 0.007057
 73449/100000: episode: 7607, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000049, mae: 0.003499, mean_q: 0.004223
 73459/100000: episode: 7608, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000047, mae: 0.003908, mean_q: 0.005273
 73469/100000: episode: 7609, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.003035, mean_q: 0.005219
 73479/100000: episode: 7610, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.002675, mean_q: 0.003627
[Info] FALSIFICATION!
 73489/100000: episode: 7611, duration: 0.282s, episode steps: 10, steps per second: 35, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000023, mae: 0.003876, mean_q: 0.005619
 73499/100000: episode: 7612, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000013, mae: 0.002500, mean_q: 0.004215
 73509/100000: episode: 7613, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000024, mae: 0.003462, mean_q: 0.004612
 73519/100000: episode: 7614, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000099, mae: 0.004697, mean_q: 0.005360
 73529/100000: episode: 7615, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000048, mae: 0.004245, mean_q: 0.005894
 73539/100000: episode: 7616, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000028, mae: 0.002987, mean_q: 0.004098
 73549/100000: episode: 7617, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000044, mae: 0.003879, mean_q: 0.005319
 73559/100000: episode: 7618, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000024, mae: 0.003250, mean_q: 0.004232
 73569/100000: episode: 7619, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003277, mean_q: 0.004765
 73579/100000: episode: 7620, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000051, mae: 0.004119, mean_q: 0.005329
 73589/100000: episode: 7621, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003728, mean_q: 0.005112
 73599/100000: episode: 7622, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000030, mae: 0.003731, mean_q: 0.004964
 73609/100000: episode: 7623, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001598, mae: 0.009590, mean_q: 0.009177
 73619/100000: episode: 7624, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000015, mae: 0.003353, mean_q: 0.004867
 73629/100000: episode: 7625, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000115, mae: 0.005064, mean_q: 0.004264
 73639/100000: episode: 7626, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000104, mae: 0.007350, mean_q: 0.007798
 73649/100000: episode: 7627, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000230, mae: 0.005942, mean_q: 0.007235
 73659/100000: episode: 7628, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000056, mae: 0.004586, mean_q: 0.005934
 73669/100000: episode: 7629, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000085, mae: 0.003926, mean_q: 0.004393
 73679/100000: episode: 7630, duration: 0.124s, episode steps: 10, steps per second: 81, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000070, mae: 0.004933, mean_q: 0.006513
 73689/100000: episode: 7631, duration: 0.131s, episode steps: 10, steps per second: 76, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001795, mae: 0.008148, mean_q: 0.005862
 73699/100000: episode: 7632, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000039, mae: 0.006888, mean_q: 0.009670
 73709/100000: episode: 7633, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000017, mae: 0.002702, mean_q: 0.004321
 73719/100000: episode: 7634, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.002624, mean_q: 0.003162
 73729/100000: episode: 7635, duration: 0.075s, episode steps: 10, steps per second: 132, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000053, mae: 0.004407, mean_q: 0.006124
 73739/100000: episode: 7636, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000048, mae: 0.004322, mean_q: 0.005870
 73749/100000: episode: 7637, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000043, mae: 0.003296, mean_q: 0.004824
 73759/100000: episode: 7638, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003250, mean_q: 0.005292
 73769/100000: episode: 7639, duration: 0.116s, episode steps: 10, steps per second: 86, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000013, mae: 0.002748, mean_q: 0.004526
 73779/100000: episode: 7640, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000030, mae: 0.003951, mean_q: 0.005454
 73789/100000: episode: 7641, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000030, mae: 0.004022, mean_q: 0.005490
 73799/100000: episode: 7642, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003779, mean_q: 0.005224
 73809/100000: episode: 7643, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000039, mae: 0.003185, mean_q: 0.004890
 73819/100000: episode: 7644, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001629, mae: 0.007779, mean_q: 0.004869
 73829/100000: episode: 7645, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000082, mae: 0.007618, mean_q: 0.010005
 73839/100000: episode: 7646, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000049, mae: 0.003598, mean_q: 0.004788
 73849/100000: episode: 7647, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000082, mae: 0.004116, mean_q: 0.004620
 73859/100000: episode: 7648, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000057, mae: 0.004978, mean_q: 0.006476
 73869/100000: episode: 7649, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.003300, mean_q: 0.004904
 73879/100000: episode: 7650, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002581, mean_q: 0.004388
 73889/100000: episode: 7651, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000261, mae: 0.004801, mean_q: 0.004973
 73899/100000: episode: 7652, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000070, mae: 0.005483, mean_q: 0.007266
 73909/100000: episode: 7653, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000028, mae: 0.003863, mean_q: 0.005358
 73919/100000: episode: 7654, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000058, mae: 0.004724, mean_q: 0.005645
 73929/100000: episode: 7655, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000038, mae: 0.003253, mean_q: 0.005298
 73939/100000: episode: 7656, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000014, mae: 0.002155, mean_q: 0.003784
 73949/100000: episode: 7657, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001789, mae: 0.009996, mean_q: 0.007442
 73959/100000: episode: 7658, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000235, mae: 0.007750, mean_q: 0.009665
 73969/100000: episode: 7659, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000086, mae: 0.003939, mean_q: 0.004246
 73979/100000: episode: 7660, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.003388, mean_q: 0.005077
 73989/100000: episode: 7661, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000017, mae: 0.003454, mean_q: 0.005464
 73999/100000: episode: 7662, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000022, mae: 0.003155, mean_q: 0.004822
 74009/100000: episode: 7663, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000054, mae: 0.003957, mean_q: 0.005034
 74019/100000: episode: 7664, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.003035, mean_q: 0.005100
 74029/100000: episode: 7665, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000021, mae: 0.003053, mean_q: 0.004227
 74039/100000: episode: 7666, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001589, mae: 0.007066, mean_q: 0.005870
 74049/100000: episode: 7667, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000027, mae: 0.005285, mean_q: 0.007892
 74059/100000: episode: 7668, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000078, mae: 0.003942, mean_q: 0.004654
 74069/100000: episode: 7669, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000043, mae: 0.003408, mean_q: 0.005212
 74079/100000: episode: 7670, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000252, mae: 0.004571, mean_q: 0.005198
 74089/100000: episode: 7671, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000047, mae: 0.004219, mean_q: 0.005925
 74099/100000: episode: 7672, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000022, mae: 0.002941, mean_q: 0.004375
 74109/100000: episode: 7673, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000020, mae: 0.002826, mean_q: 0.004441
 74119/100000: episode: 7674, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003841, mean_q: 0.004860
 74129/100000: episode: 7675, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000044, mae: 0.003909, mean_q: 0.005606
 74139/100000: episode: 7676, duration: 0.070s, episode steps: 10, steps per second: 144, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000041, mae: 0.003529, mean_q: 0.004917
 74149/100000: episode: 7677, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000017, mae: 0.002930, mean_q: 0.004674
 74159/100000: episode: 7678, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000057, mae: 0.004044, mean_q: 0.005078
 74169/100000: episode: 7679, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.003192, mean_q: 0.005238
 74179/100000: episode: 7680, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000436, mae: 0.005573, mean_q: 0.005189
 74189/100000: episode: 7681, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000049, mae: 0.004887, mean_q: 0.006561
 74199/100000: episode: 7682, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000028, mae: 0.003443, mean_q: 0.004418
 74209/100000: episode: 7683, duration: 0.112s, episode steps: 10, steps per second: 90, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003131, mean_q: 0.004676
 74219/100000: episode: 7684, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000049, mae: 0.004285, mean_q: 0.005626
 74229/100000: episode: 7685, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000091, mae: 0.003963, mean_q: 0.005001
 74239/100000: episode: 7686, duration: 0.092s, episode steps: 10, steps per second: 108, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000071, mae: 0.003928, mean_q: 0.005004
[Info] Complete ISplit Iteration
[Info] Levels: [0.007747446]
[Info] Cond. Prob: [1.0]
[Info] Error Prob: 1.0

 74249/100000: episode: 7687, duration: 1.172s, episode steps: 10, steps per second: 9, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001590, mae: 0.006788, mean_q: 0.005257
 74259/100000: episode: 7688, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003157, mae: 0.014116, mean_q: 0.010083
 74269/100000: episode: 7689, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000046, mae: 0.008554, mean_q: 0.011705
 74279/100000: episode: 7690, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000284, mae: 0.004663, mean_q: 0.004203
 74289/100000: episode: 7691, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000019, mae: 0.003060, mean_q: 0.005011
 74299/100000: episode: 7692, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000012, mae: 0.003045, mean_q: 0.005354
 74309/100000: episode: 7693, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000042, mae: 0.003122, mean_q: 0.004763
 74319/100000: episode: 7694, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001569, mae: 0.006734, mean_q: 0.005503
 74329/100000: episode: 7695, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000073, mae: 0.005642, mean_q: 0.007796
 74339/100000: episode: 7696, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.001561, mae: 0.007438, mean_q: 0.007126
 74349/100000: episode: 7697, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000232, mae: 0.004729, mean_q: 0.005714
 74359/100000: episode: 7698, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000038, mae: 0.003008, mean_q: 0.004984
 74369/100000: episode: 7699, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000026, mae: 0.003400, mean_q: 0.005004
 74379/100000: episode: 7700, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000053, mae: 0.004165, mean_q: 0.005741
 74389/100000: episode: 7701, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000019, mae: 0.003128, mean_q: 0.004958
 74399/100000: episode: 7702, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000040, mae: 0.003124, mean_q: 0.004664
 74409/100000: episode: 7703, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000009, mae: 0.002611, mean_q: 0.004493
 74419/100000: episode: 7704, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000047, mae: 0.003288, mean_q: 0.004926
 74429/100000: episode: 7705, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000041, mae: 0.003159, mean_q: 0.004998
 74439/100000: episode: 7706, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.003024, mean_q: 0.004542
 74449/100000: episode: 7707, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.002738, mean_q: 0.004540
 74459/100000: episode: 7708, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000045, mae: 0.003271, mean_q: 0.004507
 74469/100000: episode: 7709, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000027, mae: 0.003537, mean_q: 0.005045
 74479/100000: episode: 7710, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000016, mae: 0.002946, mean_q: 0.004623
 74489/100000: episode: 7711, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000080, mae: 0.003901, mean_q: 0.004566
 74499/100000: episode: 7712, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000056, mae: 0.004452, mean_q: 0.005612
 74509/100000: episode: 7713, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000077, mae: 0.004159, mean_q: 0.004996
 74519/100000: episode: 7714, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000109, mae: 0.005252, mean_q: 0.005496
 74529/100000: episode: 7715, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000059, mae: 0.005032, mean_q: 0.006064
 74539/100000: episode: 7716, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000051, mae: 0.004159, mean_q: 0.005298
 74549/100000: episode: 7717, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000016, mae: 0.003227, mean_q: 0.005194
 74559/100000: episode: 7718, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000074, mae: 0.003495, mean_q: 0.004221
 74569/100000: episode: 7719, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000054, mae: 0.004175, mean_q: 0.005153
 74579/100000: episode: 7720, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003806, mean_q: 0.005491
 74589/100000: episode: 7721, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000043, mae: 0.003283, mean_q: 0.004560
 74599/100000: episode: 7722, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000059, mae: 0.003741, mean_q: 0.004412
 74609/100000: episode: 7723, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000048, mae: 0.004100, mean_q: 0.005748
 74619/100000: episode: 7724, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.004073, mean_q: 0.005375
 74629/100000: episode: 7725, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001600, mae: 0.008156, mean_q: 0.006308
 74639/100000: episode: 7726, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.005018, mean_q: 0.007376
 74649/100000: episode: 7727, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000023, mae: 0.002990, mean_q: 0.003906
 74659/100000: episode: 7728, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000098, mae: 0.004212, mean_q: 0.004911
 74669/100000: episode: 7729, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000025, mae: 0.003849, mean_q: 0.005751
 74679/100000: episode: 7730, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000045, mae: 0.003271, mean_q: 0.004543
 74689/100000: episode: 7731, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000026, mae: 0.003089, mean_q: 0.004128
 74699/100000: episode: 7732, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.003302, mean_q: 0.004855
 74709/100000: episode: 7733, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000236, mae: 0.004789, mean_q: 0.004807
 74719/100000: episode: 7734, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000014, mae: 0.003412, mean_q: 0.005783
 74729/100000: episode: 7735, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000011, mae: 0.002086, mean_q: 0.003507
 74739/100000: episode: 7736, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000049, mae: 0.003026, mean_q: 0.003860
 74749/100000: episode: 7737, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.004483, mean_q: 0.005681
 74759/100000: episode: 7738, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000093, mae: 0.004788, mean_q: 0.006157
 74769/100000: episode: 7739, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000043, mae: 0.003312, mean_q: 0.004680
 74779/100000: episode: 7740, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000069, mae: 0.003567, mean_q: 0.004741
 74789/100000: episode: 7741, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002795, mean_q: 0.004715
 74799/100000: episode: 7742, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000077, mae: 0.003703, mean_q: 0.004165
 74809/100000: episode: 7743, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000018, mae: 0.003416, mean_q: 0.005241
 74819/100000: episode: 7744, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002831, mean_q: 0.004260
 74829/100000: episode: 7745, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000054, mae: 0.003637, mean_q: 0.004413
 74839/100000: episode: 7746, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000019, mae: 0.003665, mean_q: 0.005501
 74849/100000: episode: 7747, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000041, mae: 0.003300, mean_q: 0.004389
 74859/100000: episode: 7748, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000057, mae: 0.003867, mean_q: 0.004588
 74869/100000: episode: 7749, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003657, mean_q: 0.005303
 74879/100000: episode: 7750, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000007, mae: 0.002183, mean_q: 0.003966
 74889/100000: episode: 7751, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.003396, mean_q: 0.004113
 74899/100000: episode: 7752, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000050, mae: 0.004202, mean_q: 0.005302
 74909/100000: episode: 7753, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000019, mae: 0.003139, mean_q: 0.004456
 74919/100000: episode: 7754, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000113, mae: 0.004907, mean_q: 0.004580
 74929/100000: episode: 7755, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000027, mae: 0.004592, mean_q: 0.006313
 74939/100000: episode: 7756, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000090, mae: 0.004635, mean_q: 0.004499
 74949/100000: episode: 7757, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000021, mae: 0.003868, mean_q: 0.005672
 74959/100000: episode: 7758, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001567, mae: 0.006992, mean_q: 0.005774
 74969/100000: episode: 7759, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000062, mae: 0.005858, mean_q: 0.007352
 74979/100000: episode: 7760, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000052, mae: 0.004353, mean_q: 0.005501
 74989/100000: episode: 7761, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003479, mean_q: 0.004859
 74999/100000: episode: 7762, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.003427, mean_q: 0.005102
 75009/100000: episode: 7763, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000249, mae: 0.005116, mean_q: 0.005932
 75019/100000: episode: 7764, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000018, mae: 0.003024, mean_q: 0.004753
 75029/100000: episode: 7765, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000024, mae: 0.002758, mean_q: 0.004186
 75039/100000: episode: 7766, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.003967, mean_q: 0.005745
 75049/100000: episode: 7767, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.003376, mean_q: 0.005205
 75059/100000: episode: 7768, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000043, mae: 0.002893, mean_q: 0.003865
 75069/100000: episode: 7769, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000042, mae: 0.003220, mean_q: 0.004749
 75079/100000: episode: 7770, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000051, mae: 0.004213, mean_q: 0.005340
 75089/100000: episode: 7771, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001591, mae: 0.008002, mean_q: 0.006897
 75099/100000: episode: 7772, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000049, mae: 0.004920, mean_q: 0.006823
 75109/100000: episode: 7773, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.001684, mae: 0.007470, mean_q: 0.003886
 75119/100000: episode: 7774, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000107, mae: 0.007627, mean_q: 0.009485
 75129/100000: episode: 7775, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000023, mae: 0.004800, mean_q: 0.007510
 75139/100000: episode: 7776, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000015, mae: 0.002285, mean_q: 0.002983
 75149/100000: episode: 7777, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000014, mae: 0.002773, mean_q: 0.004079
 75159/100000: episode: 7778, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000054, mae: 0.004452, mean_q: 0.005755
 75169/100000: episode: 7779, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000259, mae: 0.004826, mean_q: 0.004998
 75179/100000: episode: 7780, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000021, mae: 0.004085, mean_q: 0.006081
 75189/100000: episode: 7781, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000057, mae: 0.003958, mean_q: 0.004980
 75199/100000: episode: 7782, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000024, mae: 0.003441, mean_q: 0.004929
 75209/100000: episode: 7783, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000075, mae: 0.004209, mean_q: 0.005301
 75219/100000: episode: 7784, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000048, mae: 0.005743, mean_q: 0.008342
 75229/100000: episode: 7785, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000051, mae: 0.004451, mean_q: 0.006027
 75239/100000: episode: 7786, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000023, mae: 0.002962, mean_q: 0.004227
[Info] 1-TH LEVEL FOUND: 0.005233041942119598, Considering 100/100 traces
 75249/100000: episode: 7787, duration: 0.839s, episode steps: 10, steps per second: 12, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003325, mean_q: 0.004688
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005233041942119598
 75259/100000: episode: 7788, duration: 0.527s, episode steps: 10, steps per second: 19, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000040, mae: 0.003451, mean_q: 0.005443
 75269/100000: episode: 7789, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000048, mae: 0.003388, mean_q: 0.004768
 75279/100000: episode: 7790, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.002916, mean_q: 0.004684
 75289/100000: episode: 7791, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000043, mae: 0.003249, mean_q: 0.004571
 75299/100000: episode: 7792, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001593, mae: 0.006759, mean_q: 0.004997
 75309/100000: episode: 7793, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000047, mae: 0.005878, mean_q: 0.008406
 75319/100000: episode: 7794, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.003320, mean_q: 0.005204
 75329/100000: episode: 7795, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000027, mae: 0.002848, mean_q: 0.003285
 75339/100000: episode: 7796, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000105, mae: 0.005004, mean_q: 0.005542
 75349/100000: episode: 7797, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000257, mae: 0.006049, mean_q: 0.006929
 75359/100000: episode: 7798, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000065, mae: 0.004370, mean_q: 0.005842
 75369/100000: episode: 7799, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.002618, mean_q: 0.004332
 75379/100000: episode: 7800, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000023, mae: 0.003344, mean_q: 0.004713
 75389/100000: episode: 7801, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003899, mean_q: 0.005105
 75399/100000: episode: 7802, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000045, mae: 0.003822, mean_q: 0.005506
 75409/100000: episode: 7803, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000032, mae: 0.003686, mean_q: 0.004871
 75419/100000: episode: 7804, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000078, mae: 0.003930, mean_q: 0.004818
 75429/100000: episode: 7805, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000045, mae: 0.003497, mean_q: 0.005028
 75439/100000: episode: 7806, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000013, mae: 0.002704, mean_q: 0.004654
 75449/100000: episode: 7807, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000044, mae: 0.003106, mean_q: 0.004460
 75459/100000: episode: 7808, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000040, mae: 0.003061, mean_q: 0.004723
 75469/100000: episode: 7809, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000026, mae: 0.003416, mean_q: 0.004674
 75479/100000: episode: 7810, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000019, mae: 0.003059, mean_q: 0.004421
 75489/100000: episode: 7811, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000227, mae: 0.004408, mean_q: 0.005108
 75499/100000: episode: 7812, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000047, mae: 0.003927, mean_q: 0.005177
 75509/100000: episode: 7813, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000057, mae: 0.004588, mean_q: 0.005319
 75519/100000: episode: 7814, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000008, mae: 0.002895, mean_q: 0.005175
 75529/100000: episode: 7815, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000112, mae: 0.004820, mean_q: 0.004426
 75539/100000: episode: 7816, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000050, mae: 0.004425, mean_q: 0.006028
 75549/100000: episode: 7817, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000277, mae: 0.005463, mean_q: 0.005470
 75559/100000: episode: 7818, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001577, mae: 0.008728, mean_q: 0.008054
 75569/100000: episode: 7819, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001594, mae: 0.007580, mean_q: 0.006345
 75579/100000: episode: 7820, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000049, mae: 0.005288, mean_q: 0.007415
 75589/100000: episode: 7821, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000017, mae: 0.003245, mean_q: 0.005038
 75599/100000: episode: 7822, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000066, mae: 0.003635, mean_q: 0.004168
 75609/100000: episode: 7823, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000029, mae: 0.004220, mean_q: 0.006063
 75619/100000: episode: 7824, duration: 0.052s, episode steps: 10, steps per second: 190, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000071, mae: 0.003934, mean_q: 0.005251
 75629/100000: episode: 7825, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000302, mae: 0.006596, mean_q: 0.005700
 75639/100000: episode: 7826, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000131, mae: 0.007089, mean_q: 0.008200
 75649/100000: episode: 7827, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000020, mae: 0.003533, mean_q: 0.005544
 75659/100000: episode: 7828, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001588, mae: 0.006995, mean_q: 0.006395
 75669/100000: episode: 7829, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000016, mae: 0.003738, mean_q: 0.006279
 75679/100000: episode: 7830, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000051, mae: 0.003279, mean_q: 0.004108
 75689/100000: episode: 7831, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000075, mae: 0.004207, mean_q: 0.005126
 75699/100000: episode: 7832, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000042, mae: 0.003890, mean_q: 0.005949
 75709/100000: episode: 7833, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000068, mae: 0.003573, mean_q: 0.004614
 75719/100000: episode: 7834, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000029, mae: 0.003523, mean_q: 0.004721
 75729/100000: episode: 7835, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000102, mae: 0.004896, mean_q: 0.005698
 75739/100000: episode: 7836, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.004018, mean_q: 0.005688
 75749/100000: episode: 7837, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000038, mae: 0.003149, mean_q: 0.004935
 75759/100000: episode: 7838, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002911, mean_q: 0.004855
 75769/100000: episode: 7839, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000250, mae: 0.004455, mean_q: 0.005066
 75779/100000: episode: 7840, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000036, mae: 0.003830, mean_q: 0.006106
 75789/100000: episode: 7841, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000292, mae: 0.005659, mean_q: 0.004978
 75799/100000: episode: 7842, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000084, mae: 0.005845, mean_q: 0.007192
 75809/100000: episode: 7843, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001615, mae: 0.007997, mean_q: 0.006478
 75819/100000: episode: 7844, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000028, mae: 0.005585, mean_q: 0.007938
 75829/100000: episode: 7845, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000015, mae: 0.002856, mean_q: 0.004800
 75839/100000: episode: 7846, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002355, mean_q: 0.003624
 75849/100000: episode: 7847, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003647, mean_q: 0.005131
 75859/100000: episode: 7848, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000017, mae: 0.002834, mean_q: 0.004751
 75869/100000: episode: 7849, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000011, mae: 0.002219, mean_q: 0.003725
 75879/100000: episode: 7850, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000014, mae: 0.002438, mean_q: 0.004134
 75889/100000: episode: 7851, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000081, mae: 0.004463, mean_q: 0.005013
 75899/100000: episode: 7852, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000140, mae: 0.006662, mean_q: 0.006935
 75909/100000: episode: 7853, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000039, mae: 0.004109, mean_q: 0.006092
 75919/100000: episode: 7854, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002396, mean_q: 0.004031
 75929/100000: episode: 7855, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000070, mae: 0.003416, mean_q: 0.004299
 75939/100000: episode: 7856, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.003699, mean_q: 0.005583
 75949/100000: episode: 7857, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000015, mae: 0.002788, mean_q: 0.004529
 75959/100000: episode: 7858, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000088, mae: 0.004089, mean_q: 0.004197
 75969/100000: episode: 7859, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000010, mae: 0.003023, mean_q: 0.005362
 75979/100000: episode: 7860, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000050, mae: 0.003599, mean_q: 0.004033
 75989/100000: episode: 7861, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000020, mae: 0.003562, mean_q: 0.005258
 75999/100000: episode: 7862, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000048, mae: 0.003854, mean_q: 0.005004
 76009/100000: episode: 7863, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000286, mae: 0.005960, mean_q: 0.005683
 76019/100000: episode: 7864, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000042, mae: 0.004493, mean_q: 0.006334
 76029/100000: episode: 7865, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.002961, mean_q: 0.004035
 76039/100000: episode: 7866, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000055, mae: 0.003884, mean_q: 0.004550
 76049/100000: episode: 7867, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000044, mae: 0.004250, mean_q: 0.005927
 76059/100000: episode: 7868, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000029, mae: 0.003778, mean_q: 0.005025
 76069/100000: episode: 7869, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.003129, mean_q: 0.004379
 76079/100000: episode: 7870, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000047, mae: 0.003574, mean_q: 0.004714
 76089/100000: episode: 7871, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000100, mae: 0.004787, mean_q: 0.005550
 76099/100000: episode: 7872, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000021, mae: 0.003276, mean_q: 0.004864
 76109/100000: episode: 7873, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003059, mean_q: 0.004059
 76119/100000: episode: 7874, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001570, mae: 0.008083, mean_q: 0.007161
 76129/100000: episode: 7875, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001669, mae: 0.010580, mean_q: 0.008759
 76139/100000: episode: 7876, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000053, mae: 0.005235, mean_q: 0.006932
 76149/100000: episode: 7877, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000078, mae: 0.003791, mean_q: 0.004305
 76159/100000: episode: 7878, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000024, mae: 0.003372, mean_q: 0.005216
 76169/100000: episode: 7879, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000236, mae: 0.005060, mean_q: 0.005719
 76179/100000: episode: 7880, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000020, mae: 0.003530, mean_q: 0.005779
 76189/100000: episode: 7881, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000078, mae: 0.003699, mean_q: 0.004250
 76199/100000: episode: 7882, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003961, mean_q: 0.005826
 76209/100000: episode: 7883, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000039, mae: 0.003507, mean_q: 0.005304
 76219/100000: episode: 7884, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000256, mae: 0.004801, mean_q: 0.005034
 76229/100000: episode: 7885, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000058, mae: 0.005436, mean_q: 0.007120
 76239/100000: episode: 7886, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000057, mae: 0.004029, mean_q: 0.005257
 76249/100000: episode: 7887, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000038, mae: 0.004200, mean_q: 0.005072
[Info] 1-TH LEVEL FOUND: 0.006353192031383514, Considering 100/100 traces
 76259/100000: episode: 7888, duration: 0.672s, episode steps: 10, steps per second: 15, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000080, mae: 0.004848, mean_q: 0.006093
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006353192031383514
 76269/100000: episode: 7889, duration: 0.499s, episode steps: 10, steps per second: 20, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000030, mae: 0.004123, mean_q: 0.005933
 76279/100000: episode: 7890, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000073, mae: 0.003927, mean_q: 0.005034
 76289/100000: episode: 7891, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000053, mae: 0.004144, mean_q: 0.005636
 76299/100000: episode: 7892, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000075, mae: 0.004063, mean_q: 0.004912
 76309/100000: episode: 7893, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000058, mae: 0.004801, mean_q: 0.006200
 76319/100000: episode: 7894, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000016, mae: 0.003469, mean_q: 0.005804
 76329/100000: episode: 7895, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000051, mae: 0.003520, mean_q: 0.004592
 76339/100000: episode: 7896, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000025, mae: 0.003492, mean_q: 0.005255
 76349/100000: episode: 7897, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000028, mae: 0.003203, mean_q: 0.004634
 76359/100000: episode: 7898, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000065, mae: 0.004564, mean_q: 0.005320
 76369/100000: episode: 7899, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000026, mae: 0.004083, mean_q: 0.005850
 76379/100000: episode: 7900, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000075, mae: 0.003769, mean_q: 0.004745
 76389/100000: episode: 7901, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000019, mae: 0.003156, mean_q: 0.004969
 76399/100000: episode: 7902, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000015, mae: 0.003119, mean_q: 0.005043
 76409/100000: episode: 7903, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001559, mae: 0.006572, mean_q: 0.005839
 76419/100000: episode: 7904, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.004488, mean_q: 0.007139
 76429/100000: episode: 7905, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000042, mae: 0.002735, mean_q: 0.003867
 76439/100000: episode: 7906, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000293, mae: 0.005867, mean_q: 0.005771
 76449/100000: episode: 7907, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000023, mae: 0.004104, mean_q: 0.006251
 76459/100000: episode: 7908, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000039, mae: 0.002637, mean_q: 0.003737
 76469/100000: episode: 7909, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000013, mae: 0.002534, mean_q: 0.004384
 76479/100000: episode: 7910, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000040, mae: 0.003482, mean_q: 0.005064
 76489/100000: episode: 7911, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000060, mae: 0.004017, mean_q: 0.004743
 76499/100000: episode: 7912, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000022, mae: 0.003618, mean_q: 0.005443
 76509/100000: episode: 7913, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000026, mae: 0.003211, mean_q: 0.004513
 76519/100000: episode: 7914, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000024, mae: 0.003449, mean_q: 0.004677
 76529/100000: episode: 7915, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001562, mae: 0.007513, mean_q: 0.007070
 76539/100000: episode: 7916, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000050, mae: 0.004220, mean_q: 0.005761
 76549/100000: episode: 7917, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002488, mean_q: 0.004200
 76559/100000: episode: 7918, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000047, mae: 0.003661, mean_q: 0.004985
 76569/100000: episode: 7919, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000015, mae: 0.003071, mean_q: 0.004908
 76579/100000: episode: 7920, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003115, mean_q: 0.004490
 76589/100000: episode: 7921, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000079, mae: 0.005168, mean_q: 0.005148
 76599/100000: episode: 7922, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000255, mae: 0.005614, mean_q: 0.006186
 76609/100000: episode: 7923, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000057, mae: 0.004641, mean_q: 0.005789
 76619/100000: episode: 7924, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000060, mae: 0.004402, mean_q: 0.005295
 76629/100000: episode: 7925, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000051, mae: 0.003930, mean_q: 0.005143
 76639/100000: episode: 7926, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000043, mae: 0.003992, mean_q: 0.005773
 76649/100000: episode: 7927, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000029, mae: 0.004141, mean_q: 0.005862
 76659/100000: episode: 7928, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000047, mae: 0.003648, mean_q: 0.005028
 76669/100000: episode: 7929, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000026, mae: 0.003361, mean_q: 0.004762
 76679/100000: episode: 7930, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000065, mae: 0.004687, mean_q: 0.005329
 76689/100000: episode: 7931, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001559, mae: 0.007855, mean_q: 0.007752
 76699/100000: episode: 7932, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000045, mae: 0.004097, mean_q: 0.005888
 76709/100000: episode: 7933, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000016, mae: 0.002533, mean_q: 0.003815
 76719/100000: episode: 7934, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003241, mean_q: 0.004854
 76729/100000: episode: 7935, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000049, mae: 0.003940, mean_q: 0.005580
 76739/100000: episode: 7936, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.003556, mean_q: 0.005220
 76749/100000: episode: 7937, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000024, mae: 0.003160, mean_q: 0.004859
 76759/100000: episode: 7938, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000044, mae: 0.002953, mean_q: 0.004232
 76769/100000: episode: 7939, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000054, mae: 0.003863, mean_q: 0.004886
 76779/100000: episode: 7940, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001569, mae: 0.006588, mean_q: 0.005396
 76789/100000: episode: 7941, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000026, mae: 0.005127, mean_q: 0.007455
 76799/100000: episode: 7942, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000052, mae: 0.004280, mean_q: 0.004513
 76809/100000: episode: 7943, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000222, mae: 0.004809, mean_q: 0.005952
 76819/100000: episode: 7944, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000063, mae: 0.005140, mean_q: 0.005931
 76829/100000: episode: 7945, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000033, mae: 0.005672, mean_q: 0.008162
 76839/100000: episode: 7946, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003365, mean_q: 0.005620
 76849/100000: episode: 7947, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000008, mae: 0.001954, mean_q: 0.002956
 76859/100000: episode: 7948, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000044, mae: 0.003339, mean_q: 0.004534
 76869/100000: episode: 7949, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000022, mae: 0.003700, mean_q: 0.005630
 76879/100000: episode: 7950, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000066, mae: 0.003594, mean_q: 0.005030
 76889/100000: episode: 7951, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002868, mean_q: 0.004771
 76899/100000: episode: 7952, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000010, mae: 0.002635, mean_q: 0.004063
 76909/100000: episode: 7953, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.003413, mean_q: 0.004380
 76919/100000: episode: 7954, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000222, mae: 0.004057, mean_q: 0.005180
 76929/100000: episode: 7955, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.003463, mean_q: 0.005108
 76939/100000: episode: 7956, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003378, mean_q: 0.004539
 76949/100000: episode: 7957, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.004376, mean_q: 0.005656
 76959/100000: episode: 7958, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.001798, mae: 0.010074, mean_q: 0.008200
 76969/100000: episode: 7959, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000022, mae: 0.004741, mean_q: 0.007271
 76979/100000: episode: 7960, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000030, mae: 0.003098, mean_q: 0.003345
 76989/100000: episode: 7961, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000070, mae: 0.004062, mean_q: 0.005028
 76999/100000: episode: 7962, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.003767, mean_q: 0.005778
 77009/100000: episode: 7963, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002447, mean_q: 0.004183
 77019/100000: episode: 7964, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003012, mean_q: 0.004411
 77029/100000: episode: 7965, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.001600, mae: 0.006708, mean_q: 0.004592
 77039/100000: episode: 7966, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000029, mae: 0.005720, mean_q: 0.008143
 77049/100000: episode: 7967, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000220, mae: 0.004827, mean_q: 0.006273
 77059/100000: episode: 7968, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000019, mae: 0.002817, mean_q: 0.004237
 77069/100000: episode: 7969, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000024, mae: 0.003325, mean_q: 0.004624
 77079/100000: episode: 7970, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000042, mae: 0.003764, mean_q: 0.005457
 77089/100000: episode: 7971, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000070, mae: 0.003525, mean_q: 0.004411
 77099/100000: episode: 7972, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.003218, mean_q: 0.004947
 77109/100000: episode: 7973, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000025, mae: 0.003358, mean_q: 0.004958
 77119/100000: episode: 7974, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000224, mae: 0.004522, mean_q: 0.005667
 77129/100000: episode: 7975, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000011, mae: 0.002789, mean_q: 0.004746
 77139/100000: episode: 7976, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003079, mean_q: 0.003904
 77149/100000: episode: 7977, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000018, mae: 0.003013, mean_q: 0.004643
 77159/100000: episode: 7978, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000052, mae: 0.003838, mean_q: 0.004973
 77169/100000: episode: 7979, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000016, mae: 0.003334, mean_q: 0.004929
 77179/100000: episode: 7980, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000024, mae: 0.003594, mean_q: 0.004927
 77189/100000: episode: 7981, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.002709, mean_q: 0.004730
 77199/100000: episode: 7982, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000073, mae: 0.003598, mean_q: 0.004249
 77209/100000: episode: 7983, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000042, mae: 0.004875, mean_q: 0.005655
 77219/100000: episode: 7984, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.003658, mean_q: 0.005483
 77229/100000: episode: 7985, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002538, mean_q: 0.003981
 77239/100000: episode: 7986, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000042, mae: 0.002858, mean_q: 0.004116
 77249/100000: episode: 7987, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000027, mae: 0.003991, mean_q: 0.005293
 77259/100000: episode: 7988, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000018, mae: 0.003170, mean_q: 0.004834
[Info] 1-TH LEVEL FOUND: 0.004652538802474737, Considering 100/100 traces
 77269/100000: episode: 7989, duration: 0.656s, episode steps: 10, steps per second: 15, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000018, mae: 0.003082, mean_q: 0.004182
[Info] 2-TH LEVEL FOUND: 0.004877545405179262, Considering 100/100 traces
 77279/100000: episode: 7990, duration: 0.642s, episode steps: 10, steps per second: 16, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000032, mae: 0.003879, mean_q: 0.005027
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004877545405179262
 77289/100000: episode: 7991, duration: 0.476s, episode steps: 10, steps per second: 21, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000027, mae: 0.003612, mean_q: 0.004959
 77299/100000: episode: 7992, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.002905, mean_q: 0.004087
 77309/100000: episode: 7993, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000015, mae: 0.003121, mean_q: 0.004395
 77319/100000: episode: 7994, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000020, mae: 0.003229, mean_q: 0.004531
 77329/100000: episode: 7995, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000010, mae: 0.002647, mean_q: 0.004515
 77339/100000: episode: 7996, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000072, mae: 0.003501, mean_q: 0.004010
 77349/100000: episode: 7997, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001619, mae: 0.007870, mean_q: 0.005943
 77359/100000: episode: 7998, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000097, mae: 0.006739, mean_q: 0.008611
 77369/100000: episode: 7999, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000040, mae: 0.002672, mean_q: 0.003721
 77379/100000: episode: 8000, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000044, mae: 0.003160, mean_q: 0.004192
 77389/100000: episode: 8001, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.003676, mean_q: 0.005141
 77399/100000: episode: 8002, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000040, mae: 0.003419, mean_q: 0.004811
 77409/100000: episode: 8003, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000049, mae: 0.004096, mean_q: 0.005017
 77419/100000: episode: 8004, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003553, mean_q: 0.005085
 77429/100000: episode: 8005, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000077, mae: 0.004410, mean_q: 0.005284
 77439/100000: episode: 8006, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000045, mae: 0.003237, mean_q: 0.004493
 77449/100000: episode: 8007, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003140, mean_q: 0.004443
 77459/100000: episode: 8008, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000054, mae: 0.005993, mean_q: 0.007900
 77469/100000: episode: 8009, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.003692, mean_q: 0.005516
 77479/100000: episode: 8010, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000049, mae: 0.002761, mean_q: 0.003273
 77489/100000: episode: 8011, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000012, mae: 0.002711, mean_q: 0.004768
 77499/100000: episode: 8012, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000008, mae: 0.002415, mean_q: 0.004179
 77509/100000: episode: 8013, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000041, mae: 0.003309, mean_q: 0.004262
 77519/100000: episode: 8014, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000040, mae: 0.003491, mean_q: 0.004979
 77529/100000: episode: 8015, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000011, mae: 0.002588, mean_q: 0.004326
 77539/100000: episode: 8016, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.003051, mean_q: 0.004185
 77549/100000: episode: 8017, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000027, mae: 0.004071, mean_q: 0.005425
 77559/100000: episode: 8018, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000042, mae: 0.003287, mean_q: 0.004625
 77569/100000: episode: 8019, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000072, mae: 0.003809, mean_q: 0.004533
 77579/100000: episode: 8020, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000025, mae: 0.003871, mean_q: 0.005502
 77589/100000: episode: 8021, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001777, mae: 0.009057, mean_q: 0.007386
 77599/100000: episode: 8022, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000013, mae: 0.003773, mean_q: 0.006296
 77609/100000: episode: 8023, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000082, mae: 0.003326, mean_q: 0.003042
 77619/100000: episode: 8024, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000054, mae: 0.004298, mean_q: 0.005504
 77629/100000: episode: 8025, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000052, mae: 0.004394, mean_q: 0.005811
 77639/100000: episode: 8026, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000050, mae: 0.003264, mean_q: 0.004126
 77649/100000: episode: 8027, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000232, mae: 0.004961, mean_q: 0.005417
 77659/100000: episode: 8028, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.001572, mae: 0.007221, mean_q: 0.005964
 77669/100000: episode: 8029, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000042, mae: 0.004833, mean_q: 0.007153
 77679/100000: episode: 8030, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000048, mae: 0.003727, mean_q: 0.004727
 77689/100000: episode: 8031, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000018, mae: 0.002815, mean_q: 0.004406
 77699/100000: episode: 8032, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001771, mae: 0.008429, mean_q: 0.006933
 77709/100000: episode: 8033, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.004753, mean_q: 0.007054
 77719/100000: episode: 8034, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.002209, mean_q: 0.003100
 77729/100000: episode: 8035, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000027, mae: 0.003241, mean_q: 0.004223
 77739/100000: episode: 8036, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001618, mae: 0.008708, mean_q: 0.007756
 77749/100000: episode: 8037, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000021, mae: 0.004278, mean_q: 0.006605
 77759/100000: episode: 8038, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000043, mae: 0.002619, mean_q: 0.003685
 77769/100000: episode: 8039, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000070, mae: 0.003622, mean_q: 0.004665
 77779/100000: episode: 8040, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000050, mae: 0.003885, mean_q: 0.005283
 77789/100000: episode: 8041, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000042, mae: 0.003666, mean_q: 0.005058
 77799/100000: episode: 8042, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000047, mae: 0.003323, mean_q: 0.004858
 77809/100000: episode: 8043, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000046, mae: 0.003409, mean_q: 0.004732
 77819/100000: episode: 8044, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000010, mae: 0.002505, mean_q: 0.004517
 77829/100000: episode: 8045, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000097, mae: 0.003797, mean_q: 0.004328
 77839/100000: episode: 8046, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.003137, mean_q: 0.004987
 77849/100000: episode: 8047, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000232, mae: 0.004548, mean_q: 0.004879
 77859/100000: episode: 8048, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000013, mae: 0.003189, mean_q: 0.005345
 77869/100000: episode: 8049, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.003351, mean_q: 0.004137
 77879/100000: episode: 8050, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000072, mae: 0.004305, mean_q: 0.005329
 77889/100000: episode: 8051, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001569, mae: 0.007186, mean_q: 0.006172
 77899/100000: episode: 8052, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000104, mae: 0.006041, mean_q: 0.007039
 77909/100000: episode: 8053, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000079, mae: 0.004276, mean_q: 0.005133
 77919/100000: episode: 8054, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000074, mae: 0.004339, mean_q: 0.005410
 77929/100000: episode: 8055, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000038, mae: 0.003260, mean_q: 0.005219
 77939/100000: episode: 8056, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000110, mae: 0.004901, mean_q: 0.004949
 77949/100000: episode: 8057, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000024, mae: 0.004314, mean_q: 0.006387
 77959/100000: episode: 8058, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000235, mae: 0.005235, mean_q: 0.005894
 77969/100000: episode: 8059, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000009, mae: 0.002805, mean_q: 0.004822
 77979/100000: episode: 8060, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000016, mae: 0.002208, mean_q: 0.003658
 77989/100000: episode: 8061, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000027, mae: 0.003630, mean_q: 0.004892
 77999/100000: episode: 8062, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000047, mae: 0.003973, mean_q: 0.005554
 78009/100000: episode: 8063, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000040, mae: 0.003235, mean_q: 0.004768
 78019/100000: episode: 8064, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.003355, mean_q: 0.004658
 78029/100000: episode: 8065, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000041, mae: 0.003387, mean_q: 0.005225
 78039/100000: episode: 8066, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000041, mae: 0.003212, mean_q: 0.004310
 78049/100000: episode: 8067, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000025, mae: 0.003461, mean_q: 0.004853
 78059/100000: episode: 8068, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000017, mae: 0.002747, mean_q: 0.004510
 78069/100000: episode: 8069, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000023, mae: 0.003227, mean_q: 0.004448
 78079/100000: episode: 8070, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000039, mae: 0.003745, mean_q: 0.005563
 78089/100000: episode: 8071, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002838, mean_q: 0.004059
 78099/100000: episode: 8072, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000039, mae: 0.003070, mean_q: 0.004484
 78109/100000: episode: 8073, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.003177, mean_q: 0.004937
 78119/100000: episode: 8074, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000013, mae: 0.002282, mean_q: 0.003922
 78129/100000: episode: 8075, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003045, mean_q: 0.004198
 78139/100000: episode: 8076, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000035, mae: 0.004034, mean_q: 0.005093
[Info] FALSIFICATION!
 78149/100000: episode: 8077, duration: 0.209s, episode steps: 10, steps per second: 48, episode reward: 1.582, mean reward: 0.158 [0.000, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [1.000, 10.000], loss: 0.000070, mae: 0.004529, mean_q: 0.004928
 78159/100000: episode: 8078, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003935, mean_q: 0.005456
 78169/100000: episode: 8079, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000040, mae: 0.002709, mean_q: 0.004173
 78179/100000: episode: 8080, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.002973, mean_q: 0.004030
 78189/100000: episode: 8081, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000052, mae: 0.004447, mean_q: 0.005672
 78199/100000: episode: 8082, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.003722, mean_q: 0.005050
 78209/100000: episode: 8083, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000045, mae: 0.003156, mean_q: 0.004199
 78219/100000: episode: 8084, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000024, mae: 0.003276, mean_q: 0.004595
 78229/100000: episode: 8085, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000327, mae: 0.006707, mean_q: 0.005492
 78239/100000: episode: 8086, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000225, mae: 0.006155, mean_q: 0.007599
 78249/100000: episode: 8087, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000040, mae: 0.003051, mean_q: 0.004160
 78259/100000: episode: 8088, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002606, mean_q: 0.003978
 78269/100000: episode: 8089, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000060, mae: 0.004782, mean_q: 0.005766
 78279/100000: episode: 8090, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000052, mae: 0.004297, mean_q: 0.005775
[Info] Complete ISplit Iteration
[Info] Levels: [0.003951453]
[Info] Cond. Prob: [1.0]
[Info] Error Prob: 1.0

 78289/100000: episode: 8091, duration: 0.835s, episode steps: 10, steps per second: 12, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003089, mean_q: 0.004320
 78299/100000: episode: 8092, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000011, mae: 0.002525, mean_q: 0.003980
 78309/100000: episode: 8093, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002800, mean_q: 0.004347
 78319/100000: episode: 8094, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000050, mae: 0.003839, mean_q: 0.005040
 78329/100000: episode: 8095, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.003582, mean_q: 0.004865
 78339/100000: episode: 8096, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003341, mean_q: 0.004593
 78349/100000: episode: 8097, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000047, mae: 0.003620, mean_q: 0.004632
 78359/100000: episode: 8098, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000028, mae: 0.003649, mean_q: 0.005103
 78369/100000: episode: 8099, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.001571, mae: 0.006680, mean_q: 0.005120
 78379/100000: episode: 8100, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000029, mae: 0.005775, mean_q: 0.008006
 78389/100000: episode: 8101, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000048, mae: 0.003260, mean_q: 0.004449
 78399/100000: episode: 8102, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000073, mae: 0.003530, mean_q: 0.004187
 78409/100000: episode: 8103, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000014, mae: 0.002996, mean_q: 0.005025
 78419/100000: episode: 8104, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000042, mae: 0.003338, mean_q: 0.004465
 78429/100000: episode: 8105, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000049, mae: 0.003487, mean_q: 0.004636
 78439/100000: episode: 8106, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000097, mae: 0.004328, mean_q: 0.005340
 78449/100000: episode: 8107, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000016, mae: 0.002769, mean_q: 0.004662
 78459/100000: episode: 8108, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000231, mae: 0.004107, mean_q: 0.004220
 78469/100000: episode: 8109, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000042, mae: 0.004157, mean_q: 0.005873
 78479/100000: episode: 8110, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003029, mean_q: 0.004325
 78489/100000: episode: 8111, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000026, mae: 0.003050, mean_q: 0.004165
 78499/100000: episode: 8112, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000016, mae: 0.003163, mean_q: 0.004918
 78509/100000: episode: 8113, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000105, mae: 0.004773, mean_q: 0.005171
 78519/100000: episode: 8114, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000024, mae: 0.004201, mean_q: 0.005813
 78529/100000: episode: 8115, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000020, mae: 0.002880, mean_q: 0.004130
 78539/100000: episode: 8116, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002647, mean_q: 0.004263
 78549/100000: episode: 8117, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003084, mean_q: 0.004336
 78559/100000: episode: 8118, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000053, mae: 0.003759, mean_q: 0.004751
 78569/100000: episode: 8119, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.003315, mean_q: 0.005132
 78579/100000: episode: 8120, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000068, mae: 0.003343, mean_q: 0.004222
 78589/100000: episode: 8121, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003123, mean_q: 0.004093
 78599/100000: episode: 8122, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000050, mae: 0.003970, mean_q: 0.005229
 78609/100000: episode: 8123, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000075, mae: 0.003871, mean_q: 0.004942
 78619/100000: episode: 8124, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001839, mae: 0.009282, mean_q: 0.005656
 78629/100000: episode: 8125, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000107, mae: 0.008087, mean_q: 0.010131
 78639/100000: episode: 8126, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002694, mean_q: 0.004356
 78649/100000: episode: 8127, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.002759, mean_q: 0.002986
 78659/100000: episode: 8128, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000028, mae: 0.004178, mean_q: 0.005579
 78669/100000: episode: 8129, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000076, mae: 0.004503, mean_q: 0.005619
 78679/100000: episode: 8130, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000044, mae: 0.003712, mean_q: 0.005017
 78689/100000: episode: 8131, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000045, mae: 0.003194, mean_q: 0.004447
 78699/100000: episode: 8132, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002693, mean_q: 0.004255
 78709/100000: episode: 8133, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000049, mae: 0.003396, mean_q: 0.004552
 78719/100000: episode: 8134, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000027, mae: 0.003510, mean_q: 0.005055
 78729/100000: episode: 8135, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000062, mae: 0.003204, mean_q: 0.004548
 78739/100000: episode: 8136, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003328, mean_q: 0.004366
 78749/100000: episode: 8137, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000064, mae: 0.003761, mean_q: 0.005360
 78759/100000: episode: 8138, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000073, mae: 0.003632, mean_q: 0.004486
 78769/100000: episode: 8139, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000039, mae: 0.002656, mean_q: 0.004234
 78779/100000: episode: 8140, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000073, mae: 0.003895, mean_q: 0.004668
 78789/100000: episode: 8141, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001656, mae: 0.008718, mean_q: 0.005903
 78799/100000: episode: 8142, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000288, mae: 0.008476, mean_q: 0.009317
 78809/100000: episode: 8143, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000026, mae: 0.004091, mean_q: 0.005783
 78819/100000: episode: 8144, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000010, mae: 0.002223, mean_q: 0.003614
 78829/100000: episode: 8145, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000015, mae: 0.002307, mean_q: 0.004070
 78839/100000: episode: 8146, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000062, mae: 0.002989, mean_q: 0.004052
 78849/100000: episode: 8147, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003610, mean_q: 0.005354
 78859/100000: episode: 8148, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000045, mae: 0.003720, mean_q: 0.005165
 78869/100000: episode: 8149, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000104, mae: 0.004117, mean_q: 0.004326
 78879/100000: episode: 8150, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003697, mean_q: 0.005713
 78889/100000: episode: 8151, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000018, mae: 0.003080, mean_q: 0.004645
 78899/100000: episode: 8152, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.002484, mean_q: 0.003656
 78909/100000: episode: 8153, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000052, mae: 0.003675, mean_q: 0.004576
 78919/100000: episode: 8154, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000226, mae: 0.004421, mean_q: 0.005180
 78929/100000: episode: 8155, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001579, mae: 0.008588, mean_q: 0.007385
 78939/100000: episode: 8156, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000016, mae: 0.003860, mean_q: 0.006317
 78949/100000: episode: 8157, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000225, mae: 0.003857, mean_q: 0.003758
 78959/100000: episode: 8158, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000078, mae: 0.004272, mean_q: 0.005505
 78969/100000: episode: 8159, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000100, mae: 0.004521, mean_q: 0.005313
 78979/100000: episode: 8160, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000044, mae: 0.003202, mean_q: 0.004588
 78989/100000: episode: 8161, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000262, mae: 0.005556, mean_q: 0.005589
 78999/100000: episode: 8162, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000048, mae: 0.004354, mean_q: 0.006006
 79009/100000: episode: 8163, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000008, mae: 0.002250, mean_q: 0.003980
 79019/100000: episode: 8164, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000057, mae: 0.003834, mean_q: 0.004760
 79029/100000: episode: 8165, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000049, mae: 0.004063, mean_q: 0.005356
 79039/100000: episode: 8166, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000046, mae: 0.003944, mean_q: 0.005552
 79049/100000: episode: 8167, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.002919, mean_q: 0.004122
 79059/100000: episode: 8168, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000070, mae: 0.003800, mean_q: 0.004942
 79069/100000: episode: 8169, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000224, mae: 0.004002, mean_q: 0.004659
 79079/100000: episode: 8170, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000076, mae: 0.004250, mean_q: 0.005316
 79089/100000: episode: 8171, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001563, mae: 0.006972, mean_q: 0.005987
 79099/100000: episode: 8172, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000025, mae: 0.004959, mean_q: 0.007394
 79109/100000: episode: 8173, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000037, mae: 0.002333, mean_q: 0.003878
 79119/100000: episode: 8174, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.002478, mean_q: 0.003661
 79129/100000: episode: 8175, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000072, mae: 0.004320, mean_q: 0.005219
 79139/100000: episode: 8176, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000038, mae: 0.003200, mean_q: 0.004997
 79149/100000: episode: 8177, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000044, mae: 0.003319, mean_q: 0.004365
 79159/100000: episode: 8178, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000042, mae: 0.003419, mean_q: 0.004981
 79169/100000: episode: 8179, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000260, mae: 0.005182, mean_q: 0.005086
 79179/100000: episode: 8180, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001569, mae: 0.008167, mean_q: 0.007343
 79189/100000: episode: 8181, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000075, mae: 0.005074, mean_q: 0.006597
 79199/100000: episode: 8182, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000049, mae: 0.003265, mean_q: 0.004206
 79209/100000: episode: 8183, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000040, mae: 0.003194, mean_q: 0.004929
 79219/100000: episode: 8184, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003361, mean_q: 0.005130
 79229/100000: episode: 8185, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000044, mae: 0.003184, mean_q: 0.004487
 79239/100000: episode: 8186, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000127, mae: 0.004956, mean_q: 0.005043
 79249/100000: episode: 8187, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.004062, mean_q: 0.006070
 79259/100000: episode: 8188, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000047, mae: 0.003754, mean_q: 0.005087
 79269/100000: episode: 8189, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003504, mean_q: 0.005004
 79279/100000: episode: 8190, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000052, mae: 0.003664, mean_q: 0.004661
[Info] 1-TH LEVEL FOUND: 0.005156513769179583, Considering 100/100 traces
 79289/100000: episode: 8191, duration: 0.753s, episode steps: 10, steps per second: 13, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003564, mean_q: 0.005021
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005156513769179583
 79299/100000: episode: 8192, duration: 0.539s, episode steps: 10, steps per second: 19, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.003042, mean_q: 0.004737
 79309/100000: episode: 8193, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000019, mae: 0.002940, mean_q: 0.004209
 79319/100000: episode: 8194, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000070, mae: 0.003905, mean_q: 0.004973
 79329/100000: episode: 8195, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000049, mae: 0.003757, mean_q: 0.005184
 79339/100000: episode: 8196, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000098, mae: 0.004616, mean_q: 0.005436
 79349/100000: episode: 8197, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.003173, mean_q: 0.005110
 79359/100000: episode: 8198, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000045, mae: 0.002885, mean_q: 0.004093
 79369/100000: episode: 8199, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000039, mae: 0.003215, mean_q: 0.004589
 79379/100000: episode: 8200, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000052, mae: 0.003789, mean_q: 0.004960
 79389/100000: episode: 8201, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000104, mae: 0.004641, mean_q: 0.005029
 79399/100000: episode: 8202, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000111, mae: 0.005592, mean_q: 0.006060
 79409/100000: episode: 8203, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000046, mae: 0.004147, mean_q: 0.005741
 79419/100000: episode: 8204, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000052, mae: 0.003130, mean_q: 0.003855
 79429/100000: episode: 8205, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000289, mae: 0.006090, mean_q: 0.005909
 79439/100000: episode: 8206, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000082, mae: 0.005532, mean_q: 0.006615
 79449/100000: episode: 8207, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000082, mae: 0.004114, mean_q: 0.004839
 79459/100000: episode: 8208, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002976, mean_q: 0.004983
 79469/100000: episode: 8209, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000021, mae: 0.002889, mean_q: 0.004309
 79479/100000: episode: 8210, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000048, mae: 0.003483, mean_q: 0.004486
 79489/100000: episode: 8211, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000075, mae: 0.004346, mean_q: 0.005206
 79499/100000: episode: 8212, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000100, mae: 0.004709, mean_q: 0.005587
 79509/100000: episode: 8213, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000007, mae: 0.002579, mean_q: 0.004719
 79519/100000: episode: 8214, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000050, mae: 0.003022, mean_q: 0.003486
 79529/100000: episode: 8215, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000011, mae: 0.002992, mean_q: 0.005080
 79539/100000: episode: 8216, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000072, mae: 0.003374, mean_q: 0.004342
 79549/100000: episode: 8217, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000071, mae: 0.004287, mean_q: 0.005200
 79559/100000: episode: 8218, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000230, mae: 0.004111, mean_q: 0.004514
 79569/100000: episode: 8219, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000035, mae: 0.004395, mean_q: 0.005740
 79579/100000: episode: 8220, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000431, mae: 0.005872, mean_q: 0.005909
 79589/100000: episode: 8221, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.001625, mae: 0.007828, mean_q: 0.005940
 79599/100000: episode: 8222, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000275, mae: 0.007475, mean_q: 0.008966
 79609/100000: episode: 8223, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000049, mae: 0.003592, mean_q: 0.005062
 79619/100000: episode: 8224, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000037, mae: 0.003558, mean_q: 0.004290
 79629/100000: episode: 8225, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000045, mae: 0.004284, mean_q: 0.005960
 79639/100000: episode: 8226, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000098, mae: 0.004505, mean_q: 0.005470
 79649/100000: episode: 8227, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000067, mae: 0.004143, mean_q: 0.005594
 79659/100000: episode: 8228, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002450, mean_q: 0.004076
 79669/100000: episode: 8229, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000045, mae: 0.002878, mean_q: 0.004043
 79679/100000: episode: 8230, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000073, mae: 0.004234, mean_q: 0.005339
 79689/100000: episode: 8231, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000229, mae: 0.004191, mean_q: 0.005064
 79699/100000: episode: 8232, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000079, mae: 0.004667, mean_q: 0.005641
 79709/100000: episode: 8233, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000100, mae: 0.005083, mean_q: 0.006083
 79719/100000: episode: 8234, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000076, mae: 0.003968, mean_q: 0.004892
 79729/100000: episode: 8235, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000041, mae: 0.003117, mean_q: 0.004687
 79739/100000: episode: 8236, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000048, mae: 0.003384, mean_q: 0.004675
 79749/100000: episode: 8237, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000052, mae: 0.003629, mean_q: 0.004824
 79759/100000: episode: 8238, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000072, mae: 0.004261, mean_q: 0.005351
 79769/100000: episode: 8239, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000067, mae: 0.003812, mean_q: 0.005032
 79779/100000: episode: 8240, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000048, mae: 0.003679, mean_q: 0.004578
 79789/100000: episode: 8241, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000019, mae: 0.003344, mean_q: 0.004952
 79799/100000: episode: 8242, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000012, mae: 0.002846, mean_q: 0.004467
 79809/100000: episode: 8243, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000017, mae: 0.002588, mean_q: 0.003669
 79819/100000: episode: 8244, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000018, mae: 0.002965, mean_q: 0.004595
 79829/100000: episode: 8245, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000080, mae: 0.004222, mean_q: 0.005036
 79839/100000: episode: 8246, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000056, mae: 0.004378, mean_q: 0.005463
 79849/100000: episode: 8247, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000017, mae: 0.003185, mean_q: 0.004846
 79859/100000: episode: 8248, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000048, mae: 0.003487, mean_q: 0.004702
 79869/100000: episode: 8249, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000137, mae: 0.005437, mean_q: 0.005562
 79879/100000: episode: 8250, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.003804, mean_q: 0.005420
 79889/100000: episode: 8251, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.001618, mae: 0.007888, mean_q: 0.006268
 79899/100000: episode: 8252, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000053, mae: 0.005384, mean_q: 0.006911
 79909/100000: episode: 8253, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000013, mae: 0.002471, mean_q: 0.003932
 79919/100000: episode: 8254, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000057, mae: 0.003669, mean_q: 0.004276
 79929/100000: episode: 8255, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000039, mae: 0.004640, mean_q: 0.007140
 79939/100000: episode: 8256, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000046, mae: 0.003631, mean_q: 0.004943
 79949/100000: episode: 8257, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000056, mae: 0.003472, mean_q: 0.004206
 79959/100000: episode: 8258, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000247, mae: 0.006246, mean_q: 0.006658
 79969/100000: episode: 8259, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000019, mae: 0.003522, mean_q: 0.005489
 79979/100000: episode: 8260, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001598, mae: 0.008043, mean_q: 0.006893
 79989/100000: episode: 8261, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000020, mae: 0.004000, mean_q: 0.006308
 79999/100000: episode: 8262, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.002583, mean_q: 0.003482
 80009/100000: episode: 8263, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003190, mean_q: 0.004982
 80019/100000: episode: 8264, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000106, mae: 0.004961, mean_q: 0.005475
 80029/100000: episode: 8265, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000113, mae: 0.006103, mean_q: 0.006671
 80039/100000: episode: 8266, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000045, mae: 0.004110, mean_q: 0.005757
 80049/100000: episode: 8267, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000046, mae: 0.005125, mean_q: 0.007353
 80059/100000: episode: 8268, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000221, mae: 0.004766, mean_q: 0.006153
 80069/100000: episode: 8269, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.002739, mean_q: 0.004340
 80079/100000: episode: 8270, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000280, mae: 0.005190, mean_q: 0.005304
 80089/100000: episode: 8271, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000027, mae: 0.004443, mean_q: 0.006555
 80099/100000: episode: 8272, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000223, mae: 0.004327, mean_q: 0.005565
 80109/100000: episode: 8273, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000225, mae: 0.004086, mean_q: 0.004751
 80119/100000: episode: 8274, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001580, mae: 0.009215, mean_q: 0.008622
 80129/100000: episode: 8275, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000023, mae: 0.004312, mean_q: 0.006496
 80139/100000: episode: 8276, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000055, mae: 0.003289, mean_q: 0.003886
 80149/100000: episode: 8277, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000079, mae: 0.004448, mean_q: 0.005752
 80159/100000: episode: 8278, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003879, mean_q: 0.006070
 80169/100000: episode: 8279, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000035, mae: 0.002740, mean_q: 0.004564
 80179/100000: episode: 8280, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000021, mae: 0.002908, mean_q: 0.004606
 80189/100000: episode: 8281, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000071, mae: 0.003883, mean_q: 0.005174
 80199/100000: episode: 8282, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003827, mean_q: 0.005441
 80209/100000: episode: 8283, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000051, mae: 0.003683, mean_q: 0.005018
 80219/100000: episode: 8284, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000030, mae: 0.003408, mean_q: 0.004883
 80229/100000: episode: 8285, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000279, mae: 0.005040, mean_q: 0.005187
 80239/100000: episode: 8286, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000281, mae: 0.006783, mean_q: 0.007435
 80249/100000: episode: 8287, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001560, mae: 0.006923, mean_q: 0.006396
 80259/100000: episode: 8288, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000048, mae: 0.005010, mean_q: 0.007280
 80269/100000: episode: 8289, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000099, mae: 0.004891, mean_q: 0.005913
 80279/100000: episode: 8290, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000223, mae: 0.004487, mean_q: 0.005752
 80289/100000: episode: 8291, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.003867, mean_q: 0.006058
[Info] 1-TH LEVEL FOUND: 0.004883205983787775, Considering 100/100 traces
 80299/100000: episode: 8292, duration: 0.699s, episode steps: 10, steps per second: 14, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000052, mae: 0.003470, mean_q: 0.004719
[Info] 2-TH LEVEL FOUND: 0.00760828610509634, Considering 100/100 traces
 80309/100000: episode: 8293, duration: 0.683s, episode steps: 10, steps per second: 15, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000312, mae: 0.006425, mean_q: 0.006167
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.00760828610509634
 80319/100000: episode: 8294, duration: 0.563s, episode steps: 10, steps per second: 18, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000020, mae: 0.004157, mean_q: 0.006623
 80329/100000: episode: 8295, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000018, mae: 0.003237, mean_q: 0.005021
 80339/100000: episode: 8296, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000032, mae: 0.004025, mean_q: 0.005333
 80349/100000: episode: 8297, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000017, mae: 0.003618, mean_q: 0.005811
 80359/100000: episode: 8298, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000073, mae: 0.003885, mean_q: 0.005039
 80369/100000: episode: 8299, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000225, mae: 0.004292, mean_q: 0.005088
 80379/100000: episode: 8300, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000049, mae: 0.004346, mean_q: 0.006093
 80389/100000: episode: 8301, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000015, mae: 0.003020, mean_q: 0.005140
 80399/100000: episode: 8302, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000430, mae: 0.004972, mean_q: 0.004916
 80409/100000: episode: 8303, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000500, mae: 0.008747, mean_q: 0.008015
 80419/100000: episode: 8304, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000060, mae: 0.005506, mean_q: 0.007303
 80429/100000: episode: 8305, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000078, mae: 0.004178, mean_q: 0.005355
 80439/100000: episode: 8306, duration: 0.073s, episode steps: 10, steps per second: 136, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000043, mae: 0.003667, mean_q: 0.005537
 80449/100000: episode: 8307, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000015, mae: 0.003041, mean_q: 0.005238
 80459/100000: episode: 8308, duration: 0.070s, episode steps: 10, steps per second: 142, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000089, mae: 0.004732, mean_q: 0.005272
 80469/100000: episode: 8309, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000078, mae: 0.004994, mean_q: 0.006407
 80479/100000: episode: 8310, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000023, mae: 0.003866, mean_q: 0.005948
 80489/100000: episode: 8311, duration: 0.121s, episode steps: 10, steps per second: 83, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000245, mae: 0.003878, mean_q: 0.004583
 80499/100000: episode: 8312, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001606, mae: 0.008188, mean_q: 0.006335
 80509/100000: episode: 8313, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000051, mae: 0.006331, mean_q: 0.009117
 80519/100000: episode: 8314, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.001572, mae: 0.006418, mean_q: 0.005217
 80529/100000: episode: 8315, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000466, mae: 0.008356, mean_q: 0.008280
 80539/100000: episode: 8316, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000079, mae: 0.006085, mean_q: 0.008312
 80549/100000: episode: 8317, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000082, mae: 0.004265, mean_q: 0.004853
 80559/100000: episode: 8318, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000013, mae: 0.002620, mean_q: 0.005059
 80569/100000: episode: 8319, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002747, mean_q: 0.004854
 80579/100000: episode: 8320, duration: 0.114s, episode steps: 10, steps per second: 88, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000030, mae: 0.003390, mean_q: 0.004624
 80589/100000: episode: 8321, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000030, mae: 0.003751, mean_q: 0.005450
 80599/100000: episode: 8322, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000078, mae: 0.004244, mean_q: 0.005390
 80609/100000: episode: 8323, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000084, mae: 0.004602, mean_q: 0.005523
 80619/100000: episode: 8324, duration: 0.093s, episode steps: 10, steps per second: 107, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000060, mae: 0.004926, mean_q: 0.006416
 80629/100000: episode: 8325, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000137, mae: 0.005485, mean_q: 0.005929
 80639/100000: episode: 8326, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000465, mae: 0.006872, mean_q: 0.006636
 80649/100000: episode: 8327, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000077, mae: 0.005397, mean_q: 0.007000
 80659/100000: episode: 8328, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000038, mae: 0.003763, mean_q: 0.006277
 80669/100000: episode: 8329, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000040, mae: 0.003294, mean_q: 0.005132
 80679/100000: episode: 8330, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000082, mae: 0.004220, mean_q: 0.004912
 80689/100000: episode: 8331, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000048, mae: 0.004598, mean_q: 0.006488
 80699/100000: episode: 8332, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001599, mae: 0.007584, mean_q: 0.006385
 80709/100000: episode: 8333, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000295, mae: 0.008031, mean_q: 0.008745
 80719/100000: episode: 8334, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000089, mae: 0.006180, mean_q: 0.007782
 80729/100000: episode: 8335, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000081, mae: 0.004448, mean_q: 0.005829
 80739/100000: episode: 8336, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001624, mae: 0.008214, mean_q: 0.006813
 80749/100000: episode: 8337, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000069, mae: 0.007144, mean_q: 0.009534
 80759/100000: episode: 8338, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000040, mae: 0.003267, mean_q: 0.005086
 80769/100000: episode: 8339, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000435, mae: 0.004694, mean_q: 0.003604
 80779/100000: episode: 8340, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000045, mae: 0.004940, mean_q: 0.007678
 80789/100000: episode: 8341, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000037, mae: 0.004492, mean_q: 0.006300
 80799/100000: episode: 8342, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000017, mae: 0.002547, mean_q: 0.004778
 80809/100000: episode: 8343, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001801, mae: 0.008214, mean_q: 0.005860
 80819/100000: episode: 8344, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000049, mae: 0.007341, mean_q: 0.009954
 80829/100000: episode: 8345, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000032, mae: 0.005383, mean_q: 0.008014
 80839/100000: episode: 8346, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000091, mae: 0.004493, mean_q: 0.005040
 80849/100000: episode: 8347, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001562, mae: 0.006950, mean_q: 0.006832
 80859/100000: episode: 8348, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000026, mae: 0.004791, mean_q: 0.007552
 80869/100000: episode: 8349, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000054, mae: 0.003938, mean_q: 0.005006
 80879/100000: episode: 8350, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000014, mae: 0.002974, mean_q: 0.005690
 80889/100000: episode: 8351, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000048, mae: 0.003911, mean_q: 0.005850
 80899/100000: episode: 8352, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000078, mae: 0.004181, mean_q: 0.005491
 80909/100000: episode: 8353, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000060, mae: 0.004669, mean_q: 0.006197
 80919/100000: episode: 8354, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000016, mae: 0.003695, mean_q: 0.006221
 80929/100000: episode: 8355, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000024, mae: 0.003512, mean_q: 0.005441
 80939/100000: episode: 8356, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000021, mae: 0.003277, mean_q: 0.005579
 80949/100000: episode: 8357, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000019, mae: 0.002777, mean_q: 0.004707
 80959/100000: episode: 8358, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000024, mae: 0.003228, mean_q: 0.004984
 80969/100000: episode: 8359, duration: 0.160s, episode steps: 10, steps per second: 62, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000075, mae: 0.003911, mean_q: 0.005502
 80979/100000: episode: 8360, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.001598, mae: 0.008781, mean_q: 0.008106
 80989/100000: episode: 8361, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000027, mae: 0.005002, mean_q: 0.007460
 80999/100000: episode: 8362, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000221, mae: 0.003580, mean_q: 0.004396
 81009/100000: episode: 8363, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000237, mae: 0.005044, mean_q: 0.005746
 81019/100000: episode: 8364, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000222, mae: 0.005361, mean_q: 0.006781
 81029/100000: episode: 8365, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000062, mae: 0.004586, mean_q: 0.005764
 81039/100000: episode: 8366, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000046, mae: 0.003869, mean_q: 0.005842
 81049/100000: episode: 8367, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000262, mae: 0.005854, mean_q: 0.006492
 81059/100000: episode: 8368, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000063, mae: 0.004712, mean_q: 0.006012
 81069/100000: episode: 8369, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.001599, mae: 0.007554, mean_q: 0.006350
 81079/100000: episode: 8370, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000265, mae: 0.007172, mean_q: 0.008524
 81089/100000: episode: 8371, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000052, mae: 0.004457, mean_q: 0.006393
 81099/100000: episode: 8372, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002322, mean_q: 0.004424
 81109/100000: episode: 8373, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000051, mae: 0.003972, mean_q: 0.005428
 81119/100000: episode: 8374, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001618, mae: 0.008157, mean_q: 0.007155
 81129/100000: episode: 8375, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000023, mae: 0.004952, mean_q: 0.007692
 81139/100000: episode: 8376, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000087, mae: 0.003870, mean_q: 0.004242
 81149/100000: episode: 8377, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000076, mae: 0.004203, mean_q: 0.005731
 81159/100000: episode: 8378, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000130, mae: 0.005555, mean_q: 0.006336
 81169/100000: episode: 8379, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000226, mae: 0.007285, mean_q: 0.009538
 81179/100000: episode: 8380, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000297, mae: 0.006375, mean_q: 0.007222
 81189/100000: episode: 8381, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000456, mae: 0.005787, mean_q: 0.005786
 81199/100000: episode: 8382, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000026, mae: 0.004012, mean_q: 0.006473
 81209/100000: episode: 8383, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000045, mae: 0.003272, mean_q: 0.005276
 81219/100000: episode: 8384, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000246, mae: 0.004215, mean_q: 0.005012
 81229/100000: episode: 8385, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.004488, mean_q: 0.006526
 81239/100000: episode: 8386, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001768, mae: 0.007605, mean_q: 0.006068
 81249/100000: episode: 8387, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000028, mae: 0.004943, mean_q: 0.007509
 81259/100000: episode: 8388, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003421, mean_q: 0.005816
 81269/100000: episode: 8389, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000028, mae: 0.002973, mean_q: 0.004355
 81279/100000: episode: 8390, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000052, mae: 0.003727, mean_q: 0.005459
 81289/100000: episode: 8391, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000079, mae: 0.004592, mean_q: 0.006184
 81299/100000: episode: 8392, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000281, mae: 0.005903, mean_q: 0.006249
 81309/100000: episode: 8393, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000048, mae: 0.004316, mean_q: 0.006184
[Info] 1-TH LEVEL FOUND: 0.0069681075401604176, Considering 100/100 traces
 81319/100000: episode: 8394, duration: 0.742s, episode steps: 10, steps per second: 13, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000436, mae: 0.005890, mean_q: 0.005927
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0069681075401604176
 81329/100000: episode: 8395, duration: 0.560s, episode steps: 10, steps per second: 18, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000023, mae: 0.004228, mean_q: 0.006675
 81339/100000: episode: 8396, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000042, mae: 0.002859, mean_q: 0.004541
 81349/100000: episode: 8397, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000066, mae: 0.003146, mean_q: 0.004680
 81359/100000: episode: 8398, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000017, mae: 0.002961, mean_q: 0.005270
 81369/100000: episode: 8399, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000116, mae: 0.005028, mean_q: 0.005055
 81379/100000: episode: 8400, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000040, mae: 0.004068, mean_q: 0.006296
 81389/100000: episode: 8401, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000073, mae: 0.003741, mean_q: 0.005050
 81399/100000: episode: 8402, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000057, mae: 0.004090, mean_q: 0.005309
 81409/100000: episode: 8403, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000282, mae: 0.005732, mean_q: 0.006023
 81419/100000: episode: 8404, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000070, mae: 0.004763, mean_q: 0.006623
 81429/100000: episode: 8405, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000313, mae: 0.006360, mean_q: 0.006102
 81439/100000: episode: 8406, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000054, mae: 0.004677, mean_q: 0.006486
 81449/100000: episode: 8407, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000038, mae: 0.002964, mean_q: 0.004945
 81459/100000: episode: 8408, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000067, mae: 0.003892, mean_q: 0.005521
 81469/100000: episode: 8409, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000084, mae: 0.004799, mean_q: 0.005734
 81479/100000: episode: 8410, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000049, mae: 0.003657, mean_q: 0.005526
 81489/100000: episode: 8411, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000054, mae: 0.004089, mean_q: 0.005383
 81499/100000: episode: 8412, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000006, mae: 0.002436, mean_q: 0.005142
 81509/100000: episode: 8413, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000046, mae: 0.002997, mean_q: 0.004118
 81519/100000: episode: 8414, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000052, mae: 0.003716, mean_q: 0.005238
 81529/100000: episode: 8415, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000256, mae: 0.005147, mean_q: 0.005552
 81539/100000: episode: 8416, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.003714, mean_q: 0.006090
 81549/100000: episode: 8417, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000284, mae: 0.005758, mean_q: 0.005915
 81559/100000: episode: 8418, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000032, mae: 0.004261, mean_q: 0.005973
 81569/100000: episode: 8419, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000082, mae: 0.004308, mean_q: 0.005436
 81579/100000: episode: 8420, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000046, mae: 0.003614, mean_q: 0.005194
 81589/100000: episode: 8421, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001569, mae: 0.007514, mean_q: 0.006715
 81599/100000: episode: 8422, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000458, mae: 0.007786, mean_q: 0.008096
 81609/100000: episode: 8423, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000082, mae: 0.004531, mean_q: 0.005717
 81619/100000: episode: 8424, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002631, mean_q: 0.004711
 81629/100000: episode: 8425, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000031, mae: 0.003345, mean_q: 0.004832
 81639/100000: episode: 8426, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000110, mae: 0.005498, mean_q: 0.006003
 81649/100000: episode: 8427, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000056, mae: 0.004511, mean_q: 0.006007
 81659/100000: episode: 8428, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000427, mae: 0.004927, mean_q: 0.004927
 81669/100000: episode: 8429, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000057, mae: 0.004967, mean_q: 0.006415
 81679/100000: episode: 8430, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003357, mean_q: 0.005419
 81689/100000: episode: 8431, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003095, mean_q: 0.004519
 81699/100000: episode: 8432, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000059, mae: 0.004106, mean_q: 0.005308
 81709/100000: episode: 8433, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003411, mean_q: 0.005675
 81719/100000: episode: 8434, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003216, mean_q: 0.004662
 81729/100000: episode: 8435, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000029, mae: 0.003294, mean_q: 0.004663
 81739/100000: episode: 8436, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000084, mae: 0.004558, mean_q: 0.005271
 81749/100000: episode: 8437, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000053, mae: 0.004124, mean_q: 0.005569
 81759/100000: episode: 8438, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000014, mae: 0.002843, mean_q: 0.004966
 81769/100000: episode: 8439, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000266, mae: 0.004845, mean_q: 0.004553
 81779/100000: episode: 8440, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000023, mae: 0.004425, mean_q: 0.006746
 81789/100000: episode: 8441, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000013, mae: 0.002794, mean_q: 0.004863
 81799/100000: episode: 8442, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002429, mean_q: 0.003588
 81809/100000: episode: 8443, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000039, mae: 0.003136, mean_q: 0.004758
 81819/100000: episode: 8444, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000069, mae: 0.003772, mean_q: 0.004857
 81829/100000: episode: 8445, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000176, mae: 0.006646, mean_q: 0.006192
 81839/100000: episode: 8446, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000286, mae: 0.007330, mean_q: 0.007737
 81849/100000: episode: 8447, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000287, mae: 0.006455, mean_q: 0.006816
 81859/100000: episode: 8448, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001593, mae: 0.008755, mean_q: 0.008225
 81869/100000: episode: 8449, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000082, mae: 0.005616, mean_q: 0.007105
 81879/100000: episode: 8450, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000047, mae: 0.003584, mean_q: 0.005123
 81889/100000: episode: 8451, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000220, mae: 0.003531, mean_q: 0.004600
 81899/100000: episode: 8452, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000223, mae: 0.003942, mean_q: 0.005132
 81909/100000: episode: 8453, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000053, mae: 0.004432, mean_q: 0.006151
 81919/100000: episode: 8454, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000019, mae: 0.003211, mean_q: 0.005434
 81929/100000: episode: 8455, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000016, mae: 0.002516, mean_q: 0.004361
 81939/100000: episode: 8456, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.001864, mae: 0.010091, mean_q: 0.006666
 81949/100000: episode: 8457, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000091, mae: 0.007492, mean_q: 0.009558
 81959/100000: episode: 8458, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000048, mae: 0.004437, mean_q: 0.006469
 81969/100000: episode: 8459, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.002958, mean_q: 0.005281
 81979/100000: episode: 8460, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000008, mae: 0.001873, mean_q: 0.004249
 81989/100000: episode: 8461, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000292, mae: 0.005220, mean_q: 0.005111
 81999/100000: episode: 8462, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000030, mae: 0.004539, mean_q: 0.006668
 82009/100000: episode: 8463, duration: 0.098s, episode steps: 10, steps per second: 102, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.003173, mean_q: 0.004972
 82019/100000: episode: 8464, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000076, mae: 0.003500, mean_q: 0.004488
 82029/100000: episode: 8465, duration: 0.131s, episode steps: 10, steps per second: 76, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000019, mae: 0.003101, mean_q: 0.005120
 82039/100000: episode: 8466, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001564, mae: 0.006188, mean_q: 0.005256
 82049/100000: episode: 8467, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000025, mae: 0.004969, mean_q: 0.007421
 82059/100000: episode: 8468, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000320, mae: 0.006047, mean_q: 0.005474
 82069/100000: episode: 8469, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000262, mae: 0.008347, mean_q: 0.009915
 82079/100000: episode: 8470, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.005335, mean_q: 0.007969
 82089/100000: episode: 8471, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000222, mae: 0.003354, mean_q: 0.004345
 82099/100000: episode: 8472, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000048, mae: 0.003751, mean_q: 0.005805
 82109/100000: episode: 8473, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000011, mae: 0.003061, mean_q: 0.005759
 82119/100000: episode: 8474, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000222, mae: 0.003635, mean_q: 0.004466
 82129/100000: episode: 8475, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003465, mean_q: 0.005518
 82139/100000: episode: 8476, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000258, mae: 0.005143, mean_q: 0.005590
 82149/100000: episode: 8477, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000076, mae: 0.004619, mean_q: 0.006158
 82159/100000: episode: 8478, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000070, mae: 0.003959, mean_q: 0.005666
 82169/100000: episode: 8479, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000018, mae: 0.003192, mean_q: 0.005402
 82179/100000: episode: 8480, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000064, mae: 0.004201, mean_q: 0.005079
 82189/100000: episode: 8481, duration: 0.060s, episode steps: 10, steps per second: 166, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000035, mae: 0.003752, mean_q: 0.006293
 82199/100000: episode: 8482, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000047, mae: 0.003614, mean_q: 0.005034
 82209/100000: episode: 8483, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000015, mae: 0.002663, mean_q: 0.004613
 82219/100000: episode: 8484, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000050, mae: 0.003693, mean_q: 0.005178
 82229/100000: episode: 8485, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000025, mae: 0.003588, mean_q: 0.005449
 82239/100000: episode: 8486, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000042, mae: 0.003035, mean_q: 0.004423
 82249/100000: episode: 8487, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000006, mae: 0.002208, mean_q: 0.004361
 82259/100000: episode: 8488, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000042, mae: 0.003065, mean_q: 0.004461
 82269/100000: episode: 8489, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000036, mae: 0.004310, mean_q: 0.005692
 82279/100000: episode: 8490, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000061, mae: 0.004278, mean_q: 0.005193
 82289/100000: episode: 8491, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000044, mae: 0.003599, mean_q: 0.005048
 82299/100000: episode: 8492, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000080, mae: 0.004408, mean_q: 0.005314
 82309/100000: episode: 8493, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000011, mae: 0.002939, mean_q: 0.005078
 82319/100000: episode: 8494, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000038, mae: 0.002988, mean_q: 0.004163
[Info] 1-TH LEVEL FOUND: 0.007131236605346203, Considering 100/100 traces
 82329/100000: episode: 8495, duration: 0.742s, episode steps: 10, steps per second: 13, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000281, mae: 0.005605, mean_q: 0.005364
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.007131236605346203
 82339/100000: episode: 8496, duration: 0.527s, episode steps: 10, steps per second: 19, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000043, mae: 0.004458, mean_q: 0.006640
 82349/100000: episode: 8497, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000041, mae: 0.003069, mean_q: 0.004450
 82359/100000: episode: 8498, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000019, mae: 0.002912, mean_q: 0.004180
 82369/100000: episode: 8499, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000070, mae: 0.003863, mean_q: 0.004937
 82379/100000: episode: 8500, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001601, mae: 0.007455, mean_q: 0.005658
 82389/100000: episode: 8501, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000225, mae: 0.006524, mean_q: 0.008413
 82399/100000: episode: 8502, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000053, mae: 0.004318, mean_q: 0.005907
 82409/100000: episode: 8503, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.004612, mean_q: 0.006319
 82419/100000: episode: 8504, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003978, mean_q: 0.006481
 82429/100000: episode: 8505, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000254, mae: 0.004362, mean_q: 0.004501
 82439/100000: episode: 8506, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000256, mae: 0.005265, mean_q: 0.006069
 82449/100000: episode: 8507, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000222, mae: 0.005772, mean_q: 0.007393
 82459/100000: episode: 8508, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000225, mae: 0.004563, mean_q: 0.005694
 82469/100000: episode: 8509, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000050, mae: 0.003956, mean_q: 0.005472
 82479/100000: episode: 8510, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000024, mae: 0.002931, mean_q: 0.004704
 82489/100000: episode: 8511, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000043, mae: 0.002864, mean_q: 0.004631
 82499/100000: episode: 8512, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000047, mae: 0.003339, mean_q: 0.004907
 82509/100000: episode: 8513, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000290, mae: 0.006151, mean_q: 0.006043
 82519/100000: episode: 8514, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000231, mae: 0.005386, mean_q: 0.006533
 82529/100000: episode: 8515, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000075, mae: 0.004462, mean_q: 0.005734
 82539/100000: episode: 8516, duration: 0.091s, episode steps: 10, steps per second: 109, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000142, mae: 0.005732, mean_q: 0.005880
 82549/100000: episode: 8517, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000042, mae: 0.004261, mean_q: 0.006265
 82559/100000: episode: 8518, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000052, mae: 0.004113, mean_q: 0.005516
 82569/100000: episode: 8519, duration: 0.075s, episode steps: 10, steps per second: 134, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000265, mae: 0.005265, mean_q: 0.005436
 82579/100000: episode: 8520, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000014, mae: 0.004044, mean_q: 0.006865
 82589/100000: episode: 8521, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000072, mae: 0.003744, mean_q: 0.004943
 82599/100000: episode: 8522, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000070, mae: 0.003565, mean_q: 0.004555
 82609/100000: episode: 8523, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.003344, mean_q: 0.005332
 82619/100000: episode: 8524, duration: 0.075s, episode steps: 10, steps per second: 133, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000024, mae: 0.003263, mean_q: 0.005108
 82629/100000: episode: 8525, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000024, mae: 0.003076, mean_q: 0.004611
 82639/100000: episode: 8526, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000015, mae: 0.002973, mean_q: 0.004927
 82649/100000: episode: 8527, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000252, mae: 0.005405, mean_q: 0.005168
 82659/100000: episode: 8528, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000270, mae: 0.006669, mean_q: 0.006606
 82669/100000: episode: 8529, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000442, mae: 0.006888, mean_q: 0.006929
 82679/100000: episode: 8530, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000031, mae: 0.004938, mean_q: 0.007122
 82689/100000: episode: 8531, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000024, mae: 0.003749, mean_q: 0.005414
 82699/100000: episode: 8532, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002308, mean_q: 0.004140
 82709/100000: episode: 8533, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000046, mae: 0.002955, mean_q: 0.004291
 82719/100000: episode: 8534, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000046, mae: 0.003831, mean_q: 0.005563
 82729/100000: episode: 8535, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000019, mae: 0.002635, mean_q: 0.004478
 82739/100000: episode: 8536, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000045, mae: 0.003266, mean_q: 0.004793
 82749/100000: episode: 8537, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000045, mae: 0.004095, mean_q: 0.005625
 82759/100000: episode: 8538, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000025, mae: 0.003586, mean_q: 0.005371
 82769/100000: episode: 8539, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000113, mae: 0.004901, mean_q: 0.005031
 82779/100000: episode: 8540, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000091, mae: 0.006337, mean_q: 0.007674
 82789/100000: episode: 8541, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000044, mae: 0.003193, mean_q: 0.005128
 82799/100000: episode: 8542, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000072, mae: 0.003131, mean_q: 0.003864
 82809/100000: episode: 8543, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000042, mae: 0.003626, mean_q: 0.005344
 82819/100000: episode: 8544, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000332, mae: 0.005997, mean_q: 0.005142
 82829/100000: episode: 8545, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000021, mae: 0.004540, mean_q: 0.006823
 82839/100000: episode: 8546, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000045, mae: 0.003431, mean_q: 0.005006
 82849/100000: episode: 8547, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000273, mae: 0.006270, mean_q: 0.006228
 82859/100000: episode: 8548, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000019, mae: 0.003691, mean_q: 0.005996
 82869/100000: episode: 8549, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000050, mae: 0.003224, mean_q: 0.004139
 82879/100000: episode: 8550, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003320, mean_q: 0.004909
 82889/100000: episode: 8551, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000053, mae: 0.003822, mean_q: 0.005223
 82899/100000: episode: 8552, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000231, mae: 0.004878, mean_q: 0.005456
 82909/100000: episode: 8553, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000048, mae: 0.003974, mean_q: 0.005313
 82919/100000: episode: 8554, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003280, mean_q: 0.004852
 82929/100000: episode: 8555, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.002691, mean_q: 0.004131
 82939/100000: episode: 8556, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000012, mae: 0.002252, mean_q: 0.004134
 82949/100000: episode: 8557, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000257, mae: 0.004938, mean_q: 0.005007
 82959/100000: episode: 8558, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000023, mae: 0.004225, mean_q: 0.006283
 82969/100000: episode: 8559, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.002597, mean_q: 0.004149
 82979/100000: episode: 8560, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000038, mae: 0.002631, mean_q: 0.003844
 82989/100000: episode: 8561, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000100, mae: 0.004499, mean_q: 0.005392
 82999/100000: episode: 8562, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000053, mae: 0.004527, mean_q: 0.006002
 83009/100000: episode: 8563, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000011, mae: 0.002737, mean_q: 0.004536
 83019/100000: episode: 8564, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000050, mae: 0.003164, mean_q: 0.003880
 83029/100000: episode: 8565, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000231, mae: 0.004984, mean_q: 0.005568
 83039/100000: episode: 8566, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000054, mae: 0.004933, mean_q: 0.006427
 83049/100000: episode: 8567, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000043, mae: 0.003220, mean_q: 0.004487
 83059/100000: episode: 8568, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.002989, mean_q: 0.004025
 83069/100000: episode: 8569, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000026, mae: 0.003667, mean_q: 0.005065
 83079/100000: episode: 8570, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000021, mae: 0.003419, mean_q: 0.004773
 83089/100000: episode: 8571, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000016, mae: 0.002855, mean_q: 0.004327
 83099/100000: episode: 8572, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000061, mae: 0.004379, mean_q: 0.004871
 83109/100000: episode: 8573, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000050, mae: 0.003957, mean_q: 0.005135
 83119/100000: episode: 8574, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000023, mae: 0.003133, mean_q: 0.004685
 83129/100000: episode: 8575, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000019, mae: 0.003760, mean_q: 0.005628
 83139/100000: episode: 8576, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.004103, mean_q: 0.005397
 83149/100000: episode: 8577, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000020, mae: 0.002770, mean_q: 0.004484
 83159/100000: episode: 8578, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000233, mae: 0.004939, mean_q: 0.005272
 83169/100000: episode: 8579, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000260, mae: 0.006456, mean_q: 0.006873
 83179/100000: episode: 8580, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003854, mean_q: 0.005258
 83189/100000: episode: 8581, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000045, mae: 0.002852, mean_q: 0.003943
 83199/100000: episode: 8582, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003026, mean_q: 0.004556
 83209/100000: episode: 8583, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000081, mae: 0.004567, mean_q: 0.005197
 83219/100000: episode: 8584, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000258, mae: 0.005741, mean_q: 0.006088
 83229/100000: episode: 8585, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000033, mae: 0.004608, mean_q: 0.006095
 83239/100000: episode: 8586, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000254, mae: 0.004618, mean_q: 0.004731
 83249/100000: episode: 8587, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000020, mae: 0.004308, mean_q: 0.006582
 83259/100000: episode: 8588, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000021, mae: 0.003058, mean_q: 0.004689
 83269/100000: episode: 8589, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000068, mae: 0.003214, mean_q: 0.003864
 83279/100000: episode: 8590, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000074, mae: 0.004522, mean_q: 0.005559
 83289/100000: episode: 8591, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000021, mae: 0.003130, mean_q: 0.004874
 83299/100000: episode: 8592, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003187, mean_q: 0.004249
 83309/100000: episode: 8593, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.003090, mean_q: 0.004921
 83319/100000: episode: 8594, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000279, mae: 0.004970, mean_q: 0.004606
 83329/100000: episode: 8595, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000238, mae: 0.006409, mean_q: 0.007293
[Info] 1-TH LEVEL FOUND: 0.004282102920114994, Considering 100/100 traces
 83339/100000: episode: 8596, duration: 0.778s, episode steps: 10, steps per second: 13, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000049, mae: 0.003965, mean_q: 0.005147
[Info] 2-TH LEVEL FOUND: 0.00438645901158452, Considering 100/100 traces
 83349/100000: episode: 8597, duration: 0.693s, episode steps: 10, steps per second: 14, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000013, mae: 0.002728, mean_q: 0.004292
[Info] 3-TH LEVEL FOUND: 0.00608961284160614, Considering 100/100 traces
 83359/100000: episode: 8598, duration: 0.709s, episode steps: 10, steps per second: 14, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000057, mae: 0.004152, mean_q: 0.005305
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.00608961284160614
 83369/100000: episode: 8599, duration: 0.520s, episode steps: 10, steps per second: 19, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000052, mae: 0.004389, mean_q: 0.005954
 83379/100000: episode: 8600, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000028, mae: 0.003393, mean_q: 0.004784
 83389/100000: episode: 8601, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000046, mae: 0.003273, mean_q: 0.004620
 83399/100000: episode: 8602, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003282, mean_q: 0.005048
 83409/100000: episode: 8603, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000049, mae: 0.003308, mean_q: 0.004225
 83419/100000: episode: 8604, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000077, mae: 0.004120, mean_q: 0.004877
 83429/100000: episode: 8605, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.004006, mean_q: 0.005745
 83439/100000: episode: 8606, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.002927, mean_q: 0.004445
 83449/100000: episode: 8607, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000027, mae: 0.002951, mean_q: 0.004019
 83459/100000: episode: 8608, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000018, mae: 0.003182, mean_q: 0.004757
 83469/100000: episode: 8609, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000016, mae: 0.002619, mean_q: 0.004032
 83479/100000: episode: 8610, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000024, mae: 0.003124, mean_q: 0.004324
 83489/100000: episode: 8611, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000038, mae: 0.003002, mean_q: 0.004801
 83499/100000: episode: 8612, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000007, mae: 0.002176, mean_q: 0.003939
 83509/100000: episode: 8613, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.003160, mean_q: 0.003913
 83519/100000: episode: 8614, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000010, mae: 0.002808, mean_q: 0.004808
 83529/100000: episode: 8615, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000075, mae: 0.003483, mean_q: 0.003588
 83539/100000: episode: 8616, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000012, mae: 0.003161, mean_q: 0.004966
 83549/100000: episode: 8617, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000011, mae: 0.002633, mean_q: 0.004076
 83559/100000: episode: 8618, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000018, mae: 0.002739, mean_q: 0.003870
 83569/100000: episode: 8619, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000044, mae: 0.003729, mean_q: 0.004863
 83579/100000: episode: 8620, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000046, mae: 0.003362, mean_q: 0.004479
 83589/100000: episode: 8621, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000071, mae: 0.003544, mean_q: 0.004381
 83599/100000: episode: 8622, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000042, mae: 0.003451, mean_q: 0.004942
 83609/100000: episode: 8623, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003153, mean_q: 0.004363
 83619/100000: episode: 8624, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000014, mae: 0.002645, mean_q: 0.004141
 83629/100000: episode: 8625, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000012, mae: 0.002614, mean_q: 0.004009
 83639/100000: episode: 8626, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000224, mae: 0.004148, mean_q: 0.004661
 83649/100000: episode: 8627, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000037, mae: 0.003332, mean_q: 0.005123
 83659/100000: episode: 8628, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000043, mae: 0.002971, mean_q: 0.003714
 83669/100000: episode: 8629, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003456, mean_q: 0.004382
 83679/100000: episode: 8630, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000010, mae: 0.002746, mean_q: 0.004606
 83689/100000: episode: 8631, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000020, mae: 0.002791, mean_q: 0.003619
 83699/100000: episode: 8632, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000096, mae: 0.003974, mean_q: 0.004157
 83709/100000: episode: 8633, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000043, mae: 0.004230, mean_q: 0.005942
 83719/100000: episode: 8634, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000070, mae: 0.003721, mean_q: 0.004707
 83729/100000: episode: 8635, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000035, mae: 0.002750, mean_q: 0.003998
 83739/100000: episode: 8636, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000261, mae: 0.004861, mean_q: 0.004525
 83749/100000: episode: 8637, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000221, mae: 0.005194, mean_q: 0.006249
 83759/100000: episode: 8638, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.003229, mean_q: 0.004186
 83769/100000: episode: 8639, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000047, mae: 0.003413, mean_q: 0.004222
 83779/100000: episode: 8640, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000022, mae: 0.003658, mean_q: 0.005274
 83789/100000: episode: 8641, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000050, mae: 0.003570, mean_q: 0.004176
 83799/100000: episode: 8642, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000008, mae: 0.002524, mean_q: 0.004282
 83809/100000: episode: 8643, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002354, mean_q: 0.003917
 83819/100000: episode: 8644, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000053, mae: 0.003517, mean_q: 0.004242
 83829/100000: episode: 8645, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000225, mae: 0.005295, mean_q: 0.006081
 83839/100000: episode: 8646, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000079, mae: 0.005162, mean_q: 0.005897
 83849/100000: episode: 8647, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000099, mae: 0.004289, mean_q: 0.004745
 83859/100000: episode: 8648, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.003548, mean_q: 0.005400
 83869/100000: episode: 8649, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000074, mae: 0.003751, mean_q: 0.004301
 83879/100000: episode: 8650, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000040, mae: 0.003398, mean_q: 0.004710
 83889/100000: episode: 8651, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000235, mae: 0.005285, mean_q: 0.005512
 83899/100000: episode: 8652, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000009, mae: 0.003489, mean_q: 0.005885
 83909/100000: episode: 8653, duration: 0.072s, episode steps: 10, steps per second: 140, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000022, mae: 0.002623, mean_q: 0.003660
 83919/100000: episode: 8654, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000081, mae: 0.004411, mean_q: 0.004900
 83929/100000: episode: 8655, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.004051, mean_q: 0.005761
 83939/100000: episode: 8656, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000018, mae: 0.002862, mean_q: 0.004191
 83949/100000: episode: 8657, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000009, mae: 0.002315, mean_q: 0.003963
 83959/100000: episode: 8658, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000048, mae: 0.003091, mean_q: 0.003915
 83969/100000: episode: 8659, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000027, mae: 0.004084, mean_q: 0.005562
 83979/100000: episode: 8660, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000017, mae: 0.003003, mean_q: 0.004772
 83989/100000: episode: 8661, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003020, mean_q: 0.003974
 83999/100000: episode: 8662, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000038, mae: 0.003162, mean_q: 0.004867
 84009/100000: episode: 8663, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.002821, mean_q: 0.004191
 84019/100000: episode: 8664, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000038, mae: 0.002898, mean_q: 0.004066
 84029/100000: episode: 8665, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000017, mae: 0.003065, mean_q: 0.004279
 84039/100000: episode: 8666, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000038, mae: 0.003954, mean_q: 0.004763
 84049/100000: episode: 8667, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.004189, mean_q: 0.005453
 84059/100000: episode: 8668, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000031, mae: 0.003552, mean_q: 0.004703
 84069/100000: episode: 8669, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000044, mae: 0.003294, mean_q: 0.004290
 84079/100000: episode: 8670, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000070, mae: 0.003818, mean_q: 0.004732
 84089/100000: episode: 8671, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000035, mae: 0.004099, mean_q: 0.005243
 84099/100000: episode: 8672, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000010, mae: 0.002460, mean_q: 0.004177
 84109/100000: episode: 8673, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000023, mae: 0.003019, mean_q: 0.003977
 84119/100000: episode: 8674, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.003041, mean_q: 0.004796
 84129/100000: episode: 8675, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.003122, mean_q: 0.004504
 84139/100000: episode: 8676, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000023, mae: 0.003053, mean_q: 0.003847
 84149/100000: episode: 8677, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000038, mae: 0.004345, mean_q: 0.005346
 84159/100000: episode: 8678, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000071, mae: 0.004141, mean_q: 0.005095
 84169/100000: episode: 8679, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000038, mae: 0.002954, mean_q: 0.004269
 84179/100000: episode: 8680, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000010, mae: 0.002493, mean_q: 0.004174
 84189/100000: episode: 8681, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000008, mae: 0.001882, mean_q: 0.003378
 84199/100000: episode: 8682, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000043, mae: 0.003010, mean_q: 0.003732
 84209/100000: episode: 8683, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.003623, mean_q: 0.004799
 84219/100000: episode: 8684, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000011, mae: 0.002532, mean_q: 0.003983
 84229/100000: episode: 8685, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000038, mae: 0.002876, mean_q: 0.004017
 84239/100000: episode: 8686, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000054, mae: 0.003788, mean_q: 0.004208
 84249/100000: episode: 8687, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000066, mae: 0.004861, mean_q: 0.005524
 84259/100000: episode: 8688, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000050, mae: 0.003922, mean_q: 0.004795
 84269/100000: episode: 8689, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000024, mae: 0.003074, mean_q: 0.004364
 84279/100000: episode: 8690, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000053, mae: 0.003881, mean_q: 0.004441
 84289/100000: episode: 8691, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000053, mae: 0.004077, mean_q: 0.004997
 84299/100000: episode: 8692, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000018, mae: 0.003141, mean_q: 0.004770
 84309/100000: episode: 8693, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000012, mae: 0.002486, mean_q: 0.003558
 84319/100000: episode: 8694, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002633, mean_q: 0.004035
 84329/100000: episode: 8695, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000065, mae: 0.003184, mean_q: 0.004012
 84339/100000: episode: 8696, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000007, mae: 0.002648, mean_q: 0.004436
 84349/100000: episode: 8697, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000010, mae: 0.002075, mean_q: 0.003344
 84359/100000: episode: 8698, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000018, mae: 0.002880, mean_q: 0.003869
[Info] 1-TH LEVEL FOUND: 0.003966533578932285, Considering 100/100 traces
 84369/100000: episode: 8699, duration: 0.766s, episode steps: 10, steps per second: 13, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000047, mae: 0.003367, mean_q: 0.004467
[Info] 2-TH LEVEL FOUND: 0.004741220735013485, Considering 100/100 traces
 84379/100000: episode: 8700, duration: 0.727s, episode steps: 10, steps per second: 14, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000045, mae: 0.003183, mean_q: 0.004085
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004741220735013485
 84389/100000: episode: 8701, duration: 0.505s, episode steps: 10, steps per second: 20, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000020, mae: 0.002919, mean_q: 0.004270
 84399/100000: episode: 8702, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000010, mae: 0.002344, mean_q: 0.003824
 84409/100000: episode: 8703, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000034, mae: 0.003799, mean_q: 0.004368
 84419/100000: episode: 8704, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000024, mae: 0.004082, mean_q: 0.005399
 84429/100000: episode: 8705, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000047, mae: 0.003224, mean_q: 0.003895
 84439/100000: episode: 8706, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.003318, mean_q: 0.004867
 84449/100000: episode: 8707, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000014, mae: 0.002702, mean_q: 0.004072
 84459/100000: episode: 8708, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003514, mean_q: 0.004606
 84469/100000: episode: 8709, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000047, mae: 0.003543, mean_q: 0.004432
 84479/100000: episode: 8710, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000022, mae: 0.003213, mean_q: 0.004355
 84489/100000: episode: 8711, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000038, mae: 0.002670, mean_q: 0.003784
 84499/100000: episode: 8712, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000009, mae: 0.002586, mean_q: 0.004268
 84509/100000: episode: 8713, duration: 0.136s, episode steps: 10, steps per second: 73, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000050, mae: 0.003380, mean_q: 0.003699
 84519/100000: episode: 8714, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000050, mae: 0.004411, mean_q: 0.005409
 84529/100000: episode: 8715, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000035, mae: 0.003119, mean_q: 0.004719
 84539/100000: episode: 8716, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000016, mae: 0.002224, mean_q: 0.003270
 84549/100000: episode: 8717, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000046, mae: 0.003614, mean_q: 0.004688
 84559/100000: episode: 8718, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000022, mae: 0.002809, mean_q: 0.004087
 84569/100000: episode: 8719, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000038, mae: 0.002848, mean_q: 0.003902
 84579/100000: episode: 8720, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002890, mean_q: 0.004280
 84589/100000: episode: 8721, duration: 0.122s, episode steps: 10, steps per second: 82, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000038, mae: 0.003020, mean_q: 0.004133
 84599/100000: episode: 8722, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000109, mae: 0.005271, mean_q: 0.005099
 84609/100000: episode: 8723, duration: 0.091s, episode steps: 10, steps per second: 110, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000049, mae: 0.004145, mean_q: 0.005367
 84619/100000: episode: 8724, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000010, mae: 0.002338, mean_q: 0.003893
 84629/100000: episode: 8725, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000037, mae: 0.002624, mean_q: 0.003755
 84639/100000: episode: 8726, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003216, mean_q: 0.003879
 84649/100000: episode: 8727, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000015, mae: 0.003386, mean_q: 0.005033
 84659/100000: episode: 8728, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000013, mae: 0.002676, mean_q: 0.003779
 84669/100000: episode: 8729, duration: 0.066s, episode steps: 10, steps per second: 150, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000039, mae: 0.002842, mean_q: 0.003543
 84679/100000: episode: 8730, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000021, mae: 0.003410, mean_q: 0.004922
 84689/100000: episode: 8731, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003477, mean_q: 0.004362
 84699/100000: episode: 8732, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000012, mae: 0.002666, mean_q: 0.004019
 84709/100000: episode: 8733, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000027, mae: 0.003459, mean_q: 0.004225
 84719/100000: episode: 8734, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000077, mae: 0.004626, mean_q: 0.005237
 84729/100000: episode: 8735, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000049, mae: 0.003341, mean_q: 0.004210
 84739/100000: episode: 8736, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.003822, mean_q: 0.004783
 84749/100000: episode: 8737, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000021, mae: 0.003223, mean_q: 0.004627
 84759/100000: episode: 8738, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000014, mae: 0.002512, mean_q: 0.003683
 84769/100000: episode: 8739, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000095, mae: 0.004365, mean_q: 0.004927
 84779/100000: episode: 8740, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000007, mae: 0.002588, mean_q: 0.004138
 84789/100000: episode: 8741, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000085, mae: 0.004090, mean_q: 0.003762
 84799/100000: episode: 8742, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.067, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000012, mae: 0.003091, mean_q: 0.005223
 84809/100000: episode: 8743, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000008, mae: 0.002042, mean_q: 0.002909
 84819/100000: episode: 8744, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000008, mae: 0.002408, mean_q: 0.003996
 84829/100000: episode: 8745, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000017, mae: 0.002914, mean_q: 0.004179
 84839/100000: episode: 8746, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000043, mae: 0.003012, mean_q: 0.003746
 84849/100000: episode: 8747, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.004413, mean_q: 0.005607
 84859/100000: episode: 8748, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.003164, mean_q: 0.004519
 84869/100000: episode: 8749, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000034, mae: 0.002181, mean_q: 0.003054
 84879/100000: episode: 8750, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000019, mae: 0.003067, mean_q: 0.004300
 84889/100000: episode: 8751, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000072, mae: 0.004411, mean_q: 0.005316
 84899/100000: episode: 8752, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000008, mae: 0.001991, mean_q: 0.003774
 84909/100000: episode: 8753, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000019, mae: 0.002525, mean_q: 0.003268
 84919/100000: episode: 8754, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.003222, mean_q: 0.004767
 84929/100000: episode: 8755, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000044, mae: 0.002816, mean_q: 0.003604
 84939/100000: episode: 8756, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000053, mae: 0.004599, mean_q: 0.005288
 84949/100000: episode: 8757, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002344, mean_q: 0.003677
 84959/100000: episode: 8758, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000052, mae: 0.003503, mean_q: 0.004032
 84969/100000: episode: 8759, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000015, mae: 0.002986, mean_q: 0.004428
 84979/100000: episode: 8760, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000016, mae: 0.002710, mean_q: 0.003635
 84989/100000: episode: 8761, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000011, mae: 0.002938, mean_q: 0.004641
 84999/100000: episode: 8762, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000047, mae: 0.003160, mean_q: 0.003478
 85009/100000: episode: 8763, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000044, mae: 0.003529, mean_q: 0.004691
 85019/100000: episode: 8764, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000013, mae: 0.002469, mean_q: 0.003762
 85029/100000: episode: 8765, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000044, mae: 0.002901, mean_q: 0.003745
 85039/100000: episode: 8766, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000047, mae: 0.004108, mean_q: 0.005152
 85049/100000: episode: 8767, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000044, mae: 0.003403, mean_q: 0.004070
 85059/100000: episode: 8768, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000005, mae: 0.002013, mean_q: 0.003925
 85069/100000: episode: 8769, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000011, mae: 0.002288, mean_q: 0.003320
 85079/100000: episode: 8770, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000069, mae: 0.003865, mean_q: 0.004206
 85089/100000: episode: 8771, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000010, mae: 0.003553, mean_q: 0.005453
 85099/100000: episode: 8772, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000049, mae: 0.003138, mean_q: 0.003121
 85109/100000: episode: 8773, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000013, mae: 0.003533, mean_q: 0.005269
 85119/100000: episode: 8774, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000011, mae: 0.002070, mean_q: 0.002973
 85129/100000: episode: 8775, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000039, mae: 0.003062, mean_q: 0.003969
 85139/100000: episode: 8776, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000071, mae: 0.004180, mean_q: 0.004967
 85149/100000: episode: 8777, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000046, mae: 0.003551, mean_q: 0.004440
 85159/100000: episode: 8778, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000009, mae: 0.002131, mean_q: 0.003593
 85169/100000: episode: 8779, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000021, mae: 0.002709, mean_q: 0.003388
 85179/100000: episode: 8780, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000044, mae: 0.004170, mean_q: 0.005299
 85189/100000: episode: 8781, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000013, mae: 0.002601, mean_q: 0.003635
 85199/100000: episode: 8782, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000047, mae: 0.003430, mean_q: 0.003986
 85209/100000: episode: 8783, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000039, mae: 0.003492, mean_q: 0.004871
 85219/100000: episode: 8784, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000073, mae: 0.003462, mean_q: 0.003657
 85229/100000: episode: 8785, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000017, mae: 0.003794, mean_q: 0.005311
 85239/100000: episode: 8786, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000020, mae: 0.002375, mean_q: 0.002632
 85249/100000: episode: 8787, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000074, mae: 0.004851, mean_q: 0.005759
 85259/100000: episode: 8788, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003960, mean_q: 0.004900
 85269/100000: episode: 8789, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000101, mae: 0.005192, mean_q: 0.005823
 85279/100000: episode: 8790, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000024, mae: 0.003140, mean_q: 0.004359
 85289/100000: episode: 8791, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003211, mean_q: 0.003958
 85299/100000: episode: 8792, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000094, mae: 0.004280, mean_q: 0.004908
 85309/100000: episode: 8793, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000014, mae: 0.002993, mean_q: 0.004659
 85319/100000: episode: 8794, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000005, mae: 0.002000, mean_q: 0.003609
 85329/100000: episode: 8795, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000025, mae: 0.003044, mean_q: 0.004039
 85339/100000: episode: 8796, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000040, mae: 0.003880, mean_q: 0.005388
 85349/100000: episode: 8797, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.004185, mean_q: 0.005250
 85359/100000: episode: 8798, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000043, mae: 0.003109, mean_q: 0.004082
 85369/100000: episode: 8799, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000021, mae: 0.003248, mean_q: 0.004693
 85379/100000: episode: 8800, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000041, mae: 0.003308, mean_q: 0.004734
[Info] 1-TH LEVEL FOUND: 0.005054313689470291, Considering 100/100 traces
 85389/100000: episode: 8801, duration: 0.664s, episode steps: 10, steps per second: 15, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003236, mean_q: 0.003834
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005054313689470291
 85399/100000: episode: 8802, duration: 0.487s, episode steps: 10, steps per second: 21, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000016, mae: 0.003117, mean_q: 0.004892
 85409/100000: episode: 8803, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000073, mae: 0.003682, mean_q: 0.004231
 85419/100000: episode: 8804, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000028, mae: 0.003510, mean_q: 0.004673
 85429/100000: episode: 8805, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.002853, mean_q: 0.004045
 85439/100000: episode: 8806, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000007, mae: 0.001885, mean_q: 0.003554
 85449/100000: episode: 8807, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000018, mae: 0.002667, mean_q: 0.003687
 85459/100000: episode: 8808, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000043, mae: 0.003667, mean_q: 0.004861
 85469/100000: episode: 8809, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002864, mean_q: 0.003962
 85479/100000: episode: 8810, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000022, mae: 0.003122, mean_q: 0.004199
 85489/100000: episode: 8811, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003724, mean_q: 0.004944
 85499/100000: episode: 8812, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000037, mae: 0.002457, mean_q: 0.003648
 85509/100000: episode: 8813, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000048, mae: 0.003737, mean_q: 0.004251
 85519/100000: episode: 8814, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000039, mae: 0.003403, mean_q: 0.004619
 85529/100000: episode: 8815, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000017, mae: 0.002638, mean_q: 0.003758
 85539/100000: episode: 8816, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000075, mae: 0.004256, mean_q: 0.004581
 85549/100000: episode: 8817, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000025, mae: 0.003415, mean_q: 0.004606
 85559/100000: episode: 8818, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002366, mean_q: 0.003539
 85569/100000: episode: 8819, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003256, mean_q: 0.004254
 85579/100000: episode: 8820, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000056, mae: 0.003921, mean_q: 0.004481
 85589/100000: episode: 8821, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000064, mae: 0.004997, mean_q: 0.005639
 85599/100000: episode: 8822, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003301, mean_q: 0.004843
 85609/100000: episode: 8823, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000012, mae: 0.001839, mean_q: 0.002924
 85619/100000: episode: 8824, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000027, mae: 0.003529, mean_q: 0.004454
 85629/100000: episode: 8825, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000044, mae: 0.003332, mean_q: 0.004441
 85639/100000: episode: 8826, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.002729, mean_q: 0.004135
 85649/100000: episode: 8827, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000042, mae: 0.002942, mean_q: 0.003829
 85659/100000: episode: 8828, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000071, mae: 0.004255, mean_q: 0.004925
 85669/100000: episode: 8829, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003397, mean_q: 0.004754
 85679/100000: episode: 8830, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000050, mae: 0.003336, mean_q: 0.003912
 85689/100000: episode: 8831, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000069, mae: 0.004419, mean_q: 0.005681
 85699/100000: episode: 8832, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000022, mae: 0.003366, mean_q: 0.004522
 85709/100000: episode: 8833, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002549, mean_q: 0.003715
 85719/100000: episode: 8834, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000087, mae: 0.004861, mean_q: 0.005299
 85729/100000: episode: 8835, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000012, mae: 0.003018, mean_q: 0.004692
 85739/100000: episode: 8836, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000046, mae: 0.002939, mean_q: 0.003252
 85749/100000: episode: 8837, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000016, mae: 0.003673, mean_q: 0.005410
 85759/100000: episode: 8838, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000024, mae: 0.002898, mean_q: 0.003945
 85769/100000: episode: 8839, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000134, mae: 0.005231, mean_q: 0.005076
 85779/100000: episode: 8840, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.003936, mean_q: 0.005777
 85789/100000: episode: 8841, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.002654, mean_q: 0.003241
 85799/100000: episode: 8842, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000025, mae: 0.003898, mean_q: 0.005294
 85809/100000: episode: 8843, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000061, mae: 0.004109, mean_q: 0.004359
 85819/100000: episode: 8844, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000024, mae: 0.004204, mean_q: 0.005687
 85829/100000: episode: 8845, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000050, mae: 0.003557, mean_q: 0.003936
 85839/100000: episode: 8846, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000054, mae: 0.004959, mean_q: 0.006268
 85849/100000: episode: 8847, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000021, mae: 0.002597, mean_q: 0.003598
 85859/100000: episode: 8848, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002892, mean_q: 0.004345
 85869/100000: episode: 8849, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000067, mae: 0.003539, mean_q: 0.004596
 85879/100000: episode: 8850, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000054, mae: 0.003610, mean_q: 0.004181
 85889/100000: episode: 8851, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002629, mean_q: 0.004250
 85899/100000: episode: 8852, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000045, mae: 0.003411, mean_q: 0.004435
 85909/100000: episode: 8853, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000040, mae: 0.003264, mean_q: 0.004958
 85919/100000: episode: 8854, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000055, mae: 0.003127, mean_q: 0.003519
 85929/100000: episode: 8855, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.003258, mean_q: 0.004995
 85939/100000: episode: 8856, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000042, mae: 0.003034, mean_q: 0.004032
 85949/100000: episode: 8857, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000019, mae: 0.003484, mean_q: 0.005031
 85959/100000: episode: 8858, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000066, mae: 0.003348, mean_q: 0.004233
 85969/100000: episode: 8859, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.003290, mean_q: 0.005070
 85979/100000: episode: 8860, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000039, mae: 0.003011, mean_q: 0.003939
 85989/100000: episode: 8861, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000099, mae: 0.005224, mean_q: 0.005937
 85999/100000: episode: 8862, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.003142, mean_q: 0.004864
 86009/100000: episode: 8863, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000148, mae: 0.005803, mean_q: 0.005006
 86019/100000: episode: 8864, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000024, mae: 0.004144, mean_q: 0.005806
 86029/100000: episode: 8865, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002788, mean_q: 0.003938
 86039/100000: episode: 8866, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000106, mae: 0.005503, mean_q: 0.006057
 86049/100000: episode: 8867, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000011, mae: 0.002642, mean_q: 0.004227
 86059/100000: episode: 8868, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000012, mae: 0.002468, mean_q: 0.003674
 86069/100000: episode: 8869, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.002949, mean_q: 0.004606
 86079/100000: episode: 8870, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000018, mae: 0.002867, mean_q: 0.004231
 86089/100000: episode: 8871, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000040, mae: 0.003659, mean_q: 0.004795
 86099/100000: episode: 8872, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002943, mean_q: 0.004189
 86109/100000: episode: 8873, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000011, mae: 0.002568, mean_q: 0.003981
 86119/100000: episode: 8874, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000052, mae: 0.003659, mean_q: 0.004505
 86129/100000: episode: 8875, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000054, mae: 0.003849, mean_q: 0.004932
 86139/100000: episode: 8876, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000049, mae: 0.003825, mean_q: 0.004904
 86149/100000: episode: 8877, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000072, mae: 0.004072, mean_q: 0.004781
 86159/100000: episode: 8878, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000012, mae: 0.002898, mean_q: 0.004389
 86169/100000: episode: 8879, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000013, mae: 0.002648, mean_q: 0.003972
 86179/100000: episode: 8880, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000014, mae: 0.002515, mean_q: 0.003876
 86189/100000: episode: 8881, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.003073, mean_q: 0.004049
 86199/100000: episode: 8882, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000040, mae: 0.003064, mean_q: 0.004176
 86209/100000: episode: 8883, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000111, mae: 0.004952, mean_q: 0.004841
 86219/100000: episode: 8884, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000054, mae: 0.004855, mean_q: 0.006067
 86229/100000: episode: 8885, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000044, mae: 0.003469, mean_q: 0.004563
 86239/100000: episode: 8886, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000051, mae: 0.003954, mean_q: 0.004745
 86249/100000: episode: 8887, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000050, mae: 0.003629, mean_q: 0.004445
 86259/100000: episode: 8888, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003865, mean_q: 0.005022
 86269/100000: episode: 8889, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000048, mae: 0.003212, mean_q: 0.004234
 86279/100000: episode: 8890, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002563, mean_q: 0.004055
 86289/100000: episode: 8891, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003102, mean_q: 0.003917
 86299/100000: episode: 8892, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000025, mae: 0.004133, mean_q: 0.005444
 86309/100000: episode: 8893, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000047, mae: 0.003458, mean_q: 0.004314
 86319/100000: episode: 8894, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003377, mean_q: 0.004799
 86329/100000: episode: 8895, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000071, mae: 0.003570, mean_q: 0.004412
 86339/100000: episode: 8896, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000022, mae: 0.003259, mean_q: 0.004412
 86349/100000: episode: 8897, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002598, mean_q: 0.004242
 86359/100000: episode: 8898, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000136, mae: 0.005763, mean_q: 0.005475
 86369/100000: episode: 8899, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000043, mae: 0.004471, mean_q: 0.006251
 86379/100000: episode: 8900, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000046, mae: 0.003160, mean_q: 0.003555
 86389/100000: episode: 8901, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000073, mae: 0.003819, mean_q: 0.004591
[Info] 1-TH LEVEL FOUND: 0.004217741545289755, Considering 100/100 traces
 86399/100000: episode: 8902, duration: 0.762s, episode steps: 10, steps per second: 13, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000015, mae: 0.003049, mean_q: 0.004721
[Info] 2-TH LEVEL FOUND: 0.0042733182199299335, Considering 100/100 traces
 86409/100000: episode: 8903, duration: 0.710s, episode steps: 10, steps per second: 14, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002691, mean_q: 0.004203
[Info] 3-TH LEVEL FOUND: 0.006189118605107069, Considering 100/100 traces
 86419/100000: episode: 8904, duration: 0.836s, episode steps: 10, steps per second: 12, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000088, mae: 0.004982, mean_q: 0.005263
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.006189118605107069
 86429/100000: episode: 8905, duration: 0.564s, episode steps: 10, steps per second: 18, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.003535, mean_q: 0.004884
 86439/100000: episode: 8906, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000053, mae: 0.003843, mean_q: 0.004199
 86449/100000: episode: 8907, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000012, mae: 0.004197, mean_q: 0.006473
 86459/100000: episode: 8908, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.002408, mean_q: 0.002857
 86469/100000: episode: 8909, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000013, mae: 0.003247, mean_q: 0.004947
 86479/100000: episode: 8910, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000030, mae: 0.003629, mean_q: 0.004470
 86489/100000: episode: 8911, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000043, mae: 0.003167, mean_q: 0.004347
 86499/100000: episode: 8912, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000068, mae: 0.005305, mean_q: 0.005979
 86509/100000: episode: 8913, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000046, mae: 0.003244, mean_q: 0.004322
 86519/100000: episode: 8914, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.003888, mean_q: 0.004835
 86529/100000: episode: 8915, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000040, mae: 0.003493, mean_q: 0.004998
 86539/100000: episode: 8916, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000062, mae: 0.004358, mean_q: 0.004608
 86549/100000: episode: 8917, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000028, mae: 0.003835, mean_q: 0.005401
 86559/100000: episode: 8918, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.002460, mean_q: 0.003232
 86569/100000: episode: 8919, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000043, mae: 0.003480, mean_q: 0.004849
 86579/100000: episode: 8920, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000037, mae: 0.002519, mean_q: 0.003747
 86589/100000: episode: 8921, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000028, mae: 0.003222, mean_q: 0.004347
 86599/100000: episode: 8922, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000108, mae: 0.004800, mean_q: 0.004717
 86609/100000: episode: 8923, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000020, mae: 0.003901, mean_q: 0.005561
 86619/100000: episode: 8924, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000049, mae: 0.003293, mean_q: 0.004171
 86629/100000: episode: 8925, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000051, mae: 0.003727, mean_q: 0.004364
 86639/100000: episode: 8926, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.004505, mean_q: 0.005866
 86649/100000: episode: 8927, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000127, mae: 0.005648, mean_q: 0.005843
 86659/100000: episode: 8928, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000048, mae: 0.003631, mean_q: 0.004870
 86669/100000: episode: 8929, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000097, mae: 0.004452, mean_q: 0.004801
 86679/100000: episode: 8930, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000049, mae: 0.004398, mean_q: 0.005474
 86689/100000: episode: 8931, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.003016, mean_q: 0.004182
 86699/100000: episode: 8932, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000070, mae: 0.004025, mean_q: 0.004943
 86709/100000: episode: 8933, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000014, mae: 0.002934, mean_q: 0.004807
 86719/100000: episode: 8934, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002539, mean_q: 0.003410
 86729/100000: episode: 8935, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003585, mean_q: 0.004577
 86739/100000: episode: 8936, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000054, mae: 0.004308, mean_q: 0.005315
 86749/100000: episode: 8937, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000080, mae: 0.005162, mean_q: 0.006084
 86759/100000: episode: 8938, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000047, mae: 0.003691, mean_q: 0.004853
 86769/100000: episode: 8939, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000047, mae: 0.003423, mean_q: 0.004159
 86779/100000: episode: 8940, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000048, mae: 0.003638, mean_q: 0.004975
 86789/100000: episode: 8941, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000057, mae: 0.004763, mean_q: 0.005806
 86799/100000: episode: 8942, duration: 0.117s, episode steps: 10, steps per second: 85, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000008, mae: 0.002245, mean_q: 0.003708
 86809/100000: episode: 8943, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000013, mae: 0.002731, mean_q: 0.003919
 86819/100000: episode: 8944, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000074, mae: 0.004292, mean_q: 0.005252
 86829/100000: episode: 8945, duration: 0.123s, episode steps: 10, steps per second: 81, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000067, mae: 0.004137, mean_q: 0.005314
 86839/100000: episode: 8946, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000026, mae: 0.003442, mean_q: 0.004871
 86849/100000: episode: 8947, duration: 0.106s, episode steps: 10, steps per second: 94, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000101, mae: 0.005056, mean_q: 0.005985
 86859/100000: episode: 8948, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000015, mae: 0.002614, mean_q: 0.004118
 86869/100000: episode: 8949, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000051, mae: 0.003828, mean_q: 0.004627
 86879/100000: episode: 8950, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000046, mae: 0.004294, mean_q: 0.005837
 86889/100000: episode: 8951, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000053, mae: 0.003554, mean_q: 0.004214
 86899/100000: episode: 8952, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003481, mean_q: 0.004744
 86909/100000: episode: 8953, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003029, mean_q: 0.004351
 86919/100000: episode: 8954, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000029, mae: 0.003609, mean_q: 0.004650
 86929/100000: episode: 8955, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000037, mae: 0.004540, mean_q: 0.005568
 86939/100000: episode: 8956, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000044, mae: 0.003569, mean_q: 0.004628
 86949/100000: episode: 8957, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000056, mae: 0.004526, mean_q: 0.005388
 86959/100000: episode: 8958, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000049, mae: 0.004127, mean_q: 0.005619
 86969/100000: episode: 8959, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000054, mae: 0.003799, mean_q: 0.004476
 86979/100000: episode: 8960, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000047, mae: 0.004213, mean_q: 0.005680
 86989/100000: episode: 8961, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000052, mae: 0.003137, mean_q: 0.003882
 86999/100000: episode: 8962, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000047, mae: 0.004185, mean_q: 0.005801
 87009/100000: episode: 8963, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000017, mae: 0.002681, mean_q: 0.003854
 87019/100000: episode: 8964, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.003014, mean_q: 0.004331
 87029/100000: episode: 8965, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000044, mae: 0.003780, mean_q: 0.005161
 87039/100000: episode: 8966, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000019, mae: 0.002753, mean_q: 0.003986
 87049/100000: episode: 8967, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000099, mae: 0.005339, mean_q: 0.006226
 87059/100000: episode: 8968, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000016, mae: 0.003056, mean_q: 0.004586
 87069/100000: episode: 8969, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000073, mae: 0.003659, mean_q: 0.004069
 87079/100000: episode: 8970, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000012, mae: 0.003263, mean_q: 0.005241
 87089/100000: episode: 8971, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000074, mae: 0.003632, mean_q: 0.004253
 87099/100000: episode: 8972, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003657, mean_q: 0.005158
 87109/100000: episode: 8973, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000016, mae: 0.002949, mean_q: 0.004511
 87119/100000: episode: 8974, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000034, mae: 0.003961, mean_q: 0.004812
 87129/100000: episode: 8975, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000018, mae: 0.002921, mean_q: 0.004359
 87139/100000: episode: 8976, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000033, mae: 0.003643, mean_q: 0.004637
 87149/100000: episode: 8977, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000052, mae: 0.003890, mean_q: 0.004690
 87159/100000: episode: 8978, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000081, mae: 0.004475, mean_q: 0.005078
 87169/100000: episode: 8979, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000027, mae: 0.004377, mean_q: 0.006086
 87179/100000: episode: 8980, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000046, mae: 0.003105, mean_q: 0.003367
 87189/100000: episode: 8981, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000043, mae: 0.004089, mean_q: 0.005760
 87199/100000: episode: 8982, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000055, mae: 0.004043, mean_q: 0.004814
 87209/100000: episode: 8983, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000027, mae: 0.003595, mean_q: 0.004777
 87219/100000: episode: 8984, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.003285, mean_q: 0.004968
 87229/100000: episode: 8985, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.002723, mean_q: 0.004050
 87239/100000: episode: 8986, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000038, mae: 0.003050, mean_q: 0.004393
 87249/100000: episode: 8987, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000045, mae: 0.003586, mean_q: 0.004928
 87259/100000: episode: 8988, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.002970, mean_q: 0.003903
 87269/100000: episode: 8989, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000134, mae: 0.005530, mean_q: 0.005529
 87279/100000: episode: 8990, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000045, mae: 0.004567, mean_q: 0.006218
 87289/100000: episode: 8991, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000052, mae: 0.003382, mean_q: 0.004226
 87299/100000: episode: 8992, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000014, mae: 0.003047, mean_q: 0.004992
 87309/100000: episode: 8993, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000070, mae: 0.003711, mean_q: 0.004741
 87319/100000: episode: 8994, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000075, mae: 0.004485, mean_q: 0.005376
 87329/100000: episode: 8995, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003369, mean_q: 0.003945
 87339/100000: episode: 8996, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000068, mae: 0.005343, mean_q: 0.006096
 87349/100000: episode: 8997, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000061, mae: 0.004794, mean_q: 0.005580
 87359/100000: episode: 8998, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000049, mae: 0.003587, mean_q: 0.004744
 87369/100000: episode: 8999, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000019, mae: 0.003045, mean_q: 0.004508
 87379/100000: episode: 9000, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000015, mae: 0.002600, mean_q: 0.004006
 87389/100000: episode: 9001, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.002908, mean_q: 0.004265
 87399/100000: episode: 9002, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000006, mae: 0.002439, mean_q: 0.004567
 87409/100000: episode: 9003, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000067, mae: 0.003360, mean_q: 0.004192
 87419/100000: episode: 9004, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003092, mean_q: 0.004368
[Info] 1-TH LEVEL FOUND: 0.005125008523464203, Considering 100/100 traces
 87429/100000: episode: 9005, duration: 0.717s, episode steps: 10, steps per second: 14, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000070, mae: 0.003703, mean_q: 0.004536
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005125008523464203
 87439/100000: episode: 9006, duration: 0.509s, episode steps: 10, steps per second: 20, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000021, mae: 0.003066, mean_q: 0.004427
 87449/100000: episode: 9007, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003113, mean_q: 0.004091
 87459/100000: episode: 9008, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000047, mae: 0.004234, mean_q: 0.005438
 87469/100000: episode: 9009, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000021, mae: 0.002968, mean_q: 0.004336
 87479/100000: episode: 9010, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000017, mae: 0.002982, mean_q: 0.004146
 87489/100000: episode: 9011, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000075, mae: 0.004153, mean_q: 0.004745
 87499/100000: episode: 9012, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000078, mae: 0.004917, mean_q: 0.005619
 87509/100000: episode: 9013, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003912, mean_q: 0.005100
 87519/100000: episode: 9014, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000083, mae: 0.004672, mean_q: 0.005342
 87529/100000: episode: 9015, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000023, mae: 0.003208, mean_q: 0.004613
 87539/100000: episode: 9016, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000073, mae: 0.004115, mean_q: 0.005315
 87549/100000: episode: 9017, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000050, mae: 0.003851, mean_q: 0.004786
 87559/100000: episode: 9018, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000058, mae: 0.003946, mean_q: 0.004435
 87569/100000: episode: 9019, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000025, mae: 0.003869, mean_q: 0.005425
 87579/100000: episode: 9020, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000015, mae: 0.002617, mean_q: 0.003817
 87589/100000: episode: 9021, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000040, mae: 0.003322, mean_q: 0.004673
 87599/100000: episode: 9022, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000013, mae: 0.002765, mean_q: 0.004613
 87609/100000: episode: 9023, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000022, mae: 0.002988, mean_q: 0.003680
 87619/100000: episode: 9024, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000011, mae: 0.003209, mean_q: 0.005334
 87629/100000: episode: 9025, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000132, mae: 0.005075, mean_q: 0.005067
 87639/100000: episode: 9026, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000032, mae: 0.004080, mean_q: 0.004929
 87649/100000: episode: 9027, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000010, mae: 0.002672, mean_q: 0.004605
 87659/100000: episode: 9028, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003678, mean_q: 0.004489
 87669/100000: episode: 9029, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000056, mae: 0.004498, mean_q: 0.005424
 87679/100000: episode: 9030, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000054, mae: 0.004241, mean_q: 0.005235
 87689/100000: episode: 9031, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000019, mae: 0.003028, mean_q: 0.004354
 87699/100000: episode: 9032, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000086, mae: 0.005007, mean_q: 0.005335
 87709/100000: episode: 9033, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000071, mae: 0.004532, mean_q: 0.005582
 87719/100000: episode: 9034, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000020, mae: 0.002623, mean_q: 0.003931
 87729/100000: episode: 9035, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000028, mae: 0.004139, mean_q: 0.005802
 87739/100000: episode: 9036, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000011, mae: 0.002249, mean_q: 0.003770
 87749/100000: episode: 9037, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000056, mae: 0.004158, mean_q: 0.004792
 87759/100000: episode: 9038, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000027, mae: 0.003716, mean_q: 0.004848
 87769/100000: episode: 9039, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000031, mae: 0.003604, mean_q: 0.004353
 87779/100000: episode: 9040, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000029, mae: 0.004509, mean_q: 0.006193
 87789/100000: episode: 9041, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000103, mae: 0.004144, mean_q: 0.003989
 87799/100000: episode: 9042, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000080, mae: 0.005837, mean_q: 0.007074
 87809/100000: episode: 9043, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000016, mae: 0.002760, mean_q: 0.004114
 87819/100000: episode: 9044, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000053, mae: 0.003984, mean_q: 0.004797
 87829/100000: episode: 9045, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000077, mae: 0.004066, mean_q: 0.004884
 87839/100000: episode: 9046, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000052, mae: 0.004081, mean_q: 0.005333
 87849/100000: episode: 9047, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003413, mean_q: 0.004779
 87859/100000: episode: 9048, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000048, mae: 0.003571, mean_q: 0.004899
 87869/100000: episode: 9049, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000130, mae: 0.004817, mean_q: 0.004776
 87879/100000: episode: 9050, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000016, mae: 0.004004, mean_q: 0.006336
 87889/100000: episode: 9051, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000049, mae: 0.002926, mean_q: 0.003660
 87899/100000: episode: 9052, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000030, mae: 0.003693, mean_q: 0.004608
 87909/100000: episode: 9053, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000066, mae: 0.003849, mean_q: 0.005106
 87919/100000: episode: 9054, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000033, mae: 0.003706, mean_q: 0.004723
 87929/100000: episode: 9055, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000023, mae: 0.003651, mean_q: 0.005220
 87939/100000: episode: 9056, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000053, mae: 0.003499, mean_q: 0.004210
 87949/100000: episode: 9057, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000015, mae: 0.002958, mean_q: 0.004552
 87959/100000: episode: 9058, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000034, mae: 0.003881, mean_q: 0.004548
 87969/100000: episode: 9059, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.003295, mean_q: 0.005011
 87979/100000: episode: 9060, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000042, mae: 0.002565, mean_q: 0.003292
 87989/100000: episode: 9061, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000055, mae: 0.004792, mean_q: 0.005964
 87999/100000: episode: 9062, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002897, mean_q: 0.004221
 88009/100000: episode: 9063, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000065, mae: 0.004516, mean_q: 0.004816
 88019/100000: episode: 9064, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.003255, mean_q: 0.005359
 88029/100000: episode: 9065, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000023, mae: 0.002705, mean_q: 0.003168
 88039/100000: episode: 9066, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000014, mae: 0.003076, mean_q: 0.004630
 88049/100000: episode: 9067, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000053, mae: 0.003767, mean_q: 0.004281
 88059/100000: episode: 9068, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000075, mae: 0.005212, mean_q: 0.006382
 88069/100000: episode: 9069, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003528, mean_q: 0.004992
 88079/100000: episode: 9070, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000039, mae: 0.002975, mean_q: 0.004159
 88089/100000: episode: 9071, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000074, mae: 0.004385, mean_q: 0.005447
 88099/100000: episode: 9072, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000015, mae: 0.002759, mean_q: 0.004163
 88109/100000: episode: 9073, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000012, mae: 0.002228, mean_q: 0.003738
 88119/100000: episode: 9074, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000031, mae: 0.003518, mean_q: 0.004618
 88129/100000: episode: 9075, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.003215, mean_q: 0.004848
 88139/100000: episode: 9076, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000044, mae: 0.003320, mean_q: 0.004147
 88149/100000: episode: 9077, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000049, mae: 0.004170, mean_q: 0.005485
 88159/100000: episode: 9078, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000020, mae: 0.003267, mean_q: 0.004492
 88169/100000: episode: 9079, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003076, mean_q: 0.004205
 88179/100000: episode: 9080, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002688, mean_q: 0.004233
 88189/100000: episode: 9081, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000070, mae: 0.003425, mean_q: 0.004052
 88199/100000: episode: 9082, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000052, mae: 0.004024, mean_q: 0.005195
 88209/100000: episode: 9083, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000073, mae: 0.005300, mean_q: 0.005430
 88219/100000: episode: 9084, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002958, mean_q: 0.004781
 88229/100000: episode: 9085, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000037, mae: 0.002600, mean_q: 0.003469
 88239/100000: episode: 9086, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.003113, mean_q: 0.004590
 88249/100000: episode: 9087, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000075, mae: 0.004351, mean_q: 0.005110
 88259/100000: episode: 9088, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000028, mae: 0.003472, mean_q: 0.004636
 88269/100000: episode: 9089, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000018, mae: 0.002943, mean_q: 0.004461
 88279/100000: episode: 9090, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000039, mae: 0.003156, mean_q: 0.004499
 88289/100000: episode: 9091, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000014, mae: 0.002827, mean_q: 0.004336
 88299/100000: episode: 9092, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000047, mae: 0.003573, mean_q: 0.004556
 88309/100000: episode: 9093, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000051, mae: 0.004018, mean_q: 0.004841
 88319/100000: episode: 9094, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000026, mae: 0.003749, mean_q: 0.004849
 88329/100000: episode: 9095, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000025, mae: 0.003214, mean_q: 0.004101
 88339/100000: episode: 9096, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000065, mae: 0.004657, mean_q: 0.004965
 88349/100000: episode: 9097, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000047, mae: 0.003790, mean_q: 0.004842
 88359/100000: episode: 9098, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.002968, mean_q: 0.004343
 88369/100000: episode: 9099, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000057, mae: 0.003999, mean_q: 0.004501
 88379/100000: episode: 9100, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000080, mae: 0.005031, mean_q: 0.005973
 88389/100000: episode: 9101, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000066, mae: 0.003130, mean_q: 0.003916
 88399/100000: episode: 9102, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000024, mae: 0.003342, mean_q: 0.004888
 88409/100000: episode: 9103, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000070, mae: 0.003605, mean_q: 0.004401
 88419/100000: episode: 9104, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000035, mae: 0.004513, mean_q: 0.005893
 88429/100000: episode: 9105, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.002775, mean_q: 0.003759
[Info] 1-TH LEVEL FOUND: 0.0071905809454619884, Considering 100/100 traces
 88439/100000: episode: 9106, duration: 0.707s, episode steps: 10, steps per second: 14, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000106, mae: 0.004823, mean_q: 0.004860
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0071905809454619884
 88449/100000: episode: 9107, duration: 0.486s, episode steps: 10, steps per second: 21, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000084, mae: 0.006191, mean_q: 0.007132
 88459/100000: episode: 9108, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000045, mae: 0.003558, mean_q: 0.004614
 88469/100000: episode: 9109, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000079, mae: 0.004732, mean_q: 0.005486
 88479/100000: episode: 9110, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000025, mae: 0.004280, mean_q: 0.005985
 88489/100000: episode: 9111, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000048, mae: 0.003416, mean_q: 0.004055
 88499/100000: episode: 9112, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000045, mae: 0.003680, mean_q: 0.005124
 88509/100000: episode: 9113, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000057, mae: 0.004046, mean_q: 0.004851
 88519/100000: episode: 9114, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000052, mae: 0.004120, mean_q: 0.005355
 88529/100000: episode: 9115, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000082, mae: 0.004542, mean_q: 0.004917
 88539/100000: episode: 9116, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000039, mae: 0.004511, mean_q: 0.005612
 88549/100000: episode: 9117, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000058, mae: 0.004984, mean_q: 0.006223
 88559/100000: episode: 9118, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000042, mae: 0.003045, mean_q: 0.004281
 88569/100000: episode: 9119, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000040, mae: 0.002919, mean_q: 0.004136
 88579/100000: episode: 9120, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000052, mae: 0.004535, mean_q: 0.005817
 88589/100000: episode: 9121, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002660, mean_q: 0.004235
 88599/100000: episode: 9122, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000080, mae: 0.004420, mean_q: 0.004728
 88609/100000: episode: 9123, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000023, mae: 0.003938, mean_q: 0.005736
 88619/100000: episode: 9124, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000022, mae: 0.003044, mean_q: 0.004273
 88629/100000: episode: 9125, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000025, mae: 0.003684, mean_q: 0.005446
 88639/100000: episode: 9126, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000031, mae: 0.003204, mean_q: 0.004125
 88649/100000: episode: 9127, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000028, mae: 0.003589, mean_q: 0.005085
 88659/100000: episode: 9128, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000050, mae: 0.003725, mean_q: 0.004598
 88669/100000: episode: 9129, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000035, mae: 0.003591, mean_q: 0.004649
 88679/100000: episode: 9130, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000052, mae: 0.003648, mean_q: 0.004631
 88689/100000: episode: 9131, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000050, mae: 0.004063, mean_q: 0.005209
 88699/100000: episode: 9132, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000075, mae: 0.004270, mean_q: 0.005061
 88709/100000: episode: 9133, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000020, mae: 0.003343, mean_q: 0.004891
 88719/100000: episode: 9134, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000046, mae: 0.004238, mean_q: 0.004745
 88729/100000: episode: 9135, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000025, mae: 0.003863, mean_q: 0.005639
 88739/100000: episode: 9136, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000032, mae: 0.003943, mean_q: 0.004880
 88749/100000: episode: 9137, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000017, mae: 0.003291, mean_q: 0.005128
 88759/100000: episode: 9138, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000036, mae: 0.003808, mean_q: 0.004601
 88769/100000: episode: 9139, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000048, mae: 0.004267, mean_q: 0.005462
 88779/100000: episode: 9140, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000046, mae: 0.003478, mean_q: 0.004790
 88789/100000: episode: 9141, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000089, mae: 0.004613, mean_q: 0.005084
 88799/100000: episode: 9142, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000053, mae: 0.004615, mean_q: 0.006076
 88809/100000: episode: 9143, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.003374, mean_q: 0.003997
 88819/100000: episode: 9144, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000068, mae: 0.004408, mean_q: 0.005736
 88829/100000: episode: 9145, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000024, mae: 0.003781, mean_q: 0.005333
 88839/100000: episode: 9146, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000070, mae: 0.003635, mean_q: 0.004613
 88849/100000: episode: 9147, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003521, mean_q: 0.005243
 88859/100000: episode: 9148, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000034, mae: 0.003439, mean_q: 0.004142
 88869/100000: episode: 9149, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000064, mae: 0.005507, mean_q: 0.006238
 88879/100000: episode: 9150, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000051, mae: 0.004051, mean_q: 0.005286
 88889/100000: episode: 9151, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000032, mae: 0.003692, mean_q: 0.005111
 88899/100000: episode: 9152, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000040, mae: 0.004155, mean_q: 0.004944
 88909/100000: episode: 9153, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003335, mean_q: 0.004893
 88919/100000: episode: 9154, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000019, mae: 0.002727, mean_q: 0.004026
 88929/100000: episode: 9155, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000050, mae: 0.003626, mean_q: 0.004565
 88939/100000: episode: 9156, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000049, mae: 0.004473, mean_q: 0.005792
 88949/100000: episode: 9157, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000037, mae: 0.003842, mean_q: 0.004647
 88959/100000: episode: 9158, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003205, mean_q: 0.004647
 88969/100000: episode: 9159, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.003048, mean_q: 0.004532
 88979/100000: episode: 9160, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000064, mae: 0.004915, mean_q: 0.005823
 88989/100000: episode: 9161, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000018, mae: 0.003341, mean_q: 0.005072
 88999/100000: episode: 9162, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000051, mae: 0.003312, mean_q: 0.003915
 89009/100000: episode: 9163, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000059, mae: 0.005165, mean_q: 0.006130
 89019/100000: episode: 9164, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000049, mae: 0.004405, mean_q: 0.005655
 89029/100000: episode: 9165, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000033, mae: 0.003212, mean_q: 0.003973
 89039/100000: episode: 9166, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000111, mae: 0.005310, mean_q: 0.005551
 89049/100000: episode: 9167, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.004310, mean_q: 0.005969
 89059/100000: episode: 9168, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000023, mae: 0.002810, mean_q: 0.003797
 89069/100000: episode: 9169, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000056, mae: 0.004087, mean_q: 0.005048
 89079/100000: episode: 9170, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000083, mae: 0.004347, mean_q: 0.004964
 89089/100000: episode: 9171, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000058, mae: 0.005784, mean_q: 0.007060
 89099/100000: episode: 9172, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000025, mae: 0.003043, mean_q: 0.004204
 89109/100000: episode: 9173, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000032, mae: 0.003618, mean_q: 0.004627
 89119/100000: episode: 9174, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000057, mae: 0.004790, mean_q: 0.005809
 89129/100000: episode: 9175, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000035, mae: 0.003512, mean_q: 0.004084
 89139/100000: episode: 9176, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000022, mae: 0.003878, mean_q: 0.005847
 89149/100000: episode: 9177, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000056, mae: 0.003477, mean_q: 0.004281
 89159/100000: episode: 9178, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000022, mae: 0.003757, mean_q: 0.005680
 89169/100000: episode: 9179, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000054, mae: 0.003633, mean_q: 0.004618
 89179/100000: episode: 9180, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000018, mae: 0.003604, mean_q: 0.005622
 89189/100000: episode: 9181, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000136, mae: 0.004862, mean_q: 0.004602
 89199/100000: episode: 9182, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000037, mae: 0.004010, mean_q: 0.006180
 89209/100000: episode: 9183, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000062, mae: 0.003899, mean_q: 0.004062
 89219/100000: episode: 9184, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003994, mean_q: 0.005956
 89229/100000: episode: 9185, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002338, mean_q: 0.003665
 89239/100000: episode: 9186, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000013, mae: 0.002698, mean_q: 0.004152
 89249/100000: episode: 9187, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000046, mae: 0.003701, mean_q: 0.005154
 89259/100000: episode: 9188, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000049, mae: 0.003684, mean_q: 0.004903
 89269/100000: episode: 9189, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000025, mae: 0.003553, mean_q: 0.004905
 89279/100000: episode: 9190, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000041, mae: 0.003292, mean_q: 0.004883
 89289/100000: episode: 9191, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000023, mae: 0.002822, mean_q: 0.004028
 89299/100000: episode: 9192, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000016, mae: 0.002884, mean_q: 0.004221
 89309/100000: episode: 9193, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000010, mae: 0.002480, mean_q: 0.004213
 89319/100000: episode: 9194, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000012, mae: 0.002632, mean_q: 0.004032
 89329/100000: episode: 9195, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000048, mae: 0.003458, mean_q: 0.004760
 89339/100000: episode: 9196, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000031, mae: 0.003919, mean_q: 0.004979
 89349/100000: episode: 9197, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000027, mae: 0.003006, mean_q: 0.004268
 89359/100000: episode: 9198, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000040, mae: 0.004101, mean_q: 0.004534
 89369/100000: episode: 9199, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000047, mae: 0.003808, mean_q: 0.004672
 89379/100000: episode: 9200, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000047, mae: 0.004554, mean_q: 0.006255
 89389/100000: episode: 9201, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000026, mae: 0.002906, mean_q: 0.003608
 89399/100000: episode: 9202, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000069, mae: 0.005253, mean_q: 0.005808
 89409/100000: episode: 9203, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000022, mae: 0.003553, mean_q: 0.005234
 89419/100000: episode: 9204, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002497, mean_q: 0.003863
 89429/100000: episode: 9205, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002617, mean_q: 0.004232
 89439/100000: episode: 9206, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000035, mae: 0.003069, mean_q: 0.004518
[Info] 1-TH LEVEL FOUND: 0.005856180563569069, Considering 100/100 traces
 89449/100000: episode: 9207, duration: 0.731s, episode steps: 10, steps per second: 14, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000074, mae: 0.003765, mean_q: 0.004356
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005856180563569069
 89459/100000: episode: 9208, duration: 0.514s, episode steps: 10, steps per second: 19, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000078, mae: 0.004783, mean_q: 0.005512
 89469/100000: episode: 9209, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000108, mae: 0.004524, mean_q: 0.004639
 89479/100000: episode: 9210, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000040, mae: 0.004176, mean_q: 0.006136
 89489/100000: episode: 9211, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000045, mae: 0.003108, mean_q: 0.004146
 89499/100000: episode: 9212, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000049, mae: 0.004184, mean_q: 0.005510
 89509/100000: episode: 9213, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003181, mean_q: 0.004531
 89519/100000: episode: 9214, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000025, mae: 0.002755, mean_q: 0.003676
 89529/100000: episode: 9215, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.003519, mean_q: 0.005200
 89539/100000: episode: 9216, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000046, mae: 0.003883, mean_q: 0.004997
 89549/100000: episode: 9217, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003583, mean_q: 0.004901
 89559/100000: episode: 9218, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000036, mae: 0.002831, mean_q: 0.003874
 89569/100000: episode: 9219, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003631, mean_q: 0.004830
 89579/100000: episode: 9220, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000020, mae: 0.002901, mean_q: 0.004263
 89589/100000: episode: 9221, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000073, mae: 0.003739, mean_q: 0.004699
 89599/100000: episode: 9222, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000064, mae: 0.004778, mean_q: 0.005313
 89609/100000: episode: 9223, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.003764, mean_q: 0.005046
 89619/100000: episode: 9224, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000098, mae: 0.004418, mean_q: 0.004912
 89629/100000: episode: 9225, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.003067, mean_q: 0.004548
 89639/100000: episode: 9226, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.002989, mean_q: 0.004025
 89649/100000: episode: 9227, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000017, mae: 0.002823, mean_q: 0.004300
 89659/100000: episode: 9228, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000017, mae: 0.002622, mean_q: 0.003898
 89669/100000: episode: 9229, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000047, mae: 0.003188, mean_q: 0.004400
 89679/100000: episode: 9230, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000024, mae: 0.002814, mean_q: 0.003814
 89689/100000: episode: 9231, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000006, mae: 0.002185, mean_q: 0.004030
 89699/100000: episode: 9232, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000046, mae: 0.003241, mean_q: 0.004005
 89709/100000: episode: 9233, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003423, mean_q: 0.005156
 89719/100000: episode: 9234, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000019, mae: 0.002428, mean_q: 0.003341
 89729/100000: episode: 9235, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003071, mean_q: 0.004225
 89739/100000: episode: 9236, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000016, mae: 0.002632, mean_q: 0.003972
 89749/100000: episode: 9237, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000054, mae: 0.004110, mean_q: 0.004756
 89759/100000: episode: 9238, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000053, mae: 0.003920, mean_q: 0.004776
 89769/100000: episode: 9239, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000044, mae: 0.003515, mean_q: 0.004744
 89779/100000: episode: 9240, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.003276, mean_q: 0.004024
 89789/100000: episode: 9241, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.002810, mean_q: 0.004350
 89799/100000: episode: 9242, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000033, mae: 0.003564, mean_q: 0.004086
 89809/100000: episode: 9243, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000052, mae: 0.004174, mean_q: 0.005249
 89819/100000: episode: 9244, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.002884, mean_q: 0.004066
 89829/100000: episode: 9245, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.003418, mean_q: 0.004521
 89839/100000: episode: 9246, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000008, mae: 0.002742, mean_q: 0.004459
 89849/100000: episode: 9247, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000022, mae: 0.002882, mean_q: 0.003783
 89859/100000: episode: 9248, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000015, mae: 0.003065, mean_q: 0.004538
 89869/100000: episode: 9249, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000047, mae: 0.003061, mean_q: 0.003996
 89879/100000: episode: 9250, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002777, mean_q: 0.004372
 89889/100000: episode: 9251, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000026, mae: 0.003197, mean_q: 0.004061
 89899/100000: episode: 9252, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000041, mae: 0.003072, mean_q: 0.004268
 89909/100000: episode: 9253, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000019, mae: 0.002951, mean_q: 0.004469
 89919/100000: episode: 9254, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000032, mae: 0.003583, mean_q: 0.004325
 89929/100000: episode: 9255, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000013, mae: 0.002676, mean_q: 0.004335
 89939/100000: episode: 9256, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000018, mae: 0.002456, mean_q: 0.003421
 89949/100000: episode: 9257, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000051, mae: 0.003969, mean_q: 0.004639
 89959/100000: episode: 9258, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000018, mae: 0.002891, mean_q: 0.004171
 89969/100000: episode: 9259, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.003663, mean_q: 0.004713
 89979/100000: episode: 9260, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000028, mae: 0.003604, mean_q: 0.004873
 89989/100000: episode: 9261, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002813, mean_q: 0.004403
 89999/100000: episode: 9262, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000047, mae: 0.002679, mean_q: 0.003382
 90009/100000: episode: 9263, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000017, mae: 0.002744, mean_q: 0.004302
 90019/100000: episode: 9264, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.002635, mean_q: 0.003873
 90029/100000: episode: 9265, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000028, mae: 0.003336, mean_q: 0.004480
 90039/100000: episode: 9266, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000012, mae: 0.002644, mean_q: 0.004239
 90049/100000: episode: 9267, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000028, mae: 0.003127, mean_q: 0.003902
 90059/100000: episode: 9268, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.003443, mean_q: 0.004892
 90069/100000: episode: 9269, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000040, mae: 0.002874, mean_q: 0.003456
 90079/100000: episode: 9270, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000015, mae: 0.003161, mean_q: 0.004842
 90089/100000: episode: 9271, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000017, mae: 0.002837, mean_q: 0.004163
 90099/100000: episode: 9272, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003233, mean_q: 0.004417
 90109/100000: episode: 9273, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000058, mae: 0.004466, mean_q: 0.004980
 90119/100000: episode: 9274, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000057, mae: 0.004433, mean_q: 0.005135
 90129/100000: episode: 9275, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000011, mae: 0.002725, mean_q: 0.004210
 90139/100000: episode: 9276, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000023, mae: 0.003082, mean_q: 0.004016
 90149/100000: episode: 9277, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000023, mae: 0.003372, mean_q: 0.004488
 90159/100000: episode: 9278, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000052, mae: 0.003923, mean_q: 0.004779
 90169/100000: episode: 9279, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000059, mae: 0.004477, mean_q: 0.004952
 90179/100000: episode: 9280, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000011, mae: 0.002774, mean_q: 0.004359
 90189/100000: episode: 9281, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002473, mean_q: 0.003697
 90199/100000: episode: 9282, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.002912, mean_q: 0.004032
 90209/100000: episode: 9283, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.003458, mean_q: 0.004619
 90219/100000: episode: 9284, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000031, mae: 0.003926, mean_q: 0.004816
 90229/100000: episode: 9285, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000011, mae: 0.002473, mean_q: 0.003970
 90239/100000: episode: 9286, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000020, mae: 0.002662, mean_q: 0.003791
 90249/100000: episode: 9287, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000080, mae: 0.004638, mean_q: 0.005170
 90259/100000: episode: 9288, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000022, mae: 0.003397, mean_q: 0.004662
 90269/100000: episode: 9289, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000012, mae: 0.002168, mean_q: 0.003452
 90279/100000: episode: 9290, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000029, mae: 0.003908, mean_q: 0.004897
 90289/100000: episode: 9291, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000013, mae: 0.002546, mean_q: 0.004052
 90299/100000: episode: 9292, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000011, mae: 0.002288, mean_q: 0.003367
 90309/100000: episode: 9293, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003243, mean_q: 0.004583
 90319/100000: episode: 9294, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000057, mae: 0.003928, mean_q: 0.004343
 90329/100000: episode: 9295, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000021, mae: 0.002795, mean_q: 0.003884
 90339/100000: episode: 9296, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000047, mae: 0.003713, mean_q: 0.004266
 90349/100000: episode: 9297, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.003605, mean_q: 0.005289
 90359/100000: episode: 9298, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000006, mae: 0.001640, mean_q: 0.002917
 90369/100000: episode: 9299, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.003473, mean_q: 0.004714
 90379/100000: episode: 9300, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002433, mean_q: 0.003670
 90389/100000: episode: 9301, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000075, mae: 0.004128, mean_q: 0.004646
 90399/100000: episode: 9302, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000035, mae: 0.004417, mean_q: 0.005518
 90409/100000: episode: 9303, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000039, mae: 0.003659, mean_q: 0.004101
 90419/100000: episode: 9304, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000051, mae: 0.003939, mean_q: 0.004725
 90429/100000: episode: 9305, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000029, mae: 0.004258, mean_q: 0.005850
 90439/100000: episode: 9306, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002560, mean_q: 0.003597
 90449/100000: episode: 9307, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000057, mae: 0.004561, mean_q: 0.005472
[Info] 1-TH LEVEL FOUND: 0.003685413394123316, Considering 100/100 traces
 90459/100000: episode: 9308, duration: 0.742s, episode steps: 10, steps per second: 13, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000018, mae: 0.002919, mean_q: 0.004234
[Info] 2-TH LEVEL FOUND: 0.005526128225028515, Considering 100/100 traces
 90469/100000: episode: 9309, duration: 0.691s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000055, mae: 0.003939, mean_q: 0.004840
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005526128225028515
 90479/100000: episode: 9310, duration: 0.497s, episode steps: 10, steps per second: 20, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000018, mae: 0.003163, mean_q: 0.004670
 90489/100000: episode: 9311, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.002861, mean_q: 0.003638
 90499/100000: episode: 9312, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000035, mae: 0.004199, mean_q: 0.004845
 90509/100000: episode: 9313, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000027, mae: 0.003850, mean_q: 0.005112
 90519/100000: episode: 9314, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000029, mae: 0.003490, mean_q: 0.004508
 90529/100000: episode: 9315, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002976, mean_q: 0.004341
 90539/100000: episode: 9316, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000032, mae: 0.003718, mean_q: 0.004664
 90549/100000: episode: 9317, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000049, mae: 0.003634, mean_q: 0.004893
 90559/100000: episode: 9318, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000024, mae: 0.003297, mean_q: 0.004852
 90569/100000: episode: 9319, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000055, mae: 0.003999, mean_q: 0.005001
 90579/100000: episode: 9320, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000017, mae: 0.003143, mean_q: 0.004752
 90589/100000: episode: 9321, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000027, mae: 0.003507, mean_q: 0.004301
 90599/100000: episode: 9322, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000041, mae: 0.003578, mean_q: 0.004842
 90609/100000: episode: 9323, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000078, mae: 0.004619, mean_q: 0.005432
 90619/100000: episode: 9324, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000035, mae: 0.003394, mean_q: 0.004078
 90629/100000: episode: 9325, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003157, mean_q: 0.004483
 90639/100000: episode: 9326, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002886, mean_q: 0.004425
 90649/100000: episode: 9327, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000071, mae: 0.003747, mean_q: 0.004466
 90659/100000: episode: 9328, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000030, mae: 0.004118, mean_q: 0.005306
 90669/100000: episode: 9329, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003505, mean_q: 0.005146
 90679/100000: episode: 9330, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000056, mae: 0.003731, mean_q: 0.004347
 90689/100000: episode: 9331, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000091, mae: 0.005643, mean_q: 0.006067
 90699/100000: episode: 9332, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000022, mae: 0.003564, mean_q: 0.005172
 90709/100000: episode: 9333, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000024, mae: 0.002801, mean_q: 0.003958
 90719/100000: episode: 9334, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.003001, mean_q: 0.004710
 90729/100000: episode: 9335, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000070, mae: 0.004638, mean_q: 0.004593
 90739/100000: episode: 9336, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000035, mae: 0.005393, mean_q: 0.006939
 90749/100000: episode: 9337, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000024, mae: 0.002923, mean_q: 0.003810
 90759/100000: episode: 9338, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000053, mae: 0.004223, mean_q: 0.005390
 90769/100000: episode: 9339, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.002992, mean_q: 0.004395
 90779/100000: episode: 9340, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000020, mae: 0.002772, mean_q: 0.004138
 90789/100000: episode: 9341, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000026, mae: 0.004007, mean_q: 0.005494
 90799/100000: episode: 9342, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.002658, mean_q: 0.003782
 90809/100000: episode: 9343, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003420, mean_q: 0.005117
 90819/100000: episode: 9344, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000033, mae: 0.003369, mean_q: 0.004128
 90829/100000: episode: 9345, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000019, mae: 0.003205, mean_q: 0.004822
 90839/100000: episode: 9346, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000020, mae: 0.002785, mean_q: 0.003976
 90849/100000: episode: 9347, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000012, mae: 0.002481, mean_q: 0.004137
 90859/100000: episode: 9348, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000027, mae: 0.003425, mean_q: 0.004745
 90869/100000: episode: 9349, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000020, mae: 0.003128, mean_q: 0.004298
 90879/100000: episode: 9350, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000045, mae: 0.003107, mean_q: 0.004170
 90889/100000: episode: 9351, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000066, mae: 0.004623, mean_q: 0.005015
 90899/100000: episode: 9352, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000014, mae: 0.003399, mean_q: 0.005485
 90909/100000: episode: 9353, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.002777, mean_q: 0.003301
 90919/100000: episode: 9354, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000085, mae: 0.005621, mean_q: 0.006351
 90929/100000: episode: 9355, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003050, mean_q: 0.004057
 90939/100000: episode: 9356, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.003213, mean_q: 0.004251
 90949/100000: episode: 9357, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000026, mae: 0.003861, mean_q: 0.005088
 90959/100000: episode: 9358, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000024, mae: 0.002794, mean_q: 0.003920
 90969/100000: episode: 9359, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000028, mae: 0.003630, mean_q: 0.004817
 90979/100000: episode: 9360, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000047, mae: 0.003030, mean_q: 0.004019
 90989/100000: episode: 9361, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003323, mean_q: 0.004591
 90999/100000: episode: 9362, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000030, mae: 0.003362, mean_q: 0.004477
 91009/100000: episode: 9363, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000025, mae: 0.003264, mean_q: 0.004343
 91019/100000: episode: 9364, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000071, mae: 0.003707, mean_q: 0.004793
 91029/100000: episode: 9365, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002810, mean_q: 0.004164
 91039/100000: episode: 9366, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000021, mae: 0.003101, mean_q: 0.004465
 91049/100000: episode: 9367, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003317, mean_q: 0.004481
 91059/100000: episode: 9368, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000080, mae: 0.004599, mean_q: 0.005329
 91069/100000: episode: 9369, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000011, mae: 0.002198, mean_q: 0.003968
 91079/100000: episode: 9370, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000018, mae: 0.002648, mean_q: 0.003524
 91089/100000: episode: 9371, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000031, mae: 0.003609, mean_q: 0.004565
 91099/100000: episode: 9372, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000077, mae: 0.004722, mean_q: 0.005481
 91109/100000: episode: 9373, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002797, mean_q: 0.004443
 91119/100000: episode: 9374, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000036, mae: 0.003408, mean_q: 0.003779
 91129/100000: episode: 9375, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000032, mae: 0.004397, mean_q: 0.005728
 91139/100000: episode: 9376, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000030, mae: 0.003680, mean_q: 0.004647
 91149/100000: episode: 9377, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000079, mae: 0.004303, mean_q: 0.005092
 91159/100000: episode: 9378, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000026, mae: 0.003370, mean_q: 0.004580
 91169/100000: episode: 9379, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003285, mean_q: 0.004265
 91179/100000: episode: 9380, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000021, mae: 0.003473, mean_q: 0.005043
 91189/100000: episode: 9381, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.003006, mean_q: 0.003831
 91199/100000: episode: 9382, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000027, mae: 0.003138, mean_q: 0.004200
 91209/100000: episode: 9383, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000070, mae: 0.003878, mean_q: 0.004679
 91219/100000: episode: 9384, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.003279, mean_q: 0.004896
 91229/100000: episode: 9385, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000051, mae: 0.003689, mean_q: 0.004263
 91239/100000: episode: 9386, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000030, mae: 0.003397, mean_q: 0.004392
 91249/100000: episode: 9387, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003313, mean_q: 0.004741
 91259/100000: episode: 9388, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000040, mae: 0.002929, mean_q: 0.003592
 91269/100000: episode: 9389, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002776, mean_q: 0.004371
 91279/100000: episode: 9390, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000085, mae: 0.004498, mean_q: 0.004629
 91289/100000: episode: 9391, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000076, mae: 0.004758, mean_q: 0.005841
 91299/100000: episode: 9392, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000012, mae: 0.002435, mean_q: 0.003726
 91309/100000: episode: 9393, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000029, mae: 0.003705, mean_q: 0.004746
 91319/100000: episode: 9394, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000054, mae: 0.004121, mean_q: 0.004997
 91329/100000: episode: 9395, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000066, mae: 0.003411, mean_q: 0.004278
 91339/100000: episode: 9396, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000090, mae: 0.004084, mean_q: 0.005048
 91349/100000: episode: 9397, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000040, mae: 0.004594, mean_q: 0.005532
 91359/100000: episode: 9398, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.002915, mean_q: 0.004177
 91369/100000: episode: 9399, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003186, mean_q: 0.004355
 91379/100000: episode: 9400, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000017, mae: 0.002694, mean_q: 0.004104
 91389/100000: episode: 9401, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000012, mae: 0.002541, mean_q: 0.003768
 91399/100000: episode: 9402, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003476, mean_q: 0.004836
 91409/100000: episode: 9403, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000023, mae: 0.002622, mean_q: 0.003769
 91419/100000: episode: 9404, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000016, mae: 0.002425, mean_q: 0.003807
 91429/100000: episode: 9405, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000041, mae: 0.003365, mean_q: 0.004727
 91439/100000: episode: 9406, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000077, mae: 0.003912, mean_q: 0.004280
 91449/100000: episode: 9407, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.004000, mean_q: 0.005603
 91459/100000: episode: 9408, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000020, mae: 0.002706, mean_q: 0.003750
 91469/100000: episode: 9409, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.002823, mean_q: 0.003804
[Info] 1-TH LEVEL FOUND: 0.004742220975458622, Considering 100/100 traces
 91479/100000: episode: 9410, duration: 0.701s, episode steps: 10, steps per second: 14, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000050, mae: 0.003940, mean_q: 0.004851
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004742220975458622
 91489/100000: episode: 9411, duration: 0.577s, episode steps: 10, steps per second: 17, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002614, mean_q: 0.003975
 91499/100000: episode: 9412, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000046, mae: 0.003071, mean_q: 0.003673
 91509/100000: episode: 9413, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000024, mae: 0.003616, mean_q: 0.004907
 91519/100000: episode: 9414, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.002410, mean_q: 0.002916
 91529/100000: episode: 9415, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000025, mae: 0.003370, mean_q: 0.004481
 91539/100000: episode: 9416, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000025, mae: 0.003576, mean_q: 0.004754
 91549/100000: episode: 9417, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000078, mae: 0.004000, mean_q: 0.004131
 91559/100000: episode: 9418, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000012, mae: 0.003328, mean_q: 0.005096
 91569/100000: episode: 9419, duration: 0.046s, episode steps: 10, steps per second: 220, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000052, mae: 0.003556, mean_q: 0.004235
 91579/100000: episode: 9420, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000014, mae: 0.002622, mean_q: 0.004103
 91589/100000: episode: 9421, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000046, mae: 0.003188, mean_q: 0.003961
 91599/100000: episode: 9422, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000024, mae: 0.003383, mean_q: 0.004735
 91609/100000: episode: 9423, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000076, mae: 0.004322, mean_q: 0.004961
 91619/100000: episode: 9424, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000033, mae: 0.004027, mean_q: 0.005020
 91629/100000: episode: 9425, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000039, mae: 0.003227, mean_q: 0.004338
 91639/100000: episode: 9426, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000018, mae: 0.002837, mean_q: 0.003964
 91649/100000: episode: 9427, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.003043, mean_q: 0.004343
 91659/100000: episode: 9428, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000011, mae: 0.002557, mean_q: 0.004019
 91669/100000: episode: 9429, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.002952, mean_q: 0.003856
 91679/100000: episode: 9430, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000084, mae: 0.004898, mean_q: 0.005366
 91689/100000: episode: 9431, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000021, mae: 0.003567, mean_q: 0.005082
 91699/100000: episode: 9432, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000027, mae: 0.003110, mean_q: 0.003683
 91709/100000: episode: 9433, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000046, mae: 0.003840, mean_q: 0.005090
 91719/100000: episode: 9434, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000042, mae: 0.003233, mean_q: 0.004376
 91729/100000: episode: 9435, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000041, mae: 0.002890, mean_q: 0.003913
 91739/100000: episode: 9436, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002928, mean_q: 0.004199
 91749/100000: episode: 9437, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000018, mae: 0.003018, mean_q: 0.004358
 91759/100000: episode: 9438, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.002686, mean_q: 0.003888
 91769/100000: episode: 9439, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000041, mae: 0.002970, mean_q: 0.003944
 91779/100000: episode: 9440, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.003076, mean_q: 0.004055
 91789/100000: episode: 9441, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000023, mae: 0.003571, mean_q: 0.004716
 91799/100000: episode: 9442, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000053, mae: 0.004253, mean_q: 0.005077
 91809/100000: episode: 9443, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000027, mae: 0.003016, mean_q: 0.003893
 91819/100000: episode: 9444, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000024, mae: 0.003479, mean_q: 0.004939
 91829/100000: episode: 9445, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000161, mae: 0.005476, mean_q: 0.004579
 91839/100000: episode: 9446, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000126, mae: 0.006709, mean_q: 0.007579
 91849/100000: episode: 9447, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000082, mae: 0.003707, mean_q: 0.003521
 91859/100000: episode: 9448, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000072, mae: 0.005011, mean_q: 0.006170
 91869/100000: episode: 9449, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000023, mae: 0.003609, mean_q: 0.004954
 91879/100000: episode: 9450, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000022, mae: 0.002769, mean_q: 0.003952
 91889/100000: episode: 9451, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000053, mae: 0.004055, mean_q: 0.004972
 91899/100000: episode: 9452, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000063, mae: 0.004381, mean_q: 0.005075
 91909/100000: episode: 9453, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000021, mae: 0.003308, mean_q: 0.004893
 91919/100000: episode: 9454, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002860, mean_q: 0.004197
 91929/100000: episode: 9455, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000044, mae: 0.003590, mean_q: 0.004610
 91939/100000: episode: 9456, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000006, mae: 0.002325, mean_q: 0.004477
 91949/100000: episode: 9457, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000060, mae: 0.003813, mean_q: 0.004168
 91959/100000: episode: 9458, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000039, mae: 0.003921, mean_q: 0.005586
 91969/100000: episode: 9459, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000089, mae: 0.004180, mean_q: 0.003857
 91979/100000: episode: 9460, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000084, mae: 0.005447, mean_q: 0.006192
 91989/100000: episode: 9461, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000053, mae: 0.003988, mean_q: 0.004802
 91999/100000: episode: 9462, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000047, mae: 0.003688, mean_q: 0.004820
 92009/100000: episode: 9463, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000084, mae: 0.005087, mean_q: 0.005830
 92019/100000: episode: 9464, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000071, mae: 0.004459, mean_q: 0.005559
 92029/100000: episode: 9465, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000028, mae: 0.003377, mean_q: 0.004090
 92039/100000: episode: 9466, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.004216, mean_q: 0.005763
 92049/100000: episode: 9467, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.003430, mean_q: 0.004512
 92059/100000: episode: 9468, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000047, mae: 0.003700, mean_q: 0.004786
 92069/100000: episode: 9469, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000050, mae: 0.003464, mean_q: 0.004510
 92079/100000: episode: 9470, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000092, mae: 0.004548, mean_q: 0.005608
 92089/100000: episode: 9471, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000050, mae: 0.003838, mean_q: 0.004981
 92099/100000: episode: 9472, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000079, mae: 0.004402, mean_q: 0.005273
 92109/100000: episode: 9473, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000013, mae: 0.002914, mean_q: 0.004865
 92119/100000: episode: 9474, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000095, mae: 0.004709, mean_q: 0.004454
 92129/100000: episode: 9475, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000019, mae: 0.003788, mean_q: 0.005898
 92139/100000: episode: 9476, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000023, mae: 0.002430, mean_q: 0.003623
 92149/100000: episode: 9477, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003475, mean_q: 0.004663
 92159/100000: episode: 9478, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000055, mae: 0.004280, mean_q: 0.005044
 92169/100000: episode: 9479, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000083, mae: 0.005173, mean_q: 0.006189
 92179/100000: episode: 9480, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000033, mae: 0.003402, mean_q: 0.004214
 92189/100000: episode: 9481, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000067, mae: 0.005590, mean_q: 0.006443
 92199/100000: episode: 9482, duration: 0.063s, episode steps: 10, steps per second: 160, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000025, mae: 0.003245, mean_q: 0.004196
 92209/100000: episode: 9483, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000231, mae: 0.004797, mean_q: 0.005085
 92219/100000: episode: 9484, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000053, mae: 0.004878, mean_q: 0.006624
 92229/100000: episode: 9485, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000020, mae: 0.002214, mean_q: 0.003153
 92239/100000: episode: 9486, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000043, mae: 0.003485, mean_q: 0.004929
 92249/100000: episode: 9487, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000011, mae: 0.002574, mean_q: 0.004211
 92259/100000: episode: 9488, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000234, mae: 0.004975, mean_q: 0.005317
 92269/100000: episode: 9489, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000043, mae: 0.003402, mean_q: 0.004657
 92279/100000: episode: 9490, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000022, mae: 0.003032, mean_q: 0.004437
 92289/100000: episode: 9491, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000051, mae: 0.003988, mean_q: 0.004998
 92299/100000: episode: 9492, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000224, mae: 0.005150, mean_q: 0.006267
 92309/100000: episode: 9493, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000028, mae: 0.003425, mean_q: 0.004857
 92319/100000: episode: 9494, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000049, mae: 0.003448, mean_q: 0.004481
 92329/100000: episode: 9495, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000259, mae: 0.006546, mean_q: 0.007113
 92339/100000: episode: 9496, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000077, mae: 0.005940, mean_q: 0.007487
 92349/100000: episode: 9497, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.003533, mean_q: 0.004526
 92359/100000: episode: 9498, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000232, mae: 0.004609, mean_q: 0.005443
 92369/100000: episode: 9499, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000044, mae: 0.003860, mean_q: 0.005398
 92379/100000: episode: 9500, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000045, mae: 0.003073, mean_q: 0.004200
 92389/100000: episode: 9501, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.003375, mean_q: 0.005514
 92399/100000: episode: 9502, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000060, mae: 0.004094, mean_q: 0.004825
 92409/100000: episode: 9503, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000040, mae: 0.003343, mean_q: 0.004809
 92419/100000: episode: 9504, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003159, mean_q: 0.004327
 92429/100000: episode: 9505, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000223, mae: 0.004782, mean_q: 0.005585
 92439/100000: episode: 9506, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000051, mae: 0.004024, mean_q: 0.005126
 92449/100000: episode: 9507, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000025, mae: 0.003388, mean_q: 0.005088
 92459/100000: episode: 9508, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000059, mae: 0.004152, mean_q: 0.004779
 92469/100000: episode: 9509, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000014, mae: 0.003044, mean_q: 0.005043
 92479/100000: episode: 9510, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003450, mean_q: 0.004600
[Info] 1-TH LEVEL FOUND: 0.005679869093000889, Considering 100/100 traces
 92489/100000: episode: 9511, duration: 0.727s, episode steps: 10, steps per second: 14, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000054, mae: 0.004079, mean_q: 0.005211
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005679869093000889
 92499/100000: episode: 9512, duration: 0.499s, episode steps: 10, steps per second: 20, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000017, mae: 0.002680, mean_q: 0.004339
 92509/100000: episode: 9513, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000013, mae: 0.002634, mean_q: 0.004093
 92519/100000: episode: 9514, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000012, mae: 0.002558, mean_q: 0.004427
 92529/100000: episode: 9515, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000049, mae: 0.003252, mean_q: 0.004026
 92539/100000: episode: 9516, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000018, mae: 0.003379, mean_q: 0.005146
 92549/100000: episode: 9517, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000052, mae: 0.003648, mean_q: 0.004786
 92559/100000: episode: 9518, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000062, mae: 0.003083, mean_q: 0.004239
 92569/100000: episode: 9519, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000029, mae: 0.003744, mean_q: 0.005034
 92579/100000: episode: 9520, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000273, mae: 0.006050, mean_q: 0.005623
 92589/100000: episode: 9521, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000518, mae: 0.009751, mean_q: 0.008839
 92599/100000: episode: 9522, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000044, mae: 0.003806, mean_q: 0.005362
 92609/100000: episode: 9523, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.002745, mean_q: 0.003779
 92619/100000: episode: 9524, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000232, mae: 0.004983, mean_q: 0.005517
 92629/100000: episode: 9525, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000081, mae: 0.005347, mean_q: 0.006420
 92639/100000: episode: 9526, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.003516, mean_q: 0.005139
 92649/100000: episode: 9527, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000045, mae: 0.003190, mean_q: 0.004564
 92659/100000: episode: 9528, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000065, mae: 0.004637, mean_q: 0.005199
 92669/100000: episode: 9529, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000069, mae: 0.004324, mean_q: 0.005998
 92679/100000: episode: 9530, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.035, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000019, mae: 0.003320, mean_q: 0.005036
 92689/100000: episode: 9531, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000072, mae: 0.003666, mean_q: 0.004283
 92699/100000: episode: 9532, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000042, mae: 0.004052, mean_q: 0.006059
 92709/100000: episode: 9533, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000026, mae: 0.003382, mean_q: 0.004129
 92719/100000: episode: 9534, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000236, mae: 0.005342, mean_q: 0.005718
 92729/100000: episode: 9535, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000289, mae: 0.007361, mean_q: 0.007600
 92739/100000: episode: 9536, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000247, mae: 0.004703, mean_q: 0.005638
 92749/100000: episode: 9537, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000042, mae: 0.003086, mean_q: 0.004709
 92759/100000: episode: 9538, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000037, mae: 0.003089, mean_q: 0.004739
 92769/100000: episode: 9539, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000056, mae: 0.003474, mean_q: 0.004127
 92779/100000: episode: 9540, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000085, mae: 0.005569, mean_q: 0.006621
 92789/100000: episode: 9541, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000023, mae: 0.003481, mean_q: 0.004930
 92799/100000: episode: 9542, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000036, mae: 0.003525, mean_q: 0.004400
 92809/100000: episode: 9543, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000051, mae: 0.003943, mean_q: 0.005426
 92819/100000: episode: 9544, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000024, mae: 0.003251, mean_q: 0.004693
 92829/100000: episode: 9545, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000058, mae: 0.003946, mean_q: 0.004952
 92839/100000: episode: 9546, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.003241, mean_q: 0.005212
 92849/100000: episode: 9547, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000032, mae: 0.003137, mean_q: 0.004098
 92859/100000: episode: 9548, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000064, mae: 0.004848, mean_q: 0.005754
 92869/100000: episode: 9549, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000086, mae: 0.004979, mean_q: 0.005929
 92879/100000: episode: 9550, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000224, mae: 0.004498, mean_q: 0.005051
 92889/100000: episode: 9551, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000023, mae: 0.003532, mean_q: 0.005225
 92899/100000: episode: 9552, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000053, mae: 0.004044, mean_q: 0.005275
 92909/100000: episode: 9553, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002773, mean_q: 0.004428
 92919/100000: episode: 9554, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000018, mae: 0.002744, mean_q: 0.004089
 92929/100000: episode: 9555, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003768, mean_q: 0.005245
 92939/100000: episode: 9556, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000071, mae: 0.004199, mean_q: 0.005284
 92949/100000: episode: 9557, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000018, mae: 0.002777, mean_q: 0.004084
 92959/100000: episode: 9558, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000016, mae: 0.002795, mean_q: 0.004527
 92969/100000: episode: 9559, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000048, mae: 0.003342, mean_q: 0.004338
 92979/100000: episode: 9560, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000022, mae: 0.003127, mean_q: 0.004396
 92989/100000: episode: 9561, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000010, mae: 0.002690, mean_q: 0.004796
 92999/100000: episode: 9562, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000063, mae: 0.004316, mean_q: 0.004526
 93009/100000: episode: 9563, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000020, mae: 0.003914, mean_q: 0.005688
 93019/100000: episode: 9564, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000011, mae: 0.002288, mean_q: 0.003745
 93029/100000: episode: 9565, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000072, mae: 0.003783, mean_q: 0.004796
 93039/100000: episode: 9566, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000039, mae: 0.003449, mean_q: 0.005067
 93049/100000: episode: 9567, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000026, mae: 0.003227, mean_q: 0.004299
 93059/100000: episode: 9568, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000075, mae: 0.004455, mean_q: 0.005550
 93069/100000: episode: 9569, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000134, mae: 0.005909, mean_q: 0.006182
 93079/100000: episode: 9570, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000042, mae: 0.003168, mean_q: 0.004512
 93089/100000: episode: 9571, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000009, mae: 0.002132, mean_q: 0.003815
 93099/100000: episode: 9572, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000046, mae: 0.003251, mean_q: 0.004121
 93109/100000: episode: 9573, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.003634, mean_q: 0.005233
 93119/100000: episode: 9574, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000046, mae: 0.003306, mean_q: 0.004450
 93129/100000: episode: 9575, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000046, mae: 0.003832, mean_q: 0.005081
 93139/100000: episode: 9576, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000064, mae: 0.004825, mean_q: 0.005463
 93149/100000: episode: 9577, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000029, mae: 0.003817, mean_q: 0.005237
 93159/100000: episode: 9578, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000074, mae: 0.003825, mean_q: 0.004333
 93169/100000: episode: 9579, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000042, mae: 0.003959, mean_q: 0.005666
 93179/100000: episode: 9580, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000083, mae: 0.004030, mean_q: 0.004429
 93189/100000: episode: 9581, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000225, mae: 0.004349, mean_q: 0.005050
 93199/100000: episode: 9582, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000065, mae: 0.004109, mean_q: 0.005614
 93209/100000: episode: 9583, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000010, mae: 0.002363, mean_q: 0.003907
 93219/100000: episode: 9584, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000021, mae: 0.002701, mean_q: 0.003863
 93229/100000: episode: 9585, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000011, mae: 0.002840, mean_q: 0.004688
 93239/100000: episode: 9586, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000028, mae: 0.003415, mean_q: 0.004614
 93249/100000: episode: 9587, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000050, mae: 0.003630, mean_q: 0.004523
 93259/100000: episode: 9588, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000024, mae: 0.003495, mean_q: 0.005000
 93269/100000: episode: 9589, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.002301, mean_q: 0.003285
 93279/100000: episode: 9590, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003184, mean_q: 0.004583
 93289/100000: episode: 9591, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000232, mae: 0.005324, mean_q: 0.005774
 93299/100000: episode: 9592, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000065, mae: 0.003941, mean_q: 0.005299
 93309/100000: episode: 9593, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000064, mae: 0.002955, mean_q: 0.003550
 93319/100000: episode: 9594, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000031, mae: 0.003808, mean_q: 0.005031
 93329/100000: episode: 9595, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000039, mae: 0.003533, mean_q: 0.005069
 93339/100000: episode: 9596, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000018, mae: 0.002481, mean_q: 0.003584
 93349/100000: episode: 9597, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000019, mae: 0.002945, mean_q: 0.004272
 93359/100000: episode: 9598, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000045, mae: 0.003429, mean_q: 0.004558
 93369/100000: episode: 9599, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000231, mae: 0.004897, mean_q: 0.005195
 93379/100000: episode: 9600, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000042, mae: 0.005136, mean_q: 0.006085
 93389/100000: episode: 9601, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000027, mae: 0.003386, mean_q: 0.004737
 93399/100000: episode: 9602, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000034, mae: 0.003737, mean_q: 0.004581
 93409/100000: episode: 9603, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000052, mae: 0.004500, mean_q: 0.005716
 93419/100000: episode: 9604, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002809, mean_q: 0.004419
 93429/100000: episode: 9605, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000053, mae: 0.003461, mean_q: 0.003932
 93439/100000: episode: 9606, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000076, mae: 0.004346, mean_q: 0.004984
 93449/100000: episode: 9607, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000249, mae: 0.005063, mean_q: 0.005327
 93459/100000: episode: 9608, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000051, mae: 0.004884, mean_q: 0.006327
 93469/100000: episode: 9609, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000047, mae: 0.003282, mean_q: 0.004478
 93479/100000: episode: 9610, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000044, mae: 0.003778, mean_q: 0.005003
 93489/100000: episode: 9611, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000052, mae: 0.003862, mean_q: 0.004925
[Info] 1-TH LEVEL FOUND: 0.004669679328799248, Considering 100/100 traces
 93499/100000: episode: 9612, duration: 0.739s, episode steps: 10, steps per second: 14, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000044, mae: 0.003404, mean_q: 0.004326
[Info] 2-TH LEVEL FOUND: 0.005213423632085323, Considering 100/100 traces
 93509/100000: episode: 9613, duration: 1.151s, episode steps: 10, steps per second: 9, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000050, mae: 0.003796, mean_q: 0.004762
[Info] 3-TH LEVEL FOUND: 0.005450504831969738, Considering 100/100 traces
 93519/100000: episode: 9614, duration: 0.800s, episode steps: 10, steps per second: 13, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000040, mae: 0.004702, mean_q: 0.005753
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005450504831969738
 93529/100000: episode: 9615, duration: 0.533s, episode steps: 10, steps per second: 19, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002652, mean_q: 0.004278
 93539/100000: episode: 9616, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000253, mae: 0.005068, mean_q: 0.005401
 93549/100000: episode: 9617, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000082, mae: 0.005583, mean_q: 0.006611
 93559/100000: episode: 9618, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000027, mae: 0.003540, mean_q: 0.004637
 93569/100000: episode: 9619, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000231, mae: 0.004851, mean_q: 0.005552
 93579/100000: episode: 9620, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000054, mae: 0.004639, mean_q: 0.006097
 93589/100000: episode: 9621, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000263, mae: 0.005199, mean_q: 0.004911
 93599/100000: episode: 9622, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000051, mae: 0.005074, mean_q: 0.006893
 93609/100000: episode: 9623, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000071, mae: 0.003452, mean_q: 0.004308
 93619/100000: episode: 9624, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000257, mae: 0.005932, mean_q: 0.006594
 93629/100000: episode: 9625, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000042, mae: 0.003323, mean_q: 0.004891
 93639/100000: episode: 9626, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000014, mae: 0.002671, mean_q: 0.004299
 93649/100000: episode: 9627, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000017, mae: 0.002611, mean_q: 0.004282
 93659/100000: episode: 9628, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000044, mae: 0.003211, mean_q: 0.004682
 93669/100000: episode: 9629, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000047, mae: 0.003642, mean_q: 0.004875
 93679/100000: episode: 9630, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000263, mae: 0.006005, mean_q: 0.006088
 93689/100000: episode: 9631, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000049, mae: 0.004433, mean_q: 0.006190
 93699/100000: episode: 9632, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000238, mae: 0.004777, mean_q: 0.005127
 93709/100000: episode: 9633, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000230, mae: 0.004932, mean_q: 0.005968
 93719/100000: episode: 9634, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.003067, mean_q: 0.005090
 93729/100000: episode: 9635, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000021, mae: 0.002801, mean_q: 0.004213
 93739/100000: episode: 9636, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000053, mae: 0.003729, mean_q: 0.004779
 93749/100000: episode: 9637, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000030, mae: 0.003736, mean_q: 0.004991
 93759/100000: episode: 9638, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000095, mae: 0.004454, mean_q: 0.005265
 93769/100000: episode: 9639, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000117, mae: 0.005551, mean_q: 0.005478
 93779/100000: episode: 9640, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000051, mae: 0.004590, mean_q: 0.006036
 93789/100000: episode: 9641, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000018, mae: 0.002599, mean_q: 0.003991
 93799/100000: episode: 9642, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000045, mae: 0.003151, mean_q: 0.004426
 93809/100000: episode: 9643, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000046, mae: 0.003721, mean_q: 0.005111
 93819/100000: episode: 9644, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000009, mae: 0.002151, mean_q: 0.004001
 93829/100000: episode: 9645, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000080, mae: 0.003792, mean_q: 0.004035
 93839/100000: episode: 9646, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000047, mae: 0.004840, mean_q: 0.006624
 93849/100000: episode: 9647, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000054, mae: 0.003866, mean_q: 0.004743
 93859/100000: episode: 9648, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000041, mae: 0.003164, mean_q: 0.004490
 93869/100000: episode: 9649, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000056, mae: 0.003719, mean_q: 0.004490
 93879/100000: episode: 9650, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000068, mae: 0.004394, mean_q: 0.005584
 93889/100000: episode: 9651, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000052, mae: 0.004066, mean_q: 0.004716
 93899/100000: episode: 9652, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000020, mae: 0.002952, mean_q: 0.004558
 93909/100000: episode: 9653, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000011, mae: 0.002286, mean_q: 0.003754
 93919/100000: episode: 9654, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.098, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000035, mae: 0.003475, mean_q: 0.004176
 93929/100000: episode: 9655, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000013, mae: 0.003623, mean_q: 0.005736
 93939/100000: episode: 9656, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000252, mae: 0.004907, mean_q: 0.004919
 93949/100000: episode: 9657, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000025, mae: 0.003852, mean_q: 0.005392
 93959/100000: episode: 9658, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000030, mae: 0.003087, mean_q: 0.003691
 93969/100000: episode: 9659, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000235, mae: 0.005809, mean_q: 0.006255
 93979/100000: episode: 9660, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000073, mae: 0.005458, mean_q: 0.006793
 93989/100000: episode: 9661, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000047, mae: 0.003271, mean_q: 0.004845
 93999/100000: episode: 9662, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000024, mae: 0.003412, mean_q: 0.004600
 94009/100000: episode: 9663, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000030, mae: 0.003759, mean_q: 0.005131
 94019/100000: episode: 9664, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000052, mae: 0.004026, mean_q: 0.004917
 94029/100000: episode: 9665, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000043, mae: 0.004038, mean_q: 0.005674
 94039/100000: episode: 9666, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000021, mae: 0.003307, mean_q: 0.004911
 94049/100000: episode: 9667, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000053, mae: 0.003783, mean_q: 0.004557
 94059/100000: episode: 9668, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000024, mae: 0.003694, mean_q: 0.005537
 94069/100000: episode: 9669, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000044, mae: 0.002894, mean_q: 0.004092
 94079/100000: episode: 9670, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000015, mae: 0.002916, mean_q: 0.004603
 94089/100000: episode: 9671, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000080, mae: 0.004266, mean_q: 0.004959
 94099/100000: episode: 9672, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000041, mae: 0.003437, mean_q: 0.005046
 94109/100000: episode: 9673, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000013, mae: 0.002184, mean_q: 0.003701
 94119/100000: episode: 9674, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000044, mae: 0.003521, mean_q: 0.004648
 94129/100000: episode: 9675, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000027, mae: 0.003460, mean_q: 0.004331
 94139/100000: episode: 9676, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000025, mae: 0.003500, mean_q: 0.005046
 94149/100000: episode: 9677, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.002986, mean_q: 0.004387
 94159/100000: episode: 9678, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000283, mae: 0.005352, mean_q: 0.004984
 94169/100000: episode: 9679, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000018, mae: 0.003739, mean_q: 0.005905
 94179/100000: episode: 9680, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000040, mae: 0.002777, mean_q: 0.003574
 94189/100000: episode: 9681, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000052, mae: 0.004126, mean_q: 0.005345
 94199/100000: episode: 9682, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000015, mae: 0.002440, mean_q: 0.003983
 94209/100000: episode: 9683, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000010, mae: 0.002184, mean_q: 0.003434
 94219/100000: episode: 9684, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000014, mae: 0.002723, mean_q: 0.004155
 94229/100000: episode: 9685, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000245, mae: 0.006341, mean_q: 0.006676
 94239/100000: episode: 9686, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000014, mae: 0.002755, mean_q: 0.004081
 94249/100000: episode: 9687, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000228, mae: 0.004097, mean_q: 0.004544
 94259/100000: episode: 9688, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000430, mae: 0.006706, mean_q: 0.006677
 94269/100000: episode: 9689, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000015, mae: 0.002910, mean_q: 0.004514
 94279/100000: episode: 9690, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000015, mae: 0.002316, mean_q: 0.003291
 94289/100000: episode: 9691, duration: 0.105s, episode steps: 10, steps per second: 95, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000042, mae: 0.003617, mean_q: 0.005096
 94299/100000: episode: 9692, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000222, mae: 0.004037, mean_q: 0.004467
 94309/100000: episode: 9693, duration: 0.062s, episode steps: 10, steps per second: 163, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000013, mae: 0.003496, mean_q: 0.005389
 94319/100000: episode: 9694, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000054, mae: 0.003584, mean_q: 0.004111
 94329/100000: episode: 9695, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000072, mae: 0.004576, mean_q: 0.005774
 94339/100000: episode: 9696, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000018, mae: 0.002531, mean_q: 0.003728
 94349/100000: episode: 9697, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000024, mae: 0.003018, mean_q: 0.004079
 94359/100000: episode: 9698, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000041, mae: 0.003771, mean_q: 0.005367
 94369/100000: episode: 9699, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000016, mae: 0.002428, mean_q: 0.003861
 94379/100000: episode: 9700, duration: 0.066s, episode steps: 10, steps per second: 150, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000050, mae: 0.003640, mean_q: 0.004449
 94389/100000: episode: 9701, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000226, mae: 0.005263, mean_q: 0.006103
 94399/100000: episode: 9702, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000254, mae: 0.004734, mean_q: 0.004984
 94409/100000: episode: 9703, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000019, mae: 0.003701, mean_q: 0.005619
 94419/100000: episode: 9704, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000140, mae: 0.005831, mean_q: 0.005636
 94429/100000: episode: 9705, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000049, mae: 0.004886, mean_q: 0.006533
 94439/100000: episode: 9706, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000026, mae: 0.002974, mean_q: 0.004138
 94449/100000: episode: 9707, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000056, mae: 0.004042, mean_q: 0.005065
 94459/100000: episode: 9708, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000052, mae: 0.004204, mean_q: 0.005530
 94469/100000: episode: 9709, duration: 0.116s, episode steps: 10, steps per second: 86, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000070, mae: 0.003667, mean_q: 0.004628
 94479/100000: episode: 9710, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000066, mae: 0.004217, mean_q: 0.005766
 94489/100000: episode: 9711, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000029, mae: 0.003289, mean_q: 0.004482
 94499/100000: episode: 9712, duration: 0.064s, episode steps: 10, steps per second: 156, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000250, mae: 0.005758, mean_q: 0.005581
 94509/100000: episode: 9713, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000075, mae: 0.004490, mean_q: 0.005713
 94519/100000: episode: 9714, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000022, mae: 0.003259, mean_q: 0.004845
[Info] 1-TH LEVEL FOUND: 0.00449562631547451, Considering 100/100 traces
 94529/100000: episode: 9715, duration: 0.761s, episode steps: 10, steps per second: 13, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003370, mean_q: 0.005012
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.00449562631547451
 94539/100000: episode: 9716, duration: 0.520s, episode steps: 10, steps per second: 19, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000018, mae: 0.002928, mean_q: 0.004539
 94549/100000: episode: 9717, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000051, mae: 0.003799, mean_q: 0.004773
 94559/100000: episode: 9718, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000017, mae: 0.003038, mean_q: 0.004968
 94569/100000: episode: 9719, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000026, mae: 0.003572, mean_q: 0.004305
 94579/100000: episode: 9720, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000030, mae: 0.003986, mean_q: 0.005246
 94589/100000: episode: 9721, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.003261, mean_q: 0.004650
 94599/100000: episode: 9722, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000013, mae: 0.002516, mean_q: 0.004210
 94609/100000: episode: 9723, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000099, mae: 0.004234, mean_q: 0.004524
 94619/100000: episode: 9724, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.003933, mean_q: 0.005912
 94629/100000: episode: 9725, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000051, mae: 0.003548, mean_q: 0.004189
 94639/100000: episode: 9726, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000083, mae: 0.004640, mean_q: 0.005270
 94649/100000: episode: 9727, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000250, mae: 0.005037, mean_q: 0.005658
 94659/100000: episode: 9728, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000260, mae: 0.005540, mean_q: 0.005367
 94669/100000: episode: 9729, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000231, mae: 0.005889, mean_q: 0.006837
 94679/100000: episode: 9730, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000038, mae: 0.004222, mean_q: 0.005566
 94689/100000: episode: 9731, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000227, mae: 0.004225, mean_q: 0.004976
 94699/100000: episode: 9732, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.004165, mean_q: 0.006093
 94709/100000: episode: 9733, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000014, mae: 0.002665, mean_q: 0.004355
 94719/100000: episode: 9734, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000041, mae: 0.002630, mean_q: 0.003858
 94729/100000: episode: 9735, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000240, mae: 0.004747, mean_q: 0.004928
 94739/100000: episode: 9736, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000249, mae: 0.005643, mean_q: 0.006414
 94749/100000: episode: 9737, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000066, mae: 0.004171, mean_q: 0.005849
 94759/100000: episode: 9738, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000039, mae: 0.002860, mean_q: 0.004565
 94769/100000: episode: 9739, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000042, mae: 0.003050, mean_q: 0.004388
 94779/100000: episode: 9740, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000030, mae: 0.003684, mean_q: 0.004844
 94789/100000: episode: 9741, duration: 0.058s, episode steps: 10, steps per second: 174, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000018, mae: 0.003028, mean_q: 0.004609
 94799/100000: episode: 9742, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.002728, mean_q: 0.003997
 94809/100000: episode: 9743, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000022, mae: 0.003412, mean_q: 0.004927
 94819/100000: episode: 9744, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000079, mae: 0.004151, mean_q: 0.004953
 94829/100000: episode: 9745, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003209, mean_q: 0.004839
 94839/100000: episode: 9746, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000028, mae: 0.003420, mean_q: 0.004513
 94849/100000: episode: 9747, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000049, mae: 0.003719, mean_q: 0.005090
 94859/100000: episode: 9748, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000046, mae: 0.003481, mean_q: 0.004741
 94869/100000: episode: 9749, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000056, mae: 0.003938, mean_q: 0.004834
 94879/100000: episode: 9750, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000066, mae: 0.003959, mean_q: 0.005139
 94889/100000: episode: 9751, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000052, mae: 0.003957, mean_q: 0.005117
 94899/100000: episode: 9752, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000039, mae: 0.002862, mean_q: 0.003999
 94909/100000: episode: 9753, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000018, mae: 0.003045, mean_q: 0.004624
 94919/100000: episode: 9754, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000017, mae: 0.002691, mean_q: 0.004017
 94929/100000: episode: 9755, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000014, mae: 0.002994, mean_q: 0.004824
 94939/100000: episode: 9756, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000065, mae: 0.003306, mean_q: 0.004469
 94949/100000: episode: 9757, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000041, mae: 0.002831, mean_q: 0.003973
 94959/100000: episode: 9758, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000022, mae: 0.003145, mean_q: 0.004290
 94969/100000: episode: 9759, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003422, mean_q: 0.004461
 94979/100000: episode: 9760, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000050, mae: 0.004176, mean_q: 0.005301
 94989/100000: episode: 9761, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000023, mae: 0.003151, mean_q: 0.004366
 94999/100000: episode: 9762, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000018, mae: 0.002674, mean_q: 0.003784
 95009/100000: episode: 9763, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000076, mae: 0.004196, mean_q: 0.004859
 95019/100000: episode: 9764, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000042, mae: 0.004207, mean_q: 0.005632
 95029/100000: episode: 9765, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.003355, mean_q: 0.004869
 95039/100000: episode: 9766, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000022, mae: 0.002770, mean_q: 0.003651
 95049/100000: episode: 9767, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000022, mae: 0.003182, mean_q: 0.004358
 95059/100000: episode: 9768, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000262, mae: 0.006364, mean_q: 0.006810
 95069/100000: episode: 9769, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000075, mae: 0.004140, mean_q: 0.004891
 95079/100000: episode: 9770, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000014, mae: 0.002326, mean_q: 0.003621
 95089/100000: episode: 9771, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000037, mae: 0.002863, mean_q: 0.004463
 95099/100000: episode: 9772, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002660, mean_q: 0.004121
 95109/100000: episode: 9773, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000015, mae: 0.002815, mean_q: 0.004155
 95119/100000: episode: 9774, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000087, mae: 0.004373, mean_q: 0.004475
 95129/100000: episode: 9775, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000252, mae: 0.006373, mean_q: 0.007314
 95139/100000: episode: 9776, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000012, mae: 0.003338, mean_q: 0.005210
 95149/100000: episode: 9777, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000049, mae: 0.002779, mean_q: 0.003196
 95159/100000: episode: 9778, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000020, mae: 0.003439, mean_q: 0.005125
 95169/100000: episode: 9779, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000258, mae: 0.005442, mean_q: 0.005643
 95179/100000: episode: 9780, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000026, mae: 0.004218, mean_q: 0.005900
 95189/100000: episode: 9781, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000013, mae: 0.002549, mean_q: 0.003467
 95199/100000: episode: 9782, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000014, mae: 0.002798, mean_q: 0.004427
 95209/100000: episode: 9783, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000012, mae: 0.002983, mean_q: 0.005241
 95219/100000: episode: 9784, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000025, mae: 0.003317, mean_q: 0.004676
 95229/100000: episode: 9785, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000018, mae: 0.003005, mean_q: 0.004219
 95239/100000: episode: 9786, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000011, mae: 0.002272, mean_q: 0.003984
 95249/100000: episode: 9787, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000046, mae: 0.003355, mean_q: 0.004280
 95259/100000: episode: 9788, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000010, mae: 0.002847, mean_q: 0.004635
 95269/100000: episode: 9789, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000253, mae: 0.004803, mean_q: 0.004711
 95279/100000: episode: 9790, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.003894, mean_q: 0.005851
 95289/100000: episode: 9791, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000019, mae: 0.002403, mean_q: 0.003202
 95299/100000: episode: 9792, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000037, mae: 0.002827, mean_q: 0.004152
 95309/100000: episode: 9793, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.003100, mean_q: 0.004769
 95319/100000: episode: 9794, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000043, mae: 0.003211, mean_q: 0.004069
 95329/100000: episode: 9795, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000267, mae: 0.006074, mean_q: 0.005721
 95339/100000: episode: 9796, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.004624, mean_q: 0.006604
 95349/100000: episode: 9797, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000100, mae: 0.003614, mean_q: 0.003330
 95359/100000: episode: 9798, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000018, mae: 0.003559, mean_q: 0.005352
 95369/100000: episode: 9799, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000018, mae: 0.002934, mean_q: 0.004344
 95379/100000: episode: 9800, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000244, mae: 0.003797, mean_q: 0.003957
 95389/100000: episode: 9801, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000071, mae: 0.004837, mean_q: 0.005869
 95399/100000: episode: 9802, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000038, mae: 0.003624, mean_q: 0.005277
 95409/100000: episode: 9803, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000015, mae: 0.002385, mean_q: 0.003438
 95419/100000: episode: 9804, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000018, mae: 0.003089, mean_q: 0.004628
 95429/100000: episode: 9805, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000039, mae: 0.002601, mean_q: 0.003954
 95439/100000: episode: 9806, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002959, mean_q: 0.004140
 95449/100000: episode: 9807, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000052, mae: 0.003680, mean_q: 0.004596
 95459/100000: episode: 9808, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000224, mae: 0.004951, mean_q: 0.005742
 95469/100000: episode: 9809, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000010, mae: 0.002496, mean_q: 0.004218
 95479/100000: episode: 9810, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000019, mae: 0.002607, mean_q: 0.003544
 95489/100000: episode: 9811, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000012, mae: 0.002695, mean_q: 0.003974
 95499/100000: episode: 9812, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000240, mae: 0.004408, mean_q: 0.004038
 95509/100000: episode: 9813, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000041, mae: 0.004508, mean_q: 0.006399
 95519/100000: episode: 9814, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.002348, mean_q: 0.003252
 95529/100000: episode: 9815, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000222, mae: 0.003984, mean_q: 0.003950
[Info] 1-TH LEVEL FOUND: 0.004089679103344679, Considering 100/100 traces
 95539/100000: episode: 9816, duration: 0.727s, episode steps: 10, steps per second: 14, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000043, mae: 0.004168, mean_q: 0.005732
[Info] 2-TH LEVEL FOUND: 0.00471272598952055, Considering 100/100 traces
 95549/100000: episode: 9817, duration: 0.658s, episode steps: 10, steps per second: 15, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000053, mae: 0.003332, mean_q: 0.003663
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.00471272598952055
 95559/100000: episode: 9818, duration: 0.498s, episode steps: 10, steps per second: 20, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000007, mae: 0.002678, mean_q: 0.004851
 95569/100000: episode: 9819, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000064, mae: 0.003077, mean_q: 0.003658
 95579/100000: episode: 9820, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.104, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000042, mae: 0.003286, mean_q: 0.004299
 95589/100000: episode: 9821, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000016, mae: 0.002702, mean_q: 0.004272
 95599/100000: episode: 9822, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000020, mae: 0.002786, mean_q: 0.003889
 95609/100000: episode: 9823, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000038, mae: 0.003024, mean_q: 0.004169
 95619/100000: episode: 9824, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000020, mae: 0.003022, mean_q: 0.003915
 95629/100000: episode: 9825, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000054, mae: 0.003754, mean_q: 0.004612
 95639/100000: episode: 9826, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000028, mae: 0.003397, mean_q: 0.004428
 95649/100000: episode: 9827, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000016, mae: 0.002827, mean_q: 0.004155
 95659/100000: episode: 9828, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000085, mae: 0.004253, mean_q: 0.004023
 95669/100000: episode: 9829, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.004414, mean_q: 0.005600
 95679/100000: episode: 9830, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000013, mae: 0.002527, mean_q: 0.003718
 95689/100000: episode: 9831, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000254, mae: 0.004575, mean_q: 0.004282
 95699/100000: episode: 9832, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000020, mae: 0.004440, mean_q: 0.006178
 95709/100000: episode: 9833, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000018, mae: 0.002522, mean_q: 0.003526
 95719/100000: episode: 9834, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.003762, mean_q: 0.004411
 95729/100000: episode: 9835, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.004110, mean_q: 0.005443
 95739/100000: episode: 9836, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000014, mae: 0.002649, mean_q: 0.003923
 95749/100000: episode: 9837, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000019, mae: 0.003001, mean_q: 0.004325
 95759/100000: episode: 9838, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000013, mae: 0.002515, mean_q: 0.004054
 95769/100000: episode: 9839, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000011, mae: 0.002633, mean_q: 0.003927
 95779/100000: episode: 9840, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000027, mae: 0.003542, mean_q: 0.004850
 95789/100000: episode: 9841, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000042, mae: 0.003125, mean_q: 0.003786
 95799/100000: episode: 9842, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000054, mae: 0.004422, mean_q: 0.005116
 95809/100000: episode: 9843, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000023, mae: 0.003534, mean_q: 0.004678
 95819/100000: episode: 9844, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002726, mean_q: 0.004007
 95829/100000: episode: 9845, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002929, mean_q: 0.004143
 95839/100000: episode: 9846, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000012, mae: 0.002895, mean_q: 0.004486
 95849/100000: episode: 9847, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.072, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000041, mae: 0.002819, mean_q: 0.003864
 95859/100000: episode: 9848, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000239, mae: 0.005588, mean_q: 0.005809
 95869/100000: episode: 9849, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000041, mae: 0.003561, mean_q: 0.005016
 95879/100000: episode: 9850, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000007, mae: 0.002065, mean_q: 0.003317
 95889/100000: episode: 9851, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000037, mae: 0.003265, mean_q: 0.004140
 95899/100000: episode: 9852, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000229, mae: 0.005241, mean_q: 0.005677
 95909/100000: episode: 9853, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000024, mae: 0.003252, mean_q: 0.004513
 95919/100000: episode: 9854, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000038, mae: 0.003317, mean_q: 0.004761
 95929/100000: episode: 9855, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000016, mae: 0.002547, mean_q: 0.003755
 95939/100000: episode: 9856, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000029, mae: 0.003455, mean_q: 0.004361
 95949/100000: episode: 9857, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000012, mae: 0.003023, mean_q: 0.004711
 95959/100000: episode: 9858, duration: 0.048s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.002619, mean_q: 0.003870
 95969/100000: episode: 9859, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000024, mae: 0.003213, mean_q: 0.004129
 95979/100000: episode: 9860, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000029, mae: 0.003690, mean_q: 0.004795
 95989/100000: episode: 9861, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000016, mae: 0.003205, mean_q: 0.004646
 95999/100000: episode: 9862, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000027, mae: 0.003126, mean_q: 0.004024
 96009/100000: episode: 9863, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000016, mae: 0.002673, mean_q: 0.004163
 96019/100000: episode: 9864, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000041, mae: 0.003029, mean_q: 0.004196
 96029/100000: episode: 9865, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000038, mae: 0.002806, mean_q: 0.003926
 96039/100000: episode: 9866, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000041, mae: 0.003165, mean_q: 0.004339
 96049/100000: episode: 9867, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000039, mae: 0.003483, mean_q: 0.005010
 96059/100000: episode: 9868, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000028, mae: 0.003265, mean_q: 0.004040
 96069/100000: episode: 9869, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000224, mae: 0.004076, mean_q: 0.004408
 96079/100000: episode: 9870, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000031, mae: 0.004243, mean_q: 0.005528
 96089/100000: episode: 9871, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000232, mae: 0.004890, mean_q: 0.005063
 96099/100000: episode: 9872, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000027, mae: 0.003871, mean_q: 0.005027
 96109/100000: episode: 9873, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.003687, mean_q: 0.004620
 96119/100000: episode: 9874, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000018, mae: 0.003607, mean_q: 0.005097
 96129/100000: episode: 9875, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003130, mean_q: 0.004042
 96139/100000: episode: 9876, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000225, mae: 0.005207, mean_q: 0.005946
 96149/100000: episode: 9877, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000221, mae: 0.004866, mean_q: 0.005677
 96159/100000: episode: 9878, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000010, mae: 0.002105, mean_q: 0.003656
 96169/100000: episode: 9879, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000011, mae: 0.002438, mean_q: 0.003823
 96179/100000: episode: 9880, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000015, mae: 0.002702, mean_q: 0.004340
 96189/100000: episode: 9881, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000018, mae: 0.002778, mean_q: 0.003733
 96199/100000: episode: 9882, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000019, mae: 0.003267, mean_q: 0.004604
 96209/100000: episode: 9883, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000017, mae: 0.002862, mean_q: 0.004266
 96219/100000: episode: 9884, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000069, mae: 0.003441, mean_q: 0.004109
 96229/100000: episode: 9885, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000034, mae: 0.003850, mean_q: 0.004813
 96239/100000: episode: 9886, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000024, mae: 0.003187, mean_q: 0.004296
 96249/100000: episode: 9887, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000255, mae: 0.004846, mean_q: 0.004786
 96259/100000: episode: 9888, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000238, mae: 0.005769, mean_q: 0.006415
 96269/100000: episode: 9889, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000045, mae: 0.003954, mean_q: 0.005479
 96279/100000: episode: 9890, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000022, mae: 0.002966, mean_q: 0.003875
 96289/100000: episode: 9891, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000219, mae: 0.003757, mean_q: 0.004537
 96299/100000: episode: 9892, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000228, mae: 0.005567, mean_q: 0.006528
 96309/100000: episode: 9893, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002310, mean_q: 0.003535
 96319/100000: episode: 9894, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000019, mae: 0.002798, mean_q: 0.003860
 96329/100000: episode: 9895, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000009, mae: 0.003006, mean_q: 0.004809
 96339/100000: episode: 9896, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000011, mae: 0.002211, mean_q: 0.003532
 96349/100000: episode: 9897, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000087, mae: 0.004562, mean_q: 0.004707
 96359/100000: episode: 9898, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000019, mae: 0.003920, mean_q: 0.005868
 96369/100000: episode: 9899, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000014, mae: 0.002562, mean_q: 0.003698
 96379/100000: episode: 9900, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000039, mae: 0.002753, mean_q: 0.004059
 96389/100000: episode: 9901, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.002939, mean_q: 0.004383
 96399/100000: episode: 9902, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000053, mae: 0.003587, mean_q: 0.004279
 96409/100000: episode: 9903, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000218, mae: 0.004215, mean_q: 0.005002
 96419/100000: episode: 9904, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003685, mean_q: 0.005050
 96429/100000: episode: 9905, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000051, mae: 0.003517, mean_q: 0.004344
 96439/100000: episode: 9906, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000022, mae: 0.003237, mean_q: 0.004491
 96449/100000: episode: 9907, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000017, mae: 0.002633, mean_q: 0.004033
 96459/100000: episode: 9908, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000009, mae: 0.002060, mean_q: 0.003438
 96469/100000: episode: 9909, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002510, mean_q: 0.003832
 96479/100000: episode: 9910, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000013, mae: 0.002515, mean_q: 0.003848
 96489/100000: episode: 9911, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000013, mae: 0.002358, mean_q: 0.003550
 96499/100000: episode: 9912, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.003853, mean_q: 0.005500
 96509/100000: episode: 9913, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000028, mae: 0.003059, mean_q: 0.003819
 96519/100000: episode: 9914, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000005, mae: 0.002058, mean_q: 0.003623
 96529/100000: episode: 9915, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000048, mae: 0.003086, mean_q: 0.003784
 96539/100000: episode: 9916, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000019, mae: 0.003343, mean_q: 0.004788
 96549/100000: episode: 9917, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000040, mae: 0.003031, mean_q: 0.003938
[Info] 1-TH LEVEL FOUND: 0.004743196070194244, Considering 100/100 traces
 96559/100000: episode: 9918, duration: 0.726s, episode steps: 10, steps per second: 14, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000022, mae: 0.003388, mean_q: 0.004574
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004743196070194244
 96569/100000: episode: 9919, duration: 0.614s, episode steps: 10, steps per second: 16, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000017, mae: 0.002920, mean_q: 0.004235
 96579/100000: episode: 9920, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000012, mae: 0.002416, mean_q: 0.003854
 96589/100000: episode: 9921, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.215, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000021, mae: 0.003040, mean_q: 0.003584
 96599/100000: episode: 9922, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000021, mae: 0.003740, mean_q: 0.005341
 96609/100000: episode: 9923, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000225, mae: 0.003683, mean_q: 0.004029
 96619/100000: episode: 9924, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000048, mae: 0.003640, mean_q: 0.004685
 96629/100000: episode: 9925, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000020, mae: 0.002770, mean_q: 0.003813
 96639/100000: episode: 9926, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000224, mae: 0.004004, mean_q: 0.004107
 96649/100000: episode: 9927, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000045, mae: 0.004348, mean_q: 0.005959
 96659/100000: episode: 9928, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000010, mae: 0.001922, mean_q: 0.002769
 96669/100000: episode: 9929, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000045, mae: 0.003291, mean_q: 0.004175
 96679/100000: episode: 9930, duration: 0.066s, episode steps: 10, steps per second: 151, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000011, mae: 0.002900, mean_q: 0.004507
 96689/100000: episode: 9931, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000020, mae: 0.002532, mean_q: 0.003448
 96699/100000: episode: 9932, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.003277, mean_q: 0.004192
 96709/100000: episode: 9933, duration: 0.093s, episode steps: 10, steps per second: 108, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000044, mae: 0.003443, mean_q: 0.004259
 96719/100000: episode: 9934, duration: 0.085s, episode steps: 10, steps per second: 117, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000049, mae: 0.003789, mean_q: 0.004719
 96729/100000: episode: 9935, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.002789, mean_q: 0.003841
 96739/100000: episode: 9936, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000009, mae: 0.002294, mean_q: 0.003700
 96749/100000: episode: 9937, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000047, mae: 0.003487, mean_q: 0.004079
 96759/100000: episode: 9938, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000012, mae: 0.003198, mean_q: 0.004820
 96769/100000: episode: 9939, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000056, mae: 0.003306, mean_q: 0.003492
 96779/100000: episode: 9940, duration: 0.104s, episode steps: 10, steps per second: 96, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000016, mae: 0.003667, mean_q: 0.005275
 96789/100000: episode: 9941, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000017, mae: 0.002608, mean_q: 0.003786
 96799/100000: episode: 9942, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000047, mae: 0.003401, mean_q: 0.004056
 96809/100000: episode: 9943, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000008, mae: 0.002703, mean_q: 0.004387
 96819/100000: episode: 9944, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000038, mae: 0.002604, mean_q: 0.003448
 96829/100000: episode: 9945, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000014, mae: 0.002778, mean_q: 0.004086
 96839/100000: episode: 9946, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000014, mae: 0.002450, mean_q: 0.003610
 96849/100000: episode: 9947, duration: 0.088s, episode steps: 10, steps per second: 113, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003183, mean_q: 0.004044
 96859/100000: episode: 9948, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000051, mae: 0.003621, mean_q: 0.004228
 96869/100000: episode: 9949, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000029, mae: 0.003659, mean_q: 0.004638
 96879/100000: episode: 9950, duration: 0.069s, episode steps: 10, steps per second: 144, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000014, mae: 0.002722, mean_q: 0.003830
 96889/100000: episode: 9951, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000045, mae: 0.003089, mean_q: 0.003815
 96899/100000: episode: 9952, duration: 0.089s, episode steps: 10, steps per second: 113, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003367, mean_q: 0.004424
 96909/100000: episode: 9953, duration: 0.114s, episode steps: 10, steps per second: 88, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000009, mae: 0.002314, mean_q: 0.003817
 96919/100000: episode: 9954, duration: 0.072s, episode steps: 10, steps per second: 139, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000013, mae: 0.002334, mean_q: 0.003667
 96929/100000: episode: 9955, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000005, mae: 0.002080, mean_q: 0.003397
 96939/100000: episode: 9956, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000040, mae: 0.002594, mean_q: 0.003362
 96949/100000: episode: 9957, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000048, mae: 0.003629, mean_q: 0.004354
 96959/100000: episode: 9958, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.041, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000014, mae: 0.002963, mean_q: 0.004385
 96969/100000: episode: 9959, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000039, mae: 0.002423, mean_q: 0.003388
 96979/100000: episode: 9960, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.233, mean reward: 0.023 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000020, mae: 0.003042, mean_q: 0.004229
 96989/100000: episode: 9961, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000050, mae: 0.003596, mean_q: 0.004179
 96999/100000: episode: 9962, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000019, mae: 0.003268, mean_q: 0.004729
 97009/100000: episode: 9963, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000012, mae: 0.002178, mean_q: 0.003480
 97019/100000: episode: 9964, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000043, mae: 0.002713, mean_q: 0.003562
 97029/100000: episode: 9965, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000038, mae: 0.003237, mean_q: 0.004569
 97039/100000: episode: 9966, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000031, mae: 0.003199, mean_q: 0.003236
 97049/100000: episode: 9967, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000041, mae: 0.003807, mean_q: 0.005165
 97059/100000: episode: 9968, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000017, mae: 0.002507, mean_q: 0.003455
 97069/100000: episode: 9969, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000025, mae: 0.003300, mean_q: 0.004210
 97079/100000: episode: 9970, duration: 0.061s, episode steps: 10, steps per second: 165, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000051, mae: 0.003928, mean_q: 0.004922
 97089/100000: episode: 9971, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000077, mae: 0.003955, mean_q: 0.004369
 97099/100000: episode: 9972, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000026, mae: 0.004175, mean_q: 0.005566
 97109/100000: episode: 9973, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000053, mae: 0.003659, mean_q: 0.004293
 97119/100000: episode: 9974, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000023, mae: 0.003550, mean_q: 0.004669
 97129/100000: episode: 9975, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000048, mae: 0.003365, mean_q: 0.004151
 97139/100000: episode: 9976, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000022, mae: 0.003245, mean_q: 0.004506
 97149/100000: episode: 9977, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000013, mae: 0.002929, mean_q: 0.004682
 97159/100000: episode: 9978, duration: 0.108s, episode steps: 10, steps per second: 92, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000023, mae: 0.002516, mean_q: 0.003564
 97169/100000: episode: 9979, duration: 0.075s, episode steps: 10, steps per second: 132, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000009, mae: 0.002354, mean_q: 0.004110
 97179/100000: episode: 9980, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000012, mae: 0.002450, mean_q: 0.003647
 97189/100000: episode: 9981, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000022, mae: 0.003429, mean_q: 0.004660
 97199/100000: episode: 9982, duration: 0.056s, episode steps: 10, steps per second: 177, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000052, mae: 0.003483, mean_q: 0.004194
 97209/100000: episode: 9983, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000052, mae: 0.004528, mean_q: 0.005239
 97219/100000: episode: 9984, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000015, mae: 0.002896, mean_q: 0.004326
 97229/100000: episode: 9985, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000041, mae: 0.002648, mean_q: 0.003548
 97239/100000: episode: 9986, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000042, mae: 0.003278, mean_q: 0.004481
 97249/100000: episode: 9987, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000018, mae: 0.002782, mean_q: 0.003861
 97259/100000: episode: 9988, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000028, mae: 0.003640, mean_q: 0.004733
 97269/100000: episode: 9989, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000075, mae: 0.003764, mean_q: 0.004484
 97279/100000: episode: 9990, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000017, mae: 0.002982, mean_q: 0.004338
 97289/100000: episode: 9991, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000014, mae: 0.002643, mean_q: 0.003776
 97299/100000: episode: 9992, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000023, mae: 0.002991, mean_q: 0.003966
 97309/100000: episode: 9993, duration: 0.107s, episode steps: 10, steps per second: 94, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000046, mae: 0.003690, mean_q: 0.004764
 97319/100000: episode: 9994, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000010, mae: 0.002364, mean_q: 0.003921
 97329/100000: episode: 9995, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000033, mae: 0.003326, mean_q: 0.003656
 97339/100000: episode: 9996, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000043, mae: 0.003936, mean_q: 0.005292
 97349/100000: episode: 9997, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000073, mae: 0.003944, mean_q: 0.004354
 97359/100000: episode: 9998, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000014, mae: 0.002845, mean_q: 0.004257
 97369/100000: episode: 9999, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.264, mean reward: 0.026 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.850 [-1.000, 10.000], loss: 0.000017, mae: 0.002524, mean_q: 0.003608
 97379/100000: episode: 10000, duration: 0.103s, episode steps: 10, steps per second: 97, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000079, mae: 0.004820, mean_q: 0.005151
 97389/100000: episode: 10001, duration: 0.069s, episode steps: 10, steps per second: 146, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000038, mae: 0.003295, mean_q: 0.004775
 97399/100000: episode: 10002, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000036, mae: 0.002653, mean_q: 0.003480
 97409/100000: episode: 10003, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000045, mae: 0.003272, mean_q: 0.004237
 97419/100000: episode: 10004, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000013, mae: 0.002666, mean_q: 0.004227
 97429/100000: episode: 10005, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003204, mean_q: 0.003765
 97439/100000: episode: 10006, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000021, mae: 0.003406, mean_q: 0.004840
 97449/100000: episode: 10007, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000015, mae: 0.002284, mean_q: 0.003275
 97459/100000: episode: 10008, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000040, mae: 0.002890, mean_q: 0.004145
 97469/100000: episode: 10009, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000013, mae: 0.002356, mean_q: 0.003589
 97479/100000: episode: 10010, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000010, mae: 0.001962, mean_q: 0.003379
 97489/100000: episode: 10011, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000016, mae: 0.002454, mean_q: 0.003639
 97499/100000: episode: 10012, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000052, mae: 0.003759, mean_q: 0.004380
 97509/100000: episode: 10013, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000010, mae: 0.002757, mean_q: 0.004116
 97519/100000: episode: 10014, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000019, mae: 0.002956, mean_q: 0.003714
 97529/100000: episode: 10015, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.003415, mean_q: 0.004808
 97539/100000: episode: 10016, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000010, mae: 0.002320, mean_q: 0.003533
 97549/100000: episode: 10017, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000042, mae: 0.003114, mean_q: 0.003658
 97559/100000: episode: 10018, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000027, mae: 0.003837, mean_q: 0.005062
[Info] 1-TH LEVEL FOUND: 0.0036873063072562218, Considering 100/100 traces
 97569/100000: episode: 10019, duration: 1.079s, episode steps: 10, steps per second: 9, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000047, mae: 0.003266, mean_q: 0.004149
[Info] 2-TH LEVEL FOUND: 0.0054664406925439835, Considering 100/100 traces
 97579/100000: episode: 10020, duration: 0.933s, episode steps: 10, steps per second: 11, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000059, mae: 0.003603, mean_q: 0.003796
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.0054664406925439835
 97589/100000: episode: 10021, duration: 0.702s, episode steps: 10, steps per second: 14, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000030, mae: 0.004126, mean_q: 0.005139
 97599/100000: episode: 10022, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000021, mae: 0.003140, mean_q: 0.004357
 97609/100000: episode: 10023, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000014, mae: 0.002609, mean_q: 0.003641
 97619/100000: episode: 10024, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000019, mae: 0.003029, mean_q: 0.004286
 97629/100000: episode: 10025, duration: 0.063s, episode steps: 10, steps per second: 158, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000038, mae: 0.002779, mean_q: 0.003768
 97639/100000: episode: 10026, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000011, mae: 0.002482, mean_q: 0.003619
 97649/100000: episode: 10027, duration: 0.067s, episode steps: 10, steps per second: 148, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002563, mean_q: 0.003807
 97659/100000: episode: 10028, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000038, mae: 0.002980, mean_q: 0.004192
 97669/100000: episode: 10029, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000013, mae: 0.002283, mean_q: 0.003524
 97679/100000: episode: 10030, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000013, mae: 0.002411, mean_q: 0.003611
 97689/100000: episode: 10031, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000027, mae: 0.003750, mean_q: 0.004504
 97699/100000: episode: 10032, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000048, mae: 0.003986, mean_q: 0.004744
 97709/100000: episode: 10033, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000019, mae: 0.002813, mean_q: 0.003774
 97719/100000: episode: 10034, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.003052, mean_q: 0.004307
 97729/100000: episode: 10035, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000020, mae: 0.003002, mean_q: 0.004134
 97739/100000: episode: 10036, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000040, mae: 0.002989, mean_q: 0.003734
 97749/100000: episode: 10037, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000073, mae: 0.003691, mean_q: 0.004182
 97759/100000: episode: 10038, duration: 0.068s, episode steps: 10, steps per second: 148, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000017, mae: 0.003194, mean_q: 0.004637
 97769/100000: episode: 10039, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000041, mae: 0.002631, mean_q: 0.003394
 97779/100000: episode: 10040, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000018, mae: 0.003189, mean_q: 0.004518
 97789/100000: episode: 10041, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000018, mae: 0.002530, mean_q: 0.003444
 97799/100000: episode: 10042, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000049, mae: 0.004396, mean_q: 0.005429
 97809/100000: episode: 10043, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000020, mae: 0.003227, mean_q: 0.004073
 97819/100000: episode: 10044, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000048, mae: 0.003436, mean_q: 0.004283
 97829/100000: episode: 10045, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000047, mae: 0.003605, mean_q: 0.004514
 97839/100000: episode: 10046, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000014, mae: 0.002711, mean_q: 0.004133
 97849/100000: episode: 10047, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000035, mae: 0.003656, mean_q: 0.004349
 97859/100000: episode: 10048, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000034, mae: 0.004174, mean_q: 0.005216
 97869/100000: episode: 10049, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000016, mae: 0.002280, mean_q: 0.003350
 97879/100000: episode: 10050, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000012, mae: 0.002441, mean_q: 0.003963
 97889/100000: episode: 10051, duration: 0.059s, episode steps: 10, steps per second: 168, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000010, mae: 0.002241, mean_q: 0.003501
 97899/100000: episode: 10052, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000087, mae: 0.004117, mean_q: 0.004057
 97909/100000: episode: 10053, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000020, mae: 0.003464, mean_q: 0.004905
 97919/100000: episode: 10054, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000017, mae: 0.002328, mean_q: 0.003269
 97929/100000: episode: 10055, duration: 0.084s, episode steps: 10, steps per second: 120, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000013, mae: 0.002686, mean_q: 0.004215
 97939/100000: episode: 10056, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000049, mae: 0.003289, mean_q: 0.003777
 97949/100000: episode: 10057, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000036, mae: 0.003214, mean_q: 0.004781
 97959/100000: episode: 10058, duration: 0.079s, episode steps: 10, steps per second: 127, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000021, mae: 0.002805, mean_q: 0.003552
 97969/100000: episode: 10059, duration: 0.088s, episode steps: 10, steps per second: 114, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000049, mae: 0.004498, mean_q: 0.005389
 97979/100000: episode: 10060, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000034, mae: 0.003151, mean_q: 0.003689
 97989/100000: episode: 10061, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000076, mae: 0.004019, mean_q: 0.004683
 97999/100000: episode: 10062, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000015, mae: 0.003253, mean_q: 0.004607
 98009/100000: episode: 10063, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000016, mae: 0.002785, mean_q: 0.003762
 98019/100000: episode: 10064, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000021, mae: 0.002819, mean_q: 0.003826
 98029/100000: episode: 10065, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000023, mae: 0.003309, mean_q: 0.004690
 98039/100000: episode: 10066, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000021, mae: 0.002825, mean_q: 0.003899
 98049/100000: episode: 10067, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000069, mae: 0.003529, mean_q: 0.004102
 98059/100000: episode: 10068, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000025, mae: 0.004047, mean_q: 0.005458
 98069/100000: episode: 10069, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000037, mae: 0.002886, mean_q: 0.004121
 98079/100000: episode: 10070, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000022, mae: 0.002741, mean_q: 0.003634
 98089/100000: episode: 10071, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000051, mae: 0.003803, mean_q: 0.004676
 98099/100000: episode: 10072, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000110, mae: 0.004954, mean_q: 0.004996
 98109/100000: episode: 10073, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000027, mae: 0.003949, mean_q: 0.005560
 98119/100000: episode: 10074, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000026, mae: 0.002915, mean_q: 0.003520
 98129/100000: episode: 10075, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000023, mae: 0.003662, mean_q: 0.004864
 98139/100000: episode: 10076, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000042, mae: 0.003130, mean_q: 0.004001
 98149/100000: episode: 10077, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000022, mae: 0.002961, mean_q: 0.004061
 98159/100000: episode: 10078, duration: 0.117s, episode steps: 10, steps per second: 86, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000010, mae: 0.002428, mean_q: 0.003890
 98169/100000: episode: 10079, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000032, mae: 0.003430, mean_q: 0.004100
 98179/100000: episode: 10080, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000043, mae: 0.004291, mean_q: 0.005912
 98189/100000: episode: 10081, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000023, mae: 0.002753, mean_q: 0.003395
 98199/100000: episode: 10082, duration: 0.105s, episode steps: 10, steps per second: 96, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000045, mae: 0.003625, mean_q: 0.004787
 98209/100000: episode: 10083, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000011, mae: 0.002821, mean_q: 0.004427
 98219/100000: episode: 10084, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000024, mae: 0.003003, mean_q: 0.003991
 98229/100000: episode: 10085, duration: 0.118s, episode steps: 10, steps per second: 85, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000024, mae: 0.003043, mean_q: 0.004019
 98239/100000: episode: 10086, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000024, mae: 0.003097, mean_q: 0.004252
 98249/100000: episode: 10087, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000052, mae: 0.003992, mean_q: 0.004894
 98259/100000: episode: 10088, duration: 0.080s, episode steps: 10, steps per second: 124, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.002879, mean_q: 0.003807
 98269/100000: episode: 10089, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000056, mae: 0.004312, mean_q: 0.005132
 98279/100000: episode: 10090, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000028, mae: 0.003512, mean_q: 0.004607
 98289/100000: episode: 10091, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000032, mae: 0.003820, mean_q: 0.004651
 98299/100000: episode: 10092, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000014, mae: 0.002236, mean_q: 0.003889
 98309/100000: episode: 10093, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000084, mae: 0.004670, mean_q: 0.004705
 98319/100000: episode: 10094, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000008, mae: 0.002535, mean_q: 0.004134
 98329/100000: episode: 10095, duration: 0.059s, episode steps: 10, steps per second: 170, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000028, mae: 0.002978, mean_q: 0.003258
 98339/100000: episode: 10096, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000043, mae: 0.003902, mean_q: 0.005209
 98349/100000: episode: 10097, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000018, mae: 0.002703, mean_q: 0.003875
 98359/100000: episode: 10098, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000021, mae: 0.002940, mean_q: 0.004169
 98369/100000: episode: 10099, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003110, mean_q: 0.003975
 98379/100000: episode: 10100, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000021, mae: 0.003387, mean_q: 0.004845
 98389/100000: episode: 10101, duration: 0.063s, episode steps: 10, steps per second: 159, episode reward: 0.950, mean reward: 0.095 [0.000, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 5.450 [1.000, 10.000], loss: 0.000012, mae: 0.001934, mean_q: 0.003347
 98399/100000: episode: 10102, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000022, mae: 0.003017, mean_q: 0.004102
 98409/100000: episode: 10103, duration: 0.101s, episode steps: 10, steps per second: 99, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000013, mae: 0.002480, mean_q: 0.003946
 98419/100000: episode: 10104, duration: 0.123s, episode steps: 10, steps per second: 82, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000014, mae: 0.002334, mean_q: 0.003512
 98429/100000: episode: 10105, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000228, mae: 0.004352, mean_q: 0.004569
 98439/100000: episode: 10106, duration: 0.106s, episode steps: 10, steps per second: 94, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.003160, mean_q: 0.004506
 98449/100000: episode: 10107, duration: 0.108s, episode steps: 10, steps per second: 93, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000056, mae: 0.003657, mean_q: 0.004026
 98459/100000: episode: 10108, duration: 0.113s, episode steps: 10, steps per second: 88, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000050, mae: 0.004024, mean_q: 0.005322
 98469/100000: episode: 10109, duration: 0.071s, episode steps: 10, steps per second: 140, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000022, mae: 0.002563, mean_q: 0.003283
 98479/100000: episode: 10110, duration: 0.086s, episode steps: 10, steps per second: 116, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000067, mae: 0.003557, mean_q: 0.004517
 98489/100000: episode: 10111, duration: 0.111s, episode steps: 10, steps per second: 90, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000046, mae: 0.003447, mean_q: 0.004283
 98499/100000: episode: 10112, duration: 0.081s, episode steps: 10, steps per second: 124, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000219, mae: 0.003296, mean_q: 0.003773
 98509/100000: episode: 10113, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000023, mae: 0.003736, mean_q: 0.005374
 98519/100000: episode: 10114, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000035, mae: 0.003847, mean_q: 0.004770
 98529/100000: episode: 10115, duration: 0.086s, episode steps: 10, steps per second: 117, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000022, mae: 0.002886, mean_q: 0.004294
 98539/100000: episode: 10116, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000017, mae: 0.002767, mean_q: 0.004176
 98549/100000: episode: 10117, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000029, mae: 0.003355, mean_q: 0.004217
 98559/100000: episode: 10118, duration: 0.062s, episode steps: 10, steps per second: 161, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000056, mae: 0.004079, mean_q: 0.004724
 98569/100000: episode: 10119, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000128, mae: 0.005644, mean_q: 0.005834
 98579/100000: episode: 10120, duration: 0.061s, episode steps: 10, steps per second: 164, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000021, mae: 0.003525, mean_q: 0.005043
[Info] 1-TH LEVEL FOUND: 0.005266007035970688, Considering 100/100 traces
 98589/100000: episode: 10121, duration: 0.781s, episode steps: 10, steps per second: 13, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000067, mae: 0.003009, mean_q: 0.003553
[Info] 2-TH LEVEL FOUND: 0.005627885926514864, Considering 100/100 traces
 98599/100000: episode: 10122, duration: 0.733s, episode steps: 10, steps per second: 14, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000108, mae: 0.006050, mean_q: 0.006619
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.005627885926514864
 98609/100000: episode: 10123, duration: 0.850s, episode steps: 10, steps per second: 12, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000081, mae: 0.004044, mean_q: 0.004358
 98619/100000: episode: 10124, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000013, mae: 0.002694, mean_q: 0.004401
 98629/100000: episode: 10125, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000026, mae: 0.003035, mean_q: 0.004150
 98639/100000: episode: 10126, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000011, mae: 0.002580, mean_q: 0.004293
 98649/100000: episode: 10127, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000264, mae: 0.005106, mean_q: 0.004664
 98659/100000: episode: 10128, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000023, mae: 0.004882, mean_q: 0.006886
 98669/100000: episode: 10129, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000022, mae: 0.002304, mean_q: 0.002868
 98679/100000: episode: 10130, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000011, mae: 0.002791, mean_q: 0.004552
 98689/100000: episode: 10131, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000032, mae: 0.003346, mean_q: 0.003999
 98699/100000: episode: 10132, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000036, mae: 0.003471, mean_q: 0.005231
 98709/100000: episode: 10133, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000021, mae: 0.002470, mean_q: 0.003331
 98719/100000: episode: 10134, duration: 0.094s, episode steps: 10, steps per second: 106, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000021, mae: 0.003210, mean_q: 0.004680
 98729/100000: episode: 10135, duration: 0.103s, episode steps: 10, steps per second: 98, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000013, mae: 0.002195, mean_q: 0.003321
 98739/100000: episode: 10136, duration: 0.107s, episode steps: 10, steps per second: 93, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000254, mae: 0.004610, mean_q: 0.004398
 98749/100000: episode: 10137, duration: 0.121s, episode steps: 10, steps per second: 83, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000029, mae: 0.005199, mean_q: 0.007007
 98759/100000: episode: 10138, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000027, mae: 0.002907, mean_q: 0.003894
 98769/100000: episode: 10139, duration: 0.099s, episode steps: 10, steps per second: 102, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000049, mae: 0.003617, mean_q: 0.004640
 98779/100000: episode: 10140, duration: 0.096s, episode steps: 10, steps per second: 104, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000013, mae: 0.002479, mean_q: 0.003977
 98789/100000: episode: 10141, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000023, mae: 0.003171, mean_q: 0.004259
 98799/100000: episode: 10142, duration: 0.079s, episode steps: 10, steps per second: 126, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000016, mae: 0.002988, mean_q: 0.004853
 98809/100000: episode: 10143, duration: 0.067s, episode steps: 10, steps per second: 150, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000018, mae: 0.002270, mean_q: 0.002996
 98819/100000: episode: 10144, duration: 0.077s, episode steps: 10, steps per second: 129, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000017, mae: 0.003077, mean_q: 0.004744
 98829/100000: episode: 10145, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000028, mae: 0.003084, mean_q: 0.003935
 98839/100000: episode: 10146, duration: 0.113s, episode steps: 10, steps per second: 89, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000009, mae: 0.002238, mean_q: 0.003980
 98849/100000: episode: 10147, duration: 0.090s, episode steps: 10, steps per second: 111, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000263, mae: 0.004460, mean_q: 0.003734
 98859/100000: episode: 10148, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000060, mae: 0.006063, mean_q: 0.007413
 98869/100000: episode: 10149, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000013, mae: 0.002414, mean_q: 0.002983
 98879/100000: episode: 10150, duration: 0.076s, episode steps: 10, steps per second: 131, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000030, mae: 0.003449, mean_q: 0.004413
 98889/100000: episode: 10151, duration: 0.081s, episode steps: 10, steps per second: 123, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000252, mae: 0.005488, mean_q: 0.005867
 98899/100000: episode: 10152, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000259, mae: 0.005161, mean_q: 0.004740
 98909/100000: episode: 10153, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000224, mae: 0.005105, mean_q: 0.005990
 98919/100000: episode: 10154, duration: 0.061s, episode steps: 10, steps per second: 163, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000009, mae: 0.002162, mean_q: 0.003853
 98929/100000: episode: 10155, duration: 0.087s, episode steps: 10, steps per second: 115, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000224, mae: 0.003468, mean_q: 0.003428
 98939/100000: episode: 10156, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000018, mae: 0.003841, mean_q: 0.005884
 98949/100000: episode: 10157, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000047, mae: 0.002810, mean_q: 0.003614
 98959/100000: episode: 10158, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000006, mae: 0.002388, mean_q: 0.004299
 98969/100000: episode: 10159, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000013, mae: 0.002254, mean_q: 0.003585
 98979/100000: episode: 10160, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000037, mae: 0.002557, mean_q: 0.003772
 98989/100000: episode: 10161, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000056, mae: 0.003671, mean_q: 0.004361
 98999/100000: episode: 10162, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000022, mae: 0.003840, mean_q: 0.005362
 99009/100000: episode: 10163, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000014, mae: 0.002253, mean_q: 0.003186
 99019/100000: episode: 10164, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000021, mae: 0.003334, mean_q: 0.004629
 99029/100000: episode: 10165, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000080, mae: 0.004003, mean_q: 0.004059
 99039/100000: episode: 10166, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000011, mae: 0.003323, mean_q: 0.005475
 99049/100000: episode: 10167, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000253, mae: 0.003941, mean_q: 0.003498
 99059/100000: episode: 10168, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000016, mae: 0.003299, mean_q: 0.005363
 99069/100000: episode: 10169, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002922, mean_q: 0.003676
 99079/100000: episode: 10170, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000016, mae: 0.002895, mean_q: 0.004628
 99089/100000: episode: 10171, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000053, mae: 0.003061, mean_q: 0.003692
 99099/100000: episode: 10172, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000015, mae: 0.002706, mean_q: 0.004418
 99109/100000: episode: 10173, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000045, mae: 0.003005, mean_q: 0.003923
 99119/100000: episode: 10174, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000017, mae: 0.002866, mean_q: 0.003965
 99129/100000: episode: 10175, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000029, mae: 0.003458, mean_q: 0.004292
 99139/100000: episode: 10176, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000013, mae: 0.002680, mean_q: 0.004241
 99149/100000: episode: 10177, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000027, mae: 0.003142, mean_q: 0.004176
 99159/100000: episode: 10178, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000075, mae: 0.004234, mean_q: 0.004715
 99169/100000: episode: 10179, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000026, mae: 0.003496, mean_q: 0.004800
 99179/100000: episode: 10180, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.000216, mae: 0.003538, mean_q: 0.004260
 99189/100000: episode: 10181, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000025, mae: 0.003553, mean_q: 0.004763
 99199/100000: episode: 10182, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000042, mae: 0.003033, mean_q: 0.003855
 99209/100000: episode: 10183, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000224, mae: 0.004061, mean_q: 0.004478
 99219/100000: episode: 10184, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000014, mae: 0.003175, mean_q: 0.004931
 99229/100000: episode: 10185, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000018, mae: 0.002484, mean_q: 0.003503
 99239/100000: episode: 10186, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000021, mae: 0.002805, mean_q: 0.004208
 99249/100000: episode: 10187, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000018, mae: 0.002561, mean_q: 0.003966
 99259/100000: episode: 10188, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000019, mae: 0.002964, mean_q: 0.003979
 99269/100000: episode: 10189, duration: 0.080s, episode steps: 10, steps per second: 125, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000014, mae: 0.002627, mean_q: 0.003893
 99279/100000: episode: 10190, duration: 0.089s, episode steps: 10, steps per second: 112, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000083, mae: 0.004206, mean_q: 0.004444
 99289/100000: episode: 10191, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000018, mae: 0.003495, mean_q: 0.005033
 99299/100000: episode: 10192, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000060, mae: 0.003763, mean_q: 0.004093
 99309/100000: episode: 10193, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000008, mae: 0.002206, mean_q: 0.003887
 99319/100000: episode: 10194, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000050, mae: 0.002705, mean_q: 0.003041
 99329/100000: episode: 10195, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000056, mae: 0.004654, mean_q: 0.005544
 99339/100000: episode: 10196, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000018, mae: 0.002810, mean_q: 0.003929
 99349/100000: episode: 10197, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000018, mae: 0.002374, mean_q: 0.003215
 99359/100000: episode: 10198, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000045, mae: 0.003291, mean_q: 0.004416
 99369/100000: episode: 10199, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000093, mae: 0.004363, mean_q: 0.005193
 99379/100000: episode: 10200, duration: 0.071s, episode steps: 10, steps per second: 141, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000020, mae: 0.002749, mean_q: 0.003900
 99389/100000: episode: 10201, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000042, mae: 0.002916, mean_q: 0.003890
 99399/100000: episode: 10202, duration: 0.078s, episode steps: 10, steps per second: 128, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000066, mae: 0.003662, mean_q: 0.004459
 99409/100000: episode: 10203, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000016, mae: 0.002502, mean_q: 0.003843
 99419/100000: episode: 10204, duration: 0.074s, episode steps: 10, steps per second: 135, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000066, mae: 0.002801, mean_q: 0.003182
 99429/100000: episode: 10205, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000028, mae: 0.004147, mean_q: 0.005459
 99439/100000: episode: 10206, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000013, mae: 0.002235, mean_q: 0.003347
 99449/100000: episode: 10207, duration: 0.068s, episode steps: 10, steps per second: 147, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000029, mae: 0.003079, mean_q: 0.003673
 99459/100000: episode: 10208, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000018, mae: 0.003257, mean_q: 0.004710
 99469/100000: episode: 10209, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000042, mae: 0.002495, mean_q: 0.003175
 99479/100000: episode: 10210, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000044, mae: 0.003785, mean_q: 0.005108
 99489/100000: episode: 10211, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000020, mae: 0.002635, mean_q: 0.003634
 99499/100000: episode: 10212, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000029, mae: 0.003435, mean_q: 0.004188
 99509/100000: episode: 10213, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000068, mae: 0.003654, mean_q: 0.004473
 99519/100000: episode: 10214, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000052, mae: 0.003639, mean_q: 0.004377
 99529/100000: episode: 10215, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000017, mae: 0.002828, mean_q: 0.004419
 99539/100000: episode: 10216, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000046, mae: 0.002797, mean_q: 0.003495
 99549/100000: episode: 10217, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000058, mae: 0.004073, mean_q: 0.004393
 99559/100000: episode: 10218, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000021, mae: 0.003726, mean_q: 0.005309
 99569/100000: episode: 10219, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000048, mae: 0.002810, mean_q: 0.003442
 99579/100000: episode: 10220, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000010, mae: 0.002645, mean_q: 0.004431
 99589/100000: episode: 10221, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000051, mae: 0.003419, mean_q: 0.003683
 99599/100000: episode: 10222, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000066, mae: 0.005387, mean_q: 0.006032
[Info] 1-TH LEVEL FOUND: 0.004725924227386713, Considering 100/100 traces
 99609/100000: episode: 10223, duration: 0.738s, episode steps: 10, steps per second: 14, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000105, mae: 0.004094, mean_q: 0.004022
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.004725924227386713
 99619/100000: episode: 10224, duration: 0.596s, episode steps: 10, steps per second: 17, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000017, mae: 0.003188, mean_q: 0.004951
 99629/100000: episode: 10225, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000048, mae: 0.003127, mean_q: 0.003767
 99639/100000: episode: 10226, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000097, mae: 0.005419, mean_q: 0.005307
 99649/100000: episode: 10227, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000053, mae: 0.004584, mean_q: 0.005776
 99659/100000: episode: 10228, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000015, mae: 0.002389, mean_q: 0.003721
 99669/100000: episode: 10229, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000019, mae: 0.002691, mean_q: 0.004120
 99679/100000: episode: 10230, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000067, mae: 0.003584, mean_q: 0.004634
 99689/100000: episode: 10231, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000074, mae: 0.003991, mean_q: 0.004664
 99699/100000: episode: 10232, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000006, mae: 0.002228, mean_q: 0.004063
 99709/100000: episode: 10233, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000011, mae: 0.002318, mean_q: 0.003534
 99719/100000: episode: 10234, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000462, mae: 0.006929, mean_q: 0.006125
 99729/100000: episode: 10235, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000249, mae: 0.005890, mean_q: 0.006681
 99739/100000: episode: 10236, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000026, mae: 0.002519, mean_q: 0.002533
 99749/100000: episode: 10237, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000016, mae: 0.003481, mean_q: 0.005273
 99759/100000: episode: 10238, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000020, mae: 0.002575, mean_q: 0.003768
 99769/100000: episode: 10239, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000069, mae: 0.003543, mean_q: 0.004419
 99779/100000: episode: 10240, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000225, mae: 0.003903, mean_q: 0.004187
 99789/100000: episode: 10241, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000252, mae: 0.006461, mean_q: 0.007112
 99799/100000: episode: 10242, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000072, mae: 0.005170, mean_q: 0.006603
 99809/100000: episode: 10243, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000043, mae: 0.002625, mean_q: 0.003348
 99819/100000: episode: 10244, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000070, mae: 0.003894, mean_q: 0.004978
 99829/100000: episode: 10245, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000010, mae: 0.002777, mean_q: 0.004886
 99839/100000: episode: 10246, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000077, mae: 0.003280, mean_q: 0.003507
 99849/100000: episode: 10247, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000013, mae: 0.003269, mean_q: 0.005248
 99859/100000: episode: 10248, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000319, mae: 0.006276, mean_q: 0.005391
 99869/100000: episode: 10249, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000284, mae: 0.005667, mean_q: 0.005523
 99879/100000: episode: 10250, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000007, mae: 0.003113, mean_q: 0.005656
 99889/100000: episode: 10251, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000084, mae: 0.003431, mean_q: 0.003603
 99899/100000: episode: 10252, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000052, mae: 0.004380, mean_q: 0.005876
 99909/100000: episode: 10253, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000046, mae: 0.003124, mean_q: 0.004190
 99919/100000: episode: 10254, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000017, mae: 0.002941, mean_q: 0.004782
 99929/100000: episode: 10255, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000040, mae: 0.003127, mean_q: 0.004316
 99939/100000: episode: 10256, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000016, mae: 0.002525, mean_q: 0.003966
 99949/100000: episode: 10257, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000039, mae: 0.002674, mean_q: 0.004234
 99959/100000: episode: 10258, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000041, mae: 0.002451, mean_q: 0.003416
 99969/100000: episode: 10259, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000050, mae: 0.003922, mean_q: 0.004902
 99979/100000: episode: 10260, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000009, mae: 0.002642, mean_q: 0.004804
 99989/100000: episode: 10261, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000038, mae: 0.002365, mean_q: 0.003275
 99999/100000: episode: 10262, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.217, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000047, mae: 0.003601, mean_q: 0.004568
done, took 681.096 seconds
[Info] End Importance Splitting. Falsification occurred 15 times.
