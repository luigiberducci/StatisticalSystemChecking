Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 2)                 0         
_________________________________________________________________
dense_1 (Dense)              (None, 16)                48        
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 193
Trainable params: 193
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Importance Splitting on succruns-v1.
Training for 10000 steps ...
   10/10000: episode: 1, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   20/10000: episode: 2, duration: 0.005s, episode steps: 10, steps per second: 1970, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   30/10000: episode: 3, duration: 0.005s, episode steps: 10, steps per second: 1962, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   40/10000: episode: 4, duration: 0.005s, episode steps: 10, steps per second: 1871, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   50/10000: episode: 5, duration: 0.005s, episode steps: 10, steps per second: 1970, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   60/10000: episode: 6, duration: 0.005s, episode steps: 10, steps per second: 1984, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   70/10000: episode: 7, duration: 0.005s, episode steps: 10, steps per second: 1964, episode reward: 0.130, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   80/10000: episode: 8, duration: 0.005s, episode steps: 10, steps per second: 1943, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
   90/10000: episode: 9, duration: 0.005s, episode steps: 10, steps per second: 2034, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  100/10000: episode: 10, duration: 0.005s, episode steps: 10, steps per second: 2103, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  110/10000: episode: 11, duration: 0.005s, episode steps: 10, steps per second: 1990, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  120/10000: episode: 12, duration: 0.005s, episode steps: 10, steps per second: 1984, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  130/10000: episode: 13, duration: 0.005s, episode steps: 10, steps per second: 2184, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  140/10000: episode: 14, duration: 0.005s, episode steps: 10, steps per second: 2185, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  150/10000: episode: 15, duration: 0.005s, episode steps: 10, steps per second: 2046, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  160/10000: episode: 16, duration: 0.005s, episode steps: 10, steps per second: 2106, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  170/10000: episode: 17, duration: 0.005s, episode steps: 10, steps per second: 2092, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  180/10000: episode: 18, duration: 0.005s, episode steps: 10, steps per second: 2051, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  190/10000: episode: 19, duration: 0.005s, episode steps: 10, steps per second: 2150, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  200/10000: episode: 20, duration: 0.005s, episode steps: 10, steps per second: 2118, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  210/10000: episode: 21, duration: 0.005s, episode steps: 10, steps per second: 2124, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  220/10000: episode: 22, duration: 0.005s, episode steps: 10, steps per second: 2151, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  230/10000: episode: 23, duration: 0.005s, episode steps: 10, steps per second: 1999, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  240/10000: episode: 24, duration: 0.005s, episode steps: 10, steps per second: 2047, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  250/10000: episode: 25, duration: 0.005s, episode steps: 10, steps per second: 2072, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  260/10000: episode: 26, duration: 0.005s, episode steps: 10, steps per second: 2025, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  270/10000: episode: 27, duration: 0.005s, episode steps: 10, steps per second: 2092, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  280/10000: episode: 28, duration: 0.005s, episode steps: 10, steps per second: 2057, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  290/10000: episode: 29, duration: 0.005s, episode steps: 10, steps per second: 2136, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  300/10000: episode: 30, duration: 0.005s, episode steps: 10, steps per second: 1983, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  310/10000: episode: 31, duration: 0.005s, episode steps: 10, steps per second: 2033, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  320/10000: episode: 32, duration: 0.005s, episode steps: 10, steps per second: 2066, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  330/10000: episode: 33, duration: 0.005s, episode steps: 10, steps per second: 2055, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  340/10000: episode: 34, duration: 0.005s, episode steps: 10, steps per second: 2031, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  350/10000: episode: 35, duration: 0.005s, episode steps: 10, steps per second: 2065, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  360/10000: episode: 36, duration: 0.005s, episode steps: 10, steps per second: 2131, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  370/10000: episode: 37, duration: 0.005s, episode steps: 10, steps per second: 2186, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  380/10000: episode: 38, duration: 0.005s, episode steps: 10, steps per second: 2099, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  390/10000: episode: 39, duration: 0.005s, episode steps: 10, steps per second: 2099, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  400/10000: episode: 40, duration: 0.005s, episode steps: 10, steps per second: 2082, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  410/10000: episode: 41, duration: 0.005s, episode steps: 10, steps per second: 2133, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  420/10000: episode: 42, duration: 0.005s, episode steps: 10, steps per second: 2016, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  430/10000: episode: 43, duration: 0.005s, episode steps: 10, steps per second: 2126, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  440/10000: episode: 44, duration: 0.005s, episode steps: 10, steps per second: 2104, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  450/10000: episode: 45, duration: 0.005s, episode steps: 10, steps per second: 2115, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  460/10000: episode: 46, duration: 0.005s, episode steps: 10, steps per second: 1938, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  470/10000: episode: 47, duration: 0.005s, episode steps: 10, steps per second: 2085, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  480/10000: episode: 48, duration: 0.005s, episode steps: 10, steps per second: 2142, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  490/10000: episode: 49, duration: 0.005s, episode steps: 10, steps per second: 1873, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  500/10000: episode: 50, duration: 0.006s, episode steps: 10, steps per second: 1711, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: --, mae: --, mean_q: --
  510/10000: episode: 51, duration: 0.674s, episode steps: 10, steps per second: 15, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.062343, mae: 0.219378, mean_q: -0.314677
  520/10000: episode: 52, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.038179, mae: 0.185864, mean_q: -0.170051
  530/10000: episode: 53, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.024547, mae: 0.136943, mean_q: -0.183926
  540/10000: episode: 54, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.019206, mae: 0.126604, mean_q: -0.173596
  550/10000: episode: 55, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.009454, mae: 0.099343, mean_q: -0.195090
  560/10000: episode: 56, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.012579, mae: 0.104333, mean_q: -0.175079
  570/10000: episode: 57, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.800 [-1.000, 10.000], loss: 0.007854, mae: 0.090505, mean_q: -0.126869
  580/10000: episode: 58, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.005218, mae: 0.078522, mean_q: -0.158535
  590/10000: episode: 59, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.008609, mae: 0.082175, mean_q: -0.126888
  600/10000: episode: 60, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.005380, mae: 0.073721, mean_q: -0.109631
  610/10000: episode: 61, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.005724, mae: 0.075284, mean_q: -0.110623
  620/10000: episode: 62, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.004030, mae: 0.065075, mean_q: -0.100802
  630/10000: episode: 63, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.003038, mae: 0.056160, mean_q: -0.102771
  640/10000: episode: 64, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.002936, mae: 0.056212, mean_q: -0.091228
  650/10000: episode: 65, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002711, mae: 0.051623, mean_q: -0.102866
  660/10000: episode: 66, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.002054, mae: 0.048502, mean_q: -0.094962
  670/10000: episode: 67, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.002006, mae: 0.048021, mean_q: -0.087117
  680/10000: episode: 68, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.001499, mae: 0.043488, mean_q: -0.080178
  690/10000: episode: 69, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.001101, mae: 0.034136, mean_q: -0.081983
  700/10000: episode: 70, duration: 0.057s, episode steps: 10, steps per second: 176, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001311, mae: 0.038508, mean_q: -0.069738
  710/10000: episode: 71, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000928, mae: 0.034102, mean_q: -0.060424
  720/10000: episode: 72, duration: 0.056s, episode steps: 10, steps per second: 180, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.001104, mae: 0.033442, mean_q: -0.058595
  730/10000: episode: 73, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.001142, mae: 0.033860, mean_q: -0.060929
  740/10000: episode: 74, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000867, mae: 0.031170, mean_q: -0.051073
  750/10000: episode: 75, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000507, mae: 0.024866, mean_q: -0.055387
  760/10000: episode: 76, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000468, mae: 0.024809, mean_q: -0.047448
  770/10000: episode: 77, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000484, mae: 0.023380, mean_q: -0.047829
  780/10000: episode: 78, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000314, mae: 0.019843, mean_q: -0.043814
  790/10000: episode: 79, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000396, mae: 0.020636, mean_q: -0.041860
  800/10000: episode: 80, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000491, mae: 0.021723, mean_q: -0.039076
  810/10000: episode: 81, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000294, mae: 0.018247, mean_q: -0.039136
  820/10000: episode: 82, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000245, mae: 0.016491, mean_q: -0.033023
  830/10000: episode: 83, duration: 0.058s, episode steps: 10, steps per second: 173, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000186, mae: 0.014383, mean_q: -0.033234
  840/10000: episode: 84, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000237, mae: 0.015882, mean_q: -0.031703
  850/10000: episode: 85, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000180, mae: 0.014078, mean_q: -0.028167
  860/10000: episode: 86, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000187, mae: 0.013724, mean_q: -0.022427
  870/10000: episode: 87, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000149, mae: 0.012174, mean_q: -0.025667
  880/10000: episode: 88, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000120, mae: 0.010845, mean_q: -0.022940
  890/10000: episode: 89, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000091, mae: 0.009673, mean_q: -0.021504
  900/10000: episode: 90, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000086, mae: 0.008672, mean_q: -0.019013
  910/10000: episode: 91, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000076, mae: 0.008898, mean_q: -0.019624
  920/10000: episode: 92, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000092, mae: 0.009087, mean_q: -0.017851
  930/10000: episode: 93, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000077, mae: 0.008600, mean_q: -0.014311
  940/10000: episode: 94, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000113, mae: 0.008625, mean_q: -0.016396
  950/10000: episode: 95, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000071, mae: 0.008159, mean_q: -0.013342
  960/10000: episode: 96, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000068, mae: 0.006730, mean_q: -0.010987
  970/10000: episode: 97, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000079, mae: 0.007060, mean_q: -0.011583
  980/10000: episode: 98, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000076, mae: 0.006312, mean_q: -0.011850
  990/10000: episode: 99, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000064, mae: 0.006294, mean_q: -0.010533
 1000/10000: episode: 100, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000054, mae: 0.005513, mean_q: -0.008421
 1010/10000: episode: 101, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000072, mae: 0.006489, mean_q: -0.008119
 1020/10000: episode: 102, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000074, mae: 0.006467, mean_q: -0.007916
 1030/10000: episode: 103, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.057, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000068, mae: 0.005996, mean_q: -0.007337
 1040/10000: episode: 104, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000065, mae: 0.005767, mean_q: -0.005667
 1050/10000: episode: 105, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000061, mae: 0.006501, mean_q: -0.004979
 1060/10000: episode: 106, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000029, mae: 0.004841, mean_q: -0.004549
 1070/10000: episode: 107, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000036, mae: 0.005384, mean_q: -0.005486
 1080/10000: episode: 108, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000110, mae: 0.007438, mean_q: -0.002530
 1090/10000: episode: 109, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000055, mae: 0.006166, mean_q: -0.002799
 1100/10000: episode: 110, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000052, mae: 0.005828, mean_q: -0.003123
 1110/10000: episode: 111, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000034, mae: 0.004945, mean_q: -0.003735
 1120/10000: episode: 112, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000027, mae: 0.004584, mean_q: -0.002303
 1130/10000: episode: 113, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000033, mae: 0.004122, mean_q: -0.002347
 1140/10000: episode: 114, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000039, mae: 0.005037, mean_q: -0.000791
 1150/10000: episode: 115, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000031, mae: 0.005234, mean_q: -0.001837
 1160/10000: episode: 116, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000038, mae: 0.004366, mean_q: -0.002016
 1170/10000: episode: 117, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000025, mae: 0.004468, mean_q: -0.000983
 1180/10000: episode: 118, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000042, mae: 0.004876, mean_q: -0.001069
 1190/10000: episode: 119, duration: 0.050s, episode steps: 10, steps per second: 198, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000029, mae: 0.004492, mean_q: -0.000165
 1200/10000: episode: 120, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000072, mae: 0.005704, mean_q: 0.000495
 1210/10000: episode: 121, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000055, mae: 0.005978, mean_q: 0.002991
 1220/10000: episode: 122, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000044, mae: 0.005940, mean_q: 0.001318
 1230/10000: episode: 123, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000026, mae: 0.004570, mean_q: -0.000840
 1240/10000: episode: 124, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000028, mae: 0.003871, mean_q: 0.001068
 1250/10000: episode: 125, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000024, mae: 0.004108, mean_q: 0.001318
 1260/10000: episode: 126, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000023, mae: 0.003625, mean_q: 0.001444
 1270/10000: episode: 127, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000041, mae: 0.004893, mean_q: 0.003172
 1280/10000: episode: 128, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000056, mae: 0.006567, mean_q: 0.001841
 1290/10000: episode: 129, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000050, mae: 0.005293, mean_q: 0.000697
 1300/10000: episode: 130, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000030, mae: 0.004865, mean_q: 0.002294
 1310/10000: episode: 131, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000025, mae: 0.004460, mean_q: 0.002668
 1320/10000: episode: 132, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000045, mae: 0.004301, mean_q: 0.002793
 1330/10000: episode: 133, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000032, mae: 0.004340, mean_q: 0.002566
 1340/10000: episode: 134, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000026, mae: 0.003834, mean_q: 0.002387
 1350/10000: episode: 135, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000017, mae: 0.003256, mean_q: 0.002346
 1360/10000: episode: 136, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000027, mae: 0.003556, mean_q: 0.002046
 1370/10000: episode: 137, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000024, mae: 0.003917, mean_q: 0.002222
 1380/10000: episode: 138, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000064, mae: 0.004857, mean_q: 0.004626
 1390/10000: episode: 139, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000025, mae: 0.004056, mean_q: 0.003364
 1400/10000: episode: 140, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000025, mae: 0.003688, mean_q: 0.003851
 1410/10000: episode: 141, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000078, mae: 0.005004, mean_q: 0.004710
 1420/10000: episode: 142, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000033, mae: 0.004370, mean_q: 0.003322
 1430/10000: episode: 143, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000047, mae: 0.004359, mean_q: 0.002575
 1440/10000: episode: 144, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000014, mae: 0.002936, mean_q: 0.003265
 1450/10000: episode: 145, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000045, mae: 0.003675, mean_q: 0.003214
 1460/10000: episode: 146, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.047, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000019, mae: 0.003600, mean_q: 0.002827
 1470/10000: episode: 147, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000015, mae: 0.002818, mean_q: 0.003229
 1480/10000: episode: 148, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000067, mae: 0.004354, mean_q: 0.005183
 1490/10000: episode: 149, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000045, mae: 0.004384, mean_q: 0.004095
[Info] 1-TH LEVEL FOUND: 0.024492831900715828, Considering 11/100 traces
 1500/10000: episode: 150, duration: 1.205s, episode steps: 10, steps per second: 8, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000027, mae: 0.004206, mean_q: 0.003902
 1503/10000: episode: 151, duration: 0.039s, episode steps: 3, steps per second: 77, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000020, mae: 0.002979, mean_q: 0.002098
 1507/10000: episode: 152, duration: 0.055s, episode steps: 4, steps per second: 72, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000056, mae: 0.003404, mean_q: 0.004540
 1510/10000: episode: 153, duration: 0.040s, episode steps: 3, steps per second: 75, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000026, mae: 0.004245, mean_q: 0.006311
 1513/10000: episode: 154, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000014, mae: 0.003614, mean_q: 0.001125
 1517/10000: episode: 155, duration: 0.038s, episode steps: 4, steps per second: 106, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000013, mae: 0.003203, mean_q: 0.003713
 1521/10000: episode: 156, duration: 0.060s, episode steps: 4, steps per second: 67, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000078, mae: 0.005040, mean_q: 0.006769
 1524/10000: episode: 157, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000041, mae: 0.004192, mean_q: 0.002903
 1528/10000: episode: 158, duration: 0.032s, episode steps: 4, steps per second: 126, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000077, mae: 0.004933, mean_q: 0.006948
 1531/10000: episode: 159, duration: 0.031s, episode steps: 3, steps per second: 98, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000020, mae: 0.003386, mean_q: 0.002676
 1534/10000: episode: 160, duration: 0.026s, episode steps: 3, steps per second: 113, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000158, mae: 0.005800, mean_q: 0.003067
 1537/10000: episode: 161, duration: 0.031s, episode steps: 3, steps per second: 97, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000113, mae: 0.008560, mean_q: 0.011377
 1540/10000: episode: 162, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000047, mae: 0.006447, mean_q: 0.001613
 1543/10000: episode: 163, duration: 0.020s, episode steps: 3, steps per second: 152, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000020, mae: 0.004227, mean_q: 0.004133
 1546/10000: episode: 164, duration: 0.028s, episode steps: 3, steps per second: 108, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000101, mae: 0.005461, mean_q: 0.006883
 1549/10000: episode: 165, duration: 0.022s, episode steps: 3, steps per second: 134, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000022, mae: 0.004795, mean_q: 0.000208
 1552/10000: episode: 166, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000011, mae: 0.003251, mean_q: 0.004648
 1555/10000: episode: 167, duration: 0.031s, episode steps: 3, steps per second: 96, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000036, mae: 0.004816, mean_q: 0.006629
 1558/10000: episode: 168, duration: 0.045s, episode steps: 3, steps per second: 66, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000067, mae: 0.005893, mean_q: 0.003971
 1561/10000: episode: 169, duration: 0.035s, episode steps: 3, steps per second: 86, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000011, mae: 0.002792, mean_q: 0.002435
 1564/10000: episode: 170, duration: 0.066s, episode steps: 3, steps per second: 46, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000041, mae: 0.004796, mean_q: 0.007885
 1567/10000: episode: 171, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000044, mae: 0.004387, mean_q: 0.003407
 1570/10000: episode: 172, duration: 0.034s, episode steps: 3, steps per second: 88, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000023, mae: 0.003329, mean_q: 0.003012
 1574/10000: episode: 173, duration: 0.041s, episode steps: 4, steps per second: 97, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000030, mae: 0.003837, mean_q: 0.005624
 1577/10000: episode: 174, duration: 0.057s, episode steps: 3, steps per second: 53, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000045, mae: 0.005196, mean_q: 0.000894
 1580/10000: episode: 175, duration: 0.035s, episode steps: 3, steps per second: 86, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000178, mae: 0.007582, mean_q: 0.008667
 1583/10000: episode: 176, duration: 0.043s, episode steps: 3, steps per second: 70, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000023, mae: 0.003906, mean_q: 0.005529
 1586/10000: episode: 177, duration: 0.037s, episode steps: 3, steps per second: 80, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000041, mae: 0.005389, mean_q: 0.001530
 1589/10000: episode: 178, duration: 0.034s, episode steps: 3, steps per second: 88, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000050, mae: 0.004680, mean_q: 0.006091
 1593/10000: episode: 179, duration: 0.063s, episode steps: 4, steps per second: 63, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000028, mae: 0.004255, mean_q: 0.000607
 1596/10000: episode: 180, duration: 0.042s, episode steps: 3, steps per second: 71, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000095, mae: 0.006643, mean_q: 0.004396
 1599/10000: episode: 181, duration: 0.034s, episode steps: 3, steps per second: 87, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000116, mae: 0.007016, mean_q: 0.008390
 1603/10000: episode: 182, duration: 0.060s, episode steps: 4, steps per second: 66, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000036, mae: 0.005641, mean_q: -0.000508
 1606/10000: episode: 183, duration: 0.035s, episode steps: 3, steps per second: 86, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000071, mae: 0.007900, mean_q: 0.010779
 1609/10000: episode: 184, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000059, mae: 0.006146, mean_q: 0.002401
 1612/10000: episode: 185, duration: 0.041s, episode steps: 3, steps per second: 73, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000020, mae: 0.003450, mean_q: 0.004829
 1615/10000: episode: 186, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000133, mae: 0.006414, mean_q: 0.008141
 1619/10000: episode: 187, duration: 0.051s, episode steps: 4, steps per second: 78, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000056, mae: 0.006991, mean_q: -0.000771
 1622/10000: episode: 188, duration: 0.033s, episode steps: 3, steps per second: 92, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000071, mae: 0.007500, mean_q: 0.008769
 1625/10000: episode: 189, duration: 0.031s, episode steps: 3, steps per second: 96, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000082, mae: 0.007043, mean_q: 0.006055
 1628/10000: episode: 190, duration: 0.031s, episode steps: 3, steps per second: 96, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000210, mae: 0.006997, mean_q: 0.003250
 1632/10000: episode: 191, duration: 0.041s, episode steps: 4, steps per second: 98, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000049, mae: 0.005338, mean_q: 0.007117
 1635/10000: episode: 192, duration: 0.032s, episode steps: 3, steps per second: 92, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000049, mae: 0.005415, mean_q: 0.003781
 1638/10000: episode: 193, duration: 0.033s, episode steps: 3, steps per second: 92, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000103, mae: 0.006005, mean_q: 0.008009
 1641/10000: episode: 194, duration: 0.032s, episode steps: 3, steps per second: 93, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000030, mae: 0.003431, mean_q: 0.004346
 1644/10000: episode: 195, duration: 0.037s, episode steps: 3, steps per second: 81, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000084, mae: 0.003864, mean_q: 0.005334
 1647/10000: episode: 196, duration: 0.032s, episode steps: 3, steps per second: 94, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000054, mae: 0.005305, mean_q: 0.007738
 1650/10000: episode: 197, duration: 0.036s, episode steps: 3, steps per second: 83, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000119, mae: 0.006526, mean_q: 0.003795
 1654/10000: episode: 198, duration: 0.042s, episode steps: 4, steps per second: 95, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000102, mae: 0.007142, mean_q: 0.009539
 1657/10000: episode: 199, duration: 0.030s, episode steps: 3, steps per second: 99, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000069, mae: 0.006373, mean_q: 0.006158
 1660/10000: episode: 200, duration: 0.029s, episode steps: 3, steps per second: 104, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000056, mae: 0.005160, mean_q: 0.007796
 1664/10000: episode: 201, duration: 0.041s, episode steps: 4, steps per second: 98, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000092, mae: 0.005463, mean_q: 0.003525
 1667/10000: episode: 202, duration: 0.030s, episode steps: 3, steps per second: 99, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000072, mae: 0.005310, mean_q: 0.006736
 1670/10000: episode: 203, duration: 0.033s, episode steps: 3, steps per second: 92, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000016, mae: 0.003777, mean_q: 0.000416
 1673/10000: episode: 204, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000080, mae: 0.007706, mean_q: 0.006769
 1677/10000: episode: 205, duration: 0.031s, episode steps: 4, steps per second: 129, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000032, mae: 0.004281, mean_q: 0.003534
 1681/10000: episode: 206, duration: 0.031s, episode steps: 4, steps per second: 131, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000051, mae: 0.005707, mean_q: 0.004057
 1684/10000: episode: 207, duration: 0.025s, episode steps: 3, steps per second: 120, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000028, mae: 0.003501, mean_q: 0.003202
 1688/10000: episode: 208, duration: 0.034s, episode steps: 4, steps per second: 117, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000039, mae: 0.005093, mean_q: 0.004945
 1691/10000: episode: 209, duration: 0.028s, episode steps: 3, steps per second: 107, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000018, mae: 0.003509, mean_q: 0.004554
 1694/10000: episode: 210, duration: 0.039s, episode steps: 3, steps per second: 76, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000170, mae: 0.006859, mean_q: 0.004986
 1697/10000: episode: 211, duration: 0.036s, episode steps: 3, steps per second: 83, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000095, mae: 0.005588, mean_q: 0.006860
 1700/10000: episode: 212, duration: 0.040s, episode steps: 3, steps per second: 75, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000073, mae: 0.007564, mean_q: 0.009197
 1703/10000: episode: 213, duration: 0.023s, episode steps: 3, steps per second: 130, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000094, mae: 0.005856, mean_q: 0.006966
 1706/10000: episode: 214, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000103, mae: 0.006362, mean_q: 0.003496
 1710/10000: episode: 215, duration: 0.032s, episode steps: 4, steps per second: 126, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000180, mae: 0.007938, mean_q: 0.009406
 1714/10000: episode: 216, duration: 0.031s, episode steps: 4, steps per second: 129, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000145, mae: 0.005741, mean_q: 0.004463
 1717/10000: episode: 217, duration: 0.024s, episode steps: 3, steps per second: 125, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000030, mae: 0.003862, mean_q: 0.006445
 1721/10000: episode: 218, duration: 0.029s, episode steps: 4, steps per second: 137, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000036, mae: 0.004546, mean_q: 0.008678
 1725/10000: episode: 219, duration: 0.023s, episode steps: 4, steps per second: 175, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000054, mae: 0.006668, mean_q: 0.003365
 1729/10000: episode: 220, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000053, mae: 0.005021, mean_q: 0.005858
 1732/10000: episode: 221, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000052, mae: 0.005158, mean_q: 0.003274
 1735/10000: episode: 222, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000160, mae: 0.011813, mean_q: 0.015391
 1738/10000: episode: 223, duration: 0.022s, episode steps: 3, steps per second: 138, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000067, mae: 0.006618, mean_q: 0.003765
 1742/10000: episode: 224, duration: 0.044s, episode steps: 4, steps per second: 92, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000100, mae: 0.007933, mean_q: 0.006204
 1745/10000: episode: 225, duration: 0.038s, episode steps: 3, steps per second: 78, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000059, mae: 0.006663, mean_q: 0.002069
 1748/10000: episode: 226, duration: 0.036s, episode steps: 3, steps per second: 84, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000055, mae: 0.005778, mean_q: 0.006321
 1751/10000: episode: 227, duration: 0.033s, episode steps: 3, steps per second: 92, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000037, mae: 0.005236, mean_q: 0.006605
 1754/10000: episode: 228, duration: 0.029s, episode steps: 3, steps per second: 105, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000100, mae: 0.006416, mean_q: 0.001286
 1757/10000: episode: 229, duration: 0.029s, episode steps: 3, steps per second: 104, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000156, mae: 0.012340, mean_q: 0.016752
 1760/10000: episode: 230, duration: 0.033s, episode steps: 3, steps per second: 92, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000153, mae: 0.008894, mean_q: -0.000795
 1763/10000: episode: 231, duration: 0.027s, episode steps: 3, steps per second: 112, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000087, mae: 0.007620, mean_q: 0.010174
 1766/10000: episode: 232, duration: 0.026s, episode steps: 3, steps per second: 114, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000035, mae: 0.005050, mean_q: 0.002752
 1769/10000: episode: 233, duration: 0.039s, episode steps: 3, steps per second: 77, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000268, mae: 0.012576, mean_q: 0.011054
 1772/10000: episode: 234, duration: 0.036s, episode steps: 3, steps per second: 84, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000123, mae: 0.010659, mean_q: 0.015829
 1775/10000: episode: 235, duration: 0.030s, episode steps: 3, steps per second: 100, episode reward: 0.018, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.667 [-1.000, 11.000], loss: 0.000199, mae: 0.014301, mean_q: 0.001445
 1779/10000: episode: 236, duration: 0.030s, episode steps: 4, steps per second: 135, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000141, mae: 0.009121, mean_q: 0.007359
 1782/10000: episode: 237, duration: 0.021s, episode steps: 3, steps per second: 144, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000226, mae: 0.010051, mean_q: 0.008427
 1785/10000: episode: 238, duration: 0.027s, episode steps: 3, steps per second: 113, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000159, mae: 0.008683, mean_q: 0.005897
[Info] 2-TH LEVEL FOUND: 0.07666747272014618, Considering 13/100 traces
 1788/10000: episode: 239, duration: 0.846s, episode steps: 3, steps per second: 4, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000142, mae: 0.010802, mean_q: 0.011274
 1791/10000: episode: 240, duration: 0.023s, episode steps: 3, steps per second: 131, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000182, mae: 0.011839, mean_q: 0.007063
 1794/10000: episode: 241, duration: 0.019s, episode steps: 3, steps per second: 156, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000083, mae: 0.007364, mean_q: 0.003773
 1797/10000: episode: 242, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000188, mae: 0.012115, mean_q: 0.013314
 1800/10000: episode: 243, duration: 0.019s, episode steps: 3, steps per second: 162, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000079, mae: 0.006706, mean_q: 0.001424
 1803/10000: episode: 244, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000073, mae: 0.006932, mean_q: 0.011373
 1806/10000: episode: 245, duration: 0.018s, episode steps: 3, steps per second: 164, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000143, mae: 0.008741, mean_q: 0.009045
 1809/10000: episode: 246, duration: 0.018s, episode steps: 3, steps per second: 169, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000169, mae: 0.009012, mean_q: 0.011120
 1812/10000: episode: 247, duration: 0.018s, episode steps: 3, steps per second: 168, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000171, mae: 0.011275, mean_q: 0.012325
 1815/10000: episode: 248, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000076, mae: 0.008770, mean_q: -0.002468
 1818/10000: episode: 249, duration: 0.017s, episode steps: 3, steps per second: 180, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000055, mae: 0.008119, mean_q: 0.010347
 1821/10000: episode: 250, duration: 0.017s, episode steps: 3, steps per second: 179, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000190, mae: 0.007620, mean_q: 0.000651
 1824/10000: episode: 251, duration: 0.031s, episode steps: 3, steps per second: 96, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000131, mae: 0.009635, mean_q: 0.014251
 1827/10000: episode: 252, duration: 0.026s, episode steps: 3, steps per second: 115, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000136, mae: 0.008510, mean_q: 0.007073
 1830/10000: episode: 253, duration: 0.028s, episode steps: 3, steps per second: 107, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000205, mae: 0.010857, mean_q: 0.013983
 1833/10000: episode: 254, duration: 0.023s, episode steps: 3, steps per second: 133, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000269, mae: 0.013847, mean_q: 0.016732
 1836/10000: episode: 255, duration: 0.025s, episode steps: 3, steps per second: 122, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000273, mae: 0.014217, mean_q: -0.000750
 1839/10000: episode: 256, duration: 0.022s, episode steps: 3, steps per second: 137, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000216, mae: 0.014917, mean_q: 0.020149
 1842/10000: episode: 257, duration: 0.019s, episode steps: 3, steps per second: 158, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000246, mae: 0.012800, mean_q: -0.004365
 1845/10000: episode: 258, duration: 0.018s, episode steps: 3, steps per second: 163, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000234, mae: 0.013948, mean_q: 0.016901
 1848/10000: episode: 259, duration: 0.018s, episode steps: 3, steps per second: 167, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000251, mae: 0.011143, mean_q: 0.001346
 1851/10000: episode: 260, duration: 0.018s, episode steps: 3, steps per second: 165, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000202, mae: 0.013125, mean_q: 0.020761
 1854/10000: episode: 261, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000199, mae: 0.011250, mean_q: 0.009201
 1857/10000: episode: 262, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000121, mae: 0.008840, mean_q: 0.011174
 1860/10000: episode: 263, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000106, mae: 0.007656, mean_q: 0.009164
 1863/10000: episode: 264, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000228, mae: 0.012245, mean_q: 0.003164
 1866/10000: episode: 265, duration: 0.020s, episode steps: 3, steps per second: 153, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000159, mae: 0.009090, mean_q: 0.011624
 1869/10000: episode: 266, duration: 0.028s, episode steps: 3, steps per second: 109, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000231, mae: 0.008247, mean_q: 0.007893
 1872/10000: episode: 267, duration: 0.024s, episode steps: 3, steps per second: 127, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000243, mae: 0.010410, mean_q: 0.014575
 1875/10000: episode: 268, duration: 0.018s, episode steps: 3, steps per second: 166, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000132, mae: 0.009040, mean_q: 0.005114
 1878/10000: episode: 269, duration: 0.021s, episode steps: 3, steps per second: 141, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000153, mae: 0.007507, mean_q: 0.009400
 1881/10000: episode: 270, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000215, mae: 0.009326, mean_q: 0.010527
 1884/10000: episode: 271, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000167, mae: 0.007931, mean_q: 0.008121
 1887/10000: episode: 272, duration: 0.017s, episode steps: 3, steps per second: 172, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000127, mae: 0.006225, mean_q: 0.005323
 1890/10000: episode: 273, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000083, mae: 0.006101, mean_q: 0.008818
 1893/10000: episode: 274, duration: 0.017s, episode steps: 3, steps per second: 176, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000243, mae: 0.009576, mean_q: 0.010080
 1896/10000: episode: 275, duration: 0.019s, episode steps: 3, steps per second: 160, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000146, mae: 0.007469, mean_q: 0.002797
 1899/10000: episode: 276, duration: 0.024s, episode steps: 3, steps per second: 123, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000393, mae: 0.015646, mean_q: 0.015828
 1902/10000: episode: 277, duration: 0.017s, episode steps: 3, steps per second: 173, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000200, mae: 0.010661, mean_q: 0.005792
 1905/10000: episode: 278, duration: 0.018s, episode steps: 3, steps per second: 171, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000221, mae: 0.009611, mean_q: 0.006696
 1908/10000: episode: 279, duration: 0.021s, episode steps: 3, steps per second: 146, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000098, mae: 0.008784, mean_q: 0.013789
 1911/10000: episode: 280, duration: 0.017s, episode steps: 3, steps per second: 175, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000329, mae: 0.011603, mean_q: 0.006255
 1914/10000: episode: 281, duration: 0.033s, episode steps: 3, steps per second: 92, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000206, mae: 0.010989, mean_q: 0.014457
 1917/10000: episode: 282, duration: 0.031s, episode steps: 3, steps per second: 95, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000154, mae: 0.006361, mean_q: 0.004804
 1920/10000: episode: 283, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000293, mae: 0.011709, mean_q: 0.011881
 1923/10000: episode: 284, duration: 0.031s, episode steps: 3, steps per second: 98, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000315, mae: 0.012486, mean_q: 0.009358
 1926/10000: episode: 285, duration: 0.041s, episode steps: 3, steps per second: 73, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000142, mae: 0.009150, mean_q: 0.012253
 1929/10000: episode: 286, duration: 0.042s, episode steps: 3, steps per second: 72, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000189, mae: 0.010335, mean_q: 0.007741
 1932/10000: episode: 287, duration: 0.046s, episode steps: 3, steps per second: 66, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000192, mae: 0.010033, mean_q: 0.013249
 1935/10000: episode: 288, duration: 0.037s, episode steps: 3, steps per second: 80, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000135, mae: 0.010164, mean_q: 0.003552
 1938/10000: episode: 289, duration: 0.034s, episode steps: 3, steps per second: 89, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000205, mae: 0.011023, mean_q: 0.004736
 1941/10000: episode: 290, duration: 0.037s, episode steps: 3, steps per second: 80, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000147, mae: 0.011820, mean_q: 0.012939
 1944/10000: episode: 291, duration: 0.048s, episode steps: 3, steps per second: 62, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000197, mae: 0.008853, mean_q: 0.003536
 1947/10000: episode: 292, duration: 0.036s, episode steps: 3, steps per second: 84, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000193, mae: 0.010914, mean_q: 0.013108
 1950/10000: episode: 293, duration: 0.034s, episode steps: 3, steps per second: 87, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000152, mae: 0.008592, mean_q: 0.005179
 1953/10000: episode: 294, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000255, mae: 0.011448, mean_q: 0.014299
 1956/10000: episode: 295, duration: 0.032s, episode steps: 3, steps per second: 93, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000191, mae: 0.007300, mean_q: 0.009168
 1959/10000: episode: 296, duration: 0.039s, episode steps: 3, steps per second: 76, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000174, mae: 0.008793, mean_q: 0.003891
 1962/10000: episode: 297, duration: 0.043s, episode steps: 3, steps per second: 69, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000287, mae: 0.011420, mean_q: 0.013259
 1965/10000: episode: 298, duration: 0.034s, episode steps: 3, steps per second: 89, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000246, mae: 0.009132, mean_q: 0.004190
 1968/10000: episode: 299, duration: 0.040s, episode steps: 3, steps per second: 76, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000526, mae: 0.020279, mean_q: 0.023362
 1971/10000: episode: 300, duration: 0.047s, episode steps: 3, steps per second: 64, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000406, mae: 0.020678, mean_q: -0.003607
 1974/10000: episode: 301, duration: 0.034s, episode steps: 3, steps per second: 87, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000291, mae: 0.015308, mean_q: 0.018139
 1977/10000: episode: 302, duration: 0.048s, episode steps: 3, steps per second: 63, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000236, mae: 0.013055, mean_q: 0.006314
 1980/10000: episode: 303, duration: 0.040s, episode steps: 3, steps per second: 76, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000171, mae: 0.010211, mean_q: 0.009058
 1983/10000: episode: 304, duration: 0.041s, episode steps: 3, steps per second: 74, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000209, mae: 0.011499, mean_q: 0.015864
 1986/10000: episode: 305, duration: 0.032s, episode steps: 3, steps per second: 94, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000262, mae: 0.012483, mean_q: 0.005518
 1989/10000: episode: 306, duration: 0.036s, episode steps: 3, steps per second: 84, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000192, mae: 0.009066, mean_q: 0.011046
 1992/10000: episode: 307, duration: 0.033s, episode steps: 3, steps per second: 91, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000332, mae: 0.011295, mean_q: 0.005012
 1995/10000: episode: 308, duration: 0.034s, episode steps: 3, steps per second: 88, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000204, mae: 0.010652, mean_q: 0.012071
 1998/10000: episode: 309, duration: 0.047s, episode steps: 3, steps per second: 63, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000168, mae: 0.009096, mean_q: 0.006609
 2001/10000: episode: 310, duration: 0.046s, episode steps: 3, steps per second: 65, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000267, mae: 0.011432, mean_q: 0.011686
 2004/10000: episode: 311, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000171, mae: 0.009134, mean_q: 0.006811
 2007/10000: episode: 312, duration: 0.036s, episode steps: 3, steps per second: 84, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000345, mae: 0.014164, mean_q: 0.015483
 2010/10000: episode: 313, duration: 0.031s, episode steps: 3, steps per second: 98, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000233, mae: 0.011730, mean_q: 0.007930
 2013/10000: episode: 314, duration: 0.027s, episode steps: 3, steps per second: 112, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000303, mae: 0.011360, mean_q: 0.014695
 2016/10000: episode: 315, duration: 0.027s, episode steps: 3, steps per second: 109, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000318, mae: 0.011015, mean_q: 0.009526
 2019/10000: episode: 316, duration: 0.031s, episode steps: 3, steps per second: 98, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000264, mae: 0.010109, mean_q: 0.008553
 2022/10000: episode: 317, duration: 0.029s, episode steps: 3, steps per second: 104, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000364, mae: 0.013727, mean_q: 0.016038
 2025/10000: episode: 318, duration: 0.028s, episode steps: 3, steps per second: 106, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000280, mae: 0.014022, mean_q: 0.006806
 2028/10000: episode: 319, duration: 0.032s, episode steps: 3, steps per second: 94, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000212, mae: 0.008749, mean_q: 0.011504
 2031/10000: episode: 320, duration: 0.028s, episode steps: 3, steps per second: 109, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000257, mae: 0.011077, mean_q: 0.013688
 2034/10000: episode: 321, duration: 0.033s, episode steps: 3, steps per second: 90, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000472, mae: 0.014753, mean_q: 0.012567
 2037/10000: episode: 322, duration: 0.027s, episode steps: 3, steps per second: 111, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000362, mae: 0.014230, mean_q: 0.017746
 2040/10000: episode: 323, duration: 0.028s, episode steps: 3, steps per second: 109, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000182, mae: 0.008442, mean_q: 0.007559
 2043/10000: episode: 324, duration: 0.028s, episode steps: 3, steps per second: 105, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000300, mae: 0.011270, mean_q: 0.009923
 2046/10000: episode: 325, duration: 0.022s, episode steps: 3, steps per second: 136, episode reward: 0.136, mean reward: 0.045 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000246, mae: 0.011734, mean_q: 0.011839
[Info] 3-TH LEVEL FOUND: 0.08500517904758453, Considering 50/100 traces
 2049/10000: episode: 326, duration: 0.981s, episode steps: 3, steps per second: 3, episode reward: 0.050, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000282, mae: 0.011070, mean_q: 0.009750
 2051/10000: episode: 327, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000219, mae: 0.012008, mean_q: 0.017933
 2053/10000: episode: 328, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000508, mae: 0.015246, mean_q: 0.006854
 2055/10000: episode: 329, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000411, mae: 0.019516, mean_q: 0.025264
 2057/10000: episode: 330, duration: 0.017s, episode steps: 2, steps per second: 117, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000314, mae: 0.010812, mean_q: 0.003610
 2059/10000: episode: 331, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000342, mae: 0.012151, mean_q: 0.012059
 2061/10000: episode: 332, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000138, mae: 0.009619, mean_q: 0.003444
 2063/10000: episode: 333, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000600, mae: 0.016527, mean_q: 0.007633
 2065/10000: episode: 334, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000528, mae: 0.024476, mean_q: 0.032040
 2067/10000: episode: 335, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000115, mae: 0.011394, mean_q: -0.001185
 2069/10000: episode: 336, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000381, mae: 0.013142, mean_q: 0.006294
 2071/10000: episode: 337, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000399, mae: 0.019454, mean_q: 0.023311
 2073/10000: episode: 338, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000314, mae: 0.020158, mean_q: -0.010145
 2075/10000: episode: 339, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000422, mae: 0.017189, mean_q: 0.016940
 2077/10000: episode: 340, duration: 0.014s, episode steps: 2, steps per second: 143, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000655, mae: 0.022158, mean_q: 0.022742
 2079/10000: episode: 341, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000360, mae: 0.014635, mean_q: 0.003966
 2081/10000: episode: 342, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000425, mae: 0.017134, mean_q: 0.008435
 2083/10000: episode: 343, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000088, mae: 0.006593, mean_q: 0.006525
 2085/10000: episode: 344, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000844, mae: 0.018611, mean_q: 0.006134
 2087/10000: episode: 345, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000329, mae: 0.018287, mean_q: 0.023239
 2089/10000: episode: 346, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000390, mae: 0.015082, mean_q: 0.004127
 2091/10000: episode: 347, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000122, mae: 0.010307, mean_q: 0.005045
 2093/10000: episode: 348, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000122, mae: 0.008608, mean_q: 0.015587
 2095/10000: episode: 349, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000172, mae: 0.010804, mean_q: 0.006820
 2097/10000: episode: 350, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000559, mae: 0.014711, mean_q: 0.006764
 2099/10000: episode: 351, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000399, mae: 0.015974, mean_q: 0.016673
 2101/10000: episode: 352, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000575, mae: 0.015425, mean_q: 0.010892
 2103/10000: episode: 353, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000324, mae: 0.013871, mean_q: 0.019711
 2105/10000: episode: 354, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000254, mae: 0.013365, mean_q: 0.007636
 2107/10000: episode: 355, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000462, mae: 0.017952, mean_q: -0.000712
 2109/10000: episode: 356, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000295, mae: 0.014839, mean_q: 0.015212
 2111/10000: episode: 357, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000639, mae: 0.017221, mean_q: 0.008641
 2113/10000: episode: 358, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000291, mae: 0.013010, mean_q: 0.015166
 2115/10000: episode: 359, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000321, mae: 0.012847, mean_q: 0.004519
 2117/10000: episode: 360, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000233, mae: 0.009857, mean_q: 0.011869
 2119/10000: episode: 361, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000351, mae: 0.011723, mean_q: 0.007997
 2121/10000: episode: 362, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000112, mae: 0.008847, mean_q: 0.011282
 2123/10000: episode: 363, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000811, mae: 0.019581, mean_q: 0.011531
 2125/10000: episode: 364, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000184, mae: 0.012329, mean_q: 0.014701
 2127/10000: episode: 365, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000104, mae: 0.009484, mean_q: 0.003311
 2129/10000: episode: 366, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000337, mae: 0.013160, mean_q: 0.016038
 2131/10000: episode: 367, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000217, mae: 0.009076, mean_q: 0.006706
 2133/10000: episode: 368, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000375, mae: 0.013043, mean_q: 0.010221
 2135/10000: episode: 369, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000471, mae: 0.015059, mean_q: 0.004745
 2137/10000: episode: 370, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000521, mae: 0.019308, mean_q: 0.022235
 2139/10000: episode: 371, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000191, mae: 0.009621, mean_q: 0.009757
 2141/10000: episode: 372, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000337, mae: 0.017532, mean_q: 0.003594
 2143/10000: episode: 373, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000219, mae: 0.008536, mean_q: 0.008822
 2145/10000: episode: 374, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000309, mae: 0.013254, mean_q: 0.008752
 2147/10000: episode: 375, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000625, mae: 0.016573, mean_q: 0.011428
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.08500517904758453
 2149/10000: episode: 376, duration: 0.626s, episode steps: 2, steps per second: 3, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000314, mae: 0.016002, mean_q: 0.020409
 2159/10000: episode: 377, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000418, mae: 0.019310, mean_q: 0.008042
 2169/10000: episode: 378, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000408, mae: 0.015365, mean_q: 0.009371
 2179/10000: episode: 379, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000313, mae: 0.015289, mean_q: 0.013041
 2189/10000: episode: 380, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000423, mae: 0.017024, mean_q: 0.010602
 2199/10000: episode: 381, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000361, mae: 0.013260, mean_q: 0.010382
 2209/10000: episode: 382, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.092, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000444, mae: 0.015161, mean_q: 0.013615
 2219/10000: episode: 383, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000289, mae: 0.013167, mean_q: 0.011696
 2229/10000: episode: 384, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000395, mae: 0.016149, mean_q: 0.011084
 2239/10000: episode: 385, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000315, mae: 0.014082, mean_q: 0.009262
 2249/10000: episode: 386, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000261, mae: 0.013507, mean_q: 0.009901
 2259/10000: episode: 387, duration: 0.055s, episode steps: 10, steps per second: 181, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000281, mae: 0.012566, mean_q: 0.010475
 2269/10000: episode: 388, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000359, mae: 0.013181, mean_q: 0.008827
 2279/10000: episode: 389, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000304, mae: 0.015605, mean_q: 0.012452
 2289/10000: episode: 390, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000468, mae: 0.017081, mean_q: 0.013431
 2299/10000: episode: 391, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000246, mae: 0.011014, mean_q: 0.007207
 2309/10000: episode: 392, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000297, mae: 0.015377, mean_q: 0.011801
 2319/10000: episode: 393, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000174, mae: 0.010063, mean_q: 0.009818
 2329/10000: episode: 394, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000334, mae: 0.015399, mean_q: 0.009952
 2339/10000: episode: 395, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000281, mae: 0.012331, mean_q: 0.011459
 2349/10000: episode: 396, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000311, mae: 0.012190, mean_q: 0.009898
 2359/10000: episode: 397, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000252, mae: 0.011239, mean_q: 0.008162
 2369/10000: episode: 398, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000199, mae: 0.010536, mean_q: 0.007414
 2379/10000: episode: 399, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000244, mae: 0.011119, mean_q: 0.007956
 2389/10000: episode: 400, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000288, mae: 0.013380, mean_q: 0.013520
 2399/10000: episode: 401, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000446, mae: 0.017866, mean_q: 0.013351
 2409/10000: episode: 402, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000417, mae: 0.017624, mean_q: 0.007219
 2419/10000: episode: 403, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000250, mae: 0.012084, mean_q: 0.009793
 2429/10000: episode: 404, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000270, mae: 0.010575, mean_q: 0.008468
 2439/10000: episode: 405, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000345, mae: 0.013833, mean_q: 0.013867
 2449/10000: episode: 406, duration: 0.060s, episode steps: 10, steps per second: 168, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000286, mae: 0.012044, mean_q: 0.008659
 2459/10000: episode: 407, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000238, mae: 0.012078, mean_q: 0.009580
 2469/10000: episode: 408, duration: 0.062s, episode steps: 10, steps per second: 162, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000383, mae: 0.014091, mean_q: 0.012264
 2479/10000: episode: 409, duration: 0.057s, episode steps: 10, steps per second: 174, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000261, mae: 0.012707, mean_q: 0.007426
 2489/10000: episode: 410, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000254, mae: 0.012602, mean_q: 0.007609
 2499/10000: episode: 411, duration: 0.055s, episode steps: 10, steps per second: 183, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000267, mae: 0.011970, mean_q: 0.008187
 2509/10000: episode: 412, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000253, mae: 0.012002, mean_q: 0.011335
 2519/10000: episode: 413, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000384, mae: 0.017816, mean_q: 0.008963
 2529/10000: episode: 414, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000327, mae: 0.013291, mean_q: 0.009557
 2539/10000: episode: 415, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000250, mae: 0.013679, mean_q: 0.009436
 2549/10000: episode: 416, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000336, mae: 0.012273, mean_q: 0.010793
 2559/10000: episode: 417, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000263, mae: 0.011003, mean_q: 0.008252
 2569/10000: episode: 418, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000371, mae: 0.016383, mean_q: 0.010511
 2579/10000: episode: 419, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000278, mae: 0.012722, mean_q: 0.010164
 2589/10000: episode: 420, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000240, mae: 0.011687, mean_q: 0.011225
 2599/10000: episode: 421, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000301, mae: 0.013692, mean_q: 0.006873
 2609/10000: episode: 422, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000229, mae: 0.013216, mean_q: 0.011690
 2619/10000: episode: 423, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000335, mae: 0.013541, mean_q: 0.007775
 2629/10000: episode: 424, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000235, mae: 0.010398, mean_q: 0.009912
 2639/10000: episode: 425, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000260, mae: 0.011145, mean_q: 0.010439
 2649/10000: episode: 426, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000188, mae: 0.009589, mean_q: 0.012111
 2659/10000: episode: 427, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000295, mae: 0.012924, mean_q: 0.009153
 2669/10000: episode: 428, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000405, mae: 0.017889, mean_q: 0.008139
 2679/10000: episode: 429, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000276, mae: 0.016695, mean_q: 0.010089
 2689/10000: episode: 430, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000334, mae: 0.012915, mean_q: 0.010137
 2699/10000: episode: 431, duration: 0.067s, episode steps: 10, steps per second: 149, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000213, mae: 0.010615, mean_q: 0.007357
 2709/10000: episode: 432, duration: 0.052s, episode steps: 10, steps per second: 191, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000246, mae: 0.012619, mean_q: 0.009720
 2719/10000: episode: 433, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000213, mae: 0.009927, mean_q: 0.008717
 2729/10000: episode: 434, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000284, mae: 0.014011, mean_q: 0.009089
 2739/10000: episode: 435, duration: 0.069s, episode steps: 10, steps per second: 145, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000237, mae: 0.010862, mean_q: 0.007631
 2749/10000: episode: 436, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000163, mae: 0.009412, mean_q: 0.009325
 2759/10000: episode: 437, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000251, mae: 0.010560, mean_q: 0.008991
 2769/10000: episode: 438, duration: 0.062s, episode steps: 10, steps per second: 160, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000159, mae: 0.008994, mean_q: 0.008805
 2779/10000: episode: 439, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000224, mae: 0.009575, mean_q: 0.007909
 2789/10000: episode: 440, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000274, mae: 0.012758, mean_q: 0.010184
 2799/10000: episode: 441, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000389, mae: 0.014068, mean_q: 0.011221
 2809/10000: episode: 442, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000287, mae: 0.012870, mean_q: 0.007662
 2819/10000: episode: 443, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000280, mae: 0.012623, mean_q: 0.010820
 2829/10000: episode: 444, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000255, mae: 0.011356, mean_q: 0.009503
 2839/10000: episode: 445, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000309, mae: 0.011443, mean_q: 0.009212
 2849/10000: episode: 446, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000166, mae: 0.009447, mean_q: 0.008106
 2859/10000: episode: 447, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000227, mae: 0.010103, mean_q: 0.008021
 2869/10000: episode: 448, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000257, mae: 0.011836, mean_q: 0.009795
 2879/10000: episode: 449, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000309, mae: 0.010717, mean_q: 0.006028
 2889/10000: episode: 450, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000407, mae: 0.018763, mean_q: 0.012987
 2899/10000: episode: 451, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000296, mae: 0.015888, mean_q: 0.006313
 2909/10000: episode: 452, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000249, mae: 0.013139, mean_q: 0.008077
 2919/10000: episode: 453, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000241, mae: 0.010346, mean_q: 0.008658
 2929/10000: episode: 454, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000235, mae: 0.012960, mean_q: 0.009911
 2939/10000: episode: 455, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000156, mae: 0.009170, mean_q: 0.007740
 2949/10000: episode: 456, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000298, mae: 0.013702, mean_q: 0.009769
 2959/10000: episode: 457, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000241, mae: 0.013695, mean_q: 0.010304
 2969/10000: episode: 458, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000231, mae: 0.009595, mean_q: 0.008916
 2979/10000: episode: 459, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000156, mae: 0.008974, mean_q: 0.007669
 2989/10000: episode: 460, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000192, mae: 0.009359, mean_q: 0.007807
 2999/10000: episode: 461, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000220, mae: 0.011309, mean_q: 0.009847
 3009/10000: episode: 462, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000215, mae: 0.010365, mean_q: 0.007878
 3019/10000: episode: 463, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000217, mae: 0.010509, mean_q: 0.008967
 3029/10000: episode: 464, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000249, mae: 0.011786, mean_q: 0.010202
 3039/10000: episode: 465, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000212, mae: 0.011234, mean_q: 0.007678
 3049/10000: episode: 466, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000197, mae: 0.010464, mean_q: 0.006344
 3059/10000: episode: 467, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.026, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000290, mae: 0.014859, mean_q: 0.010634
 3069/10000: episode: 468, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000242, mae: 0.010304, mean_q: 0.008667
 3079/10000: episode: 469, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000172, mae: 0.009156, mean_q: 0.008481
 3089/10000: episode: 470, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000220, mae: 0.009057, mean_q: 0.008084
 3099/10000: episode: 471, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000309, mae: 0.015142, mean_q: 0.008198
 3109/10000: episode: 472, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000170, mae: 0.011870, mean_q: 0.007464
 3119/10000: episode: 473, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000313, mae: 0.013448, mean_q: 0.013726
 3129/10000: episode: 474, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000217, mae: 0.011963, mean_q: 0.007960
 3139/10000: episode: 475, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000201, mae: 0.010015, mean_q: 0.008046
[Info] 1-TH LEVEL FOUND: 0.05182669684290886, Considering 13/100 traces
 3149/10000: episode: 476, duration: 0.660s, episode steps: 10, steps per second: 15, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000242, mae: 0.011387, mean_q: 0.009520
 3153/10000: episode: 477, duration: 0.033s, episode steps: 4, steps per second: 123, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000497, mae: 0.018338, mean_q: 0.010256
 3157/10000: episode: 478, duration: 0.023s, episode steps: 4, steps per second: 177, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000287, mae: 0.011842, mean_q: 0.012613
 3161/10000: episode: 479, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000265, mae: 0.012078, mean_q: 0.005868
 3165/10000: episode: 480, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000303, mae: 0.011241, mean_q: 0.010974
 3167/10000: episode: 481, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000139, mae: 0.009464, mean_q: 0.007730
 3169/10000: episode: 482, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000215, mae: 0.010436, mean_q: 0.009556
 3171/10000: episode: 483, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000209, mae: 0.010666, mean_q: 0.014926
 3173/10000: episode: 484, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000276, mae: 0.015192, mean_q: -0.004082
 3177/10000: episode: 485, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000209, mae: 0.013838, mean_q: 0.016151
 3179/10000: episode: 486, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000160, mae: 0.013353, mean_q: -0.001762
 3181/10000: episode: 487, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000193, mae: 0.012801, mean_q: 0.017020
 3183/10000: episode: 488, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000325, mae: 0.010228, mean_q: 0.004365
 3185/10000: episode: 489, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000071, mae: 0.008573, mean_q: 0.011517
 3187/10000: episode: 490, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000308, mae: 0.010957, mean_q: 0.011948
 3191/10000: episode: 491, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000221, mae: 0.010253, mean_q: 0.012628
 3195/10000: episode: 492, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000309, mae: 0.012618, mean_q: 0.011316
 3199/10000: episode: 493, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000261, mae: 0.012127, mean_q: 0.010209
 3201/10000: episode: 494, duration: 0.016s, episode steps: 2, steps per second: 127, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000171, mae: 0.008749, mean_q: 0.011809
 3203/10000: episode: 495, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000105, mae: 0.008511, mean_q: 0.013418
 3205/10000: episode: 496, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000072, mae: 0.007563, mean_q: 0.004850
 3207/10000: episode: 497, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000110, mae: 0.007911, mean_q: 0.004006
 3211/10000: episode: 498, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000260, mae: 0.009742, mean_q: 0.007995
 3215/10000: episode: 499, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000133, mae: 0.009276, mean_q: 0.006077
 3219/10000: episode: 500, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000212, mae: 0.010691, mean_q: 0.008020
 3223/10000: episode: 501, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000172, mae: 0.010066, mean_q: 0.008861
 3225/10000: episode: 502, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000219, mae: 0.008961, mean_q: 0.010094
 3227/10000: episode: 503, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000140, mae: 0.009617, mean_q: 0.013069
 3229/10000: episode: 504, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000281, mae: 0.014727, mean_q: 0.000863
 3233/10000: episode: 505, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000261, mae: 0.012334, mean_q: 0.011878
 3235/10000: episode: 506, duration: 0.014s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000520, mae: 0.015603, mean_q: 0.003036
 3237/10000: episode: 507, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000213, mae: 0.010197, mean_q: 0.014727
 3239/10000: episode: 508, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000221, mae: 0.010625, mean_q: 0.003625
 3241/10000: episode: 509, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000257, mae: 0.012154, mean_q: 0.014906
 3245/10000: episode: 510, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000205, mae: 0.009403, mean_q: 0.008525
 3249/10000: episode: 511, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000244, mae: 0.010785, mean_q: 0.013640
 3253/10000: episode: 512, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000100, mae: 0.008771, mean_q: 0.003747
 3255/10000: episode: 513, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000119, mae: 0.010428, mean_q: 0.013037
 3259/10000: episode: 514, duration: 0.022s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000217, mae: 0.010481, mean_q: 0.005177
 3263/10000: episode: 515, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000173, mae: 0.009869, mean_q: 0.012199
 3265/10000: episode: 516, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000361, mae: 0.013584, mean_q: 0.007186
 3267/10000: episode: 517, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000092, mae: 0.007766, mean_q: 0.010652
 3271/10000: episode: 518, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000164, mae: 0.010960, mean_q: 0.005687
 3275/10000: episode: 519, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000193, mae: 0.010510, mean_q: 0.008936
 3277/10000: episode: 520, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000230, mae: 0.009331, mean_q: 0.007160
 3279/10000: episode: 521, duration: 0.014s, episode steps: 2, steps per second: 140, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000120, mae: 0.008539, mean_q: 0.010402
 3281/10000: episode: 522, duration: 0.014s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000055, mae: 0.006816, mean_q: 0.001415
 3283/10000: episode: 523, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000319, mae: 0.012174, mean_q: 0.012443
 3285/10000: episode: 524, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000188, mae: 0.009124, mean_q: 0.008323
 3287/10000: episode: 525, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000110, mae: 0.009863, mean_q: 0.004942
 3289/10000: episode: 526, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000425, mae: 0.014475, mean_q: 0.013149
 3293/10000: episode: 527, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000173, mae: 0.010565, mean_q: 0.005668
 3295/10000: episode: 528, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000254, mae: 0.012305, mean_q: 0.001789
 3297/10000: episode: 529, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000153, mae: 0.012198, mean_q: 0.012879
 3299/10000: episode: 530, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000426, mae: 0.012098, mean_q: 0.001542
 3301/10000: episode: 531, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000248, mae: 0.013563, mean_q: 0.015796
 3305/10000: episode: 532, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000314, mae: 0.013309, mean_q: 0.005240
 3309/10000: episode: 533, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000230, mae: 0.013369, mean_q: 0.017358
 3311/10000: episode: 534, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000155, mae: 0.010474, mean_q: 0.006215
 3313/10000: episode: 535, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000220, mae: 0.011215, mean_q: 0.016898
 3315/10000: episode: 536, duration: 0.015s, episode steps: 2, steps per second: 133, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000231, mae: 0.010412, mean_q: 0.008885
 3317/10000: episode: 537, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000117, mae: 0.011458, mean_q: 0.000418
 3319/10000: episode: 538, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000228, mae: 0.011220, mean_q: 0.011596
 3321/10000: episode: 539, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000098, mae: 0.007796, mean_q: 0.008596
 3323/10000: episode: 540, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000302, mae: 0.010977, mean_q: 0.001569
 3325/10000: episode: 541, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000296, mae: 0.015401, mean_q: 0.023025
 3327/10000: episode: 542, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000243, mae: 0.016161, mean_q: -0.005148
 3329/10000: episode: 543, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000330, mae: 0.016596, mean_q: 0.016979
 3331/10000: episode: 544, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000204, mae: 0.011717, mean_q: 0.011943
 3333/10000: episode: 545, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000304, mae: 0.012974, mean_q: -0.004676
 3335/10000: episode: 546, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000340, mae: 0.016733, mean_q: 0.016946
 3339/10000: episode: 547, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000278, mae: 0.014136, mean_q: 0.008789
 3341/10000: episode: 548, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000060, mae: 0.007136, mean_q: 0.008621
 3343/10000: episode: 549, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000322, mae: 0.012169, mean_q: 0.014461
 3345/10000: episode: 550, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000350, mae: 0.013354, mean_q: 0.009239
 3347/10000: episode: 551, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000256, mae: 0.011690, mean_q: 0.006207
 3349/10000: episode: 552, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000270, mae: 0.012830, mean_q: 0.009276
 3351/10000: episode: 553, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000172, mae: 0.007722, mean_q: 0.007967
 3355/10000: episode: 554, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000285, mae: 0.012578, mean_q: 0.012031
 3359/10000: episode: 555, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000337, mae: 0.014632, mean_q: 0.008674
 3361/10000: episode: 556, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000216, mae: 0.009637, mean_q: 0.010202
 3363/10000: episode: 557, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000026, mae: 0.004945, mean_q: 0.001492
 3367/10000: episode: 558, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000139, mae: 0.008729, mean_q: 0.006537
 3369/10000: episode: 559, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000082, mae: 0.006057, mean_q: 0.004690
 3371/10000: episode: 560, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000208, mae: 0.010290, mean_q: 0.012834
 3373/10000: episode: 561, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000203, mae: 0.010937, mean_q: 0.011730
 3375/10000: episode: 562, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000235, mae: 0.013064, mean_q: 0.000815
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.05182669684290886
 3379/10000: episode: 563, duration: 0.502s, episode steps: 4, steps per second: 8, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000226, mae: 0.011774, mean_q: 0.012402
 3389/10000: episode: 564, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000237, mae: 0.011051, mean_q: 0.007077
 3399/10000: episode: 565, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000172, mae: 0.008601, mean_q: 0.007268
 3409/10000: episode: 566, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000278, mae: 0.013861, mean_q: 0.010356
 3419/10000: episode: 567, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000253, mae: 0.011125, mean_q: 0.008204
 3429/10000: episode: 568, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000271, mae: 0.010976, mean_q: 0.009579
 3439/10000: episode: 569, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000208, mae: 0.011922, mean_q: 0.010385
 3449/10000: episode: 570, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000355, mae: 0.016827, mean_q: 0.010709
 3459/10000: episode: 571, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000187, mae: 0.013162, mean_q: 0.007531
 3469/10000: episode: 572, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000281, mae: 0.012748, mean_q: 0.009340
 3479/10000: episode: 573, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000188, mae: 0.010355, mean_q: 0.008024
 3489/10000: episode: 574, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000196, mae: 0.009590, mean_q: 0.008820
 3499/10000: episode: 575, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000223, mae: 0.012871, mean_q: 0.009593
 3509/10000: episode: 576, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000216, mae: 0.009133, mean_q: 0.008180
 3519/10000: episode: 577, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.025, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000269, mae: 0.013431, mean_q: 0.008286
 3529/10000: episode: 578, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000265, mae: 0.010914, mean_q: 0.008456
 3539/10000: episode: 579, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000238, mae: 0.010690, mean_q: 0.007758
 3549/10000: episode: 580, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000090, mae: 0.007075, mean_q: 0.006560
 3559/10000: episode: 581, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000284, mae: 0.012265, mean_q: 0.011363
 3569/10000: episode: 582, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000279, mae: 0.014705, mean_q: 0.004503
 3579/10000: episode: 583, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000235, mae: 0.013640, mean_q: 0.011603
 3589/10000: episode: 584, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.082, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000313, mae: 0.013777, mean_q: 0.009439
 3599/10000: episode: 585, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000255, mae: 0.012838, mean_q: 0.008288
 3609/10000: episode: 586, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000220, mae: 0.011904, mean_q: 0.009312
 3619/10000: episode: 587, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000216, mae: 0.012372, mean_q: 0.007520
 3629/10000: episode: 588, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000251, mae: 0.011584, mean_q: 0.010324
 3639/10000: episode: 589, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000211, mae: 0.010660, mean_q: 0.008798
 3649/10000: episode: 590, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000181, mae: 0.010074, mean_q: 0.006422
 3659/10000: episode: 591, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000284, mae: 0.013512, mean_q: 0.012157
 3669/10000: episode: 592, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000244, mae: 0.013882, mean_q: 0.008233
 3679/10000: episode: 593, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.052, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000298, mae: 0.014026, mean_q: 0.006430
 3689/10000: episode: 594, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000218, mae: 0.011156, mean_q: 0.010882
 3699/10000: episode: 595, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000166, mae: 0.009478, mean_q: 0.009261
 3709/10000: episode: 596, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000200, mae: 0.010478, mean_q: 0.007084
 3719/10000: episode: 597, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.215, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000234, mae: 0.013081, mean_q: 0.007522
 3729/10000: episode: 598, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000202, mae: 0.010712, mean_q: 0.007805
 3739/10000: episode: 599, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000280, mae: 0.014466, mean_q: 0.011794
 3749/10000: episode: 600, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000261, mae: 0.014023, mean_q: 0.007434
 3759/10000: episode: 601, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000189, mae: 0.009594, mean_q: 0.007330
 3769/10000: episode: 602, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000164, mae: 0.007578, mean_q: 0.007780
 3779/10000: episode: 603, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000174, mae: 0.008216, mean_q: 0.007122
 3789/10000: episode: 604, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000133, mae: 0.007693, mean_q: 0.007324
 3799/10000: episode: 605, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000219, mae: 0.010795, mean_q: 0.008594
 3809/10000: episode: 606, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000300, mae: 0.014732, mean_q: 0.010829
 3819/10000: episode: 607, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000191, mae: 0.009219, mean_q: 0.007400
 3829/10000: episode: 608, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000275, mae: 0.012953, mean_q: 0.009956
 3839/10000: episode: 609, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000212, mae: 0.013044, mean_q: 0.006752
 3849/10000: episode: 610, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000212, mae: 0.011462, mean_q: 0.008373
 3859/10000: episode: 611, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000220, mae: 0.010463, mean_q: 0.010791
 3869/10000: episode: 612, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000205, mae: 0.010818, mean_q: 0.005989
 3879/10000: episode: 613, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000186, mae: 0.011193, mean_q: 0.006003
 3889/10000: episode: 614, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000289, mae: 0.013268, mean_q: 0.011255
 3899/10000: episode: 615, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000247, mae: 0.012793, mean_q: 0.004917
 3909/10000: episode: 616, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000358, mae: 0.016698, mean_q: 0.010091
 3919/10000: episode: 617, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000233, mae: 0.012684, mean_q: 0.008116
 3929/10000: episode: 618, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000317, mae: 0.012997, mean_q: 0.009287
 3939/10000: episode: 619, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000232, mae: 0.009731, mean_q: 0.009822
 3949/10000: episode: 620, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000195, mae: 0.010329, mean_q: 0.007945
 3959/10000: episode: 621, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000253, mae: 0.010654, mean_q: 0.007706
 3969/10000: episode: 622, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000224, mae: 0.009523, mean_q: 0.009385
 3979/10000: episode: 623, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000162, mae: 0.008982, mean_q: 0.008144
 3989/10000: episode: 624, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000312, mae: 0.014095, mean_q: 0.007757
 3999/10000: episode: 625, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.050, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000176, mae: 0.010489, mean_q: 0.008456
 4009/10000: episode: 626, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000190, mae: 0.009826, mean_q: 0.007307
 4019/10000: episode: 627, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000166, mae: 0.008236, mean_q: 0.007485
 4029/10000: episode: 628, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000308, mae: 0.011743, mean_q: 0.009330
 4039/10000: episode: 629, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000193, mae: 0.009345, mean_q: 0.009162
 4049/10000: episode: 630, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000168, mae: 0.011386, mean_q: 0.004844
 4059/10000: episode: 631, duration: 0.045s, episode steps: 10, steps per second: 221, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000195, mae: 0.009708, mean_q: 0.010840
 4069/10000: episode: 632, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000149, mae: 0.008085, mean_q: 0.007287
 4079/10000: episode: 633, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000229, mae: 0.012985, mean_q: 0.008065
 4089/10000: episode: 634, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000294, mae: 0.013907, mean_q: 0.011984
 4099/10000: episode: 635, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000242, mae: 0.009846, mean_q: 0.008606
 4109/10000: episode: 636, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000258, mae: 0.013081, mean_q: 0.010200
 4119/10000: episode: 637, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000273, mae: 0.011228, mean_q: 0.009323
 4129/10000: episode: 638, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.061, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000174, mae: 0.010326, mean_q: 0.007702
 4139/10000: episode: 639, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000227, mae: 0.010613, mean_q: 0.009365
 4149/10000: episode: 640, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000202, mae: 0.010497, mean_q: 0.010057
 4159/10000: episode: 641, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000245, mae: 0.011288, mean_q: 0.008566
 4169/10000: episode: 642, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000229, mae: 0.010665, mean_q: 0.009854
 4179/10000: episode: 643, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000264, mae: 0.011136, mean_q: 0.010099
 4189/10000: episode: 644, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000178, mae: 0.008376, mean_q: 0.007847
 4199/10000: episode: 645, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000195, mae: 0.011511, mean_q: 0.008288
 4209/10000: episode: 646, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000153, mae: 0.009604, mean_q: 0.004667
 4219/10000: episode: 647, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000220, mae: 0.010405, mean_q: 0.009394
 4229/10000: episode: 648, duration: 0.052s, episode steps: 10, steps per second: 194, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000142, mae: 0.009448, mean_q: 0.007598
 4239/10000: episode: 649, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.147, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000215, mae: 0.011075, mean_q: 0.009423
 4249/10000: episode: 650, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000240, mae: 0.011650, mean_q: 0.009599
 4259/10000: episode: 651, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000233, mae: 0.012280, mean_q: 0.006153
 4269/10000: episode: 652, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000211, mae: 0.009850, mean_q: 0.008088
 4279/10000: episode: 653, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000182, mae: 0.008907, mean_q: 0.008470
 4289/10000: episode: 654, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000219, mae: 0.012910, mean_q: 0.009719
 4299/10000: episode: 655, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000209, mae: 0.011510, mean_q: 0.005983
 4309/10000: episode: 656, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000224, mae: 0.010579, mean_q: 0.009491
 4319/10000: episode: 657, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000126, mae: 0.008381, mean_q: 0.006615
 4329/10000: episode: 658, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000188, mae: 0.009595, mean_q: 0.008576
 4339/10000: episode: 659, duration: 0.051s, episode steps: 10, steps per second: 198, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000096, mae: 0.006194, mean_q: 0.005321
 4349/10000: episode: 660, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.016, mean reward: 0.002 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000257, mae: 0.011459, mean_q: 0.010567
 4359/10000: episode: 661, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000172, mae: 0.009610, mean_q: 0.009486
 4369/10000: episode: 662, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000200, mae: 0.011062, mean_q: 0.005721
[Info] 1-TH LEVEL FOUND: 0.045583873987197876, Considering 11/100 traces
 4379/10000: episode: 663, duration: 0.768s, episode steps: 10, steps per second: 13, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000233, mae: 0.009705, mean_q: 0.007123
 4381/10000: episode: 664, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000200, mae: 0.012262, mean_q: 0.015204
 4385/10000: episode: 665, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000237, mae: 0.012267, mean_q: 0.006907
 4387/10000: episode: 666, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000261, mae: 0.011451, mean_q: 0.007823
 4391/10000: episode: 667, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000109, mae: 0.008445, mean_q: 0.003138
 4395/10000: episode: 668, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000208, mae: 0.010828, mean_q: 0.011392
 4399/10000: episode: 669, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000172, mae: 0.010166, mean_q: 0.009192
 4403/10000: episode: 670, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000250, mae: 0.011970, mean_q: 0.011567
 4407/10000: episode: 671, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000307, mae: 0.013089, mean_q: 0.008902
 4411/10000: episode: 672, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000214, mae: 0.011372, mean_q: 0.012742
 4415/10000: episode: 673, duration: 0.025s, episode steps: 4, steps per second: 158, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000309, mae: 0.015363, mean_q: 0.005329
 4419/10000: episode: 674, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000142, mae: 0.008765, mean_q: 0.006248
 4423/10000: episode: 675, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000389, mae: 0.013781, mean_q: 0.014774
 4427/10000: episode: 676, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000165, mae: 0.010607, mean_q: 0.006734
 4431/10000: episode: 677, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000145, mae: 0.008930, mean_q: 0.004174
 4435/10000: episode: 678, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000338, mae: 0.013399, mean_q: 0.013913
 4439/10000: episode: 679, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000195, mae: 0.010421, mean_q: 0.007175
 4443/10000: episode: 680, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000121, mae: 0.006836, mean_q: 0.007642
 4447/10000: episode: 681, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000251, mae: 0.009492, mean_q: 0.006807
 4451/10000: episode: 682, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000113, mae: 0.010293, mean_q: 0.009159
 4455/10000: episode: 683, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000336, mae: 0.015209, mean_q: 0.011854
 4459/10000: episode: 684, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000356, mae: 0.012059, mean_q: 0.007702
 4463/10000: episode: 685, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000141, mae: 0.008184, mean_q: 0.006960
 4467/10000: episode: 686, duration: 0.024s, episode steps: 4, steps per second: 169, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000143, mae: 0.008328, mean_q: 0.011253
 4471/10000: episode: 687, duration: 0.023s, episode steps: 4, steps per second: 173, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000180, mae: 0.008715, mean_q: 0.009696
 4475/10000: episode: 688, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000242, mae: 0.011425, mean_q: 0.013836
 4479/10000: episode: 689, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000256, mae: 0.010353, mean_q: 0.009870
 4483/10000: episode: 690, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000283, mae: 0.010479, mean_q: 0.007559
 4487/10000: episode: 691, duration: 0.023s, episode steps: 4, steps per second: 174, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000114, mae: 0.008312, mean_q: 0.009636
 4491/10000: episode: 692, duration: 0.025s, episode steps: 4, steps per second: 159, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000210, mae: 0.011698, mean_q: 0.006617
 4495/10000: episode: 693, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000196, mae: 0.013057, mean_q: 0.005425
 4499/10000: episode: 694, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000198, mae: 0.012356, mean_q: 0.016036
 4503/10000: episode: 695, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000159, mae: 0.009237, mean_q: 0.001779
 4507/10000: episode: 696, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000222, mae: 0.010783, mean_q: 0.012204
 4511/10000: episode: 697, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000239, mae: 0.009596, mean_q: 0.008546
 4515/10000: episode: 698, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000318, mae: 0.011042, mean_q: 0.010639
 4519/10000: episode: 699, duration: 0.025s, episode steps: 4, steps per second: 162, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000132, mae: 0.007669, mean_q: 0.010630
 4521/10000: episode: 700, duration: 0.013s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000224, mae: 0.011643, mean_q: 0.002092
 4525/10000: episode: 701, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000194, mae: 0.011108, mean_q: 0.011220
 4529/10000: episode: 702, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000169, mae: 0.009291, mean_q: 0.007622
 4533/10000: episode: 703, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000152, mae: 0.012257, mean_q: 0.005818
 4537/10000: episode: 704, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000147, mae: 0.010893, mean_q: 0.013436
 4541/10000: episode: 705, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000263, mae: 0.011286, mean_q: 0.003738
 4545/10000: episode: 706, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000170, mae: 0.010376, mean_q: 0.012718
 4549/10000: episode: 707, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000221, mae: 0.010464, mean_q: 0.005597
 4553/10000: episode: 708, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000130, mae: 0.008045, mean_q: 0.001210
 4555/10000: episode: 709, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000288, mae: 0.015625, mean_q: 0.017784
 4559/10000: episode: 710, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000232, mae: 0.011115, mean_q: 0.002406
 4563/10000: episode: 711, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000195, mae: 0.012668, mean_q: 0.012919
 4567/10000: episode: 712, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000325, mae: 0.013298, mean_q: 0.014797
 4571/10000: episode: 713, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000181, mae: 0.010488, mean_q: 0.006306
 4575/10000: episode: 714, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000256, mae: 0.011317, mean_q: 0.006984
 4579/10000: episode: 715, duration: 0.026s, episode steps: 4, steps per second: 153, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000162, mae: 0.010559, mean_q: 0.011965
 4583/10000: episode: 716, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000301, mae: 0.013398, mean_q: 0.006475
 4587/10000: episode: 717, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000215, mae: 0.011599, mean_q: 0.004496
 4591/10000: episode: 718, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000219, mae: 0.011880, mean_q: 0.014748
 4595/10000: episode: 719, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000223, mae: 0.010026, mean_q: 0.009349
 4599/10000: episode: 720, duration: 0.021s, episode steps: 4, steps per second: 193, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000220, mae: 0.011693, mean_q: 0.014444
 4603/10000: episode: 721, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000327, mae: 0.013387, mean_q: 0.011966
 4607/10000: episode: 722, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000303, mae: 0.015725, mean_q: 0.006335
 4611/10000: episode: 723, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000163, mae: 0.011756, mean_q: 0.015985
 4615/10000: episode: 724, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000162, mae: 0.010893, mean_q: 0.000987
 4619/10000: episode: 725, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000355, mae: 0.014123, mean_q: 0.008694
 4623/10000: episode: 726, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000207, mae: 0.013619, mean_q: 0.018988
 4625/10000: episode: 727, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000278, mae: 0.018442, mean_q: -0.009227
 4629/10000: episode: 728, duration: 0.021s, episode steps: 4, steps per second: 191, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000408, mae: 0.018319, mean_q: 0.019989
 4633/10000: episode: 729, duration: 0.023s, episode steps: 4, steps per second: 176, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000347, mae: 0.013206, mean_q: 0.009757
 4637/10000: episode: 730, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000181, mae: 0.011839, mean_q: 0.006116
 4639/10000: episode: 731, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000199, mae: 0.008861, mean_q: 0.013217
 4643/10000: episode: 732, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000182, mae: 0.008129, mean_q: 0.006105
 4647/10000: episode: 733, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000164, mae: 0.008342, mean_q: 0.011240
 4651/10000: episode: 734, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000202, mae: 0.010065, mean_q: 0.011191
 4653/10000: episode: 735, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000326, mae: 0.010852, mean_q: 0.006649
 4657/10000: episode: 736, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000236, mae: 0.010538, mean_q: 0.013455
 4659/10000: episode: 737, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000191, mae: 0.009962, mean_q: 0.002981
 4663/10000: episode: 738, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000196, mae: 0.010063, mean_q: 0.010624
 4667/10000: episode: 739, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000212, mae: 0.010679, mean_q: 0.013137
 4671/10000: episode: 740, duration: 0.025s, episode steps: 4, steps per second: 160, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000108, mae: 0.009537, mean_q: 0.006032
 4675/10000: episode: 741, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000231, mae: 0.013232, mean_q: 0.013433
 4677/10000: episode: 742, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000050, mae: 0.005227, mean_q: 0.005324
 4681/10000: episode: 743, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000231, mae: 0.011528, mean_q: 0.013825
 4685/10000: episode: 744, duration: 0.020s, episode steps: 4, steps per second: 196, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000224, mae: 0.012737, mean_q: 0.001059
 4689/10000: episode: 745, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000247, mae: 0.012090, mean_q: 0.012255
 4693/10000: episode: 746, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000466, mae: 0.016343, mean_q: 0.016591
 4697/10000: episode: 747, duration: 0.021s, episode steps: 4, steps per second: 190, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000496, mae: 0.020397, mean_q: 0.007730
 4701/10000: episode: 748, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000305, mae: 0.013494, mean_q: 0.016600
 4705/10000: episode: 749, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000415, mae: 0.015059, mean_q: 0.005971
 4709/10000: episode: 750, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000160, mae: 0.012286, mean_q: 0.014797
 4713/10000: episode: 751, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000186, mae: 0.010540, mean_q: 0.008995
[Info] 2-TH LEVEL FOUND: 0.05737252160906792, Considering 30/100 traces
 4717/10000: episode: 752, duration: 0.667s, episode steps: 4, steps per second: 6, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000404, mae: 0.013205, mean_q: 0.009668
 4719/10000: episode: 753, duration: 0.020s, episode steps: 2, steps per second: 101, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000203, mae: 0.010833, mean_q: 0.014599
 4721/10000: episode: 754, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000338, mae: 0.012872, mean_q: 0.010032
 4723/10000: episode: 755, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000220, mae: 0.011408, mean_q: 0.008684
 4725/10000: episode: 756, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000305, mae: 0.011624, mean_q: 0.014655
 4727/10000: episode: 757, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000433, mae: 0.013516, mean_q: 0.006271
 4729/10000: episode: 758, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000397, mae: 0.017461, mean_q: 0.021277
 4731/10000: episode: 759, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000276, mae: 0.015338, mean_q: -0.000435
 4733/10000: episode: 760, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000079, mae: 0.008029, mean_q: 0.009749
 4735/10000: episode: 761, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000333, mae: 0.012940, mean_q: 0.013806
 4737/10000: episode: 762, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000281, mae: 0.011821, mean_q: 0.006734
 4739/10000: episode: 763, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000239, mae: 0.011061, mean_q: 0.010296
 4741/10000: episode: 764, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000350, mae: 0.013593, mean_q: 0.015672
 4743/10000: episode: 765, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000412, mae: 0.013981, mean_q: 0.016697
 4745/10000: episode: 766, duration: 0.012s, episode steps: 2, steps per second: 166, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000049, mae: 0.006694, mean_q: 0.009294
 4747/10000: episode: 767, duration: 0.016s, episode steps: 2, steps per second: 123, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000271, mae: 0.012372, mean_q: 0.013822
 4749/10000: episode: 768, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000240, mae: 0.010681, mean_q: 0.011636
 4751/10000: episode: 769, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000414, mae: 0.014592, mean_q: 0.005398
 4753/10000: episode: 770, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000272, mae: 0.014429, mean_q: 0.017273
 4755/10000: episode: 771, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000269, mae: 0.013558, mean_q: 0.002303
 4757/10000: episode: 772, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000461, mae: 0.016493, mean_q: 0.020561
 4759/10000: episode: 773, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000125, mae: 0.009853, mean_q: 0.011448
 4761/10000: episode: 774, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000093, mae: 0.009628, mean_q: 0.003045
 4763/10000: episode: 775, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000356, mae: 0.015929, mean_q: 0.017306
 4765/10000: episode: 776, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000159, mae: 0.009008, mean_q: 0.006141
 4767/10000: episode: 777, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000049, mae: 0.006147, mean_q: 0.007123
 4769/10000: episode: 778, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000454, mae: 0.014710, mean_q: 0.014475
 4771/10000: episode: 779, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000241, mae: 0.010295, mean_q: 0.012632
 4773/10000: episode: 780, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000486, mae: 0.019220, mean_q: 0.014560
 4775/10000: episode: 781, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000189, mae: 0.010194, mean_q: 0.007106
 4777/10000: episode: 782, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000448, mae: 0.017909, mean_q: 0.020196
 4779/10000: episode: 783, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000436, mae: 0.014939, mean_q: 0.003452
 4781/10000: episode: 784, duration: 0.012s, episode steps: 2, steps per second: 164, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000220, mae: 0.010926, mean_q: 0.012874
 4783/10000: episode: 785, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000362, mae: 0.013653, mean_q: 0.015212
 4785/10000: episode: 786, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000329, mae: 0.014671, mean_q: 0.014431
 4787/10000: episode: 787, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000440, mae: 0.016688, mean_q: 0.010871
 4789/10000: episode: 788, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000110, mae: 0.010025, mean_q: 0.012224
 4791/10000: episode: 789, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000370, mae: 0.014059, mean_q: 0.010483
 4793/10000: episode: 790, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000184, mae: 0.008460, mean_q: 0.009640
 4795/10000: episode: 791, duration: 0.012s, episode steps: 2, steps per second: 165, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000318, mae: 0.015568, mean_q: 0.007331
 4797/10000: episode: 792, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000243, mae: 0.010857, mean_q: 0.012641
 4799/10000: episode: 793, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000157, mae: 0.010066, mean_q: 0.009633
 4801/10000: episode: 794, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000574, mae: 0.017970, mean_q: 0.008684
 4803/10000: episode: 795, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000385, mae: 0.017289, mean_q: 0.019027
 4805/10000: episode: 796, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000247, mae: 0.011834, mean_q: -0.003191
 4807/10000: episode: 797, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000340, mae: 0.014811, mean_q: 0.018342
 4809/10000: episode: 798, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000157, mae: 0.011172, mean_q: 0.010582
 4811/10000: episode: 799, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000378, mae: 0.013061, mean_q: 0.001602
 4813/10000: episode: 800, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000391, mae: 0.020022, mean_q: 0.021830
 4815/10000: episode: 801, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000427, mae: 0.015894, mean_q: 0.013265
 4817/10000: episode: 802, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000445, mae: 0.018441, mean_q: 0.013308
 4819/10000: episode: 803, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000129, mae: 0.008699, mean_q: 0.009783
 4821/10000: episode: 804, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000380, mae: 0.014247, mean_q: 0.012449
 4823/10000: episode: 805, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000248, mae: 0.011886, mean_q: 0.005678
 4825/10000: episode: 806, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000246, mae: 0.010963, mean_q: 0.009049
 4827/10000: episode: 807, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000230, mae: 0.009463, mean_q: 0.011949
 4829/10000: episode: 808, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000165, mae: 0.011685, mean_q: 0.005965
 4831/10000: episode: 809, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000281, mae: 0.013492, mean_q: 0.014788
 4833/10000: episode: 810, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000152, mae: 0.010041, mean_q: 0.006241
 4835/10000: episode: 811, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000122, mae: 0.009087, mean_q: 0.008899
 4837/10000: episode: 812, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000464, mae: 0.021018, mean_q: 0.024262
 4839/10000: episode: 813, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000350, mae: 0.017858, mean_q: 0.011331
 4841/10000: episode: 814, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000188, mae: 0.013541, mean_q: 0.010951
 4843/10000: episode: 815, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000172, mae: 0.010637, mean_q: 0.014976
 4845/10000: episode: 816, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000213, mae: 0.009293, mean_q: 0.004006
 4847/10000: episode: 817, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000301, mae: 0.011972, mean_q: 0.012165
 4849/10000: episode: 818, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000112, mae: 0.009766, mean_q: 0.011157
 4851/10000: episode: 819, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000130, mae: 0.011098, mean_q: 0.001659
 4853/10000: episode: 820, duration: 0.012s, episode steps: 2, steps per second: 168, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000328, mae: 0.013267, mean_q: 0.013843
 4855/10000: episode: 821, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000119, mae: 0.009190, mean_q: 0.011049
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.05737252160906792
 4857/10000: episode: 822, duration: 0.493s, episode steps: 2, steps per second: 4, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000093, mae: 0.008748, mean_q: 0.004971
 4867/10000: episode: 823, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000318, mae: 0.013413, mean_q: 0.011432
 4877/10000: episode: 824, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000229, mae: 0.012621, mean_q: 0.009053
 4887/10000: episode: 825, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.042, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000207, mae: 0.011338, mean_q: 0.008719
 4897/10000: episode: 826, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000223, mae: 0.011164, mean_q: 0.008279
 4907/10000: episode: 827, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000299, mae: 0.014580, mean_q: 0.012205
 4917/10000: episode: 828, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000452, mae: 0.019660, mean_q: 0.011132
 4927/10000: episode: 829, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000345, mae: 0.017182, mean_q: 0.010009
 4937/10000: episode: 830, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000293, mae: 0.015380, mean_q: 0.010674
 4947/10000: episode: 831, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000281, mae: 0.012934, mean_q: 0.008835
 4957/10000: episode: 832, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000206, mae: 0.010947, mean_q: 0.007775
 4967/10000: episode: 833, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.024, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000298, mae: 0.014364, mean_q: 0.012337
 4977/10000: episode: 834, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000389, mae: 0.017809, mean_q: 0.009142
 4987/10000: episode: 835, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000261, mae: 0.012907, mean_q: 0.010868
 4997/10000: episode: 836, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000290, mae: 0.013210, mean_q: 0.010536
 5007/10000: episode: 837, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000259, mae: 0.014217, mean_q: 0.007996
 5017/10000: episode: 838, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000411, mae: 0.018229, mean_q: 0.014084
 5027/10000: episode: 839, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000321, mae: 0.014378, mean_q: 0.007258
 5037/10000: episode: 840, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000254, mae: 0.011605, mean_q: 0.010707
 5047/10000: episode: 841, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000318, mae: 0.014593, mean_q: 0.009963
 5057/10000: episode: 842, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.214, mean reward: 0.021 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000262, mae: 0.011380, mean_q: 0.012767
 5067/10000: episode: 843, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000247, mae: 0.011390, mean_q: 0.008010
 5077/10000: episode: 844, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000292, mae: 0.016551, mean_q: 0.011916
 5087/10000: episode: 845, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000337, mae: 0.014411, mean_q: 0.012200
 5097/10000: episode: 846, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000216, mae: 0.011506, mean_q: 0.007230
 5107/10000: episode: 847, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000218, mae: 0.013705, mean_q: 0.011986
 5117/10000: episode: 848, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000258, mae: 0.012701, mean_q: 0.005967
 5127/10000: episode: 849, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000242, mae: 0.012453, mean_q: 0.011045
 5137/10000: episode: 850, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000265, mae: 0.015246, mean_q: 0.010748
 5147/10000: episode: 851, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000218, mae: 0.012583, mean_q: 0.007022
 5157/10000: episode: 852, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000244, mae: 0.014320, mean_q: 0.012084
 5167/10000: episode: 853, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000254, mae: 0.014761, mean_q: 0.007616
 5177/10000: episode: 854, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000289, mae: 0.014387, mean_q: 0.013145
 5187/10000: episode: 855, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000369, mae: 0.015755, mean_q: 0.010506
 5197/10000: episode: 856, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000215, mae: 0.012257, mean_q: 0.009849
 5207/10000: episode: 857, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000248, mae: 0.011835, mean_q: 0.009128
 5217/10000: episode: 858, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000307, mae: 0.014749, mean_q: 0.012103
 5227/10000: episode: 859, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.033, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000303, mae: 0.013621, mean_q: 0.010452
 5237/10000: episode: 860, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000305, mae: 0.015416, mean_q: 0.009211
 5247/10000: episode: 861, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000330, mae: 0.013246, mean_q: 0.011835
 5257/10000: episode: 862, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.049, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000317, mae: 0.014478, mean_q: 0.013356
 5267/10000: episode: 863, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000256, mae: 0.012666, mean_q: 0.010275
 5277/10000: episode: 864, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000335, mae: 0.016244, mean_q: 0.011962
 5287/10000: episode: 865, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000305, mae: 0.014309, mean_q: 0.013729
 5297/10000: episode: 866, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000229, mae: 0.012573, mean_q: 0.009114
 5307/10000: episode: 867, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.068, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000248, mae: 0.014593, mean_q: 0.008501
 5317/10000: episode: 868, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000331, mae: 0.016551, mean_q: 0.012564
 5327/10000: episode: 869, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000328, mae: 0.016612, mean_q: 0.007495
 5337/10000: episode: 870, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000246, mae: 0.012541, mean_q: 0.012123
 5347/10000: episode: 871, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000275, mae: 0.012693, mean_q: 0.012304
 5357/10000: episode: 872, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000285, mae: 0.015345, mean_q: 0.007490
 5367/10000: episode: 873, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000324, mae: 0.013684, mean_q: 0.010551
 5377/10000: episode: 874, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000283, mae: 0.014641, mean_q: 0.012797
 5387/10000: episode: 875, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000294, mae: 0.012735, mean_q: 0.010078
 5397/10000: episode: 876, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.135, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000238, mae: 0.011656, mean_q: 0.008145
 5407/10000: episode: 877, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000320, mae: 0.015269, mean_q: 0.011337
 5417/10000: episode: 878, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000241, mae: 0.011688, mean_q: 0.011614
 5427/10000: episode: 879, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000308, mae: 0.013729, mean_q: 0.010077
 5437/10000: episode: 880, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.115, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.700 [-1.000, 10.000], loss: 0.000318, mae: 0.014883, mean_q: 0.011796
 5447/10000: episode: 881, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000273, mae: 0.013454, mean_q: 0.010551
 5457/10000: episode: 882, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000302, mae: 0.015381, mean_q: 0.013316
 5467/10000: episode: 883, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000292, mae: 0.013339, mean_q: 0.013742
 5477/10000: episode: 884, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.055, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000263, mae: 0.015890, mean_q: 0.010284
 5487/10000: episode: 885, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000280, mae: 0.014334, mean_q: 0.011176
 5497/10000: episode: 886, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000288, mae: 0.014203, mean_q: 0.011776
 5507/10000: episode: 887, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000221, mae: 0.011081, mean_q: 0.009451
 5517/10000: episode: 888, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000276, mae: 0.011349, mean_q: 0.009976
 5527/10000: episode: 889, duration: 0.053s, episode steps: 10, steps per second: 187, episode reward: 0.013, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000292, mae: 0.014206, mean_q: 0.010774
 5537/10000: episode: 890, duration: 0.053s, episode steps: 10, steps per second: 190, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000340, mae: 0.016526, mean_q: 0.012672
 5547/10000: episode: 891, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000220, mae: 0.011563, mean_q: 0.008211
 5557/10000: episode: 892, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000336, mae: 0.013691, mean_q: 0.012829
 5567/10000: episode: 893, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.100 [-1.000, 10.000], loss: 0.000264, mae: 0.012314, mean_q: 0.007319
 5577/10000: episode: 894, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000267, mae: 0.014020, mean_q: 0.012896
 5587/10000: episode: 895, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000315, mae: 0.013452, mean_q: 0.009737
 5597/10000: episode: 896, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000247, mae: 0.011347, mean_q: 0.009382
 5607/10000: episode: 897, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000288, mae: 0.012187, mean_q: 0.012771
 5617/10000: episode: 898, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000234, mae: 0.011324, mean_q: 0.010556
 5627/10000: episode: 899, duration: 0.054s, episode steps: 10, steps per second: 187, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000307, mae: 0.013028, mean_q: 0.010487
 5637/10000: episode: 900, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000242, mae: 0.012318, mean_q: 0.011934
 5647/10000: episode: 901, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000223, mae: 0.010894, mean_q: 0.009540
 5657/10000: episode: 902, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000237, mae: 0.011494, mean_q: 0.011058
 5667/10000: episode: 903, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000281, mae: 0.012737, mean_q: 0.011092
 5677/10000: episode: 904, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000283, mae: 0.014191, mean_q: 0.012102
 5687/10000: episode: 905, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000295, mae: 0.011931, mean_q: 0.009302
 5697/10000: episode: 906, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000237, mae: 0.014235, mean_q: 0.011544
 5707/10000: episode: 907, duration: 0.064s, episode steps: 10, steps per second: 157, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000288, mae: 0.012282, mean_q: 0.010648
 5717/10000: episode: 908, duration: 0.080s, episode steps: 10, steps per second: 126, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000252, mae: 0.012966, mean_q: 0.008156
 5727/10000: episode: 909, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000340, mae: 0.016698, mean_q: 0.014655
 5737/10000: episode: 910, duration: 0.052s, episode steps: 10, steps per second: 193, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000335, mae: 0.016444, mean_q: 0.011991
 5747/10000: episode: 911, duration: 0.055s, episode steps: 10, steps per second: 182, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000356, mae: 0.015108, mean_q: 0.008014
 5757/10000: episode: 912, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000292, mae: 0.016510, mean_q: 0.013298
 5767/10000: episode: 913, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000431, mae: 0.017110, mean_q: 0.010405
 5777/10000: episode: 914, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000200, mae: 0.012879, mean_q: 0.010430
 5787/10000: episode: 915, duration: 0.083s, episode steps: 10, steps per second: 120, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000243, mae: 0.012705, mean_q: 0.009457
 5797/10000: episode: 916, duration: 0.070s, episode steps: 10, steps per second: 143, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000230, mae: 0.012493, mean_q: 0.009514
 5807/10000: episode: 917, duration: 0.073s, episode steps: 10, steps per second: 137, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000214, mae: 0.012285, mean_q: 0.012480
 5817/10000: episode: 918, duration: 0.084s, episode steps: 10, steps per second: 119, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000419, mae: 0.018515, mean_q: 0.009532
 5827/10000: episode: 919, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.221, mean reward: 0.022 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 10.000], loss: 0.000260, mae: 0.014909, mean_q: 0.010243
 5837/10000: episode: 920, duration: 0.154s, episode steps: 10, steps per second: 65, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000248, mae: 0.012305, mean_q: 0.011287
 5847/10000: episode: 921, duration: 0.122s, episode steps: 10, steps per second: 82, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000268, mae: 0.011956, mean_q: 0.012101
[Info] 1-TH LEVEL FOUND: 0.03846698999404907, Considering 18/100 traces
 5857/10000: episode: 922, duration: 1.267s, episode steps: 10, steps per second: 8, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000317, mae: 0.014820, mean_q: 0.011316
 5862/10000: episode: 923, duration: 0.028s, episode steps: 5, steps per second: 180, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000157, mae: 0.009626, mean_q: 0.011013
 5867/10000: episode: 924, duration: 0.029s, episode steps: 5, steps per second: 171, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000181, mae: 0.011736, mean_q: 0.011672
 5872/10000: episode: 925, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000204, mae: 0.010366, mean_q: 0.005168
 5876/10000: episode: 926, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000098, mae: 0.008496, mean_q: 0.008256
 5881/10000: episode: 927, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000200, mae: 0.010479, mean_q: 0.010573
 5886/10000: episode: 928, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000247, mae: 0.011110, mean_q: 0.010882
 5891/10000: episode: 929, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000176, mae: 0.010951, mean_q: 0.007314
 5895/10000: episode: 930, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000240, mae: 0.012570, mean_q: 0.014291
 5900/10000: episode: 931, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000262, mae: 0.011403, mean_q: 0.011111
 5905/10000: episode: 932, duration: 0.028s, episode steps: 5, steps per second: 177, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000147, mae: 0.010394, mean_q: 0.008182
 5910/10000: episode: 933, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000246, mae: 0.010373, mean_q: 0.007545
 5915/10000: episode: 934, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000151, mae: 0.009777, mean_q: 0.011255
 5920/10000: episode: 935, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000162, mae: 0.008542, mean_q: 0.007157
 5924/10000: episode: 936, duration: 0.021s, episode steps: 4, steps per second: 192, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000201, mae: 0.010079, mean_q: 0.008874
 5929/10000: episode: 937, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000196, mae: 0.009288, mean_q: 0.008727
 5934/10000: episode: 938, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000202, mae: 0.009996, mean_q: 0.008948
 5938/10000: episode: 939, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000206, mae: 0.010302, mean_q: 0.010157
 5943/10000: episode: 940, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000210, mae: 0.012578, mean_q: 0.008285
 5948/10000: episode: 941, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000175, mae: 0.009637, mean_q: 0.007797
 5953/10000: episode: 942, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000315, mae: 0.013924, mean_q: 0.014644
 5958/10000: episode: 943, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000258, mae: 0.013556, mean_q: 0.012667
 5963/10000: episode: 944, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000175, mae: 0.011236, mean_q: 0.003342
 5968/10000: episode: 945, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000146, mae: 0.011685, mean_q: 0.010808
 5972/10000: episode: 946, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.037, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000169, mae: 0.010881, mean_q: 0.010920
 5977/10000: episode: 947, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000403, mae: 0.014129, mean_q: 0.007992
 5981/10000: episode: 948, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000275, mae: 0.014261, mean_q: 0.007458
 5986/10000: episode: 949, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000309, mae: 0.014537, mean_q: 0.017747
 5991/10000: episode: 950, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000205, mae: 0.013066, mean_q: 0.004823
 5996/10000: episode: 951, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000287, mae: 0.010897, mean_q: 0.007418
 6001/10000: episode: 952, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000152, mae: 0.010818, mean_q: 0.011578
 6006/10000: episode: 953, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000164, mae: 0.009918, mean_q: 0.012895
 6010/10000: episode: 954, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000137, mae: 0.011289, mean_q: -0.001332
 6015/10000: episode: 955, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000234, mae: 0.012748, mean_q: 0.011701
 6020/10000: episode: 956, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000367, mae: 0.016517, mean_q: 0.015638
 6025/10000: episode: 957, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000154, mae: 0.010407, mean_q: 0.006178
 6030/10000: episode: 958, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000368, mae: 0.013416, mean_q: 0.010121
 6035/10000: episode: 959, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000216, mae: 0.011543, mean_q: 0.013536
 6040/10000: episode: 960, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000288, mae: 0.013689, mean_q: 0.009913
 6045/10000: episode: 961, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000196, mae: 0.011824, mean_q: 0.003991
 6050/10000: episode: 962, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000139, mae: 0.009474, mean_q: 0.010444
 6055/10000: episode: 963, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000197, mae: 0.010555, mean_q: 0.008860
 6060/10000: episode: 964, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000226, mae: 0.011186, mean_q: 0.013684
 6065/10000: episode: 965, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000302, mae: 0.012544, mean_q: 0.011223
 6070/10000: episode: 966, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000170, mae: 0.010604, mean_q: 0.008772
 6075/10000: episode: 967, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000292, mae: 0.011011, mean_q: 0.011623
 6080/10000: episode: 968, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000169, mae: 0.009657, mean_q: 0.009171
 6085/10000: episode: 969, duration: 0.025s, episode steps: 5, steps per second: 204, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000248, mae: 0.011452, mean_q: 0.010793
 6090/10000: episode: 970, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000260, mae: 0.011958, mean_q: 0.009448
 6095/10000: episode: 971, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000234, mae: 0.011943, mean_q: 0.012114
 6099/10000: episode: 972, duration: 0.021s, episode steps: 4, steps per second: 189, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000281, mae: 0.011941, mean_q: 0.007462
 6104/10000: episode: 973, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000289, mae: 0.013212, mean_q: 0.014377
 6109/10000: episode: 974, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000281, mae: 0.013183, mean_q: 0.012346
 6114/10000: episode: 975, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000292, mae: 0.013147, mean_q: 0.013981
 6119/10000: episode: 976, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000272, mae: 0.012612, mean_q: 0.010416
 6124/10000: episode: 977, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000082, mae: 0.008283, mean_q: 0.003904
 6129/10000: episode: 978, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000185, mae: 0.012046, mean_q: 0.012615
 6134/10000: episode: 979, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000086, mae: 0.008076, mean_q: 0.007242
 6139/10000: episode: 980, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000248, mae: 0.009982, mean_q: 0.010093
 6144/10000: episode: 981, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000261, mae: 0.012910, mean_q: 0.011582
 6149/10000: episode: 982, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000150, mae: 0.010109, mean_q: 0.010753
 6154/10000: episode: 983, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000232, mae: 0.011920, mean_q: 0.010504
 6159/10000: episode: 984, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000316, mae: 0.015277, mean_q: 0.008367
 6163/10000: episode: 985, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000368, mae: 0.015603, mean_q: 0.005527
 6167/10000: episode: 986, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000242, mae: 0.013471, mean_q: 0.014365
 6172/10000: episode: 987, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000125, mae: 0.011146, mean_q: 0.001402
 6177/10000: episode: 988, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000272, mae: 0.013401, mean_q: 0.013884
 6182/10000: episode: 989, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000329, mae: 0.014272, mean_q: 0.011873
 6187/10000: episode: 990, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000189, mae: 0.009924, mean_q: 0.010410
 6192/10000: episode: 991, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000167, mae: 0.011259, mean_q: 0.005518
 6197/10000: episode: 992, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000287, mae: 0.014031, mean_q: 0.009334
 6202/10000: episode: 993, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000331, mae: 0.016203, mean_q: 0.017122
 6207/10000: episode: 994, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000316, mae: 0.014340, mean_q: 0.010631
 6212/10000: episode: 995, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000163, mae: 0.011828, mean_q: 0.007736
 6216/10000: episode: 996, duration: 0.021s, episode steps: 4, steps per second: 188, episode reward: 0.068, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.125 [-1.000, 11.000], loss: 0.000278, mae: 0.012223, mean_q: 0.012356
 6221/10000: episode: 997, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000249, mae: 0.010759, mean_q: 0.006805
 6226/10000: episode: 998, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000268, mae: 0.011279, mean_q: 0.008953
 6231/10000: episode: 999, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000104, mae: 0.008961, mean_q: 0.009499
 6236/10000: episode: 1000, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000085, mae: 0.007595, mean_q: 0.008383
 6241/10000: episode: 1001, duration: 0.025s, episode steps: 5, steps per second: 202, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000288, mae: 0.011444, mean_q: 0.010210
 6246/10000: episode: 1002, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000225, mae: 0.012704, mean_q: 0.012210
 6251/10000: episode: 1003, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000430, mae: 0.017215, mean_q: 0.019150
[Info] NOT FOUND NEW LEVEL, Current Best Level is 0.03846698999404907
 6256/10000: episode: 1004, duration: 0.547s, episode steps: 5, steps per second: 9, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000216, mae: 0.012096, mean_q: 0.007865
 6266/10000: episode: 1005, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000125, mae: 0.008344, mean_q: 0.009492
 6276/10000: episode: 1006, duration: 0.060s, episode steps: 10, steps per second: 165, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000221, mae: 0.009131, mean_q: 0.009798
 6286/10000: episode: 1007, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000165, mae: 0.010275, mean_q: 0.009929
 6296/10000: episode: 1008, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000206, mae: 0.011621, mean_q: 0.009285
 6306/10000: episode: 1009, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000189, mae: 0.012685, mean_q: 0.012134
 6316/10000: episode: 1010, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000245, mae: 0.013380, mean_q: 0.008388
 6326/10000: episode: 1011, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.350, mean reward: 0.035 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 4.900 [-1.000, 10.000], loss: 0.000203, mae: 0.009847, mean_q: 0.009272
 6336/10000: episode: 1012, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000100, mae: 0.009569, mean_q: 0.006909
 6346/10000: episode: 1013, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000188, mae: 0.011580, mean_q: 0.007901
 6356/10000: episode: 1014, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000154, mae: 0.009692, mean_q: 0.008769
 6366/10000: episode: 1015, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000108, mae: 0.008398, mean_q: 0.007690
 6376/10000: episode: 1016, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000186, mae: 0.009879, mean_q: 0.010035
 6386/10000: episode: 1017, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000233, mae: 0.011169, mean_q: 0.009634
 6396/10000: episode: 1018, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000203, mae: 0.011401, mean_q: 0.011518
 6406/10000: episode: 1019, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000113, mae: 0.009974, mean_q: 0.007462
 6416/10000: episode: 1020, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.020, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000164, mae: 0.009782, mean_q: 0.008703
 6426/10000: episode: 1021, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000132, mae: 0.009122, mean_q: 0.008735
 6436/10000: episode: 1022, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000097, mae: 0.007498, mean_q: 0.007763
 6446/10000: episode: 1023, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000167, mae: 0.010585, mean_q: 0.010209
 6456/10000: episode: 1024, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000090, mae: 0.007326, mean_q: 0.007906
 6466/10000: episode: 1025, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000154, mae: 0.010478, mean_q: 0.008290
 6476/10000: episode: 1026, duration: 0.045s, episode steps: 10, steps per second: 220, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000153, mae: 0.010243, mean_q: 0.009327
 6486/10000: episode: 1027, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000158, mae: 0.008623, mean_q: 0.009300
 6496/10000: episode: 1028, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.045, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000059, mae: 0.006188, mean_q: 0.006048
 6506/10000: episode: 1029, duration: 0.051s, episode steps: 10, steps per second: 195, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000293, mae: 0.014606, mean_q: 0.010589
 6516/10000: episode: 1030, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000123, mae: 0.008379, mean_q: 0.010495
 6526/10000: episode: 1031, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000104, mae: 0.007796, mean_q: 0.006041
 6536/10000: episode: 1032, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000173, mae: 0.011576, mean_q: 0.011205
 6546/10000: episode: 1033, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000179, mae: 0.010069, mean_q: 0.009047
 6556/10000: episode: 1034, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000134, mae: 0.010351, mean_q: 0.006630
 6566/10000: episode: 1035, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000127, mae: 0.008704, mean_q: 0.009340
 6576/10000: episode: 1036, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000198, mae: 0.010395, mean_q: 0.011103
 6586/10000: episode: 1037, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.038, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000097, mae: 0.007382, mean_q: 0.006752
 6596/10000: episode: 1038, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000106, mae: 0.007209, mean_q: 0.007681
 6606/10000: episode: 1039, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000157, mae: 0.010028, mean_q: 0.008843
 6616/10000: episode: 1040, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000164, mae: 0.008256, mean_q: 0.008482
 6626/10000: episode: 1041, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.000 [-1.000, 10.000], loss: 0.000205, mae: 0.010691, mean_q: 0.009639
 6636/10000: episode: 1042, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000091, mae: 0.009256, mean_q: 0.008474
 6646/10000: episode: 1043, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000119, mae: 0.009241, mean_q: 0.010131
 6656/10000: episode: 1044, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.010, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000236, mae: 0.011298, mean_q: 0.010697
 6666/10000: episode: 1045, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000167, mae: 0.009520, mean_q: 0.009780
 6676/10000: episode: 1046, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000145, mae: 0.009047, mean_q: 0.007460
 6686/10000: episode: 1047, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.015, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000145, mae: 0.009079, mean_q: 0.008738
 6696/10000: episode: 1048, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000143, mae: 0.009209, mean_q: 0.009459
 6706/10000: episode: 1049, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.081, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000124, mae: 0.009185, mean_q: 0.006428
 6716/10000: episode: 1050, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000199, mae: 0.010315, mean_q: 0.011773
 6726/10000: episode: 1051, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000271, mae: 0.013890, mean_q: 0.010612
 6736/10000: episode: 1052, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000179, mae: 0.011782, mean_q: 0.008485
 6746/10000: episode: 1053, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000180, mae: 0.011643, mean_q: 0.009249
 6756/10000: episode: 1054, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000069, mae: 0.006817, mean_q: 0.006515
 6766/10000: episode: 1055, duration: 0.046s, episode steps: 10, steps per second: 218, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000160, mae: 0.010197, mean_q: 0.008319
 6776/10000: episode: 1056, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.150 [-1.000, 10.000], loss: 0.000058, mae: 0.006518, mean_q: 0.007193
 6786/10000: episode: 1057, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.043, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000189, mae: 0.009780, mean_q: 0.010600
 6796/10000: episode: 1058, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000178, mae: 0.009779, mean_q: 0.008508
 6806/10000: episode: 1059, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000092, mae: 0.007973, mean_q: 0.006768
 6816/10000: episode: 1060, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000143, mae: 0.008606, mean_q: 0.009836
 6826/10000: episode: 1061, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000174, mae: 0.009064, mean_q: 0.009122
 6836/10000: episode: 1062, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.014, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000157, mae: 0.010535, mean_q: 0.008995
 6846/10000: episode: 1063, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000145, mae: 0.009037, mean_q: 0.009619
 6856/10000: episode: 1064, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000208, mae: 0.011750, mean_q: 0.010791
 6866/10000: episode: 1065, duration: 0.046s, episode steps: 10, steps per second: 219, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000146, mae: 0.009519, mean_q: 0.008916
 6876/10000: episode: 1066, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000176, mae: 0.008694, mean_q: 0.009179
 6886/10000: episode: 1067, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000143, mae: 0.009480, mean_q: 0.007057
 6896/10000: episode: 1068, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000134, mae: 0.009655, mean_q: 0.009846
 6906/10000: episode: 1069, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000112, mae: 0.008131, mean_q: 0.010170
 6916/10000: episode: 1070, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000142, mae: 0.008283, mean_q: 0.008098
 6926/10000: episode: 1071, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000258, mae: 0.011057, mean_q: 0.011909
 6936/10000: episode: 1072, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.054, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000138, mae: 0.007763, mean_q: 0.008043
 6946/10000: episode: 1073, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000296, mae: 0.012069, mean_q: 0.014381
 6956/10000: episode: 1074, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000199, mae: 0.011803, mean_q: 0.007014
 6966/10000: episode: 1075, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000154, mae: 0.010916, mean_q: 0.010210
 6976/10000: episode: 1076, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000169, mae: 0.010929, mean_q: 0.006048
 6986/10000: episode: 1077, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000135, mae: 0.008997, mean_q: 0.010313
 6996/10000: episode: 1078, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.250 [-1.000, 10.000], loss: 0.000187, mae: 0.010354, mean_q: 0.008730
 7006/10000: episode: 1079, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.029, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000149, mae: 0.009343, mean_q: 0.009237
 7016/10000: episode: 1080, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000169, mae: 0.008651, mean_q: 0.009468
 7026/10000: episode: 1081, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000095, mae: 0.007555, mean_q: 0.008905
 7036/10000: episode: 1082, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.038, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000186, mae: 0.009642, mean_q: 0.009326
 7046/10000: episode: 1083, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000093, mae: 0.007412, mean_q: 0.007939
 7056/10000: episode: 1084, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000207, mae: 0.010813, mean_q: 0.011523
 7066/10000: episode: 1085, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000088, mae: 0.007816, mean_q: 0.006145
 7076/10000: episode: 1086, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000141, mae: 0.008170, mean_q: 0.007308
 7086/10000: episode: 1087, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000163, mae: 0.009485, mean_q: 0.010241
 7096/10000: episode: 1088, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000166, mae: 0.009196, mean_q: 0.010885
 7106/10000: episode: 1089, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000253, mae: 0.013056, mean_q: 0.009950
 7116/10000: episode: 1090, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000191, mae: 0.010231, mean_q: 0.009125
 7126/10000: episode: 1091, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000210, mae: 0.012511, mean_q: 0.009480
 7136/10000: episode: 1092, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.012, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000129, mae: 0.009020, mean_q: 0.007849
 7146/10000: episode: 1093, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.015, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000175, mae: 0.012959, mean_q: 0.012119
 7156/10000: episode: 1094, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000299, mae: 0.018311, mean_q: 0.004768
 7166/10000: episode: 1095, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000304, mae: 0.017070, mean_q: 0.011794
 7176/10000: episode: 1096, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000108, mae: 0.008575, mean_q: 0.008622
 7186/10000: episode: 1097, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000227, mae: 0.012034, mean_q: 0.007426
 7196/10000: episode: 1098, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000114, mae: 0.010350, mean_q: 0.011280
 7206/10000: episode: 1099, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000145, mae: 0.009448, mean_q: 0.007952
 7216/10000: episode: 1100, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000114, mae: 0.008167, mean_q: 0.008503
 7226/10000: episode: 1101, duration: 0.046s, episode steps: 10, steps per second: 216, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000108, mae: 0.007596, mean_q: 0.008546
 7236/10000: episode: 1102, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.019, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000171, mae: 0.009566, mean_q: 0.010881
 7246/10000: episode: 1103, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000200, mae: 0.011484, mean_q: 0.009557
[Info] 1-TH LEVEL FOUND: 0.021307919174432755, Considering 11/100 traces
 7256/10000: episode: 1104, duration: 0.644s, episode steps: 10, steps per second: 16, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000174, mae: 0.010555, mean_q: 0.009595
 7261/10000: episode: 1105, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000127, mae: 0.010833, mean_q: 0.009951
 7266/10000: episode: 1106, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000163, mae: 0.010386, mean_q: 0.009128
 7271/10000: episode: 1107, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000136, mae: 0.009327, mean_q: 0.006633
 7276/10000: episode: 1108, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000146, mae: 0.012215, mean_q: 0.011162
 7281/10000: episode: 1109, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000170, mae: 0.009740, mean_q: 0.011939
 7286/10000: episode: 1110, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000137, mae: 0.008631, mean_q: 0.009250
 7291/10000: episode: 1111, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000265, mae: 0.011039, mean_q: 0.011931
 7296/10000: episode: 1112, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000229, mae: 0.012188, mean_q: 0.009485
 7301/10000: episode: 1113, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000209, mae: 0.009724, mean_q: 0.006337
 7306/10000: episode: 1114, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000180, mae: 0.009665, mean_q: 0.010529
 7311/10000: episode: 1115, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000292, mae: 0.012988, mean_q: 0.011678
 7316/10000: episode: 1116, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000083, mae: 0.008184, mean_q: 0.006901
 7321/10000: episode: 1117, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000149, mae: 0.009593, mean_q: 0.009968
 7326/10000: episode: 1118, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000214, mae: 0.011042, mean_q: 0.010448
 7331/10000: episode: 1119, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000196, mae: 0.011108, mean_q: 0.007601
 7336/10000: episode: 1120, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000228, mae: 0.011132, mean_q: 0.014589
 7341/10000: episode: 1121, duration: 0.025s, episode steps: 5, steps per second: 203, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000238, mae: 0.011075, mean_q: 0.011362
 7346/10000: episode: 1122, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000110, mae: 0.008496, mean_q: 0.010652
 7351/10000: episode: 1123, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000225, mae: 0.012085, mean_q: 0.010190
 7356/10000: episode: 1124, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000094, mae: 0.006833, mean_q: 0.003865
 7361/10000: episode: 1125, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000120, mae: 0.007907, mean_q: 0.008419
 7366/10000: episode: 1126, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000065, mae: 0.006840, mean_q: 0.010474
 7371/10000: episode: 1127, duration: 0.031s, episode steps: 5, steps per second: 161, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000268, mae: 0.012519, mean_q: 0.014467
 7376/10000: episode: 1128, duration: 0.040s, episode steps: 5, steps per second: 124, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000119, mae: 0.008510, mean_q: 0.007670
 7381/10000: episode: 1129, duration: 0.029s, episode steps: 5, steps per second: 172, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000125, mae: 0.009792, mean_q: 0.004879
 7386/10000: episode: 1130, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000110, mae: 0.009250, mean_q: 0.009231
 7392/10000: episode: 1131, duration: 0.032s, episode steps: 6, steps per second: 190, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000238, mae: 0.010979, mean_q: 0.011850
 7397/10000: episode: 1132, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000147, mae: 0.010480, mean_q: 0.009351
 7402/10000: episode: 1133, duration: 0.036s, episode steps: 5, steps per second: 137, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000173, mae: 0.010161, mean_q: 0.009480
 7407/10000: episode: 1134, duration: 0.042s, episode steps: 5, steps per second: 120, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000206, mae: 0.011718, mean_q: 0.012470
 7412/10000: episode: 1135, duration: 0.037s, episode steps: 5, steps per second: 135, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000215, mae: 0.010587, mean_q: 0.012041
 7417/10000: episode: 1136, duration: 0.040s, episode steps: 5, steps per second: 124, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000194, mae: 0.010089, mean_q: 0.013548
 7422/10000: episode: 1137, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000209, mae: 0.009160, mean_q: 0.008156
 7427/10000: episode: 1138, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000075, mae: 0.008399, mean_q: 0.007619
 7432/10000: episode: 1139, duration: 0.028s, episode steps: 5, steps per second: 179, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000142, mae: 0.009440, mean_q: 0.013305
 7437/10000: episode: 1140, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000130, mae: 0.009559, mean_q: 0.013489
 7442/10000: episode: 1141, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000260, mae: 0.011757, mean_q: 0.014831
 7447/10000: episode: 1142, duration: 0.027s, episode steps: 5, steps per second: 185, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000169, mae: 0.009467, mean_q: 0.010203
 7452/10000: episode: 1143, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000149, mae: 0.010098, mean_q: 0.006712
 7457/10000: episode: 1144, duration: 0.038s, episode steps: 5, steps per second: 133, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000139, mae: 0.011844, mean_q: 0.010948
 7463/10000: episode: 1145, duration: 0.064s, episode steps: 6, steps per second: 94, episode reward: 0.039, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.833 [-1.000, 11.000], loss: 0.000238, mae: 0.011063, mean_q: 0.012164
 7468/10000: episode: 1146, duration: 0.044s, episode steps: 5, steps per second: 113, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000136, mae: 0.008215, mean_q: 0.007141
 7473/10000: episode: 1147, duration: 0.037s, episode steps: 5, steps per second: 136, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000072, mae: 0.007446, mean_q: 0.007398
 7478/10000: episode: 1148, duration: 0.039s, episode steps: 5, steps per second: 128, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000126, mae: 0.007756, mean_q: 0.008409
 7483/10000: episode: 1149, duration: 0.036s, episode steps: 5, steps per second: 138, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000154, mae: 0.007863, mean_q: 0.010243
 7488/10000: episode: 1150, duration: 0.036s, episode steps: 5, steps per second: 140, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000224, mae: 0.012408, mean_q: 0.010109
 7493/10000: episode: 1151, duration: 0.044s, episode steps: 5, steps per second: 113, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000119, mae: 0.010370, mean_q: 0.012530
 7498/10000: episode: 1152, duration: 0.031s, episode steps: 5, steps per second: 161, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000143, mae: 0.008552, mean_q: 0.009407
 7504/10000: episode: 1153, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000141, mae: 0.008122, mean_q: 0.008503
 7509/10000: episode: 1154, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000169, mae: 0.008433, mean_q: 0.007891
 7514/10000: episode: 1155, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000128, mae: 0.010761, mean_q: 0.009425
 7519/10000: episode: 1156, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000103, mae: 0.009396, mean_q: 0.012545
 7524/10000: episode: 1157, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000211, mae: 0.012276, mean_q: 0.010751
 7529/10000: episode: 1158, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000146, mae: 0.010289, mean_q: 0.007977
 7534/10000: episode: 1159, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000194, mae: 0.010994, mean_q: 0.011740
 7539/10000: episode: 1160, duration: 0.029s, episode steps: 5, steps per second: 175, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000157, mae: 0.011101, mean_q: 0.015347
 7544/10000: episode: 1161, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000118, mae: 0.009742, mean_q: 0.008001
 7550/10000: episode: 1162, duration: 0.031s, episode steps: 6, steps per second: 193, episode reward: 0.253, mean reward: 0.042 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.417 [-1.000, 11.000], loss: 0.000214, mae: 0.010053, mean_q: 0.008854
 7555/10000: episode: 1163, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000132, mae: 0.010038, mean_q: 0.008390
 7561/10000: episode: 1164, duration: 0.031s, episode steps: 6, steps per second: 191, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000143, mae: 0.010076, mean_q: 0.008692
 7566/10000: episode: 1165, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000143, mae: 0.010002, mean_q: 0.005474
 7571/10000: episode: 1166, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000206, mae: 0.012296, mean_q: 0.013426
 7577/10000: episode: 1167, duration: 0.030s, episode steps: 6, steps per second: 197, episode reward: 0.027, mean reward: 0.005 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.750 [-1.000, 11.000], loss: 0.000157, mae: 0.011629, mean_q: 0.011188
 7582/10000: episode: 1168, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000326, mae: 0.016248, mean_q: 0.015753
 7587/10000: episode: 1169, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000277, mae: 0.014875, mean_q: 0.006869
 7592/10000: episode: 1170, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000128, mae: 0.010899, mean_q: 0.003976
 7597/10000: episode: 1171, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000254, mae: 0.014000, mean_q: 0.011579
 7603/10000: episode: 1172, duration: 0.032s, episode steps: 6, steps per second: 189, episode reward: 0.062, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000262, mae: 0.011510, mean_q: 0.011794
 7608/10000: episode: 1173, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000129, mae: 0.011397, mean_q: 0.012473
 7613/10000: episode: 1174, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000125, mae: 0.009034, mean_q: 0.011822
 7618/10000: episode: 1175, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000121, mae: 0.009000, mean_q: 0.007711
 7623/10000: episode: 1176, duration: 0.032s, episode steps: 5, steps per second: 156, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000096, mae: 0.009119, mean_q: 0.010996
 7628/10000: episode: 1177, duration: 0.032s, episode steps: 5, steps per second: 154, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000145, mae: 0.009027, mean_q: 0.010137
 7633/10000: episode: 1178, duration: 0.028s, episode steps: 5, steps per second: 176, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000265, mae: 0.010845, mean_q: 0.010715
 7638/10000: episode: 1179, duration: 0.034s, episode steps: 5, steps per second: 146, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000215, mae: 0.011746, mean_q: 0.014855
 7644/10000: episode: 1180, duration: 0.037s, episode steps: 6, steps per second: 161, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000090, mae: 0.008003, mean_q: 0.007557
 7649/10000: episode: 1181, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000259, mae: 0.011778, mean_q: 0.012570
 7654/10000: episode: 1182, duration: 0.031s, episode steps: 5, steps per second: 159, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000156, mae: 0.010554, mean_q: 0.009646
 7660/10000: episode: 1183, duration: 0.047s, episode steps: 6, steps per second: 127, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000180, mae: 0.010092, mean_q: 0.010906
 7665/10000: episode: 1184, duration: 0.036s, episode steps: 5, steps per second: 138, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000178, mae: 0.010724, mean_q: 0.004849
 7670/10000: episode: 1185, duration: 0.035s, episode steps: 5, steps per second: 144, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000300, mae: 0.016195, mean_q: 0.016217
 7675/10000: episode: 1186, duration: 0.029s, episode steps: 5, steps per second: 170, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000198, mae: 0.011870, mean_q: 0.015159
 7680/10000: episode: 1187, duration: 0.031s, episode steps: 5, steps per second: 160, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000185, mae: 0.011988, mean_q: 0.010162
 7686/10000: episode: 1188, duration: 0.051s, episode steps: 6, steps per second: 117, episode reward: 0.050, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.917 [-1.000, 11.000], loss: 0.000146, mae: 0.009381, mean_q: 0.009615
 7691/10000: episode: 1189, duration: 0.045s, episode steps: 5, steps per second: 112, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000230, mae: 0.010964, mean_q: 0.013160
 7696/10000: episode: 1190, duration: 0.037s, episode steps: 5, steps per second: 135, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000152, mae: 0.009477, mean_q: 0.005854
 7701/10000: episode: 1191, duration: 0.031s, episode steps: 5, steps per second: 164, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000262, mae: 0.012505, mean_q: 0.013276
 7706/10000: episode: 1192, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000106, mae: 0.008859, mean_q: 0.010900
[Info] 2-TH LEVEL FOUND: 0.026568755507469177, Considering 19/100 traces
 7712/10000: episode: 1193, duration: 0.697s, episode steps: 6, steps per second: 9, episode reward: 0.222, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.333 [-1.000, 11.000], loss: 0.000121, mae: 0.008870, mean_q: 0.011175
 7714/10000: episode: 1194, duration: 0.020s, episode steps: 2, steps per second: 101, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000458, mae: 0.013625, mean_q: 0.012324
 7716/10000: episode: 1195, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000235, mae: 0.015450, mean_q: 0.024215
 7718/10000: episode: 1196, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000173, mae: 0.013604, mean_q: 0.001490
 7720/10000: episode: 1197, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000121, mae: 0.009559, mean_q: 0.008550
 7722/10000: episode: 1198, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000145, mae: 0.011987, mean_q: 0.017279
 7724/10000: episode: 1199, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000236, mae: 0.010412, mean_q: 0.000848
 7726/10000: episode: 1200, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000232, mae: 0.012583, mean_q: 0.013692
 7728/10000: episode: 1201, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000215, mae: 0.010181, mean_q: 0.008766
 7730/10000: episode: 1202, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000243, mae: 0.013096, mean_q: 0.011109
 7732/10000: episode: 1203, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000233, mae: 0.011130, mean_q: 0.013595
 7734/10000: episode: 1204, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000221, mae: 0.013343, mean_q: 0.017011
 7739/10000: episode: 1205, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000280, mae: 0.012497, mean_q: 0.010288
 7741/10000: episode: 1206, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000171, mae: 0.007713, mean_q: 0.006639
 7743/10000: episode: 1207, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000129, mae: 0.009729, mean_q: 0.014374
 7748/10000: episode: 1208, duration: 0.029s, episode steps: 5, steps per second: 174, episode reward: 0.235, mean reward: 0.047 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000251, mae: 0.013164, mean_q: 0.015000
 7753/10000: episode: 1209, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000290, mae: 0.013935, mean_q: 0.017169
 7755/10000: episode: 1210, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000204, mae: 0.009421, mean_q: 0.008503
 7757/10000: episode: 1211, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000117, mae: 0.009015, mean_q: 0.013545
 7759/10000: episode: 1212, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000222, mae: 0.012404, mean_q: 0.018014
 7761/10000: episode: 1213, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000239, mae: 0.013237, mean_q: 0.009190
 7763/10000: episode: 1214, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000099, mae: 0.008345, mean_q: 0.010656
 7765/10000: episode: 1215, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000161, mae: 0.011021, mean_q: 0.009786
 7767/10000: episode: 1216, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000074, mae: 0.008004, mean_q: 0.012679
 7769/10000: episode: 1217, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000113, mae: 0.007720, mean_q: 0.006067
 7774/10000: episode: 1218, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 1.289, mean reward: 0.258 [0.050, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 8.700 [7.000, 11.000], loss: 0.000235, mae: 0.014181, mean_q: 0.016704
 7776/10000: episode: 1219, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000387, mae: 0.017002, mean_q: 0.010848
 7778/10000: episode: 1220, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000205, mae: 0.012138, mean_q: 0.023372
 7783/10000: episode: 1221, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000136, mae: 0.012108, mean_q: 0.004996
 7785/10000: episode: 1222, duration: 0.016s, episode steps: 2, steps per second: 125, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000252, mae: 0.012140, mean_q: 0.007876
 7787/10000: episode: 1223, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000035, mae: 0.005632, mean_q: 0.002359
 7789/10000: episode: 1224, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000155, mae: 0.010243, mean_q: 0.013601
 7791/10000: episode: 1225, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000164, mae: 0.008275, mean_q: 0.007917
 7793/10000: episode: 1226, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000215, mae: 0.013360, mean_q: 0.012483
 7798/10000: episode: 1227, duration: 0.025s, episode steps: 5, steps per second: 198, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000120, mae: 0.010444, mean_q: 0.016865
 7800/10000: episode: 1228, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000206, mae: 0.009425, mean_q: 0.007126
 7805/10000: episode: 1229, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000145, mae: 0.011195, mean_q: 0.011071
 7807/10000: episode: 1230, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000314, mae: 0.013064, mean_q: 0.016553
 7809/10000: episode: 1231, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001023, mae: 0.013357, mean_q: 0.012217
 7814/10000: episode: 1232, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000094, mae: 0.007792, mean_q: 0.010871
 7816/10000: episode: 1233, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000106, mae: 0.010489, mean_q: 0.004924
 7818/10000: episode: 1234, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000238, mae: 0.011191, mean_q: 0.009062
 7820/10000: episode: 1235, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000257, mae: 0.015718, mean_q: 0.020388
 7825/10000: episode: 1236, duration: 0.025s, episode steps: 5, steps per second: 199, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000139, mae: 0.009681, mean_q: 0.007277
 7827/10000: episode: 1237, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000166, mae: 0.007703, mean_q: 0.010435
 7829/10000: episode: 1238, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000262, mae: 0.015368, mean_q: 0.020203
 7831/10000: episode: 1239, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001159, mae: 0.017502, mean_q: 0.008533
 7833/10000: episode: 1240, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000516, mae: 0.019858, mean_q: 0.018303
 7835/10000: episode: 1241, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000270, mae: 0.016090, mean_q: -0.001460
 7837/10000: episode: 1242, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000344, mae: 0.017854, mean_q: 0.020750
[Info] FALSIFICATION!
 7841/10000: episode: 1243, duration: 0.426s, episode steps: 4, steps per second: 9, episode reward: 1.553, mean reward: 0.388 [0.050, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 8.500 [7.000, 10.000], loss: 0.000835, mae: 0.017153, mean_q: 0.010193
 7846/10000: episode: 1244, duration: 0.033s, episode steps: 5, steps per second: 151, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000625, mae: 0.018267, mean_q: 0.005186
 7848/10000: episode: 1245, duration: 0.031s, episode steps: 2, steps per second: 65, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000437, mae: 0.020519, mean_q: 0.023045
 7850/10000: episode: 1246, duration: 0.024s, episode steps: 2, steps per second: 85, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000177, mae: 0.009996, mean_q: 0.011312
 7852/10000: episode: 1247, duration: 0.015s, episode steps: 2, steps per second: 131, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000340, mae: 0.013020, mean_q: 0.001812
 7857/10000: episode: 1248, duration: 0.029s, episode steps: 5, steps per second: 173, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.003186, mae: 0.021502, mean_q: 0.017766
 7859/10000: episode: 1249, duration: 0.014s, episode steps: 2, steps per second: 147, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000461, mae: 0.019731, mean_q: 0.021144
 7861/10000: episode: 1250, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000638, mae: 0.025859, mean_q: 0.001431
 7863/10000: episode: 1251, duration: 0.016s, episode steps: 2, steps per second: 124, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000226, mae: 0.012734, mean_q: 0.021889
 7868/10000: episode: 1252, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000418, mae: 0.015858, mean_q: 0.008664
 7870/10000: episode: 1253, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000188, mae: 0.010860, mean_q: 0.016331
 7872/10000: episode: 1254, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000110, mae: 0.008567, mean_q: 0.008249
 7877/10000: episode: 1255, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000187, mae: 0.012031, mean_q: 0.007292
 7879/10000: episode: 1256, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000429, mae: 0.015236, mean_q: 0.010177
 7881/10000: episode: 1257, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000239, mae: 0.012113, mean_q: 0.012869
 7886/10000: episode: 1258, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000882, mae: 0.017137, mean_q: 0.015264
 7888/10000: episode: 1259, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000248, mae: 0.017632, mean_q: -0.004764
 7890/10000: episode: 1260, duration: 0.012s, episode steps: 2, steps per second: 163, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000367, mae: 0.017769, mean_q: 0.019394
 7892/10000: episode: 1261, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001139, mae: 0.018786, mean_q: 0.013273
 7894/10000: episode: 1262, duration: 0.013s, episode steps: 2, steps per second: 159, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000116, mae: 0.009631, mean_q: 0.002911
 7896/10000: episode: 1263, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000199, mae: 0.010633, mean_q: 0.015911
 7898/10000: episode: 1264, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000101, mae: 0.007431, mean_q: 0.011617
 7903/10000: episode: 1265, duration: 0.025s, episode steps: 5, steps per second: 201, episode reward: 0.149, mean reward: 0.030 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000247, mae: 0.010994, mean_q: 0.014272
 7905/10000: episode: 1266, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000223, mae: 0.010512, mean_q: 0.012099
 7907/10000: episode: 1267, duration: 0.012s, episode steps: 2, steps per second: 161, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000345, mae: 0.014552, mean_q: 0.015849
 7909/10000: episode: 1268, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000427, mae: 0.019773, mean_q: 0.026190
 7911/10000: episode: 1269, duration: 0.013s, episode steps: 2, steps per second: 157, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000208, mae: 0.011370, mean_q: 0.012457
 7913/10000: episode: 1270, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000336, mae: 0.016980, mean_q: 0.012291
 7918/10000: episode: 1271, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.321, mean reward: 0.064 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.600 [-1.000, 11.000], loss: 0.000193, mae: 0.010987, mean_q: 0.013864
 7920/10000: episode: 1272, duration: 0.012s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000226, mae: 0.014027, mean_q: 0.010880
 7922/10000: episode: 1273, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000192, mae: 0.012291, mean_q: 0.002158
[Info] Complete ISplit Iteration
[Info] Levels: [0.02130792, 0.026568756, 0.15932225]
[Info] Cond. Prob: [0.11, 0.19, 0.01]
[Info] Error Prob: 0.000209

 7924/10000: episode: 1274, duration: 0.827s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006537, mae: 0.028159, mean_q: 0.021591
 7934/10000: episode: 1275, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000427, mae: 0.020785, mean_q: 0.013145
 7944/10000: episode: 1276, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000470, mae: 0.020733, mean_q: 0.010575
 7954/10000: episode: 1277, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.001670, mae: 0.018956, mean_q: 0.014586
 7964/10000: episode: 1278, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000475, mae: 0.023027, mean_q: 0.011910
 7974/10000: episode: 1279, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000243, mae: 0.014676, mean_q: 0.009549
 7984/10000: episode: 1280, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000384, mae: 0.012752, mean_q: 0.011921
 7994/10000: episode: 1281, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.027, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000218, mae: 0.012603, mean_q: 0.010582
 8004/10000: episode: 1282, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.034, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000458, mae: 0.015471, mean_q: 0.010231
 8014/10000: episode: 1283, duration: 0.046s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000380, mae: 0.019417, mean_q: 0.016368
 8024/10000: episode: 1284, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000257, mae: 0.014445, mean_q: 0.008077
 8034/10000: episode: 1285, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000250, mae: 0.012128, mean_q: 0.011794
 8044/10000: episode: 1286, duration: 0.047s, episode steps: 10, steps per second: 214, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000481, mae: 0.014178, mean_q: 0.014717
 8054/10000: episode: 1287, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000271, mae: 0.012733, mean_q: 0.008368
 8064/10000: episode: 1288, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000559, mae: 0.018794, mean_q: 0.018013
 8074/10000: episode: 1289, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.031, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000243, mae: 0.012151, mean_q: 0.012476
 8084/10000: episode: 1290, duration: 0.060s, episode steps: 10, steps per second: 167, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000202, mae: 0.010232, mean_q: 0.009094
 8094/10000: episode: 1291, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.066, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000439, mae: 0.016115, mean_q: 0.015407
 8104/10000: episode: 1292, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000230, mae: 0.010912, mean_q: 0.010021
 8114/10000: episode: 1293, duration: 0.066s, episode steps: 10, steps per second: 152, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000261, mae: 0.011755, mean_q: 0.012455
 8124/10000: episode: 1294, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.650 [-1.000, 10.000], loss: 0.000422, mae: 0.013072, mean_q: 0.011107
 8134/10000: episode: 1295, duration: 0.078s, episode steps: 10, steps per second: 129, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000305, mae: 0.015932, mean_q: 0.014511
 8144/10000: episode: 1296, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.900 [-1.000, 10.000], loss: 0.000239, mae: 0.013286, mean_q: 0.011018
 8154/10000: episode: 1297, duration: 0.065s, episode steps: 10, steps per second: 154, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000432, mae: 0.017045, mean_q: 0.010578
 8164/10000: episode: 1298, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000303, mae: 0.013038, mean_q: 0.013534
 8174/10000: episode: 1299, duration: 0.115s, episode steps: 10, steps per second: 87, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000211, mae: 0.011463, mean_q: 0.011232
 8184/10000: episode: 1300, duration: 0.076s, episode steps: 10, steps per second: 132, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000269, mae: 0.014797, mean_q: 0.012545
 8194/10000: episode: 1301, duration: 0.072s, episode steps: 10, steps per second: 138, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000315, mae: 0.014668, mean_q: 0.014087
 8204/10000: episode: 1302, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.016, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000187, mae: 0.011337, mean_q: 0.011006
 8214/10000: episode: 1303, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000332, mae: 0.012619, mean_q: 0.011966
 8224/10000: episode: 1304, duration: 0.064s, episode steps: 10, steps per second: 155, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000217, mae: 0.012638, mean_q: 0.009476
 8234/10000: episode: 1305, duration: 0.118s, episode steps: 10, steps per second: 85, episode reward: 0.005, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000222, mae: 0.011318, mean_q: 0.011913
 8244/10000: episode: 1306, duration: 0.124s, episode steps: 10, steps per second: 81, episode reward: 0.031, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000173, mae: 0.009676, mean_q: 0.011920
 8254/10000: episode: 1307, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.025, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000224, mae: 0.012203, mean_q: 0.010709
 8264/10000: episode: 1308, duration: 0.097s, episode steps: 10, steps per second: 104, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.950 [-1.000, 10.000], loss: 0.000253, mae: 0.012192, mean_q: 0.013560
 8274/10000: episode: 1309, duration: 0.092s, episode steps: 10, steps per second: 109, episode reward: 0.039, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.300 [-1.000, 10.000], loss: 0.000330, mae: 0.015360, mean_q: 0.012649
 8284/10000: episode: 1310, duration: 0.137s, episode steps: 10, steps per second: 73, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000218, mae: 0.012597, mean_q: 0.012882
 8294/10000: episode: 1311, duration: 0.132s, episode steps: 10, steps per second: 76, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000114, mae: 0.008506, mean_q: 0.008512
 8304/10000: episode: 1312, duration: 0.114s, episode steps: 10, steps per second: 88, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000235, mae: 0.010827, mean_q: 0.011874
 8314/10000: episode: 1313, duration: 0.127s, episode steps: 10, steps per second: 79, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000342, mae: 0.012684, mean_q: 0.010054
 8324/10000: episode: 1314, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000216, mae: 0.012661, mean_q: 0.012041
 8334/10000: episode: 1315, duration: 0.127s, episode steps: 10, steps per second: 78, episode reward: 0.030, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000213, mae: 0.012263, mean_q: 0.009790
 8344/10000: episode: 1316, duration: 0.054s, episode steps: 10, steps per second: 184, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000639, mae: 0.018420, mean_q: 0.013198
 8354/10000: episode: 1317, duration: 0.065s, episode steps: 10, steps per second: 153, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000446, mae: 0.018071, mean_q: 0.014402
 8364/10000: episode: 1318, duration: 0.122s, episode steps: 10, steps per second: 82, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.000228, mae: 0.013838, mean_q: 0.011732
 8374/10000: episode: 1319, duration: 0.085s, episode steps: 10, steps per second: 118, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000350, mae: 0.014001, mean_q: 0.010246
 8384/10000: episode: 1320, duration: 0.120s, episode steps: 10, steps per second: 83, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.700 [-1.000, 10.000], loss: 0.000294, mae: 0.014640, mean_q: 0.011478
 8394/10000: episode: 1321, duration: 0.095s, episode steps: 10, steps per second: 106, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000444, mae: 0.016299, mean_q: 0.010168
 8404/10000: episode: 1322, duration: 0.110s, episode steps: 10, steps per second: 91, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.001759, mae: 0.019473, mean_q: 0.020624
 8414/10000: episode: 1323, duration: 0.093s, episode steps: 10, steps per second: 107, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000446, mae: 0.018703, mean_q: 0.009911
 8424/10000: episode: 1324, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.100, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.600 [-1.000, 10.000], loss: 0.000392, mae: 0.016451, mean_q: 0.010110
 8434/10000: episode: 1325, duration: 0.109s, episode steps: 10, steps per second: 92, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000173, mae: 0.011973, mean_q: 0.011400
 8444/10000: episode: 1326, duration: 0.084s, episode steps: 10, steps per second: 118, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000389, mae: 0.014067, mean_q: 0.013992
 8454/10000: episode: 1327, duration: 0.100s, episode steps: 10, steps per second: 100, episode reward: 0.084, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.002882, mae: 0.021433, mean_q: 0.020742
 8464/10000: episode: 1328, duration: 0.102s, episode steps: 10, steps per second: 98, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000521, mae: 0.018251, mean_q: 0.010614
 8474/10000: episode: 1329, duration: 0.120s, episode steps: 10, steps per second: 83, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000296, mae: 0.014643, mean_q: 0.013426
 8484/10000: episode: 1330, duration: 0.105s, episode steps: 10, steps per second: 96, episode reward: 0.131, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000238, mae: 0.012289, mean_q: 0.010562
 8494/10000: episode: 1331, duration: 0.112s, episode steps: 10, steps per second: 89, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000410, mae: 0.014077, mean_q: 0.015113
 8504/10000: episode: 1332, duration: 0.105s, episode steps: 10, steps per second: 95, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000490, mae: 0.016546, mean_q: 0.013034
 8514/10000: episode: 1333, duration: 0.121s, episode steps: 10, steps per second: 83, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.000310, mae: 0.016520, mean_q: 0.012442
 8524/10000: episode: 1334, duration: 0.095s, episode steps: 10, steps per second: 105, episode reward: 0.007, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000230, mae: 0.013804, mean_q: 0.013258
 8534/10000: episode: 1335, duration: 0.099s, episode steps: 10, steps per second: 101, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000128, mae: 0.010635, mean_q: 0.009372
 8544/10000: episode: 1336, duration: 0.097s, episode steps: 10, steps per second: 103, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.000202, mae: 0.010905, mean_q: 0.010446
 8554/10000: episode: 1337, duration: 0.077s, episode steps: 10, steps per second: 130, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.850 [-1.000, 10.000], loss: 0.000199, mae: 0.011615, mean_q: 0.011520
 8564/10000: episode: 1338, duration: 0.099s, episode steps: 10, steps per second: 102, episode reward: 0.080, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.000207, mae: 0.010267, mean_q: 0.009350
 8574/10000: episode: 1339, duration: 0.054s, episode steps: 10, steps per second: 186, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000502, mae: 0.015715, mean_q: 0.017361
 8584/10000: episode: 1340, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.001687, mae: 0.018482, mean_q: 0.015493
 8594/10000: episode: 1341, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.129, mean reward: 0.013 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000281, mae: 0.016395, mean_q: 0.011857
 8604/10000: episode: 1342, duration: 0.059s, episode steps: 10, steps per second: 169, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000264, mae: 0.013988, mean_q: 0.009589
 8614/10000: episode: 1343, duration: 0.056s, episode steps: 10, steps per second: 178, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.050 [-1.000, 10.000], loss: 0.000219, mae: 0.011359, mean_q: 0.013445
 8624/10000: episode: 1344, duration: 0.056s, episode steps: 10, steps per second: 179, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000254, mae: 0.011785, mean_q: 0.008555
 8634/10000: episode: 1345, duration: 0.058s, episode steps: 10, steps per second: 172, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.900 [-1.000, 10.000], loss: 0.000508, mae: 0.017587, mean_q: 0.018458
 8644/10000: episode: 1346, duration: 0.054s, episode steps: 10, steps per second: 185, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000195, mae: 0.014314, mean_q: 0.009051
 8654/10000: episode: 1347, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.008, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.750 [-1.000, 10.000], loss: 0.000246, mae: 0.012933, mean_q: 0.010871
 8664/10000: episode: 1348, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000165, mae: 0.009970, mean_q: 0.008909
 8674/10000: episode: 1349, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000132, mae: 0.010376, mean_q: 0.009789
 8684/10000: episode: 1350, duration: 0.049s, episode steps: 10, steps per second: 203, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.000259, mae: 0.011875, mean_q: 0.013331
 8694/10000: episode: 1351, duration: 0.058s, episode steps: 10, steps per second: 171, episode reward: 0.006, mean reward: 0.001 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.000189, mae: 0.010132, mean_q: 0.010495
 8704/10000: episode: 1352, duration: 0.057s, episode steps: 10, steps per second: 177, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000183, mae: 0.010492, mean_q: 0.009352
 8714/10000: episode: 1353, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.023, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000360, mae: 0.012622, mean_q: 0.011818
 8724/10000: episode: 1354, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.500 [-1.000, 10.000], loss: 0.000554, mae: 0.017935, mean_q: 0.014838
 8734/10000: episode: 1355, duration: 0.057s, episode steps: 10, steps per second: 175, episode reward: 0.004, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.550 [-1.000, 10.000], loss: 0.000456, mae: 0.014738, mean_q: 0.015213
 8744/10000: episode: 1356, duration: 0.082s, episode steps: 10, steps per second: 122, episode reward: 0.005, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000239, mae: 0.014523, mean_q: 0.010706
 8754/10000: episode: 1357, duration: 0.052s, episode steps: 10, steps per second: 192, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.350 [-1.000, 10.000], loss: 0.000240, mae: 0.011857, mean_q: 0.011310
 8764/10000: episode: 1358, duration: 0.051s, episode steps: 10, steps per second: 194, episode reward: 0.178, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.800 [-1.000, 10.000], loss: 0.000125, mae: 0.008965, mean_q: 0.008938
 8774/10000: episode: 1359, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000381, mae: 0.013478, mean_q: 0.010401
 8784/10000: episode: 1360, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.032, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.002018, mae: 0.027677, mean_q: 0.013905
 8794/10000: episode: 1361, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000404, mae: 0.015198, mean_q: 0.011704
 8804/10000: episode: 1362, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000224, mae: 0.013122, mean_q: 0.012113
 8814/10000: episode: 1363, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.021, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.000381, mae: 0.014713, mean_q: 0.010629
 8824/10000: episode: 1364, duration: 0.049s, episode steps: 10, steps per second: 206, episode reward: 0.079, mean reward: 0.008 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000398, mae: 0.014145, mean_q: 0.011835
 8834/10000: episode: 1365, duration: 0.049s, episode steps: 10, steps per second: 204, episode reward: 0.002, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001671, mae: 0.018763, mean_q: 0.013074
 8844/10000: episode: 1366, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000522, mae: 0.013829, mean_q: 0.009902
 8854/10000: episode: 1367, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000298, mae: 0.015468, mean_q: 0.011492
 8864/10000: episode: 1368, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.022, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000300, mae: 0.012684, mean_q: 0.012173
 8874/10000: episode: 1369, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.001514, mae: 0.013397, mean_q: 0.010771
 8884/10000: episode: 1370, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.005, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.000295, mae: 0.015632, mean_q: 0.011999
 8894/10000: episode: 1371, duration: 0.048s, episode steps: 10, steps per second: 207, episode reward: 0.051, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.000211, mae: 0.012988, mean_q: 0.007463
 8904/10000: episode: 1372, duration: 0.047s, episode steps: 10, steps per second: 215, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000235, mae: 0.013250, mean_q: 0.014599
 8914/10000: episode: 1373, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.086, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.000164, mae: 0.009352, mean_q: 0.011035
[Info] 1-TH LEVEL FOUND: 0.027555368840694427, Considering 11/100 traces
 8924/10000: episode: 1374, duration: 0.686s, episode steps: 10, steps per second: 15, episode reward: 0.009, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.000207, mae: 0.011122, mean_q: 0.010270
 8931/10000: episode: 1375, duration: 0.040s, episode steps: 7, steps per second: 176, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000483, mae: 0.014595, mean_q: 0.015693
 8936/10000: episode: 1376, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000367, mae: 0.016592, mean_q: 0.007812
 8941/10000: episode: 1377, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000296, mae: 0.015288, mean_q: 0.015304
 8946/10000: episode: 1378, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000181, mae: 0.011124, mean_q: 0.013641
 8951/10000: episode: 1379, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000196, mae: 0.010113, mean_q: 0.001710
 8956/10000: episode: 1380, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000312, mae: 0.014540, mean_q: 0.018621
 8963/10000: episode: 1381, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.025, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000258, mae: 0.013646, mean_q: 0.007939
 8968/10000: episode: 1382, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000255, mae: 0.014100, mean_q: 0.014402
 8973/10000: episode: 1383, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000730, mae: 0.015152, mean_q: 0.016602
 8980/10000: episode: 1384, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.057, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000183, mae: 0.011890, mean_q: 0.007367
 8985/10000: episode: 1385, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000228, mae: 0.013256, mean_q: 0.011092
 8992/10000: episode: 1386, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 1.315, mean reward: 0.188 [0.007, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 7.786 [5.000, 11.000], loss: 0.000205, mae: 0.011564, mean_q: 0.012123
 8997/10000: episode: 1387, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000393, mae: 0.011145, mean_q: 0.010976
 9002/10000: episode: 1388, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000227, mae: 0.011632, mean_q: 0.009517
 9009/10000: episode: 1389, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.096, mean reward: 0.014 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000212, mae: 0.012150, mean_q: 0.011376
 9014/10000: episode: 1390, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000185, mae: 0.011263, mean_q: 0.008243
 9019/10000: episode: 1391, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000145, mae: 0.009084, mean_q: 0.012125
 9024/10000: episode: 1392, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000431, mae: 0.010360, mean_q: 0.010977
 9029/10000: episode: 1393, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000196, mae: 0.010774, mean_q: 0.015716
 9036/10000: episode: 1394, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000221, mae: 0.011998, mean_q: 0.008725
 9043/10000: episode: 1395, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.346, mean reward: 0.049 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.286 [-1.000, 11.000], loss: 0.000195, mae: 0.011475, mean_q: 0.008559
 9050/10000: episode: 1396, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000194, mae: 0.010533, mean_q: 0.013181
 9055/10000: episode: 1397, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000286, mae: 0.012743, mean_q: 0.011604
 9062/10000: episode: 1398, duration: 0.033s, episode steps: 7, steps per second: 211, episode reward: 0.029, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000231, mae: 0.009704, mean_q: 0.007437
 9067/10000: episode: 1399, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000178, mae: 0.011254, mean_q: 0.011536
 9072/10000: episode: 1400, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000200, mae: 0.011754, mean_q: 0.011649
 9077/10000: episode: 1401, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000192, mae: 0.009588, mean_q: 0.007436
 9084/10000: episode: 1402, duration: 0.034s, episode steps: 7, steps per second: 209, episode reward: 0.217, mean reward: 0.031 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.071 [-1.000, 11.000], loss: 0.000683, mae: 0.014122, mean_q: 0.014856
 9089/10000: episode: 1403, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000200, mae: 0.010869, mean_q: 0.007677
 9094/10000: episode: 1404, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000546, mae: 0.012316, mean_q: 0.011071
 9101/10000: episode: 1405, duration: 0.033s, episode steps: 7, steps per second: 210, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000153, mae: 0.009954, mean_q: 0.011039
 9106/10000: episode: 1406, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000077, mae: 0.006758, mean_q: 0.011091
 9113/10000: episode: 1407, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.045, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000087, mae: 0.007424, mean_q: 0.007713
 9118/10000: episode: 1408, duration: 0.026s, episode steps: 5, steps per second: 194, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000163, mae: 0.009963, mean_q: 0.009655
 9123/10000: episode: 1409, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000165, mae: 0.010940, mean_q: 0.015997
 9130/10000: episode: 1410, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000238, mae: 0.013171, mean_q: 0.011139
 9135/10000: episode: 1411, duration: 0.026s, episode steps: 5, steps per second: 196, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000627, mae: 0.015321, mean_q: 0.013843
 9140/10000: episode: 1412, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000187, mae: 0.012529, mean_q: 0.004078
 9147/10000: episode: 1413, duration: 0.034s, episode steps: 7, steps per second: 203, episode reward: 0.064, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000181, mae: 0.011216, mean_q: 0.012181
 9154/10000: episode: 1414, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.132, mean reward: 0.019 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000147, mae: 0.009302, mean_q: 0.011578
 9159/10000: episode: 1415, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000549, mae: 0.013577, mean_q: 0.014935
 9164/10000: episode: 1416, duration: 0.026s, episode steps: 5, steps per second: 193, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000164, mae: 0.009493, mean_q: 0.009457
 9171/10000: episode: 1417, duration: 0.034s, episode steps: 7, steps per second: 207, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000246, mae: 0.013330, mean_q: 0.009646
 9176/10000: episode: 1418, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000347, mae: 0.018573, mean_q: 0.019189
 9183/10000: episode: 1419, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000173, mae: 0.011395, mean_q: 0.010730
 9190/10000: episode: 1420, duration: 0.035s, episode steps: 7, steps per second: 199, episode reward: 0.084, mean reward: 0.012 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.786 [-1.000, 11.000], loss: 0.000236, mae: 0.012238, mean_q: 0.013203
 9195/10000: episode: 1421, duration: 0.027s, episode steps: 5, steps per second: 186, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000263, mae: 0.014551, mean_q: 0.015339
 9200/10000: episode: 1422, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000224, mae: 0.014144, mean_q: 0.003611
 9207/10000: episode: 1423, duration: 0.035s, episode steps: 7, steps per second: 198, episode reward: 0.229, mean reward: 0.033 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.143 [-1.000, 11.000], loss: 0.000165, mae: 0.011218, mean_q: 0.007043
 9214/10000: episode: 1424, duration: 0.036s, episode steps: 7, steps per second: 197, episode reward: 0.017, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.357 [-1.000, 11.000], loss: 0.000200, mae: 0.010468, mean_q: 0.008224
 9219/10000: episode: 1425, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000069, mae: 0.007961, mean_q: 0.006318
 9226/10000: episode: 1426, duration: 0.036s, episode steps: 7, steps per second: 194, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000203, mae: 0.012003, mean_q: 0.016455
 9231/10000: episode: 1427, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000274, mae: 0.012870, mean_q: 0.010523
 9236/10000: episode: 1428, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000243, mae: 0.011995, mean_q: 0.008410
 9241/10000: episode: 1429, duration: 0.027s, episode steps: 5, steps per second: 183, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000259, mae: 0.011689, mean_q: 0.013821
 9246/10000: episode: 1430, duration: 0.027s, episode steps: 5, steps per second: 187, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.002802, mae: 0.029454, mean_q: 0.033605
 9253/10000: episode: 1431, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.033, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.500 [-1.000, 11.000], loss: 0.000554, mae: 0.023336, mean_q: 0.006986
 9258/10000: episode: 1432, duration: 0.027s, episode steps: 5, steps per second: 188, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000617, mae: 0.016053, mean_q: 0.009411
 9263/10000: episode: 1433, duration: 0.026s, episode steps: 5, steps per second: 190, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000146, mae: 0.009203, mean_q: 0.012499
 9270/10000: episode: 1434, duration: 0.039s, episode steps: 7, steps per second: 180, episode reward: 0.037, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.571 [-1.000, 11.000], loss: 0.000210, mae: 0.012551, mean_q: 0.014501
 9275/10000: episode: 1435, duration: 0.026s, episode steps: 5, steps per second: 189, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000173, mae: 0.011427, mean_q: 0.009194
 9280/10000: episode: 1436, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000761, mae: 0.014019, mean_q: 0.015971
 9287/10000: episode: 1437, duration: 0.035s, episode steps: 7, steps per second: 202, episode reward: 0.053, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.714 [-1.000, 11.000], loss: 0.000173, mae: 0.011182, mean_q: 0.010079
 9292/10000: episode: 1438, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000209, mae: 0.010516, mean_q: 0.007272
 9299/10000: episode: 1439, duration: 0.034s, episode steps: 7, steps per second: 204, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000350, mae: 0.010633, mean_q: 0.011503
 9306/10000: episode: 1440, duration: 0.046s, episode steps: 7, steps per second: 151, episode reward: 0.069, mean reward: 0.010 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.857 [-1.000, 11.000], loss: 0.000235, mae: 0.010239, mean_q: 0.011504
 9311/10000: episode: 1441, duration: 0.036s, episode steps: 5, steps per second: 141, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000288, mae: 0.011926, mean_q: 0.015575
 9316/10000: episode: 1442, duration: 0.030s, episode steps: 5, steps per second: 169, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000083, mae: 0.007340, mean_q: 0.009902
 9321/10000: episode: 1443, duration: 0.027s, episode steps: 5, steps per second: 184, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000115, mae: 0.007335, mean_q: 0.011119
 9328/10000: episode: 1444, duration: 0.037s, episode steps: 7, steps per second: 191, episode reward: 0.127, mean reward: 0.018 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 5.929 [-1.000, 11.000], loss: 0.000208, mae: 0.010935, mean_q: 0.010873
 9333/10000: episode: 1445, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000199, mae: 0.010132, mean_q: 0.010668
 9338/10000: episode: 1446, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.000154, mae: 0.009609, mean_q: 0.007107
 9343/10000: episode: 1447, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000263, mae: 0.012477, mean_q: 0.015849
 9348/10000: episode: 1448, duration: 0.028s, episode steps: 5, steps per second: 181, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000228, mae: 0.013487, mean_q: 0.018956
 9353/10000: episode: 1449, duration: 0.025s, episode steps: 5, steps per second: 196, episode reward: 0.204, mean reward: 0.041 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.400 [-1.000, 11.000], loss: 0.002857, mae: 0.023242, mean_q: 0.008855
 9358/10000: episode: 1450, duration: 0.034s, episode steps: 5, steps per second: 145, episode reward: 0.087, mean reward: 0.017 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.200 [-1.000, 11.000], loss: 0.000432, mae: 0.022559, mean_q: 0.010574
 9365/10000: episode: 1451, duration: 0.035s, episode steps: 7, steps per second: 200, episode reward: 0.260, mean reward: 0.037 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.214 [-1.000, 11.000], loss: 0.000660, mae: 0.023360, mean_q: 0.023433
 9370/10000: episode: 1452, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.001218, mae: 0.027632, mean_q: 0.020239
 9375/10000: episode: 1453, duration: 0.026s, episode steps: 5, steps per second: 192, episode reward: 0.118, mean reward: 0.024 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.300 [-1.000, 11.000], loss: 0.000379, mae: 0.020954, mean_q: -0.002959
 9382/10000: episode: 1454, duration: 0.035s, episode steps: 7, steps per second: 203, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.002366, mae: 0.019759, mean_q: 0.018231
 9387/10000: episode: 1455, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.002664, mae: 0.020083, mean_q: 0.019452
 9392/10000: episode: 1456, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.032, mean reward: 0.006 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.900 [-1.000, 11.000], loss: 0.000429, mae: 0.020605, mean_q: 0.012487
 9397/10000: episode: 1457, duration: 0.027s, episode steps: 5, steps per second: 182, episode reward: 0.020, mean reward: 0.004 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 5.800 [-1.000, 11.000], loss: 0.000337, mae: 0.014977, mean_q: 0.018056
 9402/10000: episode: 1458, duration: 0.026s, episode steps: 5, steps per second: 195, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000186, mae: 0.012533, mean_q: 0.009410
 9407/10000: episode: 1459, duration: 0.026s, episode steps: 5, steps per second: 191, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000187, mae: 0.011111, mean_q: 0.010766
 9412/10000: episode: 1460, duration: 0.025s, episode steps: 5, steps per second: 200, episode reward: 0.075, mean reward: 0.015 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000324, mae: 0.013805, mean_q: 0.010723
 9419/10000: episode: 1461, duration: 0.034s, episode steps: 7, steps per second: 205, episode reward: 0.048, mean reward: 0.007 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 5.643 [-1.000, 11.000], loss: 0.000485, mae: 0.016010, mean_q: 0.014654
 9424/10000: episode: 1462, duration: 0.025s, episode steps: 5, steps per second: 197, episode reward: 0.055, mean reward: 0.011 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.100 [-1.000, 11.000], loss: 0.000191, mae: 0.010777, mean_q: 0.013130
[Info] 2-TH LEVEL FOUND: 0.0857090875506401, Considering 13/100 traces
 9429/10000: episode: 1463, duration: 1.011s, episode steps: 5, steps per second: 5, episode reward: 0.043, mean reward: 0.009 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 6.000 [-1.000, 11.000], loss: 0.000250, mae: 0.010720, mean_q: 0.007031
 9431/10000: episode: 1464, duration: 0.014s, episode steps: 2, steps per second: 141, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000488, mae: 0.022730, mean_q: 0.028260
 9435/10000: episode: 1465, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000777, mae: 0.021736, mean_q: 0.004835
 9439/10000: episode: 1466, duration: 0.022s, episode steps: 4, steps per second: 181, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000289, mae: 0.015161, mean_q: 0.020684
 9443/10000: episode: 1467, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000251, mae: 0.014498, mean_q: 0.002608
 9445/10000: episode: 1468, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000251, mae: 0.014263, mean_q: 0.018220
 9447/10000: episode: 1469, duration: 0.015s, episode steps: 2, steps per second: 134, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000206, mae: 0.012643, mean_q: 0.017256
 9449/10000: episode: 1470, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000145, mae: 0.012993, mean_q: -0.002377
 9451/10000: episode: 1471, duration: 0.015s, episode steps: 2, steps per second: 137, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000080, mae: 0.007025, mean_q: 0.011097
 9455/10000: episode: 1472, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000138, mae: 0.011446, mean_q: 0.010355
 9457/10000: episode: 1473, duration: 0.014s, episode steps: 2, steps per second: 146, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000306, mae: 0.013189, mean_q: 0.013419
 9459/10000: episode: 1474, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000223, mae: 0.012912, mean_q: 0.020501
 9463/10000: episode: 1475, duration: 0.022s, episode steps: 4, steps per second: 178, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000192, mae: 0.011881, mean_q: 0.008338
 9467/10000: episode: 1476, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000351, mae: 0.015592, mean_q: 0.017769
 9469/10000: episode: 1477, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000260, mae: 0.014262, mean_q: 0.019011
 9471/10000: episode: 1478, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000444, mae: 0.016800, mean_q: 0.001584
[Info] FALSIFICATION!
 9474/10000: episode: 1479, duration: 0.173s, episode steps: 3, steps per second: 17, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000473, mae: 0.023060, mean_q: 0.030051
 9476/10000: episode: 1480, duration: 0.014s, episode steps: 2, steps per second: 144, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000269, mae: 0.015072, mean_q: 0.007867
 9478/10000: episode: 1481, duration: 0.014s, episode steps: 2, steps per second: 138, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000304, mae: 0.012716, mean_q: 0.007180
 9480/10000: episode: 1482, duration: 0.016s, episode steps: 2, steps per second: 126, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000232, mae: 0.012948, mean_q: 0.018111
 9482/10000: episode: 1483, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000634, mae: 0.018012, mean_q: 0.015464
 9484/10000: episode: 1484, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006569, mae: 0.030725, mean_q: 0.025272
 9486/10000: episode: 1485, duration: 0.013s, episode steps: 2, steps per second: 153, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000309, mae: 0.014342, mean_q: 0.016819
 9490/10000: episode: 1486, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003542, mae: 0.025668, mean_q: 0.022505
 9492/10000: episode: 1487, duration: 0.013s, episode steps: 2, steps per second: 158, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000379, mae: 0.016977, mean_q: 0.011032
 9496/10000: episode: 1488, duration: 0.023s, episode steps: 4, steps per second: 171, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000348, mae: 0.016962, mean_q: 0.009585
 9500/10000: episode: 1489, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000216, mae: 0.014004, mean_q: 0.011083
 9504/10000: episode: 1490, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003994, mae: 0.023953, mean_q: 0.017225
 9508/10000: episode: 1491, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000563, mae: 0.023776, mean_q: 0.023843
 9512/10000: episode: 1492, duration: 0.021s, episode steps: 4, steps per second: 186, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000448, mae: 0.019919, mean_q: 0.004421
 9516/10000: episode: 1493, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000490, mae: 0.021794, mean_q: 0.022160
[Info] FALSIFICATION!
 9519/10000: episode: 1494, duration: 0.260s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000505, mae: 0.020275, mean_q: 0.001641
 9523/10000: episode: 1495, duration: 0.026s, episode steps: 4, steps per second: 156, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000310, mae: 0.016958, mean_q: 0.014466
 9527/10000: episode: 1496, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000731, mae: 0.019779, mean_q: 0.009075
 9531/10000: episode: 1497, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000574, mae: 0.014513, mean_q: 0.011428
 9535/10000: episode: 1498, duration: 0.022s, episode steps: 4, steps per second: 182, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000183, mae: 0.012029, mean_q: 0.010098
 9537/10000: episode: 1499, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000471, mae: 0.019073, mean_q: 0.019796
 9541/10000: episode: 1500, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000304, mae: 0.013101, mean_q: 0.015200
 9543/10000: episode: 1501, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000198, mae: 0.013995, mean_q: 0.004944
 9547/10000: episode: 1502, duration: 0.021s, episode steps: 4, steps per second: 194, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000251, mae: 0.011223, mean_q: 0.014800
 9551/10000: episode: 1503, duration: 0.022s, episode steps: 4, steps per second: 184, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003352, mae: 0.018532, mean_q: 0.013279
[Info] FALSIFICATION!
 9554/10000: episode: 1504, duration: 0.266s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000344, mae: 0.017675, mean_q: 0.024466
[Info] FALSIFICATION!
 9557/10000: episode: 1505, duration: 0.187s, episode steps: 3, steps per second: 16, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000301, mae: 0.018354, mean_q: 0.001721
 9561/10000: episode: 1506, duration: 0.025s, episode steps: 4, steps per second: 163, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000314, mae: 0.015419, mean_q: 0.022348
 9565/10000: episode: 1507, duration: 0.030s, episode steps: 4, steps per second: 135, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.000680, mae: 0.016444, mean_q: 0.010954
 9567/10000: episode: 1508, duration: 0.013s, episode steps: 2, steps per second: 150, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001409, mae: 0.024660, mean_q: 0.018575
 9569/10000: episode: 1509, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.006000, mae: 0.027912, mean_q: 0.022475
[Info] FALSIFICATION!
 9572/10000: episode: 1510, duration: 0.254s, episode steps: 3, steps per second: 12, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000481, mae: 0.021136, mean_q: 0.013442
 9574/10000: episode: 1511, duration: 0.022s, episode steps: 2, steps per second: 93, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000718, mae: 0.027887, mean_q: 0.009593
 9576/10000: episode: 1512, duration: 0.020s, episode steps: 2, steps per second: 98, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000345, mae: 0.015088, mean_q: 0.021854
 9580/10000: episode: 1513, duration: 0.025s, episode steps: 4, steps per second: 161, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.003597, mae: 0.022381, mean_q: 0.010141
 9584/10000: episode: 1514, duration: 0.023s, episode steps: 4, steps per second: 172, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000339, mae: 0.016380, mean_q: 0.017322
 9586/10000: episode: 1515, duration: 0.018s, episode steps: 2, steps per second: 111, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000606, mae: 0.026881, mean_q: -0.002479
 9588/10000: episode: 1516, duration: 0.016s, episode steps: 2, steps per second: 122, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000414, mae: 0.019969, mean_q: 0.026986
 9590/10000: episode: 1517, duration: 0.017s, episode steps: 2, steps per second: 119, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000422, mae: 0.021341, mean_q: 0.029920
 9592/10000: episode: 1518, duration: 0.019s, episode steps: 2, steps per second: 107, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000824, mae: 0.017300, mean_q: 0.017248
 9594/10000: episode: 1519, duration: 0.014s, episode steps: 2, steps per second: 139, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000596, mae: 0.025504, mean_q: 0.010326
 9598/10000: episode: 1520, duration: 0.026s, episode steps: 4, steps per second: 155, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000704, mae: 0.018216, mean_q: 0.013897
 9600/10000: episode: 1521, duration: 0.015s, episode steps: 2, steps per second: 132, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.013183, mae: 0.047286, mean_q: 0.017712
 9602/10000: episode: 1522, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001086, mae: 0.032474, mean_q: 0.040275
 9606/10000: episode: 1523, duration: 0.022s, episode steps: 4, steps per second: 180, episode reward: 1.872, mean reward: 0.468 [0.135, 1.001], mean action: 0.000 [0.000, 0.000], mean observation: 9.250 [8.000, 11.000], loss: 0.004114, mae: 0.039245, mean_q: 0.014209
 9608/10000: episode: 1524, duration: 0.014s, episode steps: 2, steps per second: 145, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001024, mae: 0.031069, mean_q: 0.045213
 9612/10000: episode: 1525, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.003752, mae: 0.029793, mean_q: 0.005850
 9616/10000: episode: 1526, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.003252, mae: 0.025605, mean_q: 0.023933
 9618/10000: episode: 1527, duration: 0.015s, episode steps: 2, steps per second: 135, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000567, mae: 0.021361, mean_q: 0.022090
 9620/10000: episode: 1528, duration: 0.015s, episode steps: 2, steps per second: 136, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000376, mae: 0.021607, mean_q: -0.003123
 9624/10000: episode: 1529, duration: 0.022s, episode steps: 4, steps per second: 179, episode reward: 1.240, mean reward: 0.310 [0.135, 0.368], mean action: 0.000 [0.000, 0.000], mean observation: 9.125 [8.000, 11.000], loss: 0.000572, mae: 0.015669, mean_q: 0.019644
 9626/10000: episode: 1530, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001071, mae: 0.022909, mean_q: 0.022076
 9628/10000: episode: 1531, duration: 0.014s, episode steps: 2, steps per second: 148, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001010, mae: 0.026260, mean_q: 0.005035
 9632/10000: episode: 1532, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.000682, mae: 0.018551, mean_q: 0.020026
 9634/10000: episode: 1533, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000292, mae: 0.014554, mean_q: 0.006945
 9636/10000: episode: 1534, duration: 0.013s, episode steps: 2, steps per second: 152, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000413, mae: 0.022985, mean_q: 0.001714
 9638/10000: episode: 1535, duration: 0.013s, episode steps: 2, steps per second: 149, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000854, mae: 0.022896, mean_q: 0.027744
 9640/10000: episode: 1536, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000433, mae: 0.018146, mean_q: 0.021186
 9642/10000: episode: 1537, duration: 0.012s, episode steps: 2, steps per second: 162, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000418, mae: 0.023459, mean_q: -0.003698
 9644/10000: episode: 1538, duration: 0.013s, episode steps: 2, steps per second: 156, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001167, mae: 0.022656, mean_q: 0.022886
 9648/10000: episode: 1539, duration: 0.021s, episode steps: 4, steps per second: 187, episode reward: 0.100, mean reward: 0.025 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 6.250 [-1.000, 11.000], loss: 0.003412, mae: 0.024546, mean_q: 0.025090
 9650/10000: episode: 1540, duration: 0.013s, episode steps: 2, steps per second: 160, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000340, mae: 0.016600, mean_q: 0.018384
 9652/10000: episode: 1541, duration: 0.013s, episode steps: 2, steps per second: 151, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000975, mae: 0.024739, mean_q: 0.030246
 9654/10000: episode: 1542, duration: 0.013s, episode steps: 2, steps per second: 154, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000514, mae: 0.018627, mean_q: 0.026925
 9658/10000: episode: 1543, duration: 0.022s, episode steps: 4, steps per second: 183, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.000259, mae: 0.017395, mean_q: -0.000904
 9662/10000: episode: 1544, duration: 0.022s, episode steps: 4, steps per second: 185, episode reward: 0.271, mean reward: 0.068 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.500 [-1.000, 11.000], loss: 0.000560, mae: 0.023283, mean_q: 0.026256
 9664/10000: episode: 1545, duration: 0.013s, episode steps: 2, steps per second: 155, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.000236, mae: 0.014445, mean_q: 0.001012
[Info] FALSIFICATION!
 9667/10000: episode: 1546, duration: 0.283s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.000642, mae: 0.016196, mean_q: 0.023344
 9671/10000: episode: 1547, duration: 0.024s, episode steps: 4, steps per second: 165, episode reward: 0.185, mean reward: 0.046 [0.000, 0.135], mean action: 0.000 [0.000, 0.000], mean observation: 6.375 [-1.000, 11.000], loss: 0.001088, mae: 0.021923, mean_q: 0.021059
[Info] FALSIFICATION!
 9674/10000: episode: 1548, duration: 0.274s, episode steps: 3, steps per second: 11, episode reward: 1.503, mean reward: 0.501 [0.135, 1.000], mean action: 0.000 [0.000, 0.000], mean observation: 9.000 [8.000, 10.000], loss: 0.004757, mae: 0.033332, mean_q: 0.019651
 9676/10000: episode: 1549, duration: 0.019s, episode steps: 2, steps per second: 104, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001061, mae: 0.020935, mean_q: 0.023695
[Info] Complete ISplit Iteration
[Info] Levels: [0.027555369, 0.08570909, 0.17073882]
[Info] Cond. Prob: [0.11, 0.13, 0.07]
[Info] Error Prob: 0.0010010000000000002

 9678/10000: episode: 1550, duration: 0.923s, episode steps: 2, steps per second: 2, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 4.750 [-1.000, 11.000], loss: 0.001093, mae: 0.024053, mean_q: 0.008956
 9688/10000: episode: 1551, duration: 0.048s, episode steps: 10, steps per second: 210, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000703, mae: 0.020329, mean_q: 0.019646
 9698/10000: episode: 1552, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.037, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000472, mae: 0.016402, mean_q: 0.015309
 9708/10000: episode: 1553, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.001, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 2.750 [-1.000, 10.000], loss: 0.001620, mae: 0.020211, mean_q: 0.021938
 9718/10000: episode: 1554, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000816, mae: 0.022815, mean_q: 0.020878
 9728/10000: episode: 1555, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.004, mean reward: 0.000 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.200 [-1.000, 10.000], loss: 0.000604, mae: 0.022098, mean_q: 0.011323
 9738/10000: episode: 1556, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.015, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.150 [-1.000, 10.000], loss: 0.001873, mae: 0.022946, mean_q: 0.023332
 9748/10000: episode: 1557, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.005, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.450 [-1.000, 10.000], loss: 0.000657, mae: 0.021779, mean_q: 0.013351
 9758/10000: episode: 1558, duration: 0.047s, episode steps: 10, steps per second: 211, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.600 [-1.000, 10.000], loss: 0.001994, mae: 0.024469, mean_q: 0.025931
 9768/10000: episode: 1559, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001251, mae: 0.028240, mean_q: 0.022463
 9778/10000: episode: 1560, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.084, mean reward: 0.008 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.650 [-1.000, 10.000], loss: 0.000649, mae: 0.020102, mean_q: 0.012290
 9788/10000: episode: 1561, duration: 0.048s, episode steps: 10, steps per second: 209, episode reward: 0.029, mean reward: 0.003 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 4.350 [-1.000, 10.000], loss: 0.001966, mae: 0.026121, mean_q: 0.020671
 9798/10000: episode: 1562, duration: 0.053s, episode steps: 10, steps per second: 189, episode reward: 0.011, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.002795, mae: 0.027133, mean_q: 0.018304
 9808/10000: episode: 1563, duration: 0.049s, episode steps: 10, steps per second: 205, episode reward: 0.003, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.500 [-1.000, 10.000], loss: 0.000498, mae: 0.020726, mean_q: 0.013908
 9818/10000: episode: 1564, duration: 0.047s, episode steps: 10, steps per second: 213, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.000506, mae: 0.016939, mean_q: 0.015820
 9828/10000: episode: 1565, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.001873, mae: 0.026417, mean_q: 0.015796
 9838/10000: episode: 1566, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.006, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 3.700 [-1.000, 10.000], loss: 0.000853, mae: 0.021965, mean_q: 0.019303
 9848/10000: episode: 1567, duration: 0.047s, episode steps: 10, steps per second: 212, episode reward: 0.002, mean reward: 0.000 [0.000, 0.000], mean action: 0.000 [0.000, 0.000], mean observation: 3.300 [-1.000, 10.000], loss: 0.001861, mae: 0.025031, mean_q: 0.025363
 9858/10000: episode: 1568, duration: 0.046s, episode steps: 10, steps per second: 217, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.450 [-1.000, 10.000], loss: 0.000797, mae: 0.021918, mean_q: 0.017688
 9868/10000: episode: 1569, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.100 [-1.000, 10.000], loss: 0.003353, mae: 0.032511, mean_q: 0.022852
 9878/10000: episode: 1570, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.003, mean reward: 0.000 [0.000, 0.001], mean action: 0.000 [0.000, 0.000], mean observation: 3.400 [-1.000, 10.000], loss: 0.001831, mae: 0.023538, mean_q: 0.017988
 9888/10000: episode: 1571, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.014, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.950 [-1.000, 10.000], loss: 0.000566, mae: 0.024237, mean_q: 0.015000
 9898/10000: episode: 1572, duration: 0.053s, episode steps: 10, steps per second: 188, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.002316, mae: 0.029083, mean_q: 0.023172
 9908/10000: episode: 1573, duration: 0.051s, episode steps: 10, steps per second: 196, episode reward: 0.048, mean reward: 0.005 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.250 [-1.000, 10.000], loss: 0.002913, mae: 0.034160, mean_q: 0.022242
 9918/10000: episode: 1574, duration: 0.050s, episode steps: 10, steps per second: 201, episode reward: 0.097, mean reward: 0.010 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.400 [-1.000, 10.000], loss: 0.002095, mae: 0.032685, mean_q: 0.021518
 9928/10000: episode: 1575, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.013, mean reward: 0.001 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.800 [-1.000, 10.000], loss: 0.002573, mae: 0.026753, mean_q: 0.021172
 9938/10000: episode: 1576, duration: 0.048s, episode steps: 10, steps per second: 208, episode reward: 0.012, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001835, mae: 0.024978, mean_q: 0.018347
 9948/10000: episode: 1577, duration: 0.049s, episode steps: 10, steps per second: 202, episode reward: 0.036, mean reward: 0.004 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.050 [-1.000, 10.000], loss: 0.000603, mae: 0.020478, mean_q: 0.014443
 9958/10000: episode: 1578, duration: 0.051s, episode steps: 10, steps per second: 197, episode reward: 0.033, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.003060, mae: 0.030025, mean_q: 0.025136
 9968/10000: episode: 1579, duration: 0.050s, episode steps: 10, steps per second: 202, episode reward: 0.088, mean reward: 0.009 [0.000, 0.050], mean action: 0.000 [0.000, 0.000], mean observation: 4.550 [-1.000, 10.000], loss: 0.000991, mae: 0.023901, mean_q: 0.019796
 9978/10000: episode: 1580, duration: 0.050s, episode steps: 10, steps per second: 199, episode reward: 0.018, mean reward: 0.002 [0.000, 0.007], mean action: 0.000 [0.000, 0.000], mean observation: 3.850 [-1.000, 10.000], loss: 0.003040, mae: 0.031051, mean_q: 0.023786
 9988/10000: episode: 1581, duration: 0.048s, episode steps: 10, steps per second: 206, episode reward: 0.011, mean reward: 0.001 [0.000, 0.002], mean action: 0.000 [0.000, 0.000], mean observation: 4.000 [-1.000, 10.000], loss: 0.001756, mae: 0.026724, mean_q: 0.021704
 9998/10000: episode: 1582, duration: 0.050s, episode steps: 10, steps per second: 200, episode reward: 0.032, mean reward: 0.003 [0.000, 0.018], mean action: 0.000 [0.000, 0.000], mean observation: 4.200 [-1.000, 10.000], loss: 0.000957, mae: 0.026442, mean_q: 0.019915
done, took 70.777 seconds
[Info] End Importance Splitting. Falsification occurred 8 times.
