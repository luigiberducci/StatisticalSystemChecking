Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 25)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                832       
_________________________________________________________________
dense_2 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_3 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 9         
=================================================================
Total params: 1,505
Trainable params: 1,505
Non-trainable params: 0
_________________________________________________________________
None
[Info] Start Uniform Random Simulation.
Training for 1000000 steps ...
    100/1000000: episode: 1, duration: 0.180s, episode steps: 100, steps per second: 556, episode reward: 62.400, mean reward: 0.624 [0.528, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.847, 10.098], loss: --, mae: --, mean_q: --
    200/1000000: episode: 2, duration: 0.067s, episode steps: 100, steps per second: 1502, episode reward: 57.673, mean reward: 0.577 [0.499, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.911, 10.098], loss: --, mae: --, mean_q: --
    300/1000000: episode: 3, duration: 0.066s, episode steps: 100, steps per second: 1513, episode reward: 64.475, mean reward: 0.645 [0.509, 0.862], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.365, 10.192], loss: --, mae: --, mean_q: --
    400/1000000: episode: 4, duration: 0.066s, episode steps: 100, steps per second: 1517, episode reward: 58.549, mean reward: 0.585 [0.502, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.974, 10.098], loss: --, mae: --, mean_q: --
    500/1000000: episode: 5, duration: 0.066s, episode steps: 100, steps per second: 1525, episode reward: 60.143, mean reward: 0.601 [0.511, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.527, 10.098], loss: --, mae: --, mean_q: --
    600/1000000: episode: 6, duration: 0.066s, episode steps: 100, steps per second: 1514, episode reward: 56.971, mean reward: 0.570 [0.505, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.731, 10.114], loss: --, mae: --, mean_q: --
    700/1000000: episode: 7, duration: 0.076s, episode steps: 100, steps per second: 1324, episode reward: 58.884, mean reward: 0.589 [0.516, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.533, 10.246], loss: --, mae: --, mean_q: --
    800/1000000: episode: 8, duration: 0.067s, episode steps: 100, steps per second: 1498, episode reward: 58.712, mean reward: 0.587 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.574, 10.098], loss: --, mae: --, mean_q: --
    900/1000000: episode: 9, duration: 0.068s, episode steps: 100, steps per second: 1470, episode reward: 59.821, mean reward: 0.598 [0.505, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.640, 10.419], loss: --, mae: --, mean_q: --
   1000/1000000: episode: 10, duration: 0.068s, episode steps: 100, steps per second: 1481, episode reward: 63.352, mean reward: 0.634 [0.517, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.101, 10.098], loss: --, mae: --, mean_q: --
   1100/1000000: episode: 11, duration: 0.066s, episode steps: 100, steps per second: 1506, episode reward: 58.585, mean reward: 0.586 [0.502, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.730, 10.172], loss: --, mae: --, mean_q: --
   1200/1000000: episode: 12, duration: 0.070s, episode steps: 100, steps per second: 1427, episode reward: 58.724, mean reward: 0.587 [0.498, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.907, 10.346], loss: --, mae: --, mean_q: --
   1300/1000000: episode: 13, duration: 0.067s, episode steps: 100, steps per second: 1493, episode reward: 59.627, mean reward: 0.596 [0.507, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.080, 10.246], loss: --, mae: --, mean_q: --
   1400/1000000: episode: 14, duration: 0.066s, episode steps: 100, steps per second: 1514, episode reward: 59.377, mean reward: 0.594 [0.508, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.379, 10.098], loss: --, mae: --, mean_q: --
   1500/1000000: episode: 15, duration: 0.079s, episode steps: 100, steps per second: 1269, episode reward: 62.227, mean reward: 0.622 [0.505, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.916, 10.098], loss: --, mae: --, mean_q: --
   1600/1000000: episode: 16, duration: 0.067s, episode steps: 100, steps per second: 1486, episode reward: 63.549, mean reward: 0.635 [0.509, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.512, 10.219], loss: --, mae: --, mean_q: --
   1700/1000000: episode: 17, duration: 0.082s, episode steps: 100, steps per second: 1214, episode reward: 59.835, mean reward: 0.598 [0.507, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.044, 10.098], loss: --, mae: --, mean_q: --
   1800/1000000: episode: 18, duration: 0.078s, episode steps: 100, steps per second: 1283, episode reward: 60.203, mean reward: 0.602 [0.503, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.604, 10.098], loss: --, mae: --, mean_q: --
   1900/1000000: episode: 19, duration: 0.067s, episode steps: 100, steps per second: 1493, episode reward: 57.488, mean reward: 0.575 [0.506, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.206, 10.098], loss: --, mae: --, mean_q: --
   2000/1000000: episode: 20, duration: 0.067s, episode steps: 100, steps per second: 1492, episode reward: 59.289, mean reward: 0.593 [0.499, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.747, 10.098], loss: --, mae: --, mean_q: --
   2100/1000000: episode: 21, duration: 0.071s, episode steps: 100, steps per second: 1401, episode reward: 60.681, mean reward: 0.607 [0.518, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.842, 10.098], loss: --, mae: --, mean_q: --
   2200/1000000: episode: 22, duration: 0.067s, episode steps: 100, steps per second: 1504, episode reward: 57.617, mean reward: 0.576 [0.501, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.128, 10.101], loss: --, mae: --, mean_q: --
   2300/1000000: episode: 23, duration: 0.083s, episode steps: 100, steps per second: 1198, episode reward: 59.884, mean reward: 0.599 [0.513, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.013, 10.098], loss: --, mae: --, mean_q: --
   2400/1000000: episode: 24, duration: 0.076s, episode steps: 100, steps per second: 1308, episode reward: 59.332, mean reward: 0.593 [0.505, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.623, 10.197], loss: --, mae: --, mean_q: --
   2500/1000000: episode: 25, duration: 0.082s, episode steps: 100, steps per second: 1224, episode reward: 59.509, mean reward: 0.595 [0.510, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.090, 10.343], loss: --, mae: --, mean_q: --
   2600/1000000: episode: 26, duration: 0.068s, episode steps: 100, steps per second: 1471, episode reward: 60.924, mean reward: 0.609 [0.506, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.868, 10.098], loss: --, mae: --, mean_q: --
   2700/1000000: episode: 27, duration: 0.074s, episode steps: 100, steps per second: 1348, episode reward: 59.158, mean reward: 0.592 [0.510, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.394, 10.135], loss: --, mae: --, mean_q: --
   2800/1000000: episode: 28, duration: 0.081s, episode steps: 100, steps per second: 1240, episode reward: 65.120, mean reward: 0.651 [0.519, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.001, 10.175], loss: --, mae: --, mean_q: --
   2900/1000000: episode: 29, duration: 0.070s, episode steps: 100, steps per second: 1424, episode reward: 58.094, mean reward: 0.581 [0.504, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.497, 10.098], loss: --, mae: --, mean_q: --
   3000/1000000: episode: 30, duration: 0.073s, episode steps: 100, steps per second: 1369, episode reward: 57.443, mean reward: 0.574 [0.499, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.472, 10.203], loss: --, mae: --, mean_q: --
   3100/1000000: episode: 31, duration: 0.070s, episode steps: 100, steps per second: 1426, episode reward: 56.885, mean reward: 0.569 [0.502, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.920, 10.145], loss: --, mae: --, mean_q: --
   3200/1000000: episode: 32, duration: 0.087s, episode steps: 100, steps per second: 1146, episode reward: 58.606, mean reward: 0.586 [0.505, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.736, 10.098], loss: --, mae: --, mean_q: --
   3300/1000000: episode: 33, duration: 0.073s, episode steps: 100, steps per second: 1368, episode reward: 58.481, mean reward: 0.585 [0.519, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.701, 10.220], loss: --, mae: --, mean_q: --
   3400/1000000: episode: 34, duration: 0.069s, episode steps: 100, steps per second: 1452, episode reward: 58.707, mean reward: 0.587 [0.504, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.828, 10.295], loss: --, mae: --, mean_q: --
   3500/1000000: episode: 35, duration: 0.069s, episode steps: 100, steps per second: 1454, episode reward: 58.288, mean reward: 0.583 [0.503, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.429, 10.098], loss: --, mae: --, mean_q: --
   3600/1000000: episode: 36, duration: 0.071s, episode steps: 100, steps per second: 1416, episode reward: 56.638, mean reward: 0.566 [0.501, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.535, 10.237], loss: --, mae: --, mean_q: --
   3700/1000000: episode: 37, duration: 0.070s, episode steps: 100, steps per second: 1429, episode reward: 58.973, mean reward: 0.590 [0.499, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.011, 10.098], loss: --, mae: --, mean_q: --
   3800/1000000: episode: 38, duration: 0.071s, episode steps: 100, steps per second: 1411, episode reward: 59.178, mean reward: 0.592 [0.510, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.225, 10.098], loss: --, mae: --, mean_q: --
   3900/1000000: episode: 39, duration: 0.068s, episode steps: 100, steps per second: 1481, episode reward: 58.155, mean reward: 0.582 [0.509, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.440, 10.286], loss: --, mae: --, mean_q: --
   4000/1000000: episode: 40, duration: 0.071s, episode steps: 100, steps per second: 1404, episode reward: 56.559, mean reward: 0.566 [0.505, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.677, 10.115], loss: --, mae: --, mean_q: --
   4100/1000000: episode: 41, duration: 0.072s, episode steps: 100, steps per second: 1390, episode reward: 59.220, mean reward: 0.592 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.908, 10.098], loss: --, mae: --, mean_q: --
   4200/1000000: episode: 42, duration: 0.072s, episode steps: 100, steps per second: 1396, episode reward: 59.757, mean reward: 0.598 [0.509, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.363, 10.098], loss: --, mae: --, mean_q: --
   4300/1000000: episode: 43, duration: 0.066s, episode steps: 100, steps per second: 1517, episode reward: 56.709, mean reward: 0.567 [0.507, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.953, 10.103], loss: --, mae: --, mean_q: --
   4400/1000000: episode: 44, duration: 0.114s, episode steps: 100, steps per second: 876, episode reward: 61.774, mean reward: 0.618 [0.519, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.436, 10.098], loss: --, mae: --, mean_q: --
   4500/1000000: episode: 45, duration: 0.095s, episode steps: 100, steps per second: 1057, episode reward: 60.032, mean reward: 0.600 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.317, 10.156], loss: --, mae: --, mean_q: --
   4600/1000000: episode: 46, duration: 0.083s, episode steps: 100, steps per second: 1198, episode reward: 59.049, mean reward: 0.590 [0.509, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.778, 10.129], loss: --, mae: --, mean_q: --
   4700/1000000: episode: 47, duration: 0.084s, episode steps: 100, steps per second: 1193, episode reward: 61.190, mean reward: 0.612 [0.509, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.827, 10.098], loss: --, mae: --, mean_q: --
   4800/1000000: episode: 48, duration: 0.067s, episode steps: 100, steps per second: 1496, episode reward: 59.495, mean reward: 0.595 [0.506, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.035, 10.201], loss: --, mae: --, mean_q: --
   4900/1000000: episode: 49, duration: 0.066s, episode steps: 100, steps per second: 1515, episode reward: 60.110, mean reward: 0.601 [0.519, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.011, 10.098], loss: --, mae: --, mean_q: --
   5000/1000000: episode: 50, duration: 0.067s, episode steps: 100, steps per second: 1502, episode reward: 61.224, mean reward: 0.612 [0.509, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.968, 10.412], loss: --, mae: --, mean_q: --
   5100/1000000: episode: 51, duration: 1.295s, episode steps: 100, steps per second: 77, episode reward: 61.619, mean reward: 0.616 [0.512, 0.886], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.861, 10.098], loss: 0.010685, mae: 0.100849, mean_q: 0.793817
   5200/1000000: episode: 52, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.705, mean reward: 0.577 [0.500, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.132, 10.098], loss: 0.003829, mae: 0.061725, mean_q: 0.926043
   5300/1000000: episode: 53, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.438, mean reward: 0.584 [0.507, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.071, 10.098], loss: 0.002708, mae: 0.053315, mean_q: 1.016268
   5400/1000000: episode: 54, duration: 0.630s, episode steps: 100, steps per second: 159, episode reward: 57.777, mean reward: 0.578 [0.505, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.975, 10.132], loss: 0.002927, mae: 0.054648, mean_q: 1.074971
   5500/1000000: episode: 55, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.283, mean reward: 0.583 [0.507, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.500, 10.098], loss: 0.002568, mae: 0.050807, mean_q: 1.114905
   5600/1000000: episode: 56, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 61.941, mean reward: 0.619 [0.511, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.420, 10.333], loss: 0.002857, mae: 0.052327, mean_q: 1.137985
   5700/1000000: episode: 57, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.243, mean reward: 0.592 [0.506, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.642, 10.277], loss: 0.003056, mae: 0.055348, mean_q: 1.153233
   5800/1000000: episode: 58, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.530, mean reward: 0.575 [0.505, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.894, 10.098], loss: 0.002894, mae: 0.053712, mean_q: 1.164652
   5900/1000000: episode: 59, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 61.848, mean reward: 0.618 [0.507, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.993, 10.098], loss: 0.002801, mae: 0.052219, mean_q: 1.166133
   6000/1000000: episode: 60, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: 58.035, mean reward: 0.580 [0.507, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.601, 10.172], loss: 0.002811, mae: 0.053600, mean_q: 1.170209
   6100/1000000: episode: 61, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 57.395, mean reward: 0.574 [0.510, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.296, 10.098], loss: 0.002563, mae: 0.049905, mean_q: 1.172069
   6200/1000000: episode: 62, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.721, mean reward: 0.587 [0.506, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.577, 10.098], loss: 0.002899, mae: 0.054167, mean_q: 1.172527
   6300/1000000: episode: 63, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.871, mean reward: 0.599 [0.518, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.759, 10.122], loss: 0.002601, mae: 0.051008, mean_q: 1.171975
   6400/1000000: episode: 64, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.759, mean reward: 0.578 [0.508, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.764, 10.098], loss: 0.002698, mae: 0.052053, mean_q: 1.174146
   6500/1000000: episode: 65, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.057, mean reward: 0.591 [0.510, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.645, 10.107], loss: 0.002314, mae: 0.049558, mean_q: 1.173784
   6600/1000000: episode: 66, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.686, mean reward: 0.597 [0.499, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.243, 10.457], loss: 0.002644, mae: 0.052253, mean_q: 1.170079
   6700/1000000: episode: 67, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.499, mean reward: 0.585 [0.499, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.318, 10.113], loss: 0.002256, mae: 0.048881, mean_q: 1.171660
   6800/1000000: episode: 68, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.331, mean reward: 0.573 [0.500, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.058, 10.098], loss: 0.002276, mae: 0.049726, mean_q: 1.171390
   6900/1000000: episode: 69, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 56.902, mean reward: 0.569 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.219, 10.351], loss: 0.002361, mae: 0.049727, mean_q: 1.169869
   7000/1000000: episode: 70, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.107, mean reward: 0.581 [0.502, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.032, 10.138], loss: 0.002447, mae: 0.050990, mean_q: 1.168543
   7100/1000000: episode: 71, duration: 0.629s, episode steps: 100, steps per second: 159, episode reward: 57.802, mean reward: 0.578 [0.503, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.275, 10.195], loss: 0.002159, mae: 0.048885, mean_q: 1.170584
   7200/1000000: episode: 72, duration: 0.618s, episode steps: 100, steps per second: 162, episode reward: 57.214, mean reward: 0.572 [0.504, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.059, 10.098], loss: 0.002270, mae: 0.048828, mean_q: 1.170031
   7300/1000000: episode: 73, duration: 0.698s, episode steps: 100, steps per second: 143, episode reward: 57.620, mean reward: 0.576 [0.506, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.548, 10.098], loss: 0.002440, mae: 0.050289, mean_q: 1.167639
   7400/1000000: episode: 74, duration: 0.635s, episode steps: 100, steps per second: 157, episode reward: 59.515, mean reward: 0.595 [0.506, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.176, 10.115], loss: 0.002299, mae: 0.049056, mean_q: 1.164858
   7500/1000000: episode: 75, duration: 0.650s, episode steps: 100, steps per second: 154, episode reward: 62.522, mean reward: 0.625 [0.536, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.097, 10.284], loss: 0.002369, mae: 0.049988, mean_q: 1.166847
   7600/1000000: episode: 76, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.620, mean reward: 0.606 [0.499, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.668, 10.291], loss: 0.002307, mae: 0.049863, mean_q: 1.167381
   7700/1000000: episode: 77, duration: 0.632s, episode steps: 100, steps per second: 158, episode reward: 59.122, mean reward: 0.591 [0.512, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.190, 10.297], loss: 0.002655, mae: 0.053746, mean_q: 1.167424
   7800/1000000: episode: 78, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.697, mean reward: 0.577 [0.501, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.581, 10.209], loss: 0.002464, mae: 0.051030, mean_q: 1.164301
   7900/1000000: episode: 79, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.265, mean reward: 0.593 [0.511, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.615, 10.098], loss: 0.002376, mae: 0.051123, mean_q: 1.164569
   8000/1000000: episode: 80, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.799, mean reward: 0.598 [0.506, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.916, 10.098], loss: 0.002658, mae: 0.052706, mean_q: 1.161655
   8100/1000000: episode: 81, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.112, mean reward: 0.581 [0.505, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.879, 10.157], loss: 0.002290, mae: 0.049941, mean_q: 1.166066
   8200/1000000: episode: 82, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.523, mean reward: 0.575 [0.500, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.854, 10.098], loss: 0.002052, mae: 0.047585, mean_q: 1.167921
   8300/1000000: episode: 83, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.134, mean reward: 0.581 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.409, 10.190], loss: 0.002229, mae: 0.048718, mean_q: 1.165743
   8400/1000000: episode: 84, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.178, mean reward: 0.582 [0.502, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.453, 10.098], loss: 0.002213, mae: 0.049209, mean_q: 1.164762
   8500/1000000: episode: 85, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 61.618, mean reward: 0.616 [0.502, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.615, 10.098], loss: 0.001994, mae: 0.047035, mean_q: 1.165135
   8600/1000000: episode: 86, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.350, mean reward: 0.583 [0.508, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.696, 10.098], loss: 0.002244, mae: 0.049530, mean_q: 1.166543
   8700/1000000: episode: 87, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.412, mean reward: 0.584 [0.499, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.126, 10.149], loss: 0.002050, mae: 0.048328, mean_q: 1.169754
   8800/1000000: episode: 88, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.529, mean reward: 0.585 [0.502, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.837, 10.134], loss: 0.002120, mae: 0.048751, mean_q: 1.168230
   8900/1000000: episode: 89, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.922, mean reward: 0.599 [0.512, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.920, 10.098], loss: 0.002343, mae: 0.050405, mean_q: 1.164869
   9000/1000000: episode: 90, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.910, mean reward: 0.579 [0.503, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.979, 10.098], loss: 0.002415, mae: 0.051692, mean_q: 1.164167
   9100/1000000: episode: 91, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.875, mean reward: 0.579 [0.501, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.003, 10.098], loss: 0.002198, mae: 0.049529, mean_q: 1.164795
   9200/1000000: episode: 92, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.784, mean reward: 0.588 [0.503, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.145, 10.098], loss: 0.002008, mae: 0.048214, mean_q: 1.168406
   9300/1000000: episode: 93, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.313, mean reward: 0.583 [0.506, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.944, 10.213], loss: 0.002016, mae: 0.047889, mean_q: 1.170765
   9400/1000000: episode: 94, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.063, mean reward: 0.571 [0.504, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.198, 10.098], loss: 0.002186, mae: 0.049253, mean_q: 1.167706
   9500/1000000: episode: 95, duration: 0.523s, episode steps: 100, steps per second: 191, episode reward: 58.411, mean reward: 0.584 [0.511, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.500, 10.221], loss: 0.002135, mae: 0.048214, mean_q: 1.167563
   9600/1000000: episode: 96, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 65.694, mean reward: 0.657 [0.510, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.391, 10.508], loss: 0.002308, mae: 0.049666, mean_q: 1.165453
   9700/1000000: episode: 97, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.180, mean reward: 0.572 [0.503, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.808, 10.098], loss: 0.002126, mae: 0.048627, mean_q: 1.167943
   9800/1000000: episode: 98, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.767, mean reward: 0.588 [0.510, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.976, 10.157], loss: 0.002130, mae: 0.048313, mean_q: 1.167104
   9900/1000000: episode: 99, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.740, mean reward: 0.577 [0.507, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.449, 10.270], loss: 0.002292, mae: 0.050387, mean_q: 1.166118
  10000/1000000: episode: 100, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.440, mean reward: 0.594 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.844, 10.189], loss: 0.002126, mae: 0.048411, mean_q: 1.168282
  10100/1000000: episode: 101, duration: 0.520s, episode steps: 100, steps per second: 192, episode reward: 58.384, mean reward: 0.584 [0.505, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.896, 10.202], loss: 0.002129, mae: 0.048764, mean_q: 1.163744
  10200/1000000: episode: 102, duration: 0.521s, episode steps: 100, steps per second: 192, episode reward: 61.846, mean reward: 0.618 [0.508, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.957, 10.098], loss: 0.002190, mae: 0.049554, mean_q: 1.162800
  10300/1000000: episode: 103, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.741, mean reward: 0.577 [0.500, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.444, 10.274], loss: 0.002073, mae: 0.048587, mean_q: 1.165288
  10400/1000000: episode: 104, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.735, mean reward: 0.597 [0.516, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.992, 10.133], loss: 0.002058, mae: 0.048009, mean_q: 1.164984
  10500/1000000: episode: 105, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.053, mean reward: 0.581 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.438, 10.098], loss: 0.002055, mae: 0.048094, mean_q: 1.164799
  10600/1000000: episode: 106, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.346, mean reward: 0.593 [0.498, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.214, 10.098], loss: 0.002061, mae: 0.048450, mean_q: 1.164026
  10700/1000000: episode: 107, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.959, mean reward: 0.580 [0.504, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.694, 10.267], loss: 0.002047, mae: 0.048462, mean_q: 1.162683
  10800/1000000: episode: 108, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 56.924, mean reward: 0.569 [0.504, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.628, 10.127], loss: 0.001850, mae: 0.046142, mean_q: 1.164051
  10900/1000000: episode: 109, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.618, mean reward: 0.586 [0.506, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.336, 10.317], loss: 0.001991, mae: 0.047872, mean_q: 1.162542
  11000/1000000: episode: 110, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 61.925, mean reward: 0.619 [0.503, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.411, 10.125], loss: 0.001870, mae: 0.046692, mean_q: 1.162139
  11100/1000000: episode: 111, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 59.849, mean reward: 0.598 [0.512, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.606, 10.297], loss: 0.002133, mae: 0.049720, mean_q: 1.165501
  11200/1000000: episode: 112, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 63.033, mean reward: 0.630 [0.503, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.320, 10.098], loss: 0.001927, mae: 0.047351, mean_q: 1.163222
  11300/1000000: episode: 113, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.304, mean reward: 0.583 [0.499, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.107, 10.165], loss: 0.002030, mae: 0.048345, mean_q: 1.165996
  11400/1000000: episode: 114, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.062, mean reward: 0.581 [0.506, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.526, 10.120], loss: 0.002100, mae: 0.048689, mean_q: 1.164242
  11500/1000000: episode: 115, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.806, mean reward: 0.588 [0.506, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.388, 10.098], loss: 0.001991, mae: 0.048179, mean_q: 1.164997
  11600/1000000: episode: 116, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 61.953, mean reward: 0.620 [0.517, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.173, 10.098], loss: 0.001922, mae: 0.047087, mean_q: 1.165529
  11700/1000000: episode: 117, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.817, mean reward: 0.588 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.896, 10.098], loss: 0.002137, mae: 0.049045, mean_q: 1.164840
  11800/1000000: episode: 118, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 60.799, mean reward: 0.608 [0.501, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.193, 10.126], loss: 0.002065, mae: 0.048976, mean_q: 1.166735
  11900/1000000: episode: 119, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 61.323, mean reward: 0.613 [0.509, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.087, 10.314], loss: 0.001985, mae: 0.047460, mean_q: 1.169563
  12000/1000000: episode: 120, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.223, mean reward: 0.602 [0.510, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.062, 10.098], loss: 0.001911, mae: 0.047091, mean_q: 1.168826
  12100/1000000: episode: 121, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.941, mean reward: 0.609 [0.505, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.687, 10.098], loss: 0.002124, mae: 0.049695, mean_q: 1.169854
  12200/1000000: episode: 122, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.650, mean reward: 0.616 [0.498, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.526, 10.456], loss: 0.002025, mae: 0.048707, mean_q: 1.172547
  12300/1000000: episode: 123, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 57.636, mean reward: 0.576 [0.503, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.340, 10.098], loss: 0.001969, mae: 0.048084, mean_q: 1.170549
  12400/1000000: episode: 124, duration: 0.533s, episode steps: 100, steps per second: 187, episode reward: 59.940, mean reward: 0.599 [0.503, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.631, 10.098], loss: 0.001884, mae: 0.047168, mean_q: 1.171481
  12500/1000000: episode: 125, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 58.144, mean reward: 0.581 [0.500, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.932, 10.235], loss: 0.001980, mae: 0.047793, mean_q: 1.174455
  12600/1000000: episode: 126, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.899, mean reward: 0.609 [0.506, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.574, 10.427], loss: 0.002072, mae: 0.049266, mean_q: 1.175205
  12700/1000000: episode: 127, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.498, mean reward: 0.575 [0.506, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.155, 10.098], loss: 0.001889, mae: 0.046884, mean_q: 1.172538
  12800/1000000: episode: 128, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.949, mean reward: 0.589 [0.513, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.938, 10.138], loss: 0.001900, mae: 0.047357, mean_q: 1.172772
  12900/1000000: episode: 129, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.687, mean reward: 0.587 [0.501, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.633, 10.163], loss: 0.001931, mae: 0.047344, mean_q: 1.173876
  13000/1000000: episode: 130, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.296, mean reward: 0.583 [0.500, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.162, 10.098], loss: 0.001830, mae: 0.046192, mean_q: 1.173526
  13100/1000000: episode: 131, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.732, mean reward: 0.577 [0.501, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.989, 10.098], loss: 0.001857, mae: 0.047210, mean_q: 1.174888
  13200/1000000: episode: 132, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.646, mean reward: 0.586 [0.503, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.526, 10.098], loss: 0.001958, mae: 0.047808, mean_q: 1.173564
  13300/1000000: episode: 133, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.456, mean reward: 0.575 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.770, 10.138], loss: 0.001855, mae: 0.046246, mean_q: 1.172343
  13400/1000000: episode: 134, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.548, mean reward: 0.575 [0.507, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.300, 10.098], loss: 0.001661, mae: 0.044769, mean_q: 1.170237
  13500/1000000: episode: 135, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.798, mean reward: 0.598 [0.510, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.501, 10.315], loss: 0.001876, mae: 0.046672, mean_q: 1.171225
  13600/1000000: episode: 136, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.738, mean reward: 0.577 [0.502, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.773, 10.098], loss: 0.001889, mae: 0.046587, mean_q: 1.171451
  13700/1000000: episode: 137, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.390, mean reward: 0.594 [0.508, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.298, 10.098], loss: 0.001975, mae: 0.048275, mean_q: 1.170012
  13800/1000000: episode: 138, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.281, mean reward: 0.573 [0.503, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.055, 10.101], loss: 0.001757, mae: 0.045385, mean_q: 1.172725
  13900/1000000: episode: 139, duration: 0.523s, episode steps: 100, steps per second: 191, episode reward: 58.788, mean reward: 0.588 [0.502, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.756, 10.212], loss: 0.001751, mae: 0.045323, mean_q: 1.167449
  14000/1000000: episode: 140, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.314, mean reward: 0.603 [0.502, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.770, 10.098], loss: 0.001842, mae: 0.046911, mean_q: 1.168620
  14100/1000000: episode: 141, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 58.079, mean reward: 0.581 [0.504, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.183, 10.239], loss: 0.001780, mae: 0.045264, mean_q: 1.169809
  14200/1000000: episode: 142, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.076, mean reward: 0.581 [0.507, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.734, 10.251], loss: 0.001784, mae: 0.045407, mean_q: 1.166926
  14300/1000000: episode: 143, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.501, mean reward: 0.595 [0.505, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.915, 10.098], loss: 0.001686, mae: 0.044198, mean_q: 1.170665
  14400/1000000: episode: 144, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 66.945, mean reward: 0.669 [0.502, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.577, 10.098], loss: 0.001806, mae: 0.046272, mean_q: 1.171857
  14500/1000000: episode: 145, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.833, mean reward: 0.578 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.847, 10.304], loss: 0.001635, mae: 0.044275, mean_q: 1.174328
  14600/1000000: episode: 146, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.755, mean reward: 0.568 [0.500, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.410, 10.098], loss: 0.001819, mae: 0.045874, mean_q: 1.169623
  14700/1000000: episode: 147, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 60.008, mean reward: 0.600 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.094, 10.098], loss: 0.001898, mae: 0.046805, mean_q: 1.172353
  14800/1000000: episode: 148, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 64.920, mean reward: 0.649 [0.514, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.464, 10.256], loss: 0.001654, mae: 0.044168, mean_q: 1.171163
  14900/1000000: episode: 149, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 57.404, mean reward: 0.574 [0.503, 0.665], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.552, 10.098], loss: 0.001749, mae: 0.045465, mean_q: 1.175861
  15000/1000000: episode: 150, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.812, mean reward: 0.578 [0.507, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.191, 10.098], loss: 0.001791, mae: 0.045529, mean_q: 1.175001
  15100/1000000: episode: 151, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 61.107, mean reward: 0.611 [0.517, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.247, 10.351], loss: 0.001789, mae: 0.046057, mean_q: 1.173148
  15200/1000000: episode: 152, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 56.803, mean reward: 0.568 [0.499, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.890, 10.098], loss: 0.001816, mae: 0.046112, mean_q: 1.172778
  15300/1000000: episode: 153, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.253, mean reward: 0.593 [0.506, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.918, 10.282], loss: 0.001679, mae: 0.045074, mean_q: 1.176145
  15400/1000000: episode: 154, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.010, mean reward: 0.580 [0.501, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.805, 10.173], loss: 0.001706, mae: 0.045479, mean_q: 1.175858
  15500/1000000: episode: 155, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.085, mean reward: 0.581 [0.501, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.579, 10.098], loss: 0.001629, mae: 0.043811, mean_q: 1.173048
  15600/1000000: episode: 156, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 56.799, mean reward: 0.568 [0.505, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.763, 10.098], loss: 0.001657, mae: 0.044054, mean_q: 1.171854
  15700/1000000: episode: 157, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 59.460, mean reward: 0.595 [0.510, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.830, 10.098], loss: 0.001565, mae: 0.042964, mean_q: 1.172253
  15800/1000000: episode: 158, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.468, mean reward: 0.605 [0.515, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.089, 10.098], loss: 0.001670, mae: 0.043772, mean_q: 1.175376
  15900/1000000: episode: 159, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 61.881, mean reward: 0.619 [0.510, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.949, 10.287], loss: 0.001704, mae: 0.044334, mean_q: 1.171801
  16000/1000000: episode: 160, duration: 0.524s, episode steps: 100, steps per second: 191, episode reward: 62.921, mean reward: 0.629 [0.502, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.451, 10.522], loss: 0.001668, mae: 0.044284, mean_q: 1.174271
  16100/1000000: episode: 161, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.165, mean reward: 0.572 [0.500, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.334, 10.185], loss: 0.001615, mae: 0.043850, mean_q: 1.175164
  16200/1000000: episode: 162, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.701, mean reward: 0.577 [0.502, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.676, 10.383], loss: 0.001708, mae: 0.045000, mean_q: 1.171785
  16300/1000000: episode: 163, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.501, mean reward: 0.585 [0.499, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.320, 10.421], loss: 0.001646, mae: 0.044205, mean_q: 1.173645
  16400/1000000: episode: 164, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.133, mean reward: 0.581 [0.508, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.446 [-0.967, 10.401], loss: 0.001729, mae: 0.044582, mean_q: 1.173256
  16500/1000000: episode: 165, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.712, mean reward: 0.587 [0.501, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.249, 10.112], loss: 0.001975, mae: 0.047548, mean_q: 1.169942
  16600/1000000: episode: 166, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.662, mean reward: 0.597 [0.516, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.853, 10.190], loss: 0.001860, mae: 0.046395, mean_q: 1.168134
  16700/1000000: episode: 167, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.383, mean reward: 0.584 [0.512, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.439, 10.352], loss: 0.001608, mae: 0.043291, mean_q: 1.166338
  16800/1000000: episode: 168, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 56.872, mean reward: 0.569 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.310, 10.098], loss: 0.001703, mae: 0.044481, mean_q: 1.168462
  16900/1000000: episode: 169, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.340, mean reward: 0.593 [0.501, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.259, 10.216], loss: 0.001665, mae: 0.044612, mean_q: 1.168108
  17000/1000000: episode: 170, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.537, mean reward: 0.585 [0.500, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.210, 10.132], loss: 0.001616, mae: 0.043410, mean_q: 1.167141
  17100/1000000: episode: 171, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.081, mean reward: 0.591 [0.508, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.426, 10.253], loss: 0.001700, mae: 0.044234, mean_q: 1.169786
  17200/1000000: episode: 172, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.947, mean reward: 0.579 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.802, 10.098], loss: 0.001602, mae: 0.043252, mean_q: 1.168514
  17300/1000000: episode: 173, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 57.408, mean reward: 0.574 [0.499, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.996, 10.341], loss: 0.001573, mae: 0.042950, mean_q: 1.164814
  17400/1000000: episode: 174, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.751, mean reward: 0.598 [0.511, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.236, 10.206], loss: 0.001433, mae: 0.040646, mean_q: 1.163919
  17500/1000000: episode: 175, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.908, mean reward: 0.579 [0.517, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.772, 10.229], loss: 0.001644, mae: 0.044085, mean_q: 1.168152
  17600/1000000: episode: 176, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.771, mean reward: 0.588 [0.502, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.913, 10.213], loss: 0.001741, mae: 0.044964, mean_q: 1.163542
  17700/1000000: episode: 177, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.284, mean reward: 0.583 [0.500, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.721, 10.098], loss: 0.001503, mae: 0.042414, mean_q: 1.164844
  17800/1000000: episode: 178, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.377, mean reward: 0.594 [0.501, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.600, 10.190], loss: 0.001607, mae: 0.042941, mean_q: 1.166587
  17900/1000000: episode: 179, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.707, mean reward: 0.587 [0.501, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.593, 10.098], loss: 0.001449, mae: 0.041087, mean_q: 1.165632
  18000/1000000: episode: 180, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.147, mean reward: 0.601 [0.503, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.052, 10.219], loss: 0.001574, mae: 0.042908, mean_q: 1.164026
  18100/1000000: episode: 181, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.252, mean reward: 0.573 [0.499, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.822, 10.129], loss: 0.001586, mae: 0.043195, mean_q: 1.166806
  18200/1000000: episode: 182, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.913, mean reward: 0.579 [0.516, 0.660], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.495, 10.175], loss: 0.001598, mae: 0.042633, mean_q: 1.164902
  18300/1000000: episode: 183, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.384, mean reward: 0.594 [0.518, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.945, 10.098], loss: 0.001661, mae: 0.044005, mean_q: 1.166555
  18400/1000000: episode: 184, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.843, mean reward: 0.578 [0.512, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.892, 10.098], loss: 0.001516, mae: 0.042076, mean_q: 1.169401
  18500/1000000: episode: 185, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.102, mean reward: 0.581 [0.507, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.826, 10.098], loss: 0.001594, mae: 0.043023, mean_q: 1.163881
  18600/1000000: episode: 186, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.853, mean reward: 0.589 [0.506, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.452, 10.186], loss: 0.001505, mae: 0.041621, mean_q: 1.164394
  18700/1000000: episode: 187, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.167, mean reward: 0.582 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.624, 10.163], loss: 0.001571, mae: 0.042650, mean_q: 1.163201
  18800/1000000: episode: 188, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.826, mean reward: 0.588 [0.500, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.972, 10.207], loss: 0.001580, mae: 0.042753, mean_q: 1.163259
  18900/1000000: episode: 189, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.978, mean reward: 0.590 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.823, 10.098], loss: 0.001561, mae: 0.042795, mean_q: 1.166666
  19000/1000000: episode: 190, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.586, mean reward: 0.596 [0.504, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.001, 10.194], loss: 0.001572, mae: 0.042841, mean_q: 1.168210
  19100/1000000: episode: 191, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 62.241, mean reward: 0.622 [0.520, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.431, 10.098], loss: 0.001643, mae: 0.043738, mean_q: 1.168383
  19200/1000000: episode: 192, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.095, mean reward: 0.581 [0.499, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.786, 10.273], loss: 0.001413, mae: 0.040973, mean_q: 1.169204
  19300/1000000: episode: 193, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.449, mean reward: 0.584 [0.503, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.633, 10.098], loss: 0.001648, mae: 0.043558, mean_q: 1.168425
  19400/1000000: episode: 194, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.964, mean reward: 0.580 [0.503, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.271, 10.136], loss: 0.001448, mae: 0.041427, mean_q: 1.163555
  19500/1000000: episode: 195, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 59.925, mean reward: 0.599 [0.499, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.810, 10.324], loss: 0.001520, mae: 0.042123, mean_q: 1.163060
  19600/1000000: episode: 196, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 60.815, mean reward: 0.608 [0.511, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.441, 10.098], loss: 0.001478, mae: 0.041534, mean_q: 1.163931
  19700/1000000: episode: 197, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.748, mean reward: 0.587 [0.499, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.396, 10.163], loss: 0.001404, mae: 0.040716, mean_q: 1.164310
  19800/1000000: episode: 198, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 62.497, mean reward: 0.625 [0.503, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.459, 10.098], loss: 0.001550, mae: 0.042335, mean_q: 1.162751
  19900/1000000: episode: 199, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.936, mean reward: 0.579 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.820, 10.098], loss: 0.001592, mae: 0.043323, mean_q: 1.162944
  20000/1000000: episode: 200, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.202, mean reward: 0.582 [0.499, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.560, 10.107], loss: 0.001469, mae: 0.041185, mean_q: 1.160341
  20100/1000000: episode: 201, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 62.044, mean reward: 0.620 [0.505, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.660, 10.355], loss: 0.001594, mae: 0.043586, mean_q: 1.165373
  20200/1000000: episode: 202, duration: 0.524s, episode steps: 100, steps per second: 191, episode reward: 57.693, mean reward: 0.577 [0.504, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.618, 10.121], loss: 0.001522, mae: 0.042187, mean_q: 1.166397
  20300/1000000: episode: 203, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 56.136, mean reward: 0.561 [0.500, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.756, 10.140], loss: 0.001470, mae: 0.042220, mean_q: 1.165136
  20400/1000000: episode: 204, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 59.946, mean reward: 0.599 [0.512, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.763, 10.410], loss: 0.001643, mae: 0.043412, mean_q: 1.161121
  20500/1000000: episode: 205, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.559, mean reward: 0.576 [0.504, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.634, 10.098], loss: 0.001585, mae: 0.042915, mean_q: 1.164977
  20600/1000000: episode: 206, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.209, mean reward: 0.592 [0.507, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.468, 10.098], loss: 0.001575, mae: 0.043449, mean_q: 1.164392
  20700/1000000: episode: 207, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 56.935, mean reward: 0.569 [0.507, 0.661], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.486, 10.098], loss: 0.001560, mae: 0.042402, mean_q: 1.163905
  20800/1000000: episode: 208, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.186, mean reward: 0.592 [0.506, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.772, 10.098], loss: 0.001589, mae: 0.043379, mean_q: 1.159340
  20900/1000000: episode: 209, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 59.158, mean reward: 0.592 [0.514, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.216, 10.244], loss: 0.001493, mae: 0.041322, mean_q: 1.161291
  21000/1000000: episode: 210, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.016, mean reward: 0.580 [0.507, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.305, 10.212], loss: 0.001548, mae: 0.042415, mean_q: 1.160828
  21100/1000000: episode: 211, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.921, mean reward: 0.589 [0.506, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.987, 10.334], loss: 0.001585, mae: 0.043034, mean_q: 1.158611
  21200/1000000: episode: 212, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 56.934, mean reward: 0.569 [0.502, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.849, 10.098], loss: 0.001472, mae: 0.041577, mean_q: 1.160032
  21300/1000000: episode: 213, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 59.965, mean reward: 0.600 [0.517, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-1.481, 10.098], loss: 0.001545, mae: 0.042215, mean_q: 1.160686
  21400/1000000: episode: 214, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 57.395, mean reward: 0.574 [0.506, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.944, 10.098], loss: 0.001511, mae: 0.041386, mean_q: 1.159004
  21500/1000000: episode: 215, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 57.188, mean reward: 0.572 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.069, 10.195], loss: 0.001426, mae: 0.040687, mean_q: 1.159252
  21600/1000000: episode: 216, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.174, mean reward: 0.612 [0.512, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.985, 10.098], loss: 0.001580, mae: 0.043038, mean_q: 1.163365
  21700/1000000: episode: 217, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.126, mean reward: 0.581 [0.507, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.420, 10.098], loss: 0.001548, mae: 0.042164, mean_q: 1.159408
  21800/1000000: episode: 218, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.589, mean reward: 0.596 [0.506, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.348, 10.098], loss: 0.001523, mae: 0.042570, mean_q: 1.158310
  21900/1000000: episode: 219, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 58.188, mean reward: 0.582 [0.510, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.714, 10.179], loss: 0.001379, mae: 0.040276, mean_q: 1.161699
  22000/1000000: episode: 220, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.671, mean reward: 0.587 [0.510, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.563, 10.134], loss: 0.001579, mae: 0.042535, mean_q: 1.162290
  22100/1000000: episode: 221, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.219, mean reward: 0.592 [0.505, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.397, 10.133], loss: 0.001478, mae: 0.041208, mean_q: 1.160941
  22200/1000000: episode: 222, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 56.999, mean reward: 0.570 [0.500, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.998, 10.328], loss: 0.001506, mae: 0.041951, mean_q: 1.160845
  22300/1000000: episode: 223, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.324, mean reward: 0.573 [0.501, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.674, 10.110], loss: 0.001389, mae: 0.040214, mean_q: 1.160014
  22400/1000000: episode: 224, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.571, mean reward: 0.616 [0.501, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.784, 10.288], loss: 0.001541, mae: 0.042695, mean_q: 1.159516
  22500/1000000: episode: 225, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.780, mean reward: 0.588 [0.504, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.746, 10.206], loss: 0.001517, mae: 0.042385, mean_q: 1.162818
  22600/1000000: episode: 226, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 62.077, mean reward: 0.621 [0.510, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.860, 10.130], loss: 0.001538, mae: 0.042668, mean_q: 1.161258
  22700/1000000: episode: 227, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 61.046, mean reward: 0.610 [0.499, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.060, 10.098], loss: 0.001667, mae: 0.044344, mean_q: 1.164707
  22800/1000000: episode: 228, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.534, mean reward: 0.585 [0.504, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.965, 10.098], loss: 0.001510, mae: 0.041748, mean_q: 1.162215
  22900/1000000: episode: 229, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.936, mean reward: 0.579 [0.502, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.034, 10.098], loss: 0.001460, mae: 0.041661, mean_q: 1.163669
  23000/1000000: episode: 230, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.142, mean reward: 0.611 [0.509, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.642, 10.098], loss: 0.001513, mae: 0.042044, mean_q: 1.161994
  23100/1000000: episode: 231, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.362, mean reward: 0.584 [0.508, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.643, 10.098], loss: 0.001493, mae: 0.042634, mean_q: 1.163959
  23200/1000000: episode: 232, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.997, mean reward: 0.590 [0.502, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.285, 10.446], loss: 0.001536, mae: 0.042315, mean_q: 1.164240
  23300/1000000: episode: 233, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.350, mean reward: 0.593 [0.507, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.346, 10.098], loss: 0.001635, mae: 0.043497, mean_q: 1.164970
  23400/1000000: episode: 234, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.569, mean reward: 0.586 [0.504, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.519, 10.098], loss: 0.001550, mae: 0.043218, mean_q: 1.169501
  23500/1000000: episode: 235, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.058, mean reward: 0.581 [0.503, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.622, 10.098], loss: 0.001504, mae: 0.042160, mean_q: 1.167978
  23600/1000000: episode: 236, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.605, mean reward: 0.596 [0.515, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.661, 10.265], loss: 0.001569, mae: 0.043396, mean_q: 1.167684
  23700/1000000: episode: 237, duration: 0.525s, episode steps: 100, steps per second: 191, episode reward: 59.150, mean reward: 0.591 [0.500, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.832, 10.203], loss: 0.001450, mae: 0.041688, mean_q: 1.166278
  23800/1000000: episode: 238, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.829, mean reward: 0.578 [0.509, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.889, 10.098], loss: 0.001615, mae: 0.043923, mean_q: 1.167752
  23900/1000000: episode: 239, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.840, mean reward: 0.588 [0.503, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.400, 10.403], loss: 0.001648, mae: 0.044240, mean_q: 1.164307
  24000/1000000: episode: 240, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.438, mean reward: 0.594 [0.516, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.192, 10.098], loss: 0.001504, mae: 0.042498, mean_q: 1.169951
  24100/1000000: episode: 241, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.609, mean reward: 0.586 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.325, 10.315], loss: 0.001563, mae: 0.042933, mean_q: 1.165957
  24200/1000000: episode: 242, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.366, mean reward: 0.594 [0.506, 0.878], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.922, 10.256], loss: 0.001520, mae: 0.042715, mean_q: 1.163679
  24300/1000000: episode: 243, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 57.707, mean reward: 0.577 [0.500, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.262, 10.098], loss: 0.001453, mae: 0.041616, mean_q: 1.166676
  24400/1000000: episode: 244, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.346, mean reward: 0.603 [0.528, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.526, 10.098], loss: 0.001523, mae: 0.042532, mean_q: 1.163761
  24500/1000000: episode: 245, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.155, mean reward: 0.572 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.123, 10.223], loss: 0.001742, mae: 0.044930, mean_q: 1.163386
  24600/1000000: episode: 246, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.389, mean reward: 0.594 [0.508, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.088, 10.130], loss: 0.001473, mae: 0.041939, mean_q: 1.165087
  24700/1000000: episode: 247, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.519, mean reward: 0.585 [0.505, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.487, 10.098], loss: 0.001641, mae: 0.043095, mean_q: 1.164804
  24800/1000000: episode: 248, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 61.561, mean reward: 0.616 [0.514, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.668, 10.200], loss: 0.001372, mae: 0.040433, mean_q: 1.165307
  24900/1000000: episode: 249, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.487, mean reward: 0.615 [0.504, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.916, 10.330], loss: 0.001486, mae: 0.042037, mean_q: 1.165164
  25000/1000000: episode: 250, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.276, mean reward: 0.593 [0.503, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.228, 10.098], loss: 0.001595, mae: 0.043956, mean_q: 1.165171
  25100/1000000: episode: 251, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 60.815, mean reward: 0.608 [0.507, 0.906], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.602, 10.650], loss: 0.001528, mae: 0.042534, mean_q: 1.166278
  25200/1000000: episode: 252, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.724, mean reward: 0.587 [0.509, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.226, 10.098], loss: 0.001506, mae: 0.042093, mean_q: 1.162197
  25300/1000000: episode: 253, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.310, mean reward: 0.603 [0.514, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.993, 10.298], loss: 0.001475, mae: 0.041968, mean_q: 1.167422
  25400/1000000: episode: 254, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.004, mean reward: 0.590 [0.507, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.882, 10.098], loss: 0.001544, mae: 0.042777, mean_q: 1.167113
  25500/1000000: episode: 255, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 61.683, mean reward: 0.617 [0.499, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.948, 10.098], loss: 0.001612, mae: 0.042990, mean_q: 1.164345
  25600/1000000: episode: 256, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 61.431, mean reward: 0.614 [0.509, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.522, 10.098], loss: 0.001502, mae: 0.042159, mean_q: 1.169267
  25700/1000000: episode: 257, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 56.690, mean reward: 0.567 [0.510, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.305, 10.098], loss: 0.001489, mae: 0.041542, mean_q: 1.167410
  25800/1000000: episode: 258, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.418, mean reward: 0.584 [0.501, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.695, 10.337], loss: 0.001501, mae: 0.042465, mean_q: 1.168895
  25900/1000000: episode: 259, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 59.566, mean reward: 0.596 [0.503, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.794, 10.200], loss: 0.001574, mae: 0.043003, mean_q: 1.170387
  26000/1000000: episode: 260, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 56.537, mean reward: 0.565 [0.501, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.991, 10.186], loss: 0.001674, mae: 0.044821, mean_q: 1.171703
  26100/1000000: episode: 261, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.145, mean reward: 0.601 [0.519, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.652, 10.098], loss: 0.001594, mae: 0.043475, mean_q: 1.168605
  26200/1000000: episode: 262, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 62.129, mean reward: 0.621 [0.506, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.939, 10.469], loss: 0.001555, mae: 0.043312, mean_q: 1.170406
  26300/1000000: episode: 263, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.814, mean reward: 0.588 [0.510, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.453, 10.098], loss: 0.001480, mae: 0.042141, mean_q: 1.170518
  26400/1000000: episode: 264, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 61.223, mean reward: 0.612 [0.516, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.726, 10.098], loss: 0.001523, mae: 0.043196, mean_q: 1.168165
  26500/1000000: episode: 265, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.031, mean reward: 0.580 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.370, 10.098], loss: 0.001529, mae: 0.042479, mean_q: 1.168922
  26600/1000000: episode: 266, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.292, mean reward: 0.593 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.593, 10.382], loss: 0.001566, mae: 0.043803, mean_q: 1.169728
  26700/1000000: episode: 267, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.774, mean reward: 0.588 [0.505, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.999, 10.121], loss: 0.001517, mae: 0.042774, mean_q: 1.172529
  26800/1000000: episode: 268, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.986, mean reward: 0.580 [0.501, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.727, 10.222], loss: 0.001495, mae: 0.042623, mean_q: 1.173182
  26900/1000000: episode: 269, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.243, mean reward: 0.582 [0.499, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.883, 10.352], loss: 0.001492, mae: 0.042777, mean_q: 1.173615
  27000/1000000: episode: 270, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.978, mean reward: 0.580 [0.503, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.256, 10.141], loss: 0.001564, mae: 0.043478, mean_q: 1.171854
  27100/1000000: episode: 271, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.610, mean reward: 0.586 [0.508, 0.843], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.475, 10.200], loss: 0.001559, mae: 0.043263, mean_q: 1.173126
  27200/1000000: episode: 272, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.098, mean reward: 0.581 [0.504, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.192, 10.098], loss: 0.001565, mae: 0.043599, mean_q: 1.175127
  27300/1000000: episode: 273, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.581, mean reward: 0.596 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.045, 10.296], loss: 0.001575, mae: 0.043045, mean_q: 1.173526
  27400/1000000: episode: 274, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.143, mean reward: 0.591 [0.501, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.698, 10.098], loss: 0.001573, mae: 0.043608, mean_q: 1.171507
  27500/1000000: episode: 275, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.836, mean reward: 0.568 [0.508, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.812, 10.098], loss: 0.001607, mae: 0.043814, mean_q: 1.176135
  27600/1000000: episode: 276, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.237, mean reward: 0.582 [0.508, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.519, 10.098], loss: 0.001660, mae: 0.044502, mean_q: 1.168600
  27700/1000000: episode: 277, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.797, mean reward: 0.618 [0.508, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.441, 10.471], loss: 0.001514, mae: 0.042978, mean_q: 1.172349
  27800/1000000: episode: 278, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 61.626, mean reward: 0.616 [0.513, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-1.032, 10.098], loss: 0.001666, mae: 0.044418, mean_q: 1.170556
  27900/1000000: episode: 279, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: 58.248, mean reward: 0.582 [0.505, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.574, 10.105], loss: 0.001483, mae: 0.042047, mean_q: 1.170665
  28000/1000000: episode: 280, duration: 0.525s, episode steps: 100, steps per second: 190, episode reward: 58.478, mean reward: 0.585 [0.509, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.128, 10.165], loss: 0.001375, mae: 0.040785, mean_q: 1.167922
  28100/1000000: episode: 281, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.866, mean reward: 0.579 [0.502, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.785, 10.126], loss: 0.001542, mae: 0.043761, mean_q: 1.172163
  28200/1000000: episode: 282, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.573, mean reward: 0.576 [0.503, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.325, 10.111], loss: 0.001532, mae: 0.042627, mean_q: 1.171414
  28300/1000000: episode: 283, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.325, mean reward: 0.583 [0.500, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.816, 10.098], loss: 0.001535, mae: 0.042656, mean_q: 1.168606
  28400/1000000: episode: 284, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 57.595, mean reward: 0.576 [0.506, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.464, 10.098], loss: 0.001464, mae: 0.042420, mean_q: 1.174035
  28500/1000000: episode: 285, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.003, mean reward: 0.610 [0.506, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.962, 10.098], loss: 0.001544, mae: 0.043182, mean_q: 1.170543
  28600/1000000: episode: 286, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.622, mean reward: 0.576 [0.502, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.777, 10.098], loss: 0.001517, mae: 0.042461, mean_q: 1.173225
  28700/1000000: episode: 287, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.010, mean reward: 0.590 [0.506, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.798, 10.098], loss: 0.001368, mae: 0.040816, mean_q: 1.171932
  28800/1000000: episode: 288, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.772, mean reward: 0.608 [0.500, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.112, 10.206], loss: 0.001561, mae: 0.043190, mean_q: 1.172823
  28900/1000000: episode: 289, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.047, mean reward: 0.570 [0.502, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.504, 10.098], loss: 0.001493, mae: 0.042249, mean_q: 1.167254
  29000/1000000: episode: 290, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.300, mean reward: 0.603 [0.511, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.504, 10.292], loss: 0.001446, mae: 0.041822, mean_q: 1.169570
  29100/1000000: episode: 291, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 62.333, mean reward: 0.623 [0.515, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.748, 10.141], loss: 0.001442, mae: 0.041394, mean_q: 1.168330
  29200/1000000: episode: 292, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.496, mean reward: 0.595 [0.512, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.571, 10.098], loss: 0.001381, mae: 0.040899, mean_q: 1.172805
  29300/1000000: episode: 293, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.161, mean reward: 0.592 [0.506, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.997, 10.223], loss: 0.001484, mae: 0.042347, mean_q: 1.173511
  29400/1000000: episode: 294, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 58.162, mean reward: 0.582 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.044, 10.098], loss: 0.001629, mae: 0.044202, mean_q: 1.170925
  29500/1000000: episode: 295, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.320, mean reward: 0.583 [0.503, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.458, 10.113], loss: 0.001539, mae: 0.043031, mean_q: 1.171828
  29600/1000000: episode: 296, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.497, mean reward: 0.595 [0.505, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.541, 10.196], loss: 0.001516, mae: 0.042696, mean_q: 1.171203
  29700/1000000: episode: 297, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.757, mean reward: 0.578 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.552, 10.253], loss: 0.001604, mae: 0.044008, mean_q: 1.170364
  29800/1000000: episode: 298, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.001, mean reward: 0.580 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.785, 10.234], loss: 0.001368, mae: 0.040991, mean_q: 1.173040
  29900/1000000: episode: 299, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.079, mean reward: 0.581 [0.510, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.844, 10.245], loss: 0.001507, mae: 0.042246, mean_q: 1.169027
  30000/1000000: episode: 300, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.980, mean reward: 0.580 [0.503, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.702, 10.098], loss: 0.001434, mae: 0.041650, mean_q: 1.167639
  30100/1000000: episode: 301, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.697, mean reward: 0.587 [0.517, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.195, 10.184], loss: 0.001431, mae: 0.041356, mean_q: 1.169247
  30200/1000000: episode: 302, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: 61.074, mean reward: 0.611 [0.500, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.410 [-0.921, 10.098], loss: 0.001438, mae: 0.041589, mean_q: 1.164503
  30300/1000000: episode: 303, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 62.030, mean reward: 0.620 [0.499, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.783, 10.485], loss: 0.001396, mae: 0.041484, mean_q: 1.166630
  30400/1000000: episode: 304, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.396, mean reward: 0.594 [0.505, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.513, 10.122], loss: 0.001469, mae: 0.042425, mean_q: 1.169911
  30500/1000000: episode: 305, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 57.682, mean reward: 0.577 [0.505, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.826, 10.128], loss: 0.001476, mae: 0.042001, mean_q: 1.166632
  30600/1000000: episode: 306, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.742, mean reward: 0.587 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.610, 10.098], loss: 0.001355, mae: 0.040250, mean_q: 1.167054
  30700/1000000: episode: 307, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.811, mean reward: 0.578 [0.504, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.781, 10.098], loss: 0.001556, mae: 0.043085, mean_q: 1.167652
  30800/1000000: episode: 308, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 57.837, mean reward: 0.578 [0.508, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.904, 10.098], loss: 0.001384, mae: 0.040998, mean_q: 1.166295
  30900/1000000: episode: 309, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.073, mean reward: 0.601 [0.507, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.741, 10.120], loss: 0.001405, mae: 0.041043, mean_q: 1.164741
  31000/1000000: episode: 310, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.068, mean reward: 0.591 [0.506, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.346, 10.249], loss: 0.001543, mae: 0.042551, mean_q: 1.167314
  31100/1000000: episode: 311, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.551, mean reward: 0.586 [0.505, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.872, 10.155], loss: 0.001483, mae: 0.042192, mean_q: 1.169869
  31200/1000000: episode: 312, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.457, mean reward: 0.585 [0.505, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.327, 10.098], loss: 0.001277, mae: 0.039177, mean_q: 1.162343
  31300/1000000: episode: 313, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.103, mean reward: 0.581 [0.505, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.659, 10.098], loss: 0.001402, mae: 0.040854, mean_q: 1.166782
  31400/1000000: episode: 314, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 62.594, mean reward: 0.626 [0.502, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.637, 10.408], loss: 0.001459, mae: 0.042206, mean_q: 1.162348
  31500/1000000: episode: 315, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 60.410, mean reward: 0.604 [0.501, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.440, 10.308], loss: 0.001313, mae: 0.039678, mean_q: 1.163350
  31600/1000000: episode: 316, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.502, mean reward: 0.595 [0.507, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.692, 10.098], loss: 0.001466, mae: 0.041950, mean_q: 1.165951
  31700/1000000: episode: 317, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 59.282, mean reward: 0.593 [0.515, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.564, 10.289], loss: 0.001417, mae: 0.040954, mean_q: 1.164087
  31800/1000000: episode: 318, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.055, mean reward: 0.581 [0.511, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.370, 10.232], loss: 0.001451, mae: 0.041731, mean_q: 1.168559
  31900/1000000: episode: 319, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.137, mean reward: 0.581 [0.505, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.802, 10.173], loss: 0.001526, mae: 0.042955, mean_q: 1.166100
  32000/1000000: episode: 320, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.467, mean reward: 0.585 [0.500, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.486, 10.098], loss: 0.001369, mae: 0.040524, mean_q: 1.167670
  32100/1000000: episode: 321, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 56.864, mean reward: 0.569 [0.506, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.010, 10.106], loss: 0.001481, mae: 0.042006, mean_q: 1.165527
  32200/1000000: episode: 322, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.301, mean reward: 0.593 [0.499, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.204, 10.391], loss: 0.001458, mae: 0.042229, mean_q: 1.163288
  32300/1000000: episode: 323, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.808, mean reward: 0.578 [0.506, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.523, 10.166], loss: 0.001375, mae: 0.040850, mean_q: 1.162693
  32400/1000000: episode: 324, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.577, mean reward: 0.586 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.396, 10.098], loss: 0.001568, mae: 0.043623, mean_q: 1.164510
  32500/1000000: episode: 325, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.984, mean reward: 0.590 [0.509, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.348, 10.219], loss: 0.001437, mae: 0.041564, mean_q: 1.166424
  32600/1000000: episode: 326, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 56.765, mean reward: 0.568 [0.505, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.091, 10.337], loss: 0.001393, mae: 0.041187, mean_q: 1.166112
  32700/1000000: episode: 327, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.393, mean reward: 0.574 [0.506, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.559, 10.098], loss: 0.001367, mae: 0.040745, mean_q: 1.163004
  32800/1000000: episode: 328, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 63.540, mean reward: 0.635 [0.498, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.890, 10.384], loss: 0.001573, mae: 0.043442, mean_q: 1.164993
  32900/1000000: episode: 329, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.280, mean reward: 0.603 [0.507, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.773, 10.098], loss: 0.001534, mae: 0.043398, mean_q: 1.164027
  33000/1000000: episode: 330, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.209, mean reward: 0.592 [0.513, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.566, 10.267], loss: 0.001541, mae: 0.042699, mean_q: 1.165066
  33100/1000000: episode: 331, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.766, mean reward: 0.568 [0.501, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.320, 10.185], loss: 0.001437, mae: 0.041267, mean_q: 1.165044
  33200/1000000: episode: 332, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.876, mean reward: 0.579 [0.502, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.692, 10.276], loss: 0.001451, mae: 0.041709, mean_q: 1.167718
  33300/1000000: episode: 333, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 58.299, mean reward: 0.583 [0.501, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.350, 10.098], loss: 0.001368, mae: 0.040900, mean_q: 1.167624
  33400/1000000: episode: 334, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.027, mean reward: 0.610 [0.515, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.864, 10.334], loss: 0.001405, mae: 0.041558, mean_q: 1.168349
  33500/1000000: episode: 335, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 60.133, mean reward: 0.601 [0.509, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.764, 10.098], loss: 0.001551, mae: 0.043417, mean_q: 1.169388
  33600/1000000: episode: 336, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.902, mean reward: 0.579 [0.504, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.201, 10.283], loss: 0.001580, mae: 0.043754, mean_q: 1.166027
  33700/1000000: episode: 337, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.242, mean reward: 0.592 [0.504, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.506, 10.205], loss: 0.001489, mae: 0.042196, mean_q: 1.163584
  33800/1000000: episode: 338, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.677, mean reward: 0.577 [0.507, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.467, 10.152], loss: 0.001456, mae: 0.041716, mean_q: 1.164885
  33900/1000000: episode: 339, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.838, mean reward: 0.578 [0.500, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.788, 10.098], loss: 0.001695, mae: 0.045024, mean_q: 1.164138
  34000/1000000: episode: 340, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.192, mean reward: 0.582 [0.508, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.891, 10.098], loss: 0.001468, mae: 0.042336, mean_q: 1.164496
  34100/1000000: episode: 341, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 61.556, mean reward: 0.616 [0.500, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.597, 10.098], loss: 0.001398, mae: 0.041474, mean_q: 1.164647
  34200/1000000: episode: 342, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 59.362, mean reward: 0.594 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.438, 10.336], loss: 0.001510, mae: 0.042198, mean_q: 1.164773
  34300/1000000: episode: 343, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.692, mean reward: 0.577 [0.504, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.896, 10.177], loss: 0.001523, mae: 0.042533, mean_q: 1.166980
  34400/1000000: episode: 344, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.527, mean reward: 0.575 [0.505, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.988, 10.119], loss: 0.001453, mae: 0.041457, mean_q: 1.161978
  34500/1000000: episode: 345, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.940, mean reward: 0.579 [0.502, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.122, 10.192], loss: 0.001380, mae: 0.040425, mean_q: 1.161670
  34600/1000000: episode: 346, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 56.518, mean reward: 0.565 [0.510, 0.662], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.765, 10.193], loss: 0.001423, mae: 0.041665, mean_q: 1.165973
  34700/1000000: episode: 347, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.313, mean reward: 0.593 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.747, 10.330], loss: 0.001420, mae: 0.041445, mean_q: 1.163809
  34800/1000000: episode: 348, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 62.564, mean reward: 0.626 [0.510, 0.865], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-0.959, 10.098], loss: 0.001476, mae: 0.041969, mean_q: 1.163884
  34900/1000000: episode: 349, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.595, mean reward: 0.586 [0.506, 0.858], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.901, 10.130], loss: 0.001595, mae: 0.043531, mean_q: 1.160787
  35000/1000000: episode: 350, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.962, mean reward: 0.580 [0.504, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.354, 10.098], loss: 0.001490, mae: 0.041927, mean_q: 1.158444
  35100/1000000: episode: 351, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: 58.785, mean reward: 0.588 [0.500, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.107, 10.223], loss: 0.001462, mae: 0.041958, mean_q: 1.162533
  35200/1000000: episode: 352, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 56.823, mean reward: 0.568 [0.504, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.177, 10.204], loss: 0.001491, mae: 0.042016, mean_q: 1.160942
  35300/1000000: episode: 353, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.851, mean reward: 0.579 [0.507, 0.654], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.870, 10.098], loss: 0.001445, mae: 0.041663, mean_q: 1.163603
  35400/1000000: episode: 354, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.610, mean reward: 0.586 [0.510, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.580, 10.098], loss: 0.001381, mae: 0.040667, mean_q: 1.161957
  35500/1000000: episode: 355, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.502, mean reward: 0.585 [0.511, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.021, 10.098], loss: 0.001448, mae: 0.041577, mean_q: 1.160490
  35600/1000000: episode: 356, duration: 0.520s, episode steps: 100, steps per second: 192, episode reward: 59.645, mean reward: 0.596 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.809, 10.197], loss: 0.001440, mae: 0.041594, mean_q: 1.158756
  35700/1000000: episode: 357, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.636, mean reward: 0.586 [0.499, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.440, 10.207], loss: 0.001345, mae: 0.040375, mean_q: 1.162684
  35800/1000000: episode: 358, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.009, mean reward: 0.580 [0.512, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.666, 10.160], loss: 0.001461, mae: 0.041906, mean_q: 1.162020
  35900/1000000: episode: 359, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.666, mean reward: 0.577 [0.503, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.298, 10.098], loss: 0.001368, mae: 0.040297, mean_q: 1.156800
  36000/1000000: episode: 360, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.180, mean reward: 0.592 [0.513, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.746, 10.098], loss: 0.001395, mae: 0.040981, mean_q: 1.160333
  36100/1000000: episode: 361, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.875, mean reward: 0.589 [0.508, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.268, 10.171], loss: 0.001385, mae: 0.040843, mean_q: 1.165350
  36200/1000000: episode: 362, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.815, mean reward: 0.588 [0.501, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.736, 10.098], loss: 0.001436, mae: 0.041585, mean_q: 1.164315
  36300/1000000: episode: 363, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.973, mean reward: 0.600 [0.511, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.741, 10.328], loss: 0.001428, mae: 0.041217, mean_q: 1.161142
  36400/1000000: episode: 364, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.916, mean reward: 0.579 [0.498, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.757, 10.098], loss: 0.001361, mae: 0.040470, mean_q: 1.159876
  36500/1000000: episode: 365, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.295, mean reward: 0.583 [0.502, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.358, 10.264], loss: 0.001364, mae: 0.040702, mean_q: 1.160263
  36600/1000000: episode: 366, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.991, mean reward: 0.590 [0.499, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.186, 10.098], loss: 0.001349, mae: 0.040583, mean_q: 1.157626
  36700/1000000: episode: 367, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.702, mean reward: 0.617 [0.505, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.495, 10.551], loss: 0.001419, mae: 0.041470, mean_q: 1.159000
  36800/1000000: episode: 368, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.191, mean reward: 0.592 [0.502, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.423, 10.409], loss: 0.001279, mae: 0.039534, mean_q: 1.156073
  36900/1000000: episode: 369, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 56.806, mean reward: 0.568 [0.505, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.318, 10.137], loss: 0.001443, mae: 0.041271, mean_q: 1.157817
  37000/1000000: episode: 370, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.352, mean reward: 0.594 [0.517, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.478, 10.098], loss: 0.001352, mae: 0.040561, mean_q: 1.159804
  37100/1000000: episode: 371, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.887, mean reward: 0.579 [0.503, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-2.085, 10.311], loss: 0.001399, mae: 0.040918, mean_q: 1.159828
  37200/1000000: episode: 372, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.636, mean reward: 0.596 [0.518, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.693, 10.339], loss: 0.001295, mae: 0.039877, mean_q: 1.161025
  37300/1000000: episode: 373, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.005, mean reward: 0.600 [0.508, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.599, 10.098], loss: 0.001388, mae: 0.040818, mean_q: 1.162263
  37400/1000000: episode: 374, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.898, mean reward: 0.569 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.551, 10.178], loss: 0.001279, mae: 0.039820, mean_q: 1.160477
  37500/1000000: episode: 375, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.221, mean reward: 0.602 [0.511, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.194, 10.223], loss: 0.001349, mae: 0.040414, mean_q: 1.160608
  37600/1000000: episode: 376, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.653, mean reward: 0.597 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.700, 10.265], loss: 0.001449, mae: 0.041947, mean_q: 1.161891
  37700/1000000: episode: 377, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 62.174, mean reward: 0.622 [0.502, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.385, 10.418], loss: 0.001332, mae: 0.039850, mean_q: 1.165456
  37800/1000000: episode: 378, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 58.570, mean reward: 0.586 [0.503, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.293, 10.098], loss: 0.001385, mae: 0.041006, mean_q: 1.165176
  37900/1000000: episode: 379, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.793, mean reward: 0.588 [0.514, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.114, 10.098], loss: 0.001295, mae: 0.039664, mean_q: 1.164635
  38000/1000000: episode: 380, duration: 0.525s, episode steps: 100, steps per second: 190, episode reward: 59.940, mean reward: 0.599 [0.508, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.320, 10.124], loss: 0.001302, mae: 0.039723, mean_q: 1.163459
  38100/1000000: episode: 381, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.605, mean reward: 0.596 [0.508, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.396, 10.098], loss: 0.001416, mae: 0.041101, mean_q: 1.164284
  38200/1000000: episode: 382, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.507, mean reward: 0.605 [0.517, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.118, 10.098], loss: 0.001405, mae: 0.041554, mean_q: 1.162925
  38300/1000000: episode: 383, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.333, mean reward: 0.583 [0.509, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.634, 10.188], loss: 0.001378, mae: 0.040579, mean_q: 1.164426
  38400/1000000: episode: 384, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.088, mean reward: 0.591 [0.516, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.674, 10.098], loss: 0.001287, mae: 0.039866, mean_q: 1.162795
  38500/1000000: episode: 385, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.978, mean reward: 0.600 [0.499, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.551, 10.433], loss: 0.001317, mae: 0.040432, mean_q: 1.163947
  38600/1000000: episode: 386, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 56.951, mean reward: 0.570 [0.504, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.172, 10.098], loss: 0.001361, mae: 0.041213, mean_q: 1.164846
  38700/1000000: episode: 387, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 59.414, mean reward: 0.594 [0.503, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.185, 10.098], loss: 0.001329, mae: 0.040516, mean_q: 1.166096
  38800/1000000: episode: 388, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.830, mean reward: 0.598 [0.512, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.422, 10.098], loss: 0.001240, mae: 0.038720, mean_q: 1.163546
  38900/1000000: episode: 389, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 58.796, mean reward: 0.588 [0.501, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.907, 10.098], loss: 0.001293, mae: 0.039923, mean_q: 1.163031
  39000/1000000: episode: 390, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.449, mean reward: 0.574 [0.505, 0.939], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.137, 10.098], loss: 0.001371, mae: 0.040793, mean_q: 1.166748
  39100/1000000: episode: 391, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.933, mean reward: 0.579 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.032, 10.138], loss: 0.001417, mae: 0.041217, mean_q: 1.161765
  39200/1000000: episode: 392, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.006, mean reward: 0.580 [0.504, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.117, 10.098], loss: 0.001511, mae: 0.042501, mean_q: 1.162692
  39300/1000000: episode: 393, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.807, mean reward: 0.588 [0.505, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.983, 10.356], loss: 0.001295, mae: 0.039813, mean_q: 1.165637
  39400/1000000: episode: 394, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.982, mean reward: 0.600 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.972, 10.273], loss: 0.001418, mae: 0.040813, mean_q: 1.166509
  39500/1000000: episode: 395, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.937, mean reward: 0.579 [0.501, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.982, 10.132], loss: 0.001386, mae: 0.041088, mean_q: 1.166175
  39600/1000000: episode: 396, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.301, mean reward: 0.573 [0.500, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.695, 10.114], loss: 0.001334, mae: 0.040220, mean_q: 1.165791
  39700/1000000: episode: 397, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 61.589, mean reward: 0.616 [0.509, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.491, 10.219], loss: 0.001332, mae: 0.039345, mean_q: 1.164683
  39800/1000000: episode: 398, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.199, mean reward: 0.592 [0.504, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.494, 10.358], loss: 0.001346, mae: 0.040088, mean_q: 1.164368
  39900/1000000: episode: 399, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.026, mean reward: 0.600 [0.509, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.704, 10.098], loss: 0.001309, mae: 0.039967, mean_q: 1.165580
  40000/1000000: episode: 400, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.692, mean reward: 0.577 [0.500, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.935, 10.123], loss: 0.001429, mae: 0.041693, mean_q: 1.167654
  40100/1000000: episode: 401, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.318, mean reward: 0.573 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.851, 10.098], loss: 0.001408, mae: 0.041529, mean_q: 1.162830
  40200/1000000: episode: 402, duration: 0.706s, episode steps: 100, steps per second: 142, episode reward: 65.195, mean reward: 0.652 [0.517, 0.889], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.889, 10.098], loss: 0.001460, mae: 0.041472, mean_q: 1.167535
  40300/1000000: episode: 403, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.011, mean reward: 0.580 [0.508, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.788, 10.427], loss: 0.001381, mae: 0.040406, mean_q: 1.167244
  40400/1000000: episode: 404, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.312, mean reward: 0.583 [0.500, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.687, 10.098], loss: 0.001374, mae: 0.040952, mean_q: 1.169279
  40500/1000000: episode: 405, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.000, mean reward: 0.590 [0.500, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.508, 10.222], loss: 0.001428, mae: 0.041514, mean_q: 1.168203
  40600/1000000: episode: 406, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.168, mean reward: 0.582 [0.504, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.947, 10.225], loss: 0.001473, mae: 0.042385, mean_q: 1.171270
  40700/1000000: episode: 407, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.710, mean reward: 0.587 [0.506, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.297, 10.252], loss: 0.001410, mae: 0.041998, mean_q: 1.166962
  40800/1000000: episode: 408, duration: 0.525s, episode steps: 100, steps per second: 191, episode reward: 57.812, mean reward: 0.578 [0.503, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.384, 10.098], loss: 0.001431, mae: 0.041496, mean_q: 1.167321
  40900/1000000: episode: 409, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.501, mean reward: 0.595 [0.500, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.645, 10.235], loss: 0.001392, mae: 0.041137, mean_q: 1.169155
  41000/1000000: episode: 410, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.574, mean reward: 0.596 [0.505, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.679, 10.098], loss: 0.001520, mae: 0.042439, mean_q: 1.166123
  41100/1000000: episode: 411, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.402, mean reward: 0.604 [0.498, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.439, 10.098], loss: 0.001425, mae: 0.041593, mean_q: 1.168005
  41200/1000000: episode: 412, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.452, mean reward: 0.575 [0.500, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.558, 10.205], loss: 0.001451, mae: 0.041464, mean_q: 1.168361
  41300/1000000: episode: 413, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.967, mean reward: 0.590 [0.508, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.083, 10.275], loss: 0.001499, mae: 0.042622, mean_q: 1.165330
  41400/1000000: episode: 414, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.120, mean reward: 0.601 [0.504, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.505, 10.202], loss: 0.001507, mae: 0.042650, mean_q: 1.168281
  41500/1000000: episode: 415, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.187, mean reward: 0.582 [0.499, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.530, 10.098], loss: 0.001351, mae: 0.040357, mean_q: 1.168039
  41600/1000000: episode: 416, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.549, mean reward: 0.565 [0.507, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.056, 10.098], loss: 0.001675, mae: 0.044242, mean_q: 1.168298
  41700/1000000: episode: 417, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.101, mean reward: 0.601 [0.507, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.927, 10.098], loss: 0.001468, mae: 0.042054, mean_q: 1.166389
  41800/1000000: episode: 418, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.015, mean reward: 0.570 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.014, 10.158], loss: 0.001448, mae: 0.041888, mean_q: 1.165372
  41900/1000000: episode: 419, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.732, mean reward: 0.587 [0.511, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.198, 10.174], loss: 0.001399, mae: 0.041570, mean_q: 1.163787
  42000/1000000: episode: 420, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.196, mean reward: 0.592 [0.513, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.586, 10.098], loss: 0.001444, mae: 0.041665, mean_q: 1.164860
  42100/1000000: episode: 421, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.968, mean reward: 0.580 [0.500, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.384, 10.098], loss: 0.001483, mae: 0.042536, mean_q: 1.166056
  42200/1000000: episode: 422, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.043, mean reward: 0.600 [0.497, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.215, 10.325], loss: 0.001415, mae: 0.041621, mean_q: 1.167054
  42300/1000000: episode: 423, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.906, mean reward: 0.599 [0.519, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.280, 10.098], loss: 0.001367, mae: 0.041498, mean_q: 1.164546
  42400/1000000: episode: 424, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.415, mean reward: 0.584 [0.506, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.524, 10.098], loss: 0.001492, mae: 0.042152, mean_q: 1.165220
  42500/1000000: episode: 425, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.416, mean reward: 0.594 [0.498, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.855, 10.098], loss: 0.001399, mae: 0.041523, mean_q: 1.165727
  42600/1000000: episode: 426, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.879, mean reward: 0.569 [0.502, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.483, 10.098], loss: 0.001431, mae: 0.041379, mean_q: 1.168045
  42700/1000000: episode: 427, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 62.049, mean reward: 0.620 [0.501, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.450, 10.098], loss: 0.001617, mae: 0.044083, mean_q: 1.162163
  42800/1000000: episode: 428, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.656, mean reward: 0.587 [0.509, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.113, 10.101], loss: 0.001407, mae: 0.040785, mean_q: 1.160746
  42900/1000000: episode: 429, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.429, mean reward: 0.584 [0.508, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.971, 10.131], loss: 0.001457, mae: 0.041746, mean_q: 1.163363
  43000/1000000: episode: 430, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.015, mean reward: 0.590 [0.505, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.041, 10.098], loss: 0.001456, mae: 0.042387, mean_q: 1.163328
  43100/1000000: episode: 431, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 66.462, mean reward: 0.665 [0.520, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.473, 10.098], loss: 0.001629, mae: 0.043570, mean_q: 1.161094
  43200/1000000: episode: 432, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.172, mean reward: 0.572 [0.500, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.094, 10.309], loss: 0.001299, mae: 0.040329, mean_q: 1.164813
  43300/1000000: episode: 433, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.695, mean reward: 0.587 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.294, 10.098], loss: 0.001357, mae: 0.040399, mean_q: 1.165915
  43400/1000000: episode: 434, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.881, mean reward: 0.609 [0.502, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.334, 10.175], loss: 0.001407, mae: 0.041110, mean_q: 1.165342
  43500/1000000: episode: 435, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.217, mean reward: 0.592 [0.500, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.428, 10.098], loss: 0.001466, mae: 0.041933, mean_q: 1.172565
  43600/1000000: episode: 436, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.047, mean reward: 0.570 [0.500, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.577, 10.098], loss: 0.001453, mae: 0.042022, mean_q: 1.169984
  43700/1000000: episode: 437, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.099, mean reward: 0.591 [0.515, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.128, 10.098], loss: 0.001508, mae: 0.042411, mean_q: 1.163545
  43800/1000000: episode: 438, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.454, mean reward: 0.595 [0.500, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.757, 10.413], loss: 0.001419, mae: 0.041273, mean_q: 1.168435
  43900/1000000: episode: 439, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.511, mean reward: 0.575 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.274, 10.098], loss: 0.001396, mae: 0.041024, mean_q: 1.167148
  44000/1000000: episode: 440, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.739, mean reward: 0.567 [0.503, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.620, 10.106], loss: 0.001342, mae: 0.040308, mean_q: 1.164810
  44100/1000000: episode: 441, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.752, mean reward: 0.588 [0.501, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.052, 10.240], loss: 0.001380, mae: 0.040813, mean_q: 1.165004
  44200/1000000: episode: 442, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 61.076, mean reward: 0.611 [0.513, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.644, 10.098], loss: 0.001433, mae: 0.041227, mean_q: 1.167336
  44300/1000000: episode: 443, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.051, mean reward: 0.571 [0.502, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.369, 10.280], loss: 0.001590, mae: 0.043283, mean_q: 1.168068
  44400/1000000: episode: 444, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.853, mean reward: 0.589 [0.515, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.155, 10.212], loss: 0.001456, mae: 0.042219, mean_q: 1.162021
  44500/1000000: episode: 445, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.481, mean reward: 0.585 [0.502, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.451, 10.121], loss: 0.001408, mae: 0.041083, mean_q: 1.166534
  44600/1000000: episode: 446, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.124, mean reward: 0.591 [0.511, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.679, 10.098], loss: 0.001448, mae: 0.041743, mean_q: 1.168539
  44700/1000000: episode: 447, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.696, mean reward: 0.607 [0.510, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.091, 10.098], loss: 0.001472, mae: 0.042030, mean_q: 1.168669
  44800/1000000: episode: 448, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.460, mean reward: 0.595 [0.505, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.434, 10.288], loss: 0.001428, mae: 0.041173, mean_q: 1.167333
  44900/1000000: episode: 449, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.450, mean reward: 0.585 [0.499, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.625, 10.098], loss: 0.001331, mae: 0.039943, mean_q: 1.169852
  45000/1000000: episode: 450, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.252, mean reward: 0.603 [0.505, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.578, 10.420], loss: 0.001447, mae: 0.041298, mean_q: 1.168086
  45100/1000000: episode: 451, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.488, mean reward: 0.585 [0.508, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.353, 10.239], loss: 0.001414, mae: 0.041215, mean_q: 1.167430
  45200/1000000: episode: 452, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.080, mean reward: 0.561 [0.501, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.229, 10.128], loss: 0.001478, mae: 0.041630, mean_q: 1.166676
  45300/1000000: episode: 453, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.451, mean reward: 0.585 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.730, 10.296], loss: 0.001347, mae: 0.040377, mean_q: 1.163792
  45400/1000000: episode: 454, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.796, mean reward: 0.588 [0.506, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.401, 10.098], loss: 0.001448, mae: 0.041777, mean_q: 1.163783
  45500/1000000: episode: 455, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.917, mean reward: 0.569 [0.500, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.665, 10.259], loss: 0.001418, mae: 0.041565, mean_q: 1.165496
  45600/1000000: episode: 456, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 58.115, mean reward: 0.581 [0.499, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-2.071, 10.098], loss: 0.001338, mae: 0.040439, mean_q: 1.164115
  45700/1000000: episode: 457, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.642, mean reward: 0.586 [0.502, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.425, 10.293], loss: 0.001444, mae: 0.041374, mean_q: 1.164738
  45800/1000000: episode: 458, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.377, mean reward: 0.574 [0.498, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-1.210, 10.098], loss: 0.001414, mae: 0.041295, mean_q: 1.164283
  45900/1000000: episode: 459, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.063, mean reward: 0.571 [0.501, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.905, 10.213], loss: 0.001426, mae: 0.041807, mean_q: 1.166047
  46000/1000000: episode: 460, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.750, mean reward: 0.597 [0.512, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.534, 10.192], loss: 0.001428, mae: 0.041457, mean_q: 1.161707
  46100/1000000: episode: 461, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.308, mean reward: 0.593 [0.513, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.233, 10.334], loss: 0.001381, mae: 0.041014, mean_q: 1.162106
  46200/1000000: episode: 462, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.170, mean reward: 0.592 [0.512, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.739, 10.182], loss: 0.001360, mae: 0.040352, mean_q: 1.162059
  46300/1000000: episode: 463, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 64.141, mean reward: 0.641 [0.522, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.018, 10.098], loss: 0.001409, mae: 0.041137, mean_q: 1.163000
  46400/1000000: episode: 464, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.930, mean reward: 0.579 [0.500, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.053, 10.098], loss: 0.001463, mae: 0.042070, mean_q: 1.164502
  46500/1000000: episode: 465, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.325, mean reward: 0.583 [0.509, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.440, 10.098], loss: 0.001277, mae: 0.039105, mean_q: 1.164405
  46600/1000000: episode: 466, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.349, mean reward: 0.603 [0.507, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.990, 10.160], loss: 0.001388, mae: 0.040556, mean_q: 1.167073
  46700/1000000: episode: 467, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.164, mean reward: 0.582 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.478, 10.340], loss: 0.001364, mae: 0.040213, mean_q: 1.163893
  46800/1000000: episode: 468, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 60.470, mean reward: 0.605 [0.511, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.160, 10.249], loss: 0.001422, mae: 0.041289, mean_q: 1.169981
  46900/1000000: episode: 469, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.896, mean reward: 0.589 [0.513, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.419, 10.161], loss: 0.001309, mae: 0.040045, mean_q: 1.166434
  47000/1000000: episode: 470, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.539, mean reward: 0.605 [0.517, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.846, 10.298], loss: 0.001410, mae: 0.041274, mean_q: 1.162403
  47100/1000000: episode: 471, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 64.745, mean reward: 0.647 [0.505, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.096, 10.098], loss: 0.001353, mae: 0.040509, mean_q: 1.168846
  47200/1000000: episode: 472, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.107, mean reward: 0.601 [0.500, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.440, 10.450], loss: 0.001507, mae: 0.041789, mean_q: 1.167887
  47300/1000000: episode: 473, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.083, mean reward: 0.601 [0.507, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.309, 10.098], loss: 0.001462, mae: 0.042001, mean_q: 1.168429
  47400/1000000: episode: 474, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.919, mean reward: 0.599 [0.510, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.996, 10.098], loss: 0.001448, mae: 0.041388, mean_q: 1.168891
  47500/1000000: episode: 475, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.568, mean reward: 0.576 [0.509, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.515, 10.098], loss: 0.001271, mae: 0.039394, mean_q: 1.170294
  47600/1000000: episode: 476, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 61.315, mean reward: 0.613 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.687, 10.098], loss: 0.001447, mae: 0.041718, mean_q: 1.170807
  47700/1000000: episode: 477, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.733, mean reward: 0.577 [0.501, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.034, 10.098], loss: 0.001332, mae: 0.040049, mean_q: 1.170478
  47800/1000000: episode: 478, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.750, mean reward: 0.607 [0.498, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.299, 10.133], loss: 0.001318, mae: 0.040639, mean_q: 1.170305
  47900/1000000: episode: 479, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.350, mean reward: 0.583 [0.502, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.287, 10.301], loss: 0.001571, mae: 0.043041, mean_q: 1.173471
  48000/1000000: episode: 480, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.559, mean reward: 0.606 [0.506, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.703, 10.252], loss: 0.001354, mae: 0.040357, mean_q: 1.168814
  48100/1000000: episode: 481, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.000, mean reward: 0.570 [0.507, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.338, 10.124], loss: 0.001412, mae: 0.041895, mean_q: 1.170278
  48200/1000000: episode: 482, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 56.930, mean reward: 0.569 [0.509, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.576, 10.124], loss: 0.001325, mae: 0.040063, mean_q: 1.166229
  48300/1000000: episode: 483, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 64.349, mean reward: 0.643 [0.513, 0.940], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.793, 10.360], loss: 0.001345, mae: 0.040389, mean_q: 1.168956
  48400/1000000: episode: 484, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.306, mean reward: 0.593 [0.514, 0.874], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.569, 10.098], loss: 0.001593, mae: 0.043767, mean_q: 1.174234
  48500/1000000: episode: 485, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.085, mean reward: 0.581 [0.506, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.862, 10.139], loss: 0.001336, mae: 0.040367, mean_q: 1.169655
  48600/1000000: episode: 486, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 61.813, mean reward: 0.618 [0.509, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.411 [-1.019, 10.098], loss: 0.001459, mae: 0.042152, mean_q: 1.173295
  48700/1000000: episode: 487, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.706, mean reward: 0.607 [0.510, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.672, 10.098], loss: 0.001383, mae: 0.040993, mean_q: 1.168788
  48800/1000000: episode: 488, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.902, mean reward: 0.589 [0.516, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.780, 10.439], loss: 0.001383, mae: 0.040875, mean_q: 1.170028
  48900/1000000: episode: 489, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.379, mean reward: 0.604 [0.506, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.359, 10.174], loss: 0.001385, mae: 0.040684, mean_q: 1.167627
  49000/1000000: episode: 490, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.665, mean reward: 0.607 [0.514, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.889, 10.196], loss: 0.001418, mae: 0.041263, mean_q: 1.172485
  49100/1000000: episode: 491, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.796, mean reward: 0.568 [0.498, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.893, 10.222], loss: 0.001503, mae: 0.042038, mean_q: 1.173362
  49200/1000000: episode: 492, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.675, mean reward: 0.587 [0.503, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.745, 10.103], loss: 0.001603, mae: 0.043704, mean_q: 1.174402
  49300/1000000: episode: 493, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.368, mean reward: 0.594 [0.504, 0.669], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.696, 10.255], loss: 0.001417, mae: 0.041302, mean_q: 1.171353
  49400/1000000: episode: 494, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.467, mean reward: 0.585 [0.508, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.918, 10.275], loss: 0.001327, mae: 0.040076, mean_q: 1.171403
  49500/1000000: episode: 495, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.641, mean reward: 0.586 [0.504, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.703, 10.169], loss: 0.001402, mae: 0.040994, mean_q: 1.171254
  49600/1000000: episode: 496, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.590, mean reward: 0.606 [0.505, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.425, 10.445], loss: 0.001474, mae: 0.042186, mean_q: 1.170287
  49700/1000000: episode: 497, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.271, mean reward: 0.603 [0.510, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.097, 10.210], loss: 0.001435, mae: 0.041760, mean_q: 1.168334
  49800/1000000: episode: 498, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.419, mean reward: 0.574 [0.504, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.786, 10.112], loss: 0.001449, mae: 0.041772, mean_q: 1.173797
  49900/1000000: episode: 499, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.430, mean reward: 0.574 [0.505, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.192, 10.162], loss: 0.001360, mae: 0.040462, mean_q: 1.168738
  50000/1000000: episode: 500, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 58.734, mean reward: 0.587 [0.508, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.122, 10.244], loss: 0.001343, mae: 0.040333, mean_q: 1.171474
  50100/1000000: episode: 501, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.165, mean reward: 0.602 [0.512, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.310, 10.098], loss: 0.001415, mae: 0.041581, mean_q: 1.170340
  50200/1000000: episode: 502, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.195, mean reward: 0.572 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.453, 10.098], loss: 0.001391, mae: 0.040969, mean_q: 1.173198
  50300/1000000: episode: 503, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.427, mean reward: 0.584 [0.505, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.985, 10.182], loss: 0.001434, mae: 0.041588, mean_q: 1.175363
  50400/1000000: episode: 504, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.255, mean reward: 0.573 [0.504, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.410, 10.147], loss: 0.001398, mae: 0.040876, mean_q: 1.171179
  50500/1000000: episode: 505, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 61.694, mean reward: 0.617 [0.509, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-1.017, 10.571], loss: 0.001408, mae: 0.041036, mean_q: 1.172138
  50600/1000000: episode: 506, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.504, mean reward: 0.595 [0.510, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.265, 10.284], loss: 0.001464, mae: 0.041756, mean_q: 1.171597
  50700/1000000: episode: 507, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.154, mean reward: 0.592 [0.499, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.451, 10.196], loss: 0.001418, mae: 0.040953, mean_q: 1.174709
  50800/1000000: episode: 508, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.767, mean reward: 0.578 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.747, 10.098], loss: 0.001431, mae: 0.041574, mean_q: 1.174527
  50900/1000000: episode: 509, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 63.871, mean reward: 0.639 [0.503, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.424, 10.292], loss: 0.001409, mae: 0.040884, mean_q: 1.172683
  51000/1000000: episode: 510, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.816, mean reward: 0.578 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.310, 10.291], loss: 0.001558, mae: 0.043208, mean_q: 1.179875
  51100/1000000: episode: 511, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.595, mean reward: 0.596 [0.513, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.560, 10.218], loss: 0.001504, mae: 0.042208, mean_q: 1.177686
  51200/1000000: episode: 512, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 62.493, mean reward: 0.625 [0.530, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.646, 10.276], loss: 0.001445, mae: 0.042087, mean_q: 1.178262
  51300/1000000: episode: 513, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 61.819, mean reward: 0.618 [0.512, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.969, 10.098], loss: 0.001506, mae: 0.042609, mean_q: 1.177653
  51400/1000000: episode: 514, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.814, mean reward: 0.588 [0.502, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.110, 10.252], loss: 0.001523, mae: 0.042849, mean_q: 1.174980
  51500/1000000: episode: 515, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.662, mean reward: 0.607 [0.509, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.248, 10.098], loss: 0.001546, mae: 0.042476, mean_q: 1.177438
  51600/1000000: episode: 516, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.803, mean reward: 0.588 [0.513, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.835, 10.134], loss: 0.001416, mae: 0.040986, mean_q: 1.175369
  51700/1000000: episode: 517, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.399, mean reward: 0.594 [0.508, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.877, 10.098], loss: 0.001419, mae: 0.040962, mean_q: 1.179236
  51800/1000000: episode: 518, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 65.591, mean reward: 0.656 [0.505, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.196, 10.230], loss: 0.001502, mae: 0.042271, mean_q: 1.182389
  51900/1000000: episode: 519, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.192, mean reward: 0.592 [0.502, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.169, 10.098], loss: 0.001467, mae: 0.041268, mean_q: 1.177474
  52000/1000000: episode: 520, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 60.146, mean reward: 0.601 [0.498, 0.873], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.523, 10.148], loss: 0.001473, mae: 0.041862, mean_q: 1.183492
  52100/1000000: episode: 521, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.536, mean reward: 0.625 [0.531, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.240, 10.214], loss: 0.001687, mae: 0.044316, mean_q: 1.175772
  52200/1000000: episode: 522, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 60.159, mean reward: 0.602 [0.518, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.994, 10.330], loss: 0.001512, mae: 0.042238, mean_q: 1.175706
  52300/1000000: episode: 523, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.345, mean reward: 0.583 [0.514, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-2.025, 10.098], loss: 0.001380, mae: 0.040649, mean_q: 1.177868
  52400/1000000: episode: 524, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.713, mean reward: 0.587 [0.508, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.825, 10.098], loss: 0.001485, mae: 0.041811, mean_q: 1.181246
  52500/1000000: episode: 525, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.992, mean reward: 0.590 [0.511, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.367, 10.365], loss: 0.001552, mae: 0.042641, mean_q: 1.174367
  52600/1000000: episode: 526, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.541, mean reward: 0.595 [0.506, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.617, 10.128], loss: 0.001415, mae: 0.041041, mean_q: 1.179754
  52700/1000000: episode: 527, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.495, mean reward: 0.585 [0.510, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.301, 10.104], loss: 0.001636, mae: 0.043473, mean_q: 1.175911
  52800/1000000: episode: 528, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.036, mean reward: 0.590 [0.499, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.088, 10.099], loss: 0.001491, mae: 0.041836, mean_q: 1.180339
  52900/1000000: episode: 529, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.338, mean reward: 0.593 [0.519, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.400, 10.332], loss: 0.001397, mae: 0.040569, mean_q: 1.178789
  53000/1000000: episode: 530, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.437, mean reward: 0.584 [0.513, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.458, 10.176], loss: 0.001422, mae: 0.041147, mean_q: 1.176323
  53100/1000000: episode: 531, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.783, mean reward: 0.588 [0.518, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.084, 10.098], loss: 0.001565, mae: 0.042909, mean_q: 1.178715
  53200/1000000: episode: 532, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.524, mean reward: 0.575 [0.503, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.634, 10.098], loss: 0.001478, mae: 0.041696, mean_q: 1.178837
  53300/1000000: episode: 533, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 62.676, mean reward: 0.627 [0.511, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.457, 10.343], loss: 0.001530, mae: 0.042216, mean_q: 1.176035
  53400/1000000: episode: 534, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.390, mean reward: 0.584 [0.506, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.890, 10.213], loss: 0.001400, mae: 0.040745, mean_q: 1.177036
  53500/1000000: episode: 535, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.684, mean reward: 0.577 [0.505, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.609, 10.135], loss: 0.001407, mae: 0.040982, mean_q: 1.176843
  53600/1000000: episode: 536, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.230, mean reward: 0.592 [0.506, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.573, 10.129], loss: 0.001472, mae: 0.041688, mean_q: 1.177470
  53700/1000000: episode: 537, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 61.008, mean reward: 0.610 [0.503, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.719, 10.278], loss: 0.001476, mae: 0.041653, mean_q: 1.172858
  53800/1000000: episode: 538, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.891, mean reward: 0.599 [0.499, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.909, 10.098], loss: 0.001415, mae: 0.040908, mean_q: 1.175803
  53900/1000000: episode: 539, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.128, mean reward: 0.601 [0.507, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.492, 10.369], loss: 0.001430, mae: 0.041387, mean_q: 1.173022
  54000/1000000: episode: 540, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.603, mean reward: 0.606 [0.502, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.997, 10.098], loss: 0.001406, mae: 0.040895, mean_q: 1.177591
  54100/1000000: episode: 541, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.575, mean reward: 0.596 [0.508, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.741, 10.098], loss: 0.001462, mae: 0.041890, mean_q: 1.174436
  54200/1000000: episode: 542, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 70.077, mean reward: 0.701 [0.521, 0.962], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.169, 10.098], loss: 0.001488, mae: 0.042223, mean_q: 1.177076
  54300/1000000: episode: 543, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.101, mean reward: 0.581 [0.506, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.146, 10.342], loss: 0.001565, mae: 0.043015, mean_q: 1.182859
  54400/1000000: episode: 544, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.603, mean reward: 0.576 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.574, 10.300], loss: 0.001540, mae: 0.042371, mean_q: 1.181516
  54500/1000000: episode: 545, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.692, mean reward: 0.607 [0.504, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.154, 10.444], loss: 0.001511, mae: 0.042044, mean_q: 1.180619
  54600/1000000: episode: 546, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 61.000, mean reward: 0.610 [0.512, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.293, 10.098], loss: 0.001456, mae: 0.041767, mean_q: 1.184644
  54700/1000000: episode: 547, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.554, mean reward: 0.566 [0.502, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.102, 10.189], loss: 0.001436, mae: 0.041079, mean_q: 1.180170
  54800/1000000: episode: 548, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.641, mean reward: 0.586 [0.515, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.408, 10.191], loss: 0.001431, mae: 0.040894, mean_q: 1.179846
  54900/1000000: episode: 549, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.188, mean reward: 0.592 [0.504, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.607, 10.098], loss: 0.001499, mae: 0.042178, mean_q: 1.183662
  55000/1000000: episode: 550, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.145, mean reward: 0.591 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.310, 10.136], loss: 0.001464, mae: 0.041380, mean_q: 1.182907
  55100/1000000: episode: 551, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.275, mean reward: 0.593 [0.502, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.239, 10.098], loss: 0.001480, mae: 0.041694, mean_q: 1.183424
  55200/1000000: episode: 552, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.036, mean reward: 0.620 [0.512, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.380, 10.499], loss: 0.001524, mae: 0.042006, mean_q: 1.182350
  55300/1000000: episode: 553, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 60.492, mean reward: 0.605 [0.504, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.208, 10.185], loss: 0.001557, mae: 0.042875, mean_q: 1.182238
  55400/1000000: episode: 554, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.991, mean reward: 0.600 [0.507, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.742, 10.194], loss: 0.001584, mae: 0.043396, mean_q: 1.184736
  55500/1000000: episode: 555, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 61.265, mean reward: 0.613 [0.507, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.132, 10.187], loss: 0.001579, mae: 0.043218, mean_q: 1.184238
  55600/1000000: episode: 556, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.331, mean reward: 0.583 [0.503, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.209, 10.098], loss: 0.001549, mae: 0.042825, mean_q: 1.186818
  55700/1000000: episode: 557, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 58.274, mean reward: 0.583 [0.512, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.860, 10.098], loss: 0.001446, mae: 0.041743, mean_q: 1.183985
  55800/1000000: episode: 558, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 64.055, mean reward: 0.641 [0.508, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.351, 10.488], loss: 0.001546, mae: 0.042658, mean_q: 1.184441
  55900/1000000: episode: 559, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 58.450, mean reward: 0.584 [0.501, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.442, 10.098], loss: 0.001473, mae: 0.042042, mean_q: 1.184524
  56000/1000000: episode: 560, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.386, mean reward: 0.584 [0.504, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.973, 10.223], loss: 0.001459, mae: 0.041942, mean_q: 1.187940
  56100/1000000: episode: 561, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.577, mean reward: 0.596 [0.500, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.814, 10.175], loss: 0.001580, mae: 0.043274, mean_q: 1.186316
  56200/1000000: episode: 562, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.947, mean reward: 0.579 [0.506, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.289, 10.098], loss: 0.001948, mae: 0.046685, mean_q: 1.182702
  56300/1000000: episode: 563, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 62.512, mean reward: 0.625 [0.516, 0.843], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.824, 10.098], loss: 0.001568, mae: 0.042942, mean_q: 1.182888
  56400/1000000: episode: 564, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 62.065, mean reward: 0.621 [0.506, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.691, 10.572], loss: 0.001514, mae: 0.042313, mean_q: 1.179718
  56500/1000000: episode: 565, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.401, mean reward: 0.584 [0.506, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.578, 10.098], loss: 0.001607, mae: 0.044134, mean_q: 1.186254
  56600/1000000: episode: 566, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.205, mean reward: 0.572 [0.500, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.835, 10.240], loss: 0.001516, mae: 0.043038, mean_q: 1.186818
  56700/1000000: episode: 567, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.277, mean reward: 0.583 [0.508, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.438, 10.167], loss: 0.001492, mae: 0.042317, mean_q: 1.180128
  56800/1000000: episode: 568, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.268, mean reward: 0.583 [0.504, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.527, 10.243], loss: 0.001456, mae: 0.042279, mean_q: 1.182063
  56900/1000000: episode: 569, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.215, mean reward: 0.592 [0.500, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.574, 10.274], loss: 0.001322, mae: 0.040123, mean_q: 1.181764
  57000/1000000: episode: 570, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.281, mean reward: 0.603 [0.504, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-0.290, 10.098], loss: 0.001436, mae: 0.041926, mean_q: 1.176385
  57100/1000000: episode: 571, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.058, mean reward: 0.591 [0.502, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.298, 10.288], loss: 0.001416, mae: 0.041102, mean_q: 1.175849
  57200/1000000: episode: 572, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.787, mean reward: 0.588 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.660, 10.489], loss: 0.001487, mae: 0.042176, mean_q: 1.177388
  57300/1000000: episode: 573, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.891, mean reward: 0.589 [0.502, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.835, 10.098], loss: 0.001533, mae: 0.042343, mean_q: 1.178473
  57400/1000000: episode: 574, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.288, mean reward: 0.593 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.711, 10.098], loss: 0.001307, mae: 0.040076, mean_q: 1.177808
  57500/1000000: episode: 575, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.743, mean reward: 0.597 [0.504, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.415, 10.098], loss: 0.001480, mae: 0.042069, mean_q: 1.179221
  57600/1000000: episode: 576, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.484, mean reward: 0.575 [0.503, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.608, 10.098], loss: 0.001321, mae: 0.039980, mean_q: 1.178104
  57700/1000000: episode: 577, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.371, mean reward: 0.564 [0.502, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.520, 10.098], loss: 0.001408, mae: 0.041606, mean_q: 1.178117
  57800/1000000: episode: 578, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.279, mean reward: 0.573 [0.508, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.991, 10.238], loss: 0.001386, mae: 0.040548, mean_q: 1.175162
  57900/1000000: episode: 579, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.100, mean reward: 0.591 [0.507, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.731, 10.098], loss: 0.001417, mae: 0.041162, mean_q: 1.178469
  58000/1000000: episode: 580, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.586, mean reward: 0.586 [0.502, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.528, 10.098], loss: 0.001502, mae: 0.042100, mean_q: 1.177684
  58100/1000000: episode: 581, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 58.087, mean reward: 0.581 [0.513, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.247, 10.107], loss: 0.001390, mae: 0.041314, mean_q: 1.175171
  58200/1000000: episode: 582, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.912, mean reward: 0.579 [0.513, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.356, 10.098], loss: 0.001395, mae: 0.041235, mean_q: 1.177621
  58300/1000000: episode: 583, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.122, mean reward: 0.581 [0.505, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.087, 10.098], loss: 0.001323, mae: 0.040295, mean_q: 1.177490
  58400/1000000: episode: 584, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.145, mean reward: 0.571 [0.507, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.127, 10.129], loss: 0.001478, mae: 0.042613, mean_q: 1.175712
  58500/1000000: episode: 585, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.760, mean reward: 0.588 [0.500, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.016, 10.098], loss: 0.001370, mae: 0.040360, mean_q: 1.174745
  58600/1000000: episode: 586, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.721, mean reward: 0.577 [0.498, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.388, 10.198], loss: 0.001252, mae: 0.039511, mean_q: 1.171657
  58700/1000000: episode: 587, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.757, mean reward: 0.598 [0.498, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.556, 10.098], loss: 0.001295, mae: 0.039224, mean_q: 1.171163
  58800/1000000: episode: 588, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.878, mean reward: 0.579 [0.510, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.241, 10.222], loss: 0.001445, mae: 0.041822, mean_q: 1.173143
  58900/1000000: episode: 589, duration: 0.512s, episode steps: 100, steps per second: 195, episode reward: 56.488, mean reward: 0.565 [0.500, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.575, 10.098], loss: 0.001372, mae: 0.040723, mean_q: 1.169822
  59000/1000000: episode: 590, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.280, mean reward: 0.583 [0.508, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.597, 10.098], loss: 0.001277, mae: 0.039640, mean_q: 1.170195
  59100/1000000: episode: 591, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.052, mean reward: 0.581 [0.509, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.812, 10.150], loss: 0.001285, mae: 0.039588, mean_q: 1.164586
  59200/1000000: episode: 592, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.050, mean reward: 0.580 [0.499, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.258, 10.265], loss: 0.001394, mae: 0.041303, mean_q: 1.167532
  59300/1000000: episode: 593, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.320, mean reward: 0.573 [0.506, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.946, 10.098], loss: 0.001406, mae: 0.041583, mean_q: 1.164640
  59400/1000000: episode: 594, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.891, mean reward: 0.599 [0.517, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.216, 10.373], loss: 0.001315, mae: 0.039962, mean_q: 1.162345
  59500/1000000: episode: 595, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.593, mean reward: 0.576 [0.503, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.749, 10.166], loss: 0.001326, mae: 0.040482, mean_q: 1.163567
  59600/1000000: episode: 596, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 56.908, mean reward: 0.569 [0.500, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.544, 10.098], loss: 0.001391, mae: 0.041004, mean_q: 1.164280
  59700/1000000: episode: 597, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.305, mean reward: 0.573 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.952, 10.138], loss: 0.001401, mae: 0.041084, mean_q: 1.164731
  59800/1000000: episode: 598, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 56.936, mean reward: 0.569 [0.499, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.298, 10.137], loss: 0.001407, mae: 0.041708, mean_q: 1.163647
  59900/1000000: episode: 599, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.670, mean reward: 0.587 [0.516, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.201, 10.098], loss: 0.001346, mae: 0.040835, mean_q: 1.161900
  60000/1000000: episode: 600, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.349, mean reward: 0.583 [0.500, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.863, 10.242], loss: 0.001247, mae: 0.038975, mean_q: 1.158316
  60100/1000000: episode: 601, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 60.420, mean reward: 0.604 [0.507, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.312, 10.137], loss: 0.001305, mae: 0.040400, mean_q: 1.161332
  60200/1000000: episode: 602, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.523, mean reward: 0.595 [0.510, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.850, 10.098], loss: 0.001326, mae: 0.040855, mean_q: 1.161608
  60300/1000000: episode: 603, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.423, mean reward: 0.584 [0.512, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.618, 10.176], loss: 0.001284, mae: 0.039677, mean_q: 1.159534
  60400/1000000: episode: 604, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 60.884, mean reward: 0.609 [0.511, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.559, 10.234], loss: 0.001317, mae: 0.039875, mean_q: 1.160033
  60500/1000000: episode: 605, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.853, mean reward: 0.599 [0.500, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.987, 10.250], loss: 0.001283, mae: 0.039739, mean_q: 1.157541
  60600/1000000: episode: 606, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.517, mean reward: 0.585 [0.510, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.624, 10.098], loss: 0.001300, mae: 0.039541, mean_q: 1.163627
  60700/1000000: episode: 607, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.846, mean reward: 0.588 [0.503, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.163, 10.098], loss: 0.001294, mae: 0.039965, mean_q: 1.162503
  60800/1000000: episode: 608, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.025, mean reward: 0.610 [0.503, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.472, 10.271], loss: 0.001348, mae: 0.040064, mean_q: 1.158485
  60900/1000000: episode: 609, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.592, mean reward: 0.596 [0.499, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.798, 10.241], loss: 0.001262, mae: 0.039291, mean_q: 1.158687
  61000/1000000: episode: 610, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.049, mean reward: 0.580 [0.505, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.877, 10.174], loss: 0.001254, mae: 0.038830, mean_q: 1.160085
  61100/1000000: episode: 611, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.313, mean reward: 0.593 [0.501, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.931, 10.272], loss: 0.001334, mae: 0.039929, mean_q: 1.158327
  61200/1000000: episode: 612, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.070, mean reward: 0.581 [0.507, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.984, 10.133], loss: 0.001273, mae: 0.039127, mean_q: 1.161632
  61300/1000000: episode: 613, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.474, mean reward: 0.595 [0.499, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.775, 10.098], loss: 0.001329, mae: 0.039835, mean_q: 1.157969
  61400/1000000: episode: 614, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.447, mean reward: 0.574 [0.505, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.094, 10.098], loss: 0.001292, mae: 0.040277, mean_q: 1.157085
  61500/1000000: episode: 615, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.312, mean reward: 0.593 [0.510, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.568, 10.115], loss: 0.001248, mae: 0.038583, mean_q: 1.157314
  61600/1000000: episode: 616, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.787, mean reward: 0.588 [0.508, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.845, 10.300], loss: 0.001226, mae: 0.038835, mean_q: 1.158779
  61700/1000000: episode: 617, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.300, mean reward: 0.603 [0.526, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.416, 10.342], loss: 0.001253, mae: 0.038860, mean_q: 1.162009
  61800/1000000: episode: 618, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.988, mean reward: 0.580 [0.499, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.835, 10.098], loss: 0.001403, mae: 0.041352, mean_q: 1.160699
  61900/1000000: episode: 619, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.493, mean reward: 0.575 [0.498, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.972, 10.207], loss: 0.001259, mae: 0.039181, mean_q: 1.155075
  62000/1000000: episode: 620, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.897, mean reward: 0.599 [0.505, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.897, 10.144], loss: 0.001251, mae: 0.039068, mean_q: 1.157025
  62100/1000000: episode: 621, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.672, mean reward: 0.597 [0.503, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.438, 10.153], loss: 0.001304, mae: 0.040147, mean_q: 1.156228
  62200/1000000: episode: 622, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.439, mean reward: 0.594 [0.503, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.118, 10.423], loss: 0.001240, mae: 0.038659, mean_q: 1.157476
  62300/1000000: episode: 623, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.707, mean reward: 0.577 [0.499, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.988, 10.098], loss: 0.001313, mae: 0.039916, mean_q: 1.159674
  62400/1000000: episode: 624, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.418, mean reward: 0.594 [0.508, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.211, 10.237], loss: 0.001307, mae: 0.039440, mean_q: 1.155012
  62500/1000000: episode: 625, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.068, mean reward: 0.581 [0.510, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.944, 10.098], loss: 0.001323, mae: 0.040450, mean_q: 1.156679
  62600/1000000: episode: 626, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.794, mean reward: 0.588 [0.510, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.513, 10.279], loss: 0.001322, mae: 0.039948, mean_q: 1.157475
  62700/1000000: episode: 627, duration: 0.528s, episode steps: 100, steps per second: 190, episode reward: 56.278, mean reward: 0.563 [0.504, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.037, 10.098], loss: 0.001248, mae: 0.039322, mean_q: 1.156731
  62800/1000000: episode: 628, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.154, mean reward: 0.582 [0.505, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.017, 10.108], loss: 0.001328, mae: 0.040335, mean_q: 1.158501
  62900/1000000: episode: 629, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.156, mean reward: 0.592 [0.502, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.696, 10.098], loss: 0.001362, mae: 0.040725, mean_q: 1.159101
  63000/1000000: episode: 630, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.878, mean reward: 0.609 [0.505, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.197, 10.098], loss: 0.001290, mae: 0.039785, mean_q: 1.155698
  63100/1000000: episode: 631, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 61.720, mean reward: 0.617 [0.509, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.905, 10.098], loss: 0.001254, mae: 0.038925, mean_q: 1.155439
  63200/1000000: episode: 632, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.342, mean reward: 0.593 [0.508, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.377, 10.436], loss: 0.001343, mae: 0.040480, mean_q: 1.158883
  63300/1000000: episode: 633, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.015, mean reward: 0.590 [0.499, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.655, 10.098], loss: 0.001339, mae: 0.040242, mean_q: 1.160146
  63400/1000000: episode: 634, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.384, mean reward: 0.584 [0.501, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.796, 10.120], loss: 0.001257, mae: 0.039020, mean_q: 1.158729
  63500/1000000: episode: 635, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.559, mean reward: 0.576 [0.503, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.512, 10.098], loss: 0.001319, mae: 0.040301, mean_q: 1.162764
  63600/1000000: episode: 636, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 61.800, mean reward: 0.618 [0.543, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.530, 10.280], loss: 0.001252, mae: 0.039077, mean_q: 1.161500
  63700/1000000: episode: 637, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.469, mean reward: 0.605 [0.503, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.720, 10.098], loss: 0.001309, mae: 0.039827, mean_q: 1.163180
  63800/1000000: episode: 638, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.029, mean reward: 0.580 [0.500, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.921, 10.238], loss: 0.001224, mae: 0.039036, mean_q: 1.163588
  63900/1000000: episode: 639, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.282, mean reward: 0.593 [0.511, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.302, 10.187], loss: 0.001382, mae: 0.040796, mean_q: 1.164641
  64000/1000000: episode: 640, duration: 0.525s, episode steps: 100, steps per second: 190, episode reward: 57.849, mean reward: 0.578 [0.502, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.045, 10.098], loss: 0.001325, mae: 0.040295, mean_q: 1.166161
  64100/1000000: episode: 641, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.572, mean reward: 0.586 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.144, 10.264], loss: 0.001241, mae: 0.039105, mean_q: 1.161496
  64200/1000000: episode: 642, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.218, mean reward: 0.592 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.759, 10.098], loss: 0.001328, mae: 0.040429, mean_q: 1.162843
  64300/1000000: episode: 643, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.645, mean reward: 0.576 [0.508, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.071, 10.201], loss: 0.001343, mae: 0.040173, mean_q: 1.166576
  64400/1000000: episode: 644, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.310, mean reward: 0.593 [0.507, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.434, 10.098], loss: 0.001344, mae: 0.040563, mean_q: 1.162176
  64500/1000000: episode: 645, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.797, mean reward: 0.588 [0.503, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.006, 10.140], loss: 0.001374, mae: 0.040768, mean_q: 1.163859
  64600/1000000: episode: 646, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.155, mean reward: 0.572 [0.500, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.087, 10.098], loss: 0.001311, mae: 0.039663, mean_q: 1.165678
  64700/1000000: episode: 647, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.598, mean reward: 0.586 [0.506, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.454, 10.235], loss: 0.001316, mae: 0.039662, mean_q: 1.163043
  64800/1000000: episode: 648, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.232, mean reward: 0.582 [0.510, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.104, 10.168], loss: 0.001391, mae: 0.040847, mean_q: 1.166753
  64900/1000000: episode: 649, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.496, mean reward: 0.575 [0.509, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.607, 10.221], loss: 0.001250, mae: 0.038830, mean_q: 1.163435
  65000/1000000: episode: 650, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.719, mean reward: 0.567 [0.505, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.312, 10.124], loss: 0.001316, mae: 0.039687, mean_q: 1.165069
  65100/1000000: episode: 651, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.285, mean reward: 0.593 [0.510, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.899, 10.098], loss: 0.001302, mae: 0.040232, mean_q: 1.162274
  65200/1000000: episode: 652, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.426, mean reward: 0.584 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.783, 10.190], loss: 0.001289, mae: 0.039320, mean_q: 1.159240
  65300/1000000: episode: 653, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.695, mean reward: 0.587 [0.501, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.488, 10.189], loss: 0.001388, mae: 0.040934, mean_q: 1.159172
  65400/1000000: episode: 654, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.199, mean reward: 0.582 [0.500, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.636, 10.351], loss: 0.001356, mae: 0.040815, mean_q: 1.159513
  65500/1000000: episode: 655, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.448, mean reward: 0.584 [0.510, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.674, 10.139], loss: 0.001327, mae: 0.040466, mean_q: 1.159441
  65600/1000000: episode: 656, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 59.336, mean reward: 0.593 [0.503, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.454, 10.098], loss: 0.001324, mae: 0.040331, mean_q: 1.162632
  65700/1000000: episode: 657, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.969, mean reward: 0.610 [0.500, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.673, 10.310], loss: 0.001658, mae: 0.044333, mean_q: 1.157721
  65800/1000000: episode: 658, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.341, mean reward: 0.583 [0.498, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.671, 10.098], loss: 0.001265, mae: 0.039237, mean_q: 1.157899
  65900/1000000: episode: 659, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.963, mean reward: 0.580 [0.502, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.932, 10.246], loss: 0.001250, mae: 0.038850, mean_q: 1.157990
  66000/1000000: episode: 660, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.682, mean reward: 0.597 [0.523, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.983, 10.192], loss: 0.001309, mae: 0.040074, mean_q: 1.157994
  66100/1000000: episode: 661, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.013, mean reward: 0.590 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.454, 10.394], loss: 0.001336, mae: 0.040249, mean_q: 1.161976
  66200/1000000: episode: 662, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.527, mean reward: 0.585 [0.510, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.676, 10.098], loss: 0.001281, mae: 0.039722, mean_q: 1.160424
  66300/1000000: episode: 663, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 62.497, mean reward: 0.625 [0.516, 0.865], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.255, 10.098], loss: 0.001240, mae: 0.039027, mean_q: 1.160192
  66400/1000000: episode: 664, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.565, mean reward: 0.576 [0.504, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.249, 10.242], loss: 0.001362, mae: 0.041136, mean_q: 1.160052
  66500/1000000: episode: 665, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.445, mean reward: 0.574 [0.498, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.117, 10.241], loss: 0.001348, mae: 0.040464, mean_q: 1.164335
  66600/1000000: episode: 666, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.167, mean reward: 0.592 [0.501, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-2.466, 10.098], loss: 0.001392, mae: 0.040912, mean_q: 1.161276
  66700/1000000: episode: 667, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.971, mean reward: 0.620 [0.522, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.488, 10.098], loss: 0.001370, mae: 0.040729, mean_q: 1.162186
  66800/1000000: episode: 668, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.213, mean reward: 0.582 [0.504, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.560, 10.150], loss: 0.001312, mae: 0.039689, mean_q: 1.163036
  66900/1000000: episode: 669, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.991, mean reward: 0.580 [0.503, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.827, 10.105], loss: 0.001334, mae: 0.040555, mean_q: 1.165794
  67000/1000000: episode: 670, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.687, mean reward: 0.577 [0.500, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.020, 10.123], loss: 0.001337, mae: 0.040178, mean_q: 1.163410
  67100/1000000: episode: 671, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.002, mean reward: 0.580 [0.501, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.202, 10.205], loss: 0.001273, mae: 0.039554, mean_q: 1.160437
  67200/1000000: episode: 672, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.434, mean reward: 0.604 [0.513, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.915, 10.098], loss: 0.001385, mae: 0.041438, mean_q: 1.163656
  67300/1000000: episode: 673, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.919, mean reward: 0.579 [0.503, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.143, 10.148], loss: 0.001422, mae: 0.041923, mean_q: 1.163101
  67400/1000000: episode: 674, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.983, mean reward: 0.590 [0.508, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.269, 10.201], loss: 0.001352, mae: 0.040725, mean_q: 1.162714
  67500/1000000: episode: 675, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 59.115, mean reward: 0.591 [0.503, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.778, 10.098], loss: 0.001402, mae: 0.040682, mean_q: 1.161689
  67600/1000000: episode: 676, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.003, mean reward: 0.600 [0.513, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.615, 10.098], loss: 0.001364, mae: 0.040632, mean_q: 1.166544
  67700/1000000: episode: 677, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.683, mean reward: 0.597 [0.515, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.755, 10.217], loss: 0.001338, mae: 0.040053, mean_q: 1.165421
  67800/1000000: episode: 678, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.558, mean reward: 0.606 [0.505, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.327, 10.184], loss: 0.001400, mae: 0.041645, mean_q: 1.165388
  67900/1000000: episode: 679, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.696, mean reward: 0.597 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.283, 10.177], loss: 0.001419, mae: 0.041436, mean_q: 1.167475
  68000/1000000: episode: 680, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.246, mean reward: 0.582 [0.507, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.729, 10.219], loss: 0.001356, mae: 0.040989, mean_q: 1.166751
  68100/1000000: episode: 681, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.054, mean reward: 0.591 [0.499, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.269, 10.098], loss: 0.001351, mae: 0.040178, mean_q: 1.162474
  68200/1000000: episode: 682, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.268, mean reward: 0.603 [0.516, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.666, 10.098], loss: 0.001385, mae: 0.040931, mean_q: 1.163833
  68300/1000000: episode: 683, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 56.653, mean reward: 0.567 [0.500, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.432, 10.198], loss: 0.001346, mae: 0.040335, mean_q: 1.162311
  68400/1000000: episode: 684, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.498, mean reward: 0.585 [0.499, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.131, 10.128], loss: 0.001332, mae: 0.040413, mean_q: 1.164408
  68500/1000000: episode: 685, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 61.329, mean reward: 0.613 [0.508, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.889, 10.221], loss: 0.001393, mae: 0.041120, mean_q: 1.162325
  68600/1000000: episode: 686, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.040, mean reward: 0.580 [0.505, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.663, 10.216], loss: 0.001353, mae: 0.040354, mean_q: 1.162355
  68700/1000000: episode: 687, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 55.856, mean reward: 0.559 [0.501, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.880, 10.340], loss: 0.001396, mae: 0.041211, mean_q: 1.162490
  68800/1000000: episode: 688, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.229, mean reward: 0.582 [0.500, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.048, 10.098], loss: 0.001318, mae: 0.039928, mean_q: 1.166414
  68900/1000000: episode: 689, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.726, mean reward: 0.597 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.082, 10.297], loss: 0.001253, mae: 0.038361, mean_q: 1.161559
  69000/1000000: episode: 690, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.888, mean reward: 0.599 [0.503, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.859, 10.354], loss: 0.001313, mae: 0.039763, mean_q: 1.161499
  69100/1000000: episode: 691, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 61.328, mean reward: 0.613 [0.501, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.835, 10.101], loss: 0.001254, mae: 0.038679, mean_q: 1.161653
  69200/1000000: episode: 692, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.500, mean reward: 0.605 [0.515, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.895, 10.098], loss: 0.001346, mae: 0.040099, mean_q: 1.162644
  69300/1000000: episode: 693, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.716, mean reward: 0.577 [0.500, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.467, 10.098], loss: 0.001451, mae: 0.041788, mean_q: 1.164498
  69400/1000000: episode: 694, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.754, mean reward: 0.598 [0.509, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.123, 10.346], loss: 0.001267, mae: 0.038858, mean_q: 1.169792
  69500/1000000: episode: 695, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.186, mean reward: 0.582 [0.498, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.394, 10.274], loss: 0.001357, mae: 0.040491, mean_q: 1.164305
  69600/1000000: episode: 696, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 60.620, mean reward: 0.606 [0.504, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.490, 10.098], loss: 0.001338, mae: 0.040383, mean_q: 1.165672
  69700/1000000: episode: 697, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.141, mean reward: 0.571 [0.505, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.337, 10.098], loss: 0.001390, mae: 0.041096, mean_q: 1.166359
  69800/1000000: episode: 698, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 64.814, mean reward: 0.648 [0.505, 0.885], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.043, 10.510], loss: 0.001333, mae: 0.039877, mean_q: 1.165412
  69900/1000000: episode: 699, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.197, mean reward: 0.572 [0.509, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.846, 10.098], loss: 0.001352, mae: 0.040078, mean_q: 1.165668
  70000/1000000: episode: 700, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 61.562, mean reward: 0.616 [0.502, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-0.714, 10.098], loss: 0.001459, mae: 0.041751, mean_q: 1.168681
  70100/1000000: episode: 701, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.357, mean reward: 0.574 [0.500, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.201, 10.098], loss: 0.001407, mae: 0.041182, mean_q: 1.167848
  70200/1000000: episode: 702, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.182, mean reward: 0.562 [0.499, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.771, 10.098], loss: 0.001390, mae: 0.041016, mean_q: 1.168580
  70300/1000000: episode: 703, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.418, mean reward: 0.594 [0.507, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.808, 10.256], loss: 0.001469, mae: 0.041740, mean_q: 1.162102
  70400/1000000: episode: 704, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 60.490, mean reward: 0.605 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.854, 10.131], loss: 0.001354, mae: 0.040299, mean_q: 1.167017
  70500/1000000: episode: 705, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.994, mean reward: 0.580 [0.506, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.772, 10.264], loss: 0.001450, mae: 0.042135, mean_q: 1.170918
  70600/1000000: episode: 706, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 56.256, mean reward: 0.563 [0.501, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.961, 10.328], loss: 0.001364, mae: 0.040515, mean_q: 1.167871
  70700/1000000: episode: 707, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.341, mean reward: 0.603 [0.499, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.757, 10.121], loss: 0.001402, mae: 0.041075, mean_q: 1.166444
  70800/1000000: episode: 708, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.205, mean reward: 0.582 [0.502, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.105, 10.130], loss: 0.001406, mae: 0.041051, mean_q: 1.166536
  70900/1000000: episode: 709, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 61.935, mean reward: 0.619 [0.513, 0.855], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.660, 10.294], loss: 0.001389, mae: 0.040472, mean_q: 1.168224
  71000/1000000: episode: 710, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 61.808, mean reward: 0.618 [0.508, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.443, 10.457], loss: 0.001364, mae: 0.040625, mean_q: 1.170160
  71100/1000000: episode: 711, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.687, mean reward: 0.607 [0.514, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.083, 10.178], loss: 0.001399, mae: 0.040879, mean_q: 1.170178
  71200/1000000: episode: 712, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.769, mean reward: 0.578 [0.500, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.511, 10.098], loss: 0.001510, mae: 0.042584, mean_q: 1.173763
  71300/1000000: episode: 713, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 60.216, mean reward: 0.602 [0.508, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.022, 10.291], loss: 0.001562, mae: 0.042278, mean_q: 1.172418
  71400/1000000: episode: 714, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.504, mean reward: 0.575 [0.505, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.047, 10.203], loss: 0.001374, mae: 0.041097, mean_q: 1.170477
  71500/1000000: episode: 715, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.182, mean reward: 0.592 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.192, 10.098], loss: 0.001435, mae: 0.041627, mean_q: 1.171252
  71600/1000000: episode: 716, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.079, mean reward: 0.601 [0.504, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.030, 10.098], loss: 0.001298, mae: 0.039706, mean_q: 1.172382
  71700/1000000: episode: 717, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 60.436, mean reward: 0.604 [0.507, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.201, 10.098], loss: 0.001472, mae: 0.041571, mean_q: 1.172847
  71800/1000000: episode: 718, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.314, mean reward: 0.573 [0.505, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.534, 10.106], loss: 0.001304, mae: 0.039515, mean_q: 1.170201
  71900/1000000: episode: 719, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.794, mean reward: 0.588 [0.506, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.801, 10.098], loss: 0.001368, mae: 0.040632, mean_q: 1.170507
  72000/1000000: episode: 720, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.384, mean reward: 0.604 [0.506, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.053, 10.098], loss: 0.001452, mae: 0.041490, mean_q: 1.166619
  72100/1000000: episode: 721, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 65.187, mean reward: 0.652 [0.502, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.929, 10.296], loss: 0.001398, mae: 0.041255, mean_q: 1.175441
  72200/1000000: episode: 722, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.353, mean reward: 0.594 [0.506, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.028, 10.098], loss: 0.001401, mae: 0.041086, mean_q: 1.175801
  72300/1000000: episode: 723, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.939, mean reward: 0.579 [0.499, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.494, 10.170], loss: 0.001354, mae: 0.040897, mean_q: 1.174906
  72400/1000000: episode: 724, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.450, mean reward: 0.595 [0.508, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.551, 10.250], loss: 0.001321, mae: 0.039752, mean_q: 1.172873
  72500/1000000: episode: 725, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.335, mean reward: 0.573 [0.497, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.955, 10.098], loss: 0.001306, mae: 0.039682, mean_q: 1.174554
  72600/1000000: episode: 726, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.736, mean reward: 0.607 [0.506, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.674, 10.098], loss: 0.001456, mae: 0.041683, mean_q: 1.175666
  72700/1000000: episode: 727, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.554, mean reward: 0.586 [0.497, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.579, 10.098], loss: 0.001336, mae: 0.040328, mean_q: 1.172018
  72800/1000000: episode: 728, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.623, mean reward: 0.586 [0.507, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.486, 10.129], loss: 0.001321, mae: 0.039732, mean_q: 1.170619
  72900/1000000: episode: 729, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.536, mean reward: 0.575 [0.502, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.658, 10.115], loss: 0.001272, mae: 0.039237, mean_q: 1.172592
  73000/1000000: episode: 730, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 56.815, mean reward: 0.568 [0.503, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.478, 10.098], loss: 0.001318, mae: 0.039915, mean_q: 1.171415
  73100/1000000: episode: 731, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.602, mean reward: 0.586 [0.501, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.528, 10.098], loss: 0.001353, mae: 0.040600, mean_q: 1.170758
  73200/1000000: episode: 732, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.282, mean reward: 0.593 [0.504, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-2.233, 10.098], loss: 0.001387, mae: 0.040891, mean_q: 1.172121
  73300/1000000: episode: 733, duration: 0.524s, episode steps: 100, steps per second: 191, episode reward: 58.316, mean reward: 0.583 [0.506, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.890, 10.129], loss: 0.001286, mae: 0.039747, mean_q: 1.169650
  73400/1000000: episode: 734, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 56.732, mean reward: 0.567 [0.505, 0.665], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.795, 10.133], loss: 0.001330, mae: 0.039779, mean_q: 1.168024
  73500/1000000: episode: 735, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.016, mean reward: 0.590 [0.505, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.277, 10.098], loss: 0.001435, mae: 0.042080, mean_q: 1.169551
  73600/1000000: episode: 736, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.385, mean reward: 0.594 [0.509, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.532, 10.098], loss: 0.001370, mae: 0.040525, mean_q: 1.168236
  73700/1000000: episode: 737, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.332, mean reward: 0.583 [0.501, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.477, 10.098], loss: 0.001285, mae: 0.039475, mean_q: 1.170372
  73800/1000000: episode: 738, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.422, mean reward: 0.584 [0.499, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.306, 10.232], loss: 0.001382, mae: 0.041264, mean_q: 1.171638
  73900/1000000: episode: 739, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.510, mean reward: 0.575 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.749, 10.098], loss: 0.001376, mae: 0.041133, mean_q: 1.173526
  74000/1000000: episode: 740, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.203, mean reward: 0.572 [0.511, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.234, 10.183], loss: 0.001361, mae: 0.040680, mean_q: 1.167427
  74100/1000000: episode: 741, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 56.999, mean reward: 0.570 [0.499, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.516, 10.190], loss: 0.001460, mae: 0.041951, mean_q: 1.166863
  74200/1000000: episode: 742, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.788, mean reward: 0.598 [0.506, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.094, 10.098], loss: 0.001339, mae: 0.040178, mean_q: 1.169358
  74300/1000000: episode: 743, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.055, mean reward: 0.581 [0.503, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.949, 10.205], loss: 0.001379, mae: 0.040830, mean_q: 1.166311
  74400/1000000: episode: 744, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.739, mean reward: 0.587 [0.498, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.911, 10.098], loss: 0.001400, mae: 0.041061, mean_q: 1.169226
  74500/1000000: episode: 745, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.989, mean reward: 0.590 [0.510, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.503, 10.157], loss: 0.001416, mae: 0.041630, mean_q: 1.168385
  74600/1000000: episode: 746, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.872, mean reward: 0.589 [0.501, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.143, 10.104], loss: 0.001342, mae: 0.040573, mean_q: 1.163522
  74700/1000000: episode: 747, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.796, mean reward: 0.588 [0.502, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.940, 10.098], loss: 0.001349, mae: 0.040547, mean_q: 1.164471
  74800/1000000: episode: 748, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.125, mean reward: 0.581 [0.513, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.540, 10.098], loss: 0.001397, mae: 0.041065, mean_q: 1.164111
  74900/1000000: episode: 749, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.474, mean reward: 0.575 [0.503, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.972, 10.098], loss: 0.001414, mae: 0.041877, mean_q: 1.166337
  75000/1000000: episode: 750, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 64.158, mean reward: 0.642 [0.512, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.628, 10.420], loss: 0.001420, mae: 0.041528, mean_q: 1.165427
  75100/1000000: episode: 751, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.432, mean reward: 0.584 [0.509, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.513, 10.152], loss: 0.001379, mae: 0.041234, mean_q: 1.166561
  75200/1000000: episode: 752, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.994, mean reward: 0.590 [0.508, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.623, 10.098], loss: 0.001373, mae: 0.040409, mean_q: 1.168207
  75300/1000000: episode: 753, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.336, mean reward: 0.583 [0.504, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.832, 10.098], loss: 0.001321, mae: 0.039983, mean_q: 1.167454
  75400/1000000: episode: 754, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.306, mean reward: 0.613 [0.513, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.271, 10.098], loss: 0.001400, mae: 0.041147, mean_q: 1.165375
  75500/1000000: episode: 755, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.277, mean reward: 0.573 [0.499, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.841, 10.098], loss: 0.001373, mae: 0.040858, mean_q: 1.167499
  75600/1000000: episode: 756, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.190, mean reward: 0.592 [0.516, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.501, 10.098], loss: 0.001430, mae: 0.041630, mean_q: 1.170523
  75700/1000000: episode: 757, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 62.284, mean reward: 0.623 [0.513, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.773, 10.164], loss: 0.001386, mae: 0.041145, mean_q: 1.167264
  75800/1000000: episode: 758, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.153, mean reward: 0.622 [0.517, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.844, 10.153], loss: 0.001345, mae: 0.040381, mean_q: 1.167875
  75900/1000000: episode: 759, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.689, mean reward: 0.597 [0.508, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.925, 10.116], loss: 0.001297, mae: 0.039809, mean_q: 1.167886
  76000/1000000: episode: 760, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.526, mean reward: 0.575 [0.511, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.520, 10.189], loss: 0.001333, mae: 0.040078, mean_q: 1.165496
  76100/1000000: episode: 761, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.755, mean reward: 0.608 [0.516, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.190, 10.098], loss: 0.001281, mae: 0.039649, mean_q: 1.166456
  76200/1000000: episode: 762, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 59.548, mean reward: 0.595 [0.512, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.337, 10.257], loss: 0.001310, mae: 0.039884, mean_q: 1.167239
  76300/1000000: episode: 763, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.001, mean reward: 0.580 [0.505, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.698, 10.098], loss: 0.001369, mae: 0.040743, mean_q: 1.166248
  76400/1000000: episode: 764, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.817, mean reward: 0.588 [0.500, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.615, 10.377], loss: 0.001293, mae: 0.039951, mean_q: 1.168483
  76500/1000000: episode: 765, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.658, mean reward: 0.597 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.159, 10.098], loss: 0.001399, mae: 0.041476, mean_q: 1.165262
  76600/1000000: episode: 766, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.449, mean reward: 0.614 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.686, 10.098], loss: 0.001259, mae: 0.039087, mean_q: 1.168610
  76700/1000000: episode: 767, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.511, mean reward: 0.585 [0.502, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.096, 10.296], loss: 0.001353, mae: 0.040945, mean_q: 1.167080
  76800/1000000: episode: 768, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.240, mean reward: 0.582 [0.507, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.807, 10.098], loss: 0.001374, mae: 0.040721, mean_q: 1.166647
  76900/1000000: episode: 769, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.172, mean reward: 0.582 [0.502, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.251, 10.365], loss: 0.001341, mae: 0.040552, mean_q: 1.164603
  77000/1000000: episode: 770, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 62.212, mean reward: 0.622 [0.520, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.623, 10.191], loss: 0.001370, mae: 0.040817, mean_q: 1.165627
  77100/1000000: episode: 771, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.467, mean reward: 0.595 [0.506, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.232, 10.098], loss: 0.001346, mae: 0.040512, mean_q: 1.167722
  77200/1000000: episode: 772, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.265, mean reward: 0.573 [0.503, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.044, 10.318], loss: 0.001260, mae: 0.039199, mean_q: 1.164303
  77300/1000000: episode: 773, duration: 0.627s, episode steps: 100, steps per second: 159, episode reward: 59.144, mean reward: 0.591 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.639, 10.409], loss: 0.001425, mae: 0.041680, mean_q: 1.161998
  77400/1000000: episode: 774, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.923, mean reward: 0.589 [0.507, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.033, 10.098], loss: 0.001475, mae: 0.042299, mean_q: 1.164147
  77500/1000000: episode: 775, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.273, mean reward: 0.573 [0.505, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.344, 10.169], loss: 0.001482, mae: 0.042822, mean_q: 1.162511
  77600/1000000: episode: 776, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.291, mean reward: 0.593 [0.502, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.648, 10.225], loss: 0.001544, mae: 0.042566, mean_q: 1.160497
  77700/1000000: episode: 777, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.417, mean reward: 0.594 [0.522, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.378, 10.098], loss: 0.001413, mae: 0.041044, mean_q: 1.162857
  77800/1000000: episode: 778, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.073, mean reward: 0.571 [0.511, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.731, 10.305], loss: 0.001444, mae: 0.041950, mean_q: 1.164667
  77900/1000000: episode: 779, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 56.815, mean reward: 0.568 [0.505, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.608, 10.263], loss: 0.001409, mae: 0.041120, mean_q: 1.165453
  78000/1000000: episode: 780, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.192, mean reward: 0.592 [0.506, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.997, 10.098], loss: 0.001291, mae: 0.039543, mean_q: 1.161852
  78100/1000000: episode: 781, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.152, mean reward: 0.572 [0.498, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.456, 10.141], loss: 0.001348, mae: 0.040628, mean_q: 1.164945
  78200/1000000: episode: 782, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.239, mean reward: 0.572 [0.498, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.452, 10.098], loss: 0.001331, mae: 0.040474, mean_q: 1.165508
  78300/1000000: episode: 783, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.182, mean reward: 0.572 [0.506, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.582, 10.098], loss: 0.001409, mae: 0.041228, mean_q: 1.161229
  78400/1000000: episode: 784, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.887, mean reward: 0.589 [0.505, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.529, 10.098], loss: 0.001259, mae: 0.039500, mean_q: 1.162651
  78500/1000000: episode: 785, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 60.813, mean reward: 0.608 [0.506, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.307, 10.416], loss: 0.001357, mae: 0.040604, mean_q: 1.162483
  78600/1000000: episode: 786, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.006, mean reward: 0.590 [0.510, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.531, 10.258], loss: 0.001418, mae: 0.041826, mean_q: 1.164949
  78700/1000000: episode: 787, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.290, mean reward: 0.583 [0.501, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.284, 10.335], loss: 0.001396, mae: 0.041171, mean_q: 1.164262
  78800/1000000: episode: 788, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 63.780, mean reward: 0.638 [0.504, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.910, 10.214], loss: 0.001358, mae: 0.040445, mean_q: 1.164288
  78900/1000000: episode: 789, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.321, mean reward: 0.593 [0.508, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.504, 10.098], loss: 0.001386, mae: 0.041351, mean_q: 1.170283
  79000/1000000: episode: 790, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.224, mean reward: 0.572 [0.500, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.043, 10.327], loss: 0.001426, mae: 0.041373, mean_q: 1.170280
  79100/1000000: episode: 791, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.355, mean reward: 0.614 [0.510, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.786, 10.098], loss: 0.001440, mae: 0.041332, mean_q: 1.169709
  79200/1000000: episode: 792, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.039, mean reward: 0.580 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.948, 10.098], loss: 0.001377, mae: 0.041166, mean_q: 1.168031
  79300/1000000: episode: 793, duration: 0.672s, episode steps: 100, steps per second: 149, episode reward: 58.147, mean reward: 0.581 [0.503, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.602, 10.098], loss: 0.001310, mae: 0.039651, mean_q: 1.166919
  79400/1000000: episode: 794, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.680, mean reward: 0.587 [0.510, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.194, 10.320], loss: 0.001370, mae: 0.040716, mean_q: 1.168392
  79500/1000000: episode: 795, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.929, mean reward: 0.589 [0.503, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.063, 10.127], loss: 0.001452, mae: 0.041764, mean_q: 1.169763
  79600/1000000: episode: 796, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.610, mean reward: 0.586 [0.498, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.155, 10.098], loss: 0.001413, mae: 0.041535, mean_q: 1.165565
  79700/1000000: episode: 797, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.230, mean reward: 0.592 [0.502, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.254, 10.469], loss: 0.001237, mae: 0.038986, mean_q: 1.168176
  79800/1000000: episode: 798, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.743, mean reward: 0.577 [0.502, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.695, 10.185], loss: 0.001261, mae: 0.039192, mean_q: 1.167833
  79900/1000000: episode: 799, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.065, mean reward: 0.611 [0.508, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.653, 10.272], loss: 0.001429, mae: 0.041816, mean_q: 1.167630
  80000/1000000: episode: 800, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.578, mean reward: 0.586 [0.506, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.166, 10.254], loss: 0.001422, mae: 0.041428, mean_q: 1.168106
  80100/1000000: episode: 801, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.156, mean reward: 0.582 [0.506, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.607, 10.133], loss: 0.001558, mae: 0.042596, mean_q: 1.168261
  80200/1000000: episode: 802, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 62.136, mean reward: 0.621 [0.504, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.056, 10.098], loss: 0.001384, mae: 0.041399, mean_q: 1.166816
  80300/1000000: episode: 803, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.675, mean reward: 0.587 [0.503, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.698, 10.098], loss: 0.001388, mae: 0.040556, mean_q: 1.166280
  80400/1000000: episode: 804, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.373, mean reward: 0.584 [0.504, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.767, 10.098], loss: 0.001331, mae: 0.039736, mean_q: 1.171995
  80500/1000000: episode: 805, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.673, mean reward: 0.587 [0.504, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.747, 10.098], loss: 0.001421, mae: 0.041468, mean_q: 1.168263
  80600/1000000: episode: 806, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 61.046, mean reward: 0.610 [0.518, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.697, 10.098], loss: 0.001344, mae: 0.040377, mean_q: 1.166445
  80700/1000000: episode: 807, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.397, mean reward: 0.584 [0.502, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.956, 10.098], loss: 0.001383, mae: 0.040815, mean_q: 1.168098
  80800/1000000: episode: 808, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.417, mean reward: 0.584 [0.505, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.350, 10.286], loss: 0.001393, mae: 0.040597, mean_q: 1.165429
  80900/1000000: episode: 809, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.125, mean reward: 0.591 [0.504, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.413 [-0.809, 10.134], loss: 0.001334, mae: 0.040556, mean_q: 1.161828
  81000/1000000: episode: 810, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.026, mean reward: 0.580 [0.502, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.570, 10.110], loss: 0.001268, mae: 0.038564, mean_q: 1.162362
  81100/1000000: episode: 811, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.244, mean reward: 0.582 [0.505, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.872, 10.237], loss: 0.001353, mae: 0.040506, mean_q: 1.165860
  81200/1000000: episode: 812, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.734, mean reward: 0.597 [0.511, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.568, 10.098], loss: 0.001318, mae: 0.039968, mean_q: 1.166697
  81300/1000000: episode: 813, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 60.320, mean reward: 0.603 [0.498, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.782, 10.163], loss: 0.001331, mae: 0.040198, mean_q: 1.167271
  81400/1000000: episode: 814, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.078, mean reward: 0.581 [0.497, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.710, 10.132], loss: 0.001338, mae: 0.040020, mean_q: 1.164180
  81500/1000000: episode: 815, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.190, mean reward: 0.572 [0.506, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.228, 10.098], loss: 0.001366, mae: 0.040466, mean_q: 1.164916
  81600/1000000: episode: 816, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.382, mean reward: 0.574 [0.506, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.959, 10.139], loss: 0.001332, mae: 0.040306, mean_q: 1.165062
  81700/1000000: episode: 817, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.645, mean reward: 0.586 [0.499, 0.898], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.925, 10.173], loss: 0.001296, mae: 0.040235, mean_q: 1.166493
  81800/1000000: episode: 818, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.693, mean reward: 0.587 [0.508, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.074, 10.254], loss: 0.001522, mae: 0.042298, mean_q: 1.165661
  81900/1000000: episode: 819, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.661, mean reward: 0.587 [0.512, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.517, 10.098], loss: 0.001423, mae: 0.040783, mean_q: 1.163904
  82000/1000000: episode: 820, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.273, mean reward: 0.603 [0.503, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.863, 10.148], loss: 0.001436, mae: 0.041161, mean_q: 1.163031
  82100/1000000: episode: 821, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.939, mean reward: 0.589 [0.514, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.658, 10.098], loss: 0.001337, mae: 0.039528, mean_q: 1.161566
  82200/1000000: episode: 822, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.942, mean reward: 0.589 [0.514, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.364, 10.098], loss: 0.001345, mae: 0.040423, mean_q: 1.161746
  82300/1000000: episode: 823, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.803, mean reward: 0.598 [0.511, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.771, 10.108], loss: 0.001386, mae: 0.040815, mean_q: 1.162621
  82400/1000000: episode: 824, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 63.650, mean reward: 0.636 [0.502, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.598, 10.243], loss: 0.001387, mae: 0.040544, mean_q: 1.164722
  82500/1000000: episode: 825, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.913, mean reward: 0.569 [0.499, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.744, 10.214], loss: 0.001396, mae: 0.041082, mean_q: 1.165968
  82600/1000000: episode: 826, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.942, mean reward: 0.579 [0.504, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.058, 10.146], loss: 0.001367, mae: 0.040254, mean_q: 1.166812
  82700/1000000: episode: 827, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 61.216, mean reward: 0.612 [0.507, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.349, 10.098], loss: 0.001403, mae: 0.040771, mean_q: 1.164095
  82800/1000000: episode: 828, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 57.736, mean reward: 0.577 [0.508, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.384, 10.123], loss: 0.001432, mae: 0.040926, mean_q: 1.163697
  82900/1000000: episode: 829, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.770, mean reward: 0.578 [0.498, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.143, 10.098], loss: 0.001367, mae: 0.040354, mean_q: 1.165249
  83000/1000000: episode: 830, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.030, mean reward: 0.600 [0.505, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.351, 10.133], loss: 0.001334, mae: 0.040012, mean_q: 1.166212
  83100/1000000: episode: 831, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.166, mean reward: 0.592 [0.500, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.299, 10.098], loss: 0.001432, mae: 0.041789, mean_q: 1.166863
  83200/1000000: episode: 832, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.215, mean reward: 0.592 [0.504, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.900, 10.270], loss: 0.001294, mae: 0.039247, mean_q: 1.165266
  83300/1000000: episode: 833, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.790, mean reward: 0.608 [0.507, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.335, 10.310], loss: 0.001427, mae: 0.041275, mean_q: 1.170309
  83400/1000000: episode: 834, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.722, mean reward: 0.577 [0.500, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.153, 10.110], loss: 0.001522, mae: 0.042724, mean_q: 1.168540
  83500/1000000: episode: 835, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 59.831, mean reward: 0.598 [0.511, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.229, 10.280], loss: 0.001388, mae: 0.040797, mean_q: 1.170619
  83600/1000000: episode: 836, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.976, mean reward: 0.580 [0.500, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.394, 10.098], loss: 0.001330, mae: 0.039735, mean_q: 1.169681
  83700/1000000: episode: 837, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.532, mean reward: 0.585 [0.506, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.928, 10.098], loss: 0.001321, mae: 0.039738, mean_q: 1.169747
  83800/1000000: episode: 838, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.225, mean reward: 0.592 [0.511, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.820, 10.291], loss: 0.001491, mae: 0.041920, mean_q: 1.165557
  83900/1000000: episode: 839, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 59.122, mean reward: 0.591 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.855, 10.104], loss: 0.001395, mae: 0.040775, mean_q: 1.165960
  84000/1000000: episode: 840, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.375, mean reward: 0.574 [0.512, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.018, 10.098], loss: 0.001424, mae: 0.041857, mean_q: 1.165317
  84100/1000000: episode: 841, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.025, mean reward: 0.580 [0.505, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.703, 10.338], loss: 0.001405, mae: 0.041668, mean_q: 1.166289
  84200/1000000: episode: 842, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.913, mean reward: 0.589 [0.504, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.749, 10.147], loss: 0.001528, mae: 0.043131, mean_q: 1.162519
  84300/1000000: episode: 843, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.885, mean reward: 0.589 [0.501, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.503, 10.137], loss: 0.001440, mae: 0.042212, mean_q: 1.164391
  84400/1000000: episode: 844, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 58.443, mean reward: 0.584 [0.501, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.844, 10.322], loss: 0.001314, mae: 0.040140, mean_q: 1.164832
  84500/1000000: episode: 845, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.829, mean reward: 0.598 [0.504, 0.854], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.196, 10.098], loss: 0.001410, mae: 0.041197, mean_q: 1.165517
  84600/1000000: episode: 846, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.263, mean reward: 0.583 [0.505, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.150, 10.098], loss: 0.001532, mae: 0.042684, mean_q: 1.164649
  84700/1000000: episode: 847, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 61.166, mean reward: 0.612 [0.505, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.239, 10.284], loss: 0.001562, mae: 0.044143, mean_q: 1.169090
  84800/1000000: episode: 848, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.432, mean reward: 0.604 [0.517, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.925, 10.098], loss: 0.001418, mae: 0.040957, mean_q: 1.168522
  84900/1000000: episode: 849, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.263, mean reward: 0.573 [0.507, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.187, 10.125], loss: 0.001384, mae: 0.040718, mean_q: 1.164429
  85000/1000000: episode: 850, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 61.418, mean reward: 0.614 [0.506, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.590, 10.431], loss: 0.001436, mae: 0.041740, mean_q: 1.165171
  85100/1000000: episode: 851, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.245, mean reward: 0.582 [0.506, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.803, 10.098], loss: 0.001527, mae: 0.042847, mean_q: 1.167593
  85200/1000000: episode: 852, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.480, mean reward: 0.575 [0.500, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.181, 10.098], loss: 0.001431, mae: 0.040933, mean_q: 1.161192
  85300/1000000: episode: 853, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.575, mean reward: 0.586 [0.516, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.402, 10.193], loss: 0.001507, mae: 0.042583, mean_q: 1.165405
  85400/1000000: episode: 854, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 60.271, mean reward: 0.603 [0.509, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.451, 10.418], loss: 0.001511, mae: 0.042217, mean_q: 1.165835
  85500/1000000: episode: 855, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.746, mean reward: 0.597 [0.503, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.971, 10.371], loss: 0.001507, mae: 0.042322, mean_q: 1.164753
  85600/1000000: episode: 856, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.564, mean reward: 0.596 [0.501, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.020, 10.144], loss: 0.001396, mae: 0.040533, mean_q: 1.165571
  85700/1000000: episode: 857, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.536, mean reward: 0.575 [0.500, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.100, 10.098], loss: 0.001462, mae: 0.041470, mean_q: 1.163526
  85800/1000000: episode: 858, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.695, mean reward: 0.587 [0.501, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.985, 10.367], loss: 0.001463, mae: 0.042162, mean_q: 1.163353
  85900/1000000: episode: 859, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.145, mean reward: 0.581 [0.510, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.938, 10.289], loss: 0.001459, mae: 0.041336, mean_q: 1.166804
  86000/1000000: episode: 860, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.169, mean reward: 0.592 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.267, 10.275], loss: 0.001399, mae: 0.040898, mean_q: 1.162698
  86100/1000000: episode: 861, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.510, mean reward: 0.575 [0.500, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.585, 10.186], loss: 0.001493, mae: 0.041977, mean_q: 1.163209
  86200/1000000: episode: 862, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.811, mean reward: 0.578 [0.506, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.692, 10.098], loss: 0.001456, mae: 0.041577, mean_q: 1.160881
  86300/1000000: episode: 863, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 64.041, mean reward: 0.640 [0.508, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.648, 10.527], loss: 0.001413, mae: 0.041322, mean_q: 1.164295
  86400/1000000: episode: 864, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 61.131, mean reward: 0.611 [0.510, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.882, 10.323], loss: 0.001445, mae: 0.040917, mean_q: 1.166753
  86500/1000000: episode: 865, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.034, mean reward: 0.580 [0.502, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.394, 10.241], loss: 0.001397, mae: 0.040982, mean_q: 1.166651
  86600/1000000: episode: 866, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.914, mean reward: 0.609 [0.515, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.619, 10.098], loss: 0.001396, mae: 0.040625, mean_q: 1.169100
  86700/1000000: episode: 867, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 67.126, mean reward: 0.671 [0.516, 0.869], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.602, 10.098], loss: 0.001492, mae: 0.041716, mean_q: 1.169530
  86800/1000000: episode: 868, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.259, mean reward: 0.573 [0.500, 0.670], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.884, 10.187], loss: 0.001600, mae: 0.043032, mean_q: 1.170193
  86900/1000000: episode: 869, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 55.971, mean reward: 0.560 [0.499, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.183, 10.098], loss: 0.001502, mae: 0.042459, mean_q: 1.172864
  87000/1000000: episode: 870, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.028, mean reward: 0.580 [0.502, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.048, 10.159], loss: 0.001394, mae: 0.040826, mean_q: 1.167466
  87100/1000000: episode: 871, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.536, mean reward: 0.595 [0.500, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.605, 10.244], loss: 0.001556, mae: 0.042826, mean_q: 1.170348
  87200/1000000: episode: 872, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 62.736, mean reward: 0.627 [0.532, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.786, 10.449], loss: 0.001509, mae: 0.042616, mean_q: 1.173450
  87300/1000000: episode: 873, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.469, mean reward: 0.585 [0.502, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.929, 10.133], loss: 0.001387, mae: 0.040365, mean_q: 1.169848
  87400/1000000: episode: 874, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.504, mean reward: 0.585 [0.501, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.765, 10.236], loss: 0.001514, mae: 0.042160, mean_q: 1.171322
  87500/1000000: episode: 875, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.991, mean reward: 0.590 [0.500, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.357, 10.346], loss: 0.001510, mae: 0.042776, mean_q: 1.169199
  87600/1000000: episode: 876, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.955, mean reward: 0.590 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.825, 10.193], loss: 0.001564, mae: 0.043296, mean_q: 1.172069
  87700/1000000: episode: 877, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.306, mean reward: 0.583 [0.505, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.630, 10.299], loss: 0.001479, mae: 0.041923, mean_q: 1.167109
  87800/1000000: episode: 878, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 67.045, mean reward: 0.670 [0.517, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.315, 10.098], loss: 0.001418, mae: 0.041004, mean_q: 1.169085
  87900/1000000: episode: 879, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.901, mean reward: 0.589 [0.503, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.705, 10.118], loss: 0.001419, mae: 0.040845, mean_q: 1.173644
  88000/1000000: episode: 880, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.229, mean reward: 0.582 [0.503, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.442, 10.098], loss: 0.001354, mae: 0.040667, mean_q: 1.173972
  88100/1000000: episode: 881, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.010, mean reward: 0.600 [0.509, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.439, 10.161], loss: 0.001382, mae: 0.040646, mean_q: 1.171866
  88200/1000000: episode: 882, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.168, mean reward: 0.572 [0.510, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.219, 10.116], loss: 0.001426, mae: 0.041283, mean_q: 1.171849
  88300/1000000: episode: 883, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.379, mean reward: 0.584 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.575, 10.166], loss: 0.001414, mae: 0.040957, mean_q: 1.169577
  88400/1000000: episode: 884, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.358, mean reward: 0.624 [0.499, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.767, 10.155], loss: 0.001698, mae: 0.043805, mean_q: 1.173231
  88500/1000000: episode: 885, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.620, mean reward: 0.576 [0.516, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.460, 10.311], loss: 0.001432, mae: 0.041133, mean_q: 1.174708
  88600/1000000: episode: 886, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.299, mean reward: 0.583 [0.506, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.781, 10.098], loss: 0.001501, mae: 0.041896, mean_q: 1.173536
  88700/1000000: episode: 887, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.878, mean reward: 0.579 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.922, 10.137], loss: 0.001453, mae: 0.041958, mean_q: 1.172146
  88800/1000000: episode: 888, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 59.159, mean reward: 0.592 [0.515, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.745, 10.098], loss: 0.001548, mae: 0.042689, mean_q: 1.173705
  88900/1000000: episode: 889, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.205, mean reward: 0.582 [0.513, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.071, 10.098], loss: 0.001363, mae: 0.040922, mean_q: 1.172814
  89000/1000000: episode: 890, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.633, mean reward: 0.586 [0.507, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.286, 10.167], loss: 0.001481, mae: 0.041381, mean_q: 1.170560
  89100/1000000: episode: 891, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 60.583, mean reward: 0.606 [0.505, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.752, 10.098], loss: 0.001410, mae: 0.040999, mean_q: 1.173037
  89200/1000000: episode: 892, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.479, mean reward: 0.575 [0.504, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.411, 10.170], loss: 0.001408, mae: 0.040771, mean_q: 1.169272
  89300/1000000: episode: 893, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.824, mean reward: 0.598 [0.517, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.582, 10.098], loss: 0.001512, mae: 0.042436, mean_q: 1.171926
  89400/1000000: episode: 894, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.354, mean reward: 0.594 [0.509, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.757, 10.098], loss: 0.001333, mae: 0.039883, mean_q: 1.171260
  89500/1000000: episode: 895, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.918, mean reward: 0.589 [0.505, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.653, 10.098], loss: 0.001323, mae: 0.040289, mean_q: 1.169140
  89600/1000000: episode: 896, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.769, mean reward: 0.608 [0.508, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.461, 10.098], loss: 0.001255, mae: 0.039021, mean_q: 1.173222
  89700/1000000: episode: 897, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.592, mean reward: 0.596 [0.497, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.387, 10.098], loss: 0.001524, mae: 0.042797, mean_q: 1.172210
  89800/1000000: episode: 898, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.620, mean reward: 0.586 [0.505, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.211, 10.098], loss: 0.001315, mae: 0.039766, mean_q: 1.169234
  89900/1000000: episode: 899, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.466, mean reward: 0.575 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.328, 10.098], loss: 0.001452, mae: 0.041637, mean_q: 1.171565
  90000/1000000: episode: 900, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.700, mean reward: 0.577 [0.512, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.426, 10.098], loss: 0.001464, mae: 0.041713, mean_q: 1.173588
  90100/1000000: episode: 901, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 56.627, mean reward: 0.566 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.795, 10.098], loss: 0.001439, mae: 0.041116, mean_q: 1.174352
  90200/1000000: episode: 902, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 57.526, mean reward: 0.575 [0.508, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.436, 10.098], loss: 0.001349, mae: 0.040172, mean_q: 1.172118
  90300/1000000: episode: 903, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.778, mean reward: 0.578 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.634, 10.108], loss: 0.001456, mae: 0.042067, mean_q: 1.169295
  90400/1000000: episode: 904, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.989, mean reward: 0.590 [0.508, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.190, 10.257], loss: 0.001417, mae: 0.041359, mean_q: 1.165275
  90500/1000000: episode: 905, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.111, mean reward: 0.571 [0.509, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.737, 10.197], loss: 0.001369, mae: 0.040560, mean_q: 1.169702
  90600/1000000: episode: 906, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.132, mean reward: 0.571 [0.501, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.603, 10.215], loss: 0.001405, mae: 0.041219, mean_q: 1.167792
  90700/1000000: episode: 907, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.379, mean reward: 0.574 [0.499, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.862, 10.098], loss: 0.001428, mae: 0.041381, mean_q: 1.166507
  90800/1000000: episode: 908, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 59.603, mean reward: 0.596 [0.510, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.121, 10.166], loss: 0.001489, mae: 0.042473, mean_q: 1.168775
  90900/1000000: episode: 909, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.770, mean reward: 0.598 [0.513, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.818, 10.433], loss: 0.001416, mae: 0.041192, mean_q: 1.171019
  91000/1000000: episode: 910, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.927, mean reward: 0.589 [0.505, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.379, 10.098], loss: 0.001422, mae: 0.041239, mean_q: 1.171869
  91100/1000000: episode: 911, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.368, mean reward: 0.574 [0.499, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.769, 10.100], loss: 0.001376, mae: 0.040594, mean_q: 1.168331
  91200/1000000: episode: 912, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 63.586, mean reward: 0.636 [0.517, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.651, 10.387], loss: 0.001469, mae: 0.041702, mean_q: 1.169137
  91300/1000000: episode: 913, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.553, mean reward: 0.586 [0.506, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.001, 10.098], loss: 0.001547, mae: 0.042946, mean_q: 1.168517
  91400/1000000: episode: 914, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.067, mean reward: 0.591 [0.501, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.292, 10.098], loss: 0.001524, mae: 0.042738, mean_q: 1.171041
  91500/1000000: episode: 915, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.112, mean reward: 0.591 [0.508, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.086, 10.098], loss: 0.001468, mae: 0.041866, mean_q: 1.169472
  91600/1000000: episode: 916, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 60.819, mean reward: 0.608 [0.499, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.698, 10.383], loss: 0.001569, mae: 0.042600, mean_q: 1.170287
  91700/1000000: episode: 917, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.438, mean reward: 0.584 [0.512, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.028, 10.304], loss: 0.001466, mae: 0.042075, mean_q: 1.165795
  91800/1000000: episode: 918, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.276, mean reward: 0.573 [0.502, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.778, 10.253], loss: 0.001500, mae: 0.042140, mean_q: 1.165433
  91900/1000000: episode: 919, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.917, mean reward: 0.579 [0.506, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.416, 10.098], loss: 0.001483, mae: 0.041954, mean_q: 1.165795
  92000/1000000: episode: 920, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.058, mean reward: 0.591 [0.504, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.942, 10.168], loss: 0.001424, mae: 0.041700, mean_q: 1.164316
  92100/1000000: episode: 921, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 64.214, mean reward: 0.642 [0.506, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.186, 10.404], loss: 0.001391, mae: 0.040798, mean_q: 1.165448
  92200/1000000: episode: 922, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.289, mean reward: 0.593 [0.506, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.781, 10.098], loss: 0.001431, mae: 0.040795, mean_q: 1.166760
  92300/1000000: episode: 923, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 58.432, mean reward: 0.584 [0.509, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.560, 10.174], loss: 0.001484, mae: 0.042150, mean_q: 1.168238
  92400/1000000: episode: 924, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 61.027, mean reward: 0.610 [0.506, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.777, 10.341], loss: 0.001365, mae: 0.039850, mean_q: 1.167170
  92500/1000000: episode: 925, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.305, mean reward: 0.573 [0.505, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.275, 10.123], loss: 0.001545, mae: 0.043089, mean_q: 1.164638
  92600/1000000: episode: 926, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 56.253, mean reward: 0.563 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.806, 10.098], loss: 0.001531, mae: 0.042424, mean_q: 1.164231
  92700/1000000: episode: 927, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.294, mean reward: 0.583 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.115, 10.293], loss: 0.001466, mae: 0.041716, mean_q: 1.165116
  92800/1000000: episode: 928, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.530, mean reward: 0.585 [0.497, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.375, 10.215], loss: 0.001441, mae: 0.041645, mean_q: 1.162705
  92900/1000000: episode: 929, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 56.965, mean reward: 0.570 [0.503, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.851, 10.232], loss: 0.001419, mae: 0.041525, mean_q: 1.162905
  93000/1000000: episode: 930, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 64.100, mean reward: 0.641 [0.506, 0.881], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.875, 10.385], loss: 0.001337, mae: 0.039792, mean_q: 1.159965
  93100/1000000: episode: 931, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.731, mean reward: 0.587 [0.501, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.708, 10.148], loss: 0.001556, mae: 0.042340, mean_q: 1.162788
  93200/1000000: episode: 932, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 62.116, mean reward: 0.621 [0.516, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.420, 10.393], loss: 0.001344, mae: 0.040589, mean_q: 1.162868
  93300/1000000: episode: 933, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.291, mean reward: 0.613 [0.516, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.883, 10.209], loss: 0.001459, mae: 0.041835, mean_q: 1.165298
  93400/1000000: episode: 934, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.635, mean reward: 0.596 [0.503, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.718, 10.154], loss: 0.001463, mae: 0.042113, mean_q: 1.163141
  93500/1000000: episode: 935, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.428, mean reward: 0.594 [0.509, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.187, 10.270], loss: 0.001583, mae: 0.043665, mean_q: 1.165698
  93600/1000000: episode: 936, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.778, mean reward: 0.598 [0.506, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.946, 10.098], loss: 0.001454, mae: 0.041258, mean_q: 1.166333
  93700/1000000: episode: 937, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.980, mean reward: 0.590 [0.509, 0.864], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.425, 10.323], loss: 0.001435, mae: 0.041114, mean_q: 1.168954
  93800/1000000: episode: 938, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 57.278, mean reward: 0.573 [0.500, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.647, 10.115], loss: 0.001373, mae: 0.040608, mean_q: 1.165082
  93900/1000000: episode: 939, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.208, mean reward: 0.572 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.429, 10.109], loss: 0.001411, mae: 0.041233, mean_q: 1.168363
  94000/1000000: episode: 940, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.329, mean reward: 0.593 [0.510, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.529, 10.156], loss: 0.001388, mae: 0.040740, mean_q: 1.165691
  94100/1000000: episode: 941, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.062, mean reward: 0.571 [0.499, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.292, 10.167], loss: 0.001488, mae: 0.042271, mean_q: 1.167307
  94200/1000000: episode: 942, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.003, mean reward: 0.570 [0.507, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.880, 10.127], loss: 0.001497, mae: 0.042811, mean_q: 1.166609
  94300/1000000: episode: 943, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 62.774, mean reward: 0.628 [0.502, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.468, 10.336], loss: 0.001505, mae: 0.041772, mean_q: 1.166235
  94400/1000000: episode: 944, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.590, mean reward: 0.596 [0.501, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.706, 10.317], loss: 0.001549, mae: 0.043191, mean_q: 1.167027
  94500/1000000: episode: 945, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.562, mean reward: 0.576 [0.511, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.457, 10.283], loss: 0.001488, mae: 0.042043, mean_q: 1.168809
  94600/1000000: episode: 946, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.009, mean reward: 0.570 [0.503, 0.663], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.691, 10.165], loss: 0.001423, mae: 0.040613, mean_q: 1.159546
  94700/1000000: episode: 947, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.467, mean reward: 0.575 [0.506, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.456, 10.098], loss: 0.001443, mae: 0.041402, mean_q: 1.162464
  94800/1000000: episode: 948, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.369, mean reward: 0.604 [0.505, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.952, 10.337], loss: 0.001438, mae: 0.040794, mean_q: 1.162654
  94900/1000000: episode: 949, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.891, mean reward: 0.579 [0.504, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.081, 10.174], loss: 0.001459, mae: 0.041526, mean_q: 1.164457
  95000/1000000: episode: 950, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.758, mean reward: 0.578 [0.503, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.361, 10.098], loss: 0.001412, mae: 0.041449, mean_q: 1.164363
  95100/1000000: episode: 951, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.087, mean reward: 0.581 [0.504, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.235, 10.098], loss: 0.001480, mae: 0.041482, mean_q: 1.162050
  95200/1000000: episode: 952, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.865, mean reward: 0.579 [0.508, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.772, 10.182], loss: 0.001421, mae: 0.041093, mean_q: 1.166896
  95300/1000000: episode: 953, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.030, mean reward: 0.600 [0.513, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.220, 10.145], loss: 0.001470, mae: 0.041809, mean_q: 1.162999
  95400/1000000: episode: 954, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 59.632, mean reward: 0.596 [0.516, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.619, 10.304], loss: 0.001500, mae: 0.042152, mean_q: 1.163400
  95500/1000000: episode: 955, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.984, mean reward: 0.580 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.112, 10.140], loss: 0.001451, mae: 0.041069, mean_q: 1.166268
  95600/1000000: episode: 956, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.256, mean reward: 0.603 [0.505, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.509, 10.213], loss: 0.001476, mae: 0.041468, mean_q: 1.165516
  95700/1000000: episode: 957, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.922, mean reward: 0.579 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.314, 10.286], loss: 0.001478, mae: 0.042198, mean_q: 1.168732
  95800/1000000: episode: 958, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.696, mean reward: 0.597 [0.507, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.984, 10.098], loss: 0.001436, mae: 0.041955, mean_q: 1.169915
  95900/1000000: episode: 959, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.894, mean reward: 0.619 [0.501, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.366, 10.098], loss: 0.001505, mae: 0.042106, mean_q: 1.167263
  96000/1000000: episode: 960, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 65.559, mean reward: 0.656 [0.497, 0.889], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.919, 10.117], loss: 0.001468, mae: 0.041935, mean_q: 1.169968
  96100/1000000: episode: 961, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.059, mean reward: 0.581 [0.503, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.830, 10.198], loss: 0.001618, mae: 0.043548, mean_q: 1.174644
  96200/1000000: episode: 962, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 56.892, mean reward: 0.569 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.939, 10.098], loss: 0.001443, mae: 0.041278, mean_q: 1.165005
  96300/1000000: episode: 963, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.433, mean reward: 0.564 [0.502, 0.656], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.130, 10.228], loss: 0.001501, mae: 0.042021, mean_q: 1.166224
  96400/1000000: episode: 964, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.505, mean reward: 0.585 [0.511, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.187, 10.288], loss: 0.001441, mae: 0.041837, mean_q: 1.167829
  96500/1000000: episode: 965, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.255, mean reward: 0.573 [0.506, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.560, 10.209], loss: 0.001555, mae: 0.042860, mean_q: 1.168888
  96600/1000000: episode: 966, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.348, mean reward: 0.583 [0.503, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.864, 10.389], loss: 0.001514, mae: 0.042217, mean_q: 1.166544
  96700/1000000: episode: 967, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.242, mean reward: 0.592 [0.506, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.617, 10.098], loss: 0.001523, mae: 0.043210, mean_q: 1.166587
  96800/1000000: episode: 968, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.578, mean reward: 0.586 [0.510, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.013, 10.098], loss: 0.001562, mae: 0.042866, mean_q: 1.166669
  96900/1000000: episode: 969, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.708, mean reward: 0.597 [0.499, 0.870], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.778, 10.260], loss: 0.001423, mae: 0.041241, mean_q: 1.168260
  97000/1000000: episode: 970, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.836, mean reward: 0.588 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.547, 10.191], loss: 0.001484, mae: 0.041621, mean_q: 1.168293
  97100/1000000: episode: 971, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.419, mean reward: 0.594 [0.503, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.170, 10.098], loss: 0.001609, mae: 0.042982, mean_q: 1.162755
  97200/1000000: episode: 972, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.462, mean reward: 0.615 [0.509, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.216, 10.098], loss: 0.001577, mae: 0.043939, mean_q: 1.165952
  97300/1000000: episode: 973, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.319, mean reward: 0.593 [0.510, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.900, 10.098], loss: 0.001553, mae: 0.042847, mean_q: 1.162522
  97400/1000000: episode: 974, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.188, mean reward: 0.592 [0.511, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.787, 10.098], loss: 0.001505, mae: 0.042668, mean_q: 1.165851
  97500/1000000: episode: 975, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.818, mean reward: 0.588 [0.501, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.955, 10.134], loss: 0.001632, mae: 0.043927, mean_q: 1.166605
  97600/1000000: episode: 976, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.321, mean reward: 0.583 [0.511, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.460, 10.202], loss: 0.001484, mae: 0.042034, mean_q: 1.164367
  97700/1000000: episode: 977, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.881, mean reward: 0.589 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.676, 10.291], loss: 0.001626, mae: 0.043811, mean_q: 1.168394
  97800/1000000: episode: 978, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.105, mean reward: 0.581 [0.498, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.352, 10.110], loss: 0.001754, mae: 0.044257, mean_q: 1.166416
  97900/1000000: episode: 979, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.079, mean reward: 0.581 [0.500, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-2.002, 10.098], loss: 0.001546, mae: 0.043130, mean_q: 1.164849
  98000/1000000: episode: 980, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.158, mean reward: 0.592 [0.501, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.498, 10.162], loss: 0.001513, mae: 0.042435, mean_q: 1.165000
  98100/1000000: episode: 981, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.701, mean reward: 0.587 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.324, 10.098], loss: 0.001695, mae: 0.044049, mean_q: 1.168612
  98200/1000000: episode: 982, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.390, mean reward: 0.574 [0.506, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.107, 10.098], loss: 0.001553, mae: 0.043171, mean_q: 1.163551
  98300/1000000: episode: 983, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.398, mean reward: 0.584 [0.505, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.484, 10.098], loss: 0.001410, mae: 0.040785, mean_q: 1.160749
  98400/1000000: episode: 984, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.692, mean reward: 0.587 [0.502, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.508, 10.180], loss: 0.001537, mae: 0.043248, mean_q: 1.161779
  98500/1000000: episode: 985, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.032, mean reward: 0.590 [0.502, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.426, 10.248], loss: 0.001463, mae: 0.040779, mean_q: 1.160651
  98600/1000000: episode: 986, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 56.637, mean reward: 0.566 [0.499, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.358, 10.098], loss: 0.001474, mae: 0.041395, mean_q: 1.157179
  98700/1000000: episode: 987, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.951, mean reward: 0.590 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.874, 10.098], loss: 0.001549, mae: 0.043046, mean_q: 1.160057
  98800/1000000: episode: 988, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.703, mean reward: 0.577 [0.498, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.911, 10.138], loss: 0.001528, mae: 0.042219, mean_q: 1.164111
  98900/1000000: episode: 989, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.149, mean reward: 0.611 [0.522, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.900, 10.098], loss: 0.001535, mae: 0.042774, mean_q: 1.160132
  99000/1000000: episode: 990, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 56.307, mean reward: 0.563 [0.511, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.578, 10.138], loss: 0.001578, mae: 0.042937, mean_q: 1.162036
  99100/1000000: episode: 991, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 61.528, mean reward: 0.615 [0.516, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.573, 10.098], loss: 0.001537, mae: 0.042166, mean_q: 1.164764
  99200/1000000: episode: 992, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.223, mean reward: 0.572 [0.507, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.257, 10.148], loss: 0.001576, mae: 0.043232, mean_q: 1.163994
  99300/1000000: episode: 993, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.044, mean reward: 0.590 [0.507, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.641, 10.098], loss: 0.001476, mae: 0.042155, mean_q: 1.164502
  99400/1000000: episode: 994, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.597, mean reward: 0.576 [0.499, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.883, 10.272], loss: 0.001481, mae: 0.042030, mean_q: 1.161821
  99500/1000000: episode: 995, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.577, mean reward: 0.586 [0.501, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.965, 10.098], loss: 0.001585, mae: 0.042865, mean_q: 1.162918
  99600/1000000: episode: 996, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.075, mean reward: 0.591 [0.507, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.223, 10.098], loss: 0.001506, mae: 0.041813, mean_q: 1.164194
  99700/1000000: episode: 997, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.896, mean reward: 0.599 [0.510, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.572, 10.098], loss: 0.001551, mae: 0.042954, mean_q: 1.163877
  99800/1000000: episode: 998, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 60.885, mean reward: 0.609 [0.517, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.596, 10.320], loss: 0.001518, mae: 0.042887, mean_q: 1.166194
  99900/1000000: episode: 999, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.023, mean reward: 0.600 [0.502, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.642, 10.098], loss: 0.001605, mae: 0.043660, mean_q: 1.165345
 100000/1000000: episode: 1000, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.273, mean reward: 0.593 [0.503, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.559, 10.156], loss: 0.001543, mae: 0.042235, mean_q: 1.167379
 100100/1000000: episode: 1001, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.503, mean reward: 0.585 [0.505, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.559, 10.110], loss: 0.001547, mae: 0.042845, mean_q: 1.169657
 100200/1000000: episode: 1002, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.990, mean reward: 0.580 [0.508, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.627, 10.098], loss: 0.001539, mae: 0.042314, mean_q: 1.163079
 100300/1000000: episode: 1003, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.474, mean reward: 0.565 [0.502, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.722, 10.098], loss: 0.001459, mae: 0.041278, mean_q: 1.161239
 100400/1000000: episode: 1004, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.165, mean reward: 0.572 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.518, 10.377], loss: 0.001515, mae: 0.042590, mean_q: 1.165586
 100500/1000000: episode: 1005, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.272, mean reward: 0.593 [0.507, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.403, 10.257], loss: 0.001613, mae: 0.043822, mean_q: 1.165203
 100600/1000000: episode: 1006, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.925, mean reward: 0.599 [0.513, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.556, 10.098], loss: 0.001410, mae: 0.041140, mean_q: 1.161205
 100700/1000000: episode: 1007, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.353, mean reward: 0.614 [0.506, 0.899], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.693, 10.098], loss: 0.001507, mae: 0.042512, mean_q: 1.162487
 100800/1000000: episode: 1008, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.764, mean reward: 0.598 [0.505, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.604, 10.382], loss: 0.001648, mae: 0.043850, mean_q: 1.162350
 100900/1000000: episode: 1009, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.166, mean reward: 0.582 [0.499, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.130, 10.098], loss: 0.001485, mae: 0.042268, mean_q: 1.163297
 101000/1000000: episode: 1010, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.598, mean reward: 0.596 [0.513, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.546, 10.098], loss: 0.001432, mae: 0.040622, mean_q: 1.160726
 101100/1000000: episode: 1011, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.097, mean reward: 0.581 [0.510, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.373, 10.098], loss: 0.001482, mae: 0.041943, mean_q: 1.162733
 101200/1000000: episode: 1012, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 62.077, mean reward: 0.621 [0.526, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.155, 10.462], loss: 0.001506, mae: 0.042273, mean_q: 1.162808
 101300/1000000: episode: 1013, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.833, mean reward: 0.608 [0.510, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.957, 10.380], loss: 0.001457, mae: 0.041440, mean_q: 1.162630
 101400/1000000: episode: 1014, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.207, mean reward: 0.582 [0.502, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.854, 10.124], loss: 0.001511, mae: 0.041979, mean_q: 1.166116
 101500/1000000: episode: 1015, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 56.421, mean reward: 0.564 [0.510, 0.646], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.341, 10.098], loss: 0.001423, mae: 0.040734, mean_q: 1.163071
 101600/1000000: episode: 1016, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.454, mean reward: 0.585 [0.499, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.745, 10.098], loss: 0.001546, mae: 0.042386, mean_q: 1.163702
 101700/1000000: episode: 1017, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.494, mean reward: 0.585 [0.506, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.907, 10.133], loss: 0.001440, mae: 0.041124, mean_q: 1.161332
 101800/1000000: episode: 1018, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.692, mean reward: 0.577 [0.500, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.040, 10.098], loss: 0.001479, mae: 0.041438, mean_q: 1.157626
 101900/1000000: episode: 1019, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.622, mean reward: 0.586 [0.499, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.585, 10.404], loss: 0.001453, mae: 0.041841, mean_q: 1.162033
 102000/1000000: episode: 1020, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 63.096, mean reward: 0.631 [0.502, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.403, 10.362], loss: 0.001462, mae: 0.042210, mean_q: 1.165068
 102100/1000000: episode: 1021, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.852, mean reward: 0.599 [0.500, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.317, 10.098], loss: 0.001569, mae: 0.043149, mean_q: 1.166442
 102200/1000000: episode: 1022, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.977, mean reward: 0.580 [0.508, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.847, 10.164], loss: 0.001434, mae: 0.041143, mean_q: 1.164094
 102300/1000000: episode: 1023, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 56.968, mean reward: 0.570 [0.507, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.573, 10.098], loss: 0.001552, mae: 0.042485, mean_q: 1.163672
 102400/1000000: episode: 1024, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.217, mean reward: 0.572 [0.508, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.199, 10.196], loss: 0.001425, mae: 0.041187, mean_q: 1.161411
 102500/1000000: episode: 1025, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.937, mean reward: 0.599 [0.505, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.031, 10.412], loss: 0.001317, mae: 0.039472, mean_q: 1.162473
 102600/1000000: episode: 1026, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 57.944, mean reward: 0.579 [0.505, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.283, 10.098], loss: 0.001472, mae: 0.041549, mean_q: 1.163348
 102700/1000000: episode: 1027, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.142, mean reward: 0.571 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.844, 10.124], loss: 0.001453, mae: 0.041622, mean_q: 1.161365
 102800/1000000: episode: 1028, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.010, mean reward: 0.590 [0.504, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.991, 10.098], loss: 0.001412, mae: 0.040750, mean_q: 1.159120
 102900/1000000: episode: 1029, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 62.269, mean reward: 0.623 [0.508, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.367, 10.266], loss: 0.001523, mae: 0.042442, mean_q: 1.161361
 103000/1000000: episode: 1030, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.496, mean reward: 0.595 [0.512, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.120, 10.216], loss: 0.001568, mae: 0.043357, mean_q: 1.163125
 103100/1000000: episode: 1031, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.724, mean reward: 0.587 [0.507, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.694, 10.124], loss: 0.001353, mae: 0.039730, mean_q: 1.161698
 103200/1000000: episode: 1032, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.227, mean reward: 0.572 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.366, 10.142], loss: 0.001414, mae: 0.041170, mean_q: 1.165994
 103300/1000000: episode: 1033, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.037, mean reward: 0.580 [0.500, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.044, 10.219], loss: 0.001399, mae: 0.040352, mean_q: 1.166753
 103400/1000000: episode: 1034, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 56.061, mean reward: 0.561 [0.499, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.811, 10.137], loss: 0.001515, mae: 0.042878, mean_q: 1.167508
 103500/1000000: episode: 1035, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.383, mean reward: 0.584 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.159, 10.098], loss: 0.001501, mae: 0.042406, mean_q: 1.162147
 103600/1000000: episode: 1036, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.742, mean reward: 0.577 [0.499, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.098, 10.098], loss: 0.001612, mae: 0.043722, mean_q: 1.162310
 103700/1000000: episode: 1037, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.112, mean reward: 0.571 [0.497, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.525, 10.277], loss: 0.001344, mae: 0.040739, mean_q: 1.160795
 103800/1000000: episode: 1038, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.606, mean reward: 0.596 [0.517, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.169, 10.098], loss: 0.001427, mae: 0.041202, mean_q: 1.162587
 103900/1000000: episode: 1039, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.431, mean reward: 0.594 [0.512, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.437, 10.210], loss: 0.001428, mae: 0.040878, mean_q: 1.162881
 104000/1000000: episode: 1040, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.334, mean reward: 0.583 [0.501, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.581, 10.123], loss: 0.001387, mae: 0.040872, mean_q: 1.162300
 104100/1000000: episode: 1041, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.775, mean reward: 0.588 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.282, 10.175], loss: 0.001352, mae: 0.040229, mean_q: 1.158521
 104200/1000000: episode: 1042, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.617, mean reward: 0.596 [0.503, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.574, 10.363], loss: 0.001415, mae: 0.040497, mean_q: 1.162732
 104300/1000000: episode: 1043, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.483, mean reward: 0.605 [0.511, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.959, 10.415], loss: 0.001414, mae: 0.041090, mean_q: 1.161552
 104400/1000000: episode: 1044, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.785, mean reward: 0.588 [0.506, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.065, 10.312], loss: 0.001397, mae: 0.040610, mean_q: 1.167224
 104500/1000000: episode: 1045, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.423, mean reward: 0.574 [0.501, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.388, 10.098], loss: 0.001341, mae: 0.040383, mean_q: 1.166756
 104600/1000000: episode: 1046, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.364, mean reward: 0.574 [0.503, 0.667], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.243, 10.123], loss: 0.001742, mae: 0.044428, mean_q: 1.163383
 104700/1000000: episode: 1047, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.647, mean reward: 0.586 [0.499, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.235, 10.310], loss: 0.001526, mae: 0.042355, mean_q: 1.159673
 104800/1000000: episode: 1048, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.403, mean reward: 0.614 [0.506, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.507, 10.098], loss: 0.001327, mae: 0.040228, mean_q: 1.163312
 104900/1000000: episode: 1049, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.840, mean reward: 0.588 [0.513, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.006, 10.179], loss: 0.001296, mae: 0.039628, mean_q: 1.161610
 105000/1000000: episode: 1050, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.288, mean reward: 0.613 [0.518, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.362, 10.098], loss: 0.001609, mae: 0.042589, mean_q: 1.163519
 105100/1000000: episode: 1051, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.848, mean reward: 0.588 [0.500, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.031, 10.098], loss: 0.001589, mae: 0.043097, mean_q: 1.159270
 105200/1000000: episode: 1052, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.105, mean reward: 0.601 [0.514, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.307, 10.363], loss: 0.001358, mae: 0.040366, mean_q: 1.163481
 105300/1000000: episode: 1053, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.227, mean reward: 0.602 [0.498, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.036, 10.098], loss: 0.001275, mae: 0.039133, mean_q: 1.163375
 105400/1000000: episode: 1054, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 62.212, mean reward: 0.622 [0.506, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.689, 10.379], loss: 0.001299, mae: 0.039197, mean_q: 1.166699
 105500/1000000: episode: 1055, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.732, mean reward: 0.577 [0.502, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.488, 10.098], loss: 0.001375, mae: 0.040325, mean_q: 1.165943
 105600/1000000: episode: 1056, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.933, mean reward: 0.589 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.378, 10.296], loss: 0.001337, mae: 0.039927, mean_q: 1.166343
 105700/1000000: episode: 1057, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 57.742, mean reward: 0.577 [0.503, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.925, 10.098], loss: 0.001275, mae: 0.039489, mean_q: 1.168507
 105800/1000000: episode: 1058, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.495, mean reward: 0.595 [0.509, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.468, 10.141], loss: 0.001294, mae: 0.039235, mean_q: 1.160683
 105900/1000000: episode: 1059, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.464, mean reward: 0.575 [0.506, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.764, 10.098], loss: 0.001368, mae: 0.040881, mean_q: 1.163911
 106000/1000000: episode: 1060, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.795, mean reward: 0.598 [0.508, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.716, 10.292], loss: 0.001341, mae: 0.040233, mean_q: 1.166466
 106100/1000000: episode: 1061, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.425, mean reward: 0.594 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.540, 10.109], loss: 0.001303, mae: 0.039511, mean_q: 1.163031
 106200/1000000: episode: 1062, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.452, mean reward: 0.575 [0.500, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.692, 10.098], loss: 0.001332, mae: 0.040064, mean_q: 1.160828
 106300/1000000: episode: 1063, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.188, mean reward: 0.592 [0.501, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.700, 10.108], loss: 0.001254, mae: 0.039022, mean_q: 1.162908
 106400/1000000: episode: 1064, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.376, mean reward: 0.574 [0.507, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.688, 10.141], loss: 0.001259, mae: 0.038941, mean_q: 1.160740
 106500/1000000: episode: 1065, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.954, mean reward: 0.600 [0.498, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.525, 10.111], loss: 0.001305, mae: 0.039167, mean_q: 1.158977
 106600/1000000: episode: 1066, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 61.868, mean reward: 0.619 [0.519, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.749, 10.373], loss: 0.001277, mae: 0.039138, mean_q: 1.163452
 106700/1000000: episode: 1067, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.916, mean reward: 0.599 [0.519, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.334, 10.102], loss: 0.001256, mae: 0.038949, mean_q: 1.164757
 106800/1000000: episode: 1068, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.372, mean reward: 0.594 [0.518, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.588, 10.098], loss: 0.001407, mae: 0.040566, mean_q: 1.164642
 106900/1000000: episode: 1069, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 62.297, mean reward: 0.623 [0.506, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.598, 10.098], loss: 0.001360, mae: 0.040950, mean_q: 1.164117
 107000/1000000: episode: 1070, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.958, mean reward: 0.580 [0.509, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.468, 10.160], loss: 0.001470, mae: 0.041986, mean_q: 1.167325
 107100/1000000: episode: 1071, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 62.048, mean reward: 0.620 [0.501, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.788, 10.098], loss: 0.001401, mae: 0.040471, mean_q: 1.161073
 107200/1000000: episode: 1072, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.096, mean reward: 0.581 [0.503, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.647, 10.098], loss: 0.001420, mae: 0.041340, mean_q: 1.169192
 107300/1000000: episode: 1073, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.017, mean reward: 0.570 [0.506, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.270, 10.275], loss: 0.001363, mae: 0.040546, mean_q: 1.167427
 107400/1000000: episode: 1074, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.222, mean reward: 0.582 [0.505, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.442, 10.098], loss: 0.001321, mae: 0.039558, mean_q: 1.169411
 107500/1000000: episode: 1075, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.277, mean reward: 0.593 [0.506, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.003, 10.098], loss: 0.001320, mae: 0.039930, mean_q: 1.167580
 107600/1000000: episode: 1076, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 61.016, mean reward: 0.610 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.311, 10.098], loss: 0.001452, mae: 0.041639, mean_q: 1.166791
 107700/1000000: episode: 1077, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.711, mean reward: 0.607 [0.503, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.477, 10.301], loss: 0.001352, mae: 0.040212, mean_q: 1.172412
 107800/1000000: episode: 1078, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.791, mean reward: 0.598 [0.509, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.056, 10.186], loss: 0.001385, mae: 0.040707, mean_q: 1.170079
 107900/1000000: episode: 1079, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.009, mean reward: 0.570 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.736, 10.098], loss: 0.001382, mae: 0.040572, mean_q: 1.173596
 108000/1000000: episode: 1080, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.935, mean reward: 0.589 [0.503, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.669, 10.148], loss: 0.001380, mae: 0.040580, mean_q: 1.169523
 108100/1000000: episode: 1081, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.257, mean reward: 0.583 [0.501, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.496, 10.184], loss: 0.001329, mae: 0.039913, mean_q: 1.168471
 108200/1000000: episode: 1082, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 56.496, mean reward: 0.565 [0.505, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.860, 10.098], loss: 0.001385, mae: 0.040706, mean_q: 1.167970
 108300/1000000: episode: 1083, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.413, mean reward: 0.594 [0.520, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.163, 10.098], loss: 0.001388, mae: 0.040506, mean_q: 1.169552
 108400/1000000: episode: 1084, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.316, mean reward: 0.573 [0.504, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.190, 10.098], loss: 0.001406, mae: 0.041112, mean_q: 1.168782
 108500/1000000: episode: 1085, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.103, mean reward: 0.571 [0.504, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.152, 10.201], loss: 0.001418, mae: 0.041043, mean_q: 1.165390
 108600/1000000: episode: 1086, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.618, mean reward: 0.576 [0.500, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.516, 10.329], loss: 0.001377, mae: 0.040848, mean_q: 1.164962
 108700/1000000: episode: 1087, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.246, mean reward: 0.572 [0.501, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.643, 10.282], loss: 0.001267, mae: 0.038860, mean_q: 1.169240
 108800/1000000: episode: 1088, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.685, mean reward: 0.587 [0.511, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.553, 10.139], loss: 0.001400, mae: 0.041286, mean_q: 1.167775
 108900/1000000: episode: 1089, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 56.497, mean reward: 0.565 [0.503, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.944, 10.098], loss: 0.001309, mae: 0.039280, mean_q: 1.165396
 109000/1000000: episode: 1090, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 57.957, mean reward: 0.580 [0.503, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.889, 10.191], loss: 0.001469, mae: 0.042295, mean_q: 1.163803
 109100/1000000: episode: 1091, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.017, mean reward: 0.560 [0.503, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.203, 10.098], loss: 0.001272, mae: 0.039300, mean_q: 1.162018
 109200/1000000: episode: 1092, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.055, mean reward: 0.591 [0.509, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.051, 10.098], loss: 0.001373, mae: 0.039926, mean_q: 1.161398
 109300/1000000: episode: 1093, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.223, mean reward: 0.602 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.411, 10.128], loss: 0.001319, mae: 0.040179, mean_q: 1.164658
 109400/1000000: episode: 1094, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.545, mean reward: 0.575 [0.499, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.213, 10.241], loss: 0.001373, mae: 0.040659, mean_q: 1.163885
 109500/1000000: episode: 1095, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 60.455, mean reward: 0.605 [0.527, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.782, 10.215], loss: 0.001445, mae: 0.041882, mean_q: 1.167637
 109600/1000000: episode: 1096, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.853, mean reward: 0.579 [0.499, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.370, 10.316], loss: 0.001445, mae: 0.041481, mean_q: 1.161306
 109700/1000000: episode: 1097, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.036, mean reward: 0.600 [0.500, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.103, 10.177], loss: 0.001337, mae: 0.039707, mean_q: 1.165803
 109800/1000000: episode: 1098, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.982, mean reward: 0.600 [0.507, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.068, 10.098], loss: 0.001335, mae: 0.039821, mean_q: 1.163876
 109900/1000000: episode: 1099, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.238, mean reward: 0.592 [0.504, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.597, 10.098], loss: 0.001457, mae: 0.041779, mean_q: 1.163010
 110000/1000000: episode: 1100, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 63.619, mean reward: 0.636 [0.503, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.093, 10.098], loss: 0.001409, mae: 0.040948, mean_q: 1.165472
 110100/1000000: episode: 1101, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.560, mean reward: 0.596 [0.507, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.180, 10.189], loss: 0.001421, mae: 0.040814, mean_q: 1.161870
 110200/1000000: episode: 1102, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.016, mean reward: 0.590 [0.499, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.689, 10.182], loss: 0.001620, mae: 0.042543, mean_q: 1.163189
 110300/1000000: episode: 1103, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.942, mean reward: 0.579 [0.509, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.969, 10.133], loss: 0.001520, mae: 0.042095, mean_q: 1.165020
 110400/1000000: episode: 1104, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.859, mean reward: 0.579 [0.504, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.464, 10.240], loss: 0.001341, mae: 0.040279, mean_q: 1.163111
 110500/1000000: episode: 1105, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.961, mean reward: 0.600 [0.506, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.848, 10.202], loss: 0.001564, mae: 0.042632, mean_q: 1.165611
 110600/1000000: episode: 1106, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.305, mean reward: 0.573 [0.503, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.562, 10.179], loss: 0.001418, mae: 0.041073, mean_q: 1.162098
 110700/1000000: episode: 1107, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 56.188, mean reward: 0.562 [0.499, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.445 [-0.130, 10.436], loss: 0.001436, mae: 0.041506, mean_q: 1.164613
 110800/1000000: episode: 1108, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 63.212, mean reward: 0.632 [0.518, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.100, 10.431], loss: 0.001389, mae: 0.040374, mean_q: 1.164106
 110900/1000000: episode: 1109, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.197, mean reward: 0.582 [0.499, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.445 [-0.772, 10.418], loss: 0.001284, mae: 0.039838, mean_q: 1.164264
 111000/1000000: episode: 1110, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.906, mean reward: 0.579 [0.508, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.639, 10.131], loss: 0.001299, mae: 0.039699, mean_q: 1.166234
 111100/1000000: episode: 1111, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.738, mean reward: 0.587 [0.500, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.552, 10.098], loss: 0.001388, mae: 0.040762, mean_q: 1.163999
 111200/1000000: episode: 1112, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.987, mean reward: 0.590 [0.506, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.471, 10.098], loss: 0.001381, mae: 0.040730, mean_q: 1.165249
 111300/1000000: episode: 1113, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 63.064, mean reward: 0.631 [0.512, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.375, 10.337], loss: 0.001247, mae: 0.038874, mean_q: 1.164444
 111400/1000000: episode: 1114, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.090, mean reward: 0.591 [0.510, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.688, 10.130], loss: 0.001385, mae: 0.040802, mean_q: 1.164431
 111500/1000000: episode: 1115, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.570, mean reward: 0.586 [0.502, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.914, 10.249], loss: 0.001384, mae: 0.040789, mean_q: 1.165806
 111600/1000000: episode: 1116, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.880, mean reward: 0.599 [0.500, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.577, 10.176], loss: 0.001382, mae: 0.040407, mean_q: 1.164731
 111700/1000000: episode: 1117, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.118, mean reward: 0.581 [0.508, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.718, 10.149], loss: 0.001387, mae: 0.040658, mean_q: 1.169002
 111800/1000000: episode: 1118, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.688, mean reward: 0.597 [0.507, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.950, 10.098], loss: 0.001419, mae: 0.041246, mean_q: 1.165135
 111900/1000000: episode: 1119, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.865, mean reward: 0.589 [0.502, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.845, 10.098], loss: 0.001367, mae: 0.040885, mean_q: 1.162857
 112000/1000000: episode: 1120, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 57.572, mean reward: 0.576 [0.498, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.751, 10.516], loss: 0.001321, mae: 0.039960, mean_q: 1.166411
 112100/1000000: episode: 1121, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.757, mean reward: 0.598 [0.523, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.517, 10.200], loss: 0.001335, mae: 0.039879, mean_q: 1.163351
 112200/1000000: episode: 1122, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 59.677, mean reward: 0.597 [0.509, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.670, 10.098], loss: 0.001341, mae: 0.040815, mean_q: 1.164162
 112300/1000000: episode: 1123, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.512, mean reward: 0.595 [0.509, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.430, 10.190], loss: 0.001443, mae: 0.041878, mean_q: 1.164888
 112400/1000000: episode: 1124, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.513, mean reward: 0.575 [0.498, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.552, 10.294], loss: 0.001448, mae: 0.041388, mean_q: 1.165577
 112500/1000000: episode: 1125, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.502, mean reward: 0.585 [0.502, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.618, 10.098], loss: 0.001489, mae: 0.041951, mean_q: 1.164691
 112600/1000000: episode: 1126, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 62.107, mean reward: 0.621 [0.503, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.405, 10.098], loss: 0.001411, mae: 0.040999, mean_q: 1.165472
 112700/1000000: episode: 1127, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.398, mean reward: 0.584 [0.500, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.029, 10.262], loss: 0.001360, mae: 0.039998, mean_q: 1.163055
 112800/1000000: episode: 1128, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.392, mean reward: 0.604 [0.524, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.800, 10.098], loss: 0.001328, mae: 0.040010, mean_q: 1.163071
 112900/1000000: episode: 1129, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.605, mean reward: 0.576 [0.510, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.321, 10.230], loss: 0.001365, mae: 0.040758, mean_q: 1.162284
 113000/1000000: episode: 1130, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.537, mean reward: 0.605 [0.502, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.852, 10.153], loss: 0.001403, mae: 0.041261, mean_q: 1.165142
 113100/1000000: episode: 1131, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.390, mean reward: 0.584 [0.501, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.760, 10.098], loss: 0.001370, mae: 0.040849, mean_q: 1.164868
 113200/1000000: episode: 1132, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.278, mean reward: 0.583 [0.501, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.378, 10.188], loss: 0.001387, mae: 0.041141, mean_q: 1.165255
 113300/1000000: episode: 1133, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.925, mean reward: 0.579 [0.503, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.741, 10.098], loss: 0.001493, mae: 0.042607, mean_q: 1.163855
 113400/1000000: episode: 1134, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.861, mean reward: 0.579 [0.501, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.278, 10.236], loss: 0.001341, mae: 0.039880, mean_q: 1.164947
 113500/1000000: episode: 1135, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.896, mean reward: 0.579 [0.501, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.992, 10.148], loss: 0.001375, mae: 0.040830, mean_q: 1.165540
 113600/1000000: episode: 1136, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 59.250, mean reward: 0.592 [0.499, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.697, 10.129], loss: 0.001425, mae: 0.040962, mean_q: 1.163896
 113700/1000000: episode: 1137, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.357, mean reward: 0.594 [0.510, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.460, 10.098], loss: 0.001375, mae: 0.040799, mean_q: 1.166377
 113800/1000000: episode: 1138, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.092, mean reward: 0.591 [0.508, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.167, 10.098], loss: 0.001382, mae: 0.040279, mean_q: 1.167474
 113900/1000000: episode: 1139, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.691, mean reward: 0.587 [0.505, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.570, 10.110], loss: 0.001463, mae: 0.041914, mean_q: 1.168886
 114000/1000000: episode: 1140, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.918, mean reward: 0.589 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.495, 10.098], loss: 0.001378, mae: 0.040447, mean_q: 1.164917
 114100/1000000: episode: 1141, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.089, mean reward: 0.591 [0.506, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.894, 10.098], loss: 0.001443, mae: 0.041474, mean_q: 1.166818
 114200/1000000: episode: 1142, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.564, mean reward: 0.586 [0.505, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.310, 10.098], loss: 0.001380, mae: 0.040345, mean_q: 1.167199
 114300/1000000: episode: 1143, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.450, mean reward: 0.575 [0.499, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.490, 10.126], loss: 0.001374, mae: 0.040626, mean_q: 1.167389
 114400/1000000: episode: 1144, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.658, mean reward: 0.587 [0.504, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.624, 10.098], loss: 0.001390, mae: 0.040060, mean_q: 1.166367
 114500/1000000: episode: 1145, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.122, mean reward: 0.571 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.771, 10.184], loss: 0.001380, mae: 0.040172, mean_q: 1.170754
 114600/1000000: episode: 1146, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.815, mean reward: 0.578 [0.503, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.507, 10.107], loss: 0.001411, mae: 0.040956, mean_q: 1.167566
 114700/1000000: episode: 1147, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 56.955, mean reward: 0.570 [0.505, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.772, 10.098], loss: 0.001383, mae: 0.040401, mean_q: 1.166604
 114800/1000000: episode: 1148, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.542, mean reward: 0.575 [0.509, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.755, 10.098], loss: 0.001404, mae: 0.040911, mean_q: 1.167437
 114900/1000000: episode: 1149, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.300, mean reward: 0.603 [0.509, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.588, 10.304], loss: 0.001488, mae: 0.041471, mean_q: 1.162943
 115000/1000000: episode: 1150, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.010, mean reward: 0.580 [0.519, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.238, 10.098], loss: 0.001567, mae: 0.042551, mean_q: 1.163821
 115100/1000000: episode: 1151, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.439, mean reward: 0.584 [0.510, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.927, 10.187], loss: 0.001353, mae: 0.040041, mean_q: 1.159789
 115200/1000000: episode: 1152, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.041, mean reward: 0.590 [0.506, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.745, 10.098], loss: 0.001362, mae: 0.040349, mean_q: 1.161512
 115300/1000000: episode: 1153, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 63.288, mean reward: 0.633 [0.508, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.729, 10.418], loss: 0.001336, mae: 0.040294, mean_q: 1.161173
 115400/1000000: episode: 1154, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.377, mean reward: 0.584 [0.511, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.595, 10.102], loss: 0.001330, mae: 0.039217, mean_q: 1.158964
 115500/1000000: episode: 1155, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.869, mean reward: 0.619 [0.521, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.274, 10.282], loss: 0.001397, mae: 0.040660, mean_q: 1.166919
 115600/1000000: episode: 1156, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.130, mean reward: 0.581 [0.504, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.656, 10.340], loss: 0.001388, mae: 0.040422, mean_q: 1.162801
 115700/1000000: episode: 1157, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.524, mean reward: 0.585 [0.503, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.108, 10.300], loss: 0.001457, mae: 0.041512, mean_q: 1.167048
 115800/1000000: episode: 1158, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.050, mean reward: 0.620 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-1.339, 10.098], loss: 0.001415, mae: 0.041077, mean_q: 1.162720
 115900/1000000: episode: 1159, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.718, mean reward: 0.587 [0.517, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.740, 10.098], loss: 0.001373, mae: 0.040062, mean_q: 1.166285
 116000/1000000: episode: 1160, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.159, mean reward: 0.592 [0.501, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.939, 10.098], loss: 0.001412, mae: 0.041046, mean_q: 1.164776
 116100/1000000: episode: 1161, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.407, mean reward: 0.594 [0.507, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.880, 10.302], loss: 0.001458, mae: 0.041852, mean_q: 1.166072
 116200/1000000: episode: 1162, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 61.266, mean reward: 0.613 [0.499, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.463, 10.297], loss: 0.001428, mae: 0.041375, mean_q: 1.165139
 116300/1000000: episode: 1163, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.810, mean reward: 0.588 [0.504, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.798, 10.277], loss: 0.001510, mae: 0.042057, mean_q: 1.165964
 116400/1000000: episode: 1164, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.607, mean reward: 0.586 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.595, 10.374], loss: 0.001501, mae: 0.042232, mean_q: 1.165817
 116500/1000000: episode: 1165, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.962, mean reward: 0.610 [0.512, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.486, 10.098], loss: 0.001382, mae: 0.040170, mean_q: 1.163160
 116600/1000000: episode: 1166, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.105, mean reward: 0.601 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.310, 10.098], loss: 0.001493, mae: 0.042606, mean_q: 1.166108
 116700/1000000: episode: 1167, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.535, mean reward: 0.595 [0.498, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.857, 10.122], loss: 0.001525, mae: 0.042395, mean_q: 1.166919
 116800/1000000: episode: 1168, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.264, mean reward: 0.603 [0.504, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.715, 10.341], loss: 0.001399, mae: 0.040573, mean_q: 1.166738
 116900/1000000: episode: 1169, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 60.769, mean reward: 0.608 [0.515, 0.895], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.069, 10.273], loss: 0.001420, mae: 0.041120, mean_q: 1.170170
 117000/1000000: episode: 1170, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.242, mean reward: 0.582 [0.506, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.245, 10.165], loss: 0.001476, mae: 0.041910, mean_q: 1.169944
 117100/1000000: episode: 1171, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.702, mean reward: 0.577 [0.500, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.731, 10.111], loss: 0.001354, mae: 0.039932, mean_q: 1.167891
 117200/1000000: episode: 1172, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.080, mean reward: 0.591 [0.500, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.420, 10.122], loss: 0.001383, mae: 0.040901, mean_q: 1.168833
 117300/1000000: episode: 1173, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 58.395, mean reward: 0.584 [0.499, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.848, 10.098], loss: 0.001434, mae: 0.041521, mean_q: 1.165399
 117400/1000000: episode: 1174, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 61.452, mean reward: 0.615 [0.519, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.113, 10.429], loss: 0.001381, mae: 0.040552, mean_q: 1.165708
 117500/1000000: episode: 1175, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.302, mean reward: 0.583 [0.505, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.302, 10.098], loss: 0.001379, mae: 0.040801, mean_q: 1.168707
 117600/1000000: episode: 1176, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.361, mean reward: 0.574 [0.503, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.811, 10.165], loss: 0.001406, mae: 0.041830, mean_q: 1.168209
 117700/1000000: episode: 1177, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 62.677, mean reward: 0.627 [0.521, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.037, 10.228], loss: 0.001388, mae: 0.040947, mean_q: 1.166519
 117800/1000000: episode: 1178, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 60.366, mean reward: 0.604 [0.517, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-2.399, 10.098], loss: 0.001473, mae: 0.041612, mean_q: 1.168149
 117900/1000000: episode: 1179, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 56.191, mean reward: 0.562 [0.505, 0.650], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.329, 10.098], loss: 0.001440, mae: 0.041667, mean_q: 1.170193
 118000/1000000: episode: 1180, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.485, mean reward: 0.575 [0.508, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.361, 10.098], loss: 0.001482, mae: 0.041665, mean_q: 1.166474
 118100/1000000: episode: 1181, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.711, mean reward: 0.567 [0.497, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.772, 10.098], loss: 0.001462, mae: 0.042081, mean_q: 1.167673
 118200/1000000: episode: 1182, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.731, mean reward: 0.597 [0.511, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.201, 10.349], loss: 0.001454, mae: 0.041556, mean_q: 1.165759
 118300/1000000: episode: 1183, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.555, mean reward: 0.606 [0.505, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.577, 10.310], loss: 0.001484, mae: 0.042254, mean_q: 1.169209
 118400/1000000: episode: 1184, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 57.815, mean reward: 0.578 [0.498, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.323, 10.098], loss: 0.001473, mae: 0.042097, mean_q: 1.167221
 118500/1000000: episode: 1185, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 57.137, mean reward: 0.571 [0.502, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.496, 10.222], loss: 0.001399, mae: 0.040703, mean_q: 1.171658
 118600/1000000: episode: 1186, duration: 0.627s, episode steps: 100, steps per second: 159, episode reward: 57.749, mean reward: 0.577 [0.503, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.278, 10.286], loss: 0.001399, mae: 0.041112, mean_q: 1.167760
 118700/1000000: episode: 1187, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 59.284, mean reward: 0.593 [0.502, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.539, 10.098], loss: 0.001318, mae: 0.039642, mean_q: 1.169171
 118800/1000000: episode: 1188, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 60.671, mean reward: 0.607 [0.517, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.283, 10.098], loss: 0.001360, mae: 0.040393, mean_q: 1.168975
 118900/1000000: episode: 1189, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 63.716, mean reward: 0.637 [0.504, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.243, 10.343], loss: 0.001514, mae: 0.042681, mean_q: 1.167263
 119000/1000000: episode: 1190, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.618, mean reward: 0.586 [0.508, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.614, 10.098], loss: 0.001408, mae: 0.040976, mean_q: 1.171929
 119100/1000000: episode: 1191, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 59.011, mean reward: 0.590 [0.503, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.070, 10.229], loss: 0.001479, mae: 0.042044, mean_q: 1.171093
 119200/1000000: episode: 1192, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.549, mean reward: 0.575 [0.508, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.456, 10.286], loss: 0.001391, mae: 0.040197, mean_q: 1.172894
 119300/1000000: episode: 1193, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 58.730, mean reward: 0.587 [0.501, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-2.178, 10.098], loss: 0.001463, mae: 0.041886, mean_q: 1.171601
 119400/1000000: episode: 1194, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.612, mean reward: 0.586 [0.511, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.430, 10.098], loss: 0.001557, mae: 0.043187, mean_q: 1.170038
 119500/1000000: episode: 1195, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.545, mean reward: 0.585 [0.505, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.738, 10.230], loss: 0.001462, mae: 0.041417, mean_q: 1.170435
 119600/1000000: episode: 1196, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.436, mean reward: 0.604 [0.520, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.341, 10.098], loss: 0.001491, mae: 0.041563, mean_q: 1.168922
 119700/1000000: episode: 1197, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.830, mean reward: 0.578 [0.500, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.501, 10.105], loss: 0.001395, mae: 0.040642, mean_q: 1.172270
 119800/1000000: episode: 1198, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.971, mean reward: 0.590 [0.510, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.753, 10.108], loss: 0.001471, mae: 0.041623, mean_q: 1.172596
 119900/1000000: episode: 1199, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.553, mean reward: 0.576 [0.503, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.793, 10.098], loss: 0.001423, mae: 0.041464, mean_q: 1.170510
 120000/1000000: episode: 1200, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 59.583, mean reward: 0.596 [0.505, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.627, 10.285], loss: 0.001398, mae: 0.041039, mean_q: 1.171468
 120100/1000000: episode: 1201, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 62.594, mean reward: 0.626 [0.507, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.777, 10.275], loss: 0.001389, mae: 0.040740, mean_q: 1.170217
 120200/1000000: episode: 1202, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 57.128, mean reward: 0.571 [0.497, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.017, 10.283], loss: 0.001419, mae: 0.041218, mean_q: 1.170804
 120300/1000000: episode: 1203, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.407, mean reward: 0.604 [0.518, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.828, 10.370], loss: 0.001351, mae: 0.040352, mean_q: 1.172331
 120400/1000000: episode: 1204, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 57.885, mean reward: 0.579 [0.497, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.190, 10.172], loss: 0.001641, mae: 0.043183, mean_q: 1.174804
 120500/1000000: episode: 1205, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.899, mean reward: 0.599 [0.509, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.959, 10.098], loss: 0.001419, mae: 0.041407, mean_q: 1.169607
 120600/1000000: episode: 1206, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.953, mean reward: 0.620 [0.510, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.955, 10.297], loss: 0.001536, mae: 0.042856, mean_q: 1.172829
 120700/1000000: episode: 1207, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 60.640, mean reward: 0.606 [0.532, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.280, 10.098], loss: 0.001403, mae: 0.041196, mean_q: 1.172933
 120800/1000000: episode: 1208, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.115, mean reward: 0.581 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.156, 10.098], loss: 0.001408, mae: 0.041039, mean_q: 1.173818
 120900/1000000: episode: 1209, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 59.914, mean reward: 0.599 [0.511, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.614, 10.173], loss: 0.001441, mae: 0.041917, mean_q: 1.176230
 121000/1000000: episode: 1210, duration: 0.625s, episode steps: 100, steps per second: 160, episode reward: 57.642, mean reward: 0.576 [0.511, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.030, 10.228], loss: 0.001373, mae: 0.040716, mean_q: 1.172184
 121100/1000000: episode: 1211, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.775, mean reward: 0.578 [0.509, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.273, 10.197], loss: 0.001487, mae: 0.042183, mean_q: 1.172921
 121200/1000000: episode: 1212, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.503, mean reward: 0.585 [0.504, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.762, 10.117], loss: 0.001345, mae: 0.040274, mean_q: 1.168079
 121300/1000000: episode: 1213, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.665, mean reward: 0.597 [0.500, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.505, 10.225], loss: 0.001372, mae: 0.040827, mean_q: 1.169747
 121400/1000000: episode: 1214, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 56.807, mean reward: 0.568 [0.505, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.171, 10.284], loss: 0.001378, mae: 0.040859, mean_q: 1.168644
 121500/1000000: episode: 1215, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.773, mean reward: 0.588 [0.501, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.666, 10.366], loss: 0.001279, mae: 0.039119, mean_q: 1.167235
 121600/1000000: episode: 1216, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 61.047, mean reward: 0.610 [0.502, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.856, 10.098], loss: 0.001390, mae: 0.040276, mean_q: 1.167003
 121700/1000000: episode: 1217, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.413, mean reward: 0.594 [0.510, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.235, 10.098], loss: 0.001355, mae: 0.040770, mean_q: 1.162142
 121800/1000000: episode: 1218, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.178, mean reward: 0.592 [0.503, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.666, 10.101], loss: 0.001416, mae: 0.041070, mean_q: 1.163218
 121900/1000000: episode: 1219, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 60.288, mean reward: 0.603 [0.505, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.669, 10.370], loss: 0.001429, mae: 0.041562, mean_q: 1.169848
 122000/1000000: episode: 1220, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.069, mean reward: 0.591 [0.507, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.472, 10.305], loss: 0.001382, mae: 0.040296, mean_q: 1.171154
 122100/1000000: episode: 1221, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.261, mean reward: 0.583 [0.507, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.592, 10.238], loss: 0.001479, mae: 0.041942, mean_q: 1.169674
 122200/1000000: episode: 1222, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.659, mean reward: 0.597 [0.499, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.497, 10.214], loss: 0.001414, mae: 0.041135, mean_q: 1.169645
 122300/1000000: episode: 1223, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.521, mean reward: 0.595 [0.501, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.836, 10.125], loss: 0.001544, mae: 0.042973, mean_q: 1.170217
 122400/1000000: episode: 1224, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.137, mean reward: 0.571 [0.501, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.077, 10.098], loss: 0.001546, mae: 0.043269, mean_q: 1.174390
 122500/1000000: episode: 1225, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 56.836, mean reward: 0.568 [0.501, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.810, 10.098], loss: 0.001360, mae: 0.040608, mean_q: 1.166650
 122600/1000000: episode: 1226, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.068, mean reward: 0.591 [0.505, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.855, 10.249], loss: 0.001426, mae: 0.041678, mean_q: 1.165584
 122700/1000000: episode: 1227, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.822, mean reward: 0.588 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.608, 10.101], loss: 0.001456, mae: 0.041624, mean_q: 1.163702
 122800/1000000: episode: 1228, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.036, mean reward: 0.600 [0.511, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.726, 10.259], loss: 0.001759, mae: 0.044272, mean_q: 1.161526
 122900/1000000: episode: 1229, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.812, mean reward: 0.628 [0.517, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.674, 10.098], loss: 0.001409, mae: 0.041250, mean_q: 1.164549
 123000/1000000: episode: 1230, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.173, mean reward: 0.592 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.614, 10.098], loss: 0.001461, mae: 0.042443, mean_q: 1.170270
 123100/1000000: episode: 1231, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.112, mean reward: 0.591 [0.506, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.668, 10.183], loss: 0.001367, mae: 0.040610, mean_q: 1.167655
 123200/1000000: episode: 1232, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.893, mean reward: 0.609 [0.501, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.891, 10.098], loss: 0.001449, mae: 0.041869, mean_q: 1.173150
 123300/1000000: episode: 1233, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 61.776, mean reward: 0.618 [0.519, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.096, 10.413], loss: 0.001415, mae: 0.041549, mean_q: 1.173181
 123400/1000000: episode: 1234, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.858, mean reward: 0.589 [0.503, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.909, 10.183], loss: 0.001471, mae: 0.041784, mean_q: 1.172526
 123500/1000000: episode: 1235, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.364, mean reward: 0.604 [0.507, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.558, 10.098], loss: 0.001477, mae: 0.041880, mean_q: 1.174383
 123600/1000000: episode: 1236, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.914, mean reward: 0.589 [0.506, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.964, 10.098], loss: 0.001407, mae: 0.040976, mean_q: 1.173312
 123700/1000000: episode: 1237, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.583, mean reward: 0.596 [0.516, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.234, 10.098], loss: 0.001468, mae: 0.042354, mean_q: 1.175743
 123800/1000000: episode: 1238, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.511, mean reward: 0.575 [0.507, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.894, 10.098], loss: 0.001523, mae: 0.042376, mean_q: 1.176612
 123900/1000000: episode: 1239, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.005, mean reward: 0.600 [0.505, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.735, 10.265], loss: 0.001475, mae: 0.041879, mean_q: 1.170906
 124000/1000000: episode: 1240, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.802, mean reward: 0.588 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.491, 10.284], loss: 0.001553, mae: 0.042982, mean_q: 1.174981
 124100/1000000: episode: 1241, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.319, mean reward: 0.603 [0.502, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.993, 10.254], loss: 0.001534, mae: 0.043167, mean_q: 1.173429
 124200/1000000: episode: 1242, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.666, mean reward: 0.577 [0.500, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.768, 10.098], loss: 0.001455, mae: 0.041867, mean_q: 1.169996
 124300/1000000: episode: 1243, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.676, mean reward: 0.597 [0.501, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.295, 10.476], loss: 0.001430, mae: 0.041516, mean_q: 1.167130
 124400/1000000: episode: 1244, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.646, mean reward: 0.606 [0.510, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.991, 10.262], loss: 0.001535, mae: 0.042949, mean_q: 1.173932
 124500/1000000: episode: 1245, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.310, mean reward: 0.573 [0.501, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.166, 10.255], loss: 0.001456, mae: 0.041480, mean_q: 1.173957
 124600/1000000: episode: 1246, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.437, mean reward: 0.594 [0.505, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.512, 10.191], loss: 0.001436, mae: 0.041518, mean_q: 1.175375
 124700/1000000: episode: 1247, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.325, mean reward: 0.593 [0.501, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.519, 10.193], loss: 0.001405, mae: 0.041092, mean_q: 1.170249
 124800/1000000: episode: 1248, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.728, mean reward: 0.577 [0.503, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.455, 10.098], loss: 0.001480, mae: 0.042156, mean_q: 1.173770
 124900/1000000: episode: 1249, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.045, mean reward: 0.580 [0.505, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.814, 10.098], loss: 0.001479, mae: 0.041516, mean_q: 1.173882
 125000/1000000: episode: 1250, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.451, mean reward: 0.585 [0.509, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.582, 10.177], loss: 0.001525, mae: 0.042881, mean_q: 1.173438
 125100/1000000: episode: 1251, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.823, mean reward: 0.598 [0.512, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.731, 10.279], loss: 0.001482, mae: 0.041563, mean_q: 1.166873
 125200/1000000: episode: 1252, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.001, mean reward: 0.590 [0.509, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.546, 10.137], loss: 0.001461, mae: 0.041554, mean_q: 1.168238
 125300/1000000: episode: 1253, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.261, mean reward: 0.563 [0.501, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.918, 10.149], loss: 0.001559, mae: 0.042787, mean_q: 1.168792
 125400/1000000: episode: 1254, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.088, mean reward: 0.571 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.342, 10.143], loss: 0.001525, mae: 0.042809, mean_q: 1.170716
 125500/1000000: episode: 1255, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.370, mean reward: 0.594 [0.508, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.783, 10.111], loss: 0.001469, mae: 0.042201, mean_q: 1.170784
 125600/1000000: episode: 1256, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.241, mean reward: 0.582 [0.506, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.432, 10.230], loss: 0.001451, mae: 0.041886, mean_q: 1.167249
 125700/1000000: episode: 1257, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.141, mean reward: 0.581 [0.502, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.959, 10.098], loss: 0.001335, mae: 0.040169, mean_q: 1.165143
 125800/1000000: episode: 1258, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.681, mean reward: 0.577 [0.511, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.535, 10.117], loss: 0.001492, mae: 0.042171, mean_q: 1.165716
 125900/1000000: episode: 1259, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.096, mean reward: 0.611 [0.498, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.504, 10.149], loss: 0.001603, mae: 0.043734, mean_q: 1.168511
 126000/1000000: episode: 1260, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.417, mean reward: 0.594 [0.500, 0.911], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.393, 10.098], loss: 0.001558, mae: 0.042905, mean_q: 1.167232
 126100/1000000: episode: 1261, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.621, mean reward: 0.586 [0.499, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.613, 10.334], loss: 0.001513, mae: 0.042220, mean_q: 1.168761
 126200/1000000: episode: 1262, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.213, mean reward: 0.592 [0.501, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.650, 10.135], loss: 0.001513, mae: 0.042439, mean_q: 1.162897
 126300/1000000: episode: 1263, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.705, mean reward: 0.587 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.229, 10.165], loss: 0.001558, mae: 0.043083, mean_q: 1.166063
 126400/1000000: episode: 1264, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.607, mean reward: 0.586 [0.505, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.167, 10.098], loss: 0.001580, mae: 0.043203, mean_q: 1.167999
 126500/1000000: episode: 1265, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.947, mean reward: 0.589 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.508, 10.311], loss: 0.001565, mae: 0.042360, mean_q: 1.167114
 126600/1000000: episode: 1266, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.561, mean reward: 0.576 [0.499, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.327, 10.163], loss: 0.001631, mae: 0.043977, mean_q: 1.167573
 126700/1000000: episode: 1267, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.727, mean reward: 0.617 [0.502, 0.846], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.956, 10.549], loss: 0.001795, mae: 0.045428, mean_q: 1.167570
 126800/1000000: episode: 1268, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.944, mean reward: 0.579 [0.500, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.296, 10.098], loss: 0.001641, mae: 0.043226, mean_q: 1.169248
 126900/1000000: episode: 1269, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.958, mean reward: 0.590 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.224, 10.214], loss: 0.001568, mae: 0.042390, mean_q: 1.165069
 127000/1000000: episode: 1270, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.724, mean reward: 0.577 [0.505, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.744, 10.122], loss: 0.001671, mae: 0.043901, mean_q: 1.169850
 127100/1000000: episode: 1271, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.826, mean reward: 0.588 [0.509, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.215, 10.098], loss: 0.001616, mae: 0.043676, mean_q: 1.168455
 127200/1000000: episode: 1272, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.766, mean reward: 0.588 [0.499, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.782, 10.408], loss: 0.001573, mae: 0.042802, mean_q: 1.162780
 127300/1000000: episode: 1273, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.006, mean reward: 0.580 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.464, 10.149], loss: 0.001442, mae: 0.041432, mean_q: 1.165493
 127400/1000000: episode: 1274, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.835, mean reward: 0.578 [0.500, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.959, 10.129], loss: 0.001475, mae: 0.041602, mean_q: 1.166022
 127500/1000000: episode: 1275, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 55.874, mean reward: 0.559 [0.503, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.138, 10.157], loss: 0.001463, mae: 0.041332, mean_q: 1.164373
 127600/1000000: episode: 1276, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.133, mean reward: 0.601 [0.499, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.120, 10.264], loss: 0.001609, mae: 0.043509, mean_q: 1.164633
 127700/1000000: episode: 1277, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.658, mean reward: 0.587 [0.501, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.157, 10.098], loss: 0.001610, mae: 0.043944, mean_q: 1.170209
 127800/1000000: episode: 1278, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 61.009, mean reward: 0.610 [0.500, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.779, 10.108], loss: 0.001612, mae: 0.043529, mean_q: 1.167313
 127900/1000000: episode: 1279, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.684, mean reward: 0.607 [0.513, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.589, 10.236], loss: 0.001521, mae: 0.042219, mean_q: 1.167944
 128000/1000000: episode: 1280, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 62.575, mean reward: 0.626 [0.522, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.734, 10.098], loss: 0.001537, mae: 0.042563, mean_q: 1.166936
 128100/1000000: episode: 1281, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.759, mean reward: 0.568 [0.505, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.572, 10.210], loss: 0.001505, mae: 0.042585, mean_q: 1.168519
 128200/1000000: episode: 1282, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.541, mean reward: 0.595 [0.508, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.108, 10.098], loss: 0.001465, mae: 0.041540, mean_q: 1.167988
 128300/1000000: episode: 1283, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.079, mean reward: 0.601 [0.514, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.314, 10.098], loss: 0.001558, mae: 0.042935, mean_q: 1.165151
 128400/1000000: episode: 1284, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.645, mean reward: 0.586 [0.500, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.852, 10.098], loss: 0.001503, mae: 0.041915, mean_q: 1.163283
 128500/1000000: episode: 1285, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 60.385, mean reward: 0.604 [0.513, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.691, 10.098], loss: 0.001771, mae: 0.044379, mean_q: 1.161999
 128600/1000000: episode: 1286, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 62.732, mean reward: 0.627 [0.511, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.859, 10.502], loss: 0.001624, mae: 0.043670, mean_q: 1.165366
 128700/1000000: episode: 1287, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.509, mean reward: 0.595 [0.503, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.812, 10.107], loss: 0.001504, mae: 0.041849, mean_q: 1.167447
 128800/1000000: episode: 1288, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.005, mean reward: 0.580 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.339, 10.180], loss: 0.001463, mae: 0.041447, mean_q: 1.163928
 128900/1000000: episode: 1289, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.969, mean reward: 0.580 [0.508, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.761, 10.126], loss: 0.001443, mae: 0.041169, mean_q: 1.165796
 129000/1000000: episode: 1290, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.354, mean reward: 0.584 [0.505, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.961, 10.250], loss: 0.001571, mae: 0.042608, mean_q: 1.164394
 129100/1000000: episode: 1291, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.147, mean reward: 0.581 [0.502, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.912, 10.098], loss: 0.001515, mae: 0.042283, mean_q: 1.162330
 129200/1000000: episode: 1292, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.063, mean reward: 0.571 [0.498, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.400, 10.211], loss: 0.001494, mae: 0.041330, mean_q: 1.164475
 129300/1000000: episode: 1293, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.183, mean reward: 0.602 [0.500, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.612, 10.098], loss: 0.001510, mae: 0.042391, mean_q: 1.165357
 129400/1000000: episode: 1294, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.785, mean reward: 0.588 [0.504, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.792, 10.210], loss: 0.001453, mae: 0.041582, mean_q: 1.163432
 129500/1000000: episode: 1295, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.229, mean reward: 0.592 [0.500, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.814, 10.318], loss: 0.001560, mae: 0.043461, mean_q: 1.166519
 129600/1000000: episode: 1296, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.737, mean reward: 0.597 [0.500, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.714, 10.098], loss: 0.001515, mae: 0.042147, mean_q: 1.163470
 129700/1000000: episode: 1297, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.961, mean reward: 0.600 [0.504, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.651, 10.098], loss: 0.001489, mae: 0.041472, mean_q: 1.161362
 129800/1000000: episode: 1298, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.272, mean reward: 0.573 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.637, 10.098], loss: 0.001588, mae: 0.043409, mean_q: 1.169388
 129900/1000000: episode: 1299, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.169, mean reward: 0.582 [0.503, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.456, 10.147], loss: 0.001521, mae: 0.042669, mean_q: 1.163481
 130000/1000000: episode: 1300, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.089, mean reward: 0.581 [0.502, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.893, 10.165], loss: 0.001498, mae: 0.042042, mean_q: 1.161725
 130100/1000000: episode: 1301, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.208, mean reward: 0.572 [0.505, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.349, 10.098], loss: 0.001666, mae: 0.043578, mean_q: 1.165488
 130200/1000000: episode: 1302, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 57.087, mean reward: 0.571 [0.508, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.601, 10.128], loss: 0.001723, mae: 0.044245, mean_q: 1.163581
 130300/1000000: episode: 1303, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 62.371, mean reward: 0.624 [0.504, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.806, 10.098], loss: 0.001540, mae: 0.042498, mean_q: 1.166552
 130400/1000000: episode: 1304, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 55.978, mean reward: 0.560 [0.500, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.397, 10.098], loss: 0.001552, mae: 0.043061, mean_q: 1.165408
 130500/1000000: episode: 1305, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.007, mean reward: 0.580 [0.505, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.488, 10.098], loss: 0.001542, mae: 0.043108, mean_q: 1.162413
 130600/1000000: episode: 1306, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 65.595, mean reward: 0.656 [0.501, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.744, 10.290], loss: 0.001497, mae: 0.041897, mean_q: 1.162170
 130700/1000000: episode: 1307, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 59.380, mean reward: 0.594 [0.504, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.626, 10.098], loss: 0.001670, mae: 0.044399, mean_q: 1.167908
 130800/1000000: episode: 1308, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.835, mean reward: 0.588 [0.503, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.283, 10.193], loss: 0.001623, mae: 0.044070, mean_q: 1.166766
 130900/1000000: episode: 1309, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.025, mean reward: 0.580 [0.513, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.402, 10.156], loss: 0.001503, mae: 0.042009, mean_q: 1.170966
 131000/1000000: episode: 1310, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.749, mean reward: 0.577 [0.512, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.793, 10.098], loss: 0.001500, mae: 0.041776, mean_q: 1.169007
 131100/1000000: episode: 1311, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 60.166, mean reward: 0.602 [0.509, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.320, 10.270], loss: 0.001495, mae: 0.042018, mean_q: 1.164746
 131200/1000000: episode: 1312, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 58.755, mean reward: 0.588 [0.507, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.328, 10.098], loss: 0.001575, mae: 0.043011, mean_q: 1.168546
 131300/1000000: episode: 1313, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.129, mean reward: 0.591 [0.499, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.284, 10.098], loss: 0.001454, mae: 0.041474, mean_q: 1.168896
 131400/1000000: episode: 1314, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.525, mean reward: 0.605 [0.499, 0.854], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.765, 10.098], loss: 0.001496, mae: 0.041848, mean_q: 1.168286
 131500/1000000: episode: 1315, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.926, mean reward: 0.609 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.706, 10.098], loss: 0.001561, mae: 0.042429, mean_q: 1.168785
 131600/1000000: episode: 1316, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.359, mean reward: 0.594 [0.512, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.841, 10.098], loss: 0.001458, mae: 0.041411, mean_q: 1.166966
 131700/1000000: episode: 1317, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.745, mean reward: 0.607 [0.517, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.563, 10.152], loss: 0.001503, mae: 0.041975, mean_q: 1.167623
 131800/1000000: episode: 1318, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.834, mean reward: 0.598 [0.512, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.657, 10.098], loss: 0.001554, mae: 0.043047, mean_q: 1.168351
 131900/1000000: episode: 1319, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.165, mean reward: 0.592 [0.515, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.473, 10.361], loss: 0.001498, mae: 0.041542, mean_q: 1.169245
 132000/1000000: episode: 1320, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 57.910, mean reward: 0.579 [0.505, 0.889], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.461, 10.312], loss: 0.001581, mae: 0.043012, mean_q: 1.169802
 132100/1000000: episode: 1321, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 60.542, mean reward: 0.605 [0.509, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.275, 10.507], loss: 0.001531, mae: 0.042452, mean_q: 1.169928
 132200/1000000: episode: 1322, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 57.859, mean reward: 0.579 [0.511, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.063, 10.098], loss: 0.001540, mae: 0.042291, mean_q: 1.172998
 132300/1000000: episode: 1323, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 61.622, mean reward: 0.616 [0.518, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.533, 10.207], loss: 0.001446, mae: 0.041108, mean_q: 1.169133
 132400/1000000: episode: 1324, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 63.327, mean reward: 0.633 [0.511, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.936, 10.104], loss: 0.001365, mae: 0.040179, mean_q: 1.169434
 132500/1000000: episode: 1325, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 61.247, mean reward: 0.612 [0.507, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.873, 10.340], loss: 0.001792, mae: 0.044747, mean_q: 1.172404
 132600/1000000: episode: 1326, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.016, mean reward: 0.600 [0.500, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.388, 10.098], loss: 0.001521, mae: 0.042220, mean_q: 1.173259
 132700/1000000: episode: 1327, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 56.456, mean reward: 0.565 [0.505, 0.670], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.907, 10.231], loss: 0.001475, mae: 0.041763, mean_q: 1.171752
 132800/1000000: episode: 1328, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.395, mean reward: 0.584 [0.507, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.881, 10.098], loss: 0.001500, mae: 0.041809, mean_q: 1.174551
 132900/1000000: episode: 1329, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.022, mean reward: 0.600 [0.508, 0.841], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.721, 10.194], loss: 0.001393, mae: 0.039977, mean_q: 1.172765
 133000/1000000: episode: 1330, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.801, mean reward: 0.608 [0.501, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.917, 10.098], loss: 0.001606, mae: 0.043118, mean_q: 1.175076
 133100/1000000: episode: 1331, duration: 0.523s, episode steps: 100, steps per second: 191, episode reward: 57.905, mean reward: 0.579 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.789, 10.098], loss: 0.001424, mae: 0.041024, mean_q: 1.176026
 133200/1000000: episode: 1332, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.475, mean reward: 0.585 [0.499, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.802, 10.098], loss: 0.001494, mae: 0.041930, mean_q: 1.173505
 133300/1000000: episode: 1333, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.428, mean reward: 0.584 [0.507, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.099, 10.232], loss: 0.001634, mae: 0.043300, mean_q: 1.173182
 133400/1000000: episode: 1334, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.343, mean reward: 0.583 [0.513, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.033, 10.098], loss: 0.001486, mae: 0.041391, mean_q: 1.175550
 133500/1000000: episode: 1335, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.158, mean reward: 0.562 [0.501, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.750, 10.245], loss: 0.001547, mae: 0.042284, mean_q: 1.174308
 133600/1000000: episode: 1336, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 61.128, mean reward: 0.611 [0.502, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.629, 10.124], loss: 0.001781, mae: 0.043609, mean_q: 1.167238
 133700/1000000: episode: 1337, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 56.970, mean reward: 0.570 [0.502, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.808, 10.281], loss: 0.001607, mae: 0.043873, mean_q: 1.172093
 133800/1000000: episode: 1338, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.478, mean reward: 0.605 [0.500, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.050, 10.098], loss: 0.001440, mae: 0.041631, mean_q: 1.170305
 133900/1000000: episode: 1339, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.839, mean reward: 0.618 [0.506, 0.841], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.873, 10.098], loss: 0.001392, mae: 0.040404, mean_q: 1.173356
 134000/1000000: episode: 1340, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.380, mean reward: 0.584 [0.506, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.411, 10.176], loss: 0.001414, mae: 0.040468, mean_q: 1.171430
 134100/1000000: episode: 1341, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.477, mean reward: 0.585 [0.506, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.352, 10.098], loss: 0.001566, mae: 0.042800, mean_q: 1.172066
 134200/1000000: episode: 1342, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.952, mean reward: 0.600 [0.509, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.334, 10.098], loss: 0.001476, mae: 0.041263, mean_q: 1.173245
 134300/1000000: episode: 1343, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.096, mean reward: 0.571 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.918, 10.098], loss: 0.001592, mae: 0.042941, mean_q: 1.172324
 134400/1000000: episode: 1344, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.010, mean reward: 0.580 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.586, 10.098], loss: 0.001664, mae: 0.043418, mean_q: 1.172106
 134500/1000000: episode: 1345, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.084, mean reward: 0.611 [0.498, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.989, 10.098], loss: 0.001515, mae: 0.042338, mean_q: 1.171749
 134600/1000000: episode: 1346, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.219, mean reward: 0.582 [0.497, 0.920], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.107, 10.181], loss: 0.001603, mae: 0.042684, mean_q: 1.172816
 134700/1000000: episode: 1347, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 56.949, mean reward: 0.569 [0.501, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.323, 10.098], loss: 0.001548, mae: 0.042753, mean_q: 1.172071
 134800/1000000: episode: 1348, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.943, mean reward: 0.579 [0.515, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.495, 10.158], loss: 0.001554, mae: 0.042042, mean_q: 1.172783
 134900/1000000: episode: 1349, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.968, mean reward: 0.580 [0.501, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.537, 10.202], loss: 0.001565, mae: 0.042540, mean_q: 1.171709
 135000/1000000: episode: 1350, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.642, mean reward: 0.576 [0.507, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.224, 10.098], loss: 0.001629, mae: 0.043280, mean_q: 1.172338
 135100/1000000: episode: 1351, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 67.867, mean reward: 0.679 [0.512, 0.902], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.594, 10.342], loss: 0.001561, mae: 0.042812, mean_q: 1.171155
 135200/1000000: episode: 1352, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.928, mean reward: 0.569 [0.507, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.844, 10.194], loss: 0.001575, mae: 0.042333, mean_q: 1.180386
 135300/1000000: episode: 1353, duration: 0.523s, episode steps: 100, steps per second: 191, episode reward: 58.556, mean reward: 0.586 [0.506, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.147, 10.151], loss: 0.001464, mae: 0.041562, mean_q: 1.173751
 135400/1000000: episode: 1354, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 56.842, mean reward: 0.568 [0.504, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.115, 10.240], loss: 0.001520, mae: 0.042503, mean_q: 1.175377
 135500/1000000: episode: 1355, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.462, mean reward: 0.585 [0.501, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.694, 10.156], loss: 0.001432, mae: 0.041230, mean_q: 1.172461
 135600/1000000: episode: 1356, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.458, mean reward: 0.585 [0.500, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.334, 10.098], loss: 0.001492, mae: 0.041374, mean_q: 1.170867
 135700/1000000: episode: 1357, duration: 0.604s, episode steps: 100, steps per second: 165, episode reward: 58.283, mean reward: 0.583 [0.505, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.695, 10.101], loss: 0.001418, mae: 0.040521, mean_q: 1.168709
 135800/1000000: episode: 1358, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 64.127, mean reward: 0.641 [0.502, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.645, 10.413], loss: 0.001586, mae: 0.043007, mean_q: 1.168918
 135900/1000000: episode: 1359, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.529, mean reward: 0.585 [0.508, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.844, 10.098], loss: 0.002053, mae: 0.046571, mean_q: 1.173494
 136000/1000000: episode: 1360, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.078, mean reward: 0.571 [0.501, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.610, 10.153], loss: 0.001508, mae: 0.042035, mean_q: 1.169134
 136100/1000000: episode: 1361, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.814, mean reward: 0.618 [0.505, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.934, 10.098], loss: 0.001568, mae: 0.042610, mean_q: 1.171127
 136200/1000000: episode: 1362, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.012, mean reward: 0.600 [0.517, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.448 [-1.301, 10.269], loss: 0.001523, mae: 0.042212, mean_q: 1.174316
 136300/1000000: episode: 1363, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 57.866, mean reward: 0.579 [0.508, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.878, 10.218], loss: 0.001652, mae: 0.044050, mean_q: 1.175844
 136400/1000000: episode: 1364, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.529, mean reward: 0.585 [0.504, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.786, 10.199], loss: 0.001606, mae: 0.043202, mean_q: 1.174925
 136500/1000000: episode: 1365, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.147, mean reward: 0.581 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.218, 10.098], loss: 0.001520, mae: 0.042761, mean_q: 1.172681
 136600/1000000: episode: 1366, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 56.259, mean reward: 0.563 [0.506, 0.660], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.506, 10.106], loss: 0.001464, mae: 0.041521, mean_q: 1.171568
 136700/1000000: episode: 1367, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.083, mean reward: 0.591 [0.505, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.488, 10.098], loss: 0.001510, mae: 0.042677, mean_q: 1.168352
 136800/1000000: episode: 1368, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.550, mean reward: 0.585 [0.506, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.631, 10.098], loss: 0.001569, mae: 0.042695, mean_q: 1.167997
 136900/1000000: episode: 1369, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.855, mean reward: 0.589 [0.504, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.721, 10.098], loss: 0.001475, mae: 0.041978, mean_q: 1.166355
 137000/1000000: episode: 1370, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.251, mean reward: 0.573 [0.512, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.798, 10.130], loss: 0.001544, mae: 0.042891, mean_q: 1.172359
 137100/1000000: episode: 1371, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 61.209, mean reward: 0.612 [0.515, 0.886], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.694, 10.098], loss: 0.001446, mae: 0.041522, mean_q: 1.167987
 137200/1000000: episode: 1372, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.744, mean reward: 0.577 [0.506, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.724, 10.187], loss: 0.001420, mae: 0.040867, mean_q: 1.167277
 137300/1000000: episode: 1373, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.113, mean reward: 0.571 [0.499, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.900, 10.108], loss: 0.001639, mae: 0.043327, mean_q: 1.164353
 137400/1000000: episode: 1374, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.776, mean reward: 0.608 [0.507, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.626, 10.268], loss: 0.001476, mae: 0.042081, mean_q: 1.162500
 137500/1000000: episode: 1375, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.924, mean reward: 0.579 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.442, 10.203], loss: 0.001519, mae: 0.042279, mean_q: 1.162837
 137600/1000000: episode: 1376, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.090, mean reward: 0.591 [0.507, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.341, 10.334], loss: 0.001574, mae: 0.043538, mean_q: 1.164617
 137700/1000000: episode: 1377, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.540, mean reward: 0.575 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.434, 10.098], loss: 0.001565, mae: 0.042616, mean_q: 1.166558
 137800/1000000: episode: 1378, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 62.568, mean reward: 0.626 [0.506, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.491, 10.239], loss: 0.001567, mae: 0.042996, mean_q: 1.160818
 137900/1000000: episode: 1379, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.582, mean reward: 0.596 [0.512, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.616, 10.098], loss: 0.001446, mae: 0.041365, mean_q: 1.165317
 138000/1000000: episode: 1380, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.177, mean reward: 0.572 [0.504, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.745, 10.222], loss: 0.001506, mae: 0.042205, mean_q: 1.165555
 138100/1000000: episode: 1381, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.928, mean reward: 0.579 [0.502, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.495, 10.098], loss: 0.001400, mae: 0.040840, mean_q: 1.163244
 138200/1000000: episode: 1382, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 58.585, mean reward: 0.586 [0.502, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.645, 10.098], loss: 0.001365, mae: 0.040930, mean_q: 1.162884
 138300/1000000: episode: 1383, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.508, mean reward: 0.595 [0.506, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.068, 10.303], loss: 0.001515, mae: 0.042244, mean_q: 1.165540
 138400/1000000: episode: 1384, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.347, mean reward: 0.563 [0.502, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.417, 10.177], loss: 0.001432, mae: 0.041550, mean_q: 1.160978
 138500/1000000: episode: 1385, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.550, mean reward: 0.605 [0.505, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.172, 10.121], loss: 0.001463, mae: 0.041951, mean_q: 1.166316
 138600/1000000: episode: 1386, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.447, mean reward: 0.574 [0.500, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.181, 10.099], loss: 0.001429, mae: 0.040997, mean_q: 1.162517
 138700/1000000: episode: 1387, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.661, mean reward: 0.577 [0.508, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.610, 10.250], loss: 0.001528, mae: 0.042953, mean_q: 1.164811
 138800/1000000: episode: 1388, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.253, mean reward: 0.583 [0.500, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.681, 10.158], loss: 0.001566, mae: 0.043239, mean_q: 1.166486
 138900/1000000: episode: 1389, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.451, mean reward: 0.605 [0.507, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.128, 10.098], loss: 0.001351, mae: 0.040648, mean_q: 1.160645
 139000/1000000: episode: 1390, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.029, mean reward: 0.590 [0.511, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.935, 10.183], loss: 0.001435, mae: 0.040971, mean_q: 1.162954
 139100/1000000: episode: 1391, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.977, mean reward: 0.590 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.229, 10.098], loss: 0.001443, mae: 0.041754, mean_q: 1.166671
 139200/1000000: episode: 1392, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.089, mean reward: 0.601 [0.501, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.283, 10.098], loss: 0.001380, mae: 0.040443, mean_q: 1.165810
 139300/1000000: episode: 1393, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.951, mean reward: 0.580 [0.502, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.370, 10.161], loss: 0.001431, mae: 0.041810, mean_q: 1.164274
 139400/1000000: episode: 1394, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 56.457, mean reward: 0.565 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.298, 10.147], loss: 0.001395, mae: 0.040672, mean_q: 1.162918
 139500/1000000: episode: 1395, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.776, mean reward: 0.598 [0.519, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.983, 10.098], loss: 0.001470, mae: 0.042350, mean_q: 1.165133
 139600/1000000: episode: 1396, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.362, mean reward: 0.574 [0.500, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.577, 10.098], loss: 0.001375, mae: 0.040529, mean_q: 1.161324
 139700/1000000: episode: 1397, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.002, mean reward: 0.580 [0.509, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.014, 10.098], loss: 0.001435, mae: 0.041409, mean_q: 1.161086
 139800/1000000: episode: 1398, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 57.682, mean reward: 0.577 [0.501, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.126, 10.098], loss: 0.001432, mae: 0.040954, mean_q: 1.159857
 139900/1000000: episode: 1399, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.511, mean reward: 0.605 [0.498, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.545, 10.098], loss: 0.001499, mae: 0.042195, mean_q: 1.161797
 140000/1000000: episode: 1400, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 56.926, mean reward: 0.569 [0.501, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.346, 10.349], loss: 0.001370, mae: 0.040252, mean_q: 1.164869
 140100/1000000: episode: 1401, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.458, mean reward: 0.605 [0.506, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.459, 10.098], loss: 0.001360, mae: 0.040531, mean_q: 1.163852
 140200/1000000: episode: 1402, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.865, mean reward: 0.589 [0.509, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.292, 10.098], loss: 0.001509, mae: 0.041999, mean_q: 1.163401
 140300/1000000: episode: 1403, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 64.353, mean reward: 0.644 [0.500, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.897, 10.319], loss: 0.001580, mae: 0.043580, mean_q: 1.162472
 140400/1000000: episode: 1404, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.897, mean reward: 0.609 [0.508, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.870, 10.098], loss: 0.001380, mae: 0.040416, mean_q: 1.161781
 140500/1000000: episode: 1405, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.337, mean reward: 0.593 [0.502, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.002, 10.209], loss: 0.001607, mae: 0.042643, mean_q: 1.165434
 140600/1000000: episode: 1406, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.375, mean reward: 0.594 [0.500, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.415, 10.105], loss: 0.001448, mae: 0.041791, mean_q: 1.164596
 140700/1000000: episode: 1407, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.615, mean reward: 0.586 [0.500, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.892, 10.157], loss: 0.001381, mae: 0.040489, mean_q: 1.163722
 140800/1000000: episode: 1408, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.453, mean reward: 0.575 [0.499, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.606, 10.098], loss: 0.001313, mae: 0.039900, mean_q: 1.165582
 140900/1000000: episode: 1409, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 61.364, mean reward: 0.614 [0.503, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.814, 10.098], loss: 0.001445, mae: 0.041588, mean_q: 1.167173
 141000/1000000: episode: 1410, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.761, mean reward: 0.588 [0.507, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.929, 10.331], loss: 0.001448, mae: 0.041483, mean_q: 1.167931
 141100/1000000: episode: 1411, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.953, mean reward: 0.580 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.327, 10.098], loss: 0.001428, mae: 0.041795, mean_q: 1.162722
 141200/1000000: episode: 1412, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.353, mean reward: 0.584 [0.504, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.915, 10.219], loss: 0.001384, mae: 0.040621, mean_q: 1.163499
 141300/1000000: episode: 1413, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.746, mean reward: 0.587 [0.506, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.261, 10.226], loss: 0.001424, mae: 0.041650, mean_q: 1.159295
 141400/1000000: episode: 1414, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.199, mean reward: 0.582 [0.497, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.581, 10.159], loss: 0.001388, mae: 0.040629, mean_q: 1.164356
 141500/1000000: episode: 1415, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.856, mean reward: 0.589 [0.506, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.729, 10.106], loss: 0.001488, mae: 0.040971, mean_q: 1.160964
 141600/1000000: episode: 1416, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.577, mean reward: 0.586 [0.501, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.294, 10.140], loss: 0.001414, mae: 0.040909, mean_q: 1.164039
 141700/1000000: episode: 1417, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 62.463, mean reward: 0.625 [0.516, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.930, 10.356], loss: 0.001345, mae: 0.039805, mean_q: 1.164683
 141800/1000000: episode: 1418, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.764, mean reward: 0.608 [0.514, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.421, 10.246], loss: 0.001423, mae: 0.041101, mean_q: 1.167281
 141900/1000000: episode: 1419, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.443, mean reward: 0.574 [0.506, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.524, 10.098], loss: 0.001517, mae: 0.042116, mean_q: 1.169085
 142000/1000000: episode: 1420, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.500, mean reward: 0.605 [0.516, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.465, 10.290], loss: 0.001335, mae: 0.039767, mean_q: 1.163480
 142100/1000000: episode: 1421, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.152, mean reward: 0.582 [0.506, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.526, 10.176], loss: 0.001345, mae: 0.040282, mean_q: 1.164675
 142200/1000000: episode: 1422, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.735, mean reward: 0.587 [0.502, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.860, 10.098], loss: 0.001430, mae: 0.041022, mean_q: 1.164463
 142300/1000000: episode: 1423, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.737, mean reward: 0.577 [0.504, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.613, 10.098], loss: 0.001512, mae: 0.042480, mean_q: 1.167009
 142400/1000000: episode: 1424, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.937, mean reward: 0.579 [0.508, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.022, 10.098], loss: 0.001459, mae: 0.041820, mean_q: 1.167449
 142500/1000000: episode: 1425, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 64.757, mean reward: 0.648 [0.503, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.413 [-0.751, 10.098], loss: 0.001460, mae: 0.040981, mean_q: 1.165106
 142600/1000000: episode: 1426, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 62.348, mean reward: 0.623 [0.502, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.755, 10.511], loss: 0.001452, mae: 0.040988, mean_q: 1.166255
 142700/1000000: episode: 1427, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.179, mean reward: 0.582 [0.499, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.886, 10.098], loss: 0.001490, mae: 0.041617, mean_q: 1.171817
 142800/1000000: episode: 1428, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 63.287, mean reward: 0.633 [0.516, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.845, 10.098], loss: 0.001375, mae: 0.040516, mean_q: 1.167636
 142900/1000000: episode: 1429, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.311, mean reward: 0.583 [0.514, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.747, 10.231], loss: 0.001434, mae: 0.041075, mean_q: 1.167232
 143000/1000000: episode: 1430, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.877, mean reward: 0.599 [0.504, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.675, 10.098], loss: 0.001721, mae: 0.043475, mean_q: 1.171081
 143100/1000000: episode: 1431, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.764, mean reward: 0.608 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.448, 10.098], loss: 0.001416, mae: 0.041176, mean_q: 1.169294
 143200/1000000: episode: 1432, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.009, mean reward: 0.580 [0.508, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.819, 10.207], loss: 0.001413, mae: 0.040861, mean_q: 1.172587
 143300/1000000: episode: 1433, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 64.910, mean reward: 0.649 [0.508, 0.885], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.115, 10.098], loss: 0.001362, mae: 0.040044, mean_q: 1.171913
 143400/1000000: episode: 1434, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 55.884, mean reward: 0.559 [0.499, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.775, 10.098], loss: 0.001523, mae: 0.041948, mean_q: 1.175668
 143500/1000000: episode: 1435, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.364, mean reward: 0.594 [0.503, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.928, 10.399], loss: 0.001650, mae: 0.043492, mean_q: 1.172979
 143600/1000000: episode: 1436, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.569, mean reward: 0.576 [0.500, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.601, 10.098], loss: 0.001510, mae: 0.041861, mean_q: 1.173097
 143700/1000000: episode: 1437, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.034, mean reward: 0.570 [0.507, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.676, 10.304], loss: 0.001387, mae: 0.040554, mean_q: 1.175302
 143800/1000000: episode: 1438, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 60.001, mean reward: 0.600 [0.504, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.695, 10.098], loss: 0.001475, mae: 0.041968, mean_q: 1.172444
 143900/1000000: episode: 1439, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.576, mean reward: 0.596 [0.506, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.183, 10.151], loss: 0.001453, mae: 0.040993, mean_q: 1.173439
 144000/1000000: episode: 1440, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.077, mean reward: 0.591 [0.511, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.874, 10.098], loss: 0.001599, mae: 0.043293, mean_q: 1.170020
 144100/1000000: episode: 1441, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.652, mean reward: 0.577 [0.512, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.639, 10.211], loss: 0.001407, mae: 0.040807, mean_q: 1.172795
 144200/1000000: episode: 1442, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.663, mean reward: 0.607 [0.503, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.596, 10.098], loss: 0.001397, mae: 0.040528, mean_q: 1.173375
 144300/1000000: episode: 1443, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.581, mean reward: 0.586 [0.499, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.739, 10.180], loss: 0.001478, mae: 0.041458, mean_q: 1.172936
 144400/1000000: episode: 1444, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 61.172, mean reward: 0.612 [0.521, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.495, 10.245], loss: 0.001423, mae: 0.041164, mean_q: 1.175106
 144500/1000000: episode: 1445, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.059, mean reward: 0.591 [0.504, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.320, 10.098], loss: 0.001476, mae: 0.041397, mean_q: 1.174807
 144600/1000000: episode: 1446, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.429, mean reward: 0.574 [0.501, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.862, 10.098], loss: 0.001480, mae: 0.041756, mean_q: 1.175445
 144700/1000000: episode: 1447, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.020, mean reward: 0.580 [0.500, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.925, 10.126], loss: 0.001457, mae: 0.041476, mean_q: 1.177919
 144800/1000000: episode: 1448, duration: 0.601s, episode steps: 100, steps per second: 167, episode reward: 60.932, mean reward: 0.609 [0.524, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.775, 10.098], loss: 0.001500, mae: 0.041740, mean_q: 1.176576
 144900/1000000: episode: 1449, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.343, mean reward: 0.613 [0.523, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.308, 10.098], loss: 0.001418, mae: 0.040936, mean_q: 1.178412
 145000/1000000: episode: 1450, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 56.725, mean reward: 0.567 [0.500, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.187, 10.098], loss: 0.001490, mae: 0.042094, mean_q: 1.174083
 145100/1000000: episode: 1451, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.602, mean reward: 0.596 [0.506, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.665, 10.142], loss: 0.001417, mae: 0.040763, mean_q: 1.174851
 145200/1000000: episode: 1452, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.168, mean reward: 0.582 [0.511, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.875, 10.098], loss: 0.001408, mae: 0.040463, mean_q: 1.173696
 145300/1000000: episode: 1453, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.456, mean reward: 0.595 [0.507, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.689, 10.098], loss: 0.001357, mae: 0.040282, mean_q: 1.174810
 145400/1000000: episode: 1454, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.834, mean reward: 0.588 [0.507, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.890, 10.098], loss: 0.001395, mae: 0.040647, mean_q: 1.173062
 145500/1000000: episode: 1455, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.037, mean reward: 0.590 [0.506, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.725, 10.098], loss: 0.001451, mae: 0.041405, mean_q: 1.172766
 145600/1000000: episode: 1456, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.590, mean reward: 0.586 [0.503, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.839, 10.098], loss: 0.001484, mae: 0.041275, mean_q: 1.173164
 145700/1000000: episode: 1457, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.399, mean reward: 0.604 [0.510, 0.885], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.085, 10.098], loss: 0.001349, mae: 0.039508, mean_q: 1.171269
 145800/1000000: episode: 1458, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.560, mean reward: 0.566 [0.501, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.002, 10.098], loss: 0.001422, mae: 0.040306, mean_q: 1.173756
 145900/1000000: episode: 1459, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.621, mean reward: 0.576 [0.506, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.099, 10.098], loss: 0.001303, mae: 0.039362, mean_q: 1.168474
 146000/1000000: episode: 1460, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 63.164, mean reward: 0.632 [0.524, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.312, 10.098], loss: 0.001366, mae: 0.040063, mean_q: 1.170459
 146100/1000000: episode: 1461, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.777, mean reward: 0.618 [0.522, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.649, 10.098], loss: 0.001530, mae: 0.042714, mean_q: 1.175675
 146200/1000000: episode: 1462, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.403, mean reward: 0.604 [0.508, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.597, 10.461], loss: 0.001341, mae: 0.039872, mean_q: 1.175243
 146300/1000000: episode: 1463, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.445, mean reward: 0.574 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.663, 10.255], loss: 0.001458, mae: 0.041249, mean_q: 1.175179
 146400/1000000: episode: 1464, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.167, mean reward: 0.592 [0.500, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.793, 10.394], loss: 0.001337, mae: 0.040052, mean_q: 1.177044
 146500/1000000: episode: 1465, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.677, mean reward: 0.597 [0.519, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.311, 10.213], loss: 0.001418, mae: 0.041046, mean_q: 1.173906
 146600/1000000: episode: 1466, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.352, mean reward: 0.584 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.258, 10.265], loss: 0.001462, mae: 0.041105, mean_q: 1.176578
 146700/1000000: episode: 1467, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.657, mean reward: 0.597 [0.504, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.831, 10.098], loss: 0.001459, mae: 0.041214, mean_q: 1.179054
 146800/1000000: episode: 1468, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.994, mean reward: 0.590 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.358, 10.301], loss: 0.001461, mae: 0.041702, mean_q: 1.174531
 146900/1000000: episode: 1469, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.253, mean reward: 0.593 [0.506, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.235, 10.214], loss: 0.001626, mae: 0.043755, mean_q: 1.172083
 147000/1000000: episode: 1470, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 57.050, mean reward: 0.570 [0.500, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.423, 10.333], loss: 0.001507, mae: 0.041915, mean_q: 1.172235
 147100/1000000: episode: 1471, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.180, mean reward: 0.572 [0.508, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.698, 10.344], loss: 0.001385, mae: 0.040740, mean_q: 1.171312
 147200/1000000: episode: 1472, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 59.430, mean reward: 0.594 [0.507, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-2.382, 10.098], loss: 0.001368, mae: 0.040612, mean_q: 1.173397
 147300/1000000: episode: 1473, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.082, mean reward: 0.571 [0.503, 0.664], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.701, 10.149], loss: 0.001460, mae: 0.040975, mean_q: 1.175707
 147400/1000000: episode: 1474, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.559, mean reward: 0.576 [0.510, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.598, 10.098], loss: 0.001316, mae: 0.039920, mean_q: 1.170738
 147500/1000000: episode: 1475, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.746, mean reward: 0.577 [0.510, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.692, 10.204], loss: 0.001353, mae: 0.040200, mean_q: 1.171565
 147600/1000000: episode: 1476, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.633, mean reward: 0.576 [0.503, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.946, 10.098], loss: 0.001404, mae: 0.040653, mean_q: 1.168295
 147700/1000000: episode: 1477, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.669, mean reward: 0.577 [0.502, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.098, 10.118], loss: 0.001391, mae: 0.040803, mean_q: 1.168356
 147800/1000000: episode: 1478, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.848, mean reward: 0.608 [0.509, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.577, 10.098], loss: 0.001354, mae: 0.040146, mean_q: 1.164517
 147900/1000000: episode: 1479, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.977, mean reward: 0.570 [0.512, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.898, 10.233], loss: 0.001480, mae: 0.041597, mean_q: 1.167624
 148000/1000000: episode: 1480, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.507, mean reward: 0.585 [0.504, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.513, 10.098], loss: 0.001358, mae: 0.040534, mean_q: 1.167040
 148100/1000000: episode: 1481, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.949, mean reward: 0.579 [0.499, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.116, 10.148], loss: 0.001449, mae: 0.040857, mean_q: 1.165219
 148200/1000000: episode: 1482, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.304, mean reward: 0.603 [0.506, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.661, 10.304], loss: 0.001524, mae: 0.042258, mean_q: 1.163122
 148300/1000000: episode: 1483, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 55.973, mean reward: 0.560 [0.499, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.485, 10.139], loss: 0.001464, mae: 0.041261, mean_q: 1.161089
 148400/1000000: episode: 1484, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.250, mean reward: 0.582 [0.503, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.491, 10.248], loss: 0.001296, mae: 0.039085, mean_q: 1.161107
 148500/1000000: episode: 1485, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.900, mean reward: 0.589 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.010, 10.098], loss: 0.001250, mae: 0.038564, mean_q: 1.160176
 148600/1000000: episode: 1486, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 57.623, mean reward: 0.576 [0.499, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.555, 10.098], loss: 0.001355, mae: 0.040121, mean_q: 1.163647
 148700/1000000: episode: 1487, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.401, mean reward: 0.584 [0.498, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.645, 10.302], loss: 0.001304, mae: 0.039200, mean_q: 1.161655
 148800/1000000: episode: 1488, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.186, mean reward: 0.582 [0.506, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.974, 10.176], loss: 0.001342, mae: 0.039704, mean_q: 1.163497
 148900/1000000: episode: 1489, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.358, mean reward: 0.604 [0.524, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.569, 10.409], loss: 0.001330, mae: 0.039242, mean_q: 1.161555
 149000/1000000: episode: 1490, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.510, mean reward: 0.575 [0.504, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.780, 10.174], loss: 0.001337, mae: 0.040220, mean_q: 1.164485
 149100/1000000: episode: 1491, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.306, mean reward: 0.573 [0.501, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.002, 10.128], loss: 0.001301, mae: 0.038710, mean_q: 1.163972
 149200/1000000: episode: 1492, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.685, mean reward: 0.587 [0.501, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.574, 10.098], loss: 0.001343, mae: 0.039466, mean_q: 1.161038
 149300/1000000: episode: 1493, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 61.307, mean reward: 0.613 [0.502, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.676, 10.098], loss: 0.001227, mae: 0.038030, mean_q: 1.161028
 149400/1000000: episode: 1494, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.320, mean reward: 0.603 [0.503, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.428, 10.148], loss: 0.001330, mae: 0.039418, mean_q: 1.162317
 149500/1000000: episode: 1495, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.072, mean reward: 0.591 [0.503, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.446 [-1.071, 10.260], loss: 0.001430, mae: 0.040865, mean_q: 1.161135
 149600/1000000: episode: 1496, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.840, mean reward: 0.598 [0.509, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.434, 10.098], loss: 0.001291, mae: 0.039031, mean_q: 1.162290
 149700/1000000: episode: 1497, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.708, mean reward: 0.567 [0.504, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.900, 10.253], loss: 0.001473, mae: 0.040191, mean_q: 1.163407
 149800/1000000: episode: 1498, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 59.301, mean reward: 0.593 [0.499, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.204, 10.165], loss: 0.001426, mae: 0.040724, mean_q: 1.158959
 149900/1000000: episode: 1499, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.762, mean reward: 0.588 [0.508, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.938, 10.189], loss: 0.001286, mae: 0.038712, mean_q: 1.162900
 150000/1000000: episode: 1500, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.886, mean reward: 0.579 [0.501, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.448, 10.208], loss: 0.001396, mae: 0.040555, mean_q: 1.164378
 150100/1000000: episode: 1501, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.574, mean reward: 0.586 [0.504, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.436, 10.098], loss: 0.001443, mae: 0.040361, mean_q: 1.161680
 150200/1000000: episode: 1502, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 60.124, mean reward: 0.601 [0.503, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.686, 10.238], loss: 0.001484, mae: 0.041859, mean_q: 1.161846
 150300/1000000: episode: 1503, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.610, mean reward: 0.576 [0.499, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.960, 10.098], loss: 0.001359, mae: 0.039951, mean_q: 1.159384
 150400/1000000: episode: 1504, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 61.320, mean reward: 0.613 [0.504, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.040, 10.187], loss: 0.001423, mae: 0.040439, mean_q: 1.159953
 150500/1000000: episode: 1505, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.586, mean reward: 0.596 [0.508, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.786, 10.098], loss: 0.001452, mae: 0.041170, mean_q: 1.163826
 150600/1000000: episode: 1506, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.637, mean reward: 0.596 [0.509, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.909, 10.354], loss: 0.001376, mae: 0.040062, mean_q: 1.161528
 150700/1000000: episode: 1507, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.466, mean reward: 0.585 [0.513, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.795, 10.256], loss: 0.001237, mae: 0.038351, mean_q: 1.161346
 150800/1000000: episode: 1508, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.951, mean reward: 0.600 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.920, 10.098], loss: 0.001368, mae: 0.040006, mean_q: 1.166458
 150900/1000000: episode: 1509, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.161, mean reward: 0.582 [0.508, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.534, 10.224], loss: 0.001350, mae: 0.039787, mean_q: 1.166483
 151000/1000000: episode: 1510, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.677, mean reward: 0.607 [0.506, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.594, 10.098], loss: 0.001455, mae: 0.041125, mean_q: 1.162598
 151100/1000000: episode: 1511, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.138, mean reward: 0.591 [0.507, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.739, 10.320], loss: 0.001307, mae: 0.039292, mean_q: 1.159980
 151200/1000000: episode: 1512, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.514, mean reward: 0.595 [0.502, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.751, 10.283], loss: 0.001318, mae: 0.039381, mean_q: 1.162780
 151300/1000000: episode: 1513, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.506, mean reward: 0.575 [0.499, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.018, 10.238], loss: 0.001442, mae: 0.040921, mean_q: 1.162519
 151400/1000000: episode: 1514, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.176, mean reward: 0.582 [0.500, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.680, 10.177], loss: 0.001488, mae: 0.041438, mean_q: 1.163648
 151500/1000000: episode: 1515, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.793, mean reward: 0.598 [0.504, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.283, 10.408], loss: 0.001680, mae: 0.043030, mean_q: 1.160220
 151600/1000000: episode: 1516, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.575, mean reward: 0.576 [0.499, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.704, 10.118], loss: 0.001400, mae: 0.040482, mean_q: 1.163285
 151700/1000000: episode: 1517, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.667, mean reward: 0.587 [0.498, 0.870], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.538, 10.098], loss: 0.001406, mae: 0.040141, mean_q: 1.162815
 151800/1000000: episode: 1518, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.962, mean reward: 0.590 [0.503, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.520, 10.264], loss: 0.001389, mae: 0.040544, mean_q: 1.159949
 151900/1000000: episode: 1519, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.870, mean reward: 0.579 [0.498, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.661, 10.098], loss: 0.001319, mae: 0.039241, mean_q: 1.157692
 152000/1000000: episode: 1520, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.990, mean reward: 0.580 [0.508, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.506, 10.143], loss: 0.001545, mae: 0.041898, mean_q: 1.160232
 152100/1000000: episode: 1521, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.114, mean reward: 0.571 [0.502, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.189, 10.114], loss: 0.001367, mae: 0.039984, mean_q: 1.160472
 152200/1000000: episode: 1522, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.178, mean reward: 0.592 [0.510, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.989, 10.294], loss: 0.001374, mae: 0.039927, mean_q: 1.159832
 152300/1000000: episode: 1523, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.478, mean reward: 0.575 [0.507, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.571, 10.098], loss: 0.001402, mae: 0.040121, mean_q: 1.160240
 152400/1000000: episode: 1524, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.018, mean reward: 0.580 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.536, 10.098], loss: 0.001394, mae: 0.040373, mean_q: 1.158859
 152500/1000000: episode: 1525, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 62.795, mean reward: 0.628 [0.504, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.313, 10.315], loss: 0.001436, mae: 0.040889, mean_q: 1.158163
 152600/1000000: episode: 1526, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.622, mean reward: 0.576 [0.502, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.559, 10.153], loss: 0.001484, mae: 0.042011, mean_q: 1.161813
 152700/1000000: episode: 1527, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.436, mean reward: 0.594 [0.503, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.675, 10.098], loss: 0.001489, mae: 0.041065, mean_q: 1.162658
 152800/1000000: episode: 1528, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 61.735, mean reward: 0.617 [0.502, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.546, 10.098], loss: 0.001483, mae: 0.042185, mean_q: 1.164905
 152900/1000000: episode: 1529, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 56.104, mean reward: 0.561 [0.503, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.711, 10.162], loss: 0.001450, mae: 0.041332, mean_q: 1.162964
 153000/1000000: episode: 1530, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.558, mean reward: 0.596 [0.504, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.812, 10.332], loss: 0.001375, mae: 0.040456, mean_q: 1.164272
 153100/1000000: episode: 1531, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 61.417, mean reward: 0.614 [0.513, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.152, 10.402], loss: 0.001381, mae: 0.040783, mean_q: 1.162092
 153200/1000000: episode: 1532, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.099, mean reward: 0.571 [0.503, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.706, 10.245], loss: 0.001446, mae: 0.041478, mean_q: 1.166662
 153300/1000000: episode: 1533, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.201, mean reward: 0.572 [0.507, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.040, 10.098], loss: 0.001376, mae: 0.040599, mean_q: 1.162184
 153400/1000000: episode: 1534, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.926, mean reward: 0.579 [0.507, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.861, 10.333], loss: 0.001428, mae: 0.041284, mean_q: 1.162299
 153500/1000000: episode: 1535, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.746, mean reward: 0.607 [0.513, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.604, 10.183], loss: 0.001529, mae: 0.042628, mean_q: 1.164073
 153600/1000000: episode: 1536, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.051, mean reward: 0.601 [0.500, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.202, 10.098], loss: 0.001416, mae: 0.041444, mean_q: 1.165637
 153700/1000000: episode: 1537, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 56.460, mean reward: 0.565 [0.499, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.468, 10.114], loss: 0.001724, mae: 0.044282, mean_q: 1.165013
 153800/1000000: episode: 1538, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.182, mean reward: 0.592 [0.514, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.790, 10.359], loss: 0.001682, mae: 0.043538, mean_q: 1.163416
 153900/1000000: episode: 1539, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.338, mean reward: 0.583 [0.508, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.277, 10.240], loss: 0.001479, mae: 0.042125, mean_q: 1.163116
 154000/1000000: episode: 1540, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.138, mean reward: 0.571 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.754, 10.181], loss: 0.001335, mae: 0.040039, mean_q: 1.161734
 154100/1000000: episode: 1541, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.871, mean reward: 0.589 [0.499, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.690, 10.098], loss: 0.001464, mae: 0.041370, mean_q: 1.163583
 154200/1000000: episode: 1542, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.779, mean reward: 0.608 [0.502, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.816, 10.101], loss: 0.001447, mae: 0.041396, mean_q: 1.163328
 154300/1000000: episode: 1543, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.013, mean reward: 0.600 [0.511, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.044, 10.098], loss: 0.001446, mae: 0.041458, mean_q: 1.162446
 154400/1000000: episode: 1544, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.180, mean reward: 0.602 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.476, 10.347], loss: 0.001524, mae: 0.042969, mean_q: 1.160322
 154500/1000000: episode: 1545, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.847, mean reward: 0.578 [0.507, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.719, 10.116], loss: 0.001416, mae: 0.041301, mean_q: 1.163422
 154600/1000000: episode: 1546, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.632, mean reward: 0.596 [0.511, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.639, 10.142], loss: 0.001427, mae: 0.040818, mean_q: 1.163996
 154700/1000000: episode: 1547, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.081, mean reward: 0.601 [0.512, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.103, 10.412], loss: 0.001539, mae: 0.042228, mean_q: 1.164961
 154800/1000000: episode: 1548, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.838, mean reward: 0.578 [0.501, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.302, 10.112], loss: 0.001563, mae: 0.042595, mean_q: 1.163774
 154900/1000000: episode: 1549, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.244, mean reward: 0.572 [0.507, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.818, 10.105], loss: 0.001427, mae: 0.041125, mean_q: 1.163607
 155000/1000000: episode: 1550, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.447, mean reward: 0.584 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.034, 10.378], loss: 0.001392, mae: 0.040208, mean_q: 1.164390
 155100/1000000: episode: 1551, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.856, mean reward: 0.579 [0.502, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.111, 10.098], loss: 0.001475, mae: 0.042169, mean_q: 1.164338
 155200/1000000: episode: 1552, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.846, mean reward: 0.598 [0.516, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.458, 10.098], loss: 0.001707, mae: 0.044275, mean_q: 1.159526
 155300/1000000: episode: 1553, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.582, mean reward: 0.586 [0.500, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.045, 10.242], loss: 0.001473, mae: 0.041654, mean_q: 1.163633
 155400/1000000: episode: 1554, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.743, mean reward: 0.617 [0.499, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.622, 10.103], loss: 0.001511, mae: 0.042552, mean_q: 1.165020
 155500/1000000: episode: 1555, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.791, mean reward: 0.588 [0.515, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.875, 10.199], loss: 0.001522, mae: 0.042131, mean_q: 1.164771
 155600/1000000: episode: 1556, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.417, mean reward: 0.574 [0.501, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.843, 10.240], loss: 0.001465, mae: 0.041573, mean_q: 1.164045
 155700/1000000: episode: 1557, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.628, mean reward: 0.576 [0.507, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.693, 10.098], loss: 0.001463, mae: 0.041663, mean_q: 1.166154
 155800/1000000: episode: 1558, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.894, mean reward: 0.599 [0.503, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.925, 10.098], loss: 0.001446, mae: 0.040539, mean_q: 1.162509
 155900/1000000: episode: 1559, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.682, mean reward: 0.577 [0.501, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.074, 10.098], loss: 0.001479, mae: 0.042077, mean_q: 1.166920
 156000/1000000: episode: 1560, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.371, mean reward: 0.564 [0.504, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.251, 10.098], loss: 0.001453, mae: 0.041363, mean_q: 1.165336
 156100/1000000: episode: 1561, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.397, mean reward: 0.594 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-2.326, 10.267], loss: 0.001519, mae: 0.041902, mean_q: 1.164066
 156200/1000000: episode: 1562, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.855, mean reward: 0.589 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.305, 10.098], loss: 0.001439, mae: 0.040741, mean_q: 1.161673
 156300/1000000: episode: 1563, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.877, mean reward: 0.579 [0.504, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.596, 10.098], loss: 0.001402, mae: 0.040529, mean_q: 1.165193
 156400/1000000: episode: 1564, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.964, mean reward: 0.570 [0.499, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.882, 10.210], loss: 0.001372, mae: 0.040199, mean_q: 1.161147
 156500/1000000: episode: 1565, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.736, mean reward: 0.567 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.092, 10.098], loss: 0.001484, mae: 0.041577, mean_q: 1.162710
 156600/1000000: episode: 1566, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.917, mean reward: 0.579 [0.503, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.742, 10.098], loss: 0.001368, mae: 0.039908, mean_q: 1.160806
 156700/1000000: episode: 1567, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.509, mean reward: 0.575 [0.513, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.889, 10.200], loss: 0.001423, mae: 0.041203, mean_q: 1.158662
 156800/1000000: episode: 1568, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.410, mean reward: 0.584 [0.511, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.417, 10.098], loss: 0.001354, mae: 0.039460, mean_q: 1.157676
 156900/1000000: episode: 1569, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 57.911, mean reward: 0.579 [0.505, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.695, 10.098], loss: 0.001356, mae: 0.040050, mean_q: 1.158977
 157000/1000000: episode: 1570, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.120, mean reward: 0.581 [0.517, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.339, 10.131], loss: 0.001406, mae: 0.040473, mean_q: 1.160222
 157100/1000000: episode: 1571, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.770, mean reward: 0.608 [0.498, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.708, 10.098], loss: 0.001385, mae: 0.040789, mean_q: 1.160226
 157200/1000000: episode: 1572, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.946, mean reward: 0.619 [0.508, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.101, 10.098], loss: 0.001368, mae: 0.040089, mean_q: 1.162385
 157300/1000000: episode: 1573, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.762, mean reward: 0.578 [0.507, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.891, 10.098], loss: 0.001533, mae: 0.042141, mean_q: 1.163381
 157400/1000000: episode: 1574, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 60.849, mean reward: 0.608 [0.528, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.292, 10.316], loss: 0.001384, mae: 0.040913, mean_q: 1.163106
 157500/1000000: episode: 1575, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.851, mean reward: 0.599 [0.503, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.323, 10.286], loss: 0.001508, mae: 0.042089, mean_q: 1.160932
 157600/1000000: episode: 1576, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 61.977, mean reward: 0.620 [0.515, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-1.146, 10.098], loss: 0.001412, mae: 0.041212, mean_q: 1.160619
 157700/1000000: episode: 1577, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.168, mean reward: 0.582 [0.512, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.282, 10.157], loss: 0.001412, mae: 0.041239, mean_q: 1.161555
 157800/1000000: episode: 1578, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.923, mean reward: 0.619 [0.515, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.456, 10.098], loss: 0.001465, mae: 0.041114, mean_q: 1.161373
 157900/1000000: episode: 1579, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.839, mean reward: 0.588 [0.499, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.511, 10.151], loss: 0.001436, mae: 0.040921, mean_q: 1.164752
 158000/1000000: episode: 1580, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.836, mean reward: 0.588 [0.500, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.060, 10.229], loss: 0.001368, mae: 0.040284, mean_q: 1.161701
 158100/1000000: episode: 1581, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 61.750, mean reward: 0.617 [0.505, 0.893], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.626, 10.098], loss: 0.001467, mae: 0.041811, mean_q: 1.162578
 158200/1000000: episode: 1582, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.208, mean reward: 0.582 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.970, 10.264], loss: 0.001608, mae: 0.042404, mean_q: 1.163680
 158300/1000000: episode: 1583, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.843, mean reward: 0.588 [0.505, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.421, 10.098], loss: 0.001674, mae: 0.043661, mean_q: 1.166187
 158400/1000000: episode: 1584, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.197, mean reward: 0.572 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.490, 10.098], loss: 0.001513, mae: 0.042033, mean_q: 1.163217
 158500/1000000: episode: 1585, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 63.319, mean reward: 0.633 [0.506, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.840, 10.098], loss: 0.001408, mae: 0.040202, mean_q: 1.159622
 158600/1000000: episode: 1586, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.931, mean reward: 0.619 [0.504, 0.871], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.011, 10.098], loss: 0.001394, mae: 0.040516, mean_q: 1.167088
 158700/1000000: episode: 1587, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.891, mean reward: 0.579 [0.505, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.309, 10.098], loss: 0.001515, mae: 0.042084, mean_q: 1.167861
 158800/1000000: episode: 1588, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.848, mean reward: 0.568 [0.501, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.277, 10.244], loss: 0.001386, mae: 0.040094, mean_q: 1.166524
 158900/1000000: episode: 1589, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.031, mean reward: 0.590 [0.499, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.448, 10.098], loss: 0.001388, mae: 0.040689, mean_q: 1.164624
 159000/1000000: episode: 1590, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 60.458, mean reward: 0.605 [0.499, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.569, 10.098], loss: 0.001467, mae: 0.041181, mean_q: 1.165317
 159100/1000000: episode: 1591, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.100, mean reward: 0.601 [0.506, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.127, 10.128], loss: 0.001527, mae: 0.041904, mean_q: 1.171136
 159200/1000000: episode: 1592, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.398, mean reward: 0.574 [0.503, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.313, 10.098], loss: 0.001549, mae: 0.042029, mean_q: 1.167369
 159300/1000000: episode: 1593, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.104, mean reward: 0.571 [0.507, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.214, 10.194], loss: 0.001396, mae: 0.040225, mean_q: 1.169609
 159400/1000000: episode: 1594, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.576, mean reward: 0.616 [0.520, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.429, 10.417], loss: 0.001411, mae: 0.040451, mean_q: 1.163468
 159500/1000000: episode: 1595, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.253, mean reward: 0.593 [0.499, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.489, 10.491], loss: 0.001384, mae: 0.040863, mean_q: 1.167207
 159600/1000000: episode: 1596, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.880, mean reward: 0.579 [0.501, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.700, 10.098], loss: 0.001385, mae: 0.039928, mean_q: 1.167211
 159700/1000000: episode: 1597, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 60.611, mean reward: 0.606 [0.517, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.078, 10.214], loss: 0.001396, mae: 0.040488, mean_q: 1.166843
 159800/1000000: episode: 1598, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.235, mean reward: 0.582 [0.502, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.978, 10.129], loss: 0.001439, mae: 0.041078, mean_q: 1.167314
 159900/1000000: episode: 1599, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.725, mean reward: 0.587 [0.510, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.866, 10.098], loss: 0.001298, mae: 0.038913, mean_q: 1.167591
 160000/1000000: episode: 1600, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.061, mean reward: 0.601 [0.500, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.058, 10.148], loss: 0.001330, mae: 0.040070, mean_q: 1.167953
 160100/1000000: episode: 1601, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 56.892, mean reward: 0.569 [0.501, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.769, 10.207], loss: 0.001476, mae: 0.041578, mean_q: 1.167745
 160200/1000000: episode: 1602, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.054, mean reward: 0.591 [0.497, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.800, 10.203], loss: 0.001458, mae: 0.041227, mean_q: 1.166187
 160300/1000000: episode: 1603, duration: 0.519s, episode steps: 100, steps per second: 193, episode reward: 59.455, mean reward: 0.595 [0.505, 0.858], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.622, 10.337], loss: 0.001398, mae: 0.040915, mean_q: 1.168648
 160400/1000000: episode: 1604, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.901, mean reward: 0.579 [0.502, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.877, 10.154], loss: 0.001449, mae: 0.041259, mean_q: 1.165908
 160500/1000000: episode: 1605, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.178, mean reward: 0.572 [0.500, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.897, 10.098], loss: 0.001477, mae: 0.041692, mean_q: 1.167538
 160600/1000000: episode: 1606, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.769, mean reward: 0.578 [0.502, 0.667], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.488, 10.226], loss: 0.001503, mae: 0.042132, mean_q: 1.164691
 160700/1000000: episode: 1607, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.721, mean reward: 0.567 [0.503, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.497, 10.154], loss: 0.001453, mae: 0.041244, mean_q: 1.169196
 160800/1000000: episode: 1608, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.125, mean reward: 0.571 [0.502, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.049, 10.163], loss: 0.001379, mae: 0.040778, mean_q: 1.166368
 160900/1000000: episode: 1609, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 62.847, mean reward: 0.628 [0.514, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.634, 10.358], loss: 0.001629, mae: 0.043987, mean_q: 1.163745
 161000/1000000: episode: 1610, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.013, mean reward: 0.590 [0.499, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.249, 10.098], loss: 0.001353, mae: 0.040072, mean_q: 1.168397
 161100/1000000: episode: 1611, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.843, mean reward: 0.588 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.071, 10.397], loss: 0.001476, mae: 0.041845, mean_q: 1.166173
 161200/1000000: episode: 1612, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.700, mean reward: 0.587 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.429, 10.098], loss: 0.001393, mae: 0.041091, mean_q: 1.168701
 161300/1000000: episode: 1613, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.994, mean reward: 0.580 [0.507, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.910, 10.195], loss: 0.001424, mae: 0.041271, mean_q: 1.167926
 161400/1000000: episode: 1614, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.862, mean reward: 0.599 [0.505, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.062, 10.098], loss: 0.001476, mae: 0.041329, mean_q: 1.169761
 161500/1000000: episode: 1615, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.441, mean reward: 0.584 [0.507, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.922, 10.144], loss: 0.001372, mae: 0.040311, mean_q: 1.168146
 161600/1000000: episode: 1616, duration: 0.522s, episode steps: 100, steps per second: 192, episode reward: 68.473, mean reward: 0.685 [0.508, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.189, 10.495], loss: 0.001515, mae: 0.042413, mean_q: 1.169146
 161700/1000000: episode: 1617, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.925, mean reward: 0.599 [0.506, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.370, 10.147], loss: 0.001544, mae: 0.043065, mean_q: 1.172655
 161800/1000000: episode: 1618, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.278, mean reward: 0.583 [0.510, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.772, 10.098], loss: 0.001655, mae: 0.043761, mean_q: 1.177173
 161900/1000000: episode: 1619, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 56.401, mean reward: 0.564 [0.499, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.814, 10.130], loss: 0.001418, mae: 0.040834, mean_q: 1.179159
 162000/1000000: episode: 1620, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.234, mean reward: 0.572 [0.502, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.768, 10.098], loss: 0.001444, mae: 0.041658, mean_q: 1.173285
 162100/1000000: episode: 1621, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.509, mean reward: 0.585 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.535, 10.098], loss: 0.001374, mae: 0.040761, mean_q: 1.173680
 162200/1000000: episode: 1622, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.350, mean reward: 0.583 [0.502, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.372, 10.098], loss: 0.001439, mae: 0.041393, mean_q: 1.173648
 162300/1000000: episode: 1623, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.020, mean reward: 0.580 [0.503, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.856, 10.226], loss: 0.001681, mae: 0.043595, mean_q: 1.171550
 162400/1000000: episode: 1624, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.400, mean reward: 0.594 [0.504, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.027, 10.141], loss: 0.001453, mae: 0.041747, mean_q: 1.169528
 162500/1000000: episode: 1625, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 61.495, mean reward: 0.615 [0.506, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.379, 10.298], loss: 0.001399, mae: 0.040659, mean_q: 1.169377
 162600/1000000: episode: 1626, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.500, mean reward: 0.595 [0.502, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.062, 10.098], loss: 0.001515, mae: 0.042062, mean_q: 1.172527
 162700/1000000: episode: 1627, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 61.462, mean reward: 0.615 [0.497, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.650, 10.098], loss: 0.001418, mae: 0.041379, mean_q: 1.169766
 162800/1000000: episode: 1628, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.351, mean reward: 0.584 [0.508, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.861, 10.098], loss: 0.001529, mae: 0.043170, mean_q: 1.174175
 162900/1000000: episode: 1629, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.705, mean reward: 0.587 [0.512, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.599, 10.098], loss: 0.001473, mae: 0.041889, mean_q: 1.169649
 163000/1000000: episode: 1630, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 63.655, mean reward: 0.637 [0.504, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.527, 10.492], loss: 0.001525, mae: 0.042728, mean_q: 1.170612
 163100/1000000: episode: 1631, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.688, mean reward: 0.577 [0.501, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.307, 10.148], loss: 0.001437, mae: 0.041228, mean_q: 1.171407
 163200/1000000: episode: 1632, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.056, mean reward: 0.591 [0.509, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.016, 10.098], loss: 0.001321, mae: 0.039959, mean_q: 1.170562
 163300/1000000: episode: 1633, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.236, mean reward: 0.602 [0.505, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.922, 10.098], loss: 0.001397, mae: 0.041331, mean_q: 1.173394
 163400/1000000: episode: 1634, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.184, mean reward: 0.562 [0.505, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.772, 10.126], loss: 0.001307, mae: 0.039918, mean_q: 1.168879
 163500/1000000: episode: 1635, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.970, mean reward: 0.590 [0.506, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.564, 10.238], loss: 0.001355, mae: 0.040559, mean_q: 1.167429
 163600/1000000: episode: 1636, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.847, mean reward: 0.588 [0.508, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.945, 10.293], loss: 0.001329, mae: 0.040660, mean_q: 1.164984
 163700/1000000: episode: 1637, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 56.619, mean reward: 0.566 [0.500, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.089, 10.098], loss: 0.001423, mae: 0.041642, mean_q: 1.169346
 163800/1000000: episode: 1638, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.452, mean reward: 0.575 [0.499, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.859, 10.241], loss: 0.001371, mae: 0.040602, mean_q: 1.168850
 163900/1000000: episode: 1639, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.405, mean reward: 0.584 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.846, 10.174], loss: 0.001384, mae: 0.041191, mean_q: 1.168501
 164000/1000000: episode: 1640, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.577, mean reward: 0.576 [0.501, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.847, 10.156], loss: 0.001314, mae: 0.039510, mean_q: 1.164467
 164100/1000000: episode: 1641, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 61.090, mean reward: 0.611 [0.513, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.462, 10.098], loss: 0.001313, mae: 0.040023, mean_q: 1.164194
 164200/1000000: episode: 1642, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.523, mean reward: 0.565 [0.504, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.760, 10.141], loss: 0.001385, mae: 0.041010, mean_q: 1.166042
 164300/1000000: episode: 1643, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.614, mean reward: 0.616 [0.500, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.444, 10.098], loss: 0.001368, mae: 0.040473, mean_q: 1.167215
 164400/1000000: episode: 1644, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 58.488, mean reward: 0.585 [0.513, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.614, 10.098], loss: 0.001555, mae: 0.042582, mean_q: 1.169924
 164500/1000000: episode: 1645, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 60.355, mean reward: 0.604 [0.508, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.872, 10.098], loss: 0.001460, mae: 0.041982, mean_q: 1.169558
 164600/1000000: episode: 1646, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 61.420, mean reward: 0.614 [0.511, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.647, 10.098], loss: 0.001358, mae: 0.041102, mean_q: 1.170526
 164700/1000000: episode: 1647, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.220, mean reward: 0.582 [0.510, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.635, 10.355], loss: 0.001396, mae: 0.041273, mean_q: 1.170740
 164800/1000000: episode: 1648, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.887, mean reward: 0.579 [0.501, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.162, 10.098], loss: 0.001362, mae: 0.040947, mean_q: 1.164596
 164900/1000000: episode: 1649, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 58.405, mean reward: 0.584 [0.509, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.018, 10.363], loss: 0.001389, mae: 0.041419, mean_q: 1.168268
 165000/1000000: episode: 1650, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.938, mean reward: 0.579 [0.513, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.467, 10.098], loss: 0.001377, mae: 0.040950, mean_q: 1.167132
 165100/1000000: episode: 1651, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.678, mean reward: 0.577 [0.513, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.364, 10.251], loss: 0.001359, mae: 0.040991, mean_q: 1.169286
 165200/1000000: episode: 1652, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.656, mean reward: 0.587 [0.508, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.935, 10.098], loss: 0.001412, mae: 0.041232, mean_q: 1.167672
 165300/1000000: episode: 1653, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.245, mean reward: 0.602 [0.507, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.061, 10.098], loss: 0.001370, mae: 0.040914, mean_q: 1.165136
 165400/1000000: episode: 1654, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.492, mean reward: 0.575 [0.503, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.581, 10.289], loss: 0.001338, mae: 0.040120, mean_q: 1.167142
 165500/1000000: episode: 1655, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.403, mean reward: 0.604 [0.516, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.336, 10.212], loss: 0.001321, mae: 0.040425, mean_q: 1.168355
 165600/1000000: episode: 1656, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 60.233, mean reward: 0.602 [0.502, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.126, 10.141], loss: 0.001393, mae: 0.041171, mean_q: 1.168468
 165700/1000000: episode: 1657, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 63.693, mean reward: 0.637 [0.518, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.982, 10.419], loss: 0.001460, mae: 0.042234, mean_q: 1.172680
 165800/1000000: episode: 1658, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.224, mean reward: 0.592 [0.505, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.254, 10.098], loss: 0.001431, mae: 0.041524, mean_q: 1.174034
 165900/1000000: episode: 1659, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.707, mean reward: 0.577 [0.502, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.357, 10.205], loss: 0.001397, mae: 0.041457, mean_q: 1.171017
 166000/1000000: episode: 1660, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.745, mean reward: 0.587 [0.505, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.510, 10.098], loss: 0.001374, mae: 0.040792, mean_q: 1.171062
 166100/1000000: episode: 1661, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 63.668, mean reward: 0.637 [0.524, 0.869], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.974, 10.098], loss: 0.001452, mae: 0.042130, mean_q: 1.168963
 166200/1000000: episode: 1662, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.377, mean reward: 0.574 [0.500, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.320, 10.098], loss: 0.001681, mae: 0.044822, mean_q: 1.171434
 166300/1000000: episode: 1663, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.745, mean reward: 0.587 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.249, 10.098], loss: 0.001351, mae: 0.040756, mean_q: 1.169916
 166400/1000000: episode: 1664, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.096, mean reward: 0.571 [0.501, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.570, 10.098], loss: 0.001397, mae: 0.040713, mean_q: 1.168385
 166500/1000000: episode: 1665, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 62.818, mean reward: 0.628 [0.527, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.465, 10.098], loss: 0.001306, mae: 0.039920, mean_q: 1.170265
 166600/1000000: episode: 1666, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.435, mean reward: 0.574 [0.501, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.051, 10.098], loss: 0.001360, mae: 0.040364, mean_q: 1.166941
 166700/1000000: episode: 1667, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.574, mean reward: 0.606 [0.505, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.895, 10.098], loss: 0.001399, mae: 0.041637, mean_q: 1.168125
 166800/1000000: episode: 1668, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 56.971, mean reward: 0.570 [0.511, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.712, 10.098], loss: 0.001402, mae: 0.040878, mean_q: 1.169966
 166900/1000000: episode: 1669, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 56.699, mean reward: 0.567 [0.510, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.626, 10.098], loss: 0.001399, mae: 0.041251, mean_q: 1.172318
 167000/1000000: episode: 1670, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 60.032, mean reward: 0.600 [0.505, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.610, 10.144], loss: 0.001415, mae: 0.041249, mean_q: 1.169221
 167100/1000000: episode: 1671, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.239, mean reward: 0.572 [0.506, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.893, 10.098], loss: 0.001479, mae: 0.042007, mean_q: 1.169630
 167200/1000000: episode: 1672, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.945, mean reward: 0.579 [0.511, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.788, 10.098], loss: 0.001390, mae: 0.041493, mean_q: 1.171134
 167300/1000000: episode: 1673, duration: 0.522s, episode steps: 100, steps per second: 191, episode reward: 59.279, mean reward: 0.593 [0.513, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.969, 10.098], loss: 0.001488, mae: 0.041953, mean_q: 1.169529
 167400/1000000: episode: 1674, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.465, mean reward: 0.605 [0.525, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.136, 10.218], loss: 0.001799, mae: 0.045447, mean_q: 1.169133
 167500/1000000: episode: 1675, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.474, mean reward: 0.595 [0.517, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.015, 10.368], loss: 0.001418, mae: 0.041599, mean_q: 1.165816
 167600/1000000: episode: 1676, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.373, mean reward: 0.604 [0.507, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.609, 10.098], loss: 0.001458, mae: 0.041798, mean_q: 1.167687
 167700/1000000: episode: 1677, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.644, mean reward: 0.576 [0.503, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.839, 10.098], loss: 0.001397, mae: 0.040937, mean_q: 1.164668
 167800/1000000: episode: 1678, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.106, mean reward: 0.591 [0.500, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.615, 10.138], loss: 0.001352, mae: 0.040281, mean_q: 1.166304
 167900/1000000: episode: 1679, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.704, mean reward: 0.577 [0.499, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.164, 10.225], loss: 0.001335, mae: 0.039897, mean_q: 1.164466
 168000/1000000: episode: 1680, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.354, mean reward: 0.584 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.089, 10.171], loss: 0.001377, mae: 0.040812, mean_q: 1.167268
 168100/1000000: episode: 1681, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.199, mean reward: 0.592 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.669, 10.336], loss: 0.001378, mae: 0.040562, mean_q: 1.164288
 168200/1000000: episode: 1682, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.053, mean reward: 0.591 [0.506, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.802, 10.124], loss: 0.001405, mae: 0.040704, mean_q: 1.165094
 168300/1000000: episode: 1683, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.623, mean reward: 0.606 [0.500, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.580, 10.098], loss: 0.001418, mae: 0.041164, mean_q: 1.170911
 168400/1000000: episode: 1684, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.651, mean reward: 0.567 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.547, 10.098], loss: 0.001339, mae: 0.040118, mean_q: 1.162901
 168500/1000000: episode: 1685, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.578, mean reward: 0.576 [0.498, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.100, 10.194], loss: 0.001650, mae: 0.043305, mean_q: 1.166094
 168600/1000000: episode: 1686, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.983, mean reward: 0.590 [0.499, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.139, 10.261], loss: 0.001467, mae: 0.041910, mean_q: 1.167057
 168700/1000000: episode: 1687, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.206, mean reward: 0.582 [0.508, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.543, 10.098], loss: 0.001356, mae: 0.040338, mean_q: 1.163489
 168800/1000000: episode: 1688, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.537, mean reward: 0.605 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.459, 10.252], loss: 0.001426, mae: 0.041080, mean_q: 1.166378
 168900/1000000: episode: 1689, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.895, mean reward: 0.579 [0.507, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.080, 10.248], loss: 0.001489, mae: 0.042126, mean_q: 1.170446
 169000/1000000: episode: 1690, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.834, mean reward: 0.578 [0.504, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.807, 10.098], loss: 0.001379, mae: 0.040579, mean_q: 1.167507
 169100/1000000: episode: 1691, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.294, mean reward: 0.613 [0.505, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.018, 10.175], loss: 0.001378, mae: 0.040902, mean_q: 1.169391
 169200/1000000: episode: 1692, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.969, mean reward: 0.580 [0.509, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.755, 10.311], loss: 0.001356, mae: 0.039747, mean_q: 1.168315
 169300/1000000: episode: 1693, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.385, mean reward: 0.594 [0.515, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.677, 10.098], loss: 0.001521, mae: 0.042158, mean_q: 1.167091
 169400/1000000: episode: 1694, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.130, mean reward: 0.571 [0.505, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.143, 10.180], loss: 0.001368, mae: 0.040243, mean_q: 1.165444
 169500/1000000: episode: 1695, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.026, mean reward: 0.580 [0.503, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.880, 10.142], loss: 0.001473, mae: 0.041331, mean_q: 1.167895
 169600/1000000: episode: 1696, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 56.604, mean reward: 0.566 [0.504, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.944, 10.200], loss: 0.001474, mae: 0.041486, mean_q: 1.167473
 169700/1000000: episode: 1697, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.946, mean reward: 0.589 [0.501, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.852, 10.153], loss: 0.001483, mae: 0.041640, mean_q: 1.165159
 169800/1000000: episode: 1698, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 61.652, mean reward: 0.617 [0.506, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.037, 10.372], loss: 0.001427, mae: 0.040554, mean_q: 1.164099
 169900/1000000: episode: 1699, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.897, mean reward: 0.579 [0.498, 0.868], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.230, 10.142], loss: 0.001441, mae: 0.041510, mean_q: 1.166107
 170000/1000000: episode: 1700, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.804, mean reward: 0.588 [0.504, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.537, 10.098], loss: 0.001529, mae: 0.042512, mean_q: 1.166789
 170100/1000000: episode: 1701, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.529, mean reward: 0.585 [0.502, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.995, 10.196], loss: 0.001481, mae: 0.041655, mean_q: 1.163934
 170200/1000000: episode: 1702, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.738, mean reward: 0.577 [0.502, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.468, 10.098], loss: 0.001532, mae: 0.042203, mean_q: 1.163625
 170300/1000000: episode: 1703, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.991, mean reward: 0.590 [0.507, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.481, 10.098], loss: 0.001374, mae: 0.040849, mean_q: 1.166834
 170400/1000000: episode: 1704, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.647, mean reward: 0.586 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.350, 10.098], loss: 0.001577, mae: 0.042938, mean_q: 1.166619
 170500/1000000: episode: 1705, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.069, mean reward: 0.581 [0.500, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.667, 10.204], loss: 0.001417, mae: 0.041077, mean_q: 1.165299
 170600/1000000: episode: 1706, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 63.062, mean reward: 0.631 [0.504, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.301, 10.098], loss: 0.001464, mae: 0.041116, mean_q: 1.169110
 170700/1000000: episode: 1707, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.560, mean reward: 0.586 [0.518, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.057, 10.336], loss: 0.001396, mae: 0.040491, mean_q: 1.165095
 170800/1000000: episode: 1708, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.850, mean reward: 0.589 [0.502, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.003, 10.098], loss: 0.001333, mae: 0.039313, mean_q: 1.161891
 170900/1000000: episode: 1709, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.378, mean reward: 0.594 [0.506, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.284, 10.286], loss: 0.001511, mae: 0.041868, mean_q: 1.165170
 171000/1000000: episode: 1710, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.658, mean reward: 0.577 [0.512, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.683, 10.098], loss: 0.001406, mae: 0.040549, mean_q: 1.162356
 171100/1000000: episode: 1711, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.526, mean reward: 0.595 [0.511, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.382, 10.307], loss: 0.001449, mae: 0.041287, mean_q: 1.163952
 171200/1000000: episode: 1712, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.679, mean reward: 0.607 [0.512, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-1.026, 10.098], loss: 0.001465, mae: 0.041741, mean_q: 1.161409
 171300/1000000: episode: 1713, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.377, mean reward: 0.584 [0.507, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.663, 10.149], loss: 0.001377, mae: 0.039697, mean_q: 1.162845
 171400/1000000: episode: 1714, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.228, mean reward: 0.572 [0.504, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.488, 10.163], loss: 0.001443, mae: 0.041112, mean_q: 1.165437
 171500/1000000: episode: 1715, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.403, mean reward: 0.584 [0.500, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.873, 10.126], loss: 0.001438, mae: 0.041096, mean_q: 1.162467
 171600/1000000: episode: 1716, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.421, mean reward: 0.594 [0.501, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.553, 10.123], loss: 0.001357, mae: 0.040284, mean_q: 1.165891
 171700/1000000: episode: 1717, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 58.073, mean reward: 0.581 [0.507, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-2.069, 10.289], loss: 0.001266, mae: 0.038948, mean_q: 1.165948
 171800/1000000: episode: 1718, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.139, mean reward: 0.581 [0.499, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.673, 10.329], loss: 0.001494, mae: 0.041916, mean_q: 1.163351
 171900/1000000: episode: 1719, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.425, mean reward: 0.614 [0.520, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.016, 10.342], loss: 0.001515, mae: 0.041967, mean_q: 1.158115
 172000/1000000: episode: 1720, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.070, mean reward: 0.591 [0.502, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.686, 10.098], loss: 0.001324, mae: 0.039385, mean_q: 1.164103
 172100/1000000: episode: 1721, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.233, mean reward: 0.582 [0.498, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.298, 10.111], loss: 0.001347, mae: 0.039947, mean_q: 1.165129
 172200/1000000: episode: 1722, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.991, mean reward: 0.590 [0.501, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.260, 10.098], loss: 0.001385, mae: 0.040377, mean_q: 1.167685
 172300/1000000: episode: 1723, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.155, mean reward: 0.592 [0.501, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.826, 10.138], loss: 0.001464, mae: 0.041346, mean_q: 1.163475
 172400/1000000: episode: 1724, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.154, mean reward: 0.582 [0.509, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.982, 10.403], loss: 0.001374, mae: 0.040385, mean_q: 1.163146
 172500/1000000: episode: 1725, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.039, mean reward: 0.590 [0.501, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.843, 10.172], loss: 0.001370, mae: 0.040244, mean_q: 1.163684
 172600/1000000: episode: 1726, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 57.640, mean reward: 0.576 [0.499, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.452, 10.250], loss: 0.001485, mae: 0.041586, mean_q: 1.163175
 172700/1000000: episode: 1727, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.149, mean reward: 0.581 [0.513, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.539, 10.098], loss: 0.001354, mae: 0.039808, mean_q: 1.164166
 172800/1000000: episode: 1728, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 56.937, mean reward: 0.569 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.471, 10.128], loss: 0.001326, mae: 0.039537, mean_q: 1.164387
 172900/1000000: episode: 1729, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 61.744, mean reward: 0.617 [0.515, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.519, 10.098], loss: 0.001313, mae: 0.038798, mean_q: 1.164112
 173000/1000000: episode: 1730, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.253, mean reward: 0.593 [0.504, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.684, 10.110], loss: 0.001363, mae: 0.040196, mean_q: 1.163944
 173100/1000000: episode: 1731, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.239, mean reward: 0.582 [0.512, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.557, 10.152], loss: 0.001390, mae: 0.040486, mean_q: 1.165776
 173200/1000000: episode: 1732, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.210, mean reward: 0.582 [0.499, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.927, 10.098], loss: 0.001384, mae: 0.040014, mean_q: 1.166286
 173300/1000000: episode: 1733, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.312, mean reward: 0.603 [0.514, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.759, 10.098], loss: 0.001375, mae: 0.040448, mean_q: 1.164066
 173400/1000000: episode: 1734, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.318, mean reward: 0.583 [0.503, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.221, 10.252], loss: 0.001308, mae: 0.039201, mean_q: 1.163399
 173500/1000000: episode: 1735, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 55.873, mean reward: 0.559 [0.499, 0.654], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.759, 10.200], loss: 0.001342, mae: 0.040006, mean_q: 1.164135
 173600/1000000: episode: 1736, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.340, mean reward: 0.583 [0.501, 0.905], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.760, 10.098], loss: 0.001591, mae: 0.041877, mean_q: 1.163749
 173700/1000000: episode: 1737, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.858, mean reward: 0.589 [0.508, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.845, 10.098], loss: 0.001420, mae: 0.041148, mean_q: 1.161897
 173800/1000000: episode: 1738, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 57.763, mean reward: 0.578 [0.503, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.889, 10.099], loss: 0.001327, mae: 0.039482, mean_q: 1.162448
 173900/1000000: episode: 1739, duration: 0.610s, episode steps: 100, steps per second: 164, episode reward: 61.831, mean reward: 0.618 [0.510, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.045, 10.098], loss: 0.001368, mae: 0.040383, mean_q: 1.163572
 174000/1000000: episode: 1740, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.180, mean reward: 0.592 [0.515, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.852, 10.410], loss: 0.001359, mae: 0.039797, mean_q: 1.165609
 174100/1000000: episode: 1741, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.343, mean reward: 0.583 [0.500, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.600, 10.279], loss: 0.001448, mae: 0.041065, mean_q: 1.161997
 174200/1000000: episode: 1742, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 61.576, mean reward: 0.616 [0.515, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.616, 10.098], loss: 0.001414, mae: 0.040805, mean_q: 1.161632
 174300/1000000: episode: 1743, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.350, mean reward: 0.573 [0.517, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.653, 10.190], loss: 0.001261, mae: 0.038412, mean_q: 1.164982
 174400/1000000: episode: 1744, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.521, mean reward: 0.575 [0.501, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.747, 10.134], loss: 0.001373, mae: 0.040046, mean_q: 1.167642
 174500/1000000: episode: 1745, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.694, mean reward: 0.607 [0.509, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.559, 10.098], loss: 0.001425, mae: 0.040377, mean_q: 1.164999
 174600/1000000: episode: 1746, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.081, mean reward: 0.581 [0.501, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.802, 10.163], loss: 0.001406, mae: 0.040493, mean_q: 1.167754
 174700/1000000: episode: 1747, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.160, mean reward: 0.592 [0.504, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.589, 10.098], loss: 0.001360, mae: 0.039356, mean_q: 1.163199
 174800/1000000: episode: 1748, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 57.877, mean reward: 0.579 [0.514, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.835, 10.098], loss: 0.001378, mae: 0.039726, mean_q: 1.165995
 174900/1000000: episode: 1749, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.421, mean reward: 0.594 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.575, 10.120], loss: 0.001388, mae: 0.040600, mean_q: 1.168304
 175000/1000000: episode: 1750, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.823, mean reward: 0.588 [0.504, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.242, 10.098], loss: 0.001352, mae: 0.040322, mean_q: 1.166625
 175100/1000000: episode: 1751, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.589, mean reward: 0.596 [0.514, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.298, 10.296], loss: 0.001504, mae: 0.041599, mean_q: 1.165530
 175200/1000000: episode: 1752, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.720, mean reward: 0.587 [0.497, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.786, 10.232], loss: 0.001380, mae: 0.040365, mean_q: 1.165867
 175300/1000000: episode: 1753, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.286, mean reward: 0.603 [0.506, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.192, 10.123], loss: 0.001337, mae: 0.039575, mean_q: 1.165246
 175400/1000000: episode: 1754, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 61.778, mean reward: 0.618 [0.511, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.263, 10.114], loss: 0.001499, mae: 0.042012, mean_q: 1.165581
 175500/1000000: episode: 1755, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.335, mean reward: 0.593 [0.509, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.817, 10.202], loss: 0.001309, mae: 0.039617, mean_q: 1.166476
 175600/1000000: episode: 1756, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.082, mean reward: 0.591 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.718, 10.098], loss: 0.001400, mae: 0.040293, mean_q: 1.164375
 175700/1000000: episode: 1757, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.301, mean reward: 0.593 [0.499, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.139, 10.098], loss: 0.001505, mae: 0.041434, mean_q: 1.164566
 175800/1000000: episode: 1758, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.005, mean reward: 0.570 [0.503, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.862, 10.230], loss: 0.001347, mae: 0.040011, mean_q: 1.162898
 175900/1000000: episode: 1759, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.581, mean reward: 0.586 [0.504, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.946, 10.141], loss: 0.001447, mae: 0.041325, mean_q: 1.164142
 176000/1000000: episode: 1760, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.559, mean reward: 0.586 [0.507, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.826, 10.302], loss: 0.001465, mae: 0.041350, mean_q: 1.166890
 176100/1000000: episode: 1761, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.549, mean reward: 0.585 [0.513, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.705, 10.174], loss: 0.001433, mae: 0.040438, mean_q: 1.165666
 176200/1000000: episode: 1762, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.102, mean reward: 0.581 [0.505, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.885, 10.136], loss: 0.001431, mae: 0.040440, mean_q: 1.162987
 176300/1000000: episode: 1763, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.836, mean reward: 0.598 [0.502, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.445 [-0.552, 10.234], loss: 0.001482, mae: 0.041219, mean_q: 1.166406
 176400/1000000: episode: 1764, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 61.855, mean reward: 0.619 [0.507, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.396, 10.327], loss: 0.001525, mae: 0.041876, mean_q: 1.164984
 176500/1000000: episode: 1765, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.995, mean reward: 0.590 [0.511, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.403, 10.098], loss: 0.001441, mae: 0.041216, mean_q: 1.164709
 176600/1000000: episode: 1766, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.237, mean reward: 0.582 [0.504, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.078, 10.110], loss: 0.001431, mae: 0.041177, mean_q: 1.166715
 176700/1000000: episode: 1767, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.129, mean reward: 0.571 [0.503, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.478, 10.130], loss: 0.001500, mae: 0.041802, mean_q: 1.168881
 176800/1000000: episode: 1768, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.373, mean reward: 0.584 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.133, 10.336], loss: 0.001466, mae: 0.041370, mean_q: 1.167353
 176900/1000000: episode: 1769, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.950, mean reward: 0.589 [0.504, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.702, 10.132], loss: 0.001497, mae: 0.041265, mean_q: 1.163945
 177000/1000000: episode: 1770, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.492, mean reward: 0.575 [0.505, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.954, 10.098], loss: 0.001504, mae: 0.041325, mean_q: 1.166348
 177100/1000000: episode: 1771, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 57.549, mean reward: 0.575 [0.500, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.131, 10.098], loss: 0.001490, mae: 0.041760, mean_q: 1.166851
 177200/1000000: episode: 1772, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.152, mean reward: 0.592 [0.516, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.615, 10.199], loss: 0.001360, mae: 0.039943, mean_q: 1.164814
 177300/1000000: episode: 1773, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.609, mean reward: 0.566 [0.504, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.910, 10.206], loss: 0.001376, mae: 0.040108, mean_q: 1.162297
 177400/1000000: episode: 1774, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.690, mean reward: 0.577 [0.512, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.205, 10.123], loss: 0.001514, mae: 0.041916, mean_q: 1.165158
 177500/1000000: episode: 1775, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.882, mean reward: 0.569 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.807, 10.099], loss: 0.001526, mae: 0.041262, mean_q: 1.164201
 177600/1000000: episode: 1776, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.653, mean reward: 0.597 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.230, 10.098], loss: 0.001465, mae: 0.041175, mean_q: 1.164524
 177700/1000000: episode: 1777, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.299, mean reward: 0.583 [0.508, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.732, 10.098], loss: 0.001380, mae: 0.039941, mean_q: 1.163485
 177800/1000000: episode: 1778, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.749, mean reward: 0.607 [0.517, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.265, 10.098], loss: 0.001322, mae: 0.039901, mean_q: 1.163655
 177900/1000000: episode: 1779, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.329, mean reward: 0.583 [0.502, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.716, 10.098], loss: 0.001317, mae: 0.039641, mean_q: 1.163380
 178000/1000000: episode: 1780, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 57.743, mean reward: 0.577 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-2.129, 10.098], loss: 0.001431, mae: 0.040603, mean_q: 1.162280
 178100/1000000: episode: 1781, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.363, mean reward: 0.594 [0.504, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.841, 10.192], loss: 0.001454, mae: 0.041387, mean_q: 1.160251
 178200/1000000: episode: 1782, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.141, mean reward: 0.601 [0.503, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.557, 10.378], loss: 0.001470, mae: 0.040951, mean_q: 1.163880
 178300/1000000: episode: 1783, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.592, mean reward: 0.566 [0.499, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.868, 10.098], loss: 0.001472, mae: 0.041589, mean_q: 1.164259
 178400/1000000: episode: 1784, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.725, mean reward: 0.597 [0.504, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-2.492, 10.098], loss: 0.001406, mae: 0.040769, mean_q: 1.161657
 178500/1000000: episode: 1785, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 56.988, mean reward: 0.570 [0.499, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.750, 10.171], loss: 0.001621, mae: 0.042905, mean_q: 1.163042
 178600/1000000: episode: 1786, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 56.255, mean reward: 0.563 [0.501, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.833, 10.138], loss: 0.001503, mae: 0.041864, mean_q: 1.162390
 178700/1000000: episode: 1787, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.130, mean reward: 0.591 [0.507, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.300, 10.098], loss: 0.001723, mae: 0.043687, mean_q: 1.164942
 178800/1000000: episode: 1788, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.771, mean reward: 0.578 [0.506, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.509, 10.169], loss: 0.001376, mae: 0.040021, mean_q: 1.161945
 178900/1000000: episode: 1789, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.389, mean reward: 0.604 [0.504, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.044, 10.098], loss: 0.001389, mae: 0.040304, mean_q: 1.160048
 179000/1000000: episode: 1790, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 56.684, mean reward: 0.567 [0.501, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.126, 10.098], loss: 0.001428, mae: 0.040797, mean_q: 1.160477
 179100/1000000: episode: 1791, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.794, mean reward: 0.578 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.325, 10.232], loss: 0.001456, mae: 0.041186, mean_q: 1.161390
 179200/1000000: episode: 1792, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.453, mean reward: 0.585 [0.500, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.407, 10.204], loss: 0.001419, mae: 0.040898, mean_q: 1.157636
 179300/1000000: episode: 1793, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.930, mean reward: 0.589 [0.500, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.195, 10.397], loss: 0.001502, mae: 0.041625, mean_q: 1.158632
 179400/1000000: episode: 1794, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 60.529, mean reward: 0.605 [0.498, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.870, 10.364], loss: 0.001413, mae: 0.040600, mean_q: 1.158174
 179500/1000000: episode: 1795, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.283, mean reward: 0.583 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.039, 10.098], loss: 0.001386, mae: 0.040006, mean_q: 1.160701
 179600/1000000: episode: 1796, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 60.653, mean reward: 0.607 [0.524, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.573, 10.098], loss: 0.001326, mae: 0.039393, mean_q: 1.159400
 179700/1000000: episode: 1797, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.527, mean reward: 0.615 [0.514, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.693, 10.536], loss: 0.001520, mae: 0.042291, mean_q: 1.159639
 179800/1000000: episode: 1798, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.615, mean reward: 0.586 [0.499, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.105, 10.299], loss: 0.001494, mae: 0.041851, mean_q: 1.162791
 179900/1000000: episode: 1799, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.441, mean reward: 0.574 [0.503, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.686, 10.225], loss: 0.001447, mae: 0.041545, mean_q: 1.162890
 180000/1000000: episode: 1800, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.691, mean reward: 0.587 [0.506, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.745, 10.294], loss: 0.001361, mae: 0.039954, mean_q: 1.162516
 180100/1000000: episode: 1801, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.285, mean reward: 0.583 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.698, 10.310], loss: 0.001353, mae: 0.040134, mean_q: 1.162819
 180200/1000000: episode: 1802, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.203, mean reward: 0.582 [0.505, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.922, 10.352], loss: 0.001414, mae: 0.041012, mean_q: 1.158681
 180300/1000000: episode: 1803, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 58.289, mean reward: 0.583 [0.498, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.548, 10.102], loss: 0.001415, mae: 0.041050, mean_q: 1.160110
 180400/1000000: episode: 1804, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.239, mean reward: 0.592 [0.499, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.969, 10.098], loss: 0.001349, mae: 0.040432, mean_q: 1.158434
 180500/1000000: episode: 1805, duration: 0.621s, episode steps: 100, steps per second: 161, episode reward: 58.907, mean reward: 0.589 [0.506, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.898, 10.207], loss: 0.001465, mae: 0.041981, mean_q: 1.159744
 180600/1000000: episode: 1806, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 60.572, mean reward: 0.606 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.652, 10.359], loss: 0.001403, mae: 0.040553, mean_q: 1.160680
 180700/1000000: episode: 1807, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 57.589, mean reward: 0.576 [0.510, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.730, 10.098], loss: 0.001475, mae: 0.042035, mean_q: 1.159375
 180800/1000000: episode: 1808, duration: 0.619s, episode steps: 100, steps per second: 162, episode reward: 59.404, mean reward: 0.594 [0.509, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.839, 10.106], loss: 0.001431, mae: 0.041573, mean_q: 1.158875
 180900/1000000: episode: 1809, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 66.062, mean reward: 0.661 [0.530, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.942, 10.098], loss: 0.001450, mae: 0.041763, mean_q: 1.160291
 181000/1000000: episode: 1810, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 64.777, mean reward: 0.648 [0.511, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.753, 10.098], loss: 0.001449, mae: 0.041890, mean_q: 1.166833
 181100/1000000: episode: 1811, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.096, mean reward: 0.571 [0.506, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.407, 10.148], loss: 0.001443, mae: 0.041830, mean_q: 1.162125
 181200/1000000: episode: 1812, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.550, mean reward: 0.575 [0.510, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.666, 10.147], loss: 0.001468, mae: 0.042240, mean_q: 1.164719
 181300/1000000: episode: 1813, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.604, mean reward: 0.586 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.409, 10.140], loss: 0.001464, mae: 0.042049, mean_q: 1.162302
 181400/1000000: episode: 1814, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.649, mean reward: 0.586 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.560, 10.098], loss: 0.001472, mae: 0.041518, mean_q: 1.161095
 181500/1000000: episode: 1815, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.250, mean reward: 0.592 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.785, 10.098], loss: 0.001437, mae: 0.041503, mean_q: 1.164175
 181600/1000000: episode: 1816, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.285, mean reward: 0.583 [0.507, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.110, 10.098], loss: 0.001338, mae: 0.040263, mean_q: 1.161072
 181700/1000000: episode: 1817, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 59.890, mean reward: 0.599 [0.507, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.564, 10.098], loss: 0.001521, mae: 0.042701, mean_q: 1.160051
 181800/1000000: episode: 1818, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.046, mean reward: 0.590 [0.498, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.678, 10.141], loss: 0.001467, mae: 0.041917, mean_q: 1.159890
 181900/1000000: episode: 1819, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.850, mean reward: 0.588 [0.509, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.886, 10.111], loss: 0.001513, mae: 0.041769, mean_q: 1.162965
 182000/1000000: episode: 1820, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 59.872, mean reward: 0.599 [0.505, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.700, 10.098], loss: 0.001482, mae: 0.042176, mean_q: 1.165394
 182100/1000000: episode: 1821, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.889, mean reward: 0.589 [0.499, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.267, 10.143], loss: 0.001578, mae: 0.043677, mean_q: 1.163582
 182200/1000000: episode: 1822, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.852, mean reward: 0.579 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.832, 10.098], loss: 0.001522, mae: 0.042363, mean_q: 1.167137
 182300/1000000: episode: 1823, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.462, mean reward: 0.605 [0.501, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.740, 10.098], loss: 0.001463, mae: 0.041612, mean_q: 1.164675
 182400/1000000: episode: 1824, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.460, mean reward: 0.585 [0.512, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.154, 10.098], loss: 0.001501, mae: 0.043106, mean_q: 1.169048
 182500/1000000: episode: 1825, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 58.256, mean reward: 0.583 [0.515, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.673, 10.098], loss: 0.001583, mae: 0.043714, mean_q: 1.167482
 182600/1000000: episode: 1826, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.886, mean reward: 0.579 [0.501, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.350, 10.153], loss: 0.001554, mae: 0.043237, mean_q: 1.165385
 182700/1000000: episode: 1827, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 58.396, mean reward: 0.584 [0.502, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.416, 10.107], loss: 0.001547, mae: 0.042905, mean_q: 1.165428
 182800/1000000: episode: 1828, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.303, mean reward: 0.583 [0.508, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.534, 10.109], loss: 0.001558, mae: 0.042799, mean_q: 1.167871
 182900/1000000: episode: 1829, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.776, mean reward: 0.608 [0.512, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.706, 10.098], loss: 0.001643, mae: 0.044428, mean_q: 1.166839
 183000/1000000: episode: 1830, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 58.548, mean reward: 0.585 [0.501, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.790, 10.098], loss: 0.001531, mae: 0.042884, mean_q: 1.166456
 183100/1000000: episode: 1831, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.556, mean reward: 0.586 [0.518, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.449, 10.098], loss: 0.001471, mae: 0.042175, mean_q: 1.168498
 183200/1000000: episode: 1832, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 63.633, mean reward: 0.636 [0.517, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.500, 10.396], loss: 0.001483, mae: 0.041842, mean_q: 1.167132
 183300/1000000: episode: 1833, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.248, mean reward: 0.582 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.412, 10.098], loss: 0.001395, mae: 0.041530, mean_q: 1.168238
 183400/1000000: episode: 1834, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 64.654, mean reward: 0.647 [0.514, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.471, 10.377], loss: 0.001438, mae: 0.041186, mean_q: 1.167019
 183500/1000000: episode: 1835, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.033, mean reward: 0.590 [0.501, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.598, 10.215], loss: 0.001454, mae: 0.041547, mean_q: 1.171113
 183600/1000000: episode: 1836, duration: 0.608s, episode steps: 100, steps per second: 165, episode reward: 60.629, mean reward: 0.606 [0.504, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.604, 10.285], loss: 0.001564, mae: 0.043716, mean_q: 1.170291
 183700/1000000: episode: 1837, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 57.406, mean reward: 0.574 [0.501, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.350, 10.111], loss: 0.001584, mae: 0.042821, mean_q: 1.171648
 183800/1000000: episode: 1838, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.598, mean reward: 0.616 [0.515, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.610, 10.278], loss: 0.001500, mae: 0.042910, mean_q: 1.173991
 183900/1000000: episode: 1839, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.369, mean reward: 0.574 [0.501, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.451, 10.234], loss: 0.001466, mae: 0.041390, mean_q: 1.173408
 184000/1000000: episode: 1840, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.528, mean reward: 0.595 [0.499, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.717, 10.098], loss: 0.001413, mae: 0.040869, mean_q: 1.177173
 184100/1000000: episode: 1841, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.609, mean reward: 0.596 [0.509, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.738, 10.230], loss: 0.001487, mae: 0.041779, mean_q: 1.176161
 184200/1000000: episode: 1842, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.463, mean reward: 0.575 [0.498, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.248, 10.247], loss: 0.001465, mae: 0.041888, mean_q: 1.176144
 184300/1000000: episode: 1843, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.976, mean reward: 0.610 [0.498, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.987, 10.112], loss: 0.001494, mae: 0.042076, mean_q: 1.174458
 184400/1000000: episode: 1844, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.308, mean reward: 0.603 [0.510, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.501, 10.098], loss: 0.001446, mae: 0.042225, mean_q: 1.174401
 184500/1000000: episode: 1845, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 58.430, mean reward: 0.584 [0.516, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.640, 10.098], loss: 0.001450, mae: 0.041646, mean_q: 1.179605
 184600/1000000: episode: 1846, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.093, mean reward: 0.581 [0.511, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.998, 10.098], loss: 0.001501, mae: 0.042227, mean_q: 1.175834
 184700/1000000: episode: 1847, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.210, mean reward: 0.592 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.119, 10.249], loss: 0.001549, mae: 0.042321, mean_q: 1.175105
 184800/1000000: episode: 1848, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 56.250, mean reward: 0.563 [0.505, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.612, 10.098], loss: 0.001530, mae: 0.042536, mean_q: 1.173535
 184900/1000000: episode: 1849, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.005, mean reward: 0.620 [0.504, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.662, 10.201], loss: 0.001507, mae: 0.042250, mean_q: 1.175088
 185000/1000000: episode: 1850, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.592, mean reward: 0.596 [0.501, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.914, 10.186], loss: 0.001491, mae: 0.041802, mean_q: 1.180523
 185100/1000000: episode: 1851, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.234, mean reward: 0.582 [0.510, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.941, 10.098], loss: 0.001681, mae: 0.043720, mean_q: 1.176238
 185200/1000000: episode: 1852, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.074, mean reward: 0.591 [0.499, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.006, 10.163], loss: 0.001333, mae: 0.039587, mean_q: 1.170723
 185300/1000000: episode: 1853, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.061, mean reward: 0.591 [0.511, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.968, 10.194], loss: 0.001538, mae: 0.043185, mean_q: 1.175429
 185400/1000000: episode: 1854, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.371, mean reward: 0.614 [0.502, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.075, 10.098], loss: 0.001389, mae: 0.039950, mean_q: 1.171866
 185500/1000000: episode: 1855, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.710, mean reward: 0.587 [0.498, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.757, 10.105], loss: 0.001417, mae: 0.040779, mean_q: 1.181509
 185600/1000000: episode: 1856, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.600, mean reward: 0.576 [0.507, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.014, 10.249], loss: 0.001363, mae: 0.040369, mean_q: 1.174867
 185700/1000000: episode: 1857, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.074, mean reward: 0.591 [0.506, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.809, 10.098], loss: 0.001436, mae: 0.040855, mean_q: 1.171182
 185800/1000000: episode: 1858, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.383, mean reward: 0.594 [0.506, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.244, 10.244], loss: 0.001384, mae: 0.040695, mean_q: 1.173401
 185900/1000000: episode: 1859, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.280, mean reward: 0.573 [0.501, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.223, 10.119], loss: 0.001574, mae: 0.042789, mean_q: 1.173426
 186000/1000000: episode: 1860, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.562, mean reward: 0.586 [0.507, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.961, 10.098], loss: 0.001419, mae: 0.040468, mean_q: 1.166795
 186100/1000000: episode: 1861, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 62.626, mean reward: 0.626 [0.511, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.713, 10.284], loss: 0.001579, mae: 0.042093, mean_q: 1.176265
 186200/1000000: episode: 1862, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.274, mean reward: 0.603 [0.512, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.733, 10.098], loss: 0.001391, mae: 0.040676, mean_q: 1.171136
 186300/1000000: episode: 1863, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.812, mean reward: 0.578 [0.500, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.483, 10.146], loss: 0.001448, mae: 0.041126, mean_q: 1.169104
 186400/1000000: episode: 1864, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.600, mean reward: 0.586 [0.509, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.184, 10.291], loss: 0.001720, mae: 0.044088, mean_q: 1.172323
 186500/1000000: episode: 1865, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.765, mean reward: 0.618 [0.513, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.657, 10.098], loss: 0.001501, mae: 0.042204, mean_q: 1.175205
 186600/1000000: episode: 1866, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.742, mean reward: 0.607 [0.510, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.428, 10.338], loss: 0.001496, mae: 0.041724, mean_q: 1.175440
 186700/1000000: episode: 1867, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.522, mean reward: 0.575 [0.506, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.501, 10.194], loss: 0.001482, mae: 0.041808, mean_q: 1.177269
 186800/1000000: episode: 1868, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.601, mean reward: 0.596 [0.515, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.416, 10.123], loss: 0.001572, mae: 0.042803, mean_q: 1.176648
 186900/1000000: episode: 1869, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.207, mean reward: 0.602 [0.509, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.075, 10.280], loss: 0.001423, mae: 0.040667, mean_q: 1.170467
 187000/1000000: episode: 1870, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.634, mean reward: 0.586 [0.506, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.774, 10.098], loss: 0.001459, mae: 0.041421, mean_q: 1.171919
 187100/1000000: episode: 1871, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.886, mean reward: 0.609 [0.515, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.899, 10.098], loss: 0.001551, mae: 0.042394, mean_q: 1.172064
 187200/1000000: episode: 1872, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.445, mean reward: 0.584 [0.501, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.356, 10.098], loss: 0.001489, mae: 0.042280, mean_q: 1.177947
 187300/1000000: episode: 1873, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.075, mean reward: 0.581 [0.500, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.775, 10.144], loss: 0.001428, mae: 0.040628, mean_q: 1.176818
 187400/1000000: episode: 1874, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.494, mean reward: 0.595 [0.503, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.136, 10.098], loss: 0.001412, mae: 0.040627, mean_q: 1.174610
 187500/1000000: episode: 1875, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.968, mean reward: 0.590 [0.516, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.799, 10.098], loss: 0.001437, mae: 0.041062, mean_q: 1.173240
 187600/1000000: episode: 1876, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 59.222, mean reward: 0.592 [0.506, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.111, 10.172], loss: 0.001426, mae: 0.040938, mean_q: 1.177417
 187700/1000000: episode: 1877, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.489, mean reward: 0.605 [0.505, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.950, 10.098], loss: 0.001372, mae: 0.040082, mean_q: 1.176344
 187800/1000000: episode: 1878, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.856, mean reward: 0.619 [0.518, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.523, 10.098], loss: 0.001419, mae: 0.040452, mean_q: 1.177240
 187900/1000000: episode: 1879, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.899, mean reward: 0.589 [0.504, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.473, 10.145], loss: 0.001470, mae: 0.041776, mean_q: 1.176844
 188000/1000000: episode: 1880, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.639, mean reward: 0.576 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.886, 10.098], loss: 0.001516, mae: 0.042636, mean_q: 1.176969
 188100/1000000: episode: 1881, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.000, mean reward: 0.580 [0.507, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.585, 10.098], loss: 0.001418, mae: 0.041179, mean_q: 1.174237
 188200/1000000: episode: 1882, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.075, mean reward: 0.581 [0.499, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.027, 10.180], loss: 0.001435, mae: 0.041112, mean_q: 1.175432
 188300/1000000: episode: 1883, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.673, mean reward: 0.597 [0.501, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.727, 10.098], loss: 0.001431, mae: 0.041501, mean_q: 1.173177
 188400/1000000: episode: 1884, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.302, mean reward: 0.593 [0.516, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.385, 10.098], loss: 0.001488, mae: 0.041779, mean_q: 1.173695
 188500/1000000: episode: 1885, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.246, mean reward: 0.572 [0.504, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.699, 10.200], loss: 0.001473, mae: 0.042117, mean_q: 1.172089
 188600/1000000: episode: 1886, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.329, mean reward: 0.593 [0.515, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.042, 10.274], loss: 0.001466, mae: 0.041367, mean_q: 1.172255
 188700/1000000: episode: 1887, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 56.290, mean reward: 0.563 [0.503, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.365, 10.201], loss: 0.001540, mae: 0.042124, mean_q: 1.172598
 188800/1000000: episode: 1888, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.874, mean reward: 0.609 [0.507, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.837, 10.098], loss: 0.001335, mae: 0.039676, mean_q: 1.168157
 188900/1000000: episode: 1889, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 56.870, mean reward: 0.569 [0.499, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.366, 10.098], loss: 0.001545, mae: 0.042366, mean_q: 1.174265
 189000/1000000: episode: 1890, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.139, mean reward: 0.591 [0.506, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.450, 10.098], loss: 0.001448, mae: 0.041619, mean_q: 1.169800
 189100/1000000: episode: 1891, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.161, mean reward: 0.582 [0.505, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.524, 10.208], loss: 0.001448, mae: 0.041249, mean_q: 1.169013
 189200/1000000: episode: 1892, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.023, mean reward: 0.580 [0.499, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.222, 10.331], loss: 0.001573, mae: 0.042779, mean_q: 1.169138
 189300/1000000: episode: 1893, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.562, mean reward: 0.606 [0.507, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.359, 10.098], loss: 0.001445, mae: 0.041601, mean_q: 1.169517
 189400/1000000: episode: 1894, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.527, mean reward: 0.595 [0.501, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.358, 10.098], loss: 0.001483, mae: 0.041874, mean_q: 1.171222
 189500/1000000: episode: 1895, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.189, mean reward: 0.572 [0.509, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.396, 10.129], loss: 0.001474, mae: 0.041741, mean_q: 1.171720
 189600/1000000: episode: 1896, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.977, mean reward: 0.580 [0.498, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.306, 10.098], loss: 0.001398, mae: 0.040469, mean_q: 1.167074
 189700/1000000: episode: 1897, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.741, mean reward: 0.597 [0.513, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.033, 10.098], loss: 0.001457, mae: 0.041598, mean_q: 1.171143
 189800/1000000: episode: 1898, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.905, mean reward: 0.589 [0.499, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.458, 10.423], loss: 0.001280, mae: 0.039135, mean_q: 1.167359
 189900/1000000: episode: 1899, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.906, mean reward: 0.579 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.547, 10.222], loss: 0.001460, mae: 0.041314, mean_q: 1.166629
 190000/1000000: episode: 1900, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 61.742, mean reward: 0.617 [0.498, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.603, 10.361], loss: 0.001518, mae: 0.042671, mean_q: 1.169081
 190100/1000000: episode: 1901, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.332, mean reward: 0.573 [0.505, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.691, 10.098], loss: 0.001493, mae: 0.041776, mean_q: 1.168551
 190200/1000000: episode: 1902, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 60.472, mean reward: 0.605 [0.517, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.027, 10.339], loss: 0.001356, mae: 0.040196, mean_q: 1.167576
 190300/1000000: episode: 1903, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 60.107, mean reward: 0.601 [0.521, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.072, 10.155], loss: 0.001491, mae: 0.042436, mean_q: 1.169967
 190400/1000000: episode: 1904, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.093, mean reward: 0.611 [0.508, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.263, 10.098], loss: 0.001452, mae: 0.041720, mean_q: 1.172423
 190500/1000000: episode: 1905, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.567, mean reward: 0.576 [0.499, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.559, 10.144], loss: 0.001476, mae: 0.041831, mean_q: 1.170820
 190600/1000000: episode: 1906, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 58.329, mean reward: 0.583 [0.502, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.066, 10.098], loss: 0.001413, mae: 0.041599, mean_q: 1.166005
 190700/1000000: episode: 1907, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.691, mean reward: 0.577 [0.500, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.124, 10.098], loss: 0.001475, mae: 0.041863, mean_q: 1.167828
 190800/1000000: episode: 1908, duration: 0.601s, episode steps: 100, steps per second: 167, episode reward: 58.280, mean reward: 0.583 [0.506, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.680, 10.098], loss: 0.001461, mae: 0.041917, mean_q: 1.170042
 190900/1000000: episode: 1909, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.940, mean reward: 0.579 [0.501, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.406, 10.288], loss: 0.001470, mae: 0.042402, mean_q: 1.167602
 191000/1000000: episode: 1910, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.598, mean reward: 0.596 [0.505, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.398, 10.098], loss: 0.001337, mae: 0.040491, mean_q: 1.171649
 191100/1000000: episode: 1911, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 61.270, mean reward: 0.613 [0.511, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.008, 10.098], loss: 0.001439, mae: 0.041556, mean_q: 1.172204
 191200/1000000: episode: 1912, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.394, mean reward: 0.604 [0.508, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.479, 10.098], loss: 0.001368, mae: 0.041131, mean_q: 1.167314
 191300/1000000: episode: 1913, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 61.566, mean reward: 0.616 [0.514, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.055, 10.098], loss: 0.001400, mae: 0.040727, mean_q: 1.167130
 191400/1000000: episode: 1914, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.094, mean reward: 0.581 [0.500, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.729, 10.268], loss: 0.001464, mae: 0.042328, mean_q: 1.170775
 191500/1000000: episode: 1915, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.079, mean reward: 0.591 [0.518, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.213, 10.098], loss: 0.001364, mae: 0.040845, mean_q: 1.172472
 191600/1000000: episode: 1916, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.521, mean reward: 0.575 [0.503, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.483, 10.202], loss: 0.001436, mae: 0.041987, mean_q: 1.170686
 191700/1000000: episode: 1917, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.882, mean reward: 0.589 [0.501, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.341, 10.186], loss: 0.001376, mae: 0.040306, mean_q: 1.169418
 191800/1000000: episode: 1918, duration: 0.518s, episode steps: 100, steps per second: 193, episode reward: 56.921, mean reward: 0.569 [0.506, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.238, 10.098], loss: 0.001329, mae: 0.040064, mean_q: 1.164215
 191900/1000000: episode: 1919, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.361, mean reward: 0.584 [0.501, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.986, 10.098], loss: 0.001302, mae: 0.039716, mean_q: 1.164997
 192000/1000000: episode: 1920, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.838, mean reward: 0.578 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.450, 10.266], loss: 0.001420, mae: 0.041624, mean_q: 1.164301
 192100/1000000: episode: 1921, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.900, mean reward: 0.579 [0.503, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.877, 10.098], loss: 0.001434, mae: 0.041248, mean_q: 1.163443
 192200/1000000: episode: 1922, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.551, mean reward: 0.606 [0.505, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.092, 10.287], loss: 0.001403, mae: 0.041094, mean_q: 1.167642
 192300/1000000: episode: 1923, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 61.059, mean reward: 0.611 [0.509, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.661, 10.271], loss: 0.001360, mae: 0.040584, mean_q: 1.164237
 192400/1000000: episode: 1924, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.331, mean reward: 0.593 [0.499, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.925, 10.306], loss: 0.001370, mae: 0.041176, mean_q: 1.165200
 192500/1000000: episode: 1925, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.294, mean reward: 0.593 [0.500, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.818, 10.161], loss: 0.001455, mae: 0.042480, mean_q: 1.167594
 192600/1000000: episode: 1926, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.559, mean reward: 0.596 [0.507, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.979, 10.098], loss: 0.001300, mae: 0.039832, mean_q: 1.166997
 192700/1000000: episode: 1927, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 59.530, mean reward: 0.595 [0.503, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.116, 10.098], loss: 0.001415, mae: 0.041029, mean_q: 1.166169
 192800/1000000: episode: 1928, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.545, mean reward: 0.575 [0.506, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.497, 10.098], loss: 0.001450, mae: 0.041396, mean_q: 1.164495
 192900/1000000: episode: 1929, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.365, mean reward: 0.574 [0.501, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.152, 10.098], loss: 0.001358, mae: 0.041010, mean_q: 1.161365
 193000/1000000: episode: 1930, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.895, mean reward: 0.589 [0.498, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.145, 10.321], loss: 0.001447, mae: 0.041929, mean_q: 1.165242
 193100/1000000: episode: 1931, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.568, mean reward: 0.586 [0.498, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.027, 10.158], loss: 0.001380, mae: 0.040562, mean_q: 1.163463
 193200/1000000: episode: 1932, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.805, mean reward: 0.588 [0.500, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.132, 10.098], loss: 0.001461, mae: 0.041934, mean_q: 1.162849
 193300/1000000: episode: 1933, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.754, mean reward: 0.588 [0.505, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.291, 10.181], loss: 0.001415, mae: 0.041658, mean_q: 1.167368
 193400/1000000: episode: 1934, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.180, mean reward: 0.572 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.076, 10.190], loss: 0.001353, mae: 0.040256, mean_q: 1.164822
 193500/1000000: episode: 1935, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.777, mean reward: 0.598 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.643, 10.298], loss: 0.001417, mae: 0.040897, mean_q: 1.166058
 193600/1000000: episode: 1936, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.564, mean reward: 0.606 [0.505, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.064, 10.098], loss: 0.001474, mae: 0.041919, mean_q: 1.168513
 193700/1000000: episode: 1937, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.738, mean reward: 0.587 [0.505, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.666, 10.098], loss: 0.001494, mae: 0.042067, mean_q: 1.169628
 193800/1000000: episode: 1938, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.443, mean reward: 0.604 [0.530, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.974, 10.297], loss: 0.001571, mae: 0.043534, mean_q: 1.165907
 193900/1000000: episode: 1939, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.426, mean reward: 0.594 [0.510, 0.900], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.985, 10.221], loss: 0.001474, mae: 0.042713, mean_q: 1.166441
 194000/1000000: episode: 1940, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 57.075, mean reward: 0.571 [0.502, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.234, 10.167], loss: 0.001512, mae: 0.042480, mean_q: 1.165871
 194100/1000000: episode: 1941, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.876, mean reward: 0.589 [0.506, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.507, 10.215], loss: 0.001402, mae: 0.040699, mean_q: 1.165166
 194200/1000000: episode: 1942, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.941, mean reward: 0.599 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-0.723, 10.098], loss: 0.001488, mae: 0.042234, mean_q: 1.169122
 194300/1000000: episode: 1943, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 60.426, mean reward: 0.604 [0.503, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.501, 10.416], loss: 0.001382, mae: 0.041094, mean_q: 1.167650
 194400/1000000: episode: 1944, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.668, mean reward: 0.597 [0.498, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.624, 10.098], loss: 0.001369, mae: 0.040549, mean_q: 1.168869
 194500/1000000: episode: 1945, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 59.434, mean reward: 0.594 [0.511, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.168, 10.098], loss: 0.001549, mae: 0.042631, mean_q: 1.171492
 194600/1000000: episode: 1946, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.515, mean reward: 0.585 [0.512, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.596, 10.098], loss: 0.001492, mae: 0.042250, mean_q: 1.168731
 194700/1000000: episode: 1947, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.821, mean reward: 0.588 [0.511, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.864, 10.173], loss: 0.001378, mae: 0.040634, mean_q: 1.166901
 194800/1000000: episode: 1948, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.337, mean reward: 0.573 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.997, 10.098], loss: 0.001467, mae: 0.041848, mean_q: 1.169785
 194900/1000000: episode: 1949, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 57.625, mean reward: 0.576 [0.507, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.928, 10.098], loss: 0.001433, mae: 0.041015, mean_q: 1.167659
 195000/1000000: episode: 1950, duration: 0.524s, episode steps: 100, steps per second: 191, episode reward: 58.622, mean reward: 0.586 [0.510, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.681, 10.098], loss: 0.001488, mae: 0.041874, mean_q: 1.164466
 195100/1000000: episode: 1951, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 56.992, mean reward: 0.570 [0.509, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.518, 10.255], loss: 0.001469, mae: 0.042218, mean_q: 1.164793
 195200/1000000: episode: 1952, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.784, mean reward: 0.598 [0.499, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.730, 10.300], loss: 0.001494, mae: 0.041576, mean_q: 1.165510
 195300/1000000: episode: 1953, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.999, mean reward: 0.600 [0.507, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.658, 10.122], loss: 0.001392, mae: 0.040927, mean_q: 1.165632
 195400/1000000: episode: 1954, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.441, mean reward: 0.584 [0.504, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.782, 10.303], loss: 0.001365, mae: 0.040342, mean_q: 1.163378
 195500/1000000: episode: 1955, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.545, mean reward: 0.605 [0.502, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.570, 10.266], loss: 0.001342, mae: 0.039569, mean_q: 1.166219
 195600/1000000: episode: 1956, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.964, mean reward: 0.590 [0.508, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.975, 10.098], loss: 0.001365, mae: 0.039989, mean_q: 1.166471
 195700/1000000: episode: 1957, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.860, mean reward: 0.609 [0.500, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.094, 10.098], loss: 0.001456, mae: 0.040980, mean_q: 1.169296
 195800/1000000: episode: 1958, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.303, mean reward: 0.593 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.120, 10.098], loss: 0.001582, mae: 0.043095, mean_q: 1.168493
 195900/1000000: episode: 1959, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 62.600, mean reward: 0.626 [0.508, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.502, 10.098], loss: 0.001419, mae: 0.041056, mean_q: 1.169961
 196000/1000000: episode: 1960, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.196, mean reward: 0.592 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.355, 10.289], loss: 0.001553, mae: 0.042741, mean_q: 1.167427
 196100/1000000: episode: 1961, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 62.136, mean reward: 0.621 [0.510, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.642, 10.098], loss: 0.001470, mae: 0.041937, mean_q: 1.169691
 196200/1000000: episode: 1962, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.427, mean reward: 0.594 [0.511, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.525, 10.098], loss: 0.001564, mae: 0.042632, mean_q: 1.171158
 196300/1000000: episode: 1963, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.836, mean reward: 0.578 [0.502, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.020, 10.098], loss: 0.001428, mae: 0.041555, mean_q: 1.170248
 196400/1000000: episode: 1964, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.697, mean reward: 0.607 [0.505, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.735, 10.098], loss: 0.001571, mae: 0.043317, mean_q: 1.171090
 196500/1000000: episode: 1965, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.630, mean reward: 0.596 [0.510, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.518, 10.098], loss: 0.001541, mae: 0.042135, mean_q: 1.168074
 196600/1000000: episode: 1966, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.603, mean reward: 0.586 [0.507, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.230, 10.126], loss: 0.001546, mae: 0.042240, mean_q: 1.169810
 196700/1000000: episode: 1967, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.222, mean reward: 0.592 [0.498, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.287, 10.098], loss: 0.001482, mae: 0.041936, mean_q: 1.167954
 196800/1000000: episode: 1968, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.539, mean reward: 0.585 [0.501, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.493, 10.098], loss: 0.001588, mae: 0.043326, mean_q: 1.170166
 196900/1000000: episode: 1969, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.719, mean reward: 0.587 [0.509, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.983, 10.246], loss: 0.001553, mae: 0.042837, mean_q: 1.174308
 197000/1000000: episode: 1970, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.976, mean reward: 0.610 [0.511, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.815, 10.098], loss: 0.001483, mae: 0.041858, mean_q: 1.172371
 197100/1000000: episode: 1971, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.029, mean reward: 0.590 [0.501, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.084, 10.098], loss: 0.001408, mae: 0.040798, mean_q: 1.170041
 197200/1000000: episode: 1972, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 56.125, mean reward: 0.561 [0.498, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.761, 10.266], loss: 0.001476, mae: 0.041476, mean_q: 1.169127
 197300/1000000: episode: 1973, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 66.427, mean reward: 0.664 [0.510, 0.887], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.802, 10.325], loss: 0.001517, mae: 0.041644, mean_q: 1.169048
 197400/1000000: episode: 1974, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.752, mean reward: 0.608 [0.500, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.849, 10.098], loss: 0.001586, mae: 0.042895, mean_q: 1.172615
 197500/1000000: episode: 1975, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.666, mean reward: 0.607 [0.504, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.155, 10.098], loss: 0.001530, mae: 0.042752, mean_q: 1.172148
 197600/1000000: episode: 1976, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.527, mean reward: 0.595 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.996, 10.174], loss: 0.001591, mae: 0.043322, mean_q: 1.170313
 197700/1000000: episode: 1977, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.837, mean reward: 0.608 [0.504, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.835, 10.098], loss: 0.001508, mae: 0.042346, mean_q: 1.174624
 197800/1000000: episode: 1978, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.352, mean reward: 0.594 [0.501, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.572, 10.098], loss: 0.001636, mae: 0.043528, mean_q: 1.173497
 197900/1000000: episode: 1979, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 58.765, mean reward: 0.588 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.418, 10.158], loss: 0.001588, mae: 0.042499, mean_q: 1.179250
 198000/1000000: episode: 1980, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.908, mean reward: 0.589 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.911, 10.098], loss: 0.001699, mae: 0.044449, mean_q: 1.175452
 198100/1000000: episode: 1981, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 62.502, mean reward: 0.625 [0.501, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.303, 10.377], loss: 0.001567, mae: 0.042945, mean_q: 1.176266
 198200/1000000: episode: 1982, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.237, mean reward: 0.592 [0.516, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.918, 10.223], loss: 0.001565, mae: 0.042683, mean_q: 1.177015
 198300/1000000: episode: 1983, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.168, mean reward: 0.592 [0.512, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.969, 10.098], loss: 0.001519, mae: 0.042419, mean_q: 1.179565
 198400/1000000: episode: 1984, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 60.163, mean reward: 0.602 [0.501, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.879, 10.098], loss: 0.001617, mae: 0.043009, mean_q: 1.177860
 198500/1000000: episode: 1985, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.145, mean reward: 0.571 [0.498, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.790, 10.130], loss: 0.001456, mae: 0.041435, mean_q: 1.178372
 198600/1000000: episode: 1986, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 58.249, mean reward: 0.582 [0.502, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.701, 10.510], loss: 0.001693, mae: 0.044063, mean_q: 1.176971
 198700/1000000: episode: 1987, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.640, mean reward: 0.576 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.619, 10.098], loss: 0.001523, mae: 0.041762, mean_q: 1.178618
 198800/1000000: episode: 1988, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 63.182, mean reward: 0.632 [0.509, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.531, 10.285], loss: 0.001562, mae: 0.042323, mean_q: 1.176972
 198900/1000000: episode: 1989, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.558, mean reward: 0.586 [0.502, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.783, 10.374], loss: 0.001658, mae: 0.043819, mean_q: 1.179153
 199000/1000000: episode: 1990, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.685, mean reward: 0.587 [0.507, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.634, 10.098], loss: 0.001449, mae: 0.041027, mean_q: 1.176823
 199100/1000000: episode: 1991, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.044, mean reward: 0.570 [0.500, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.437, 10.179], loss: 0.001483, mae: 0.041078, mean_q: 1.176399
 199200/1000000: episode: 1992, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.745, mean reward: 0.567 [0.502, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.092, 10.098], loss: 0.001668, mae: 0.043578, mean_q: 1.178929
 199300/1000000: episode: 1993, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.536, mean reward: 0.565 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.292, 10.124], loss: 0.001457, mae: 0.041213, mean_q: 1.176369
 199400/1000000: episode: 1994, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.816, mean reward: 0.578 [0.502, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.663, 10.286], loss: 0.001446, mae: 0.041089, mean_q: 1.174754
 199500/1000000: episode: 1995, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.587, mean reward: 0.596 [0.499, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.857, 10.257], loss: 0.001498, mae: 0.041001, mean_q: 1.173989
 199600/1000000: episode: 1996, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 59.879, mean reward: 0.599 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.340, 10.098], loss: 0.001656, mae: 0.044046, mean_q: 1.176223
 199700/1000000: episode: 1997, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.788, mean reward: 0.578 [0.509, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.579, 10.098], loss: 0.001490, mae: 0.041791, mean_q: 1.170306
 199800/1000000: episode: 1998, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 56.720, mean reward: 0.567 [0.500, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.975, 10.181], loss: 0.001577, mae: 0.042799, mean_q: 1.174014
 199900/1000000: episode: 1999, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 62.092, mean reward: 0.621 [0.501, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.747, 10.173], loss: 0.001511, mae: 0.042576, mean_q: 1.173155
 200000/1000000: episode: 2000, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.956, mean reward: 0.570 [0.497, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.665, 10.166], loss: 0.001523, mae: 0.042084, mean_q: 1.177028
 200100/1000000: episode: 2001, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.144, mean reward: 0.611 [0.507, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.470, 10.151], loss: 0.001461, mae: 0.041742, mean_q: 1.176932
 200200/1000000: episode: 2002, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.564, mean reward: 0.596 [0.508, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.601, 10.289], loss: 0.001527, mae: 0.042500, mean_q: 1.175519
 200300/1000000: episode: 2003, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.472, mean reward: 0.585 [0.506, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.807, 10.098], loss: 0.001544, mae: 0.042616, mean_q: 1.171538
 200400/1000000: episode: 2004, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 61.535, mean reward: 0.615 [0.500, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.403, 10.332], loss: 0.001559, mae: 0.042378, mean_q: 1.174213
 200500/1000000: episode: 2005, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.464, mean reward: 0.605 [0.512, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.355, 10.264], loss: 0.001550, mae: 0.042464, mean_q: 1.177187
 200600/1000000: episode: 2006, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.307, mean reward: 0.583 [0.505, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.282, 10.101], loss: 0.001650, mae: 0.044258, mean_q: 1.179237
 200700/1000000: episode: 2007, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 65.036, mean reward: 0.650 [0.508, 0.964], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.166, 10.098], loss: 0.001596, mae: 0.043261, mean_q: 1.177699
 200800/1000000: episode: 2008, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.607, mean reward: 0.596 [0.500, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.596, 10.098], loss: 0.001747, mae: 0.044865, mean_q: 1.174885
 200900/1000000: episode: 2009, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.355, mean reward: 0.584 [0.506, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.933, 10.306], loss: 0.001454, mae: 0.041729, mean_q: 1.173653
 201000/1000000: episode: 2010, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.911, mean reward: 0.589 [0.503, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.018, 10.136], loss: 0.001476, mae: 0.042164, mean_q: 1.177000
 201100/1000000: episode: 2011, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.470, mean reward: 0.585 [0.511, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.466, 10.098], loss: 0.001568, mae: 0.043163, mean_q: 1.174255
 201200/1000000: episode: 2012, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.178, mean reward: 0.582 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.252, 10.098], loss: 0.001470, mae: 0.041669, mean_q: 1.175710
 201300/1000000: episode: 2013, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.667, mean reward: 0.587 [0.501, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.831, 10.098], loss: 0.001895, mae: 0.045462, mean_q: 1.177290
 201400/1000000: episode: 2014, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.900, mean reward: 0.579 [0.501, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.819, 10.154], loss: 0.001723, mae: 0.044807, mean_q: 1.170030
 201500/1000000: episode: 2015, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 61.512, mean reward: 0.615 [0.511, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.307, 10.098], loss: 0.001567, mae: 0.043706, mean_q: 1.176747
 201600/1000000: episode: 2016, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.033, mean reward: 0.580 [0.506, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.692, 10.098], loss: 0.001558, mae: 0.042996, mean_q: 1.178600
 201700/1000000: episode: 2017, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 60.662, mean reward: 0.607 [0.529, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.404, 10.098], loss: 0.001466, mae: 0.041934, mean_q: 1.173563
 201800/1000000: episode: 2018, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.175, mean reward: 0.602 [0.501, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.366, 10.098], loss: 0.001526, mae: 0.042805, mean_q: 1.175404
 201900/1000000: episode: 2019, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.206, mean reward: 0.582 [0.513, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.749, 10.098], loss: 0.001398, mae: 0.040750, mean_q: 1.175631
 202000/1000000: episode: 2020, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.430, mean reward: 0.584 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.965, 10.098], loss: 0.001526, mae: 0.043191, mean_q: 1.173858
 202100/1000000: episode: 2021, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.027, mean reward: 0.590 [0.502, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.024, 10.098], loss: 0.001613, mae: 0.044118, mean_q: 1.171831
 202200/1000000: episode: 2022, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.190, mean reward: 0.582 [0.500, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.513, 10.098], loss: 0.001490, mae: 0.042676, mean_q: 1.178305
 202300/1000000: episode: 2023, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.631, mean reward: 0.586 [0.507, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.753, 10.098], loss: 0.001679, mae: 0.044730, mean_q: 1.173934
 202400/1000000: episode: 2024, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.476, mean reward: 0.595 [0.504, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.787, 10.430], loss: 0.001574, mae: 0.043700, mean_q: 1.174999
 202500/1000000: episode: 2025, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.821, mean reward: 0.588 [0.509, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.583, 10.162], loss: 0.001419, mae: 0.041920, mean_q: 1.174653
 202600/1000000: episode: 2026, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.694, mean reward: 0.587 [0.498, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.682, 10.156], loss: 0.001612, mae: 0.043761, mean_q: 1.172859
 202700/1000000: episode: 2027, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.832, mean reward: 0.588 [0.500, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.080, 10.098], loss: 0.001549, mae: 0.043489, mean_q: 1.171857
 202800/1000000: episode: 2028, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.445, mean reward: 0.574 [0.507, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.351, 10.098], loss: 0.001487, mae: 0.041845, mean_q: 1.166237
 202900/1000000: episode: 2029, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.280, mean reward: 0.583 [0.506, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.860, 10.396], loss: 0.001437, mae: 0.041396, mean_q: 1.168051
 203000/1000000: episode: 2030, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.641, mean reward: 0.616 [0.504, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.910, 10.098], loss: 0.001709, mae: 0.044636, mean_q: 1.170774
 203100/1000000: episode: 2031, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.240, mean reward: 0.602 [0.498, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.714, 10.098], loss: 0.001486, mae: 0.042352, mean_q: 1.168652
 203200/1000000: episode: 2032, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.780, mean reward: 0.588 [0.501, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.076, 10.098], loss: 0.001474, mae: 0.041822, mean_q: 1.165162
 203300/1000000: episode: 2033, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.311, mean reward: 0.593 [0.506, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.589, 10.253], loss: 0.001510, mae: 0.042249, mean_q: 1.166127
 203400/1000000: episode: 2034, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.668, mean reward: 0.567 [0.509, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.756, 10.098], loss: 0.001459, mae: 0.042084, mean_q: 1.166989
 203500/1000000: episode: 2035, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.140, mean reward: 0.591 [0.508, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.492, 10.120], loss: 0.001492, mae: 0.042119, mean_q: 1.164536
 203600/1000000: episode: 2036, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.928, mean reward: 0.599 [0.508, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.863, 10.098], loss: 0.001526, mae: 0.042222, mean_q: 1.164731
 203700/1000000: episode: 2037, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.963, mean reward: 0.580 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.691, 10.119], loss: 0.001477, mae: 0.041812, mean_q: 1.168893
 203800/1000000: episode: 2038, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.587, mean reward: 0.586 [0.503, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.531, 10.320], loss: 0.001495, mae: 0.042389, mean_q: 1.165872
 203900/1000000: episode: 2039, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.938, mean reward: 0.609 [0.513, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.343, 10.444], loss: 0.001446, mae: 0.041495, mean_q: 1.164913
 204000/1000000: episode: 2040, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 62.473, mean reward: 0.625 [0.507, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.567, 10.271], loss: 0.001381, mae: 0.040970, mean_q: 1.168592
 204100/1000000: episode: 2041, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.097, mean reward: 0.591 [0.504, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.238, 10.098], loss: 0.001491, mae: 0.042720, mean_q: 1.173525
 204200/1000000: episode: 2042, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.401, mean reward: 0.584 [0.508, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.522, 10.098], loss: 0.001584, mae: 0.043206, mean_q: 1.169259
 204300/1000000: episode: 2043, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.033, mean reward: 0.570 [0.506, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.363, 10.098], loss: 0.001423, mae: 0.041422, mean_q: 1.171784
 204400/1000000: episode: 2044, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.832, mean reward: 0.588 [0.512, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.640, 10.098], loss: 0.001533, mae: 0.042506, mean_q: 1.171939
 204500/1000000: episode: 2045, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.429, mean reward: 0.584 [0.505, 0.866], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.000, 10.148], loss: 0.001487, mae: 0.042013, mean_q: 1.173010
 204600/1000000: episode: 2046, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.004, mean reward: 0.580 [0.500, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.220, 10.098], loss: 0.001491, mae: 0.041786, mean_q: 1.171145
 204700/1000000: episode: 2047, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.945, mean reward: 0.589 [0.500, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.351, 10.304], loss: 0.001419, mae: 0.041500, mean_q: 1.170150
 204800/1000000: episode: 2048, duration: 0.611s, episode steps: 100, steps per second: 164, episode reward: 61.106, mean reward: 0.611 [0.522, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.361, 10.295], loss: 0.001398, mae: 0.041082, mean_q: 1.171077
 204900/1000000: episode: 2049, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.467, mean reward: 0.595 [0.505, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.963, 10.098], loss: 0.001450, mae: 0.042183, mean_q: 1.175343
 205000/1000000: episode: 2050, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 70.220, mean reward: 0.702 [0.511, 0.914], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-2.006, 10.098], loss: 0.001475, mae: 0.041733, mean_q: 1.176454
 205100/1000000: episode: 2051, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 60.237, mean reward: 0.602 [0.500, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.064, 10.245], loss: 0.001429, mae: 0.041769, mean_q: 1.177055
 205200/1000000: episode: 2052, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.334, mean reward: 0.593 [0.507, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.168, 10.098], loss: 0.001470, mae: 0.041673, mean_q: 1.176438
 205300/1000000: episode: 2053, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.301, mean reward: 0.583 [0.506, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.139, 10.221], loss: 0.001439, mae: 0.042058, mean_q: 1.176430
 205400/1000000: episode: 2054, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 58.934, mean reward: 0.589 [0.518, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.002, 10.327], loss: 0.001449, mae: 0.041952, mean_q: 1.175210
 205500/1000000: episode: 2055, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 58.197, mean reward: 0.582 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.284, 10.098], loss: 0.001483, mae: 0.042210, mean_q: 1.174200
 205600/1000000: episode: 2056, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.785, mean reward: 0.608 [0.505, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.911, 10.105], loss: 0.001558, mae: 0.042976, mean_q: 1.173756
 205700/1000000: episode: 2057, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 61.135, mean reward: 0.611 [0.511, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.585, 10.481], loss: 0.001380, mae: 0.040968, mean_q: 1.172035
 205800/1000000: episode: 2058, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.258, mean reward: 0.563 [0.505, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.605, 10.141], loss: 0.001368, mae: 0.040401, mean_q: 1.175318
 205900/1000000: episode: 2059, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.690, mean reward: 0.587 [0.500, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.353, 10.185], loss: 0.001575, mae: 0.042516, mean_q: 1.172168
 206000/1000000: episode: 2060, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.773, mean reward: 0.578 [0.500, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.509, 10.224], loss: 0.001420, mae: 0.040801, mean_q: 1.167672
 206100/1000000: episode: 2061, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.573, mean reward: 0.596 [0.510, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.752, 10.098], loss: 0.001368, mae: 0.039976, mean_q: 1.165594
 206200/1000000: episode: 2062, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 61.113, mean reward: 0.611 [0.511, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.868, 10.098], loss: 0.001409, mae: 0.040827, mean_q: 1.173195
 206300/1000000: episode: 2063, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 61.190, mean reward: 0.612 [0.516, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.099, 10.098], loss: 0.001465, mae: 0.040995, mean_q: 1.173777
 206400/1000000: episode: 2064, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.889, mean reward: 0.579 [0.513, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.523, 10.098], loss: 0.001373, mae: 0.040265, mean_q: 1.169500
 206500/1000000: episode: 2065, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.809, mean reward: 0.588 [0.501, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.778, 10.197], loss: 0.001515, mae: 0.041874, mean_q: 1.171895
 206600/1000000: episode: 2066, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.231, mean reward: 0.612 [0.523, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.142, 10.323], loss: 0.001531, mae: 0.042609, mean_q: 1.171866
 206700/1000000: episode: 2067, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.737, mean reward: 0.587 [0.500, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.978, 10.098], loss: 0.001455, mae: 0.041197, mean_q: 1.174706
 206800/1000000: episode: 2068, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.471, mean reward: 0.585 [0.503, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.687, 10.098], loss: 0.001542, mae: 0.042513, mean_q: 1.174146
 206900/1000000: episode: 2069, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.522, mean reward: 0.585 [0.514, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.060, 10.098], loss: 0.001364, mae: 0.040936, mean_q: 1.179155
 207000/1000000: episode: 2070, duration: 0.533s, episode steps: 100, steps per second: 187, episode reward: 59.688, mean reward: 0.597 [0.500, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.569, 10.098], loss: 0.001422, mae: 0.041182, mean_q: 1.176152
 207100/1000000: episode: 2071, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.508, mean reward: 0.595 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.040, 10.098], loss: 0.001433, mae: 0.041296, mean_q: 1.175107
 207200/1000000: episode: 2072, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.276, mean reward: 0.573 [0.501, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.348, 10.098], loss: 0.001471, mae: 0.042307, mean_q: 1.177289
 207300/1000000: episode: 2073, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.750, mean reward: 0.597 [0.515, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.785, 10.098], loss: 0.001472, mae: 0.041882, mean_q: 1.175046
 207400/1000000: episode: 2074, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.965, mean reward: 0.610 [0.510, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.583, 10.103], loss: 0.001456, mae: 0.041290, mean_q: 1.178555
 207500/1000000: episode: 2075, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.573, mean reward: 0.586 [0.506, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.401, 10.098], loss: 0.001492, mae: 0.042014, mean_q: 1.177010
 207600/1000000: episode: 2076, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 60.158, mean reward: 0.602 [0.504, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.672, 10.127], loss: 0.001441, mae: 0.041754, mean_q: 1.175315
 207700/1000000: episode: 2077, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.768, mean reward: 0.578 [0.499, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.564, 10.199], loss: 0.001394, mae: 0.040585, mean_q: 1.178292
 207800/1000000: episode: 2078, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.589, mean reward: 0.606 [0.509, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.559, 10.098], loss: 0.001367, mae: 0.040116, mean_q: 1.176655
 207900/1000000: episode: 2079, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 62.114, mean reward: 0.621 [0.499, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.721, 10.463], loss: 0.001486, mae: 0.041902, mean_q: 1.176305
 208000/1000000: episode: 2080, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.894, mean reward: 0.589 [0.505, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.965, 10.098], loss: 0.001409, mae: 0.041097, mean_q: 1.177568
 208100/1000000: episode: 2081, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.812, mean reward: 0.608 [0.501, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.257, 10.328], loss: 0.001442, mae: 0.041186, mean_q: 1.178783
 208200/1000000: episode: 2082, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.201, mean reward: 0.582 [0.504, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.616, 10.098], loss: 0.001375, mae: 0.040717, mean_q: 1.179422
 208300/1000000: episode: 2083, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.718, mean reward: 0.607 [0.527, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.567, 10.098], loss: 0.001429, mae: 0.041640, mean_q: 1.176045
 208400/1000000: episode: 2084, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 58.831, mean reward: 0.588 [0.502, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.595, 10.248], loss: 0.001392, mae: 0.039955, mean_q: 1.180036
 208500/1000000: episode: 2085, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.734, mean reward: 0.577 [0.508, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.517, 10.099], loss: 0.001392, mae: 0.040516, mean_q: 1.176453
 208600/1000000: episode: 2086, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.376, mean reward: 0.584 [0.511, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.808, 10.131], loss: 0.001502, mae: 0.041830, mean_q: 1.180369
 208700/1000000: episode: 2087, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.323, mean reward: 0.563 [0.497, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.157, 10.098], loss: 0.001430, mae: 0.041466, mean_q: 1.179338
 208800/1000000: episode: 2088, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.510, mean reward: 0.615 [0.512, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.863, 10.098], loss: 0.001846, mae: 0.044750, mean_q: 1.175011
 208900/1000000: episode: 2089, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.071, mean reward: 0.591 [0.510, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.970, 10.098], loss: 0.001598, mae: 0.042907, mean_q: 1.180158
 209000/1000000: episode: 2090, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.682, mean reward: 0.577 [0.504, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.491, 10.198], loss: 0.001384, mae: 0.040091, mean_q: 1.177054
 209100/1000000: episode: 2091, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.060, mean reward: 0.581 [0.513, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.687, 10.098], loss: 0.001471, mae: 0.040959, mean_q: 1.174137
 209200/1000000: episode: 2092, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.518, mean reward: 0.605 [0.512, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.603, 10.098], loss: 0.001436, mae: 0.041155, mean_q: 1.176861
 209300/1000000: episode: 2093, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.947, mean reward: 0.599 [0.505, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.575, 10.098], loss: 0.001413, mae: 0.040783, mean_q: 1.178241
 209400/1000000: episode: 2094, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.285, mean reward: 0.593 [0.505, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.988, 10.334], loss: 0.001340, mae: 0.039657, mean_q: 1.174293
 209500/1000000: episode: 2095, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.752, mean reward: 0.598 [0.500, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.188, 10.348], loss: 0.001380, mae: 0.040108, mean_q: 1.174738
 209600/1000000: episode: 2096, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.666, mean reward: 0.577 [0.501, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.654, 10.108], loss: 0.001404, mae: 0.040579, mean_q: 1.177354
 209700/1000000: episode: 2097, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.041, mean reward: 0.590 [0.508, 0.895], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.308, 10.121], loss: 0.001419, mae: 0.040680, mean_q: 1.174512
 209800/1000000: episode: 2098, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 63.812, mean reward: 0.638 [0.509, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.501, 10.098], loss: 0.001403, mae: 0.040774, mean_q: 1.175873
 209900/1000000: episode: 2099, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.771, mean reward: 0.588 [0.503, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.795, 10.098], loss: 0.001333, mae: 0.039526, mean_q: 1.177728
 210000/1000000: episode: 2100, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.342, mean reward: 0.593 [0.505, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.551, 10.247], loss: 0.001484, mae: 0.041571, mean_q: 1.176553
 210100/1000000: episode: 2101, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.260, mean reward: 0.583 [0.511, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.200, 10.216], loss: 0.001434, mae: 0.040736, mean_q: 1.170721
 210200/1000000: episode: 2102, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.576, mean reward: 0.606 [0.502, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.193, 10.098], loss: 0.001614, mae: 0.041848, mean_q: 1.176028
 210300/1000000: episode: 2103, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.120, mean reward: 0.591 [0.513, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.471, 10.098], loss: 0.001448, mae: 0.040876, mean_q: 1.178484
 210400/1000000: episode: 2104, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.897, mean reward: 0.589 [0.500, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.976, 10.098], loss: 0.001464, mae: 0.041378, mean_q: 1.174898
 210500/1000000: episode: 2105, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 59.066, mean reward: 0.591 [0.508, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.456, 10.350], loss: 0.001554, mae: 0.042648, mean_q: 1.173336
 210600/1000000: episode: 2106, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.722, mean reward: 0.577 [0.508, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.952, 10.147], loss: 0.001468, mae: 0.040784, mean_q: 1.172510
 210700/1000000: episode: 2107, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.818, mean reward: 0.578 [0.505, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.028, 10.244], loss: 0.001489, mae: 0.041431, mean_q: 1.170677
 210800/1000000: episode: 2108, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.885, mean reward: 0.579 [0.504, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.597, 10.123], loss: 0.001450, mae: 0.040479, mean_q: 1.170332
 210900/1000000: episode: 2109, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.448, mean reward: 0.584 [0.505, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.537, 10.352], loss: 0.001515, mae: 0.041197, mean_q: 1.174423
 211000/1000000: episode: 2110, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.056, mean reward: 0.601 [0.504, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-1.103, 10.210], loss: 0.001461, mae: 0.041184, mean_q: 1.171852
 211100/1000000: episode: 2111, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 56.688, mean reward: 0.567 [0.504, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.734, 10.102], loss: 0.001345, mae: 0.039850, mean_q: 1.169803
 211200/1000000: episode: 2112, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.335, mean reward: 0.623 [0.510, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.234, 10.395], loss: 0.001452, mae: 0.041477, mean_q: 1.173593
 211300/1000000: episode: 2113, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.650, mean reward: 0.597 [0.517, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.582, 10.098], loss: 0.001440, mae: 0.040798, mean_q: 1.170961
 211400/1000000: episode: 2114, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.804, mean reward: 0.578 [0.508, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.223, 10.129], loss: 0.001564, mae: 0.042830, mean_q: 1.173193
 211500/1000000: episode: 2115, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.791, mean reward: 0.568 [0.502, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.774, 10.098], loss: 0.001490, mae: 0.042142, mean_q: 1.170926
 211600/1000000: episode: 2116, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 58.773, mean reward: 0.588 [0.499, 0.941], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.520, 10.281], loss: 0.001419, mae: 0.040465, mean_q: 1.167976
 211700/1000000: episode: 2117, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.554, mean reward: 0.586 [0.499, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.132, 10.178], loss: 0.001374, mae: 0.039804, mean_q: 1.169617
 211800/1000000: episode: 2118, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.702, mean reward: 0.607 [0.513, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.893, 10.365], loss: 0.001455, mae: 0.040801, mean_q: 1.171036
 211900/1000000: episode: 2119, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.069, mean reward: 0.571 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.785, 10.098], loss: 0.001451, mae: 0.040920, mean_q: 1.170833
 212000/1000000: episode: 2120, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.055, mean reward: 0.601 [0.510, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.869, 10.098], loss: 0.001574, mae: 0.042247, mean_q: 1.171579
 212100/1000000: episode: 2121, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.795, mean reward: 0.598 [0.508, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.571, 10.321], loss: 0.001496, mae: 0.041823, mean_q: 1.171762
 212200/1000000: episode: 2122, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.595, mean reward: 0.586 [0.507, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.650, 10.161], loss: 0.001472, mae: 0.041243, mean_q: 1.174431
 212300/1000000: episode: 2123, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.870, mean reward: 0.589 [0.507, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.980, 10.406], loss: 0.001370, mae: 0.039479, mean_q: 1.165096
 212400/1000000: episode: 2124, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.538, mean reward: 0.585 [0.505, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.976, 10.141], loss: 0.001520, mae: 0.041508, mean_q: 1.167923
 212500/1000000: episode: 2125, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 63.073, mean reward: 0.631 [0.516, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.659, 10.098], loss: 0.001400, mae: 0.040879, mean_q: 1.167346
 212600/1000000: episode: 2126, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.961, mean reward: 0.580 [0.502, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.702, 10.098], loss: 0.001549, mae: 0.041773, mean_q: 1.174030
 212700/1000000: episode: 2127, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.485, mean reward: 0.585 [0.513, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.702, 10.164], loss: 0.001476, mae: 0.040978, mean_q: 1.172762
 212800/1000000: episode: 2128, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.328, mean reward: 0.573 [0.502, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.004, 10.098], loss: 0.001499, mae: 0.040912, mean_q: 1.171581
 212900/1000000: episode: 2129, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.914, mean reward: 0.589 [0.504, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.871, 10.098], loss: 0.001489, mae: 0.041479, mean_q: 1.168577
 213000/1000000: episode: 2130, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.793, mean reward: 0.578 [0.521, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.003, 10.098], loss: 0.001405, mae: 0.040437, mean_q: 1.168635
 213100/1000000: episode: 2131, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.309, mean reward: 0.583 [0.508, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.126, 10.156], loss: 0.001437, mae: 0.041069, mean_q: 1.168539
 213200/1000000: episode: 2132, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.362, mean reward: 0.594 [0.513, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.257, 10.111], loss: 0.001490, mae: 0.041491, mean_q: 1.169361
 213300/1000000: episode: 2133, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.086, mean reward: 0.591 [0.498, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.542, 10.144], loss: 0.001479, mae: 0.041434, mean_q: 1.166852
 213400/1000000: episode: 2134, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.620, mean reward: 0.586 [0.507, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.742, 10.132], loss: 0.001354, mae: 0.040256, mean_q: 1.163660
 213500/1000000: episode: 2135, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.311, mean reward: 0.583 [0.505, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.683, 10.098], loss: 0.001831, mae: 0.042983, mean_q: 1.167091
 213600/1000000: episode: 2136, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.311, mean reward: 0.583 [0.518, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.938, 10.272], loss: 0.001818, mae: 0.044633, mean_q: 1.167551
 213700/1000000: episode: 2137, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.741, mean reward: 0.577 [0.501, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.289, 10.098], loss: 0.001556, mae: 0.042725, mean_q: 1.168652
 213800/1000000: episode: 2138, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.681, mean reward: 0.587 [0.506, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.353, 10.414], loss: 0.001516, mae: 0.041899, mean_q: 1.167046
 213900/1000000: episode: 2139, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.125, mean reward: 0.581 [0.503, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.605, 10.150], loss: 0.001568, mae: 0.042226, mean_q: 1.167318
 214000/1000000: episode: 2140, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.933, mean reward: 0.589 [0.499, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.292, 10.365], loss: 0.001509, mae: 0.041885, mean_q: 1.165057
 214100/1000000: episode: 2141, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.881, mean reward: 0.579 [0.503, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.262, 10.098], loss: 0.001523, mae: 0.042390, mean_q: 1.166099
 214200/1000000: episode: 2142, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.462, mean reward: 0.595 [0.514, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.095, 10.098], loss: 0.001616, mae: 0.043608, mean_q: 1.167569
 214300/1000000: episode: 2143, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.904, mean reward: 0.579 [0.507, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.703, 10.169], loss: 0.001509, mae: 0.041697, mean_q: 1.166453
 214400/1000000: episode: 2144, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.647, mean reward: 0.586 [0.514, 0.866], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.665, 10.276], loss: 0.001422, mae: 0.041430, mean_q: 1.163922
 214500/1000000: episode: 2145, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 60.422, mean reward: 0.604 [0.506, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.354, 10.166], loss: 0.001458, mae: 0.041619, mean_q: 1.164404
 214600/1000000: episode: 2146, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.151, mean reward: 0.582 [0.506, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.272, 10.116], loss: 0.001537, mae: 0.042679, mean_q: 1.165317
 214700/1000000: episode: 2147, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 61.024, mean reward: 0.610 [0.499, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.306, 10.249], loss: 0.001467, mae: 0.041733, mean_q: 1.165237
 214800/1000000: episode: 2148, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.568, mean reward: 0.586 [0.518, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.478, 10.098], loss: 0.001390, mae: 0.040411, mean_q: 1.162609
 214900/1000000: episode: 2149, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.276, mean reward: 0.593 [0.506, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.634, 10.176], loss: 0.001417, mae: 0.040541, mean_q: 1.161696
 215000/1000000: episode: 2150, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.381, mean reward: 0.594 [0.505, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.621, 10.170], loss: 0.001361, mae: 0.040096, mean_q: 1.163868
 215100/1000000: episode: 2151, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.084, mean reward: 0.581 [0.506, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.670, 10.331], loss: 0.001500, mae: 0.041558, mean_q: 1.165278
 215200/1000000: episode: 2152, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.327, mean reward: 0.583 [0.510, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.525, 10.098], loss: 0.001448, mae: 0.041335, mean_q: 1.161392
 215300/1000000: episode: 2153, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.937, mean reward: 0.599 [0.509, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.536, 10.237], loss: 0.001453, mae: 0.041272, mean_q: 1.162054
 215400/1000000: episode: 2154, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.794, mean reward: 0.588 [0.506, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.474, 10.098], loss: 0.001464, mae: 0.041523, mean_q: 1.160998
 215500/1000000: episode: 2155, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.091, mean reward: 0.591 [0.500, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.363, 10.098], loss: 0.001418, mae: 0.041155, mean_q: 1.162045
 215600/1000000: episode: 2156, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 56.977, mean reward: 0.570 [0.505, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.199, 10.098], loss: 0.001395, mae: 0.040443, mean_q: 1.162888
 215700/1000000: episode: 2157, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.092, mean reward: 0.581 [0.506, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.519, 10.098], loss: 0.001483, mae: 0.042123, mean_q: 1.161593
 215800/1000000: episode: 2158, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.666, mean reward: 0.597 [0.515, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.868, 10.176], loss: 0.001499, mae: 0.042199, mean_q: 1.166138
 215900/1000000: episode: 2159, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.901, mean reward: 0.599 [0.499, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.754, 10.170], loss: 0.001432, mae: 0.041169, mean_q: 1.165282
 216000/1000000: episode: 2160, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.650, mean reward: 0.587 [0.506, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.618, 10.098], loss: 0.001395, mae: 0.040384, mean_q: 1.163590
 216100/1000000: episode: 2161, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.080, mean reward: 0.601 [0.503, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.218, 10.199], loss: 0.001440, mae: 0.041004, mean_q: 1.163993
 216200/1000000: episode: 2162, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.490, mean reward: 0.585 [0.502, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.085, 10.140], loss: 0.001563, mae: 0.042580, mean_q: 1.163805
 216300/1000000: episode: 2163, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 61.623, mean reward: 0.616 [0.501, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-2.902, 10.163], loss: 0.001340, mae: 0.039439, mean_q: 1.160479
 216400/1000000: episode: 2164, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.175, mean reward: 0.582 [0.505, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.982, 10.098], loss: 0.001489, mae: 0.041682, mean_q: 1.164443
 216500/1000000: episode: 2165, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.345, mean reward: 0.583 [0.507, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.574, 10.098], loss: 0.001448, mae: 0.041458, mean_q: 1.160337
 216600/1000000: episode: 2166, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.304, mean reward: 0.573 [0.502, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.361, 10.160], loss: 0.001413, mae: 0.040726, mean_q: 1.164118
 216700/1000000: episode: 2167, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 62.506, mean reward: 0.625 [0.520, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.495, 10.098], loss: 0.001428, mae: 0.041640, mean_q: 1.166162
 216800/1000000: episode: 2168, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.899, mean reward: 0.599 [0.519, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.564, 10.213], loss: 0.001421, mae: 0.041077, mean_q: 1.165692
 216900/1000000: episode: 2169, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.866, mean reward: 0.569 [0.502, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.696, 10.325], loss: 0.001428, mae: 0.040788, mean_q: 1.165047
 217000/1000000: episode: 2170, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.014, mean reward: 0.600 [0.505, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.495, 10.326], loss: 0.001461, mae: 0.041513, mean_q: 1.165833
 217100/1000000: episode: 2171, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.453, mean reward: 0.585 [0.509, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-2.596, 10.263], loss: 0.001387, mae: 0.040768, mean_q: 1.162854
 217200/1000000: episode: 2172, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.447, mean reward: 0.594 [0.501, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.677, 10.335], loss: 0.001454, mae: 0.041707, mean_q: 1.166511
 217300/1000000: episode: 2173, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 62.112, mean reward: 0.621 [0.499, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.466, 10.382], loss: 0.001302, mae: 0.039351, mean_q: 1.164840
 217400/1000000: episode: 2174, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.968, mean reward: 0.600 [0.515, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.219, 10.333], loss: 0.001320, mae: 0.039122, mean_q: 1.163526
 217500/1000000: episode: 2175, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.850, mean reward: 0.588 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.062, 10.098], loss: 0.001480, mae: 0.041669, mean_q: 1.169985
 217600/1000000: episode: 2176, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.572, mean reward: 0.596 [0.503, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.822, 10.168], loss: 0.001394, mae: 0.040726, mean_q: 1.167973
 217700/1000000: episode: 2177, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.125, mean reward: 0.591 [0.506, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.915, 10.303], loss: 0.001340, mae: 0.039837, mean_q: 1.165907
 217800/1000000: episode: 2178, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.263, mean reward: 0.583 [0.509, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.120, 10.195], loss: 0.001362, mae: 0.040587, mean_q: 1.167305
 217900/1000000: episode: 2179, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.458, mean reward: 0.575 [0.505, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.870, 10.198], loss: 0.001314, mae: 0.039627, mean_q: 1.168232
 218000/1000000: episode: 2180, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 56.647, mean reward: 0.566 [0.500, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.795, 10.098], loss: 0.001339, mae: 0.040021, mean_q: 1.163205
 218100/1000000: episode: 2181, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.459, mean reward: 0.595 [0.508, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.467, 10.098], loss: 0.001354, mae: 0.040049, mean_q: 1.167293
 218200/1000000: episode: 2182, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.508, mean reward: 0.605 [0.512, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.459, 10.317], loss: 0.001437, mae: 0.041202, mean_q: 1.164088
 218300/1000000: episode: 2183, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.076, mean reward: 0.611 [0.509, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.449, 10.124], loss: 0.001409, mae: 0.041107, mean_q: 1.168895
 218400/1000000: episode: 2184, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.455, mean reward: 0.575 [0.504, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.296, 10.144], loss: 0.001486, mae: 0.041634, mean_q: 1.169444
 218500/1000000: episode: 2185, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.459, mean reward: 0.585 [0.503, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.878, 10.252], loss: 0.001401, mae: 0.040966, mean_q: 1.165534
 218600/1000000: episode: 2186, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.699, mean reward: 0.597 [0.515, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.211, 10.346], loss: 0.001383, mae: 0.040740, mean_q: 1.167451
 218700/1000000: episode: 2187, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.385, mean reward: 0.584 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.675, 10.098], loss: 0.001404, mae: 0.041053, mean_q: 1.165074
 218800/1000000: episode: 2188, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 63.197, mean reward: 0.632 [0.501, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.510, 10.435], loss: 0.001426, mae: 0.040998, mean_q: 1.168033
 218900/1000000: episode: 2189, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.299, mean reward: 0.583 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.103, 10.169], loss: 0.001512, mae: 0.042659, mean_q: 1.170022
 219000/1000000: episode: 2190, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.040, mean reward: 0.590 [0.516, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.366, 10.098], loss: 0.001342, mae: 0.040202, mean_q: 1.169948
 219100/1000000: episode: 2191, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.179, mean reward: 0.592 [0.503, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.492, 10.098], loss: 0.001452, mae: 0.041775, mean_q: 1.171976
 219200/1000000: episode: 2192, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 56.014, mean reward: 0.560 [0.499, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.060, 10.098], loss: 0.001410, mae: 0.040985, mean_q: 1.171770
 219300/1000000: episode: 2193, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.124, mean reward: 0.571 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.055, 10.215], loss: 0.001481, mae: 0.041803, mean_q: 1.169497
 219400/1000000: episode: 2194, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.916, mean reward: 0.589 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.129, 10.098], loss: 0.001448, mae: 0.041586, mean_q: 1.164923
 219500/1000000: episode: 2195, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.396, mean reward: 0.594 [0.504, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.466, 10.098], loss: 0.001436, mae: 0.041850, mean_q: 1.169645
 219600/1000000: episode: 2196, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.374, mean reward: 0.594 [0.499, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.195, 10.098], loss: 0.001409, mae: 0.041557, mean_q: 1.170471
 219700/1000000: episode: 2197, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.025, mean reward: 0.590 [0.503, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.468, 10.142], loss: 0.001464, mae: 0.042078, mean_q: 1.172670
 219800/1000000: episode: 2198, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.293, mean reward: 0.593 [0.499, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.361, 10.098], loss: 0.001341, mae: 0.040391, mean_q: 1.170179
 219900/1000000: episode: 2199, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.398, mean reward: 0.584 [0.504, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.680, 10.098], loss: 0.001474, mae: 0.042606, mean_q: 1.169556
 220000/1000000: episode: 2200, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.512, mean reward: 0.585 [0.506, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.952, 10.250], loss: 0.001498, mae: 0.042538, mean_q: 1.169491
 220100/1000000: episode: 2201, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 60.447, mean reward: 0.604 [0.503, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.666, 10.098], loss: 0.001405, mae: 0.041266, mean_q: 1.169603
 220200/1000000: episode: 2202, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.877, mean reward: 0.569 [0.501, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.557, 10.163], loss: 0.001376, mae: 0.040845, mean_q: 1.168071
 220300/1000000: episode: 2203, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.072, mean reward: 0.591 [0.501, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.022, 10.098], loss: 0.001443, mae: 0.041768, mean_q: 1.165436
 220400/1000000: episode: 2204, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 62.833, mean reward: 0.628 [0.503, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.325, 10.098], loss: 0.001473, mae: 0.042151, mean_q: 1.165656
 220500/1000000: episode: 2205, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.390, mean reward: 0.574 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.099, 10.098], loss: 0.001409, mae: 0.041652, mean_q: 1.169571
 220600/1000000: episode: 2206, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.223, mean reward: 0.592 [0.509, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.372, 10.161], loss: 0.001443, mae: 0.042042, mean_q: 1.170623
 220700/1000000: episode: 2207, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.035, mean reward: 0.620 [0.513, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.294, 10.209], loss: 0.001479, mae: 0.042564, mean_q: 1.174293
 220800/1000000: episode: 2208, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.449, mean reward: 0.604 [0.512, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.999, 10.116], loss: 0.001496, mae: 0.042315, mean_q: 1.170245
 220900/1000000: episode: 2209, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.691, mean reward: 0.597 [0.499, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.123, 10.113], loss: 0.001469, mae: 0.041794, mean_q: 1.171197
 221000/1000000: episode: 2210, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.931, mean reward: 0.609 [0.500, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.599, 10.098], loss: 0.001443, mae: 0.041990, mean_q: 1.171022
 221100/1000000: episode: 2211, duration: 0.533s, episode steps: 100, steps per second: 187, episode reward: 61.347, mean reward: 0.613 [0.506, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.371, 10.098], loss: 0.001394, mae: 0.041374, mean_q: 1.172613
 221200/1000000: episode: 2212, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.411, mean reward: 0.604 [0.506, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.529, 10.258], loss: 0.001425, mae: 0.041623, mean_q: 1.175169
 221300/1000000: episode: 2213, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.243, mean reward: 0.582 [0.500, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.154, 10.141], loss: 0.001485, mae: 0.042348, mean_q: 1.170629
 221400/1000000: episode: 2214, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 56.636, mean reward: 0.566 [0.498, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.989, 10.112], loss: 0.001501, mae: 0.042868, mean_q: 1.174097
 221500/1000000: episode: 2215, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.775, mean reward: 0.608 [0.508, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.570, 10.402], loss: 0.001523, mae: 0.042923, mean_q: 1.169696
 221600/1000000: episode: 2216, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.657, mean reward: 0.577 [0.507, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.847, 10.252], loss: 0.001545, mae: 0.043166, mean_q: 1.175765
 221700/1000000: episode: 2217, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.553, mean reward: 0.596 [0.514, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.289, 10.098], loss: 0.001484, mae: 0.042538, mean_q: 1.170915
 221800/1000000: episode: 2218, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.214, mean reward: 0.592 [0.499, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.759, 10.312], loss: 0.001407, mae: 0.040748, mean_q: 1.172115
 221900/1000000: episode: 2219, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.812, mean reward: 0.598 [0.500, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.434, 10.262], loss: 0.001497, mae: 0.042629, mean_q: 1.171638
 222000/1000000: episode: 2220, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.189, mean reward: 0.582 [0.499, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.084, 10.139], loss: 0.001419, mae: 0.041176, mean_q: 1.170555
 222100/1000000: episode: 2221, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.881, mean reward: 0.579 [0.500, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.989, 10.098], loss: 0.001390, mae: 0.040878, mean_q: 1.169906
 222200/1000000: episode: 2222, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 66.592, mean reward: 0.666 [0.509, 0.880], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.787, 10.516], loss: 0.001441, mae: 0.041566, mean_q: 1.170610
 222300/1000000: episode: 2223, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 62.366, mean reward: 0.624 [0.506, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.118, 10.257], loss: 0.001470, mae: 0.041815, mean_q: 1.172222
 222400/1000000: episode: 2224, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.332, mean reward: 0.583 [0.499, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.905, 10.131], loss: 0.001413, mae: 0.041320, mean_q: 1.176825
 222500/1000000: episode: 2225, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.961, mean reward: 0.600 [0.505, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.537, 10.098], loss: 0.001418, mae: 0.041338, mean_q: 1.173984
 222600/1000000: episode: 2226, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.688, mean reward: 0.577 [0.500, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.028, 10.125], loss: 0.001490, mae: 0.042381, mean_q: 1.174893
 222700/1000000: episode: 2227, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.411, mean reward: 0.574 [0.500, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.145, 10.098], loss: 0.001531, mae: 0.042838, mean_q: 1.171788
 222800/1000000: episode: 2228, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.070, mean reward: 0.591 [0.508, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.797, 10.124], loss: 0.001493, mae: 0.042297, mean_q: 1.172611
 222900/1000000: episode: 2229, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.386, mean reward: 0.584 [0.502, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.614, 10.113], loss: 0.001507, mae: 0.042775, mean_q: 1.170889
 223000/1000000: episode: 2230, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.360, mean reward: 0.574 [0.502, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.836, 10.098], loss: 0.001488, mae: 0.041945, mean_q: 1.174714
 223100/1000000: episode: 2231, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.532, mean reward: 0.595 [0.501, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.843, 10.098], loss: 0.001558, mae: 0.043079, mean_q: 1.174932
 223200/1000000: episode: 2232, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.024, mean reward: 0.600 [0.509, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.857, 10.098], loss: 0.001454, mae: 0.041958, mean_q: 1.170942
 223300/1000000: episode: 2233, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.861, mean reward: 0.569 [0.505, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.710, 10.173], loss: 0.001429, mae: 0.041373, mean_q: 1.175314
 223400/1000000: episode: 2234, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.170, mean reward: 0.582 [0.499, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.255, 10.206], loss: 0.001499, mae: 0.042392, mean_q: 1.171366
 223500/1000000: episode: 2235, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.325, mean reward: 0.583 [0.501, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.976, 10.098], loss: 0.001414, mae: 0.041617, mean_q: 1.172511
 223600/1000000: episode: 2236, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.665, mean reward: 0.617 [0.511, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.826, 10.246], loss: 0.001422, mae: 0.041395, mean_q: 1.171987
 223700/1000000: episode: 2237, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.693, mean reward: 0.587 [0.502, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.575, 10.122], loss: 0.001473, mae: 0.041684, mean_q: 1.174072
 223800/1000000: episode: 2238, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.161, mean reward: 0.592 [0.502, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.774, 10.350], loss: 0.001500, mae: 0.042147, mean_q: 1.168674
 223900/1000000: episode: 2239, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.602, mean reward: 0.606 [0.511, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.907, 10.098], loss: 0.001550, mae: 0.042358, mean_q: 1.169838
 224000/1000000: episode: 2240, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.790, mean reward: 0.588 [0.509, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.360, 10.098], loss: 0.001511, mae: 0.042124, mean_q: 1.171359
 224100/1000000: episode: 2241, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 57.403, mean reward: 0.574 [0.499, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.425, 10.098], loss: 0.001425, mae: 0.041351, mean_q: 1.172017
 224200/1000000: episode: 2242, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.119, mean reward: 0.571 [0.501, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.569, 10.098], loss: 0.001606, mae: 0.043459, mean_q: 1.172238
 224300/1000000: episode: 2243, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.168, mean reward: 0.572 [0.507, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.844, 10.123], loss: 0.001539, mae: 0.042475, mean_q: 1.175441
 224400/1000000: episode: 2244, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.797, mean reward: 0.578 [0.501, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.617, 10.196], loss: 0.001532, mae: 0.042584, mean_q: 1.172918
 224500/1000000: episode: 2245, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 65.286, mean reward: 0.653 [0.518, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.626, 10.272], loss: 0.001491, mae: 0.042236, mean_q: 1.174753
 224600/1000000: episode: 2246, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.195, mean reward: 0.582 [0.507, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.939, 10.098], loss: 0.001388, mae: 0.040611, mean_q: 1.173464
 224700/1000000: episode: 2247, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.644, mean reward: 0.596 [0.509, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.713, 10.098], loss: 0.001371, mae: 0.040121, mean_q: 1.170305
 224800/1000000: episode: 2248, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.140, mean reward: 0.601 [0.501, 0.843], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-2.655, 10.294], loss: 0.001554, mae: 0.042441, mean_q: 1.176314
 224900/1000000: episode: 2249, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.398, mean reward: 0.574 [0.500, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.782, 10.098], loss: 0.001544, mae: 0.042775, mean_q: 1.171064
 225000/1000000: episode: 2250, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.256, mean reward: 0.593 [0.519, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.949, 10.098], loss: 0.001568, mae: 0.042321, mean_q: 1.174482
 225100/1000000: episode: 2251, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.901, mean reward: 0.579 [0.510, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.214, 10.098], loss: 0.001531, mae: 0.042327, mean_q: 1.175852
 225200/1000000: episode: 2252, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.318, mean reward: 0.573 [0.499, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.924, 10.142], loss: 0.001612, mae: 0.043168, mean_q: 1.173475
 225300/1000000: episode: 2253, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.198, mean reward: 0.592 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.110, 10.100], loss: 0.001516, mae: 0.042013, mean_q: 1.168769
 225400/1000000: episode: 2254, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.029, mean reward: 0.580 [0.509, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.581, 10.125], loss: 0.001557, mae: 0.042995, mean_q: 1.173111
 225500/1000000: episode: 2255, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.763, mean reward: 0.578 [0.500, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.108, 10.143], loss: 0.001502, mae: 0.041569, mean_q: 1.170512
 225600/1000000: episode: 2256, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.441, mean reward: 0.584 [0.500, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.775, 10.116], loss: 0.001545, mae: 0.042329, mean_q: 1.169935
 225700/1000000: episode: 2257, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.756, mean reward: 0.608 [0.498, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.571, 10.287], loss: 0.001591, mae: 0.043047, mean_q: 1.170214
 225800/1000000: episode: 2258, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 57.976, mean reward: 0.580 [0.498, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.662, 10.098], loss: 0.001517, mae: 0.041329, mean_q: 1.169870
 225900/1000000: episode: 2259, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.029, mean reward: 0.590 [0.498, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.101, 10.098], loss: 0.001482, mae: 0.042044, mean_q: 1.169439
 226000/1000000: episode: 2260, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.033, mean reward: 0.590 [0.499, 0.873], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.114, 10.103], loss: 0.001645, mae: 0.043455, mean_q: 1.171274
 226100/1000000: episode: 2261, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 58.574, mean reward: 0.586 [0.510, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.635, 10.098], loss: 0.001486, mae: 0.042003, mean_q: 1.165575
 226200/1000000: episode: 2262, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.864, mean reward: 0.609 [0.507, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.067, 10.230], loss: 0.001572, mae: 0.042950, mean_q: 1.171742
 226300/1000000: episode: 2263, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.561, mean reward: 0.566 [0.500, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.817, 10.237], loss: 0.001535, mae: 0.042311, mean_q: 1.164995
 226400/1000000: episode: 2264, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.548, mean reward: 0.585 [0.503, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.881, 10.098], loss: 0.001519, mae: 0.042098, mean_q: 1.169629
 226500/1000000: episode: 2265, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 59.453, mean reward: 0.595 [0.517, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.386, 10.098], loss: 0.001514, mae: 0.041633, mean_q: 1.166941
 226600/1000000: episode: 2266, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.078, mean reward: 0.571 [0.511, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.447, 10.098], loss: 0.001508, mae: 0.041473, mean_q: 1.167347
 226700/1000000: episode: 2267, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 56.760, mean reward: 0.568 [0.504, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.926, 10.139], loss: 0.001601, mae: 0.042612, mean_q: 1.168465
 226800/1000000: episode: 2268, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.500, mean reward: 0.585 [0.503, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.033, 10.098], loss: 0.001568, mae: 0.042163, mean_q: 1.165179
 226900/1000000: episode: 2269, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.764, mean reward: 0.588 [0.512, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.489, 10.098], loss: 0.001495, mae: 0.041368, mean_q: 1.165330
 227000/1000000: episode: 2270, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.449, mean reward: 0.594 [0.514, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.697, 10.149], loss: 0.001508, mae: 0.041979, mean_q: 1.166135
 227100/1000000: episode: 2271, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.812, mean reward: 0.588 [0.498, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.762, 10.098], loss: 0.001528, mae: 0.042081, mean_q: 1.168379
 227200/1000000: episode: 2272, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.787, mean reward: 0.588 [0.521, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.779, 10.098], loss: 0.001480, mae: 0.041487, mean_q: 1.164084
 227300/1000000: episode: 2273, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.405, mean reward: 0.584 [0.511, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.461, 10.098], loss: 0.001520, mae: 0.041286, mean_q: 1.159839
 227400/1000000: episode: 2274, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.529, mean reward: 0.575 [0.503, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.142, 10.195], loss: 0.001564, mae: 0.042656, mean_q: 1.165143
 227500/1000000: episode: 2275, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 60.605, mean reward: 0.606 [0.515, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.565, 10.113], loss: 0.001601, mae: 0.042749, mean_q: 1.164220
 227600/1000000: episode: 2276, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.737, mean reward: 0.577 [0.510, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.937, 10.098], loss: 0.001426, mae: 0.039891, mean_q: 1.160578
 227700/1000000: episode: 2277, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.544, mean reward: 0.585 [0.505, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.905, 10.142], loss: 0.001528, mae: 0.041972, mean_q: 1.163887
 227800/1000000: episode: 2278, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.760, mean reward: 0.588 [0.508, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.178, 10.217], loss: 0.001365, mae: 0.040067, mean_q: 1.162506
 227900/1000000: episode: 2279, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.522, mean reward: 0.585 [0.501, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.644, 10.241], loss: 0.001371, mae: 0.039717, mean_q: 1.161465
 228000/1000000: episode: 2280, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.689, mean reward: 0.597 [0.504, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.963, 10.246], loss: 0.001360, mae: 0.039713, mean_q: 1.158436
 228100/1000000: episode: 2281, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.625, mean reward: 0.586 [0.505, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.554, 10.212], loss: 0.001455, mae: 0.040994, mean_q: 1.164145
 228200/1000000: episode: 2282, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.287, mean reward: 0.573 [0.498, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.728, 10.098], loss: 0.001403, mae: 0.040508, mean_q: 1.161245
 228300/1000000: episode: 2283, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.828, mean reward: 0.588 [0.507, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.107, 10.098], loss: 0.001352, mae: 0.039677, mean_q: 1.159589
 228400/1000000: episode: 2284, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.998, mean reward: 0.580 [0.500, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.848, 10.098], loss: 0.001386, mae: 0.040151, mean_q: 1.164531
 228500/1000000: episode: 2285, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.756, mean reward: 0.608 [0.515, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.988, 10.277], loss: 0.001380, mae: 0.040551, mean_q: 1.162263
 228600/1000000: episode: 2286, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 64.404, mean reward: 0.644 [0.504, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.976, 10.370], loss: 0.001352, mae: 0.039498, mean_q: 1.162226
 228700/1000000: episode: 2287, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.193, mean reward: 0.612 [0.505, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.269, 10.399], loss: 0.001376, mae: 0.040030, mean_q: 1.162986
 228800/1000000: episode: 2288, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.632, mean reward: 0.596 [0.499, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.697, 10.098], loss: 0.001371, mae: 0.040216, mean_q: 1.166721
 228900/1000000: episode: 2289, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.683, mean reward: 0.577 [0.501, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.232, 10.098], loss: 0.001425, mae: 0.040969, mean_q: 1.165360
 229000/1000000: episode: 2290, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.219, mean reward: 0.592 [0.507, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.870, 10.131], loss: 0.001336, mae: 0.039458, mean_q: 1.162871
 229100/1000000: episode: 2291, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.717, mean reward: 0.587 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.084, 10.237], loss: 0.001426, mae: 0.040940, mean_q: 1.159284
 229200/1000000: episode: 2292, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.529, mean reward: 0.585 [0.501, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.434, 10.123], loss: 0.001527, mae: 0.042280, mean_q: 1.164423
 229300/1000000: episode: 2293, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.519, mean reward: 0.575 [0.504, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.933, 10.149], loss: 0.001406, mae: 0.040707, mean_q: 1.164159
 229400/1000000: episode: 2294, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.437, mean reward: 0.594 [0.502, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.978, 10.098], loss: 0.001379, mae: 0.040310, mean_q: 1.166220
 229500/1000000: episode: 2295, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.596, mean reward: 0.596 [0.509, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.066, 10.140], loss: 0.001472, mae: 0.041292, mean_q: 1.162567
 229600/1000000: episode: 2296, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.615, mean reward: 0.576 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.729, 10.176], loss: 0.001554, mae: 0.042462, mean_q: 1.165211
 229700/1000000: episode: 2297, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.419, mean reward: 0.574 [0.499, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.119, 10.215], loss: 0.001405, mae: 0.041084, mean_q: 1.165005
 229800/1000000: episode: 2298, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.565, mean reward: 0.616 [0.507, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.881, 10.197], loss: 0.001386, mae: 0.040731, mean_q: 1.163241
 229900/1000000: episode: 2299, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.305, mean reward: 0.593 [0.506, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.045, 10.175], loss: 0.001370, mae: 0.040568, mean_q: 1.164609
 230000/1000000: episode: 2300, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 61.133, mean reward: 0.611 [0.508, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.000, 10.368], loss: 0.001411, mae: 0.041205, mean_q: 1.162961
 230100/1000000: episode: 2301, duration: 0.487s, episode steps: 100, steps per second: 205, episode reward: 59.492, mean reward: 0.595 [0.504, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.922, 10.326], loss: 0.001539, mae: 0.043116, mean_q: 1.166670
 230200/1000000: episode: 2302, duration: 0.484s, episode steps: 100, steps per second: 206, episode reward: 59.817, mean reward: 0.598 [0.509, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.934, 10.098], loss: 0.001390, mae: 0.040693, mean_q: 1.164445
 230300/1000000: episode: 2303, duration: 0.487s, episode steps: 100, steps per second: 205, episode reward: 58.154, mean reward: 0.582 [0.500, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.469, 10.142], loss: 0.001425, mae: 0.040905, mean_q: 1.168832
 230400/1000000: episode: 2304, duration: 0.522s, episode steps: 100, steps per second: 192, episode reward: 58.108, mean reward: 0.581 [0.508, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.898, 10.098], loss: 0.001472, mae: 0.041698, mean_q: 1.168640
 230500/1000000: episode: 2305, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.092, mean reward: 0.591 [0.512, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.431, 10.098], loss: 0.001323, mae: 0.040071, mean_q: 1.167668
 230600/1000000: episode: 2306, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 60.616, mean reward: 0.606 [0.507, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.384, 10.098], loss: 0.001307, mae: 0.039177, mean_q: 1.161810
 230700/1000000: episode: 2307, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.929, mean reward: 0.589 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.887, 10.098], loss: 0.001352, mae: 0.039849, mean_q: 1.162024
 230800/1000000: episode: 2308, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.757, mean reward: 0.598 [0.510, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.549, 10.098], loss: 0.001297, mae: 0.039065, mean_q: 1.163472
 230900/1000000: episode: 2309, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.357, mean reward: 0.584 [0.501, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.579, 10.098], loss: 0.001451, mae: 0.041474, mean_q: 1.167252
 231000/1000000: episode: 2310, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 63.644, mean reward: 0.636 [0.505, 0.905], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.553, 10.098], loss: 0.001323, mae: 0.039835, mean_q: 1.167031
 231100/1000000: episode: 2311, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.719, mean reward: 0.577 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.322, 10.098], loss: 0.001395, mae: 0.040741, mean_q: 1.169646
 231200/1000000: episode: 2312, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.598, mean reward: 0.586 [0.508, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.078, 10.098], loss: 0.001487, mae: 0.041558, mean_q: 1.170083
 231300/1000000: episode: 2313, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.955, mean reward: 0.610 [0.503, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.597, 10.098], loss: 0.001424, mae: 0.041563, mean_q: 1.169669
 231400/1000000: episode: 2314, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.265, mean reward: 0.583 [0.508, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.842, 10.247], loss: 0.001369, mae: 0.040294, mean_q: 1.170129
 231500/1000000: episode: 2315, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.958, mean reward: 0.620 [0.513, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.260, 10.098], loss: 0.001456, mae: 0.041713, mean_q: 1.171281
 231600/1000000: episode: 2316, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.228, mean reward: 0.572 [0.499, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.978, 10.290], loss: 0.001350, mae: 0.040167, mean_q: 1.168019
 231700/1000000: episode: 2317, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.560, mean reward: 0.596 [0.513, 0.841], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.046, 10.098], loss: 0.001427, mae: 0.041648, mean_q: 1.168664
 231800/1000000: episode: 2318, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 60.577, mean reward: 0.606 [0.510, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.501, 10.098], loss: 0.001378, mae: 0.040506, mean_q: 1.170378
 231900/1000000: episode: 2319, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.539, mean reward: 0.595 [0.510, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.099, 10.098], loss: 0.001469, mae: 0.041452, mean_q: 1.171493
 232000/1000000: episode: 2320, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.227, mean reward: 0.582 [0.508, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.343, 10.166], loss: 0.001362, mae: 0.040462, mean_q: 1.166635
 232100/1000000: episode: 2321, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.794, mean reward: 0.588 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.994, 10.106], loss: 0.001490, mae: 0.042122, mean_q: 1.171810
 232200/1000000: episode: 2322, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.700, mean reward: 0.587 [0.500, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.463, 10.186], loss: 0.001425, mae: 0.041111, mean_q: 1.171810
 232300/1000000: episode: 2323, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.260, mean reward: 0.603 [0.500, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.217, 10.300], loss: 0.001574, mae: 0.043062, mean_q: 1.177335
 232400/1000000: episode: 2324, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.584, mean reward: 0.576 [0.504, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.916, 10.140], loss: 0.001502, mae: 0.041468, mean_q: 1.174127
 232500/1000000: episode: 2325, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.734, mean reward: 0.577 [0.503, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-2.034, 10.161], loss: 0.001583, mae: 0.042647, mean_q: 1.171989
 232600/1000000: episode: 2326, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 56.211, mean reward: 0.562 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.762, 10.179], loss: 0.001507, mae: 0.042135, mean_q: 1.169134
 232700/1000000: episode: 2327, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.707, mean reward: 0.587 [0.504, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.220, 10.098], loss: 0.001550, mae: 0.043111, mean_q: 1.170129
 232800/1000000: episode: 2328, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.656, mean reward: 0.587 [0.500, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.351, 10.189], loss: 0.001484, mae: 0.042178, mean_q: 1.167189
 232900/1000000: episode: 2329, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.963, mean reward: 0.590 [0.510, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.181, 10.098], loss: 0.001567, mae: 0.043136, mean_q: 1.173831
 233000/1000000: episode: 2330, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 62.971, mean reward: 0.630 [0.501, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.437, 10.098], loss: 0.001435, mae: 0.041782, mean_q: 1.168728
 233100/1000000: episode: 2331, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.064, mean reward: 0.571 [0.500, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.787, 10.098], loss: 0.001478, mae: 0.041894, mean_q: 1.172416
 233200/1000000: episode: 2332, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.617, mean reward: 0.576 [0.498, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.447, 10.231], loss: 0.001563, mae: 0.042892, mean_q: 1.175763
 233300/1000000: episode: 2333, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.736, mean reward: 0.577 [0.504, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.977, 10.196], loss: 0.001456, mae: 0.041901, mean_q: 1.170632
 233400/1000000: episode: 2334, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.193, mean reward: 0.582 [0.509, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.146, 10.136], loss: 0.001570, mae: 0.043394, mean_q: 1.168843
 233500/1000000: episode: 2335, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.770, mean reward: 0.578 [0.510, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.863, 10.209], loss: 0.001389, mae: 0.040820, mean_q: 1.168760
 233600/1000000: episode: 2336, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.041, mean reward: 0.600 [0.514, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.790, 10.098], loss: 0.001489, mae: 0.041893, mean_q: 1.168593
 233700/1000000: episode: 2337, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.399, mean reward: 0.604 [0.517, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.354, 10.143], loss: 0.001596, mae: 0.043626, mean_q: 1.167399
 233800/1000000: episode: 2338, duration: 0.635s, episode steps: 100, steps per second: 158, episode reward: 56.904, mean reward: 0.569 [0.500, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.636, 10.098], loss: 0.001434, mae: 0.042114, mean_q: 1.168889
 233900/1000000: episode: 2339, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.452, mean reward: 0.585 [0.505, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.916, 10.234], loss: 0.001395, mae: 0.041007, mean_q: 1.168094
 234000/1000000: episode: 2340, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.476, mean reward: 0.575 [0.505, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.606, 10.313], loss: 0.001528, mae: 0.042409, mean_q: 1.166561
 234100/1000000: episode: 2341, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.193, mean reward: 0.592 [0.509, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.633, 10.098], loss: 0.001380, mae: 0.040288, mean_q: 1.165559
 234200/1000000: episode: 2342, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.723, mean reward: 0.587 [0.511, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.629, 10.154], loss: 0.001435, mae: 0.041765, mean_q: 1.167256
 234300/1000000: episode: 2343, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.877, mean reward: 0.589 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.664, 10.098], loss: 0.001459, mae: 0.042554, mean_q: 1.171332
 234400/1000000: episode: 2344, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 58.572, mean reward: 0.586 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.584, 10.152], loss: 0.001440, mae: 0.041331, mean_q: 1.164435
 234500/1000000: episode: 2345, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 60.363, mean reward: 0.604 [0.507, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.420, 10.162], loss: 0.001443, mae: 0.041398, mean_q: 1.167171
 234600/1000000: episode: 2346, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.159, mean reward: 0.592 [0.505, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.544, 10.167], loss: 0.001511, mae: 0.042517, mean_q: 1.168803
 234700/1000000: episode: 2347, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 60.946, mean reward: 0.609 [0.504, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.811, 10.098], loss: 0.001406, mae: 0.041284, mean_q: 1.168035
 234800/1000000: episode: 2348, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.222, mean reward: 0.592 [0.507, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.798, 10.098], loss: 0.001425, mae: 0.041540, mean_q: 1.167637
 234900/1000000: episode: 2349, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 56.882, mean reward: 0.569 [0.504, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.418, 10.205], loss: 0.001401, mae: 0.041268, mean_q: 1.169481
 235000/1000000: episode: 2350, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.713, mean reward: 0.577 [0.507, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.749, 10.098], loss: 0.001459, mae: 0.042118, mean_q: 1.165987
 235100/1000000: episode: 2351, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.724, mean reward: 0.607 [0.511, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.818, 10.203], loss: 0.001442, mae: 0.041515, mean_q: 1.168749
 235200/1000000: episode: 2352, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.495, mean reward: 0.585 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.523, 10.098], loss: 0.001415, mae: 0.040987, mean_q: 1.163307
 235300/1000000: episode: 2353, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.950, mean reward: 0.599 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.449, 10.098], loss: 0.001375, mae: 0.040644, mean_q: 1.163590
 235400/1000000: episode: 2354, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.700, mean reward: 0.587 [0.502, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.158, 10.328], loss: 0.001369, mae: 0.040659, mean_q: 1.165969
 235500/1000000: episode: 2355, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.739, mean reward: 0.567 [0.500, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.311, 10.122], loss: 0.001311, mae: 0.039504, mean_q: 1.166996
 235600/1000000: episode: 2356, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.968, mean reward: 0.610 [0.523, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.496, 10.269], loss: 0.001400, mae: 0.041174, mean_q: 1.170075
 235700/1000000: episode: 2357, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.597, mean reward: 0.576 [0.504, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.186, 10.098], loss: 0.001305, mae: 0.039304, mean_q: 1.163509
 235800/1000000: episode: 2358, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 62.221, mean reward: 0.622 [0.504, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.771, 10.209], loss: 0.001514, mae: 0.042214, mean_q: 1.170274
 235900/1000000: episode: 2359, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.117, mean reward: 0.591 [0.504, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.875, 10.098], loss: 0.001537, mae: 0.042498, mean_q: 1.170659
 236000/1000000: episode: 2360, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.190, mean reward: 0.582 [0.508, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.560, 10.098], loss: 0.001471, mae: 0.042417, mean_q: 1.164325
 236100/1000000: episode: 2361, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 62.312, mean reward: 0.623 [0.508, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.476, 10.382], loss: 0.001353, mae: 0.040676, mean_q: 1.167327
 236200/1000000: episode: 2362, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.018, mean reward: 0.580 [0.508, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.752, 10.098], loss: 0.001371, mae: 0.040484, mean_q: 1.165905
 236300/1000000: episode: 2363, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.361, mean reward: 0.614 [0.521, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.160, 10.360], loss: 0.001411, mae: 0.040953, mean_q: 1.164102
 236400/1000000: episode: 2364, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.295, mean reward: 0.583 [0.505, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.635, 10.098], loss: 0.001370, mae: 0.040223, mean_q: 1.167081
 236500/1000000: episode: 2365, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.374, mean reward: 0.574 [0.506, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.757, 10.157], loss: 0.001510, mae: 0.041866, mean_q: 1.168170
 236600/1000000: episode: 2366, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.499, mean reward: 0.615 [0.507, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.269, 10.392], loss: 0.001330, mae: 0.039780, mean_q: 1.165623
 236700/1000000: episode: 2367, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.036, mean reward: 0.570 [0.506, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.396, 10.098], loss: 0.001404, mae: 0.040719, mean_q: 1.163478
 236800/1000000: episode: 2368, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.515, mean reward: 0.595 [0.503, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.957, 10.229], loss: 0.001402, mae: 0.040735, mean_q: 1.166631
 236900/1000000: episode: 2369, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.918, mean reward: 0.599 [0.500, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.446, 10.429], loss: 0.001244, mae: 0.038832, mean_q: 1.165002
 237000/1000000: episode: 2370, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.033, mean reward: 0.580 [0.505, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.635, 10.098], loss: 0.001338, mae: 0.039639, mean_q: 1.166728
 237100/1000000: episode: 2371, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.964, mean reward: 0.580 [0.500, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.672, 10.098], loss: 0.001364, mae: 0.040207, mean_q: 1.164415
 237200/1000000: episode: 2372, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.406, mean reward: 0.594 [0.503, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.234, 10.258], loss: 0.001339, mae: 0.039662, mean_q: 1.165625
 237300/1000000: episode: 2373, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.938, mean reward: 0.589 [0.510, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.473, 10.436], loss: 0.001322, mae: 0.039663, mean_q: 1.163079
 237400/1000000: episode: 2374, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.161, mean reward: 0.572 [0.506, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.636, 10.098], loss: 0.001330, mae: 0.040036, mean_q: 1.168813
 237500/1000000: episode: 2375, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.238, mean reward: 0.592 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.471, 10.194], loss: 0.001330, mae: 0.040411, mean_q: 1.168143
 237600/1000000: episode: 2376, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.704, mean reward: 0.597 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.240, 10.361], loss: 0.001333, mae: 0.039730, mean_q: 1.167985
 237700/1000000: episode: 2377, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.099, mean reward: 0.601 [0.505, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.884, 10.098], loss: 0.001360, mae: 0.039989, mean_q: 1.167210
 237800/1000000: episode: 2378, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.312, mean reward: 0.573 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.243, 10.187], loss: 0.001368, mae: 0.040272, mean_q: 1.167454
 237900/1000000: episode: 2379, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.663, mean reward: 0.577 [0.513, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.605, 10.171], loss: 0.001278, mae: 0.039047, mean_q: 1.166997
 238000/1000000: episode: 2380, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.882, mean reward: 0.619 [0.507, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.689, 10.098], loss: 0.001342, mae: 0.040037, mean_q: 1.164791
 238100/1000000: episode: 2381, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.412, mean reward: 0.584 [0.500, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.676, 10.127], loss: 0.001361, mae: 0.039487, mean_q: 1.167768
 238200/1000000: episode: 2382, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.113, mean reward: 0.571 [0.506, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.895, 10.138], loss: 0.001313, mae: 0.039558, mean_q: 1.166870
 238300/1000000: episode: 2383, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.345, mean reward: 0.583 [0.505, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.720, 10.098], loss: 0.001343, mae: 0.039895, mean_q: 1.168599
 238400/1000000: episode: 2384, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.796, mean reward: 0.608 [0.523, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.758, 10.098], loss: 0.001330, mae: 0.039825, mean_q: 1.168005
 238500/1000000: episode: 2385, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.261, mean reward: 0.593 [0.500, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.849, 10.098], loss: 0.001437, mae: 0.041143, mean_q: 1.167462
 238600/1000000: episode: 2386, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.680, mean reward: 0.587 [0.507, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.380, 10.153], loss: 0.001337, mae: 0.039576, mean_q: 1.168509
 238700/1000000: episode: 2387, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.699, mean reward: 0.587 [0.512, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.868, 10.179], loss: 0.001408, mae: 0.040468, mean_q: 1.168246
 238800/1000000: episode: 2388, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.502, mean reward: 0.565 [0.498, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.143, 10.253], loss: 0.001337, mae: 0.039610, mean_q: 1.168778
 238900/1000000: episode: 2389, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.185, mean reward: 0.592 [0.503, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.056, 10.108], loss: 0.001297, mae: 0.039254, mean_q: 1.166876
 239000/1000000: episode: 2390, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.100, mean reward: 0.581 [0.515, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.317, 10.098], loss: 0.001361, mae: 0.040392, mean_q: 1.168599
 239100/1000000: episode: 2391, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.970, mean reward: 0.580 [0.508, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.289, 10.304], loss: 0.001353, mae: 0.040063, mean_q: 1.165311
 239200/1000000: episode: 2392, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.349, mean reward: 0.583 [0.503, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.203, 10.127], loss: 0.001451, mae: 0.041422, mean_q: 1.167366
 239300/1000000: episode: 2393, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.435, mean reward: 0.594 [0.503, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.360, 10.142], loss: 0.001446, mae: 0.040801, mean_q: 1.170289
 239400/1000000: episode: 2394, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.021, mean reward: 0.590 [0.509, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.682, 10.218], loss: 0.001358, mae: 0.040471, mean_q: 1.168201
 239500/1000000: episode: 2395, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.173, mean reward: 0.582 [0.502, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.511, 10.172], loss: 0.001268, mae: 0.038719, mean_q: 1.165039
 239600/1000000: episode: 2396, duration: 0.525s, episode steps: 100, steps per second: 191, episode reward: 60.387, mean reward: 0.604 [0.504, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.502, 10.098], loss: 0.001366, mae: 0.040222, mean_q: 1.168510
 239700/1000000: episode: 2397, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.880, mean reward: 0.579 [0.498, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.355, 10.098], loss: 0.001288, mae: 0.039070, mean_q: 1.165773
 239800/1000000: episode: 2398, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 61.711, mean reward: 0.617 [0.505, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.413, 10.098], loss: 0.001324, mae: 0.039468, mean_q: 1.163376
 239900/1000000: episode: 2399, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.078, mean reward: 0.591 [0.508, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.486, 10.243], loss: 0.001317, mae: 0.039256, mean_q: 1.162642
 240000/1000000: episode: 2400, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 62.787, mean reward: 0.628 [0.502, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.212, 10.368], loss: 0.001431, mae: 0.041112, mean_q: 1.167142
 240100/1000000: episode: 2401, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.016, mean reward: 0.580 [0.507, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.358, 10.241], loss: 0.001365, mae: 0.040064, mean_q: 1.165822
 240200/1000000: episode: 2402, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.120, mean reward: 0.601 [0.507, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.519, 10.112], loss: 0.001379, mae: 0.040418, mean_q: 1.168174
 240300/1000000: episode: 2403, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.120, mean reward: 0.601 [0.508, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.418, 10.098], loss: 0.001428, mae: 0.041081, mean_q: 1.168695
 240400/1000000: episode: 2404, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 63.836, mean reward: 0.638 [0.507, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.331, 10.098], loss: 0.001400, mae: 0.040940, mean_q: 1.169372
 240500/1000000: episode: 2405, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.278, mean reward: 0.573 [0.499, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.516, 10.182], loss: 0.001420, mae: 0.040385, mean_q: 1.171692
 240600/1000000: episode: 2406, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.286, mean reward: 0.573 [0.500, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.637, 10.098], loss: 0.001383, mae: 0.040483, mean_q: 1.169924
 240700/1000000: episode: 2407, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.323, mean reward: 0.583 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.779, 10.098], loss: 0.001404, mae: 0.041178, mean_q: 1.169702
 240800/1000000: episode: 2408, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.027, mean reward: 0.580 [0.506, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.397, 10.098], loss: 0.001487, mae: 0.041257, mean_q: 1.166105
 240900/1000000: episode: 2409, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.017, mean reward: 0.570 [0.498, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.093, 10.215], loss: 0.001429, mae: 0.041632, mean_q: 1.166331
 241000/1000000: episode: 2410, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.530, mean reward: 0.595 [0.509, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.499, 10.133], loss: 0.001368, mae: 0.039730, mean_q: 1.165178
 241100/1000000: episode: 2411, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 64.269, mean reward: 0.643 [0.504, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.899, 10.128], loss: 0.001379, mae: 0.040000, mean_q: 1.164893
 241200/1000000: episode: 2412, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.173, mean reward: 0.602 [0.504, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.847, 10.296], loss: 0.001394, mae: 0.040410, mean_q: 1.166456
 241300/1000000: episode: 2413, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.310, mean reward: 0.583 [0.504, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.123, 10.098], loss: 0.001418, mae: 0.041018, mean_q: 1.170305
 241400/1000000: episode: 2414, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.252, mean reward: 0.603 [0.501, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.571, 10.397], loss: 0.001433, mae: 0.041135, mean_q: 1.168956
 241500/1000000: episode: 2415, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.620, mean reward: 0.586 [0.506, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.413, 10.169], loss: 0.001442, mae: 0.041617, mean_q: 1.168776
 241600/1000000: episode: 2416, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.097, mean reward: 0.591 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.891, 10.308], loss: 0.001392, mae: 0.040997, mean_q: 1.169887
 241700/1000000: episode: 2417, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.594, mean reward: 0.586 [0.503, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.624, 10.170], loss: 0.001488, mae: 0.042463, mean_q: 1.168079
 241800/1000000: episode: 2418, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.421, mean reward: 0.594 [0.506, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.874, 10.237], loss: 0.001390, mae: 0.040643, mean_q: 1.165207
 241900/1000000: episode: 2419, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 65.512, mean reward: 0.655 [0.508, 0.940], mean action: 0.000 [0.000, 0.000], mean observation: 1.413 [-0.836, 10.098], loss: 0.001500, mae: 0.042190, mean_q: 1.167827
 242000/1000000: episode: 2420, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.191, mean reward: 0.582 [0.498, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.677, 10.394], loss: 0.001360, mae: 0.040294, mean_q: 1.173230
 242100/1000000: episode: 2421, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.142, mean reward: 0.581 [0.502, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.698, 10.169], loss: 0.001482, mae: 0.041965, mean_q: 1.174638
 242200/1000000: episode: 2422, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 59.050, mean reward: 0.590 [0.503, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.584, 10.308], loss: 0.001379, mae: 0.040390, mean_q: 1.168826
 242300/1000000: episode: 2423, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.686, mean reward: 0.597 [0.499, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.675, 10.098], loss: 0.001403, mae: 0.041181, mean_q: 1.170396
 242400/1000000: episode: 2424, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.158, mean reward: 0.592 [0.509, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.779, 10.165], loss: 0.001510, mae: 0.042517, mean_q: 1.172669
 242500/1000000: episode: 2425, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.660, mean reward: 0.587 [0.502, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.510, 10.098], loss: 0.001419, mae: 0.041566, mean_q: 1.174208
 242600/1000000: episode: 2426, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.399, mean reward: 0.584 [0.507, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.531, 10.098], loss: 0.001454, mae: 0.041905, mean_q: 1.170903
 242700/1000000: episode: 2427, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.712, mean reward: 0.597 [0.500, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.411, 10.346], loss: 0.001418, mae: 0.040993, mean_q: 1.174300
 242800/1000000: episode: 2428, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.383, mean reward: 0.584 [0.508, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.386, 10.280], loss: 0.001384, mae: 0.040618, mean_q: 1.172865
 242900/1000000: episode: 2429, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.094, mean reward: 0.581 [0.501, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.771, 10.098], loss: 0.001538, mae: 0.043030, mean_q: 1.176206
 243000/1000000: episode: 2430, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.776, mean reward: 0.618 [0.516, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.051, 10.200], loss: 0.001425, mae: 0.041428, mean_q: 1.173972
 243100/1000000: episode: 2431, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 61.776, mean reward: 0.618 [0.510, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.764, 10.168], loss: 0.001455, mae: 0.041403, mean_q: 1.174332
 243200/1000000: episode: 2432, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 61.334, mean reward: 0.613 [0.497, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.917, 10.098], loss: 0.001433, mae: 0.041137, mean_q: 1.177853
 243300/1000000: episode: 2433, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.809, mean reward: 0.598 [0.502, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.109, 10.120], loss: 0.001389, mae: 0.040945, mean_q: 1.180140
 243400/1000000: episode: 2434, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.215, mean reward: 0.592 [0.511, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.877, 10.344], loss: 0.001419, mae: 0.040684, mean_q: 1.174599
 243500/1000000: episode: 2435, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.555, mean reward: 0.596 [0.499, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.954, 10.098], loss: 0.001384, mae: 0.040738, mean_q: 1.174735
 243600/1000000: episode: 2436, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.707, mean reward: 0.567 [0.504, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.662, 10.098], loss: 0.001402, mae: 0.040905, mean_q: 1.173539
 243700/1000000: episode: 2437, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.702, mean reward: 0.587 [0.502, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.559, 10.098], loss: 0.001455, mae: 0.041643, mean_q: 1.175761
 243800/1000000: episode: 2438, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.390, mean reward: 0.584 [0.511, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.602, 10.098], loss: 0.001593, mae: 0.044068, mean_q: 1.175417
 243900/1000000: episode: 2439, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.934, mean reward: 0.599 [0.501, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.495, 10.296], loss: 0.001433, mae: 0.041112, mean_q: 1.172870
 244000/1000000: episode: 2440, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 63.668, mean reward: 0.637 [0.500, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.148, 10.098], loss: 0.001397, mae: 0.040912, mean_q: 1.176594
 244100/1000000: episode: 2441, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.048, mean reward: 0.600 [0.515, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.448, 10.202], loss: 0.001469, mae: 0.041321, mean_q: 1.177615
 244200/1000000: episode: 2442, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.300, mean reward: 0.593 [0.521, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.583, 10.098], loss: 0.001479, mae: 0.041659, mean_q: 1.177598
 244300/1000000: episode: 2443, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.629, mean reward: 0.606 [0.504, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.589, 10.329], loss: 0.001470, mae: 0.041336, mean_q: 1.180772
 244400/1000000: episode: 2444, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.553, mean reward: 0.576 [0.502, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.857, 10.098], loss: 0.001395, mae: 0.040603, mean_q: 1.179732
 244500/1000000: episode: 2445, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 59.147, mean reward: 0.591 [0.502, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.376, 10.098], loss: 0.001474, mae: 0.041454, mean_q: 1.179931
 244600/1000000: episode: 2446, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 62.892, mean reward: 0.629 [0.500, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.261, 10.098], loss: 0.001442, mae: 0.041667, mean_q: 1.182122
 244700/1000000: episode: 2447, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.911, mean reward: 0.589 [0.505, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.174, 10.234], loss: 0.001430, mae: 0.041516, mean_q: 1.182024
 244800/1000000: episode: 2448, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.965, mean reward: 0.590 [0.501, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.553, 10.098], loss: 0.001443, mae: 0.041284, mean_q: 1.183908
 244900/1000000: episode: 2449, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.953, mean reward: 0.590 [0.501, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.761, 10.260], loss: 0.001467, mae: 0.042067, mean_q: 1.181714
 245000/1000000: episode: 2450, duration: 0.525s, episode steps: 100, steps per second: 191, episode reward: 59.976, mean reward: 0.600 [0.509, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.940, 10.098], loss: 0.001461, mae: 0.041476, mean_q: 1.175330
 245100/1000000: episode: 2451, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.811, mean reward: 0.598 [0.516, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.331, 10.098], loss: 0.001331, mae: 0.040156, mean_q: 1.178347
 245200/1000000: episode: 2452, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.555, mean reward: 0.596 [0.506, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.691, 10.249], loss: 0.001413, mae: 0.041804, mean_q: 1.177242
 245300/1000000: episode: 2453, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 56.882, mean reward: 0.569 [0.505, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.377, 10.132], loss: 0.001478, mae: 0.042111, mean_q: 1.181328
 245400/1000000: episode: 2454, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 66.427, mean reward: 0.664 [0.504, 0.886], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.851, 10.269], loss: 0.001476, mae: 0.041946, mean_q: 1.178466
 245500/1000000: episode: 2455, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.819, mean reward: 0.578 [0.500, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.524, 10.098], loss: 0.001449, mae: 0.042214, mean_q: 1.180682
 245600/1000000: episode: 2456, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 63.187, mean reward: 0.632 [0.501, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.281, 10.098], loss: 0.001404, mae: 0.040821, mean_q: 1.180068
 245700/1000000: episode: 2457, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.222, mean reward: 0.572 [0.499, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-2.005, 10.098], loss: 0.001399, mae: 0.041170, mean_q: 1.183649
 245800/1000000: episode: 2458, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.168, mean reward: 0.592 [0.502, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.949, 10.146], loss: 0.001382, mae: 0.040580, mean_q: 1.178374
 245900/1000000: episode: 2459, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.471, mean reward: 0.575 [0.504, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.067, 10.204], loss: 0.001522, mae: 0.043102, mean_q: 1.183880
 246000/1000000: episode: 2460, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.841, mean reward: 0.588 [0.504, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.693, 10.223], loss: 0.001342, mae: 0.040284, mean_q: 1.178257
 246100/1000000: episode: 2461, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.341, mean reward: 0.583 [0.501, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.308, 10.098], loss: 0.001434, mae: 0.041761, mean_q: 1.178272
 246200/1000000: episode: 2462, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.165, mean reward: 0.572 [0.499, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.640, 10.098], loss: 0.001414, mae: 0.041327, mean_q: 1.180500
 246300/1000000: episode: 2463, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.363, mean reward: 0.574 [0.505, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.096, 10.098], loss: 0.001418, mae: 0.041415, mean_q: 1.175490
 246400/1000000: episode: 2464, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 60.261, mean reward: 0.603 [0.520, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.086, 10.209], loss: 0.001372, mae: 0.041418, mean_q: 1.175684
 246500/1000000: episode: 2465, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.207, mean reward: 0.572 [0.503, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.807, 10.098], loss: 0.001442, mae: 0.041969, mean_q: 1.181853
 246600/1000000: episode: 2466, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 57.809, mean reward: 0.578 [0.509, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.669, 10.106], loss: 0.001407, mae: 0.041161, mean_q: 1.178539
 246700/1000000: episode: 2467, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.040, mean reward: 0.590 [0.510, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.509, 10.319], loss: 0.001462, mae: 0.042267, mean_q: 1.175233
 246800/1000000: episode: 2468, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.796, mean reward: 0.578 [0.501, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.786, 10.172], loss: 0.001422, mae: 0.041668, mean_q: 1.176119
 246900/1000000: episode: 2469, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 58.160, mean reward: 0.582 [0.508, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.039, 10.284], loss: 0.001411, mae: 0.041205, mean_q: 1.172466
 247000/1000000: episode: 2470, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 56.896, mean reward: 0.569 [0.506, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.151, 10.190], loss: 0.001515, mae: 0.043114, mean_q: 1.173038
 247100/1000000: episode: 2471, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.070, mean reward: 0.601 [0.500, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.959, 10.098], loss: 0.001342, mae: 0.040318, mean_q: 1.170542
 247200/1000000: episode: 2472, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.251, mean reward: 0.603 [0.499, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.516, 10.098], loss: 0.001439, mae: 0.042052, mean_q: 1.174219
 247300/1000000: episode: 2473, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.652, mean reward: 0.587 [0.512, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.658, 10.122], loss: 0.001421, mae: 0.041673, mean_q: 1.171589
 247400/1000000: episode: 2474, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.211, mean reward: 0.602 [0.511, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.854, 10.098], loss: 0.001312, mae: 0.040191, mean_q: 1.174279
 247500/1000000: episode: 2475, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.183, mean reward: 0.592 [0.504, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.749, 10.185], loss: 0.001480, mae: 0.042180, mean_q: 1.172069
 247600/1000000: episode: 2476, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.323, mean reward: 0.583 [0.516, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.981, 10.098], loss: 0.001416, mae: 0.041457, mean_q: 1.173615
 247700/1000000: episode: 2477, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.012, mean reward: 0.610 [0.522, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.093, 10.098], loss: 0.001321, mae: 0.040365, mean_q: 1.171047
 247800/1000000: episode: 2478, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 56.878, mean reward: 0.569 [0.507, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.661, 10.098], loss: 0.001401, mae: 0.040686, mean_q: 1.179274
 247900/1000000: episode: 2479, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.092, mean reward: 0.581 [0.502, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.666, 10.126], loss: 0.001408, mae: 0.041499, mean_q: 1.177137
 248000/1000000: episode: 2480, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.544, mean reward: 0.605 [0.507, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.122, 10.234], loss: 0.001538, mae: 0.043234, mean_q: 1.170243
 248100/1000000: episode: 2481, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.004, mean reward: 0.560 [0.502, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.065, 10.273], loss: 0.001383, mae: 0.041214, mean_q: 1.173398
 248200/1000000: episode: 2482, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.715, mean reward: 0.577 [0.506, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.175, 10.171], loss: 0.001427, mae: 0.041296, mean_q: 1.169969
 248300/1000000: episode: 2483, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.276, mean reward: 0.603 [0.507, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.931, 10.426], loss: 0.001445, mae: 0.041872, mean_q: 1.170681
 248400/1000000: episode: 2484, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.737, mean reward: 0.587 [0.504, 0.871], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.100, 10.168], loss: 0.001329, mae: 0.039632, mean_q: 1.166942
 248500/1000000: episode: 2485, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 59.143, mean reward: 0.591 [0.502, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.407, 10.098], loss: 0.001414, mae: 0.041548, mean_q: 1.166893
 248600/1000000: episode: 2486, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.542, mean reward: 0.565 [0.503, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.916, 10.098], loss: 0.001376, mae: 0.040861, mean_q: 1.167452
 248700/1000000: episode: 2487, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.973, mean reward: 0.590 [0.502, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.275, 10.098], loss: 0.001403, mae: 0.041179, mean_q: 1.166432
 248800/1000000: episode: 2488, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.870, mean reward: 0.589 [0.511, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.660, 10.262], loss: 0.001387, mae: 0.040771, mean_q: 1.169199
 248900/1000000: episode: 2489, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.906, mean reward: 0.599 [0.508, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.955, 10.098], loss: 0.001397, mae: 0.041049, mean_q: 1.170351
 249000/1000000: episode: 2490, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.797, mean reward: 0.578 [0.498, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.521, 10.098], loss: 0.001386, mae: 0.041006, mean_q: 1.167627
 249100/1000000: episode: 2491, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.300, mean reward: 0.603 [0.511, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.990, 10.098], loss: 0.001430, mae: 0.041342, mean_q: 1.168950
 249200/1000000: episode: 2492, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.185, mean reward: 0.602 [0.508, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.517, 10.098], loss: 0.001323, mae: 0.039798, mean_q: 1.163405
 249300/1000000: episode: 2493, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.287, mean reward: 0.593 [0.507, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.195, 10.098], loss: 0.001409, mae: 0.041054, mean_q: 1.163828
 249400/1000000: episode: 2494, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 62.249, mean reward: 0.622 [0.501, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.997, 10.516], loss: 0.001461, mae: 0.041430, mean_q: 1.169314
 249500/1000000: episode: 2495, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.814, mean reward: 0.578 [0.513, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.036, 10.288], loss: 0.001454, mae: 0.041999, mean_q: 1.172458
 249600/1000000: episode: 2496, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.188, mean reward: 0.572 [0.508, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.290, 10.150], loss: 0.001405, mae: 0.040357, mean_q: 1.165956
 249700/1000000: episode: 2497, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.291, mean reward: 0.573 [0.505, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.635, 10.289], loss: 0.001407, mae: 0.040324, mean_q: 1.164469
 249800/1000000: episode: 2498, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.795, mean reward: 0.598 [0.504, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.788, 10.256], loss: 0.001474, mae: 0.041425, mean_q: 1.165476
 249900/1000000: episode: 2499, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.206, mean reward: 0.612 [0.505, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.185, 10.098], loss: 0.001374, mae: 0.040736, mean_q: 1.163007
 250000/1000000: episode: 2500, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.461, mean reward: 0.605 [0.516, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.376, 10.183], loss: 0.001314, mae: 0.039327, mean_q: 1.163090
 250100/1000000: episode: 2501, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 56.522, mean reward: 0.565 [0.507, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.902, 10.219], loss: 0.001444, mae: 0.041254, mean_q: 1.166838
 250200/1000000: episode: 2502, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.880, mean reward: 0.589 [0.509, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.127, 10.098], loss: 0.001202, mae: 0.037867, mean_q: 1.161654
 250300/1000000: episode: 2503, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.757, mean reward: 0.578 [0.508, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.161, 10.098], loss: 0.001360, mae: 0.040193, mean_q: 1.165436
 250400/1000000: episode: 2504, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.543, mean reward: 0.615 [0.509, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.849, 10.252], loss: 0.001404, mae: 0.041134, mean_q: 1.162889
 250500/1000000: episode: 2505, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.941, mean reward: 0.609 [0.514, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.335, 10.098], loss: 0.001364, mae: 0.040522, mean_q: 1.165337
 250600/1000000: episode: 2506, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.508, mean reward: 0.585 [0.499, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.042, 10.139], loss: 0.001451, mae: 0.041241, mean_q: 1.162301
 250700/1000000: episode: 2507, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: 59.618, mean reward: 0.596 [0.508, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.460, 10.174], loss: 0.001398, mae: 0.041173, mean_q: 1.166525
 250800/1000000: episode: 2508, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.939, mean reward: 0.579 [0.507, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.114, 10.264], loss: 0.001370, mae: 0.040029, mean_q: 1.164380
 250900/1000000: episode: 2509, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.155, mean reward: 0.582 [0.506, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.925, 10.098], loss: 0.001371, mae: 0.040124, mean_q: 1.160599
 251000/1000000: episode: 2510, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.016, mean reward: 0.600 [0.502, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.681, 10.182], loss: 0.001375, mae: 0.040841, mean_q: 1.167584
 251100/1000000: episode: 2511, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.995, mean reward: 0.580 [0.505, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.952, 10.130], loss: 0.001278, mae: 0.039426, mean_q: 1.163513
 251200/1000000: episode: 2512, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 66.175, mean reward: 0.662 [0.524, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.743, 10.398], loss: 0.001320, mae: 0.039532, mean_q: 1.162809
 251300/1000000: episode: 2513, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.124, mean reward: 0.581 [0.500, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.376, 10.330], loss: 0.001477, mae: 0.041644, mean_q: 1.171483
 251400/1000000: episode: 2514, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.348, mean reward: 0.593 [0.512, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.969, 10.098], loss: 0.001374, mae: 0.040302, mean_q: 1.167140
 251500/1000000: episode: 2515, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.582, mean reward: 0.586 [0.513, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.820, 10.098], loss: 0.001419, mae: 0.041118, mean_q: 1.169364
 251600/1000000: episode: 2516, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.367, mean reward: 0.584 [0.500, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-2.537, 10.267], loss: 0.001451, mae: 0.041393, mean_q: 1.168736
 251700/1000000: episode: 2517, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.580, mean reward: 0.576 [0.503, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.317, 10.098], loss: 0.001346, mae: 0.040061, mean_q: 1.164560
 251800/1000000: episode: 2518, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.287, mean reward: 0.603 [0.499, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.507, 10.103], loss: 0.001331, mae: 0.039633, mean_q: 1.165823
 251900/1000000: episode: 2519, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.840, mean reward: 0.568 [0.498, 0.657], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.786, 10.292], loss: 0.001417, mae: 0.040234, mean_q: 1.164382
 252000/1000000: episode: 2520, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.391, mean reward: 0.604 [0.507, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.409, 10.131], loss: 0.001355, mae: 0.039802, mean_q: 1.167889
 252100/1000000: episode: 2521, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.382, mean reward: 0.594 [0.508, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.152, 10.203], loss: 0.001429, mae: 0.041147, mean_q: 1.168970
 252200/1000000: episode: 2522, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.324, mean reward: 0.593 [0.511, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.107, 10.301], loss: 0.001384, mae: 0.040203, mean_q: 1.165253
 252300/1000000: episode: 2523, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.594, mean reward: 0.586 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.017, 10.098], loss: 0.001391, mae: 0.040782, mean_q: 1.169848
 252400/1000000: episode: 2524, duration: 0.533s, episode steps: 100, steps per second: 187, episode reward: 63.322, mean reward: 0.633 [0.509, 0.862], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.904, 10.098], loss: 0.001432, mae: 0.041039, mean_q: 1.170152
 252500/1000000: episode: 2525, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.090, mean reward: 0.581 [0.505, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.408, 10.098], loss: 0.001298, mae: 0.038950, mean_q: 1.169714
 252600/1000000: episode: 2526, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.601, mean reward: 0.586 [0.504, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.725, 10.303], loss: 0.001485, mae: 0.041725, mean_q: 1.170600
 252700/1000000: episode: 2527, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.742, mean reward: 0.577 [0.505, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.917, 10.253], loss: 0.001321, mae: 0.039731, mean_q: 1.168156
 252800/1000000: episode: 2528, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.682, mean reward: 0.587 [0.504, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.972, 10.240], loss: 0.001417, mae: 0.040479, mean_q: 1.165578
 252900/1000000: episode: 2529, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.876, mean reward: 0.589 [0.509, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.632, 10.098], loss: 0.001431, mae: 0.041535, mean_q: 1.171093
 253000/1000000: episode: 2530, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.623, mean reward: 0.596 [0.505, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.721, 10.098], loss: 0.001404, mae: 0.040667, mean_q: 1.168850
 253100/1000000: episode: 2531, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 62.155, mean reward: 0.622 [0.519, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.520, 10.139], loss: 0.001359, mae: 0.040221, mean_q: 1.170221
 253200/1000000: episode: 2532, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.347, mean reward: 0.573 [0.502, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.189, 10.114], loss: 0.001502, mae: 0.042374, mean_q: 1.171224
 253300/1000000: episode: 2533, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.721, mean reward: 0.577 [0.506, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.083, 10.098], loss: 0.001430, mae: 0.041591, mean_q: 1.171630
 253400/1000000: episode: 2534, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.485, mean reward: 0.585 [0.505, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.351, 10.264], loss: 0.001430, mae: 0.041325, mean_q: 1.173646
 253500/1000000: episode: 2535, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.357, mean reward: 0.584 [0.510, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.433, 10.098], loss: 0.001412, mae: 0.041047, mean_q: 1.170653
 253600/1000000: episode: 2536, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 60.917, mean reward: 0.609 [0.502, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.167, 10.098], loss: 0.001376, mae: 0.040228, mean_q: 1.169948
 253700/1000000: episode: 2537, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.020, mean reward: 0.590 [0.507, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.301, 10.230], loss: 0.001386, mae: 0.040209, mean_q: 1.167755
 253800/1000000: episode: 2538, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.179, mean reward: 0.572 [0.509, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.099, 10.253], loss: 0.001498, mae: 0.042204, mean_q: 1.171753
 253900/1000000: episode: 2539, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.373, mean reward: 0.594 [0.512, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.224, 10.098], loss: 0.001472, mae: 0.042116, mean_q: 1.166887
 254000/1000000: episode: 2540, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.942, mean reward: 0.589 [0.504, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.088, 10.098], loss: 0.001409, mae: 0.041228, mean_q: 1.168964
 254100/1000000: episode: 2541, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.376, mean reward: 0.594 [0.506, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.343, 10.098], loss: 0.001378, mae: 0.040745, mean_q: 1.169129
 254200/1000000: episode: 2542, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 63.503, mean reward: 0.635 [0.515, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.593, 10.098], loss: 0.001467, mae: 0.041854, mean_q: 1.168513
 254300/1000000: episode: 2543, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 62.909, mean reward: 0.629 [0.519, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.631, 10.098], loss: 0.001386, mae: 0.041007, mean_q: 1.172757
 254400/1000000: episode: 2544, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.506, mean reward: 0.585 [0.510, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.274, 10.320], loss: 0.001422, mae: 0.041363, mean_q: 1.170073
 254500/1000000: episode: 2545, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.234, mean reward: 0.582 [0.498, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.996, 10.335], loss: 0.001419, mae: 0.041579, mean_q: 1.174944
 254600/1000000: episode: 2546, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 56.761, mean reward: 0.568 [0.501, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.574, 10.212], loss: 0.001459, mae: 0.042161, mean_q: 1.173927
 254700/1000000: episode: 2547, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.022, mean reward: 0.590 [0.507, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.778, 10.098], loss: 0.001306, mae: 0.039801, mean_q: 1.170633
 254800/1000000: episode: 2548, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.806, mean reward: 0.588 [0.500, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.380, 10.098], loss: 0.001357, mae: 0.040320, mean_q: 1.175157
 254900/1000000: episode: 2549, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.220, mean reward: 0.582 [0.503, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.758, 10.252], loss: 0.001408, mae: 0.041063, mean_q: 1.171352
 255000/1000000: episode: 2550, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.029, mean reward: 0.570 [0.500, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.687, 10.098], loss: 0.001546, mae: 0.042786, mean_q: 1.170513
 255100/1000000: episode: 2551, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.555, mean reward: 0.596 [0.502, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-2.210, 10.160], loss: 0.001465, mae: 0.041781, mean_q: 1.172447
 255200/1000000: episode: 2552, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.704, mean reward: 0.597 [0.515, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.808, 10.098], loss: 0.001459, mae: 0.041665, mean_q: 1.169311
 255300/1000000: episode: 2553, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.798, mean reward: 0.598 [0.515, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.983, 10.183], loss: 0.001460, mae: 0.041826, mean_q: 1.169878
 255400/1000000: episode: 2554, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.614, mean reward: 0.596 [0.505, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.814, 10.336], loss: 0.001336, mae: 0.040152, mean_q: 1.171781
 255500/1000000: episode: 2555, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.615, mean reward: 0.586 [0.509, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.378, 10.287], loss: 0.001428, mae: 0.041179, mean_q: 1.173904
 255600/1000000: episode: 2556, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.377, mean reward: 0.564 [0.500, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.078, 10.098], loss: 0.001402, mae: 0.040636, mean_q: 1.170610
 255700/1000000: episode: 2557, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.250, mean reward: 0.583 [0.504, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.242, 10.134], loss: 0.001362, mae: 0.040693, mean_q: 1.170777
 255800/1000000: episode: 2558, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.859, mean reward: 0.609 [0.530, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.393, 10.376], loss: 0.001328, mae: 0.039673, mean_q: 1.170245
 255900/1000000: episode: 2559, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.457, mean reward: 0.585 [0.504, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.555, 10.426], loss: 0.001420, mae: 0.041239, mean_q: 1.168927
 256000/1000000: episode: 2560, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.363, mean reward: 0.584 [0.500, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.733, 10.103], loss: 0.001436, mae: 0.041695, mean_q: 1.172458
 256100/1000000: episode: 2561, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.047, mean reward: 0.590 [0.506, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.701, 10.098], loss: 0.001399, mae: 0.040936, mean_q: 1.171291
 256200/1000000: episode: 2562, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.319, mean reward: 0.583 [0.502, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.066, 10.113], loss: 0.001396, mae: 0.040600, mean_q: 1.169255
 256300/1000000: episode: 2563, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.057, mean reward: 0.591 [0.505, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.928, 10.098], loss: 0.001435, mae: 0.041945, mean_q: 1.166286
 256400/1000000: episode: 2564, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.558, mean reward: 0.606 [0.522, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.710, 10.140], loss: 0.001439, mae: 0.041396, mean_q: 1.166997
 256500/1000000: episode: 2565, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.136, mean reward: 0.591 [0.505, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.603, 10.131], loss: 0.001468, mae: 0.041811, mean_q: 1.171543
 256600/1000000: episode: 2566, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.122, mean reward: 0.591 [0.519, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.671, 10.343], loss: 0.001496, mae: 0.042530, mean_q: 1.169981
 256700/1000000: episode: 2567, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 62.001, mean reward: 0.620 [0.498, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.357, 10.098], loss: 0.001486, mae: 0.042539, mean_q: 1.169667
 256800/1000000: episode: 2568, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.559, mean reward: 0.596 [0.521, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.682, 10.296], loss: 0.001456, mae: 0.042273, mean_q: 1.171026
 256900/1000000: episode: 2569, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.888, mean reward: 0.609 [0.504, 0.889], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.039, 10.121], loss: 0.001443, mae: 0.042472, mean_q: 1.171193
 257000/1000000: episode: 2570, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.815, mean reward: 0.588 [0.510, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.497, 10.098], loss: 0.001548, mae: 0.043371, mean_q: 1.176199
 257100/1000000: episode: 2571, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.655, mean reward: 0.577 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.076, 10.167], loss: 0.001487, mae: 0.042425, mean_q: 1.172006
 257200/1000000: episode: 2572, duration: 0.645s, episode steps: 100, steps per second: 155, episode reward: 56.539, mean reward: 0.565 [0.499, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.906, 10.144], loss: 0.001437, mae: 0.041820, mean_q: 1.170072
 257300/1000000: episode: 2573, duration: 0.622s, episode steps: 100, steps per second: 161, episode reward: 62.023, mean reward: 0.620 [0.506, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.477, 10.098], loss: 0.001561, mae: 0.043181, mean_q: 1.171548
 257400/1000000: episode: 2574, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 60.526, mean reward: 0.605 [0.517, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.299, 10.394], loss: 0.001516, mae: 0.042910, mean_q: 1.170241
 257500/1000000: episode: 2575, duration: 0.628s, episode steps: 100, steps per second: 159, episode reward: 59.745, mean reward: 0.597 [0.506, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.805, 10.288], loss: 0.001393, mae: 0.041219, mean_q: 1.168564
 257600/1000000: episode: 2576, duration: 0.643s, episode steps: 100, steps per second: 156, episode reward: 57.845, mean reward: 0.578 [0.502, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.391, 10.216], loss: 0.001466, mae: 0.042045, mean_q: 1.170715
 257700/1000000: episode: 2577, duration: 0.646s, episode steps: 100, steps per second: 155, episode reward: 63.649, mean reward: 0.636 [0.528, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.801, 10.139], loss: 0.001477, mae: 0.042277, mean_q: 1.169714
 257800/1000000: episode: 2578, duration: 0.668s, episode steps: 100, steps per second: 150, episode reward: 59.348, mean reward: 0.593 [0.510, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.825, 10.286], loss: 0.001382, mae: 0.041099, mean_q: 1.175342
 257900/1000000: episode: 2579, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 58.086, mean reward: 0.581 [0.500, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.616, 10.124], loss: 0.001503, mae: 0.043118, mean_q: 1.173022
 258000/1000000: episode: 2580, duration: 0.669s, episode steps: 100, steps per second: 149, episode reward: 58.620, mean reward: 0.586 [0.505, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.034, 10.098], loss: 0.001504, mae: 0.042097, mean_q: 1.171317
 258100/1000000: episode: 2581, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 62.559, mean reward: 0.626 [0.506, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-0.943, 10.098], loss: 0.001455, mae: 0.041682, mean_q: 1.172243
 258200/1000000: episode: 2582, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.926, mean reward: 0.589 [0.507, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-2.081, 10.183], loss: 0.001518, mae: 0.042695, mean_q: 1.174552
 258300/1000000: episode: 2583, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.815, mean reward: 0.588 [0.501, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.894, 10.513], loss: 0.001542, mae: 0.042655, mean_q: 1.171600
 258400/1000000: episode: 2584, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.544, mean reward: 0.595 [0.500, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.516, 10.098], loss: 0.001442, mae: 0.041572, mean_q: 1.172126
 258500/1000000: episode: 2585, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.292, mean reward: 0.583 [0.505, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.765, 10.098], loss: 0.001527, mae: 0.042761, mean_q: 1.175541
 258600/1000000: episode: 2586, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.637, mean reward: 0.566 [0.499, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.799, 10.098], loss: 0.001524, mae: 0.042474, mean_q: 1.171466
 258700/1000000: episode: 2587, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 65.932, mean reward: 0.659 [0.512, 0.881], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.561, 10.416], loss: 0.001530, mae: 0.042837, mean_q: 1.175848
 258800/1000000: episode: 2588, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.508, mean reward: 0.585 [0.500, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.109, 10.098], loss: 0.001618, mae: 0.043352, mean_q: 1.174817
 258900/1000000: episode: 2589, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.331, mean reward: 0.603 [0.512, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.212, 10.279], loss: 0.001605, mae: 0.044087, mean_q: 1.178518
 259000/1000000: episode: 2590, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.927, mean reward: 0.599 [0.499, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.295, 10.319], loss: 0.001577, mae: 0.043177, mean_q: 1.178837
 259100/1000000: episode: 2591, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.277, mean reward: 0.593 [0.512, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.705, 10.250], loss: 0.001539, mae: 0.042678, mean_q: 1.172793
 259200/1000000: episode: 2592, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.370, mean reward: 0.584 [0.499, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.121, 10.257], loss: 0.001650, mae: 0.044158, mean_q: 1.174144
 259300/1000000: episode: 2593, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.012, mean reward: 0.580 [0.498, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.057, 10.292], loss: 0.001619, mae: 0.043608, mean_q: 1.176657
 259400/1000000: episode: 2594, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.808, mean reward: 0.588 [0.501, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.692, 10.098], loss: 0.001613, mae: 0.043641, mean_q: 1.171113
 259500/1000000: episode: 2595, duration: 0.631s, episode steps: 100, steps per second: 159, episode reward: 61.818, mean reward: 0.618 [0.501, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.003, 10.434], loss: 0.001647, mae: 0.044694, mean_q: 1.170767
 259600/1000000: episode: 2596, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.295, mean reward: 0.573 [0.507, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.580, 10.098], loss: 0.001541, mae: 0.042956, mean_q: 1.170389
 259700/1000000: episode: 2597, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.129, mean reward: 0.601 [0.507, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.788, 10.098], loss: 0.001597, mae: 0.043216, mean_q: 1.169897
 259800/1000000: episode: 2598, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.061, mean reward: 0.581 [0.501, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.942, 10.098], loss: 0.001553, mae: 0.042563, mean_q: 1.170913
 259900/1000000: episode: 2599, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.754, mean reward: 0.588 [0.499, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.292, 10.181], loss: 0.001643, mae: 0.044573, mean_q: 1.173764
 260000/1000000: episode: 2600, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.334, mean reward: 0.593 [0.505, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.417, 10.195], loss: 0.001491, mae: 0.041843, mean_q: 1.174254
 260100/1000000: episode: 2601, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.192, mean reward: 0.592 [0.508, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.927, 10.147], loss: 0.001716, mae: 0.045403, mean_q: 1.177184
 260200/1000000: episode: 2602, duration: 0.632s, episode steps: 100, steps per second: 158, episode reward: 59.350, mean reward: 0.594 [0.503, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.735, 10.133], loss: 0.001710, mae: 0.044445, mean_q: 1.175701
 260300/1000000: episode: 2603, duration: 0.656s, episode steps: 100, steps per second: 153, episode reward: 61.773, mean reward: 0.618 [0.502, 0.899], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.060, 10.098], loss: 0.001709, mae: 0.044622, mean_q: 1.178245
 260400/1000000: episode: 2604, duration: 0.654s, episode steps: 100, steps per second: 153, episode reward: 62.500, mean reward: 0.625 [0.510, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.826, 10.098], loss: 0.001685, mae: 0.044813, mean_q: 1.177236
 260500/1000000: episode: 2605, duration: 0.647s, episode steps: 100, steps per second: 154, episode reward: 59.432, mean reward: 0.594 [0.513, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.217, 10.137], loss: 0.001557, mae: 0.043298, mean_q: 1.177691
 260600/1000000: episode: 2606, duration: 0.642s, episode steps: 100, steps per second: 156, episode reward: 57.990, mean reward: 0.580 [0.503, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.798, 10.098], loss: 0.001581, mae: 0.043279, mean_q: 1.179767
 260700/1000000: episode: 2607, duration: 0.650s, episode steps: 100, steps per second: 154, episode reward: 58.358, mean reward: 0.584 [0.502, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-2.373, 10.131], loss: 0.001581, mae: 0.043336, mean_q: 1.176055
 260800/1000000: episode: 2608, duration: 0.647s, episode steps: 100, steps per second: 155, episode reward: 58.930, mean reward: 0.589 [0.501, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.232, 10.200], loss: 0.001744, mae: 0.045710, mean_q: 1.175451
 260900/1000000: episode: 2609, duration: 0.624s, episode steps: 100, steps per second: 160, episode reward: 59.861, mean reward: 0.599 [0.510, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.883, 10.277], loss: 0.001654, mae: 0.044939, mean_q: 1.175481
 261000/1000000: episode: 2610, duration: 0.648s, episode steps: 100, steps per second: 154, episode reward: 59.315, mean reward: 0.593 [0.502, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.383, 10.144], loss: 0.001651, mae: 0.044323, mean_q: 1.178641
 261100/1000000: episode: 2611, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 62.452, mean reward: 0.625 [0.527, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.960, 10.098], loss: 0.001568, mae: 0.043007, mean_q: 1.178483
 261200/1000000: episode: 2612, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 56.999, mean reward: 0.570 [0.507, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.408, 10.098], loss: 0.001611, mae: 0.043597, mean_q: 1.178365
 261300/1000000: episode: 2613, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.182, mean reward: 0.592 [0.511, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.108, 10.098], loss: 0.001674, mae: 0.044403, mean_q: 1.180025
 261400/1000000: episode: 2614, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.905, mean reward: 0.589 [0.508, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.280, 10.098], loss: 0.001503, mae: 0.042259, mean_q: 1.177318
 261500/1000000: episode: 2615, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.771, mean reward: 0.588 [0.500, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.554, 10.098], loss: 0.001599, mae: 0.043059, mean_q: 1.177983
 261600/1000000: episode: 2616, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.472, mean reward: 0.595 [0.514, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.943, 10.098], loss: 0.001598, mae: 0.043925, mean_q: 1.180106
 261700/1000000: episode: 2617, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.502, mean reward: 0.595 [0.512, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.221, 10.349], loss: 0.001575, mae: 0.042571, mean_q: 1.176938
 261800/1000000: episode: 2618, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.364, mean reward: 0.584 [0.501, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.890, 10.098], loss: 0.001519, mae: 0.042857, mean_q: 1.175354
 261900/1000000: episode: 2619, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.477, mean reward: 0.605 [0.511, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.690, 10.098], loss: 0.001569, mae: 0.042566, mean_q: 1.176728
 262000/1000000: episode: 2620, duration: 0.641s, episode steps: 100, steps per second: 156, episode reward: 61.654, mean reward: 0.617 [0.509, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.374, 10.098], loss: 0.001609, mae: 0.043277, mean_q: 1.180743
 262100/1000000: episode: 2621, duration: 0.651s, episode steps: 100, steps per second: 154, episode reward: 57.241, mean reward: 0.572 [0.507, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.372, 10.206], loss: 0.001648, mae: 0.043921, mean_q: 1.181577
 262200/1000000: episode: 2622, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 56.927, mean reward: 0.569 [0.510, 0.670], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.921, 10.098], loss: 0.001506, mae: 0.042324, mean_q: 1.180080
 262300/1000000: episode: 2623, duration: 0.661s, episode steps: 100, steps per second: 151, episode reward: 57.658, mean reward: 0.577 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.264, 10.098], loss: 0.001570, mae: 0.043036, mean_q: 1.174589
 262400/1000000: episode: 2624, duration: 0.660s, episode steps: 100, steps per second: 152, episode reward: 61.561, mean reward: 0.616 [0.505, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.070, 10.098], loss: 0.001456, mae: 0.042015, mean_q: 1.175777
 262500/1000000: episode: 2625, duration: 0.639s, episode steps: 100, steps per second: 157, episode reward: 58.223, mean reward: 0.582 [0.503, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.239, 10.152], loss: 0.001557, mae: 0.043123, mean_q: 1.172970
 262600/1000000: episode: 2626, duration: 0.629s, episode steps: 100, steps per second: 159, episode reward: 60.383, mean reward: 0.604 [0.504, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.088, 10.098], loss: 0.001481, mae: 0.042746, mean_q: 1.176711
 262700/1000000: episode: 2627, duration: 0.688s, episode steps: 100, steps per second: 145, episode reward: 60.469, mean reward: 0.605 [0.501, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.136, 10.383], loss: 0.001601, mae: 0.043517, mean_q: 1.178345
 262800/1000000: episode: 2628, duration: 0.646s, episode steps: 100, steps per second: 155, episode reward: 57.662, mean reward: 0.577 [0.504, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.670, 10.098], loss: 0.001582, mae: 0.042949, mean_q: 1.174174
 262900/1000000: episode: 2629, duration: 0.649s, episode steps: 100, steps per second: 154, episode reward: 58.592, mean reward: 0.586 [0.498, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.855, 10.204], loss: 0.001481, mae: 0.042500, mean_q: 1.174469
 263000/1000000: episode: 2630, duration: 0.656s, episode steps: 100, steps per second: 152, episode reward: 58.216, mean reward: 0.582 [0.512, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.204, 10.098], loss: 0.001479, mae: 0.041860, mean_q: 1.173303
 263100/1000000: episode: 2631, duration: 0.670s, episode steps: 100, steps per second: 149, episode reward: 58.679, mean reward: 0.587 [0.505, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.339, 10.157], loss: 0.001549, mae: 0.043781, mean_q: 1.172605
 263200/1000000: episode: 2632, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.541, mean reward: 0.575 [0.505, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.304, 10.098], loss: 0.001552, mae: 0.042998, mean_q: 1.173732
 263300/1000000: episode: 2633, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 60.933, mean reward: 0.609 [0.501, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.257, 10.098], loss: 0.001409, mae: 0.041144, mean_q: 1.173302
 263400/1000000: episode: 2634, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.300, mean reward: 0.583 [0.508, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.743, 10.098], loss: 0.001477, mae: 0.041893, mean_q: 1.172996
 263500/1000000: episode: 2635, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.102, mean reward: 0.581 [0.508, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.577, 10.139], loss: 0.001465, mae: 0.042239, mean_q: 1.176693
 263600/1000000: episode: 2636, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 60.024, mean reward: 0.600 [0.507, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.234, 10.098], loss: 0.001484, mae: 0.042558, mean_q: 1.175791
 263700/1000000: episode: 2637, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 61.387, mean reward: 0.614 [0.511, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.807, 10.098], loss: 0.001461, mae: 0.042386, mean_q: 1.173883
 263800/1000000: episode: 2638, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.359, mean reward: 0.574 [0.506, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.905, 10.181], loss: 0.001417, mae: 0.041261, mean_q: 1.171813
 263900/1000000: episode: 2639, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.957, mean reward: 0.590 [0.502, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.599, 10.355], loss: 0.001475, mae: 0.042106, mean_q: 1.169912
 264000/1000000: episode: 2640, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.504, mean reward: 0.575 [0.511, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.181, 10.191], loss: 0.001370, mae: 0.040441, mean_q: 1.170638
 264100/1000000: episode: 2641, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 58.357, mean reward: 0.584 [0.509, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.446, 10.098], loss: 0.001511, mae: 0.042963, mean_q: 1.169751
 264200/1000000: episode: 2642, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.919, mean reward: 0.589 [0.518, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.393, 10.098], loss: 0.001413, mae: 0.041407, mean_q: 1.170459
 264300/1000000: episode: 2643, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.195, mean reward: 0.592 [0.504, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.963, 10.098], loss: 0.001370, mae: 0.041197, mean_q: 1.170917
 264400/1000000: episode: 2644, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.823, mean reward: 0.588 [0.500, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.589, 10.166], loss: 0.001362, mae: 0.040374, mean_q: 1.164963
 264500/1000000: episode: 2645, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.490, mean reward: 0.585 [0.501, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.908, 10.228], loss: 0.001439, mae: 0.041875, mean_q: 1.166117
 264600/1000000: episode: 2646, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.797, mean reward: 0.578 [0.510, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.765, 10.098], loss: 0.001405, mae: 0.041453, mean_q: 1.169039
 264700/1000000: episode: 2647, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.410, mean reward: 0.584 [0.509, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.875, 10.098], loss: 0.001421, mae: 0.041717, mean_q: 1.169370
 264800/1000000: episode: 2648, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.491, mean reward: 0.585 [0.509, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.976, 10.098], loss: 0.001537, mae: 0.042782, mean_q: 1.172021
 264900/1000000: episode: 2649, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.011, mean reward: 0.600 [0.499, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.852, 10.138], loss: 0.001372, mae: 0.040475, mean_q: 1.168343
 265000/1000000: episode: 2650, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.634, mean reward: 0.586 [0.502, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.169, 10.138], loss: 0.001350, mae: 0.040612, mean_q: 1.169546
 265100/1000000: episode: 2651, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.893, mean reward: 0.599 [0.505, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.756, 10.200], loss: 0.001426, mae: 0.041243, mean_q: 1.169173
 265200/1000000: episode: 2652, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.193, mean reward: 0.582 [0.506, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.714, 10.098], loss: 0.001392, mae: 0.041254, mean_q: 1.173723
 265300/1000000: episode: 2653, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.178, mean reward: 0.582 [0.516, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.558, 10.135], loss: 0.001367, mae: 0.040440, mean_q: 1.169297
 265400/1000000: episode: 2654, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.732, mean reward: 0.587 [0.509, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.688, 10.098], loss: 0.001456, mae: 0.041520, mean_q: 1.165640
 265500/1000000: episode: 2655, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.185, mean reward: 0.592 [0.502, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.566, 10.119], loss: 0.001422, mae: 0.041158, mean_q: 1.168130
 265600/1000000: episode: 2656, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 58.384, mean reward: 0.584 [0.499, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.717, 10.190], loss: 0.001351, mae: 0.039578, mean_q: 1.168340
 265700/1000000: episode: 2657, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.819, mean reward: 0.598 [0.512, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.463, 10.174], loss: 0.001363, mae: 0.040329, mean_q: 1.168063
 265800/1000000: episode: 2658, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.952, mean reward: 0.580 [0.503, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.127, 10.166], loss: 0.001319, mae: 0.040118, mean_q: 1.165702
 265900/1000000: episode: 2659, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.715, mean reward: 0.567 [0.499, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.382, 10.098], loss: 0.001355, mae: 0.040586, mean_q: 1.164657
 266000/1000000: episode: 2660, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.456, mean reward: 0.595 [0.510, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.306, 10.235], loss: 0.001350, mae: 0.040024, mean_q: 1.164778
 266100/1000000: episode: 2661, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.491, mean reward: 0.585 [0.508, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.509, 10.098], loss: 0.001480, mae: 0.041258, mean_q: 1.164828
 266200/1000000: episode: 2662, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.706, mean reward: 0.597 [0.512, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.361, 10.334], loss: 0.001330, mae: 0.040008, mean_q: 1.164228
 266300/1000000: episode: 2663, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.575, mean reward: 0.576 [0.500, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.278, 10.098], loss: 0.001320, mae: 0.039506, mean_q: 1.160649
 266400/1000000: episode: 2664, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 61.311, mean reward: 0.613 [0.513, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.816, 10.098], loss: 0.001307, mae: 0.039495, mean_q: 1.162121
 266500/1000000: episode: 2665, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 56.761, mean reward: 0.568 [0.507, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.618, 10.265], loss: 0.001418, mae: 0.041367, mean_q: 1.165599
 266600/1000000: episode: 2666, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 56.763, mean reward: 0.568 [0.504, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.844, 10.278], loss: 0.001408, mae: 0.040741, mean_q: 1.160711
 266700/1000000: episode: 2667, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.141, mean reward: 0.611 [0.503, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.524, 10.347], loss: 0.001377, mae: 0.040176, mean_q: 1.160625
 266800/1000000: episode: 2668, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.623, mean reward: 0.586 [0.501, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.024, 10.098], loss: 0.001415, mae: 0.041786, mean_q: 1.162724
 266900/1000000: episode: 2669, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.731, mean reward: 0.577 [0.501, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.967, 10.098], loss: 0.001355, mae: 0.040136, mean_q: 1.160288
 267000/1000000: episode: 2670, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.346, mean reward: 0.583 [0.514, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.412, 10.299], loss: 0.001375, mae: 0.040199, mean_q: 1.162759
 267100/1000000: episode: 2671, duration: 0.689s, episode steps: 100, steps per second: 145, episode reward: 59.896, mean reward: 0.599 [0.502, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.133, 10.153], loss: 0.001326, mae: 0.039365, mean_q: 1.163131
 267200/1000000: episode: 2672, duration: 0.684s, episode steps: 100, steps per second: 146, episode reward: 63.791, mean reward: 0.638 [0.512, 0.866], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.893, 10.098], loss: 0.001328, mae: 0.039590, mean_q: 1.160666
 267300/1000000: episode: 2673, duration: 0.627s, episode steps: 100, steps per second: 159, episode reward: 58.866, mean reward: 0.589 [0.506, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.596, 10.274], loss: 0.001326, mae: 0.040133, mean_q: 1.162468
 267400/1000000: episode: 2674, duration: 0.639s, episode steps: 100, steps per second: 157, episode reward: 59.616, mean reward: 0.596 [0.507, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.229, 10.098], loss: 0.001381, mae: 0.040530, mean_q: 1.164560
 267500/1000000: episode: 2675, duration: 0.641s, episode steps: 100, steps per second: 156, episode reward: 58.162, mean reward: 0.582 [0.503, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.377, 10.122], loss: 0.001312, mae: 0.039528, mean_q: 1.165131
 267600/1000000: episode: 2676, duration: 0.671s, episode steps: 100, steps per second: 149, episode reward: 60.883, mean reward: 0.609 [0.514, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.297, 10.329], loss: 0.001351, mae: 0.040071, mean_q: 1.164096
 267700/1000000: episode: 2677, duration: 0.630s, episode steps: 100, steps per second: 159, episode reward: 59.516, mean reward: 0.595 [0.501, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.731, 10.098], loss: 0.001399, mae: 0.040956, mean_q: 1.167050
 267800/1000000: episode: 2678, duration: 0.644s, episode steps: 100, steps per second: 155, episode reward: 58.784, mean reward: 0.588 [0.506, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.383, 10.379], loss: 0.001399, mae: 0.040485, mean_q: 1.162577
 267900/1000000: episode: 2679, duration: 0.635s, episode steps: 100, steps per second: 158, episode reward: 62.974, mean reward: 0.630 [0.521, 0.881], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.206, 10.441], loss: 0.001397, mae: 0.040516, mean_q: 1.163200
 268000/1000000: episode: 2680, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 61.751, mean reward: 0.618 [0.502, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.769, 10.254], loss: 0.001515, mae: 0.041886, mean_q: 1.169166
 268100/1000000: episode: 2681, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.725, mean reward: 0.587 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.196, 10.148], loss: 0.001457, mae: 0.041670, mean_q: 1.169647
 268200/1000000: episode: 2682, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.041, mean reward: 0.580 [0.497, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.687, 10.098], loss: 0.001503, mae: 0.041889, mean_q: 1.171402
 268300/1000000: episode: 2683, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 56.959, mean reward: 0.570 [0.503, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.293, 10.155], loss: 0.001504, mae: 0.042231, mean_q: 1.168663
 268400/1000000: episode: 2684, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.907, mean reward: 0.579 [0.501, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.947, 10.098], loss: 0.001418, mae: 0.040771, mean_q: 1.167791
 268500/1000000: episode: 2685, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.079, mean reward: 0.571 [0.498, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.272, 10.098], loss: 0.001477, mae: 0.041593, mean_q: 1.165566
 268600/1000000: episode: 2686, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.333, mean reward: 0.603 [0.506, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.285, 10.287], loss: 0.001485, mae: 0.041078, mean_q: 1.165808
 268700/1000000: episode: 2687, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: 61.929, mean reward: 0.619 [0.503, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.861, 10.358], loss: 0.001507, mae: 0.041838, mean_q: 1.164561
 268800/1000000: episode: 2688, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.297, mean reward: 0.563 [0.500, 0.645], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.506, 10.138], loss: 0.001448, mae: 0.041146, mean_q: 1.166462
 268900/1000000: episode: 2689, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.050, mean reward: 0.571 [0.504, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.633, 10.105], loss: 0.001517, mae: 0.042531, mean_q: 1.167027
 269000/1000000: episode: 2690, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 61.017, mean reward: 0.610 [0.504, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.394, 10.098], loss: 0.001451, mae: 0.041036, mean_q: 1.165454
 269100/1000000: episode: 2691, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 56.519, mean reward: 0.565 [0.502, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.155, 10.101], loss: 0.001594, mae: 0.042647, mean_q: 1.167994
 269200/1000000: episode: 2692, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.339, mean reward: 0.593 [0.509, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.868, 10.344], loss: 0.001566, mae: 0.042892, mean_q: 1.166787
 269300/1000000: episode: 2693, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 60.949, mean reward: 0.609 [0.507, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.212, 10.098], loss: 0.001493, mae: 0.041824, mean_q: 1.166108
 269400/1000000: episode: 2694, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.484, mean reward: 0.595 [0.505, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.394, 10.121], loss: 0.001296, mae: 0.039470, mean_q: 1.168490
 269500/1000000: episode: 2695, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.683, mean reward: 0.577 [0.508, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.572, 10.098], loss: 0.001498, mae: 0.041557, mean_q: 1.165119
 269600/1000000: episode: 2696, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.000, mean reward: 0.600 [0.511, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.593, 10.098], loss: 0.001434, mae: 0.041492, mean_q: 1.166256
 269700/1000000: episode: 2697, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 59.195, mean reward: 0.592 [0.506, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.572, 10.098], loss: 0.001541, mae: 0.042455, mean_q: 1.168519
 269800/1000000: episode: 2698, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 57.332, mean reward: 0.573 [0.500, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.775, 10.175], loss: 0.001471, mae: 0.041648, mean_q: 1.167285
 269900/1000000: episode: 2699, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.373, mean reward: 0.614 [0.507, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.260, 10.098], loss: 0.001436, mae: 0.041210, mean_q: 1.167243
 270000/1000000: episode: 2700, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.213, mean reward: 0.582 [0.503, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.446, 10.098], loss: 0.001510, mae: 0.041419, mean_q: 1.167383
 270100/1000000: episode: 2701, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.134, mean reward: 0.581 [0.498, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.087, 10.154], loss: 0.001525, mae: 0.042702, mean_q: 1.169701
 270200/1000000: episode: 2702, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.585, mean reward: 0.576 [0.502, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.827, 10.199], loss: 0.001503, mae: 0.042100, mean_q: 1.167535
 270300/1000000: episode: 2703, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.867, mean reward: 0.609 [0.507, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.730, 10.098], loss: 0.001524, mae: 0.042322, mean_q: 1.168634
 270400/1000000: episode: 2704, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 63.943, mean reward: 0.639 [0.508, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.968, 10.152], loss: 0.001532, mae: 0.042462, mean_q: 1.171375
 270500/1000000: episode: 2705, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.949, mean reward: 0.579 [0.502, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.898, 10.098], loss: 0.001536, mae: 0.042700, mean_q: 1.173069
 270600/1000000: episode: 2706, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.334, mean reward: 0.593 [0.514, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.523, 10.116], loss: 0.001461, mae: 0.041495, mean_q: 1.168577
 270700/1000000: episode: 2707, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.258, mean reward: 0.573 [0.507, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.779, 10.148], loss: 0.001509, mae: 0.042075, mean_q: 1.170784
 270800/1000000: episode: 2708, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 62.259, mean reward: 0.623 [0.513, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.411 [-0.669, 10.098], loss: 0.001526, mae: 0.042496, mean_q: 1.170630
 270900/1000000: episode: 2709, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.674, mean reward: 0.587 [0.506, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.150, 10.098], loss: 0.001527, mae: 0.042046, mean_q: 1.172644
 271000/1000000: episode: 2710, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.385, mean reward: 0.594 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.653, 10.098], loss: 0.001587, mae: 0.042645, mean_q: 1.171818
 271100/1000000: episode: 2711, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.559, mean reward: 0.576 [0.505, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.257, 10.118], loss: 0.001623, mae: 0.042838, mean_q: 1.174566
 271200/1000000: episode: 2712, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.305, mean reward: 0.593 [0.505, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.621, 10.098], loss: 0.001585, mae: 0.042953, mean_q: 1.171375
 271300/1000000: episode: 2713, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 61.072, mean reward: 0.611 [0.515, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.275, 10.216], loss: 0.001464, mae: 0.041525, mean_q: 1.170979
 271400/1000000: episode: 2714, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.225, mean reward: 0.572 [0.505, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.972, 10.098], loss: 0.001497, mae: 0.041452, mean_q: 1.171474
 271500/1000000: episode: 2715, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 58.972, mean reward: 0.590 [0.508, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.780, 10.287], loss: 0.001409, mae: 0.040807, mean_q: 1.168756
 271600/1000000: episode: 2716, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.528, mean reward: 0.575 [0.498, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.704, 10.127], loss: 0.001531, mae: 0.042390, mean_q: 1.174524
 271700/1000000: episode: 2717, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.061, mean reward: 0.611 [0.508, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.759, 10.345], loss: 0.001448, mae: 0.040992, mean_q: 1.170814
 271800/1000000: episode: 2718, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.322, mean reward: 0.573 [0.509, 0.667], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.847, 10.185], loss: 0.001593, mae: 0.042985, mean_q: 1.174548
 271900/1000000: episode: 2719, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 62.318, mean reward: 0.623 [0.499, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-2.125, 10.234], loss: 0.001436, mae: 0.041296, mean_q: 1.172751
 272000/1000000: episode: 2720, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.801, mean reward: 0.598 [0.507, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.569, 10.098], loss: 0.001437, mae: 0.041467, mean_q: 1.174263
 272100/1000000: episode: 2721, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.979, mean reward: 0.580 [0.506, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.065, 10.190], loss: 0.001352, mae: 0.039904, mean_q: 1.170043
 272200/1000000: episode: 2722, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 63.462, mean reward: 0.635 [0.509, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.722, 10.528], loss: 0.001415, mae: 0.040544, mean_q: 1.170275
 272300/1000000: episode: 2723, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.897, mean reward: 0.579 [0.505, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.682, 10.154], loss: 0.001447, mae: 0.041584, mean_q: 1.173550
 272400/1000000: episode: 2724, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.016, mean reward: 0.590 [0.509, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.078, 10.188], loss: 0.001460, mae: 0.041347, mean_q: 1.176735
 272500/1000000: episode: 2725, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.081, mean reward: 0.581 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.030, 10.239], loss: 0.001455, mae: 0.040978, mean_q: 1.176969
 272600/1000000: episode: 2726, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.050, mean reward: 0.611 [0.527, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.285, 10.264], loss: 0.001413, mae: 0.040944, mean_q: 1.172889
 272700/1000000: episode: 2727, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.897, mean reward: 0.579 [0.510, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.321, 10.098], loss: 0.001506, mae: 0.042136, mean_q: 1.176619
 272800/1000000: episode: 2728, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.945, mean reward: 0.599 [0.499, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.364, 10.110], loss: 0.001466, mae: 0.042033, mean_q: 1.172594
 272900/1000000: episode: 2729, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.872, mean reward: 0.599 [0.504, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.570, 10.231], loss: 0.001501, mae: 0.042313, mean_q: 1.170126
 273000/1000000: episode: 2730, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.922, mean reward: 0.579 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.650, 10.234], loss: 0.001442, mae: 0.041194, mean_q: 1.167662
 273100/1000000: episode: 2731, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.681, mean reward: 0.587 [0.501, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.619, 10.098], loss: 0.001453, mae: 0.041498, mean_q: 1.168922
 273200/1000000: episode: 2732, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.249, mean reward: 0.572 [0.505, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.849, 10.098], loss: 0.001540, mae: 0.042578, mean_q: 1.169059
 273300/1000000: episode: 2733, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.393, mean reward: 0.574 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.591, 10.098], loss: 0.001430, mae: 0.041404, mean_q: 1.169358
 273400/1000000: episode: 2734, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.553, mean reward: 0.586 [0.502, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.150, 10.135], loss: 0.001509, mae: 0.042113, mean_q: 1.174018
 273500/1000000: episode: 2735, duration: 0.528s, episode steps: 100, steps per second: 190, episode reward: 61.136, mean reward: 0.611 [0.513, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.703, 10.443], loss: 0.001301, mae: 0.039491, mean_q: 1.171056
 273600/1000000: episode: 2736, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.594, mean reward: 0.586 [0.508, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.507, 10.323], loss: 0.001346, mae: 0.039471, mean_q: 1.170960
 273700/1000000: episode: 2737, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.779, mean reward: 0.588 [0.498, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.717, 10.098], loss: 0.001300, mae: 0.039452, mean_q: 1.168742
 273800/1000000: episode: 2738, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 59.376, mean reward: 0.594 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.407, 10.098], loss: 0.001335, mae: 0.039807, mean_q: 1.168010
 273900/1000000: episode: 2739, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.346, mean reward: 0.573 [0.502, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.838, 10.098], loss: 0.001341, mae: 0.039766, mean_q: 1.164338
 274000/1000000: episode: 2740, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.241, mean reward: 0.582 [0.507, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.138, 10.098], loss: 0.001380, mae: 0.040676, mean_q: 1.169394
 274100/1000000: episode: 2741, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 64.287, mean reward: 0.643 [0.511, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.188, 10.555], loss: 0.001311, mae: 0.039419, mean_q: 1.170847
 274200/1000000: episode: 2742, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.582, mean reward: 0.596 [0.509, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.157, 10.410], loss: 0.001404, mae: 0.040580, mean_q: 1.171177
 274300/1000000: episode: 2743, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.997, mean reward: 0.580 [0.501, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.273, 10.279], loss: 0.001418, mae: 0.040774, mean_q: 1.170781
 274400/1000000: episode: 2744, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.010, mean reward: 0.590 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.774, 10.098], loss: 0.001433, mae: 0.041536, mean_q: 1.171351
 274500/1000000: episode: 2745, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.012, mean reward: 0.580 [0.499, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.560, 10.098], loss: 0.001364, mae: 0.040345, mean_q: 1.170755
 274600/1000000: episode: 2746, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.627, mean reward: 0.606 [0.506, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.033, 10.098], loss: 0.001471, mae: 0.041868, mean_q: 1.171752
 274700/1000000: episode: 2747, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.636, mean reward: 0.586 [0.503, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.422, 10.415], loss: 0.001515, mae: 0.042579, mean_q: 1.177096
 274800/1000000: episode: 2748, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.183, mean reward: 0.572 [0.498, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.519, 10.170], loss: 0.001515, mae: 0.042336, mean_q: 1.172542
 274900/1000000: episode: 2749, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.424, mean reward: 0.574 [0.499, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.543, 10.098], loss: 0.001487, mae: 0.041946, mean_q: 1.173879
 275000/1000000: episode: 2750, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.320, mean reward: 0.573 [0.498, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.780, 10.163], loss: 0.001535, mae: 0.042260, mean_q: 1.170763
 275100/1000000: episode: 2751, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.940, mean reward: 0.589 [0.505, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.883, 10.098], loss: 0.001417, mae: 0.041351, mean_q: 1.171952
 275200/1000000: episode: 2752, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.960, mean reward: 0.590 [0.500, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.987, 10.098], loss: 0.001388, mae: 0.041000, mean_q: 1.168498
 275300/1000000: episode: 2753, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.182, mean reward: 0.572 [0.498, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.899, 10.098], loss: 0.001406, mae: 0.041098, mean_q: 1.169176
 275400/1000000: episode: 2754, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.135, mean reward: 0.591 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.636, 10.175], loss: 0.001465, mae: 0.041706, mean_q: 1.173244
 275500/1000000: episode: 2755, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.893, mean reward: 0.599 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.470, 10.376], loss: 0.001508, mae: 0.042286, mean_q: 1.170035
 275600/1000000: episode: 2756, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.942, mean reward: 0.589 [0.500, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.786, 10.158], loss: 0.001546, mae: 0.042483, mean_q: 1.167227
 275700/1000000: episode: 2757, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.395, mean reward: 0.604 [0.514, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.251, 10.098], loss: 0.001478, mae: 0.042260, mean_q: 1.169069
 275800/1000000: episode: 2758, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 57.278, mean reward: 0.573 [0.500, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.423, 10.098], loss: 0.001472, mae: 0.041810, mean_q: 1.163744
 275900/1000000: episode: 2759, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.541, mean reward: 0.595 [0.513, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.408, 10.098], loss: 0.001450, mae: 0.041664, mean_q: 1.165036
 276000/1000000: episode: 2760, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.775, mean reward: 0.598 [0.505, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.892, 10.232], loss: 0.001383, mae: 0.041144, mean_q: 1.167370
 276100/1000000: episode: 2761, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.494, mean reward: 0.575 [0.511, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.631, 10.239], loss: 0.001278, mae: 0.039285, mean_q: 1.166520
 276200/1000000: episode: 2762, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.650, mean reward: 0.587 [0.509, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.173, 10.111], loss: 0.001370, mae: 0.040529, mean_q: 1.163484
 276300/1000000: episode: 2763, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.486, mean reward: 0.595 [0.498, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.113, 10.305], loss: 0.001488, mae: 0.042073, mean_q: 1.167330
 276400/1000000: episode: 2764, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 60.567, mean reward: 0.606 [0.500, 0.886], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.471, 10.098], loss: 0.001483, mae: 0.042198, mean_q: 1.171313
 276500/1000000: episode: 2765, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.729, mean reward: 0.597 [0.502, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.522, 10.224], loss: 0.001364, mae: 0.040483, mean_q: 1.167337
 276600/1000000: episode: 2766, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.092, mean reward: 0.591 [0.511, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.729, 10.098], loss: 0.001411, mae: 0.041116, mean_q: 1.166187
 276700/1000000: episode: 2767, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.395, mean reward: 0.594 [0.511, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.956, 10.223], loss: 0.001428, mae: 0.041491, mean_q: 1.170393
 276800/1000000: episode: 2768, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.987, mean reward: 0.590 [0.504, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.372, 10.232], loss: 0.001504, mae: 0.042665, mean_q: 1.168464
 276900/1000000: episode: 2769, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.436, mean reward: 0.604 [0.505, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.805, 10.098], loss: 0.001558, mae: 0.042868, mean_q: 1.165857
 277000/1000000: episode: 2770, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.480, mean reward: 0.585 [0.505, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.048, 10.098], loss: 0.001537, mae: 0.043030, mean_q: 1.165013
 277100/1000000: episode: 2771, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.859, mean reward: 0.589 [0.508, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.674, 10.098], loss: 0.001402, mae: 0.041151, mean_q: 1.169019
 277200/1000000: episode: 2772, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.139, mean reward: 0.611 [0.510, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.058, 10.268], loss: 0.001531, mae: 0.042878, mean_q: 1.167179
 277300/1000000: episode: 2773, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.487, mean reward: 0.605 [0.499, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.960, 10.098], loss: 0.001434, mae: 0.041499, mean_q: 1.165690
 277400/1000000: episode: 2774, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.432, mean reward: 0.574 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.974, 10.115], loss: 0.001467, mae: 0.042254, mean_q: 1.169919
 277500/1000000: episode: 2775, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.358, mean reward: 0.604 [0.510, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.290, 10.098], loss: 0.001496, mae: 0.042545, mean_q: 1.167768
 277600/1000000: episode: 2776, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.673, mean reward: 0.597 [0.519, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.266, 10.098], loss: 0.001342, mae: 0.039887, mean_q: 1.167212
 277700/1000000: episode: 2777, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.861, mean reward: 0.599 [0.503, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.465, 10.098], loss: 0.001387, mae: 0.040570, mean_q: 1.169266
 277800/1000000: episode: 2778, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.195, mean reward: 0.592 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.451, 10.244], loss: 0.001459, mae: 0.041496, mean_q: 1.168504
 277900/1000000: episode: 2779, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.701, mean reward: 0.587 [0.505, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.961, 10.117], loss: 0.001368, mae: 0.040667, mean_q: 1.167573
 278000/1000000: episode: 2780, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 60.273, mean reward: 0.603 [0.509, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.683, 10.098], loss: 0.001385, mae: 0.040547, mean_q: 1.168271
 278100/1000000: episode: 2781, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.252, mean reward: 0.583 [0.506, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.551, 10.204], loss: 0.001393, mae: 0.040838, mean_q: 1.167200
 278200/1000000: episode: 2782, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.184, mean reward: 0.582 [0.501, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.601, 10.098], loss: 0.001497, mae: 0.041890, mean_q: 1.168681
 278300/1000000: episode: 2783, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 56.759, mean reward: 0.568 [0.500, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.165, 10.098], loss: 0.001432, mae: 0.041229, mean_q: 1.166212
 278400/1000000: episode: 2784, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.228, mean reward: 0.592 [0.522, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.217, 10.277], loss: 0.001403, mae: 0.040947, mean_q: 1.167200
 278500/1000000: episode: 2785, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.617, mean reward: 0.576 [0.502, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.198, 10.098], loss: 0.001482, mae: 0.041754, mean_q: 1.167035
 278600/1000000: episode: 2786, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.437, mean reward: 0.574 [0.499, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.838, 10.115], loss: 0.001443, mae: 0.041303, mean_q: 1.169119
 278700/1000000: episode: 2787, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.419, mean reward: 0.584 [0.503, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.926, 10.168], loss: 0.001471, mae: 0.041409, mean_q: 1.167009
 278800/1000000: episode: 2788, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 66.133, mean reward: 0.661 [0.517, 0.870], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.993, 10.518], loss: 0.001413, mae: 0.041030, mean_q: 1.167314
 278900/1000000: episode: 2789, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.959, mean reward: 0.600 [0.507, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.333, 10.114], loss: 0.001467, mae: 0.042240, mean_q: 1.170935
 279000/1000000: episode: 2790, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.300, mean reward: 0.593 [0.500, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.154, 10.168], loss: 0.001516, mae: 0.042400, mean_q: 1.168749
 279100/1000000: episode: 2791, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.321, mean reward: 0.573 [0.501, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.943, 10.151], loss: 0.001436, mae: 0.041288, mean_q: 1.165915
 279200/1000000: episode: 2792, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.103, mean reward: 0.601 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.756, 10.098], loss: 0.001413, mae: 0.040952, mean_q: 1.169847
 279300/1000000: episode: 2793, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.462, mean reward: 0.595 [0.506, 0.846], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.549, 10.372], loss: 0.001474, mae: 0.042102, mean_q: 1.170733
 279400/1000000: episode: 2794, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 56.432, mean reward: 0.564 [0.499, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.698, 10.098], loss: 0.001429, mae: 0.041483, mean_q: 1.169329
 279500/1000000: episode: 2795, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.865, mean reward: 0.569 [0.509, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.455, 10.168], loss: 0.001460, mae: 0.041909, mean_q: 1.170235
 279600/1000000: episode: 2796, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 60.027, mean reward: 0.600 [0.505, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.448 [-0.650, 10.508], loss: 0.001302, mae: 0.039158, mean_q: 1.166955
 279700/1000000: episode: 2797, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.186, mean reward: 0.582 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.817, 10.098], loss: 0.001510, mae: 0.042561, mean_q: 1.170673
 279800/1000000: episode: 2798, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 58.636, mean reward: 0.586 [0.506, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.377, 10.098], loss: 0.001432, mae: 0.041134, mean_q: 1.170150
 279900/1000000: episode: 2799, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.763, mean reward: 0.578 [0.509, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.535, 10.177], loss: 0.001546, mae: 0.042582, mean_q: 1.171160
 280000/1000000: episode: 2800, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.419, mean reward: 0.594 [0.511, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.170, 10.218], loss: 0.001419, mae: 0.040857, mean_q: 1.168335
 280100/1000000: episode: 2801, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.445, mean reward: 0.604 [0.513, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.922, 10.142], loss: 0.001463, mae: 0.041751, mean_q: 1.170228
 280200/1000000: episode: 2802, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.589, mean reward: 0.586 [0.502, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.952, 10.098], loss: 0.001522, mae: 0.042301, mean_q: 1.169678
 280300/1000000: episode: 2803, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.595, mean reward: 0.586 [0.506, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.039, 10.098], loss: 0.001402, mae: 0.041153, mean_q: 1.171182
 280400/1000000: episode: 2804, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.381, mean reward: 0.594 [0.499, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.102, 10.098], loss: 0.001440, mae: 0.041394, mean_q: 1.171686
 280500/1000000: episode: 2805, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.628, mean reward: 0.576 [0.505, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.211, 10.098], loss: 0.001422, mae: 0.040993, mean_q: 1.170941
 280600/1000000: episode: 2806, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 59.805, mean reward: 0.598 [0.508, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.944, 10.098], loss: 0.001357, mae: 0.041064, mean_q: 1.169492
 280700/1000000: episode: 2807, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.414, mean reward: 0.594 [0.503, 0.873], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.468, 10.183], loss: 0.001379, mae: 0.040465, mean_q: 1.169376
 280800/1000000: episode: 2808, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.769, mean reward: 0.588 [0.506, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.605, 10.098], loss: 0.001349, mae: 0.040360, mean_q: 1.166943
 280900/1000000: episode: 2809, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.616, mean reward: 0.596 [0.504, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.991, 10.098], loss: 0.001540, mae: 0.042582, mean_q: 1.169000
 281000/1000000: episode: 2810, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.646, mean reward: 0.576 [0.503, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.317, 10.098], loss: 0.001404, mae: 0.040803, mean_q: 1.170018
 281100/1000000: episode: 2811, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.294, mean reward: 0.593 [0.512, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.254, 10.098], loss: 0.001400, mae: 0.040914, mean_q: 1.171871
 281200/1000000: episode: 2812, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.009, mean reward: 0.590 [0.515, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.639, 10.098], loss: 0.001345, mae: 0.039849, mean_q: 1.168610
 281300/1000000: episode: 2813, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.535, mean reward: 0.585 [0.502, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.312, 10.098], loss: 0.001380, mae: 0.040012, mean_q: 1.170502
 281400/1000000: episode: 2814, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.594, mean reward: 0.586 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.211, 10.174], loss: 0.001412, mae: 0.040733, mean_q: 1.169984
 281500/1000000: episode: 2815, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.177, mean reward: 0.582 [0.498, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.423, 10.264], loss: 0.001402, mae: 0.040318, mean_q: 1.168449
 281600/1000000: episode: 2816, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.339, mean reward: 0.583 [0.502, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.933, 10.098], loss: 0.001343, mae: 0.040065, mean_q: 1.164195
 281700/1000000: episode: 2817, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.310, mean reward: 0.583 [0.503, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.776, 10.098], loss: 0.001438, mae: 0.041450, mean_q: 1.167754
 281800/1000000: episode: 2818, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.566, mean reward: 0.576 [0.505, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.616, 10.120], loss: 0.001347, mae: 0.039936, mean_q: 1.169068
 281900/1000000: episode: 2819, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.439, mean reward: 0.604 [0.516, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.171, 10.382], loss: 0.001505, mae: 0.041412, mean_q: 1.166376
 282000/1000000: episode: 2820, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.826, mean reward: 0.588 [0.516, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.533, 10.098], loss: 0.001474, mae: 0.042057, mean_q: 1.167564
 282100/1000000: episode: 2821, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.200, mean reward: 0.592 [0.511, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.272, 10.098], loss: 0.001461, mae: 0.041968, mean_q: 1.167347
 282200/1000000: episode: 2822, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 60.292, mean reward: 0.603 [0.504, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.334, 10.172], loss: 0.001318, mae: 0.039388, mean_q: 1.165659
 282300/1000000: episode: 2823, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 62.661, mean reward: 0.627 [0.502, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.713, 10.468], loss: 0.001386, mae: 0.040910, mean_q: 1.167486
 282400/1000000: episode: 2824, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 56.674, mean reward: 0.567 [0.498, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.842, 10.310], loss: 0.001357, mae: 0.040548, mean_q: 1.169864
 282500/1000000: episode: 2825, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.770, mean reward: 0.568 [0.511, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.572, 10.188], loss: 0.001428, mae: 0.041569, mean_q: 1.167289
 282600/1000000: episode: 2826, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.340, mean reward: 0.593 [0.507, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.110, 10.098], loss: 0.001395, mae: 0.040841, mean_q: 1.164177
 282700/1000000: episode: 2827, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.015, mean reward: 0.590 [0.500, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.601, 10.098], loss: 0.001500, mae: 0.042053, mean_q: 1.164523
 282800/1000000: episode: 2828, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.102, mean reward: 0.581 [0.510, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.579, 10.098], loss: 0.001370, mae: 0.040289, mean_q: 1.167763
 282900/1000000: episode: 2829, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.466, mean reward: 0.575 [0.498, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.753, 10.098], loss: 0.001397, mae: 0.040058, mean_q: 1.164901
 283000/1000000: episode: 2830, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.935, mean reward: 0.589 [0.503, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.419, 10.242], loss: 0.001418, mae: 0.041348, mean_q: 1.162227
 283100/1000000: episode: 2831, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 56.256, mean reward: 0.563 [0.501, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.275, 10.268], loss: 0.001392, mae: 0.040965, mean_q: 1.161417
 283200/1000000: episode: 2832, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.381, mean reward: 0.594 [0.510, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.697, 10.098], loss: 0.001419, mae: 0.040751, mean_q: 1.161605
 283300/1000000: episode: 2833, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.689, mean reward: 0.597 [0.509, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-2.204, 10.156], loss: 0.001361, mae: 0.040133, mean_q: 1.163197
 283400/1000000: episode: 2834, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.871, mean reward: 0.589 [0.509, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.853, 10.312], loss: 0.001414, mae: 0.040310, mean_q: 1.161102
 283500/1000000: episode: 2835, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.007, mean reward: 0.600 [0.504, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.466, 10.282], loss: 0.001452, mae: 0.040980, mean_q: 1.164612
 283600/1000000: episode: 2836, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.020, mean reward: 0.590 [0.503, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.741, 10.098], loss: 0.001401, mae: 0.040487, mean_q: 1.164214
 283700/1000000: episode: 2837, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 61.946, mean reward: 0.619 [0.510, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.438, 10.399], loss: 0.001440, mae: 0.040828, mean_q: 1.165668
 283800/1000000: episode: 2838, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.080, mean reward: 0.591 [0.503, 0.897], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.642, 10.183], loss: 0.001521, mae: 0.042521, mean_q: 1.163225
 283900/1000000: episode: 2839, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.493, mean reward: 0.615 [0.513, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.397, 10.098], loss: 0.001508, mae: 0.042606, mean_q: 1.164345
 284000/1000000: episode: 2840, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.133, mean reward: 0.581 [0.499, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.467, 10.098], loss: 0.001504, mae: 0.041480, mean_q: 1.166362
 284100/1000000: episode: 2841, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.115, mean reward: 0.581 [0.504, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.484, 10.130], loss: 0.001490, mae: 0.041483, mean_q: 1.166247
 284200/1000000: episode: 2842, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.057, mean reward: 0.591 [0.513, 0.896], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.853, 10.658], loss: 0.001482, mae: 0.042125, mean_q: 1.162964
 284300/1000000: episode: 2843, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.245, mean reward: 0.592 [0.511, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.965, 10.131], loss: 0.001508, mae: 0.042058, mean_q: 1.166214
 284400/1000000: episode: 2844, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.217, mean reward: 0.602 [0.506, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.550, 10.311], loss: 0.001498, mae: 0.041994, mean_q: 1.165705
 284500/1000000: episode: 2845, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.713, mean reward: 0.587 [0.505, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.469, 10.098], loss: 0.001627, mae: 0.043165, mean_q: 1.169582
 284600/1000000: episode: 2846, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.883, mean reward: 0.579 [0.505, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.867, 10.098], loss: 0.001445, mae: 0.040967, mean_q: 1.167780
 284700/1000000: episode: 2847, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 60.566, mean reward: 0.606 [0.499, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.319, 10.220], loss: 0.001436, mae: 0.040245, mean_q: 1.164094
 284800/1000000: episode: 2848, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.076, mean reward: 0.591 [0.507, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.356, 10.161], loss: 0.001366, mae: 0.039570, mean_q: 1.163353
 284900/1000000: episode: 2849, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.677, mean reward: 0.577 [0.500, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.352, 10.098], loss: 0.001467, mae: 0.041411, mean_q: 1.167322
 285000/1000000: episode: 2850, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.881, mean reward: 0.589 [0.499, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.163, 10.321], loss: 0.001413, mae: 0.041003, mean_q: 1.168575
 285100/1000000: episode: 2851, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.418, mean reward: 0.594 [0.503, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.234, 10.151], loss: 0.001484, mae: 0.041586, mean_q: 1.169227
 285200/1000000: episode: 2852, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.083, mean reward: 0.611 [0.503, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.671, 10.098], loss: 0.001447, mae: 0.041347, mean_q: 1.164941
 285300/1000000: episode: 2853, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.539, mean reward: 0.595 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.862, 10.098], loss: 0.001380, mae: 0.040817, mean_q: 1.167211
 285400/1000000: episode: 2854, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.137, mean reward: 0.591 [0.505, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.433, 10.098], loss: 0.001347, mae: 0.039758, mean_q: 1.166362
 285500/1000000: episode: 2855, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.093, mean reward: 0.601 [0.505, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.444, 10.243], loss: 0.001366, mae: 0.039987, mean_q: 1.167967
 285600/1000000: episode: 2856, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 59.521, mean reward: 0.595 [0.506, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.786, 10.098], loss: 0.001542, mae: 0.042575, mean_q: 1.168734
 285700/1000000: episode: 2857, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.617, mean reward: 0.586 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.355, 10.098], loss: 0.001496, mae: 0.041669, mean_q: 1.167390
 285800/1000000: episode: 2858, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.147, mean reward: 0.581 [0.505, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.312, 10.179], loss: 0.001387, mae: 0.040991, mean_q: 1.166945
 285900/1000000: episode: 2859, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.498, mean reward: 0.565 [0.504, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.773, 10.178], loss: 0.001483, mae: 0.041361, mean_q: 1.169217
 286000/1000000: episode: 2860, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 61.587, mean reward: 0.616 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.140, 10.133], loss: 0.001450, mae: 0.041904, mean_q: 1.170096
 286100/1000000: episode: 2861, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 61.380, mean reward: 0.614 [0.523, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.413, 10.098], loss: 0.001455, mae: 0.041721, mean_q: 1.169511
 286200/1000000: episode: 2862, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.403, mean reward: 0.574 [0.498, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.629, 10.136], loss: 0.001488, mae: 0.041858, mean_q: 1.172507
 286300/1000000: episode: 2863, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.488, mean reward: 0.605 [0.507, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.530, 10.098], loss: 0.001366, mae: 0.040354, mean_q: 1.168043
 286400/1000000: episode: 2864, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.072, mean reward: 0.591 [0.502, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.670, 10.146], loss: 0.001482, mae: 0.041810, mean_q: 1.169822
 286500/1000000: episode: 2865, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 58.026, mean reward: 0.580 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.895, 10.098], loss: 0.001412, mae: 0.040664, mean_q: 1.171148
 286600/1000000: episode: 2866, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.557, mean reward: 0.576 [0.508, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.823, 10.171], loss: 0.001413, mae: 0.041254, mean_q: 1.171253
 286700/1000000: episode: 2867, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.851, mean reward: 0.589 [0.509, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.044, 10.098], loss: 0.001419, mae: 0.040877, mean_q: 1.170366
 286800/1000000: episode: 2868, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.486, mean reward: 0.585 [0.509, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.636, 10.101], loss: 0.001491, mae: 0.041998, mean_q: 1.170349
 286900/1000000: episode: 2869, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.120, mean reward: 0.591 [0.499, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.553, 10.098], loss: 0.001456, mae: 0.041356, mean_q: 1.167348
 287000/1000000: episode: 2870, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 59.796, mean reward: 0.598 [0.505, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.611, 10.098], loss: 0.001502, mae: 0.042553, mean_q: 1.169290
 287100/1000000: episode: 2871, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 56.177, mean reward: 0.562 [0.504, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.978, 10.146], loss: 0.001416, mae: 0.041058, mean_q: 1.168369
 287200/1000000: episode: 2872, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.744, mean reward: 0.597 [0.509, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.584, 10.228], loss: 0.001491, mae: 0.042553, mean_q: 1.168596
 287300/1000000: episode: 2873, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.347, mean reward: 0.563 [0.500, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.116, 10.217], loss: 0.001501, mae: 0.041488, mean_q: 1.165153
 287400/1000000: episode: 2874, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.680, mean reward: 0.567 [0.500, 0.662], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.855, 10.098], loss: 0.001680, mae: 0.044299, mean_q: 1.168530
 287500/1000000: episode: 2875, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.189, mean reward: 0.592 [0.509, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.849, 10.190], loss: 0.001414, mae: 0.041377, mean_q: 1.167425
 287600/1000000: episode: 2876, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.544, mean reward: 0.595 [0.512, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.910, 10.098], loss: 0.001536, mae: 0.043213, mean_q: 1.169194
 287700/1000000: episode: 2877, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.881, mean reward: 0.589 [0.499, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.510, 10.202], loss: 0.001460, mae: 0.041868, mean_q: 1.167915
 287800/1000000: episode: 2878, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.658, mean reward: 0.577 [0.498, 0.882], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.869, 10.205], loss: 0.001420, mae: 0.040992, mean_q: 1.165464
 287900/1000000: episode: 2879, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.600, mean reward: 0.576 [0.498, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.152, 10.098], loss: 0.001565, mae: 0.042608, mean_q: 1.167010
 288000/1000000: episode: 2880, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 67.898, mean reward: 0.679 [0.511, 0.872], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.396, 10.379], loss: 0.001496, mae: 0.042343, mean_q: 1.169511
 288100/1000000: episode: 2881, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.736, mean reward: 0.607 [0.510, 0.868], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.033, 10.307], loss: 0.001449, mae: 0.042038, mean_q: 1.169066
 288200/1000000: episode: 2882, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.619, mean reward: 0.586 [0.506, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.843, 10.187], loss: 0.001393, mae: 0.041237, mean_q: 1.170662
 288300/1000000: episode: 2883, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.991, mean reward: 0.590 [0.498, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.216, 10.233], loss: 0.001460, mae: 0.041468, mean_q: 1.169829
 288400/1000000: episode: 2884, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.659, mean reward: 0.577 [0.507, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.763, 10.150], loss: 0.001520, mae: 0.042490, mean_q: 1.169106
 288500/1000000: episode: 2885, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.356, mean reward: 0.574 [0.509, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.732, 10.106], loss: 0.001503, mae: 0.041938, mean_q: 1.167813
 288600/1000000: episode: 2886, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 58.364, mean reward: 0.584 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.804, 10.098], loss: 0.001414, mae: 0.041538, mean_q: 1.169271
 288700/1000000: episode: 2887, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.361, mean reward: 0.594 [0.517, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.441, 10.114], loss: 0.001446, mae: 0.041469, mean_q: 1.171144
 288800/1000000: episode: 2888, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.247, mean reward: 0.602 [0.517, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.995, 10.098], loss: 0.001474, mae: 0.041755, mean_q: 1.169556
 288900/1000000: episode: 2889, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.568, mean reward: 0.576 [0.501, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.333, 10.098], loss: 0.001537, mae: 0.042909, mean_q: 1.168200
 289000/1000000: episode: 2890, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.602, mean reward: 0.606 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.446, 10.098], loss: 0.001470, mae: 0.041919, mean_q: 1.168594
 289100/1000000: episode: 2891, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.645, mean reward: 0.606 [0.503, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.662, 10.098], loss: 0.001437, mae: 0.041856, mean_q: 1.169681
 289200/1000000: episode: 2892, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 60.919, mean reward: 0.609 [0.517, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.256, 10.098], loss: 0.001484, mae: 0.042016, mean_q: 1.167588
 289300/1000000: episode: 2893, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.335, mean reward: 0.593 [0.504, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.781, 10.234], loss: 0.001372, mae: 0.040330, mean_q: 1.169591
 289400/1000000: episode: 2894, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.396, mean reward: 0.594 [0.505, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.711, 10.145], loss: 0.001437, mae: 0.041363, mean_q: 1.167946
 289500/1000000: episode: 2895, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.729, mean reward: 0.587 [0.501, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.584, 10.228], loss: 0.001462, mae: 0.041382, mean_q: 1.168493
 289600/1000000: episode: 2896, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.964, mean reward: 0.600 [0.514, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.130, 10.098], loss: 0.001492, mae: 0.042258, mean_q: 1.171224
 289700/1000000: episode: 2897, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.487, mean reward: 0.585 [0.506, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.735, 10.145], loss: 0.001474, mae: 0.042230, mean_q: 1.167733
 289800/1000000: episode: 2898, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.085, mean reward: 0.591 [0.500, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.164, 10.098], loss: 0.001491, mae: 0.042246, mean_q: 1.168549
 289900/1000000: episode: 2899, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.065, mean reward: 0.581 [0.503, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.842, 10.098], loss: 0.001487, mae: 0.042213, mean_q: 1.170192
 290000/1000000: episode: 2900, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.869, mean reward: 0.589 [0.507, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.114, 10.098], loss: 0.001535, mae: 0.042777, mean_q: 1.167402
 290100/1000000: episode: 2901, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.264, mean reward: 0.573 [0.499, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.422, 10.138], loss: 0.001384, mae: 0.040653, mean_q: 1.165545
 290200/1000000: episode: 2902, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.327, mean reward: 0.573 [0.499, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.911, 10.098], loss: 0.001458, mae: 0.041902, mean_q: 1.167621
 290300/1000000: episode: 2903, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.143, mean reward: 0.571 [0.501, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.231, 10.332], loss: 0.001488, mae: 0.041811, mean_q: 1.170087
 290400/1000000: episode: 2904, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.441, mean reward: 0.574 [0.508, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.668, 10.098], loss: 0.001465, mae: 0.041748, mean_q: 1.165677
 290500/1000000: episode: 2905, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.084, mean reward: 0.571 [0.506, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.648, 10.106], loss: 0.001519, mae: 0.042242, mean_q: 1.167360
 290600/1000000: episode: 2906, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.512, mean reward: 0.575 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.115, 10.110], loss: 0.001441, mae: 0.040880, mean_q: 1.164919
 290700/1000000: episode: 2907, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.715, mean reward: 0.577 [0.506, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.410, 10.123], loss: 0.001503, mae: 0.041854, mean_q: 1.166395
 290800/1000000: episode: 2908, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.205, mean reward: 0.582 [0.500, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.263, 10.098], loss: 0.001465, mae: 0.041345, mean_q: 1.166283
 290900/1000000: episode: 2909, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 56.846, mean reward: 0.568 [0.498, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.749, 10.098], loss: 0.001349, mae: 0.040307, mean_q: 1.165951
 291000/1000000: episode: 2910, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.142, mean reward: 0.571 [0.503, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.802, 10.105], loss: 0.001422, mae: 0.040881, mean_q: 1.163900
 291100/1000000: episode: 2911, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.963, mean reward: 0.600 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.586, 10.098], loss: 0.001459, mae: 0.041679, mean_q: 1.160963
 291200/1000000: episode: 2912, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.576, mean reward: 0.576 [0.500, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.902, 10.098], loss: 0.001530, mae: 0.042805, mean_q: 1.161770
 291300/1000000: episode: 2913, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.238, mean reward: 0.602 [0.508, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.335, 10.098], loss: 0.001446, mae: 0.040976, mean_q: 1.162164
 291400/1000000: episode: 2914, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.088, mean reward: 0.571 [0.501, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.186, 10.098], loss: 0.001432, mae: 0.040943, mean_q: 1.158240
 291500/1000000: episode: 2915, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.460, mean reward: 0.585 [0.500, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.404, 10.098], loss: 0.001441, mae: 0.041008, mean_q: 1.161969
 291600/1000000: episode: 2916, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.183, mean reward: 0.572 [0.505, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.343, 10.098], loss: 0.001396, mae: 0.040374, mean_q: 1.159981
 291700/1000000: episode: 2917, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.579, mean reward: 0.606 [0.508, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.810, 10.098], loss: 0.001418, mae: 0.040435, mean_q: 1.159595
 291800/1000000: episode: 2918, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.286, mean reward: 0.573 [0.503, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.321, 10.239], loss: 0.001365, mae: 0.039760, mean_q: 1.160853
 291900/1000000: episode: 2919, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 56.940, mean reward: 0.569 [0.499, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.996, 10.135], loss: 0.001441, mae: 0.041060, mean_q: 1.162820
 292000/1000000: episode: 2920, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.223, mean reward: 0.592 [0.519, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.585, 10.098], loss: 0.001377, mae: 0.040050, mean_q: 1.160202
 292100/1000000: episode: 2921, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.527, mean reward: 0.575 [0.505, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.693, 10.126], loss: 0.001453, mae: 0.041302, mean_q: 1.159285
 292200/1000000: episode: 2922, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.166, mean reward: 0.572 [0.503, 0.662], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.549, 10.142], loss: 0.001389, mae: 0.040533, mean_q: 1.158638
 292300/1000000: episode: 2923, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.617, mean reward: 0.576 [0.507, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.681, 10.137], loss: 0.001296, mae: 0.039507, mean_q: 1.157365
 292400/1000000: episode: 2924, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.724, mean reward: 0.587 [0.504, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.776, 10.184], loss: 0.001405, mae: 0.040529, mean_q: 1.161123
 292500/1000000: episode: 2925, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.845, mean reward: 0.578 [0.504, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.812, 10.098], loss: 0.001353, mae: 0.039559, mean_q: 1.159490
 292600/1000000: episode: 2926, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.851, mean reward: 0.599 [0.503, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.354, 10.458], loss: 0.001307, mae: 0.038674, mean_q: 1.159637
 292700/1000000: episode: 2927, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.253, mean reward: 0.573 [0.504, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.827, 10.098], loss: 0.001464, mae: 0.041315, mean_q: 1.160656
 292800/1000000: episode: 2928, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.872, mean reward: 0.599 [0.503, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.768, 10.098], loss: 0.001346, mae: 0.039603, mean_q: 1.161211
 292900/1000000: episode: 2929, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.525, mean reward: 0.585 [0.505, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.252, 10.098], loss: 0.001386, mae: 0.040179, mean_q: 1.160892
 293000/1000000: episode: 2930, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 61.518, mean reward: 0.615 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.414, 10.278], loss: 0.001316, mae: 0.039828, mean_q: 1.156381
 293100/1000000: episode: 2931, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.494, mean reward: 0.595 [0.498, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.704, 10.365], loss: 0.001395, mae: 0.040741, mean_q: 1.154601
 293200/1000000: episode: 2932, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 62.269, mean reward: 0.623 [0.499, 0.966], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.270, 10.098], loss: 0.001512, mae: 0.042240, mean_q: 1.157300
 293300/1000000: episode: 2933, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.545, mean reward: 0.565 [0.501, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.601, 10.197], loss: 0.001366, mae: 0.040198, mean_q: 1.158782
 293400/1000000: episode: 2934, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.053, mean reward: 0.581 [0.498, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.687, 10.098], loss: 0.001393, mae: 0.040394, mean_q: 1.158567
 293500/1000000: episode: 2935, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.902, mean reward: 0.599 [0.513, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.188, 10.374], loss: 0.001440, mae: 0.041421, mean_q: 1.156851
 293600/1000000: episode: 2936, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.519, mean reward: 0.575 [0.503, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.583, 10.231], loss: 0.001451, mae: 0.041112, mean_q: 1.158017
 293700/1000000: episode: 2937, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.783, mean reward: 0.588 [0.513, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.499, 10.098], loss: 0.001472, mae: 0.041724, mean_q: 1.160038
 293800/1000000: episode: 2938, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.702, mean reward: 0.587 [0.509, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.479, 10.098], loss: 0.001401, mae: 0.040415, mean_q: 1.155381
 293900/1000000: episode: 2939, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.655, mean reward: 0.587 [0.509, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.803, 10.182], loss: 0.001500, mae: 0.041787, mean_q: 1.158268
 294000/1000000: episode: 2940, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.112, mean reward: 0.591 [0.503, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.184, 10.230], loss: 0.001376, mae: 0.040262, mean_q: 1.158348
 294100/1000000: episode: 2941, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.492, mean reward: 0.585 [0.502, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.841, 10.098], loss: 0.001368, mae: 0.040867, mean_q: 1.155050
 294200/1000000: episode: 2942, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.932, mean reward: 0.609 [0.500, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.159, 10.376], loss: 0.001326, mae: 0.040036, mean_q: 1.157196
 294300/1000000: episode: 2943, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.163, mean reward: 0.582 [0.500, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.511, 10.140], loss: 0.001482, mae: 0.041319, mean_q: 1.157881
 294400/1000000: episode: 2944, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 56.534, mean reward: 0.565 [0.502, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.678, 10.154], loss: 0.001383, mae: 0.041094, mean_q: 1.158528
 294500/1000000: episode: 2945, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.360, mean reward: 0.604 [0.510, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.869, 10.098], loss: 0.001355, mae: 0.039970, mean_q: 1.156588
 294600/1000000: episode: 2946, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.019, mean reward: 0.580 [0.508, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.365, 10.120], loss: 0.001438, mae: 0.041054, mean_q: 1.156587
 294700/1000000: episode: 2947, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.886, mean reward: 0.619 [0.526, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.162, 10.236], loss: 0.001360, mae: 0.039404, mean_q: 1.152986
 294800/1000000: episode: 2948, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.495, mean reward: 0.575 [0.506, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.631, 10.098], loss: 0.001367, mae: 0.040675, mean_q: 1.154486
 294900/1000000: episode: 2949, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.625, mean reward: 0.606 [0.508, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.700, 10.342], loss: 0.001437, mae: 0.041153, mean_q: 1.155978
 295000/1000000: episode: 2950, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.345, mean reward: 0.603 [0.497, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.814, 10.098], loss: 0.001328, mae: 0.040055, mean_q: 1.156876
 295100/1000000: episode: 2951, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.980, mean reward: 0.590 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.440, 10.098], loss: 0.001474, mae: 0.041296, mean_q: 1.158615
 295200/1000000: episode: 2952, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.928, mean reward: 0.599 [0.504, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.766, 10.098], loss: 0.001438, mae: 0.041081, mean_q: 1.159087
 295300/1000000: episode: 2953, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.697, mean reward: 0.607 [0.503, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.575, 10.098], loss: 0.001385, mae: 0.040573, mean_q: 1.160567
 295400/1000000: episode: 2954, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.075, mean reward: 0.591 [0.509, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.907, 10.243], loss: 0.001402, mae: 0.040396, mean_q: 1.157624
 295500/1000000: episode: 2955, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.460, mean reward: 0.575 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.069, 10.227], loss: 0.001442, mae: 0.041604, mean_q: 1.162953
 295600/1000000: episode: 2956, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 61.881, mean reward: 0.619 [0.499, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.046, 10.098], loss: 0.001342, mae: 0.039715, mean_q: 1.162123
 295700/1000000: episode: 2957, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.813, mean reward: 0.598 [0.507, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.669, 10.098], loss: 0.001383, mae: 0.040232, mean_q: 1.160849
 295800/1000000: episode: 2958, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.813, mean reward: 0.588 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.791, 10.098], loss: 0.001462, mae: 0.041384, mean_q: 1.164686
 295900/1000000: episode: 2959, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.966, mean reward: 0.580 [0.507, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.417, 10.333], loss: 0.001549, mae: 0.042294, mean_q: 1.169063
 296000/1000000: episode: 2960, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.910, mean reward: 0.579 [0.503, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.511, 10.098], loss: 0.001451, mae: 0.041536, mean_q: 1.167297
 296100/1000000: episode: 2961, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.786, mean reward: 0.608 [0.503, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.699, 10.332], loss: 0.001495, mae: 0.042111, mean_q: 1.164884
 296200/1000000: episode: 2962, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.990, mean reward: 0.580 [0.501, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.070, 10.098], loss: 0.001413, mae: 0.040616, mean_q: 1.163647
 296300/1000000: episode: 2963, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.358, mean reward: 0.584 [0.501, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.472, 10.098], loss: 0.001417, mae: 0.041078, mean_q: 1.164941
 296400/1000000: episode: 2964, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.492, mean reward: 0.575 [0.505, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.973, 10.098], loss: 0.001479, mae: 0.041330, mean_q: 1.167157
 296500/1000000: episode: 2965, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 62.935, mean reward: 0.629 [0.513, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.850, 10.098], loss: 0.001402, mae: 0.040539, mean_q: 1.166043
 296600/1000000: episode: 2966, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 60.350, mean reward: 0.604 [0.518, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.889, 10.201], loss: 0.001493, mae: 0.041921, mean_q: 1.164226
 296700/1000000: episode: 2967, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 57.437, mean reward: 0.574 [0.499, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.210, 10.209], loss: 0.001481, mae: 0.042040, mean_q: 1.164810
 296800/1000000: episode: 2968, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.988, mean reward: 0.600 [0.501, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.122, 10.232], loss: 0.001579, mae: 0.043178, mean_q: 1.167968
 296900/1000000: episode: 2969, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.210, mean reward: 0.592 [0.505, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.394, 10.098], loss: 0.001531, mae: 0.042496, mean_q: 1.169700
 297000/1000000: episode: 2970, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.770, mean reward: 0.588 [0.503, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.421, 10.178], loss: 0.001535, mae: 0.042802, mean_q: 1.168839
 297100/1000000: episode: 2971, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.530, mean reward: 0.585 [0.507, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.676, 10.190], loss: 0.001431, mae: 0.041015, mean_q: 1.168959
 297200/1000000: episode: 2972, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.608, mean reward: 0.566 [0.498, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.499, 10.142], loss: 0.001594, mae: 0.043333, mean_q: 1.170129
 297300/1000000: episode: 2973, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.042, mean reward: 0.580 [0.511, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.665, 10.098], loss: 0.001505, mae: 0.041952, mean_q: 1.172224
 297400/1000000: episode: 2974, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 56.210, mean reward: 0.562 [0.502, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.537, 10.098], loss: 0.001570, mae: 0.043413, mean_q: 1.171958
 297500/1000000: episode: 2975, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.058, mean reward: 0.571 [0.503, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.631, 10.329], loss: 0.001406, mae: 0.040816, mean_q: 1.167523
 297600/1000000: episode: 2976, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.917, mean reward: 0.619 [0.506, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.090, 10.363], loss: 0.001511, mae: 0.042771, mean_q: 1.167214
 297700/1000000: episode: 2977, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.778, mean reward: 0.598 [0.499, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.100, 10.098], loss: 0.001383, mae: 0.041190, mean_q: 1.169578
 297800/1000000: episode: 2978, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.516, mean reward: 0.605 [0.503, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.163, 10.098], loss: 0.001522, mae: 0.042614, mean_q: 1.170195
 297900/1000000: episode: 2979, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.546, mean reward: 0.585 [0.501, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.347, 10.098], loss: 0.001313, mae: 0.039266, mean_q: 1.168416
 298000/1000000: episode: 2980, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 62.377, mean reward: 0.624 [0.521, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.410, 10.378], loss: 0.001526, mae: 0.042544, mean_q: 1.171298
 298100/1000000: episode: 2981, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.989, mean reward: 0.590 [0.514, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.343, 10.203], loss: 0.001480, mae: 0.042567, mean_q: 1.168441
 298200/1000000: episode: 2982, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.395, mean reward: 0.614 [0.512, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.581, 10.480], loss: 0.001426, mae: 0.041757, mean_q: 1.168499
 298300/1000000: episode: 2983, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.146, mean reward: 0.591 [0.508, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.854, 10.098], loss: 0.001442, mae: 0.040987, mean_q: 1.165903
 298400/1000000: episode: 2984, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 58.793, mean reward: 0.588 [0.509, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.399, 10.098], loss: 0.001482, mae: 0.042050, mean_q: 1.170959
 298500/1000000: episode: 2985, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.320, mean reward: 0.573 [0.503, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.514, 10.098], loss: 0.001482, mae: 0.041895, mean_q: 1.169493
 298600/1000000: episode: 2986, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.848, mean reward: 0.598 [0.512, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.719, 10.098], loss: 0.001528, mae: 0.042961, mean_q: 1.172948
 298700/1000000: episode: 2987, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 60.155, mean reward: 0.602 [0.510, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.052, 10.297], loss: 0.001457, mae: 0.041908, mean_q: 1.175784
 298800/1000000: episode: 2988, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.049, mean reward: 0.600 [0.505, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.459, 10.098], loss: 0.001455, mae: 0.041519, mean_q: 1.172772
 298900/1000000: episode: 2989, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.534, mean reward: 0.575 [0.497, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.671, 10.098], loss: 0.001380, mae: 0.040591, mean_q: 1.169892
 299000/1000000: episode: 2990, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.905, mean reward: 0.589 [0.512, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.961, 10.240], loss: 0.001498, mae: 0.042163, mean_q: 1.171033
 299100/1000000: episode: 2991, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.461, mean reward: 0.575 [0.499, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.970, 10.158], loss: 0.001403, mae: 0.040726, mean_q: 1.167837
 299200/1000000: episode: 2992, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.731, mean reward: 0.587 [0.507, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.931, 10.272], loss: 0.001473, mae: 0.041365, mean_q: 1.172416
 299300/1000000: episode: 2993, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 61.218, mean reward: 0.612 [0.508, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.657, 10.223], loss: 0.001532, mae: 0.043579, mean_q: 1.171770
 299400/1000000: episode: 2994, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.945, mean reward: 0.589 [0.507, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.884, 10.128], loss: 0.001352, mae: 0.040036, mean_q: 1.166904
 299500/1000000: episode: 2995, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.726, mean reward: 0.587 [0.502, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.661, 10.098], loss: 0.001440, mae: 0.041182, mean_q: 1.171507
 299600/1000000: episode: 2996, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.511, mean reward: 0.585 [0.497, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.023, 10.339], loss: 0.001511, mae: 0.042291, mean_q: 1.170635
 299700/1000000: episode: 2997, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.954, mean reward: 0.570 [0.500, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.756, 10.098], loss: 0.001466, mae: 0.041816, mean_q: 1.169790
 299800/1000000: episode: 2998, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.198, mean reward: 0.602 [0.514, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.704, 10.098], loss: 0.001460, mae: 0.041215, mean_q: 1.167728
 299900/1000000: episode: 2999, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.315, mean reward: 0.583 [0.503, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.657, 10.123], loss: 0.001489, mae: 0.042235, mean_q: 1.169963
 300000/1000000: episode: 3000, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 58.943, mean reward: 0.589 [0.508, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.272, 10.275], loss: 0.001445, mae: 0.041797, mean_q: 1.170892
 300100/1000000: episode: 3001, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.848, mean reward: 0.588 [0.500, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.228, 10.098], loss: 0.001492, mae: 0.041711, mean_q: 1.169162
 300200/1000000: episode: 3002, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.125, mean reward: 0.561 [0.500, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.791, 10.106], loss: 0.001477, mae: 0.041563, mean_q: 1.171164
 300300/1000000: episode: 3003, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 59.363, mean reward: 0.594 [0.513, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.003, 10.236], loss: 0.001540, mae: 0.042414, mean_q: 1.170317
 300400/1000000: episode: 3004, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.422, mean reward: 0.584 [0.503, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.275, 10.098], loss: 0.001582, mae: 0.042767, mean_q: 1.168225
 300500/1000000: episode: 3005, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.123, mean reward: 0.591 [0.504, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.531, 10.098], loss: 0.001542, mae: 0.042702, mean_q: 1.169363
 300600/1000000: episode: 3006, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.456, mean reward: 0.605 [0.501, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.536, 10.134], loss: 0.001461, mae: 0.041789, mean_q: 1.168012
 300700/1000000: episode: 3007, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.395, mean reward: 0.604 [0.502, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.982, 10.194], loss: 0.001456, mae: 0.041512, mean_q: 1.164344
 300800/1000000: episode: 3008, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.306, mean reward: 0.603 [0.511, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.299, 10.321], loss: 0.001521, mae: 0.042784, mean_q: 1.167209
 300900/1000000: episode: 3009, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.525, mean reward: 0.585 [0.499, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.680, 10.098], loss: 0.001437, mae: 0.040957, mean_q: 1.166926
 301000/1000000: episode: 3010, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.626, mean reward: 0.586 [0.515, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.771, 10.098], loss: 0.001471, mae: 0.042134, mean_q: 1.167449
 301100/1000000: episode: 3011, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.778, mean reward: 0.578 [0.507, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.634, 10.098], loss: 0.001414, mae: 0.041059, mean_q: 1.166394
 301200/1000000: episode: 3012, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.847, mean reward: 0.578 [0.513, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.458, 10.221], loss: 0.001369, mae: 0.040589, mean_q: 1.165712
 301300/1000000: episode: 3013, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.242, mean reward: 0.582 [0.507, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.385, 10.171], loss: 0.001451, mae: 0.041571, mean_q: 1.167239
 301400/1000000: episode: 3014, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.295, mean reward: 0.603 [0.500, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.724, 10.098], loss: 0.001492, mae: 0.042034, mean_q: 1.167120
 301500/1000000: episode: 3015, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 57.905, mean reward: 0.579 [0.500, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.953, 10.275], loss: 0.001515, mae: 0.042330, mean_q: 1.166982
 301600/1000000: episode: 3016, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.224, mean reward: 0.602 [0.512, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.311, 10.292], loss: 0.001541, mae: 0.042670, mean_q: 1.168556
 301700/1000000: episode: 3017, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.741, mean reward: 0.597 [0.502, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.645, 10.101], loss: 0.001524, mae: 0.042458, mean_q: 1.168337
 301800/1000000: episode: 3018, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.541, mean reward: 0.575 [0.502, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.364, 10.103], loss: 0.001524, mae: 0.042638, mean_q: 1.167005
 301900/1000000: episode: 3019, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.935, mean reward: 0.589 [0.508, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.356, 10.281], loss: 0.001510, mae: 0.041896, mean_q: 1.167604
 302000/1000000: episode: 3020, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.919, mean reward: 0.609 [0.514, 0.893], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.649, 10.098], loss: 0.001537, mae: 0.042111, mean_q: 1.167875
 302100/1000000: episode: 3021, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.373, mean reward: 0.584 [0.506, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.627, 10.103], loss: 0.001569, mae: 0.043171, mean_q: 1.169163
 302200/1000000: episode: 3022, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.063, mean reward: 0.601 [0.502, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.323, 10.438], loss: 0.001436, mae: 0.041307, mean_q: 1.164366
 302300/1000000: episode: 3023, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 63.741, mean reward: 0.637 [0.507, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.747, 10.545], loss: 0.001517, mae: 0.042155, mean_q: 1.167486
 302400/1000000: episode: 3024, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.265, mean reward: 0.573 [0.506, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.224, 10.127], loss: 0.001513, mae: 0.042101, mean_q: 1.170995
 302500/1000000: episode: 3025, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 62.613, mean reward: 0.626 [0.528, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.109, 10.395], loss: 0.001525, mae: 0.042131, mean_q: 1.172405
 302600/1000000: episode: 3026, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.275, mean reward: 0.573 [0.507, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.603, 10.208], loss: 0.001535, mae: 0.042886, mean_q: 1.170640
 302700/1000000: episode: 3027, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.617, mean reward: 0.576 [0.505, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.979, 10.105], loss: 0.001619, mae: 0.043560, mean_q: 1.167429
 302800/1000000: episode: 3028, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 62.685, mean reward: 0.627 [0.516, 0.938], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.277, 10.281], loss: 0.001461, mae: 0.041614, mean_q: 1.170102
 302900/1000000: episode: 3029, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.674, mean reward: 0.587 [0.501, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.623, 10.098], loss: 0.001571, mae: 0.043024, mean_q: 1.173533
 303000/1000000: episode: 3030, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.323, mean reward: 0.573 [0.500, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.165, 10.247], loss: 0.001506, mae: 0.042569, mean_q: 1.169510
 303100/1000000: episode: 3031, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 65.107, mean reward: 0.651 [0.502, 0.882], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.419, 10.098], loss: 0.001492, mae: 0.042369, mean_q: 1.172542
 303200/1000000: episode: 3032, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.965, mean reward: 0.580 [0.505, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.088, 10.098], loss: 0.001428, mae: 0.040964, mean_q: 1.174340
 303300/1000000: episode: 3033, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.775, mean reward: 0.598 [0.503, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.767, 10.098], loss: 0.001505, mae: 0.042466, mean_q: 1.171165
 303400/1000000: episode: 3034, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.307, mean reward: 0.573 [0.503, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.305, 10.289], loss: 0.001433, mae: 0.040880, mean_q: 1.168977
 303500/1000000: episode: 3035, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.680, mean reward: 0.587 [0.500, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.637, 10.098], loss: 0.001472, mae: 0.041774, mean_q: 1.170915
 303600/1000000: episode: 3036, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.714, mean reward: 0.577 [0.501, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.627, 10.106], loss: 0.001548, mae: 0.042181, mean_q: 1.169408
 303700/1000000: episode: 3037, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.312, mean reward: 0.583 [0.507, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.122, 10.114], loss: 0.001535, mae: 0.042333, mean_q: 1.170410
 303800/1000000: episode: 3038, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.744, mean reward: 0.577 [0.507, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.810, 10.118], loss: 0.001431, mae: 0.041157, mean_q: 1.170178
 303900/1000000: episode: 3039, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.420, mean reward: 0.594 [0.498, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.268, 10.098], loss: 0.001461, mae: 0.041311, mean_q: 1.168526
 304000/1000000: episode: 3040, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.745, mean reward: 0.597 [0.502, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.504, 10.098], loss: 0.001487, mae: 0.042365, mean_q: 1.171123
 304100/1000000: episode: 3041, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.731, mean reward: 0.587 [0.506, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.748, 10.296], loss: 0.001607, mae: 0.043368, mean_q: 1.170309
 304200/1000000: episode: 3042, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.248, mean reward: 0.582 [0.505, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.009, 10.098], loss: 0.001538, mae: 0.042417, mean_q: 1.172298
 304300/1000000: episode: 3043, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.943, mean reward: 0.579 [0.501, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.279, 10.218], loss: 0.001547, mae: 0.042509, mean_q: 1.169205
 304400/1000000: episode: 3044, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.347, mean reward: 0.583 [0.507, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.160, 10.098], loss: 0.001554, mae: 0.042576, mean_q: 1.165045
 304500/1000000: episode: 3045, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.834, mean reward: 0.598 [0.502, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.590, 10.324], loss: 0.001444, mae: 0.041131, mean_q: 1.167952
 304600/1000000: episode: 3046, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.639, mean reward: 0.586 [0.509, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.371, 10.098], loss: 0.001478, mae: 0.041730, mean_q: 1.167678
 304700/1000000: episode: 3047, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.275, mean reward: 0.583 [0.507, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.698, 10.111], loss: 0.001438, mae: 0.041214, mean_q: 1.166277
 304800/1000000: episode: 3048, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.207, mean reward: 0.602 [0.503, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.725, 10.098], loss: 0.001380, mae: 0.040402, mean_q: 1.166610
 304900/1000000: episode: 3049, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.969, mean reward: 0.580 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.694, 10.310], loss: 0.001462, mae: 0.041723, mean_q: 1.170065
 305000/1000000: episode: 3050, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.249, mean reward: 0.582 [0.501, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.778, 10.098], loss: 0.001494, mae: 0.041981, mean_q: 1.169432
 305100/1000000: episode: 3051, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.812, mean reward: 0.608 [0.503, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.729, 10.185], loss: 0.001439, mae: 0.040924, mean_q: 1.171147
 305200/1000000: episode: 3052, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.343, mean reward: 0.613 [0.502, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.011, 10.098], loss: 0.001457, mae: 0.041148, mean_q: 1.169552
 305300/1000000: episode: 3053, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.864, mean reward: 0.599 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.735, 10.290], loss: 0.001560, mae: 0.043019, mean_q: 1.170684
 305400/1000000: episode: 3054, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.886, mean reward: 0.569 [0.504, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.205, 10.102], loss: 0.001426, mae: 0.041104, mean_q: 1.172006
 305500/1000000: episode: 3055, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.892, mean reward: 0.589 [0.502, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.085, 10.106], loss: 0.001505, mae: 0.042065, mean_q: 1.170682
 305600/1000000: episode: 3056, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.956, mean reward: 0.590 [0.501, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.796, 10.098], loss: 0.001558, mae: 0.042629, mean_q: 1.173886
 305700/1000000: episode: 3057, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.690, mean reward: 0.577 [0.500, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.937, 10.116], loss: 0.001415, mae: 0.041131, mean_q: 1.171777
 305800/1000000: episode: 3058, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.597, mean reward: 0.596 [0.513, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.709, 10.098], loss: 0.001396, mae: 0.041229, mean_q: 1.165483
 305900/1000000: episode: 3059, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 57.410, mean reward: 0.574 [0.506, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.747, 10.169], loss: 0.001457, mae: 0.041827, mean_q: 1.166498
 306000/1000000: episode: 3060, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.963, mean reward: 0.610 [0.514, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.773, 10.277], loss: 0.001498, mae: 0.041150, mean_q: 1.169363
 306100/1000000: episode: 3061, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.332, mean reward: 0.603 [0.506, 0.855], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.250, 10.424], loss: 0.001404, mae: 0.040568, mean_q: 1.168220
 306200/1000000: episode: 3062, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.396, mean reward: 0.574 [0.501, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.268, 10.106], loss: 0.001435, mae: 0.041251, mean_q: 1.169623
 306300/1000000: episode: 3063, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.548, mean reward: 0.595 [0.513, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.169, 10.339], loss: 0.001499, mae: 0.042136, mean_q: 1.169675
 306400/1000000: episode: 3064, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.197, mean reward: 0.572 [0.505, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.797, 10.131], loss: 0.001416, mae: 0.040928, mean_q: 1.171101
 306500/1000000: episode: 3065, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.622, mean reward: 0.606 [0.499, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.087, 10.376], loss: 0.001430, mae: 0.041070, mean_q: 1.173004
 306600/1000000: episode: 3066, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.723, mean reward: 0.597 [0.505, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.009, 10.319], loss: 0.001453, mae: 0.041233, mean_q: 1.170343
 306700/1000000: episode: 3067, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.828, mean reward: 0.588 [0.517, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.077, 10.207], loss: 0.001475, mae: 0.041834, mean_q: 1.170475
 306800/1000000: episode: 3068, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.923, mean reward: 0.569 [0.510, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.441, 10.129], loss: 0.001442, mae: 0.040890, mean_q: 1.173490
 306900/1000000: episode: 3069, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.647, mean reward: 0.596 [0.513, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.267, 10.124], loss: 0.001432, mae: 0.040905, mean_q: 1.170163
 307000/1000000: episode: 3070, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 63.363, mean reward: 0.634 [0.510, 0.902], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.856, 10.098], loss: 0.001396, mae: 0.040752, mean_q: 1.172163
 307100/1000000: episode: 3071, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 63.001, mean reward: 0.630 [0.504, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.013, 10.137], loss: 0.001400, mae: 0.040626, mean_q: 1.170845
 307200/1000000: episode: 3072, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.786, mean reward: 0.588 [0.505, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.623, 10.239], loss: 0.001464, mae: 0.041586, mean_q: 1.170913
 307300/1000000: episode: 3073, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.500, mean reward: 0.615 [0.523, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.736, 10.098], loss: 0.001428, mae: 0.041712, mean_q: 1.171119
 307400/1000000: episode: 3074, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 62.418, mean reward: 0.624 [0.514, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.907, 10.098], loss: 0.001369, mae: 0.040633, mean_q: 1.169602
 307500/1000000: episode: 3075, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.506, mean reward: 0.575 [0.508, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.240, 10.098], loss: 0.001400, mae: 0.040352, mean_q: 1.170973
 307600/1000000: episode: 3076, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.830, mean reward: 0.618 [0.513, 0.892], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.718, 10.098], loss: 0.001383, mae: 0.040272, mean_q: 1.171305
 307700/1000000: episode: 3077, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.674, mean reward: 0.577 [0.508, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.834, 10.098], loss: 0.001435, mae: 0.040714, mean_q: 1.175089
 307800/1000000: episode: 3078, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.889, mean reward: 0.579 [0.500, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.775, 10.098], loss: 0.001469, mae: 0.040750, mean_q: 1.171560
 307900/1000000: episode: 3079, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.327, mean reward: 0.583 [0.511, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.205, 10.261], loss: 0.001388, mae: 0.040138, mean_q: 1.166453
 308000/1000000: episode: 3080, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.416, mean reward: 0.584 [0.499, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.637, 10.335], loss: 0.001439, mae: 0.041203, mean_q: 1.173342
 308100/1000000: episode: 3081, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.468, mean reward: 0.585 [0.507, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.525, 10.098], loss: 0.001482, mae: 0.041487, mean_q: 1.169669
 308200/1000000: episode: 3082, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.121, mean reward: 0.571 [0.502, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.713, 10.098], loss: 0.001385, mae: 0.040261, mean_q: 1.167375
 308300/1000000: episode: 3083, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.979, mean reward: 0.580 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.105, 10.098], loss: 0.001415, mae: 0.040664, mean_q: 1.170242
 308400/1000000: episode: 3084, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.550, mean reward: 0.586 [0.506, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.311, 10.199], loss: 0.001354, mae: 0.040085, mean_q: 1.172166
 308500/1000000: episode: 3085, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 57.314, mean reward: 0.573 [0.501, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.954, 10.104], loss: 0.001443, mae: 0.041672, mean_q: 1.167060
 308600/1000000: episode: 3086, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.426, mean reward: 0.614 [0.515, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.374, 10.098], loss: 0.001349, mae: 0.039494, mean_q: 1.169032
 308700/1000000: episode: 3087, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.483, mean reward: 0.585 [0.507, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.646, 10.143], loss: 0.001400, mae: 0.040338, mean_q: 1.171195
 308800/1000000: episode: 3088, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.004, mean reward: 0.600 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.874, 10.369], loss: 0.001390, mae: 0.040497, mean_q: 1.171730
 308900/1000000: episode: 3089, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.207, mean reward: 0.602 [0.516, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.032, 10.212], loss: 0.001448, mae: 0.041008, mean_q: 1.173542
 309000/1000000: episode: 3090, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 60.754, mean reward: 0.608 [0.509, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.458, 10.292], loss: 0.001436, mae: 0.040952, mean_q: 1.171967
 309100/1000000: episode: 3091, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.327, mean reward: 0.583 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.602, 10.098], loss: 0.001360, mae: 0.040548, mean_q: 1.172838
 309200/1000000: episode: 3092, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.981, mean reward: 0.590 [0.505, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.686, 10.313], loss: 0.001451, mae: 0.041243, mean_q: 1.171376
 309300/1000000: episode: 3093, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.681, mean reward: 0.577 [0.505, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.872, 10.296], loss: 0.001394, mae: 0.040696, mean_q: 1.173144
 309400/1000000: episode: 3094, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.238, mean reward: 0.572 [0.509, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.346, 10.098], loss: 0.001496, mae: 0.041921, mean_q: 1.172957
 309500/1000000: episode: 3095, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.968, mean reward: 0.580 [0.499, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.974, 10.149], loss: 0.001446, mae: 0.041161, mean_q: 1.175209
 309600/1000000: episode: 3096, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.497, mean reward: 0.595 [0.510, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.624, 10.098], loss: 0.001359, mae: 0.040021, mean_q: 1.171852
 309700/1000000: episode: 3097, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.611, mean reward: 0.586 [0.509, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.002, 10.098], loss: 0.001397, mae: 0.040701, mean_q: 1.170494
 309800/1000000: episode: 3098, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.210, mean reward: 0.562 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.480, 10.151], loss: 0.001487, mae: 0.041676, mean_q: 1.173907
 309900/1000000: episode: 3099, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 56.995, mean reward: 0.570 [0.501, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.739, 10.217], loss: 0.001449, mae: 0.041070, mean_q: 1.173528
 310000/1000000: episode: 3100, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.862, mean reward: 0.589 [0.507, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.992, 10.187], loss: 0.001475, mae: 0.041692, mean_q: 1.170113
 310100/1000000: episode: 3101, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.400, mean reward: 0.584 [0.498, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.515, 10.098], loss: 0.001353, mae: 0.039778, mean_q: 1.165463
 310200/1000000: episode: 3102, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.247, mean reward: 0.582 [0.500, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.567, 10.098], loss: 0.001428, mae: 0.041227, mean_q: 1.164870
 310300/1000000: episode: 3103, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 60.850, mean reward: 0.609 [0.508, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.544, 10.286], loss: 0.001459, mae: 0.041223, mean_q: 1.166389
 310400/1000000: episode: 3104, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.852, mean reward: 0.589 [0.515, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.927, 10.098], loss: 0.001474, mae: 0.041637, mean_q: 1.169663
 310500/1000000: episode: 3105, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.109, mean reward: 0.581 [0.508, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.933, 10.098], loss: 0.001500, mae: 0.041241, mean_q: 1.171580
 310600/1000000: episode: 3106, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.821, mean reward: 0.578 [0.501, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.601, 10.250], loss: 0.001401, mae: 0.040459, mean_q: 1.165043
 310700/1000000: episode: 3107, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.483, mean reward: 0.585 [0.503, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.115, 10.098], loss: 0.001343, mae: 0.039889, mean_q: 1.163537
 310800/1000000: episode: 3108, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.759, mean reward: 0.588 [0.502, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.114, 10.098], loss: 0.001462, mae: 0.041443, mean_q: 1.168923
 310900/1000000: episode: 3109, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.461, mean reward: 0.595 [0.499, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.372, 10.098], loss: 0.001430, mae: 0.040730, mean_q: 1.166952
 311000/1000000: episode: 3110, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 62.858, mean reward: 0.629 [0.505, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.342, 10.098], loss: 0.001422, mae: 0.040576, mean_q: 1.167256
 311100/1000000: episode: 3111, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.259, mean reward: 0.603 [0.510, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.437, 10.098], loss: 0.001411, mae: 0.040811, mean_q: 1.169868
 311200/1000000: episode: 3112, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.173, mean reward: 0.572 [0.502, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.708, 10.098], loss: 0.001414, mae: 0.040654, mean_q: 1.167315
 311300/1000000: episode: 3113, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.824, mean reward: 0.568 [0.500, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.587, 10.148], loss: 0.001386, mae: 0.040479, mean_q: 1.167645
 311400/1000000: episode: 3114, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.217, mean reward: 0.612 [0.522, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.516, 10.098], loss: 0.001342, mae: 0.039835, mean_q: 1.171079
 311500/1000000: episode: 3115, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.297, mean reward: 0.603 [0.499, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.288, 10.098], loss: 0.001389, mae: 0.040330, mean_q: 1.167768
 311600/1000000: episode: 3116, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.924, mean reward: 0.569 [0.507, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.957, 10.139], loss: 0.001415, mae: 0.040481, mean_q: 1.167225
 311700/1000000: episode: 3117, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.104, mean reward: 0.581 [0.505, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.744, 10.362], loss: 0.001526, mae: 0.041630, mean_q: 1.167897
 311800/1000000: episode: 3118, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.614, mean reward: 0.586 [0.503, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.712, 10.149], loss: 0.001430, mae: 0.041050, mean_q: 1.168929
 311900/1000000: episode: 3119, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 61.841, mean reward: 0.618 [0.523, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.004, 10.255], loss: 0.001431, mae: 0.040413, mean_q: 1.167295
 312000/1000000: episode: 3120, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.485, mean reward: 0.585 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.409, 10.205], loss: 0.001467, mae: 0.041115, mean_q: 1.167752
 312100/1000000: episode: 3121, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.606, mean reward: 0.586 [0.507, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.088, 10.257], loss: 0.001486, mae: 0.041172, mean_q: 1.168580
 312200/1000000: episode: 3122, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.749, mean reward: 0.577 [0.499, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.664, 10.098], loss: 0.001446, mae: 0.041168, mean_q: 1.162810
 312300/1000000: episode: 3123, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.509, mean reward: 0.585 [0.508, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.396, 10.126], loss: 0.001581, mae: 0.042713, mean_q: 1.165166
 312400/1000000: episode: 3124, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 61.999, mean reward: 0.620 [0.513, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.966, 10.408], loss: 0.001399, mae: 0.040062, mean_q: 1.160593
 312500/1000000: episode: 3125, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.197, mean reward: 0.572 [0.498, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.664, 10.126], loss: 0.001474, mae: 0.041228, mean_q: 1.163763
 312600/1000000: episode: 3126, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.291, mean reward: 0.573 [0.497, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.252, 10.098], loss: 0.001459, mae: 0.041322, mean_q: 1.160818
 312700/1000000: episode: 3127, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.406, mean reward: 0.584 [0.504, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.497, 10.287], loss: 0.001432, mae: 0.041195, mean_q: 1.158414
 312800/1000000: episode: 3128, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.630, mean reward: 0.586 [0.502, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.521, 10.161], loss: 0.001484, mae: 0.041509, mean_q: 1.164563
 312900/1000000: episode: 3129, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.946, mean reward: 0.579 [0.513, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.259, 10.158], loss: 0.001520, mae: 0.041647, mean_q: 1.163632
 313000/1000000: episode: 3130, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.299, mean reward: 0.573 [0.500, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.781, 10.098], loss: 0.001430, mae: 0.041340, mean_q: 1.161876
 313100/1000000: episode: 3131, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.290, mean reward: 0.593 [0.508, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.272, 10.098], loss: 0.001402, mae: 0.041263, mean_q: 1.162080
 313200/1000000: episode: 3132, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.509, mean reward: 0.575 [0.499, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.621, 10.098], loss: 0.001407, mae: 0.041011, mean_q: 1.160638
 313300/1000000: episode: 3133, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.411, mean reward: 0.574 [0.504, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.707, 10.197], loss: 0.001531, mae: 0.042393, mean_q: 1.159318
 313400/1000000: episode: 3134, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.472, mean reward: 0.585 [0.499, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.383, 10.269], loss: 0.001465, mae: 0.041624, mean_q: 1.164067
 313500/1000000: episode: 3135, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.570, mean reward: 0.576 [0.503, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.175, 10.293], loss: 0.001539, mae: 0.042795, mean_q: 1.161549
 313600/1000000: episode: 3136, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.148, mean reward: 0.601 [0.511, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.456, 10.098], loss: 0.001464, mae: 0.041953, mean_q: 1.158868
 313700/1000000: episode: 3137, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.708, mean reward: 0.587 [0.500, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.911, 10.098], loss: 0.001529, mae: 0.042401, mean_q: 1.163543
 313800/1000000: episode: 3138, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.545, mean reward: 0.575 [0.508, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.555, 10.098], loss: 0.001461, mae: 0.041769, mean_q: 1.162549
 313900/1000000: episode: 3139, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.364, mean reward: 0.594 [0.504, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.879, 10.119], loss: 0.001430, mae: 0.040970, mean_q: 1.155659
 314000/1000000: episode: 3140, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.696, mean reward: 0.577 [0.505, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.038, 10.098], loss: 0.001444, mae: 0.041070, mean_q: 1.156644
 314100/1000000: episode: 3141, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.823, mean reward: 0.598 [0.505, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.835, 10.098], loss: 0.001455, mae: 0.041668, mean_q: 1.159397
 314200/1000000: episode: 3142, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.529, mean reward: 0.595 [0.502, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.793, 10.098], loss: 0.001475, mae: 0.041455, mean_q: 1.159134
 314300/1000000: episode: 3143, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.659, mean reward: 0.567 [0.500, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.053, 10.126], loss: 0.001612, mae: 0.043512, mean_q: 1.159763
 314400/1000000: episode: 3144, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.052, mean reward: 0.591 [0.505, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-2.007, 10.098], loss: 0.001452, mae: 0.041563, mean_q: 1.159395
 314500/1000000: episode: 3145, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.750, mean reward: 0.587 [0.507, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.549, 10.098], loss: 0.001544, mae: 0.043181, mean_q: 1.160688
 314600/1000000: episode: 3146, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 60.165, mean reward: 0.602 [0.506, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.257, 10.408], loss: 0.001484, mae: 0.041868, mean_q: 1.161023
 314700/1000000: episode: 3147, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.881, mean reward: 0.569 [0.501, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.861, 10.098], loss: 0.001499, mae: 0.042401, mean_q: 1.159712
 314800/1000000: episode: 3148, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.678, mean reward: 0.587 [0.505, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.922, 10.098], loss: 0.001438, mae: 0.041503, mean_q: 1.161549
 314900/1000000: episode: 3149, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.929, mean reward: 0.579 [0.499, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.156, 10.098], loss: 0.001435, mae: 0.041411, mean_q: 1.161279
 315000/1000000: episode: 3150, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.520, mean reward: 0.575 [0.505, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.449, 10.210], loss: 0.001474, mae: 0.041619, mean_q: 1.163695
 315100/1000000: episode: 3151, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.618, mean reward: 0.586 [0.500, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.933, 10.098], loss: 0.001484, mae: 0.041682, mean_q: 1.159836
 315200/1000000: episode: 3152, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.925, mean reward: 0.599 [0.506, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.470, 10.496], loss: 0.001433, mae: 0.041369, mean_q: 1.160504
 315300/1000000: episode: 3153, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 56.942, mean reward: 0.569 [0.502, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.259, 10.102], loss: 0.001425, mae: 0.040895, mean_q: 1.158640
 315400/1000000: episode: 3154, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.058, mean reward: 0.581 [0.514, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.288, 10.146], loss: 0.001523, mae: 0.042713, mean_q: 1.158372
 315500/1000000: episode: 3155, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.669, mean reward: 0.587 [0.509, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.848, 10.098], loss: 0.001524, mae: 0.042504, mean_q: 1.160021
 315600/1000000: episode: 3156, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.315, mean reward: 0.593 [0.502, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.876, 10.098], loss: 0.001429, mae: 0.041209, mean_q: 1.159457
 315700/1000000: episode: 3157, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 57.981, mean reward: 0.580 [0.517, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.293, 10.110], loss: 0.001417, mae: 0.041250, mean_q: 1.160032
 315800/1000000: episode: 3158, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.039, mean reward: 0.570 [0.502, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.464, 10.125], loss: 0.001453, mae: 0.042087, mean_q: 1.160481
 315900/1000000: episode: 3159, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.513, mean reward: 0.575 [0.505, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.856, 10.098], loss: 0.001483, mae: 0.041913, mean_q: 1.159886
 316000/1000000: episode: 3160, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.837, mean reward: 0.578 [0.508, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.937, 10.098], loss: 0.001422, mae: 0.041530, mean_q: 1.156955
 316100/1000000: episode: 3161, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.513, mean reward: 0.575 [0.504, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.744, 10.237], loss: 0.001450, mae: 0.041241, mean_q: 1.154995
 316200/1000000: episode: 3162, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.730, mean reward: 0.617 [0.507, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.363, 10.098], loss: 0.001488, mae: 0.041860, mean_q: 1.156272
 316300/1000000: episode: 3163, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.403, mean reward: 0.574 [0.503, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.652, 10.261], loss: 0.001564, mae: 0.043164, mean_q: 1.155825
 316400/1000000: episode: 3164, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.929, mean reward: 0.579 [0.499, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.603, 10.098], loss: 0.001480, mae: 0.041923, mean_q: 1.153920
 316500/1000000: episode: 3165, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.956, mean reward: 0.580 [0.498, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.527, 10.166], loss: 0.001402, mae: 0.040940, mean_q: 1.152644
 316600/1000000: episode: 3166, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.575, mean reward: 0.596 [0.507, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.475, 10.098], loss: 0.001499, mae: 0.042275, mean_q: 1.158739
 316700/1000000: episode: 3167, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.438, mean reward: 0.564 [0.501, 0.659], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.763, 10.132], loss: 0.001553, mae: 0.043028, mean_q: 1.157777
 316800/1000000: episode: 3168, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.630, mean reward: 0.586 [0.502, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.270, 10.298], loss: 0.001447, mae: 0.041676, mean_q: 1.154025
 316900/1000000: episode: 3169, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.717, mean reward: 0.567 [0.500, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.123, 10.221], loss: 0.001473, mae: 0.042381, mean_q: 1.154508
 317000/1000000: episode: 3170, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.132, mean reward: 0.591 [0.504, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.711, 10.291], loss: 0.001444, mae: 0.041583, mean_q: 1.150883
 317100/1000000: episode: 3171, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.123, mean reward: 0.581 [0.510, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.208, 10.098], loss: 0.001463, mae: 0.041500, mean_q: 1.153226
 317200/1000000: episode: 3172, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 64.529, mean reward: 0.645 [0.503, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.133, 10.098], loss: 0.001483, mae: 0.042222, mean_q: 1.154502
 317300/1000000: episode: 3173, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.074, mean reward: 0.591 [0.512, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.250, 10.170], loss: 0.001486, mae: 0.042407, mean_q: 1.157917
 317400/1000000: episode: 3174, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.496, mean reward: 0.585 [0.500, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.445, 10.098], loss: 0.001403, mae: 0.040944, mean_q: 1.153694
 317500/1000000: episode: 3175, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.946, mean reward: 0.579 [0.508, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.424, 10.109], loss: 0.001406, mae: 0.041163, mean_q: 1.158377
 317600/1000000: episode: 3176, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.060, mean reward: 0.561 [0.499, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.347, 10.098], loss: 0.001493, mae: 0.041948, mean_q: 1.156171
 317700/1000000: episode: 3177, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.589, mean reward: 0.606 [0.513, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.783, 10.122], loss: 0.001359, mae: 0.040138, mean_q: 1.154419
 317800/1000000: episode: 3178, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.788, mean reward: 0.618 [0.503, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.857, 10.373], loss: 0.001390, mae: 0.040674, mean_q: 1.155744
 317900/1000000: episode: 3179, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.561, mean reward: 0.606 [0.503, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.613, 10.245], loss: 0.001419, mae: 0.041156, mean_q: 1.157502
 318000/1000000: episode: 3180, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.546, mean reward: 0.575 [0.498, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.459, 10.188], loss: 0.001475, mae: 0.041418, mean_q: 1.160135
 318100/1000000: episode: 3181, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.702, mean reward: 0.587 [0.502, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.094, 10.184], loss: 0.001352, mae: 0.040452, mean_q: 1.155513
 318200/1000000: episode: 3182, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.650, mean reward: 0.576 [0.507, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.890, 10.098], loss: 0.001409, mae: 0.040944, mean_q: 1.158183
 318300/1000000: episode: 3183, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.973, mean reward: 0.590 [0.504, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.958, 10.098], loss: 0.001459, mae: 0.041519, mean_q: 1.157930
 318400/1000000: episode: 3184, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.281, mean reward: 0.583 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.765, 10.240], loss: 0.001409, mae: 0.040827, mean_q: 1.157697
 318500/1000000: episode: 3185, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.122, mean reward: 0.611 [0.503, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.667, 10.098], loss: 0.001440, mae: 0.041046, mean_q: 1.158612
 318600/1000000: episode: 3186, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.441, mean reward: 0.574 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.949, 10.133], loss: 0.001583, mae: 0.043342, mean_q: 1.160908
 318700/1000000: episode: 3187, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.414, mean reward: 0.574 [0.503, 0.666], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.499, 10.098], loss: 0.001517, mae: 0.041953, mean_q: 1.160751
 318800/1000000: episode: 3188, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.083, mean reward: 0.571 [0.504, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.973, 10.098], loss: 0.001492, mae: 0.041813, mean_q: 1.155307
 318900/1000000: episode: 3189, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.533, mean reward: 0.585 [0.501, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.661, 10.098], loss: 0.001408, mae: 0.040470, mean_q: 1.155554
 319000/1000000: episode: 3190, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.528, mean reward: 0.585 [0.510, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.436, 10.311], loss: 0.001400, mae: 0.040880, mean_q: 1.157831
 319100/1000000: episode: 3191, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.399, mean reward: 0.594 [0.502, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.350, 10.337], loss: 0.001430, mae: 0.041174, mean_q: 1.158335
 319200/1000000: episode: 3192, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.803, mean reward: 0.598 [0.506, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.010, 10.401], loss: 0.001433, mae: 0.041348, mean_q: 1.159613
 319300/1000000: episode: 3193, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.705, mean reward: 0.577 [0.505, 0.872], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.925, 10.154], loss: 0.001459, mae: 0.041164, mean_q: 1.155411
 319400/1000000: episode: 3194, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.506, mean reward: 0.595 [0.510, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.262, 10.390], loss: 0.001495, mae: 0.042064, mean_q: 1.158595
 319500/1000000: episode: 3195, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.530, mean reward: 0.595 [0.502, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.985, 10.098], loss: 0.001376, mae: 0.040472, mean_q: 1.158514
 319600/1000000: episode: 3196, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.147, mean reward: 0.581 [0.500, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.121, 10.098], loss: 0.001392, mae: 0.040566, mean_q: 1.156259
 319700/1000000: episode: 3197, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.927, mean reward: 0.599 [0.505, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.826, 10.115], loss: 0.001527, mae: 0.042424, mean_q: 1.158375
 319800/1000000: episode: 3198, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.824, mean reward: 0.598 [0.500, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.703, 10.337], loss: 0.001530, mae: 0.042801, mean_q: 1.159359
 319900/1000000: episode: 3199, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.224, mean reward: 0.602 [0.515, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.766, 10.177], loss: 0.001313, mae: 0.039706, mean_q: 1.158236
 320000/1000000: episode: 3200, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.054, mean reward: 0.601 [0.504, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.693, 10.170], loss: 0.001454, mae: 0.041623, mean_q: 1.160128
 320100/1000000: episode: 3201, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.832, mean reward: 0.578 [0.505, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.304, 10.098], loss: 0.001473, mae: 0.041902, mean_q: 1.161613
 320200/1000000: episode: 3202, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.057, mean reward: 0.601 [0.508, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.448, 10.184], loss: 0.001474, mae: 0.041833, mean_q: 1.160255
 320300/1000000: episode: 3203, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.362, mean reward: 0.594 [0.503, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.212, 10.100], loss: 0.001479, mae: 0.041705, mean_q: 1.163662
 320400/1000000: episode: 3204, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.493, mean reward: 0.585 [0.500, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.863, 10.313], loss: 0.001401, mae: 0.040731, mean_q: 1.161696
 320500/1000000: episode: 3205, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.976, mean reward: 0.590 [0.509, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.382, 10.124], loss: 0.001357, mae: 0.040262, mean_q: 1.162681
 320600/1000000: episode: 3206, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.397, mean reward: 0.584 [0.507, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.853, 10.100], loss: 0.001440, mae: 0.041407, mean_q: 1.162363
 320700/1000000: episode: 3207, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.185, mean reward: 0.582 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.020, 10.193], loss: 0.001419, mae: 0.041448, mean_q: 1.165489
 320800/1000000: episode: 3208, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.689, mean reward: 0.577 [0.503, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.527, 10.098], loss: 0.001462, mae: 0.041661, mean_q: 1.164258
 320900/1000000: episode: 3209, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.781, mean reward: 0.578 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.854, 10.098], loss: 0.001376, mae: 0.040723, mean_q: 1.164014
 321000/1000000: episode: 3210, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.635, mean reward: 0.606 [0.509, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.539, 10.098], loss: 0.001525, mae: 0.042171, mean_q: 1.167329
 321100/1000000: episode: 3211, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 57.772, mean reward: 0.578 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.503, 10.135], loss: 0.001487, mae: 0.041530, mean_q: 1.162911
 321200/1000000: episode: 3212, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.312, mean reward: 0.583 [0.504, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.901, 10.383], loss: 0.001493, mae: 0.041814, mean_q: 1.167733
 321300/1000000: episode: 3213, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 62.635, mean reward: 0.626 [0.504, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.855, 10.495], loss: 0.001530, mae: 0.042440, mean_q: 1.160588
 321400/1000000: episode: 3214, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.791, mean reward: 0.578 [0.504, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.479, 10.098], loss: 0.001521, mae: 0.042121, mean_q: 1.168642
 321500/1000000: episode: 3215, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.764, mean reward: 0.598 [0.506, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.331, 10.494], loss: 0.001486, mae: 0.041700, mean_q: 1.166855
 321600/1000000: episode: 3216, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.882, mean reward: 0.609 [0.509, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.487, 10.448], loss: 0.001428, mae: 0.040797, mean_q: 1.164916
 321700/1000000: episode: 3217, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.251, mean reward: 0.583 [0.513, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.395, 10.131], loss: 0.001547, mae: 0.042289, mean_q: 1.164251
 321800/1000000: episode: 3218, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.824, mean reward: 0.598 [0.507, 0.893], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.124, 10.098], loss: 0.001427, mae: 0.041078, mean_q: 1.167245
 321900/1000000: episode: 3219, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.198, mean reward: 0.582 [0.503, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.265, 10.098], loss: 0.001441, mae: 0.041254, mean_q: 1.169044
 322000/1000000: episode: 3220, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.741, mean reward: 0.587 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.585, 10.243], loss: 0.001470, mae: 0.041544, mean_q: 1.166059
 322100/1000000: episode: 3221, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.302, mean reward: 0.603 [0.506, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.673, 10.147], loss: 0.001443, mae: 0.040956, mean_q: 1.163145
 322200/1000000: episode: 3222, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.941, mean reward: 0.569 [0.510, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.539, 10.098], loss: 0.001455, mae: 0.041175, mean_q: 1.162586
 322300/1000000: episode: 3223, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.508, mean reward: 0.595 [0.515, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.137, 10.172], loss: 0.001517, mae: 0.042631, mean_q: 1.165882
 322400/1000000: episode: 3224, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 56.882, mean reward: 0.569 [0.501, 0.866], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.500, 10.098], loss: 0.001439, mae: 0.040705, mean_q: 1.163325
 322500/1000000: episode: 3225, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.815, mean reward: 0.618 [0.516, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.820, 10.476], loss: 0.001483, mae: 0.041067, mean_q: 1.165181
 322600/1000000: episode: 3226, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 56.874, mean reward: 0.569 [0.498, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.117, 10.147], loss: 0.001565, mae: 0.042158, mean_q: 1.168744
 322700/1000000: episode: 3227, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.741, mean reward: 0.577 [0.502, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.072, 10.183], loss: 0.001490, mae: 0.041191, mean_q: 1.171225
 322800/1000000: episode: 3228, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.857, mean reward: 0.579 [0.498, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.428, 10.098], loss: 0.001452, mae: 0.041467, mean_q: 1.163648
 322900/1000000: episode: 3229, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.350, mean reward: 0.573 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.859, 10.098], loss: 0.001441, mae: 0.040927, mean_q: 1.164623
 323000/1000000: episode: 3230, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.323, mean reward: 0.603 [0.509, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.680, 10.278], loss: 0.001468, mae: 0.041891, mean_q: 1.166104
 323100/1000000: episode: 3231, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.875, mean reward: 0.579 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.360, 10.161], loss: 0.001429, mae: 0.040668, mean_q: 1.168150
 323200/1000000: episode: 3232, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.211, mean reward: 0.572 [0.512, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.940, 10.108], loss: 0.001464, mae: 0.041494, mean_q: 1.164453
 323300/1000000: episode: 3233, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.028, mean reward: 0.610 [0.506, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.615, 10.331], loss: 0.001448, mae: 0.041053, mean_q: 1.168224
 323400/1000000: episode: 3234, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.677, mean reward: 0.577 [0.503, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.340, 10.098], loss: 0.001423, mae: 0.039801, mean_q: 1.163395
 323500/1000000: episode: 3235, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.418, mean reward: 0.574 [0.505, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.900, 10.098], loss: 0.001452, mae: 0.040845, mean_q: 1.162478
 323600/1000000: episode: 3236, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 61.562, mean reward: 0.616 [0.504, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.649, 10.192], loss: 0.001571, mae: 0.042089, mean_q: 1.168302
 323700/1000000: episode: 3237, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.337, mean reward: 0.573 [0.499, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.132, 10.098], loss: 0.001514, mae: 0.042059, mean_q: 1.167847
 323800/1000000: episode: 3238, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.798, mean reward: 0.588 [0.503, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.957, 10.098], loss: 0.001422, mae: 0.040389, mean_q: 1.166724
 323900/1000000: episode: 3239, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.040, mean reward: 0.580 [0.501, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.034, 10.228], loss: 0.001423, mae: 0.040626, mean_q: 1.164644
 324000/1000000: episode: 3240, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.972, mean reward: 0.570 [0.501, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.690, 10.117], loss: 0.001378, mae: 0.039932, mean_q: 1.165250
 324100/1000000: episode: 3241, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 61.547, mean reward: 0.615 [0.506, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.494, 10.098], loss: 0.001430, mae: 0.040806, mean_q: 1.165874
 324200/1000000: episode: 3242, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.813, mean reward: 0.578 [0.509, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.681, 10.150], loss: 0.001489, mae: 0.041417, mean_q: 1.164703
 324300/1000000: episode: 3243, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.675, mean reward: 0.597 [0.515, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.991, 10.098], loss: 0.001517, mae: 0.042085, mean_q: 1.166362
 324400/1000000: episode: 3244, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 62.018, mean reward: 0.620 [0.512, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.820, 10.359], loss: 0.001472, mae: 0.041354, mean_q: 1.165684
 324500/1000000: episode: 3245, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.736, mean reward: 0.607 [0.506, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.832, 10.098], loss: 0.001536, mae: 0.042384, mean_q: 1.166417
 324600/1000000: episode: 3246, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.434, mean reward: 0.584 [0.502, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.010, 10.098], loss: 0.001509, mae: 0.041915, mean_q: 1.170215
 324700/1000000: episode: 3247, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.251, mean reward: 0.583 [0.501, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.711, 10.098], loss: 0.001451, mae: 0.040985, mean_q: 1.168693
 324800/1000000: episode: 3248, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.278, mean reward: 0.573 [0.499, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.493, 10.098], loss: 0.001555, mae: 0.042074, mean_q: 1.167964
 324900/1000000: episode: 3249, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.300, mean reward: 0.583 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.665, 10.098], loss: 0.001447, mae: 0.041494, mean_q: 1.164409
 325000/1000000: episode: 3250, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.388, mean reward: 0.594 [0.507, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.052, 10.098], loss: 0.001511, mae: 0.041890, mean_q: 1.163802
 325100/1000000: episode: 3251, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 56.506, mean reward: 0.565 [0.498, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.929, 10.290], loss: 0.001512, mae: 0.042310, mean_q: 1.168092
 325200/1000000: episode: 3252, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.981, mean reward: 0.590 [0.510, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.592, 10.300], loss: 0.001439, mae: 0.041201, mean_q: 1.163511
 325300/1000000: episode: 3253, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.898, mean reward: 0.579 [0.505, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.820, 10.311], loss: 0.001476, mae: 0.041538, mean_q: 1.165744
 325400/1000000: episode: 3254, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 61.327, mean reward: 0.613 [0.521, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.491, 10.098], loss: 0.001449, mae: 0.041668, mean_q: 1.165161
 325500/1000000: episode: 3255, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 66.534, mean reward: 0.665 [0.528, 0.928], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.343, 10.098], loss: 0.001418, mae: 0.040702, mean_q: 1.163868
 325600/1000000: episode: 3256, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.456, mean reward: 0.605 [0.510, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.615, 10.222], loss: 0.001457, mae: 0.041456, mean_q: 1.163711
 325700/1000000: episode: 3257, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.327, mean reward: 0.593 [0.515, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.906, 10.098], loss: 0.001485, mae: 0.041702, mean_q: 1.167128
 325800/1000000: episode: 3258, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.154, mean reward: 0.602 [0.519, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.892, 10.098], loss: 0.001551, mae: 0.041948, mean_q: 1.167513
 325900/1000000: episode: 3259, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.348, mean reward: 0.573 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.022, 10.098], loss: 0.001462, mae: 0.041481, mean_q: 1.169079
 326000/1000000: episode: 3260, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.097, mean reward: 0.581 [0.502, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.880, 10.220], loss: 0.001510, mae: 0.042262, mean_q: 1.168726
 326100/1000000: episode: 3261, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.939, mean reward: 0.599 [0.500, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.185, 10.202], loss: 0.001479, mae: 0.041449, mean_q: 1.166560
 326200/1000000: episode: 3262, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.310, mean reward: 0.613 [0.506, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.006, 10.098], loss: 0.001445, mae: 0.040545, mean_q: 1.167721
 326300/1000000: episode: 3263, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 63.334, mean reward: 0.633 [0.531, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.415, 10.279], loss: 0.001557, mae: 0.042141, mean_q: 1.170313
 326400/1000000: episode: 3264, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 61.548, mean reward: 0.615 [0.509, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.517, 10.323], loss: 0.001491, mae: 0.041762, mean_q: 1.170368
 326500/1000000: episode: 3265, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 63.768, mean reward: 0.638 [0.520, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.243, 10.422], loss: 0.001481, mae: 0.041362, mean_q: 1.174624
 326600/1000000: episode: 3266, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.269, mean reward: 0.573 [0.504, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.950, 10.098], loss: 0.001609, mae: 0.042940, mean_q: 1.172800
 326700/1000000: episode: 3267, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 56.663, mean reward: 0.567 [0.503, 0.667], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.699, 10.098], loss: 0.001582, mae: 0.042830, mean_q: 1.171560
 326800/1000000: episode: 3268, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.697, mean reward: 0.597 [0.519, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.786, 10.253], loss: 0.001598, mae: 0.042995, mean_q: 1.172305
 326900/1000000: episode: 3269, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.581, mean reward: 0.596 [0.505, 0.907], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.615, 10.209], loss: 0.001555, mae: 0.042894, mean_q: 1.171815
 327000/1000000: episode: 3270, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 64.484, mean reward: 0.645 [0.505, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.978, 10.310], loss: 0.001586, mae: 0.042947, mean_q: 1.172435
 327100/1000000: episode: 3271, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.913, mean reward: 0.589 [0.507, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.627, 10.098], loss: 0.001483, mae: 0.041877, mean_q: 1.175288
 327200/1000000: episode: 3272, duration: 0.523s, episode steps: 100, steps per second: 191, episode reward: 57.588, mean reward: 0.576 [0.502, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.630, 10.135], loss: 0.001476, mae: 0.041281, mean_q: 1.175388
 327300/1000000: episode: 3273, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.130, mean reward: 0.581 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.936, 10.126], loss: 0.001449, mae: 0.041301, mean_q: 1.170511
 327400/1000000: episode: 3274, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.257, mean reward: 0.573 [0.501, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.948, 10.098], loss: 0.001550, mae: 0.042681, mean_q: 1.170391
 327500/1000000: episode: 3275, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.006, mean reward: 0.570 [0.511, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.554, 10.196], loss: 0.001480, mae: 0.041848, mean_q: 1.170505
 327600/1000000: episode: 3276, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.544, mean reward: 0.585 [0.506, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.769, 10.138], loss: 0.001418, mae: 0.040833, mean_q: 1.168883
 327700/1000000: episode: 3277, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 65.841, mean reward: 0.658 [0.501, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.756, 10.179], loss: 0.001578, mae: 0.043321, mean_q: 1.175162
 327800/1000000: episode: 3278, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.294, mean reward: 0.583 [0.509, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-1.080, 10.098], loss: 0.001521, mae: 0.042003, mean_q: 1.172646
 327900/1000000: episode: 3279, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.568, mean reward: 0.626 [0.509, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.404, 10.098], loss: 0.001517, mae: 0.042423, mean_q: 1.174413
 328000/1000000: episode: 3280, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.136, mean reward: 0.571 [0.503, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.758, 10.232], loss: 0.001585, mae: 0.042730, mean_q: 1.180326
 328100/1000000: episode: 3281, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.992, mean reward: 0.580 [0.505, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.538, 10.098], loss: 0.001513, mae: 0.041936, mean_q: 1.177139
 328200/1000000: episode: 3282, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.990, mean reward: 0.580 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.505, 10.099], loss: 0.001569, mae: 0.042783, mean_q: 1.177428
 328300/1000000: episode: 3283, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.661, mean reward: 0.607 [0.500, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.840, 10.402], loss: 0.001529, mae: 0.042082, mean_q: 1.174102
 328400/1000000: episode: 3284, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.587, mean reward: 0.596 [0.501, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.148, 10.252], loss: 0.001503, mae: 0.042002, mean_q: 1.173956
 328500/1000000: episode: 3285, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.128, mean reward: 0.581 [0.506, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.297, 10.332], loss: 0.001615, mae: 0.043299, mean_q: 1.177565
 328600/1000000: episode: 3286, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.561, mean reward: 0.596 [0.500, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.638, 10.098], loss: 0.001547, mae: 0.042253, mean_q: 1.177295
 328700/1000000: episode: 3287, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.343, mean reward: 0.583 [0.505, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.730, 10.099], loss: 0.001455, mae: 0.041454, mean_q: 1.180269
 328800/1000000: episode: 3288, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.494, mean reward: 0.585 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.851, 10.098], loss: 0.001389, mae: 0.040639, mean_q: 1.174908
 328900/1000000: episode: 3289, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.140, mean reward: 0.591 [0.513, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.810, 10.098], loss: 0.001481, mae: 0.041999, mean_q: 1.176189
 329000/1000000: episode: 3290, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.288, mean reward: 0.573 [0.502, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.129, 10.098], loss: 0.001447, mae: 0.041311, mean_q: 1.177715
 329100/1000000: episode: 3291, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.652, mean reward: 0.577 [0.503, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.379, 10.098], loss: 0.001558, mae: 0.041860, mean_q: 1.175469
 329200/1000000: episode: 3292, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 60.459, mean reward: 0.605 [0.505, 0.890], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.399, 10.460], loss: 0.001466, mae: 0.041112, mean_q: 1.176150
 329300/1000000: episode: 3293, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.213, mean reward: 0.602 [0.503, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.651, 10.208], loss: 0.001616, mae: 0.042892, mean_q: 1.177388
 329400/1000000: episode: 3294, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.098, mean reward: 0.581 [0.507, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.752, 10.118], loss: 0.001609, mae: 0.043272, mean_q: 1.175407
 329500/1000000: episode: 3295, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.348, mean reward: 0.603 [0.517, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.527, 10.246], loss: 0.001574, mae: 0.042418, mean_q: 1.174952
 329600/1000000: episode: 3296, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 62.072, mean reward: 0.621 [0.519, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.356, 10.453], loss: 0.001516, mae: 0.041795, mean_q: 1.173632
 329700/1000000: episode: 3297, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.313, mean reward: 0.583 [0.500, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.921, 10.098], loss: 0.001561, mae: 0.042859, mean_q: 1.180050
 329800/1000000: episode: 3298, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.855, mean reward: 0.589 [0.501, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.661, 10.098], loss: 0.001464, mae: 0.041469, mean_q: 1.180043
 329900/1000000: episode: 3299, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.812, mean reward: 0.598 [0.499, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.551, 10.187], loss: 0.001472, mae: 0.041797, mean_q: 1.178131
 330000/1000000: episode: 3300, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 62.428, mean reward: 0.624 [0.502, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.262, 10.098], loss: 0.001555, mae: 0.042608, mean_q: 1.178177
 330100/1000000: episode: 3301, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.041, mean reward: 0.590 [0.502, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.919, 10.183], loss: 0.001475, mae: 0.041293, mean_q: 1.178020
 330200/1000000: episode: 3302, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 63.804, mean reward: 0.638 [0.508, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.076, 10.365], loss: 0.001474, mae: 0.041318, mean_q: 1.177894
 330300/1000000: episode: 3303, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.149, mean reward: 0.581 [0.509, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.751, 10.281], loss: 0.001506, mae: 0.042120, mean_q: 1.183274
 330400/1000000: episode: 3304, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.666, mean reward: 0.597 [0.507, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.555, 10.220], loss: 0.001524, mae: 0.041831, mean_q: 1.183511
 330500/1000000: episode: 3305, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.704, mean reward: 0.597 [0.502, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.096, 10.098], loss: 0.001541, mae: 0.042099, mean_q: 1.181053
 330600/1000000: episode: 3306, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.560, mean reward: 0.576 [0.500, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.659, 10.098], loss: 0.001451, mae: 0.041196, mean_q: 1.179375
 330700/1000000: episode: 3307, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.368, mean reward: 0.574 [0.504, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.889, 10.100], loss: 0.001435, mae: 0.040818, mean_q: 1.178931
 330800/1000000: episode: 3308, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.954, mean reward: 0.570 [0.499, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.672, 10.106], loss: 0.001591, mae: 0.042647, mean_q: 1.174548
 330900/1000000: episode: 3309, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.665, mean reward: 0.587 [0.502, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.042, 10.098], loss: 0.001475, mae: 0.041712, mean_q: 1.174649
 331000/1000000: episode: 3310, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.303, mean reward: 0.593 [0.512, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.929, 10.141], loss: 0.001493, mae: 0.041818, mean_q: 1.182404
 331100/1000000: episode: 3311, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.692, mean reward: 0.587 [0.510, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.165, 10.098], loss: 0.001459, mae: 0.041595, mean_q: 1.177266
 331200/1000000: episode: 3312, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 60.919, mean reward: 0.609 [0.501, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.630, 10.287], loss: 0.001581, mae: 0.042805, mean_q: 1.174463
 331300/1000000: episode: 3313, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 57.831, mean reward: 0.578 [0.505, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.605, 10.098], loss: 0.001453, mae: 0.041520, mean_q: 1.174256
 331400/1000000: episode: 3314, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.635, mean reward: 0.586 [0.512, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.152, 10.185], loss: 0.001575, mae: 0.042706, mean_q: 1.175117
 331500/1000000: episode: 3315, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.168, mean reward: 0.582 [0.502, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.310, 10.098], loss: 0.001460, mae: 0.041556, mean_q: 1.173318
 331600/1000000: episode: 3316, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.854, mean reward: 0.589 [0.504, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.177, 10.141], loss: 0.001516, mae: 0.042332, mean_q: 1.176333
 331700/1000000: episode: 3317, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 61.817, mean reward: 0.618 [0.500, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.037, 10.098], loss: 0.001506, mae: 0.042809, mean_q: 1.174987
 331800/1000000: episode: 3318, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 56.697, mean reward: 0.567 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.561, 10.199], loss: 0.001419, mae: 0.040801, mean_q: 1.176625
 331900/1000000: episode: 3319, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.503, mean reward: 0.585 [0.502, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.541, 10.098], loss: 0.001401, mae: 0.040435, mean_q: 1.173404
 332000/1000000: episode: 3320, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.561, mean reward: 0.596 [0.500, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.764, 10.098], loss: 0.001440, mae: 0.041476, mean_q: 1.173630
 332100/1000000: episode: 3321, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.879, mean reward: 0.599 [0.513, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.643, 10.098], loss: 0.001416, mae: 0.040838, mean_q: 1.169739
 332200/1000000: episode: 3322, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.508, mean reward: 0.615 [0.509, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.931, 10.098], loss: 0.001389, mae: 0.040684, mean_q: 1.169589
 332300/1000000: episode: 3323, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.265, mean reward: 0.583 [0.502, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.448 [-0.381, 10.354], loss: 0.001446, mae: 0.041547, mean_q: 1.170391
 332400/1000000: episode: 3324, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.556, mean reward: 0.576 [0.502, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.711, 10.098], loss: 0.001387, mae: 0.040286, mean_q: 1.168885
 332500/1000000: episode: 3325, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 62.159, mean reward: 0.622 [0.520, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.328, 10.098], loss: 0.001421, mae: 0.040972, mean_q: 1.173896
 332600/1000000: episode: 3326, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.280, mean reward: 0.593 [0.503, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.595, 10.098], loss: 0.001483, mae: 0.041464, mean_q: 1.174712
 332700/1000000: episode: 3327, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 56.941, mean reward: 0.569 [0.501, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.563, 10.293], loss: 0.001418, mae: 0.041088, mean_q: 1.170174
 332800/1000000: episode: 3328, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.625, mean reward: 0.576 [0.510, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.313, 10.184], loss: 0.001455, mae: 0.041419, mean_q: 1.168383
 332900/1000000: episode: 3329, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.520, mean reward: 0.585 [0.502, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.671, 10.098], loss: 0.001394, mae: 0.040720, mean_q: 1.168546
 333000/1000000: episode: 3330, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.262, mean reward: 0.603 [0.507, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.455, 10.098], loss: 0.001483, mae: 0.041918, mean_q: 1.170107
 333100/1000000: episode: 3331, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.099, mean reward: 0.571 [0.499, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.615, 10.127], loss: 0.001596, mae: 0.043076, mean_q: 1.171254
 333200/1000000: episode: 3332, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.755, mean reward: 0.578 [0.499, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.701, 10.098], loss: 0.001581, mae: 0.042949, mean_q: 1.168620
 333300/1000000: episode: 3333, duration: 0.533s, episode steps: 100, steps per second: 187, episode reward: 58.530, mean reward: 0.585 [0.511, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.616, 10.185], loss: 0.001526, mae: 0.042045, mean_q: 1.172166
 333400/1000000: episode: 3334, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.511, mean reward: 0.595 [0.498, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.300, 10.098], loss: 0.001450, mae: 0.041317, mean_q: 1.169826
 333500/1000000: episode: 3335, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.457, mean reward: 0.585 [0.514, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.756, 10.205], loss: 0.001470, mae: 0.041763, mean_q: 1.172762
 333600/1000000: episode: 3336, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 62.401, mean reward: 0.624 [0.506, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.467, 10.098], loss: 0.001470, mae: 0.041364, mean_q: 1.166600
 333700/1000000: episode: 3337, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.638, mean reward: 0.576 [0.504, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.529, 10.098], loss: 0.001485, mae: 0.042288, mean_q: 1.167708
 333800/1000000: episode: 3338, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.259, mean reward: 0.583 [0.508, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.676, 10.211], loss: 0.001443, mae: 0.041565, mean_q: 1.169326
 333900/1000000: episode: 3339, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 57.153, mean reward: 0.572 [0.499, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.353, 10.196], loss: 0.001464, mae: 0.041330, mean_q: 1.170196
 334000/1000000: episode: 3340, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.678, mean reward: 0.597 [0.502, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.548, 10.143], loss: 0.001417, mae: 0.041077, mean_q: 1.168176
 334100/1000000: episode: 3341, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.459, mean reward: 0.585 [0.507, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.618, 10.098], loss: 0.001484, mae: 0.042145, mean_q: 1.168960
 334200/1000000: episode: 3342, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.855, mean reward: 0.599 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.517, 10.446], loss: 0.001427, mae: 0.040905, mean_q: 1.170923
 334300/1000000: episode: 3343, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 62.097, mean reward: 0.621 [0.504, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.712, 10.098], loss: 0.001514, mae: 0.042354, mean_q: 1.168381
 334400/1000000: episode: 3344, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.087, mean reward: 0.581 [0.501, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.903, 10.098], loss: 0.001438, mae: 0.042177, mean_q: 1.171271
 334500/1000000: episode: 3345, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.932, mean reward: 0.579 [0.501, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.005, 10.224], loss: 0.001423, mae: 0.041200, mean_q: 1.169562
 334600/1000000: episode: 3346, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.473, mean reward: 0.575 [0.498, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.853, 10.098], loss: 0.001470, mae: 0.042232, mean_q: 1.171121
 334700/1000000: episode: 3347, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 61.240, mean reward: 0.612 [0.505, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.921, 10.432], loss: 0.001395, mae: 0.040759, mean_q: 1.169448
 334800/1000000: episode: 3348, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.085, mean reward: 0.591 [0.497, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.842, 10.128], loss: 0.001429, mae: 0.041187, mean_q: 1.170849
 334900/1000000: episode: 3349, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.912, mean reward: 0.589 [0.509, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.339, 10.098], loss: 0.001391, mae: 0.040265, mean_q: 1.166645
 335000/1000000: episode: 3350, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.426, mean reward: 0.584 [0.506, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.746, 10.098], loss: 0.001413, mae: 0.040892, mean_q: 1.167724
 335100/1000000: episode: 3351, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 63.565, mean reward: 0.636 [0.505, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.711, 10.595], loss: 0.001383, mae: 0.040859, mean_q: 1.165764
 335200/1000000: episode: 3352, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.217, mean reward: 0.572 [0.499, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.738, 10.243], loss: 0.001466, mae: 0.041691, mean_q: 1.167434
 335300/1000000: episode: 3353, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.896, mean reward: 0.579 [0.504, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.387, 10.098], loss: 0.001464, mae: 0.041423, mean_q: 1.168862
 335400/1000000: episode: 3354, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.746, mean reward: 0.587 [0.499, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.772, 10.177], loss: 0.001520, mae: 0.042766, mean_q: 1.168304
 335500/1000000: episode: 3355, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 56.318, mean reward: 0.563 [0.506, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.559, 10.098], loss: 0.001491, mae: 0.042626, mean_q: 1.166719
 335600/1000000: episode: 3356, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.031, mean reward: 0.600 [0.512, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.751, 10.098], loss: 0.001500, mae: 0.042279, mean_q: 1.168000
 335700/1000000: episode: 3357, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 57.722, mean reward: 0.577 [0.500, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.930, 10.132], loss: 0.001391, mae: 0.040909, mean_q: 1.169151
 335800/1000000: episode: 3358, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.556, mean reward: 0.616 [0.512, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.370, 10.333], loss: 0.001382, mae: 0.040619, mean_q: 1.165590
 335900/1000000: episode: 3359, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.688, mean reward: 0.567 [0.508, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.084, 10.240], loss: 0.001499, mae: 0.041637, mean_q: 1.167624
 336000/1000000: episode: 3360, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 63.463, mean reward: 0.635 [0.506, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.520, 10.204], loss: 0.001471, mae: 0.041532, mean_q: 1.170084
 336100/1000000: episode: 3361, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.706, mean reward: 0.577 [0.499, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.678, 10.143], loss: 0.001505, mae: 0.041371, mean_q: 1.169434
 336200/1000000: episode: 3362, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 58.166, mean reward: 0.582 [0.498, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.142, 10.098], loss: 0.001452, mae: 0.041450, mean_q: 1.169933
 336300/1000000: episode: 3363, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 63.207, mean reward: 0.632 [0.507, 0.872], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.837, 10.463], loss: 0.001430, mae: 0.041203, mean_q: 1.165468
 336400/1000000: episode: 3364, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.063, mean reward: 0.591 [0.511, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.362, 10.098], loss: 0.001528, mae: 0.041740, mean_q: 1.166710
 336500/1000000: episode: 3365, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 58.125, mean reward: 0.581 [0.506, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.796, 10.098], loss: 0.001443, mae: 0.041298, mean_q: 1.163675
 336600/1000000: episode: 3366, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.642, mean reward: 0.596 [0.510, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.553, 10.137], loss: 0.001450, mae: 0.041131, mean_q: 1.166895
 336700/1000000: episode: 3367, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.046, mean reward: 0.580 [0.499, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.014, 10.098], loss: 0.001517, mae: 0.042003, mean_q: 1.166773
 336800/1000000: episode: 3368, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.245, mean reward: 0.592 [0.506, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.882, 10.173], loss: 0.001494, mae: 0.042152, mean_q: 1.172573
 336900/1000000: episode: 3369, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.554, mean reward: 0.586 [0.505, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.618, 10.291], loss: 0.001413, mae: 0.040478, mean_q: 1.171951
 337000/1000000: episode: 3370, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.005, mean reward: 0.590 [0.504, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.562, 10.173], loss: 0.001484, mae: 0.041523, mean_q: 1.167033
 337100/1000000: episode: 3371, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.323, mean reward: 0.603 [0.506, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.089, 10.378], loss: 0.001478, mae: 0.041933, mean_q: 1.170516
 337200/1000000: episode: 3372, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.116, mean reward: 0.611 [0.504, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.930, 10.377], loss: 0.001449, mae: 0.041559, mean_q: 1.169506
 337300/1000000: episode: 3373, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.986, mean reward: 0.580 [0.508, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.917, 10.275], loss: 0.001532, mae: 0.042358, mean_q: 1.168416
 337400/1000000: episode: 3374, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.765, mean reward: 0.568 [0.509, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.056, 10.098], loss: 0.001407, mae: 0.041030, mean_q: 1.169600
 337500/1000000: episode: 3375, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.226, mean reward: 0.602 [0.511, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.229, 10.319], loss: 0.001489, mae: 0.042094, mean_q: 1.168940
 337600/1000000: episode: 3376, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.853, mean reward: 0.569 [0.499, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.970, 10.098], loss: 0.001529, mae: 0.042130, mean_q: 1.168165
 337700/1000000: episode: 3377, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.055, mean reward: 0.591 [0.500, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.056, 10.098], loss: 0.001541, mae: 0.042324, mean_q: 1.171702
 337800/1000000: episode: 3378, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.046, mean reward: 0.600 [0.501, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.306, 10.249], loss: 0.001443, mae: 0.041087, mean_q: 1.168121
 337900/1000000: episode: 3379, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.066, mean reward: 0.581 [0.500, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.168, 10.098], loss: 0.001420, mae: 0.041127, mean_q: 1.167495
 338000/1000000: episode: 3380, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.095, mean reward: 0.611 [0.501, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.507, 10.461], loss: 0.001342, mae: 0.040095, mean_q: 1.168059
 338100/1000000: episode: 3381, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.017, mean reward: 0.590 [0.507, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.533, 10.229], loss: 0.001475, mae: 0.041573, mean_q: 1.168630
 338200/1000000: episode: 3382, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.276, mean reward: 0.593 [0.507, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.612, 10.342], loss: 0.001480, mae: 0.041358, mean_q: 1.168582
 338300/1000000: episode: 3383, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.933, mean reward: 0.569 [0.501, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.704, 10.114], loss: 0.001499, mae: 0.042341, mean_q: 1.169262
 338400/1000000: episode: 3384, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 56.656, mean reward: 0.567 [0.503, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.625, 10.137], loss: 0.001466, mae: 0.041509, mean_q: 1.169245
 338500/1000000: episode: 3385, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.095, mean reward: 0.571 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.571, 10.098], loss: 0.001404, mae: 0.040591, mean_q: 1.165819
 338600/1000000: episode: 3386, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.693, mean reward: 0.607 [0.521, 0.870], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.423, 10.098], loss: 0.001425, mae: 0.041182, mean_q: 1.168447
 338700/1000000: episode: 3387, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.286, mean reward: 0.583 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.901, 10.098], loss: 0.001435, mae: 0.041421, mean_q: 1.169249
 338800/1000000: episode: 3388, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.057, mean reward: 0.591 [0.507, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.005, 10.098], loss: 0.001513, mae: 0.041701, mean_q: 1.167112
 338900/1000000: episode: 3389, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.197, mean reward: 0.572 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.455, 10.098], loss: 0.001493, mae: 0.042009, mean_q: 1.167627
 339000/1000000: episode: 3390, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.397, mean reward: 0.594 [0.504, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.909, 10.117], loss: 0.001502, mae: 0.042144, mean_q: 1.166889
 339100/1000000: episode: 3391, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 63.248, mean reward: 0.632 [0.520, 0.881], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.767, 10.098], loss: 0.001489, mae: 0.041887, mean_q: 1.168004
 339200/1000000: episode: 3392, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.889, mean reward: 0.599 [0.506, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.852, 10.257], loss: 0.001520, mae: 0.042401, mean_q: 1.170722
 339300/1000000: episode: 3393, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.141, mean reward: 0.601 [0.504, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.709, 10.098], loss: 0.001518, mae: 0.041985, mean_q: 1.169117
 339400/1000000: episode: 3394, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.639, mean reward: 0.586 [0.499, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.147, 10.098], loss: 0.001523, mae: 0.041768, mean_q: 1.166050
 339500/1000000: episode: 3395, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.264, mean reward: 0.573 [0.502, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.479, 10.313], loss: 0.001572, mae: 0.041763, mean_q: 1.170929
 339600/1000000: episode: 3396, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.903, mean reward: 0.579 [0.505, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.254, 10.338], loss: 0.001494, mae: 0.041217, mean_q: 1.171292
 339700/1000000: episode: 3397, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 67.106, mean reward: 0.671 [0.534, 0.877], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.167, 10.347], loss: 0.001528, mae: 0.041686, mean_q: 1.165746
 339800/1000000: episode: 3398, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.988, mean reward: 0.600 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.047, 10.098], loss: 0.001523, mae: 0.042215, mean_q: 1.172835
 339900/1000000: episode: 3399, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.264, mean reward: 0.573 [0.505, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-2.403, 10.212], loss: 0.001571, mae: 0.042417, mean_q: 1.170143
 340000/1000000: episode: 3400, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.081, mean reward: 0.601 [0.508, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.990, 10.137], loss: 0.001555, mae: 0.042509, mean_q: 1.172599
 340100/1000000: episode: 3401, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 59.764, mean reward: 0.598 [0.508, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.373, 10.170], loss: 0.001469, mae: 0.041040, mean_q: 1.170874
 340200/1000000: episode: 3402, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.512, mean reward: 0.585 [0.501, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.980, 10.098], loss: 0.001599, mae: 0.042734, mean_q: 1.172060
 340300/1000000: episode: 3403, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.524, mean reward: 0.575 [0.506, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.020, 10.098], loss: 0.001548, mae: 0.042298, mean_q: 1.171955
 340400/1000000: episode: 3404, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.247, mean reward: 0.612 [0.506, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.590, 10.098], loss: 0.001551, mae: 0.041835, mean_q: 1.177152
 340500/1000000: episode: 3405, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.865, mean reward: 0.579 [0.505, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.143, 10.098], loss: 0.001570, mae: 0.042754, mean_q: 1.171604
 340600/1000000: episode: 3406, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.779, mean reward: 0.608 [0.511, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.635, 10.098], loss: 0.001600, mae: 0.043210, mean_q: 1.173230
 340700/1000000: episode: 3407, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.215, mean reward: 0.572 [0.503, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.791, 10.201], loss: 0.001518, mae: 0.041833, mean_q: 1.171052
 340800/1000000: episode: 3408, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.639, mean reward: 0.576 [0.497, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.838, 10.098], loss: 0.001452, mae: 0.041688, mean_q: 1.170478
 340900/1000000: episode: 3409, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.700, mean reward: 0.577 [0.506, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.571, 10.380], loss: 0.001459, mae: 0.041317, mean_q: 1.173800
 341000/1000000: episode: 3410, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.040, mean reward: 0.590 [0.501, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.104, 10.098], loss: 0.001568, mae: 0.042127, mean_q: 1.172824
 341100/1000000: episode: 3411, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.202, mean reward: 0.582 [0.502, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.844, 10.310], loss: 0.001502, mae: 0.041873, mean_q: 1.168401
 341200/1000000: episode: 3412, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.877, mean reward: 0.599 [0.510, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.826, 10.122], loss: 0.001561, mae: 0.042562, mean_q: 1.169201
 341300/1000000: episode: 3413, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.395, mean reward: 0.574 [0.501, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.581, 10.098], loss: 0.001585, mae: 0.042618, mean_q: 1.166533
 341400/1000000: episode: 3414, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 59.252, mean reward: 0.593 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.281, 10.224], loss: 0.001512, mae: 0.041982, mean_q: 1.165269
 341500/1000000: episode: 3415, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 57.919, mean reward: 0.579 [0.502, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.617, 10.354], loss: 0.001611, mae: 0.043131, mean_q: 1.164885
 341600/1000000: episode: 3416, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.722, mean reward: 0.607 [0.504, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.174, 10.098], loss: 0.001610, mae: 0.043358, mean_q: 1.164518
 341700/1000000: episode: 3417, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 56.783, mean reward: 0.568 [0.503, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.009, 10.141], loss: 0.001534, mae: 0.042373, mean_q: 1.169254
 341800/1000000: episode: 3418, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.065, mean reward: 0.581 [0.504, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.875, 10.357], loss: 0.001515, mae: 0.041803, mean_q: 1.167392
 341900/1000000: episode: 3419, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.009, mean reward: 0.580 [0.500, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.149, 10.294], loss: 0.001572, mae: 0.042614, mean_q: 1.164945
 342000/1000000: episode: 3420, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 60.571, mean reward: 0.606 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.843, 10.456], loss: 0.001538, mae: 0.041853, mean_q: 1.165816
 342100/1000000: episode: 3421, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.834, mean reward: 0.588 [0.501, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.608, 10.124], loss: 0.001496, mae: 0.041790, mean_q: 1.165407
 342200/1000000: episode: 3422, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 58.472, mean reward: 0.585 [0.500, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.930, 10.098], loss: 0.001634, mae: 0.043316, mean_q: 1.168417
 342300/1000000: episode: 3423, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.500, mean reward: 0.575 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.772, 10.164], loss: 0.001700, mae: 0.044435, mean_q: 1.165295
 342400/1000000: episode: 3424, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.331, mean reward: 0.603 [0.505, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.591, 10.192], loss: 0.001571, mae: 0.042591, mean_q: 1.164733
 342500/1000000: episode: 3425, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.135, mean reward: 0.591 [0.509, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.018, 10.098], loss: 0.001555, mae: 0.042063, mean_q: 1.168270
 342600/1000000: episode: 3426, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 56.981, mean reward: 0.570 [0.501, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.689, 10.098], loss: 0.001685, mae: 0.043397, mean_q: 1.166331
 342700/1000000: episode: 3427, duration: 0.525s, episode steps: 100, steps per second: 191, episode reward: 63.606, mean reward: 0.636 [0.525, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.733, 10.269], loss: 0.001509, mae: 0.041724, mean_q: 1.165816
 342800/1000000: episode: 3428, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 57.359, mean reward: 0.574 [0.504, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.054, 10.160], loss: 0.001619, mae: 0.043189, mean_q: 1.168653
 342900/1000000: episode: 3429, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.290, mean reward: 0.583 [0.508, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.355, 10.270], loss: 0.001598, mae: 0.043233, mean_q: 1.168412
 343000/1000000: episode: 3430, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.221, mean reward: 0.582 [0.499, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.199, 10.113], loss: 0.001523, mae: 0.041795, mean_q: 1.162152
 343100/1000000: episode: 3431, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.588, mean reward: 0.586 [0.508, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.101, 10.240], loss: 0.001542, mae: 0.042006, mean_q: 1.168460
 343200/1000000: episode: 3432, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.896, mean reward: 0.589 [0.507, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.426, 10.098], loss: 0.001635, mae: 0.043321, mean_q: 1.166239
 343300/1000000: episode: 3433, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.610, mean reward: 0.606 [0.499, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.988, 10.290], loss: 0.001711, mae: 0.044668, mean_q: 1.171500
 343400/1000000: episode: 3434, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.979, mean reward: 0.620 [0.521, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.826, 10.414], loss: 0.001610, mae: 0.043011, mean_q: 1.169590
 343500/1000000: episode: 3435, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.019, mean reward: 0.600 [0.512, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.717, 10.429], loss: 0.001709, mae: 0.043699, mean_q: 1.173051
 343600/1000000: episode: 3436, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 59.049, mean reward: 0.590 [0.503, 0.895], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.343, 10.098], loss: 0.001727, mae: 0.044003, mean_q: 1.170915
 343700/1000000: episode: 3437, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.489, mean reward: 0.565 [0.502, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.873, 10.098], loss: 0.001542, mae: 0.042294, mean_q: 1.167008
 343800/1000000: episode: 3438, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.541, mean reward: 0.605 [0.507, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.782, 10.243], loss: 0.001555, mae: 0.042232, mean_q: 1.167180
 343900/1000000: episode: 3439, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 63.084, mean reward: 0.631 [0.510, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.018, 10.318], loss: 0.001529, mae: 0.042431, mean_q: 1.169404
 344000/1000000: episode: 3440, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.338, mean reward: 0.573 [0.510, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.352, 10.344], loss: 0.001644, mae: 0.043265, mean_q: 1.171943
 344100/1000000: episode: 3441, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.351, mean reward: 0.594 [0.513, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.716, 10.131], loss: 0.001573, mae: 0.043317, mean_q: 1.173062
 344200/1000000: episode: 3442, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.460, mean reward: 0.585 [0.510, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.603, 10.098], loss: 0.001651, mae: 0.043863, mean_q: 1.168576
 344300/1000000: episode: 3443, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 62.055, mean reward: 0.621 [0.514, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.449, 10.098], loss: 0.001495, mae: 0.042078, mean_q: 1.170881
 344400/1000000: episode: 3444, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.587, mean reward: 0.586 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.260, 10.161], loss: 0.001538, mae: 0.042171, mean_q: 1.172179
 344500/1000000: episode: 3445, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.086, mean reward: 0.591 [0.505, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.911, 10.098], loss: 0.001572, mae: 0.043402, mean_q: 1.172354
 344600/1000000: episode: 3446, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.152, mean reward: 0.572 [0.506, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.577, 10.098], loss: 0.001590, mae: 0.043391, mean_q: 1.169533
 344700/1000000: episode: 3447, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.942, mean reward: 0.609 [0.509, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.665, 10.098], loss: 0.001499, mae: 0.042739, mean_q: 1.166648
 344800/1000000: episode: 3448, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.054, mean reward: 0.571 [0.499, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.948, 10.121], loss: 0.001747, mae: 0.044833, mean_q: 1.167211
 344900/1000000: episode: 3449, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.583, mean reward: 0.586 [0.505, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.026, 10.098], loss: 0.001566, mae: 0.043102, mean_q: 1.169325
 345000/1000000: episode: 3450, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.795, mean reward: 0.578 [0.499, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.441, 10.202], loss: 0.001519, mae: 0.042220, mean_q: 1.164626
 345100/1000000: episode: 3451, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 63.064, mean reward: 0.631 [0.511, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.857, 10.098], loss: 0.001519, mae: 0.042293, mean_q: 1.164139
 345200/1000000: episode: 3452, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.159, mean reward: 0.602 [0.511, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.316, 10.098], loss: 0.001600, mae: 0.043250, mean_q: 1.168458
 345300/1000000: episode: 3453, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.217, mean reward: 0.572 [0.503, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.990, 10.098], loss: 0.001705, mae: 0.044092, mean_q: 1.169960
 345400/1000000: episode: 3454, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 57.893, mean reward: 0.579 [0.508, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.647, 10.221], loss: 0.001581, mae: 0.043020, mean_q: 1.169694
 345500/1000000: episode: 3455, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.168, mean reward: 0.602 [0.503, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.215, 10.098], loss: 0.001506, mae: 0.041865, mean_q: 1.166338
 345600/1000000: episode: 3456, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.883, mean reward: 0.599 [0.501, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.679, 10.412], loss: 0.001537, mae: 0.042216, mean_q: 1.163940
 345700/1000000: episode: 3457, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.036, mean reward: 0.570 [0.501, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.943, 10.156], loss: 0.001511, mae: 0.042242, mean_q: 1.169193
 345800/1000000: episode: 3458, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.397, mean reward: 0.594 [0.505, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.491, 10.098], loss: 0.001502, mae: 0.041941, mean_q: 1.167565
 345900/1000000: episode: 3459, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 61.404, mean reward: 0.614 [0.508, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.752, 10.107], loss: 0.001456, mae: 0.041369, mean_q: 1.169813
 346000/1000000: episode: 3460, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.811, mean reward: 0.608 [0.508, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.048, 10.104], loss: 0.001589, mae: 0.043164, mean_q: 1.172754
 346100/1000000: episode: 3461, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 61.305, mean reward: 0.613 [0.531, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.935, 10.260], loss: 0.001501, mae: 0.041799, mean_q: 1.167228
 346200/1000000: episode: 3462, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.734, mean reward: 0.587 [0.501, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.470, 10.098], loss: 0.001568, mae: 0.042987, mean_q: 1.169426
 346300/1000000: episode: 3463, duration: 0.525s, episode steps: 100, steps per second: 190, episode reward: 58.710, mean reward: 0.587 [0.503, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.587, 10.226], loss: 0.001594, mae: 0.042809, mean_q: 1.173661
 346400/1000000: episode: 3464, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.063, mean reward: 0.581 [0.501, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.951, 10.330], loss: 0.001533, mae: 0.042314, mean_q: 1.168949
 346500/1000000: episode: 3465, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.545, mean reward: 0.585 [0.509, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.852, 10.178], loss: 0.001496, mae: 0.042097, mean_q: 1.172686
 346600/1000000: episode: 3466, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.351, mean reward: 0.584 [0.500, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.293, 10.371], loss: 0.001445, mae: 0.041411, mean_q: 1.172192
 346700/1000000: episode: 3467, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.318, mean reward: 0.593 [0.505, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.423, 10.098], loss: 0.001579, mae: 0.043235, mean_q: 1.172001
 346800/1000000: episode: 3468, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 60.187, mean reward: 0.602 [0.503, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.599, 10.098], loss: 0.001526, mae: 0.042423, mean_q: 1.171039
 346900/1000000: episode: 3469, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.724, mean reward: 0.597 [0.501, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.874, 10.098], loss: 0.001598, mae: 0.042826, mean_q: 1.172047
 347000/1000000: episode: 3470, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.984, mean reward: 0.600 [0.508, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.675, 10.098], loss: 0.001466, mae: 0.040661, mean_q: 1.168575
 347100/1000000: episode: 3471, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.049, mean reward: 0.600 [0.505, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.903, 10.098], loss: 0.001530, mae: 0.042301, mean_q: 1.173002
 347200/1000000: episode: 3472, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 57.310, mean reward: 0.573 [0.502, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.627, 10.199], loss: 0.001507, mae: 0.042415, mean_q: 1.174586
 347300/1000000: episode: 3473, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.850, mean reward: 0.588 [0.501, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.599, 10.194], loss: 0.001500, mae: 0.041613, mean_q: 1.175685
 347400/1000000: episode: 3474, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 62.880, mean reward: 0.629 [0.506, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.970, 10.098], loss: 0.001474, mae: 0.041967, mean_q: 1.175270
 347500/1000000: episode: 3475, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.238, mean reward: 0.572 [0.499, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.536, 10.098], loss: 0.001482, mae: 0.042062, mean_q: 1.174133
 347600/1000000: episode: 3476, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.946, mean reward: 0.589 [0.514, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.266, 10.169], loss: 0.001527, mae: 0.042596, mean_q: 1.177791
 347700/1000000: episode: 3477, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.438, mean reward: 0.584 [0.501, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.361, 10.098], loss: 0.001335, mae: 0.039830, mean_q: 1.170077
 347800/1000000: episode: 3478, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.959, mean reward: 0.610 [0.502, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.758, 10.232], loss: 0.001449, mae: 0.041119, mean_q: 1.175628
 347900/1000000: episode: 3479, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.453, mean reward: 0.585 [0.501, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.593, 10.279], loss: 0.001428, mae: 0.041634, mean_q: 1.173923
 348000/1000000: episode: 3480, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.476, mean reward: 0.575 [0.498, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.728, 10.103], loss: 0.001465, mae: 0.041410, mean_q: 1.173817
 348100/1000000: episode: 3481, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.167, mean reward: 0.582 [0.508, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.209, 10.193], loss: 0.001404, mae: 0.040277, mean_q: 1.171673
 348200/1000000: episode: 3482, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.289, mean reward: 0.593 [0.503, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.962, 10.138], loss: 0.001523, mae: 0.042482, mean_q: 1.172117
 348300/1000000: episode: 3483, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 63.578, mean reward: 0.636 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.649, 10.212], loss: 0.001420, mae: 0.040685, mean_q: 1.174256
 348400/1000000: episode: 3484, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.847, mean reward: 0.608 [0.503, 0.863], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.802, 10.254], loss: 0.001460, mae: 0.041619, mean_q: 1.172919
 348500/1000000: episode: 3485, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.777, mean reward: 0.578 [0.509, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.179, 10.098], loss: 0.001438, mae: 0.040479, mean_q: 1.172715
 348600/1000000: episode: 3486, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.160, mean reward: 0.602 [0.511, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.299, 10.352], loss: 0.001526, mae: 0.042156, mean_q: 1.174144
 348700/1000000: episode: 3487, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 56.754, mean reward: 0.568 [0.508, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.546, 10.191], loss: 0.001417, mae: 0.040768, mean_q: 1.173283
 348800/1000000: episode: 3488, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.969, mean reward: 0.590 [0.510, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.621, 10.108], loss: 0.001469, mae: 0.041700, mean_q: 1.174174
 348900/1000000: episode: 3489, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 61.167, mean reward: 0.612 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.947, 10.178], loss: 0.001448, mae: 0.041456, mean_q: 1.173036
 349000/1000000: episode: 3490, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.662, mean reward: 0.587 [0.515, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.602, 10.098], loss: 0.001441, mae: 0.041449, mean_q: 1.174774
 349100/1000000: episode: 3491, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.100, mean reward: 0.581 [0.499, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.513, 10.217], loss: 0.001411, mae: 0.040757, mean_q: 1.172880
 349200/1000000: episode: 3492, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 65.377, mean reward: 0.654 [0.512, 0.911], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.904, 10.629], loss: 0.001536, mae: 0.042398, mean_q: 1.175400
 349300/1000000: episode: 3493, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.557, mean reward: 0.596 [0.501, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.980, 10.098], loss: 0.001359, mae: 0.040105, mean_q: 1.174560
 349400/1000000: episode: 3494, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.185, mean reward: 0.582 [0.498, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.047, 10.100], loss: 0.001494, mae: 0.042078, mean_q: 1.174991
 349500/1000000: episode: 3495, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 63.183, mean reward: 0.632 [0.511, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.709, 10.302], loss: 0.001396, mae: 0.040706, mean_q: 1.175192
 349600/1000000: episode: 3496, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.531, mean reward: 0.585 [0.505, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-2.114, 10.112], loss: 0.001481, mae: 0.041799, mean_q: 1.177889
 349700/1000000: episode: 3497, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.497, mean reward: 0.575 [0.505, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.542, 10.205], loss: 0.001416, mae: 0.041314, mean_q: 1.173596
 349800/1000000: episode: 3498, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.826, mean reward: 0.578 [0.500, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.341, 10.221], loss: 0.001479, mae: 0.041763, mean_q: 1.173403
 349900/1000000: episode: 3499, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.627, mean reward: 0.586 [0.509, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.382, 10.232], loss: 0.001482, mae: 0.041824, mean_q: 1.177219
 350000/1000000: episode: 3500, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.234, mean reward: 0.582 [0.506, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.394, 10.098], loss: 0.001414, mae: 0.041316, mean_q: 1.176366
 350100/1000000: episode: 3501, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.752, mean reward: 0.598 [0.523, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.504, 10.098], loss: 0.001472, mae: 0.041765, mean_q: 1.174864
 350200/1000000: episode: 3502, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.991, mean reward: 0.570 [0.505, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.299, 10.098], loss: 0.001502, mae: 0.041901, mean_q: 1.176073
 350300/1000000: episode: 3503, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.648, mean reward: 0.626 [0.510, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.582, 10.098], loss: 0.001445, mae: 0.041543, mean_q: 1.177823
 350400/1000000: episode: 3504, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.934, mean reward: 0.579 [0.501, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.865, 10.284], loss: 0.001370, mae: 0.040324, mean_q: 1.174428
 350500/1000000: episode: 3505, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.490, mean reward: 0.595 [0.503, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.861, 10.098], loss: 0.001358, mae: 0.039863, mean_q: 1.173213
 350600/1000000: episode: 3506, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.877, mean reward: 0.569 [0.503, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.701, 10.213], loss: 0.001396, mae: 0.041021, mean_q: 1.173685
 350700/1000000: episode: 3507, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.757, mean reward: 0.578 [0.504, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-2.006, 10.243], loss: 0.001560, mae: 0.042660, mean_q: 1.174337
 350800/1000000: episode: 3508, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.218, mean reward: 0.592 [0.506, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.720, 10.098], loss: 0.001441, mae: 0.041655, mean_q: 1.172480
 350900/1000000: episode: 3509, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.521, mean reward: 0.575 [0.506, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.682, 10.292], loss: 0.001457, mae: 0.041508, mean_q: 1.174381
 351000/1000000: episode: 3510, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.065, mean reward: 0.591 [0.502, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.630, 10.134], loss: 0.001474, mae: 0.041947, mean_q: 1.171006
 351100/1000000: episode: 3511, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.987, mean reward: 0.590 [0.502, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.894, 10.098], loss: 0.001354, mae: 0.040095, mean_q: 1.168247
 351200/1000000: episode: 3512, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.016, mean reward: 0.600 [0.503, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.578, 10.463], loss: 0.001410, mae: 0.041399, mean_q: 1.172454
 351300/1000000: episode: 3513, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.194, mean reward: 0.572 [0.502, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.524, 10.098], loss: 0.001478, mae: 0.041698, mean_q: 1.172937
 351400/1000000: episode: 3514, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.770, mean reward: 0.578 [0.501, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.216, 10.098], loss: 0.001433, mae: 0.041421, mean_q: 1.172502
 351500/1000000: episode: 3515, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.215, mean reward: 0.592 [0.514, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.949, 10.236], loss: 0.001391, mae: 0.040785, mean_q: 1.169744
 351600/1000000: episode: 3516, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.878, mean reward: 0.589 [0.505, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.008, 10.098], loss: 0.001341, mae: 0.040460, mean_q: 1.169668
 351700/1000000: episode: 3517, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.806, mean reward: 0.578 [0.506, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.988, 10.193], loss: 0.001382, mae: 0.040460, mean_q: 1.171182
 351800/1000000: episode: 3518, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.047, mean reward: 0.580 [0.504, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.760, 10.105], loss: 0.001338, mae: 0.039398, mean_q: 1.169570
 351900/1000000: episode: 3519, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.329, mean reward: 0.563 [0.507, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.819, 10.098], loss: 0.001279, mae: 0.039128, mean_q: 1.167251
 352000/1000000: episode: 3520, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.861, mean reward: 0.579 [0.498, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.800, 10.181], loss: 0.001357, mae: 0.040787, mean_q: 1.166055
 352100/1000000: episode: 3521, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.200, mean reward: 0.582 [0.508, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.959, 10.098], loss: 0.001373, mae: 0.040410, mean_q: 1.165922
 352200/1000000: episode: 3522, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.141, mean reward: 0.591 [0.502, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.061, 10.117], loss: 0.001461, mae: 0.041519, mean_q: 1.170275
 352300/1000000: episode: 3523, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.017, mean reward: 0.600 [0.514, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.243, 10.098], loss: 0.001415, mae: 0.041056, mean_q: 1.165261
 352400/1000000: episode: 3524, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.875, mean reward: 0.579 [0.509, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.421, 10.329], loss: 0.001466, mae: 0.041701, mean_q: 1.169094
 352500/1000000: episode: 3525, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.924, mean reward: 0.589 [0.506, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.206, 10.230], loss: 0.001481, mae: 0.041909, mean_q: 1.167271
 352600/1000000: episode: 3526, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.688, mean reward: 0.597 [0.507, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.610, 10.369], loss: 0.001426, mae: 0.040934, mean_q: 1.167524
 352700/1000000: episode: 3527, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.984, mean reward: 0.580 [0.510, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.603, 10.098], loss: 0.001567, mae: 0.043254, mean_q: 1.165797
 352800/1000000: episode: 3528, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.282, mean reward: 0.583 [0.501, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.273, 10.098], loss: 0.001421, mae: 0.040502, mean_q: 1.166841
 352900/1000000: episode: 3529, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.176, mean reward: 0.602 [0.516, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.228, 10.235], loss: 0.001484, mae: 0.042032, mean_q: 1.163189
 353000/1000000: episode: 3530, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.458, mean reward: 0.575 [0.503, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.561, 10.098], loss: 0.001431, mae: 0.041488, mean_q: 1.168667
 353100/1000000: episode: 3531, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.592, mean reward: 0.606 [0.513, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.038, 10.224], loss: 0.001342, mae: 0.039843, mean_q: 1.161399
 353200/1000000: episode: 3532, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.388, mean reward: 0.584 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.219, 10.126], loss: 0.001456, mae: 0.041396, mean_q: 1.165148
 353300/1000000: episode: 3533, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.518, mean reward: 0.585 [0.507, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.882, 10.098], loss: 0.001489, mae: 0.041695, mean_q: 1.165522
 353400/1000000: episode: 3534, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.373, mean reward: 0.604 [0.505, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.018, 10.098], loss: 0.001413, mae: 0.041300, mean_q: 1.165257
 353500/1000000: episode: 3535, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.074, mean reward: 0.591 [0.514, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.845, 10.331], loss: 0.001433, mae: 0.041355, mean_q: 1.164043
 353600/1000000: episode: 3536, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 61.712, mean reward: 0.617 [0.519, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.036, 10.098], loss: 0.001500, mae: 0.042675, mean_q: 1.166345
 353700/1000000: episode: 3537, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.422, mean reward: 0.584 [0.503, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.287, 10.098], loss: 0.001471, mae: 0.041936, mean_q: 1.166885
 353800/1000000: episode: 3538, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.564, mean reward: 0.586 [0.507, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.222, 10.098], loss: 0.001381, mae: 0.040797, mean_q: 1.163684
 353900/1000000: episode: 3539, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.946, mean reward: 0.579 [0.506, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.346, 10.141], loss: 0.001425, mae: 0.041593, mean_q: 1.162090
 354000/1000000: episode: 3540, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.840, mean reward: 0.598 [0.516, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.722, 10.098], loss: 0.001347, mae: 0.040048, mean_q: 1.160619
 354100/1000000: episode: 3541, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.985, mean reward: 0.590 [0.511, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.792, 10.098], loss: 0.001346, mae: 0.039742, mean_q: 1.161989
 354200/1000000: episode: 3542, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.678, mean reward: 0.587 [0.500, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.702, 10.145], loss: 0.001493, mae: 0.042036, mean_q: 1.163659
 354300/1000000: episode: 3543, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.776, mean reward: 0.588 [0.513, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.614, 10.098], loss: 0.001341, mae: 0.039996, mean_q: 1.161987
 354400/1000000: episode: 3544, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.583, mean reward: 0.586 [0.513, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-1.468, 10.252], loss: 0.001362, mae: 0.040037, mean_q: 1.163055
 354500/1000000: episode: 3545, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.082, mean reward: 0.591 [0.500, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.667, 10.119], loss: 0.001452, mae: 0.042001, mean_q: 1.164673
 354600/1000000: episode: 3546, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.922, mean reward: 0.609 [0.515, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.139, 10.098], loss: 0.001409, mae: 0.040562, mean_q: 1.162972
 354700/1000000: episode: 3547, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.995, mean reward: 0.590 [0.511, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.804, 10.269], loss: 0.001400, mae: 0.040807, mean_q: 1.163626
 354800/1000000: episode: 3548, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.912, mean reward: 0.609 [0.499, 0.884], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.164, 10.226], loss: 0.001421, mae: 0.040945, mean_q: 1.165780
 354900/1000000: episode: 3549, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.038, mean reward: 0.580 [0.501, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.154, 10.220], loss: 0.001444, mae: 0.041244, mean_q: 1.162618
 355000/1000000: episode: 3550, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 56.621, mean reward: 0.566 [0.506, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.927, 10.184], loss: 0.001411, mae: 0.040779, mean_q: 1.164631
 355100/1000000: episode: 3551, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.933, mean reward: 0.599 [0.512, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.784, 10.141], loss: 0.001408, mae: 0.040860, mean_q: 1.162014
 355200/1000000: episode: 3552, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.614, mean reward: 0.586 [0.506, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.692, 10.116], loss: 0.001478, mae: 0.042655, mean_q: 1.164501
 355300/1000000: episode: 3553, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 60.634, mean reward: 0.606 [0.508, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.794, 10.277], loss: 0.001551, mae: 0.043136, mean_q: 1.163684
 355400/1000000: episode: 3554, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 63.221, mean reward: 0.632 [0.511, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.453, 10.397], loss: 0.001437, mae: 0.041140, mean_q: 1.163509
 355500/1000000: episode: 3555, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.625, mean reward: 0.576 [0.504, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.185, 10.098], loss: 0.001416, mae: 0.041176, mean_q: 1.166356
 355600/1000000: episode: 3556, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.867, mean reward: 0.619 [0.511, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.429, 10.451], loss: 0.001547, mae: 0.043092, mean_q: 1.168074
 355700/1000000: episode: 3557, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.614, mean reward: 0.586 [0.513, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.376, 10.102], loss: 0.001459, mae: 0.041511, mean_q: 1.165619
 355800/1000000: episode: 3558, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.044, mean reward: 0.590 [0.509, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.599, 10.098], loss: 0.001403, mae: 0.040811, mean_q: 1.165689
 355900/1000000: episode: 3559, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.916, mean reward: 0.599 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.135, 10.150], loss: 0.001434, mae: 0.041653, mean_q: 1.167298
 356000/1000000: episode: 3560, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.671, mean reward: 0.577 [0.506, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.756, 10.098], loss: 0.001539, mae: 0.042719, mean_q: 1.168289
 356100/1000000: episode: 3561, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.368, mean reward: 0.584 [0.515, 0.670], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.012, 10.196], loss: 0.001405, mae: 0.040442, mean_q: 1.167846
 356200/1000000: episode: 3562, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.211, mean reward: 0.592 [0.502, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.748, 10.216], loss: 0.001424, mae: 0.040911, mean_q: 1.167840
 356300/1000000: episode: 3563, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.089, mean reward: 0.581 [0.510, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.538, 10.110], loss: 0.001453, mae: 0.041781, mean_q: 1.169614
 356400/1000000: episode: 3564, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.288, mean reward: 0.603 [0.504, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.146, 10.098], loss: 0.001477, mae: 0.041651, mean_q: 1.170048
 356500/1000000: episode: 3565, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 57.499, mean reward: 0.575 [0.500, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.420, 10.242], loss: 0.001421, mae: 0.041462, mean_q: 1.167856
 356600/1000000: episode: 3566, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.358, mean reward: 0.584 [0.506, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.304, 10.329], loss: 0.001480, mae: 0.041826, mean_q: 1.166838
 356700/1000000: episode: 3567, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.446, mean reward: 0.574 [0.506, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-1.145, 10.287], loss: 0.001521, mae: 0.042828, mean_q: 1.170913
 356800/1000000: episode: 3568, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.070, mean reward: 0.591 [0.517, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-1.203, 10.098], loss: 0.001508, mae: 0.042249, mean_q: 1.164982
 356900/1000000: episode: 3569, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.519, mean reward: 0.585 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.903, 10.104], loss: 0.001531, mae: 0.042925, mean_q: 1.170023
 357000/1000000: episode: 3570, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.832, mean reward: 0.588 [0.499, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.631, 10.098], loss: 0.001492, mae: 0.042611, mean_q: 1.169663
 357100/1000000: episode: 3571, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.412, mean reward: 0.594 [0.512, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.764, 10.103], loss: 0.001492, mae: 0.041973, mean_q: 1.170457
 357200/1000000: episode: 3572, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.410, mean reward: 0.604 [0.505, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.464, 10.370], loss: 0.001558, mae: 0.042912, mean_q: 1.168136
 357300/1000000: episode: 3573, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.675, mean reward: 0.607 [0.523, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.127, 10.347], loss: 0.001538, mae: 0.042867, mean_q: 1.170278
 357400/1000000: episode: 3574, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.104, mean reward: 0.571 [0.507, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.646, 10.098], loss: 0.001511, mae: 0.041984, mean_q: 1.167269
 357500/1000000: episode: 3575, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.662, mean reward: 0.587 [0.507, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.557, 10.098], loss: 0.001441, mae: 0.041453, mean_q: 1.171281
 357600/1000000: episode: 3576, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.203, mean reward: 0.602 [0.504, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.586, 10.120], loss: 0.001401, mae: 0.040544, mean_q: 1.170180
 357700/1000000: episode: 3577, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.297, mean reward: 0.593 [0.506, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.809, 10.201], loss: 0.001518, mae: 0.041883, mean_q: 1.171173
 357800/1000000: episode: 3578, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.012, mean reward: 0.580 [0.499, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.641, 10.103], loss: 0.001468, mae: 0.042048, mean_q: 1.168934
 357900/1000000: episode: 3579, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.687, mean reward: 0.577 [0.501, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.667, 10.171], loss: 0.001540, mae: 0.042418, mean_q: 1.169302
 358000/1000000: episode: 3580, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.560, mean reward: 0.586 [0.510, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.602, 10.139], loss: 0.001456, mae: 0.041874, mean_q: 1.170064
 358100/1000000: episode: 3581, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.470, mean reward: 0.575 [0.502, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.164, 10.218], loss: 0.001421, mae: 0.041141, mean_q: 1.169101
 358200/1000000: episode: 3582, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.494, mean reward: 0.585 [0.502, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.179, 10.160], loss: 0.001455, mae: 0.041595, mean_q: 1.170617
 358300/1000000: episode: 3583, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.428, mean reward: 0.604 [0.509, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.158, 10.098], loss: 0.001524, mae: 0.042397, mean_q: 1.169194
 358400/1000000: episode: 3584, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.909, mean reward: 0.609 [0.502, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.067, 10.388], loss: 0.001495, mae: 0.042239, mean_q: 1.167423
 358500/1000000: episode: 3585, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.438, mean reward: 0.594 [0.506, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.681, 10.098], loss: 0.001381, mae: 0.040128, mean_q: 1.167765
 358600/1000000: episode: 3586, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 60.889, mean reward: 0.609 [0.508, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.779, 10.364], loss: 0.001428, mae: 0.041346, mean_q: 1.170038
 358700/1000000: episode: 3587, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.952, mean reward: 0.590 [0.500, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.519, 10.098], loss: 0.001448, mae: 0.041331, mean_q: 1.171062
 358800/1000000: episode: 3588, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.664, mean reward: 0.577 [0.507, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.479, 10.098], loss: 0.001363, mae: 0.040370, mean_q: 1.167386
 358900/1000000: episode: 3589, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 56.478, mean reward: 0.565 [0.502, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.457, 10.098], loss: 0.001455, mae: 0.041722, mean_q: 1.170266
 359000/1000000: episode: 3590, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.891, mean reward: 0.609 [0.518, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.234, 10.098], loss: 0.001315, mae: 0.039920, mean_q: 1.166669
 359100/1000000: episode: 3591, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.408, mean reward: 0.594 [0.499, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.825, 10.098], loss: 0.001476, mae: 0.041475, mean_q: 1.168805
 359200/1000000: episode: 3592, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 58.807, mean reward: 0.588 [0.505, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.299, 10.098], loss: 0.001350, mae: 0.039912, mean_q: 1.169151
 359300/1000000: episode: 3593, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.739, mean reward: 0.587 [0.498, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.193, 10.098], loss: 0.001449, mae: 0.041685, mean_q: 1.167839
 359400/1000000: episode: 3594, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.332, mean reward: 0.593 [0.512, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.382, 10.130], loss: 0.001377, mae: 0.040432, mean_q: 1.168749
 359500/1000000: episode: 3595, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.258, mean reward: 0.583 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.739, 10.256], loss: 0.001354, mae: 0.040391, mean_q: 1.168565
 359600/1000000: episode: 3596, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.311, mean reward: 0.603 [0.501, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.943, 10.098], loss: 0.001547, mae: 0.042770, mean_q: 1.171470
 359700/1000000: episode: 3597, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.673, mean reward: 0.577 [0.498, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.980, 10.257], loss: 0.001443, mae: 0.041539, mean_q: 1.168608
 359800/1000000: episode: 3598, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.703, mean reward: 0.577 [0.506, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.634, 10.211], loss: 0.001340, mae: 0.039595, mean_q: 1.165792
 359900/1000000: episode: 3599, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.639, mean reward: 0.576 [0.502, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.387, 10.208], loss: 0.001434, mae: 0.041294, mean_q: 1.168346
 360000/1000000: episode: 3600, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.827, mean reward: 0.568 [0.502, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.544, 10.167], loss: 0.001473, mae: 0.041531, mean_q: 1.167194
 360100/1000000: episode: 3601, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.946, mean reward: 0.589 [0.511, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.262, 10.098], loss: 0.001422, mae: 0.041015, mean_q: 1.163754
 360200/1000000: episode: 3602, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.403, mean reward: 0.594 [0.505, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.618, 10.098], loss: 0.001429, mae: 0.041162, mean_q: 1.165510
 360300/1000000: episode: 3603, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 56.934, mean reward: 0.569 [0.507, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.198, 10.138], loss: 0.001438, mae: 0.040829, mean_q: 1.166208
 360400/1000000: episode: 3604, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.624, mean reward: 0.596 [0.504, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.394, 10.098], loss: 0.001440, mae: 0.041454, mean_q: 1.163030
 360500/1000000: episode: 3605, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.479, mean reward: 0.575 [0.506, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.424, 10.098], loss: 0.001342, mae: 0.039880, mean_q: 1.165596
 360600/1000000: episode: 3606, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 61.362, mean reward: 0.614 [0.500, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.743, 10.098], loss: 0.001362, mae: 0.039968, mean_q: 1.163413
 360700/1000000: episode: 3607, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.633, mean reward: 0.616 [0.511, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.904, 10.331], loss: 0.001396, mae: 0.040779, mean_q: 1.164291
 360800/1000000: episode: 3608, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 58.328, mean reward: 0.583 [0.499, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.680, 10.218], loss: 0.001394, mae: 0.040768, mean_q: 1.165452
 360900/1000000: episode: 3609, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.125, mean reward: 0.581 [0.510, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.350, 10.098], loss: 0.001440, mae: 0.041134, mean_q: 1.164756
 361000/1000000: episode: 3610, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.574, mean reward: 0.576 [0.515, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.446, 10.098], loss: 0.001412, mae: 0.040504, mean_q: 1.162102
 361100/1000000: episode: 3611, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.063, mean reward: 0.591 [0.506, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.475, 10.216], loss: 0.001449, mae: 0.041307, mean_q: 1.164459
 361200/1000000: episode: 3612, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.593, mean reward: 0.606 [0.505, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.813, 10.400], loss: 0.001501, mae: 0.042208, mean_q: 1.166887
 361300/1000000: episode: 3613, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.292, mean reward: 0.583 [0.500, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.654, 10.215], loss: 0.001449, mae: 0.041263, mean_q: 1.165954
 361400/1000000: episode: 3614, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.409, mean reward: 0.604 [0.500, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.780, 10.416], loss: 0.001395, mae: 0.040800, mean_q: 1.165131
 361500/1000000: episode: 3615, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.030, mean reward: 0.600 [0.511, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.530, 10.098], loss: 0.001595, mae: 0.043056, mean_q: 1.168298
 361600/1000000: episode: 3616, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.929, mean reward: 0.589 [0.506, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.052, 10.119], loss: 0.001497, mae: 0.042035, mean_q: 1.165755
 361700/1000000: episode: 3617, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.489, mean reward: 0.585 [0.500, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.131, 10.236], loss: 0.001554, mae: 0.042512, mean_q: 1.172001
 361800/1000000: episode: 3618, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.336, mean reward: 0.613 [0.499, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.977, 10.098], loss: 0.001437, mae: 0.041173, mean_q: 1.167235
 361900/1000000: episode: 3619, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.033, mean reward: 0.600 [0.509, 0.877], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.778, 10.291], loss: 0.001397, mae: 0.040298, mean_q: 1.165585
 362000/1000000: episode: 3620, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.521, mean reward: 0.575 [0.502, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.509, 10.157], loss: 0.001421, mae: 0.040830, mean_q: 1.166908
 362100/1000000: episode: 3621, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.769, mean reward: 0.608 [0.518, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.714, 10.098], loss: 0.001508, mae: 0.041964, mean_q: 1.170708
 362200/1000000: episode: 3622, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.673, mean reward: 0.587 [0.512, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.517, 10.267], loss: 0.001462, mae: 0.041604, mean_q: 1.168418
 362300/1000000: episode: 3623, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.903, mean reward: 0.589 [0.504, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.626, 10.358], loss: 0.001436, mae: 0.040995, mean_q: 1.165297
 362400/1000000: episode: 3624, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 62.396, mean reward: 0.624 [0.509, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.433, 10.098], loss: 0.001521, mae: 0.041546, mean_q: 1.167948
 362500/1000000: episode: 3625, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 62.206, mean reward: 0.622 [0.501, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-2.799, 10.098], loss: 0.001425, mae: 0.040194, mean_q: 1.171999
 362600/1000000: episode: 3626, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.457, mean reward: 0.575 [0.502, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.341, 10.201], loss: 0.001471, mae: 0.041136, mean_q: 1.169139
 362700/1000000: episode: 3627, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.968, mean reward: 0.590 [0.505, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.257, 10.098], loss: 0.001452, mae: 0.041289, mean_q: 1.172336
 362800/1000000: episode: 3628, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.001, mean reward: 0.590 [0.501, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.707, 10.244], loss: 0.001557, mae: 0.042848, mean_q: 1.171695
 362900/1000000: episode: 3629, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.539, mean reward: 0.585 [0.504, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.626, 10.343], loss: 0.001620, mae: 0.043138, mean_q: 1.170785
 363000/1000000: episode: 3630, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.917, mean reward: 0.589 [0.501, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.367, 10.106], loss: 0.001558, mae: 0.042464, mean_q: 1.171500
 363100/1000000: episode: 3631, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.832, mean reward: 0.598 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.576, 10.270], loss: 0.001589, mae: 0.042560, mean_q: 1.174067
 363200/1000000: episode: 3632, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.058, mean reward: 0.601 [0.507, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.472, 10.098], loss: 0.001637, mae: 0.042865, mean_q: 1.172596
 363300/1000000: episode: 3633, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.789, mean reward: 0.578 [0.497, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.423, 10.168], loss: 0.001470, mae: 0.042038, mean_q: 1.172502
 363400/1000000: episode: 3634, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.114, mean reward: 0.571 [0.502, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.891, 10.329], loss: 0.001551, mae: 0.042677, mean_q: 1.168039
 363500/1000000: episode: 3635, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.023, mean reward: 0.580 [0.505, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.852, 10.098], loss: 0.001595, mae: 0.042829, mean_q: 1.168465
 363600/1000000: episode: 3636, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 62.310, mean reward: 0.623 [0.508, 0.897], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.034, 10.098], loss: 0.001490, mae: 0.041802, mean_q: 1.166305
 363700/1000000: episode: 3637, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.522, mean reward: 0.585 [0.512, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.815, 10.178], loss: 0.001542, mae: 0.042016, mean_q: 1.167503
 363800/1000000: episode: 3638, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.618, mean reward: 0.606 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.227, 10.098], loss: 0.001509, mae: 0.041627, mean_q: 1.168357
 363900/1000000: episode: 3639, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 59.717, mean reward: 0.597 [0.505, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.927, 10.173], loss: 0.001540, mae: 0.042700, mean_q: 1.171162
 364000/1000000: episode: 3640, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.687, mean reward: 0.607 [0.502, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.319, 10.246], loss: 0.001553, mae: 0.042621, mean_q: 1.172168
 364100/1000000: episode: 3641, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.699, mean reward: 0.577 [0.501, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.000, 10.152], loss: 0.001514, mae: 0.042031, mean_q: 1.174143
 364200/1000000: episode: 3642, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.051, mean reward: 0.581 [0.503, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.804, 10.152], loss: 0.001493, mae: 0.041695, mean_q: 1.170059
 364300/1000000: episode: 3643, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.974, mean reward: 0.600 [0.530, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.737, 10.098], loss: 0.001568, mae: 0.043173, mean_q: 1.170894
 364400/1000000: episode: 3644, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.727, mean reward: 0.577 [0.509, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.487, 10.279], loss: 0.001470, mae: 0.041887, mean_q: 1.171039
 364500/1000000: episode: 3645, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.050, mean reward: 0.581 [0.499, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.018, 10.098], loss: 0.001656, mae: 0.044131, mean_q: 1.174174
 364600/1000000: episode: 3646, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 56.963, mean reward: 0.570 [0.504, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.403, 10.100], loss: 0.001486, mae: 0.042303, mean_q: 1.172442
 364700/1000000: episode: 3647, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 61.592, mean reward: 0.616 [0.518, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.433, 10.098], loss: 0.001496, mae: 0.042292, mean_q: 1.174696
 364800/1000000: episode: 3648, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.879, mean reward: 0.599 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.539, 10.130], loss: 0.001504, mae: 0.041835, mean_q: 1.172370
 364900/1000000: episode: 3649, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 62.505, mean reward: 0.625 [0.523, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.832, 10.098], loss: 0.001530, mae: 0.042044, mean_q: 1.170497
 365000/1000000: episode: 3650, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.480, mean reward: 0.575 [0.507, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.010, 10.124], loss: 0.001588, mae: 0.043301, mean_q: 1.171164
 365100/1000000: episode: 3651, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.616, mean reward: 0.576 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.903, 10.318], loss: 0.001628, mae: 0.043356, mean_q: 1.173609
 365200/1000000: episode: 3652, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.760, mean reward: 0.598 [0.505, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.609, 10.297], loss: 0.001446, mae: 0.041491, mean_q: 1.170823
 365300/1000000: episode: 3653, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.656, mean reward: 0.577 [0.505, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.771, 10.200], loss: 0.001459, mae: 0.041154, mean_q: 1.174956
 365400/1000000: episode: 3654, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.391, mean reward: 0.584 [0.497, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.957, 10.098], loss: 0.001553, mae: 0.042581, mean_q: 1.168725
 365500/1000000: episode: 3655, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.279, mean reward: 0.603 [0.516, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.559, 10.165], loss: 0.001622, mae: 0.043903, mean_q: 1.173711
 365600/1000000: episode: 3656, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.934, mean reward: 0.589 [0.508, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.943, 10.098], loss: 0.001568, mae: 0.042694, mean_q: 1.169049
 365700/1000000: episode: 3657, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.276, mean reward: 0.603 [0.517, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.043, 10.098], loss: 0.001439, mae: 0.041591, mean_q: 1.171327
 365800/1000000: episode: 3658, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.019, mean reward: 0.580 [0.505, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.321, 10.098], loss: 0.001502, mae: 0.042000, mean_q: 1.173574
 365900/1000000: episode: 3659, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 65.056, mean reward: 0.651 [0.515, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.738, 10.426], loss: 0.001466, mae: 0.041982, mean_q: 1.174128
 366000/1000000: episode: 3660, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.584, mean reward: 0.606 [0.502, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.062, 10.338], loss: 0.001486, mae: 0.042267, mean_q: 1.175339
 366100/1000000: episode: 3661, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.527, mean reward: 0.605 [0.508, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.940, 10.098], loss: 0.001527, mae: 0.043376, mean_q: 1.174764
 366200/1000000: episode: 3662, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.158, mean reward: 0.592 [0.502, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.235, 10.098], loss: 0.001532, mae: 0.042623, mean_q: 1.174194
 366300/1000000: episode: 3663, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.701, mean reward: 0.597 [0.504, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.149, 10.098], loss: 0.001469, mae: 0.041873, mean_q: 1.178846
 366400/1000000: episode: 3664, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.915, mean reward: 0.579 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.336, 10.098], loss: 0.001596, mae: 0.043699, mean_q: 1.179426
 366500/1000000: episode: 3665, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.600, mean reward: 0.576 [0.501, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.172, 10.098], loss: 0.001512, mae: 0.043073, mean_q: 1.171147
 366600/1000000: episode: 3666, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.426, mean reward: 0.604 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.911, 10.098], loss: 0.001518, mae: 0.042557, mean_q: 1.172956
 366700/1000000: episode: 3667, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.419, mean reward: 0.574 [0.500, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.899, 10.098], loss: 0.001575, mae: 0.043235, mean_q: 1.177960
 366800/1000000: episode: 3668, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.425, mean reward: 0.594 [0.515, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.508, 10.098], loss: 0.001497, mae: 0.042160, mean_q: 1.174181
 366900/1000000: episode: 3669, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 56.530, mean reward: 0.565 [0.504, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.556, 10.099], loss: 0.001484, mae: 0.042039, mean_q: 1.172257
 367000/1000000: episode: 3670, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.478, mean reward: 0.605 [0.503, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.006, 10.098], loss: 0.001438, mae: 0.041775, mean_q: 1.174140
 367100/1000000: episode: 3671, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.534, mean reward: 0.595 [0.514, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.472, 10.098], loss: 0.001411, mae: 0.041247, mean_q: 1.175122
 367200/1000000: episode: 3672, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.321, mean reward: 0.593 [0.530, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.213, 10.195], loss: 0.001372, mae: 0.041166, mean_q: 1.173978
 367300/1000000: episode: 3673, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.209, mean reward: 0.582 [0.501, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.977, 10.248], loss: 0.001360, mae: 0.040239, mean_q: 1.174795
 367400/1000000: episode: 3674, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.017, mean reward: 0.570 [0.500, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.792, 10.098], loss: 0.001478, mae: 0.042114, mean_q: 1.173302
 367500/1000000: episode: 3675, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.835, mean reward: 0.598 [0.501, 0.900], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.377, 10.098], loss: 0.001464, mae: 0.041884, mean_q: 1.168602
 367600/1000000: episode: 3676, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 61.769, mean reward: 0.618 [0.501, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.655, 10.098], loss: 0.001458, mae: 0.041842, mean_q: 1.172449
 367700/1000000: episode: 3677, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 60.455, mean reward: 0.605 [0.510, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.468, 10.189], loss: 0.001461, mae: 0.041890, mean_q: 1.172886
 367800/1000000: episode: 3678, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.206, mean reward: 0.592 [0.500, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.409, 10.117], loss: 0.001496, mae: 0.041713, mean_q: 1.169238
 367900/1000000: episode: 3679, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.256, mean reward: 0.583 [0.500, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.297, 10.098], loss: 0.001401, mae: 0.040937, mean_q: 1.172152
 368000/1000000: episode: 3680, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.307, mean reward: 0.593 [0.510, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.080, 10.156], loss: 0.001513, mae: 0.042963, mean_q: 1.171294
 368100/1000000: episode: 3681, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.722, mean reward: 0.587 [0.506, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.682, 10.111], loss: 0.001448, mae: 0.041739, mean_q: 1.169359
 368200/1000000: episode: 3682, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.889, mean reward: 0.589 [0.501, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.874, 10.098], loss: 0.001485, mae: 0.042135, mean_q: 1.170677
 368300/1000000: episode: 3683, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.064, mean reward: 0.601 [0.511, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.667, 10.341], loss: 0.001438, mae: 0.041787, mean_q: 1.170374
 368400/1000000: episode: 3684, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 57.324, mean reward: 0.573 [0.507, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.927, 10.185], loss: 0.001468, mae: 0.041658, mean_q: 1.174798
 368500/1000000: episode: 3685, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.833, mean reward: 0.588 [0.505, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.418, 10.221], loss: 0.001485, mae: 0.042338, mean_q: 1.173474
 368600/1000000: episode: 3686, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.422, mean reward: 0.574 [0.499, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.357, 10.098], loss: 0.001507, mae: 0.042493, mean_q: 1.170553
 368700/1000000: episode: 3687, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.909, mean reward: 0.599 [0.513, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.778, 10.098], loss: 0.001574, mae: 0.043092, mean_q: 1.170424
 368800/1000000: episode: 3688, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.604, mean reward: 0.586 [0.508, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.388, 10.098], loss: 0.001459, mae: 0.041609, mean_q: 1.169594
 368900/1000000: episode: 3689, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.527, mean reward: 0.575 [0.509, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.524, 10.098], loss: 0.001369, mae: 0.040375, mean_q: 1.167524
 369000/1000000: episode: 3690, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.171, mean reward: 0.592 [0.499, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.552, 10.098], loss: 0.001460, mae: 0.041389, mean_q: 1.170235
 369100/1000000: episode: 3691, duration: 0.517s, episode steps: 100, steps per second: 193, episode reward: 58.879, mean reward: 0.589 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.606, 10.102], loss: 0.001477, mae: 0.042115, mean_q: 1.170623
 369200/1000000: episode: 3692, duration: 0.525s, episode steps: 100, steps per second: 191, episode reward: 57.958, mean reward: 0.580 [0.506, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.472, 10.358], loss: 0.001473, mae: 0.041892, mean_q: 1.167991
 369300/1000000: episode: 3693, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.143, mean reward: 0.591 [0.505, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.905, 10.200], loss: 0.001529, mae: 0.042125, mean_q: 1.172856
 369400/1000000: episode: 3694, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.701, mean reward: 0.577 [0.503, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.414, 10.098], loss: 0.001478, mae: 0.041604, mean_q: 1.171442
 369500/1000000: episode: 3695, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.727, mean reward: 0.577 [0.505, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.213, 10.143], loss: 0.001482, mae: 0.041972, mean_q: 1.169814
 369600/1000000: episode: 3696, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.706, mean reward: 0.597 [0.503, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.461, 10.203], loss: 0.001459, mae: 0.041511, mean_q: 1.166660
 369700/1000000: episode: 3697, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.221, mean reward: 0.582 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.798, 10.282], loss: 0.001501, mae: 0.042082, mean_q: 1.166208
 369800/1000000: episode: 3698, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.823, mean reward: 0.588 [0.503, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.241, 10.137], loss: 0.001481, mae: 0.042199, mean_q: 1.171589
 369900/1000000: episode: 3699, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.349, mean reward: 0.583 [0.504, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.698, 10.117], loss: 0.001486, mae: 0.042697, mean_q: 1.168381
 370000/1000000: episode: 3700, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.740, mean reward: 0.597 [0.503, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.507, 10.098], loss: 0.001492, mae: 0.042253, mean_q: 1.170541
 370100/1000000: episode: 3701, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.095, mean reward: 0.581 [0.505, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.972, 10.098], loss: 0.001428, mae: 0.041582, mean_q: 1.167534
 370200/1000000: episode: 3702, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.583, mean reward: 0.596 [0.501, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.668, 10.158], loss: 0.001423, mae: 0.041346, mean_q: 1.167634
 370300/1000000: episode: 3703, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 56.612, mean reward: 0.566 [0.501, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.652, 10.134], loss: 0.001504, mae: 0.042316, mean_q: 1.168633
 370400/1000000: episode: 3704, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.809, mean reward: 0.578 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.006, 10.098], loss: 0.001391, mae: 0.040824, mean_q: 1.165345
 370500/1000000: episode: 3705, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.053, mean reward: 0.591 [0.511, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.854, 10.127], loss: 0.001513, mae: 0.042504, mean_q: 1.167331
 370600/1000000: episode: 3706, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.753, mean reward: 0.568 [0.502, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.979, 10.194], loss: 0.001500, mae: 0.041803, mean_q: 1.167043
 370700/1000000: episode: 3707, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 56.834, mean reward: 0.568 [0.500, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.461, 10.098], loss: 0.001438, mae: 0.041647, mean_q: 1.162661
 370800/1000000: episode: 3708, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.016, mean reward: 0.580 [0.499, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.736, 10.215], loss: 0.001502, mae: 0.042377, mean_q: 1.165072
 370900/1000000: episode: 3709, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 60.236, mean reward: 0.602 [0.502, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.149, 10.259], loss: 0.001428, mae: 0.041446, mean_q: 1.161629
 371000/1000000: episode: 3710, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.012, mean reward: 0.600 [0.502, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.102, 10.098], loss: 0.001524, mae: 0.042485, mean_q: 1.164873
 371100/1000000: episode: 3711, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 60.159, mean reward: 0.602 [0.510, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.097, 10.098], loss: 0.001466, mae: 0.041812, mean_q: 1.162505
 371200/1000000: episode: 3712, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.563, mean reward: 0.596 [0.501, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.558, 10.123], loss: 0.001606, mae: 0.043783, mean_q: 1.165459
 371300/1000000: episode: 3713, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.283, mean reward: 0.583 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.146, 10.098], loss: 0.001541, mae: 0.042712, mean_q: 1.158926
 371400/1000000: episode: 3714, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.241, mean reward: 0.582 [0.503, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.408, 10.212], loss: 0.001408, mae: 0.040948, mean_q: 1.163936
 371500/1000000: episode: 3715, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.578, mean reward: 0.586 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.313, 10.180], loss: 0.001469, mae: 0.042024, mean_q: 1.160159
 371600/1000000: episode: 3716, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.118, mean reward: 0.581 [0.501, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.902, 10.098], loss: 0.001483, mae: 0.042361, mean_q: 1.161642
 371700/1000000: episode: 3717, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.227, mean reward: 0.592 [0.502, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.818, 10.171], loss: 0.001484, mae: 0.042150, mean_q: 1.161396
 371800/1000000: episode: 3718, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.071, mean reward: 0.601 [0.515, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.802, 10.267], loss: 0.001518, mae: 0.042417, mean_q: 1.162583
 371900/1000000: episode: 3719, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.909, mean reward: 0.579 [0.499, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.800, 10.098], loss: 0.001459, mae: 0.041806, mean_q: 1.160246
 372000/1000000: episode: 3720, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.936, mean reward: 0.589 [0.510, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.664, 10.385], loss: 0.001530, mae: 0.042506, mean_q: 1.160789
 372100/1000000: episode: 3721, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.789, mean reward: 0.598 [0.513, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.716, 10.098], loss: 0.001560, mae: 0.042947, mean_q: 1.162198
 372200/1000000: episode: 3722, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.960, mean reward: 0.580 [0.504, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.586, 10.098], loss: 0.001537, mae: 0.043024, mean_q: 1.161548
 372300/1000000: episode: 3723, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.732, mean reward: 0.607 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.763, 10.413], loss: 0.001570, mae: 0.043571, mean_q: 1.165301
 372400/1000000: episode: 3724, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.196, mean reward: 0.612 [0.503, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.361, 10.098], loss: 0.001572, mae: 0.043972, mean_q: 1.164451
 372500/1000000: episode: 3725, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.764, mean reward: 0.588 [0.502, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.806, 10.098], loss: 0.001539, mae: 0.042711, mean_q: 1.164384
 372600/1000000: episode: 3726, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 56.980, mean reward: 0.570 [0.508, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.761, 10.098], loss: 0.001524, mae: 0.042809, mean_q: 1.164898
 372700/1000000: episode: 3727, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.154, mean reward: 0.602 [0.503, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.716, 10.225], loss: 0.001594, mae: 0.044032, mean_q: 1.163018
 372800/1000000: episode: 3728, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.263, mean reward: 0.573 [0.505, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.771, 10.236], loss: 0.001539, mae: 0.043317, mean_q: 1.162954
 372900/1000000: episode: 3729, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 64.133, mean reward: 0.641 [0.539, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.514, 10.370], loss: 0.001530, mae: 0.042889, mean_q: 1.162123
 373000/1000000: episode: 3730, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 61.950, mean reward: 0.619 [0.516, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.447, 10.263], loss: 0.001534, mae: 0.043443, mean_q: 1.164525
 373100/1000000: episode: 3731, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.687, mean reward: 0.597 [0.524, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.087, 10.098], loss: 0.001505, mae: 0.042564, mean_q: 1.165482
 373200/1000000: episode: 3732, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 57.490, mean reward: 0.575 [0.507, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.900, 10.268], loss: 0.001534, mae: 0.043150, mean_q: 1.166651
 373300/1000000: episode: 3733, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.214, mean reward: 0.572 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.815, 10.142], loss: 0.001554, mae: 0.043128, mean_q: 1.164327
 373400/1000000: episode: 3734, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.326, mean reward: 0.583 [0.501, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.194, 10.098], loss: 0.001580, mae: 0.043891, mean_q: 1.163856
 373500/1000000: episode: 3735, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.471, mean reward: 0.575 [0.502, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.629, 10.140], loss: 0.001607, mae: 0.044765, mean_q: 1.167699
 373600/1000000: episode: 3736, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.910, mean reward: 0.589 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.254, 10.205], loss: 0.001638, mae: 0.044481, mean_q: 1.161173
 373700/1000000: episode: 3737, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.141, mean reward: 0.581 [0.499, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.610, 10.171], loss: 0.001641, mae: 0.044860, mean_q: 1.161596
 373800/1000000: episode: 3738, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.433, mean reward: 0.574 [0.504, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.442, 10.098], loss: 0.001472, mae: 0.041907, mean_q: 1.163656
 373900/1000000: episode: 3739, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.460, mean reward: 0.595 [0.508, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.606, 10.304], loss: 0.001542, mae: 0.043391, mean_q: 1.163372
 374000/1000000: episode: 3740, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.928, mean reward: 0.579 [0.509, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.084, 10.098], loss: 0.001547, mae: 0.043037, mean_q: 1.164025
 374100/1000000: episode: 3741, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 57.803, mean reward: 0.578 [0.503, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.344, 10.098], loss: 0.001517, mae: 0.042929, mean_q: 1.163293
 374200/1000000: episode: 3742, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 56.914, mean reward: 0.569 [0.501, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.737, 10.129], loss: 0.001421, mae: 0.041514, mean_q: 1.162399
 374300/1000000: episode: 3743, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.414, mean reward: 0.594 [0.500, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.406, 10.098], loss: 0.001428, mae: 0.042084, mean_q: 1.162161
 374400/1000000: episode: 3744, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.939, mean reward: 0.579 [0.502, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.984, 10.159], loss: 0.001501, mae: 0.042759, mean_q: 1.164750
 374500/1000000: episode: 3745, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.861, mean reward: 0.609 [0.509, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.397, 10.098], loss: 0.001457, mae: 0.041989, mean_q: 1.164943
 374600/1000000: episode: 3746, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.833, mean reward: 0.578 [0.499, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.880, 10.098], loss: 0.001493, mae: 0.042710, mean_q: 1.166586
 374700/1000000: episode: 3747, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.103, mean reward: 0.581 [0.501, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.859, 10.098], loss: 0.001539, mae: 0.042542, mean_q: 1.163870
 374800/1000000: episode: 3748, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.667, mean reward: 0.607 [0.505, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.854, 10.098], loss: 0.001567, mae: 0.043515, mean_q: 1.166691
 374900/1000000: episode: 3749, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.019, mean reward: 0.580 [0.521, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.532, 10.144], loss: 0.001494, mae: 0.042277, mean_q: 1.166862
 375000/1000000: episode: 3750, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.304, mean reward: 0.593 [0.510, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.948, 10.098], loss: 0.001492, mae: 0.042229, mean_q: 1.163201
 375100/1000000: episode: 3751, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.318, mean reward: 0.613 [0.503, 0.841], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.706, 10.297], loss: 0.001466, mae: 0.042017, mean_q: 1.168824
 375200/1000000: episode: 3752, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.084, mean reward: 0.591 [0.499, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.486, 10.308], loss: 0.001459, mae: 0.041949, mean_q: 1.166210
 375300/1000000: episode: 3753, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.778, mean reward: 0.578 [0.506, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.557, 10.180], loss: 0.001447, mae: 0.041675, mean_q: 1.163458
 375400/1000000: episode: 3754, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.807, mean reward: 0.608 [0.501, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.018, 10.225], loss: 0.001439, mae: 0.041895, mean_q: 1.167147
 375500/1000000: episode: 3755, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.446, mean reward: 0.604 [0.504, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.720, 10.506], loss: 0.001489, mae: 0.042308, mean_q: 1.164850
 375600/1000000: episode: 3756, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.155, mean reward: 0.592 [0.507, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.279, 10.333], loss: 0.001521, mae: 0.042299, mean_q: 1.167958
 375700/1000000: episode: 3757, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.250, mean reward: 0.593 [0.520, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.688, 10.098], loss: 0.001432, mae: 0.041195, mean_q: 1.168397
 375800/1000000: episode: 3758, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.872, mean reward: 0.599 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.805, 10.307], loss: 0.001411, mae: 0.041015, mean_q: 1.167546
 375900/1000000: episode: 3759, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 56.510, mean reward: 0.565 [0.505, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.348, 10.098], loss: 0.001447, mae: 0.041996, mean_q: 1.165983
 376000/1000000: episode: 3760, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.463, mean reward: 0.575 [0.508, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.029, 10.159], loss: 0.001360, mae: 0.040267, mean_q: 1.166884
 376100/1000000: episode: 3761, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.384, mean reward: 0.584 [0.497, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.806, 10.115], loss: 0.001448, mae: 0.041855, mean_q: 1.170556
 376200/1000000: episode: 3762, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.537, mean reward: 0.595 [0.503, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.849, 10.098], loss: 0.001494, mae: 0.042267, mean_q: 1.166631
 376300/1000000: episode: 3763, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.838, mean reward: 0.588 [0.510, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.890, 10.098], loss: 0.001375, mae: 0.040779, mean_q: 1.167866
 376400/1000000: episode: 3764, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 55.971, mean reward: 0.560 [0.499, 0.662], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.127, 10.128], loss: 0.001410, mae: 0.041519, mean_q: 1.165154
 376500/1000000: episode: 3765, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 55.933, mean reward: 0.559 [0.498, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.598, 10.128], loss: 0.001406, mae: 0.041289, mean_q: 1.164445
 376600/1000000: episode: 3766, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.698, mean reward: 0.607 [0.502, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.319, 10.098], loss: 0.001449, mae: 0.041873, mean_q: 1.166228
 376700/1000000: episode: 3767, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.299, mean reward: 0.603 [0.502, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.540, 10.098], loss: 0.001338, mae: 0.040066, mean_q: 1.162611
 376800/1000000: episode: 3768, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.710, mean reward: 0.597 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.382, 10.098], loss: 0.001428, mae: 0.041558, mean_q: 1.164703
 376900/1000000: episode: 3769, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.000, mean reward: 0.590 [0.505, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.563, 10.143], loss: 0.001447, mae: 0.041561, mean_q: 1.168185
 377000/1000000: episode: 3770, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.501, mean reward: 0.585 [0.510, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.898, 10.246], loss: 0.001461, mae: 0.042123, mean_q: 1.169079
 377100/1000000: episode: 3771, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.044, mean reward: 0.580 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.790, 10.180], loss: 0.001311, mae: 0.039777, mean_q: 1.163578
 377200/1000000: episode: 3772, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.328, mean reward: 0.583 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.558, 10.098], loss: 0.001376, mae: 0.040847, mean_q: 1.168071
 377300/1000000: episode: 3773, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 61.790, mean reward: 0.618 [0.501, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.090, 10.170], loss: 0.001423, mae: 0.041381, mean_q: 1.168646
 377400/1000000: episode: 3774, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 62.330, mean reward: 0.623 [0.506, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.558, 10.167], loss: 0.001359, mae: 0.040569, mean_q: 1.166747
 377500/1000000: episode: 3775, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.761, mean reward: 0.588 [0.501, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.454, 10.403], loss: 0.001320, mae: 0.040433, mean_q: 1.169502
 377600/1000000: episode: 3776, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.390, mean reward: 0.584 [0.513, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.336, 10.098], loss: 0.001388, mae: 0.041130, mean_q: 1.167456
 377700/1000000: episode: 3777, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 62.468, mean reward: 0.625 [0.520, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.007, 10.098], loss: 0.001343, mae: 0.040428, mean_q: 1.166153
 377800/1000000: episode: 3778, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.927, mean reward: 0.579 [0.500, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.028, 10.209], loss: 0.001393, mae: 0.041421, mean_q: 1.163921
 377900/1000000: episode: 3779, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.568, mean reward: 0.576 [0.501, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.744, 10.291], loss: 0.001388, mae: 0.040895, mean_q: 1.165483
 378000/1000000: episode: 3780, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.908, mean reward: 0.599 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.932, 10.114], loss: 0.001472, mae: 0.041895, mean_q: 1.161895
 378100/1000000: episode: 3781, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.892, mean reward: 0.599 [0.504, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.803, 10.323], loss: 0.001406, mae: 0.040597, mean_q: 1.162721
 378200/1000000: episode: 3782, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.140, mean reward: 0.601 [0.504, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.447, 10.475], loss: 0.001452, mae: 0.042011, mean_q: 1.162053
 378300/1000000: episode: 3783, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.910, mean reward: 0.589 [0.508, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.724, 10.098], loss: 0.001328, mae: 0.040201, mean_q: 1.165189
 378400/1000000: episode: 3784, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.163, mean reward: 0.592 [0.510, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.762, 10.098], loss: 0.001489, mae: 0.042428, mean_q: 1.165992
 378500/1000000: episode: 3785, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.547, mean reward: 0.585 [0.504, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.534, 10.250], loss: 0.001421, mae: 0.041659, mean_q: 1.167588
 378600/1000000: episode: 3786, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.871, mean reward: 0.579 [0.498, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.348, 10.098], loss: 0.001396, mae: 0.041002, mean_q: 1.167289
 378700/1000000: episode: 3787, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.984, mean reward: 0.580 [0.513, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.063, 10.196], loss: 0.001414, mae: 0.041549, mean_q: 1.170340
 378800/1000000: episode: 3788, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.959, mean reward: 0.590 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.546, 10.098], loss: 0.001375, mae: 0.041235, mean_q: 1.169882
 378900/1000000: episode: 3789, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.170, mean reward: 0.592 [0.498, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.747, 10.098], loss: 0.001350, mae: 0.039787, mean_q: 1.166578
 379000/1000000: episode: 3790, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.101, mean reward: 0.611 [0.510, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.757, 10.186], loss: 0.001438, mae: 0.041246, mean_q: 1.168645
 379100/1000000: episode: 3791, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.444, mean reward: 0.584 [0.502, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.876, 10.198], loss: 0.001395, mae: 0.040884, mean_q: 1.164192
 379200/1000000: episode: 3792, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.825, mean reward: 0.608 [0.514, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.784, 10.293], loss: 0.001435, mae: 0.041721, mean_q: 1.168907
 379300/1000000: episode: 3793, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.090, mean reward: 0.611 [0.505, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.200, 10.225], loss: 0.001421, mae: 0.041246, mean_q: 1.170275
 379400/1000000: episode: 3794, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.460, mean reward: 0.575 [0.502, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.155, 10.098], loss: 0.001464, mae: 0.041635, mean_q: 1.168742
 379500/1000000: episode: 3795, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.551, mean reward: 0.586 [0.504, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.899, 10.160], loss: 0.001421, mae: 0.041486, mean_q: 1.171399
 379600/1000000: episode: 3796, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.095, mean reward: 0.581 [0.507, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.851, 10.190], loss: 0.001430, mae: 0.041716, mean_q: 1.171821
 379700/1000000: episode: 3797, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.942, mean reward: 0.589 [0.503, 0.883], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.663, 10.381], loss: 0.001448, mae: 0.041758, mean_q: 1.171981
 379800/1000000: episode: 3798, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.751, mean reward: 0.598 [0.514, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.170, 10.241], loss: 0.001512, mae: 0.042335, mean_q: 1.172805
 379900/1000000: episode: 3799, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.036, mean reward: 0.570 [0.511, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.511, 10.098], loss: 0.001418, mae: 0.041263, mean_q: 1.167959
 380000/1000000: episode: 3800, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 62.301, mean reward: 0.623 [0.504, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.403, 10.098], loss: 0.001437, mae: 0.041592, mean_q: 1.170274
 380100/1000000: episode: 3801, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.726, mean reward: 0.577 [0.503, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.088, 10.310], loss: 0.001438, mae: 0.041860, mean_q: 1.167360
 380200/1000000: episode: 3802, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.645, mean reward: 0.606 [0.515, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.593, 10.324], loss: 0.001356, mae: 0.040519, mean_q: 1.169416
 380300/1000000: episode: 3803, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.733, mean reward: 0.577 [0.506, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.088, 10.098], loss: 0.001403, mae: 0.040935, mean_q: 1.168048
 380400/1000000: episode: 3804, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.297, mean reward: 0.583 [0.505, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.992, 10.209], loss: 0.001478, mae: 0.042186, mean_q: 1.170537
 380500/1000000: episode: 3805, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 56.189, mean reward: 0.562 [0.503, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.425, 10.168], loss: 0.001390, mae: 0.040629, mean_q: 1.165554
 380600/1000000: episode: 3806, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.470, mean reward: 0.585 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.132, 10.409], loss: 0.001435, mae: 0.041665, mean_q: 1.165734
 380700/1000000: episode: 3807, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.555, mean reward: 0.606 [0.499, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.298, 10.199], loss: 0.001403, mae: 0.041179, mean_q: 1.166535
 380800/1000000: episode: 3808, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.091, mean reward: 0.601 [0.507, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.036, 10.224], loss: 0.001419, mae: 0.041202, mean_q: 1.168347
 380900/1000000: episode: 3809, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.853, mean reward: 0.579 [0.502, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.878, 10.114], loss: 0.001412, mae: 0.041137, mean_q: 1.169461
 381000/1000000: episode: 3810, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.446, mean reward: 0.594 [0.503, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.053, 10.098], loss: 0.001483, mae: 0.041442, mean_q: 1.165565
 381100/1000000: episode: 3811, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.575, mean reward: 0.576 [0.502, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.745, 10.105], loss: 0.001545, mae: 0.042615, mean_q: 1.170010
 381200/1000000: episode: 3812, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.709, mean reward: 0.577 [0.507, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.231, 10.147], loss: 0.001495, mae: 0.042309, mean_q: 1.169534
 381300/1000000: episode: 3813, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.981, mean reward: 0.590 [0.511, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.802, 10.098], loss: 0.001535, mae: 0.042629, mean_q: 1.168551
 381400/1000000: episode: 3814, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.986, mean reward: 0.580 [0.519, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.670, 10.225], loss: 0.001494, mae: 0.042554, mean_q: 1.170360
 381500/1000000: episode: 3815, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.247, mean reward: 0.572 [0.510, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.702, 10.125], loss: 0.001434, mae: 0.041512, mean_q: 1.168567
 381600/1000000: episode: 3816, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.412, mean reward: 0.584 [0.508, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.053, 10.242], loss: 0.001484, mae: 0.041810, mean_q: 1.167358
 381700/1000000: episode: 3817, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 64.033, mean reward: 0.640 [0.507, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.236, 10.098], loss: 0.001516, mae: 0.041923, mean_q: 1.164973
 381800/1000000: episode: 3818, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.917, mean reward: 0.629 [0.501, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.444, 10.098], loss: 0.001540, mae: 0.042738, mean_q: 1.170381
 381900/1000000: episode: 3819, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 60.941, mean reward: 0.609 [0.507, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.444, 10.098], loss: 0.001583, mae: 0.042852, mean_q: 1.173500
 382000/1000000: episode: 3820, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 61.439, mean reward: 0.614 [0.518, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.108, 10.419], loss: 0.001584, mae: 0.043294, mean_q: 1.177374
 382100/1000000: episode: 3821, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.945, mean reward: 0.599 [0.526, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.610, 10.098], loss: 0.001511, mae: 0.042552, mean_q: 1.175853
 382200/1000000: episode: 3822, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.586, mean reward: 0.576 [0.500, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.763, 10.276], loss: 0.001498, mae: 0.041578, mean_q: 1.174675
 382300/1000000: episode: 3823, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 60.425, mean reward: 0.604 [0.504, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.836, 10.261], loss: 0.001557, mae: 0.043222, mean_q: 1.172609
 382400/1000000: episode: 3824, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.456, mean reward: 0.595 [0.511, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.572, 10.263], loss: 0.001523, mae: 0.042584, mean_q: 1.173228
 382500/1000000: episode: 3825, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.700, mean reward: 0.597 [0.510, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.250, 10.098], loss: 0.001561, mae: 0.042518, mean_q: 1.175210
 382600/1000000: episode: 3826, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.211, mean reward: 0.572 [0.503, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.489, 10.098], loss: 0.001559, mae: 0.042551, mean_q: 1.172355
 382700/1000000: episode: 3827, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 60.041, mean reward: 0.600 [0.509, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.277, 10.207], loss: 0.001494, mae: 0.042409, mean_q: 1.172792
 382800/1000000: episode: 3828, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.281, mean reward: 0.583 [0.513, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.800, 10.098], loss: 0.001442, mae: 0.041191, mean_q: 1.170483
 382900/1000000: episode: 3829, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.806, mean reward: 0.598 [0.508, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.078, 10.271], loss: 0.001529, mae: 0.042269, mean_q: 1.172893
 383000/1000000: episode: 3830, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.792, mean reward: 0.588 [0.500, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.366, 10.167], loss: 0.001619, mae: 0.043519, mean_q: 1.172283
 383100/1000000: episode: 3831, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.446, mean reward: 0.574 [0.508, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.113, 10.181], loss: 0.001580, mae: 0.043565, mean_q: 1.169222
 383200/1000000: episode: 3832, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.956, mean reward: 0.590 [0.503, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.172, 10.098], loss: 0.001471, mae: 0.041784, mean_q: 1.168949
 383300/1000000: episode: 3833, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.093, mean reward: 0.591 [0.508, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.328, 10.108], loss: 0.001502, mae: 0.042227, mean_q: 1.169159
 383400/1000000: episode: 3834, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.606, mean reward: 0.596 [0.509, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.863, 10.098], loss: 0.001506, mae: 0.042252, mean_q: 1.170726
 383500/1000000: episode: 3835, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.371, mean reward: 0.574 [0.500, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.789, 10.189], loss: 0.001564, mae: 0.042819, mean_q: 1.171263
 383600/1000000: episode: 3836, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.881, mean reward: 0.599 [0.514, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.991, 10.098], loss: 0.001552, mae: 0.042814, mean_q: 1.170290
 383700/1000000: episode: 3837, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.224, mean reward: 0.582 [0.508, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.744, 10.098], loss: 0.001482, mae: 0.041868, mean_q: 1.176028
 383800/1000000: episode: 3838, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 64.495, mean reward: 0.645 [0.510, 0.921], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.171, 10.506], loss: 0.001608, mae: 0.043805, mean_q: 1.172755
 383900/1000000: episode: 3839, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.269, mean reward: 0.593 [0.514, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.989, 10.098], loss: 0.001612, mae: 0.043478, mean_q: 1.172560
 384000/1000000: episode: 3840, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.197, mean reward: 0.572 [0.504, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.487, 10.098], loss: 0.001582, mae: 0.043236, mean_q: 1.175221
 384100/1000000: episode: 3841, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.759, mean reward: 0.568 [0.502, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.608, 10.098], loss: 0.001553, mae: 0.042553, mean_q: 1.173294
 384200/1000000: episode: 3842, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.329, mean reward: 0.603 [0.499, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.277, 10.199], loss: 0.001602, mae: 0.043742, mean_q: 1.169455
 384300/1000000: episode: 3843, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.138, mean reward: 0.571 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.233, 10.098], loss: 0.001517, mae: 0.042572, mean_q: 1.167992
 384400/1000000: episode: 3844, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.402, mean reward: 0.584 [0.511, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.963, 10.098], loss: 0.001524, mae: 0.042535, mean_q: 1.169023
 384500/1000000: episode: 3845, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.845, mean reward: 0.588 [0.506, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-1.477, 10.098], loss: 0.001680, mae: 0.043365, mean_q: 1.167248
 384600/1000000: episode: 3846, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 60.542, mean reward: 0.605 [0.506, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.296, 10.229], loss: 0.001584, mae: 0.043290, mean_q: 1.170030
 384700/1000000: episode: 3847, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.230, mean reward: 0.572 [0.504, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.918, 10.098], loss: 0.001504, mae: 0.042321, mean_q: 1.169897
 384800/1000000: episode: 3848, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.006, mean reward: 0.600 [0.519, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.658, 10.098], loss: 0.001519, mae: 0.042454, mean_q: 1.169543
 384900/1000000: episode: 3849, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.729, mean reward: 0.567 [0.505, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.612, 10.151], loss: 0.001505, mae: 0.042065, mean_q: 1.167984
 385000/1000000: episode: 3850, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.470, mean reward: 0.575 [0.503, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.899, 10.243], loss: 0.001423, mae: 0.041182, mean_q: 1.168209
 385100/1000000: episode: 3851, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.815, mean reward: 0.598 [0.507, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.242, 10.106], loss: 0.001450, mae: 0.041458, mean_q: 1.165346
 385200/1000000: episode: 3852, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.826, mean reward: 0.598 [0.510, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-2.227, 10.098], loss: 0.001473, mae: 0.041920, mean_q: 1.164581
 385300/1000000: episode: 3853, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.885, mean reward: 0.579 [0.506, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.654, 10.098], loss: 0.001465, mae: 0.042163, mean_q: 1.170770
 385400/1000000: episode: 3854, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.230, mean reward: 0.582 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.816, 10.212], loss: 0.001462, mae: 0.041980, mean_q: 1.169483
 385500/1000000: episode: 3855, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.392, mean reward: 0.604 [0.520, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.988, 10.265], loss: 0.001577, mae: 0.043758, mean_q: 1.172008
 385600/1000000: episode: 3856, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.984, mean reward: 0.600 [0.508, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.446, 10.204], loss: 0.001622, mae: 0.043744, mean_q: 1.172379
 385700/1000000: episode: 3857, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.064, mean reward: 0.571 [0.500, 0.669], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.030, 10.264], loss: 0.001493, mae: 0.041944, mean_q: 1.165578
 385800/1000000: episode: 3858, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.423, mean reward: 0.584 [0.506, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.158, 10.098], loss: 0.001533, mae: 0.042594, mean_q: 1.170980
 385900/1000000: episode: 3859, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.352, mean reward: 0.594 [0.502, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.760, 10.216], loss: 0.001530, mae: 0.042473, mean_q: 1.169685
 386000/1000000: episode: 3860, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.219, mean reward: 0.602 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.996, 10.098], loss: 0.001568, mae: 0.042956, mean_q: 1.171189
 386100/1000000: episode: 3861, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.690, mean reward: 0.587 [0.499, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.730, 10.098], loss: 0.001462, mae: 0.042165, mean_q: 1.169992
 386200/1000000: episode: 3862, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.957, mean reward: 0.600 [0.506, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.850, 10.098], loss: 0.001483, mae: 0.042114, mean_q: 1.170909
 386300/1000000: episode: 3863, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.048, mean reward: 0.590 [0.509, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.486, 10.116], loss: 0.001463, mae: 0.041967, mean_q: 1.169899
 386400/1000000: episode: 3864, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.682, mean reward: 0.577 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.594, 10.181], loss: 0.001500, mae: 0.041965, mean_q: 1.171855
 386500/1000000: episode: 3865, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.274, mean reward: 0.583 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.779, 10.103], loss: 0.001518, mae: 0.042402, mean_q: 1.172023
 386600/1000000: episode: 3866, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.025, mean reward: 0.590 [0.504, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.183, 10.158], loss: 0.001561, mae: 0.042630, mean_q: 1.173289
 386700/1000000: episode: 3867, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.164, mean reward: 0.612 [0.501, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.375, 10.098], loss: 0.001592, mae: 0.043428, mean_q: 1.171628
 386800/1000000: episode: 3868, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.451, mean reward: 0.605 [0.507, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.337, 10.245], loss: 0.001512, mae: 0.042146, mean_q: 1.169898
 386900/1000000: episode: 3869, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.315, mean reward: 0.583 [0.506, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.356, 10.098], loss: 0.001526, mae: 0.042734, mean_q: 1.168786
 387000/1000000: episode: 3870, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.666, mean reward: 0.607 [0.500, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.631, 10.098], loss: 0.001514, mae: 0.042321, mean_q: 1.170039
 387100/1000000: episode: 3871, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 56.831, mean reward: 0.568 [0.500, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.716, 10.098], loss: 0.001655, mae: 0.044063, mean_q: 1.166712
 387200/1000000: episode: 3872, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.129, mean reward: 0.581 [0.504, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.118, 10.276], loss: 0.001479, mae: 0.041458, mean_q: 1.167605
 387300/1000000: episode: 3873, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.618, mean reward: 0.606 [0.510, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.683, 10.328], loss: 0.001447, mae: 0.041194, mean_q: 1.168541
 387400/1000000: episode: 3874, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.225, mean reward: 0.602 [0.509, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.291, 10.098], loss: 0.001598, mae: 0.043628, mean_q: 1.169517
 387500/1000000: episode: 3875, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.132, mean reward: 0.581 [0.499, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.804, 10.098], loss: 0.001476, mae: 0.041864, mean_q: 1.164592
 387600/1000000: episode: 3876, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 56.897, mean reward: 0.569 [0.499, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.724, 10.252], loss: 0.001644, mae: 0.043701, mean_q: 1.171110
 387700/1000000: episode: 3877, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.112, mean reward: 0.581 [0.499, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.630, 10.395], loss: 0.001480, mae: 0.042564, mean_q: 1.165588
 387800/1000000: episode: 3878, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.489, mean reward: 0.575 [0.499, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.273, 10.098], loss: 0.001461, mae: 0.041263, mean_q: 1.167302
 387900/1000000: episode: 3879, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.180, mean reward: 0.602 [0.506, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.156, 10.175], loss: 0.001582, mae: 0.042855, mean_q: 1.164101
 388000/1000000: episode: 3880, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.158, mean reward: 0.592 [0.507, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.477, 10.329], loss: 0.001644, mae: 0.043879, mean_q: 1.165690
 388100/1000000: episode: 3881, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.181, mean reward: 0.582 [0.500, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.428, 10.098], loss: 0.001445, mae: 0.041184, mean_q: 1.164761
 388200/1000000: episode: 3882, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.693, mean reward: 0.587 [0.502, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.280, 10.270], loss: 0.001547, mae: 0.042574, mean_q: 1.167775
 388300/1000000: episode: 3883, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.112, mean reward: 0.591 [0.501, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.618, 10.264], loss: 0.001473, mae: 0.040915, mean_q: 1.166222
 388400/1000000: episode: 3884, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.853, mean reward: 0.589 [0.506, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.020, 10.098], loss: 0.001445, mae: 0.041167, mean_q: 1.165396
 388500/1000000: episode: 3885, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.156, mean reward: 0.602 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.948, 10.417], loss: 0.001441, mae: 0.041158, mean_q: 1.162769
 388600/1000000: episode: 3886, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.723, mean reward: 0.577 [0.502, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.338, 10.098], loss: 0.001518, mae: 0.041914, mean_q: 1.164679
 388700/1000000: episode: 3887, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.028, mean reward: 0.580 [0.501, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.909, 10.098], loss: 0.001472, mae: 0.041576, mean_q: 1.165781
 388800/1000000: episode: 3888, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.616, mean reward: 0.586 [0.503, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.978, 10.137], loss: 0.001468, mae: 0.041500, mean_q: 1.163148
 388900/1000000: episode: 3889, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.732, mean reward: 0.607 [0.502, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.351, 10.477], loss: 0.001552, mae: 0.042283, mean_q: 1.165909
 389000/1000000: episode: 3890, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.590, mean reward: 0.586 [0.504, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.886, 10.354], loss: 0.001455, mae: 0.041101, mean_q: 1.161758
 389100/1000000: episode: 3891, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 63.574, mean reward: 0.636 [0.521, 0.875], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.487, 10.098], loss: 0.001470, mae: 0.041613, mean_q: 1.164992
 389200/1000000: episode: 3892, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.923, mean reward: 0.619 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.349, 10.098], loss: 0.001474, mae: 0.042019, mean_q: 1.168755
 389300/1000000: episode: 3893, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.721, mean reward: 0.577 [0.500, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.506, 10.098], loss: 0.001577, mae: 0.042425, mean_q: 1.168840
 389400/1000000: episode: 3894, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.459, mean reward: 0.575 [0.503, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.932, 10.158], loss: 0.001569, mae: 0.042869, mean_q: 1.168266
 389500/1000000: episode: 3895, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.160, mean reward: 0.582 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.476, 10.194], loss: 0.001494, mae: 0.042452, mean_q: 1.170972
 389600/1000000: episode: 3896, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 61.593, mean reward: 0.616 [0.508, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.837, 10.098], loss: 0.001524, mae: 0.041971, mean_q: 1.169248
 389700/1000000: episode: 3897, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.647, mean reward: 0.606 [0.513, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.744, 10.393], loss: 0.001559, mae: 0.042499, mean_q: 1.166851
 389800/1000000: episode: 3898, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.963, mean reward: 0.590 [0.509, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.086, 10.098], loss: 0.001589, mae: 0.043809, mean_q: 1.167775
 389900/1000000: episode: 3899, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.347, mean reward: 0.563 [0.503, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.807, 10.197], loss: 0.001528, mae: 0.042594, mean_q: 1.168780
 390000/1000000: episode: 3900, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.792, mean reward: 0.598 [0.502, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.897, 10.333], loss: 0.001508, mae: 0.042374, mean_q: 1.168388
 390100/1000000: episode: 3901, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.462, mean reward: 0.585 [0.507, 0.862], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.580, 10.098], loss: 0.001553, mae: 0.042786, mean_q: 1.169621
 390200/1000000: episode: 3902, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.938, mean reward: 0.579 [0.506, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.573, 10.098], loss: 0.001429, mae: 0.041222, mean_q: 1.165575
 390300/1000000: episode: 3903, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 59.087, mean reward: 0.591 [0.507, 0.914], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.128, 10.213], loss: 0.001599, mae: 0.043471, mean_q: 1.171439
 390400/1000000: episode: 3904, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.112, mean reward: 0.581 [0.503, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.080, 10.098], loss: 0.001505, mae: 0.041695, mean_q: 1.170138
 390500/1000000: episode: 3905, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.981, mean reward: 0.590 [0.502, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.481, 10.098], loss: 0.001576, mae: 0.042980, mean_q: 1.170738
 390600/1000000: episode: 3906, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 63.027, mean reward: 0.630 [0.506, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.885, 10.192], loss: 0.001510, mae: 0.042354, mean_q: 1.172947
 390700/1000000: episode: 3907, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.473, mean reward: 0.585 [0.503, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.026, 10.098], loss: 0.001606, mae: 0.043559, mean_q: 1.166288
 390800/1000000: episode: 3908, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 60.444, mean reward: 0.604 [0.506, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.763, 10.173], loss: 0.001506, mae: 0.042122, mean_q: 1.167638
 390900/1000000: episode: 3909, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 60.543, mean reward: 0.605 [0.516, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.804, 10.398], loss: 0.001431, mae: 0.040927, mean_q: 1.167800
 391000/1000000: episode: 3910, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 57.235, mean reward: 0.572 [0.505, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.882, 10.105], loss: 0.001406, mae: 0.041130, mean_q: 1.168937
 391100/1000000: episode: 3911, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.190, mean reward: 0.592 [0.501, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.394, 10.098], loss: 0.001468, mae: 0.041529, mean_q: 1.169690
 391200/1000000: episode: 3912, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 59.132, mean reward: 0.591 [0.520, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.784, 10.098], loss: 0.001428, mae: 0.041179, mean_q: 1.166929
 391300/1000000: episode: 3913, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.881, mean reward: 0.579 [0.504, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.808, 10.181], loss: 0.001560, mae: 0.042681, mean_q: 1.167749
 391400/1000000: episode: 3914, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.683, mean reward: 0.587 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.357, 10.315], loss: 0.001547, mae: 0.042809, mean_q: 1.168119
 391500/1000000: episode: 3915, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 68.196, mean reward: 0.682 [0.513, 0.886], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.449, 10.098], loss: 0.001551, mae: 0.042965, mean_q: 1.170663
 391600/1000000: episode: 3916, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.070, mean reward: 0.591 [0.511, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.496, 10.098], loss: 0.001361, mae: 0.040556, mean_q: 1.175989
 391700/1000000: episode: 3917, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.621, mean reward: 0.586 [0.510, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.653, 10.098], loss: 0.001497, mae: 0.042033, mean_q: 1.170436
 391800/1000000: episode: 3918, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.225, mean reward: 0.612 [0.497, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.553, 10.414], loss: 0.001571, mae: 0.043026, mean_q: 1.170957
 391900/1000000: episode: 3919, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.985, mean reward: 0.610 [0.499, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.554, 10.408], loss: 0.001440, mae: 0.041290, mean_q: 1.177195
 392000/1000000: episode: 3920, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.261, mean reward: 0.583 [0.500, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.632, 10.098], loss: 0.001495, mae: 0.042599, mean_q: 1.174374
 392100/1000000: episode: 3921, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.918, mean reward: 0.599 [0.506, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.236, 10.173], loss: 0.001509, mae: 0.042022, mean_q: 1.174679
 392200/1000000: episode: 3922, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 61.306, mean reward: 0.613 [0.499, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.092, 10.098], loss: 0.001516, mae: 0.042442, mean_q: 1.175761
 392300/1000000: episode: 3923, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.928, mean reward: 0.589 [0.519, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.706, 10.185], loss: 0.001381, mae: 0.040258, mean_q: 1.176707
 392400/1000000: episode: 3924, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.708, mean reward: 0.587 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.924, 10.123], loss: 0.001457, mae: 0.042256, mean_q: 1.176450
 392500/1000000: episode: 3925, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.240, mean reward: 0.572 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.570, 10.101], loss: 0.001444, mae: 0.042038, mean_q: 1.177879
 392600/1000000: episode: 3926, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.048, mean reward: 0.570 [0.503, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.787, 10.139], loss: 0.001525, mae: 0.042280, mean_q: 1.176901
 392700/1000000: episode: 3927, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.445, mean reward: 0.594 [0.510, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.307, 10.369], loss: 0.001477, mae: 0.042177, mean_q: 1.173639
 392800/1000000: episode: 3928, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.957, mean reward: 0.590 [0.502, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.456, 10.178], loss: 0.001448, mae: 0.041459, mean_q: 1.174685
 392900/1000000: episode: 3929, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.554, mean reward: 0.576 [0.506, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.303, 10.272], loss: 0.001426, mae: 0.041871, mean_q: 1.176890
 393000/1000000: episode: 3930, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.889, mean reward: 0.589 [0.508, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.868, 10.146], loss: 0.001429, mae: 0.041320, mean_q: 1.173885
 393100/1000000: episode: 3931, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.679, mean reward: 0.597 [0.505, 0.901], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.130, 10.279], loss: 0.001449, mae: 0.041225, mean_q: 1.175647
 393200/1000000: episode: 3932, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.477, mean reward: 0.575 [0.506, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.013, 10.098], loss: 0.001492, mae: 0.042257, mean_q: 1.175993
 393300/1000000: episode: 3933, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.752, mean reward: 0.588 [0.511, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.307, 10.248], loss: 0.001524, mae: 0.042220, mean_q: 1.175023
 393400/1000000: episode: 3934, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.222, mean reward: 0.572 [0.507, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.278, 10.179], loss: 0.001489, mae: 0.042619, mean_q: 1.173825
 393500/1000000: episode: 3935, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.365, mean reward: 0.574 [0.503, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.294, 10.098], loss: 0.001579, mae: 0.043237, mean_q: 1.174992
 393600/1000000: episode: 3936, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 56.800, mean reward: 0.568 [0.512, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.468, 10.098], loss: 0.001490, mae: 0.042296, mean_q: 1.172904
 393700/1000000: episode: 3937, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.976, mean reward: 0.590 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.286, 10.098], loss: 0.001310, mae: 0.039684, mean_q: 1.171713
 393800/1000000: episode: 3938, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.295, mean reward: 0.573 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.617, 10.358], loss: 0.001512, mae: 0.042057, mean_q: 1.176407
 393900/1000000: episode: 3939, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.811, mean reward: 0.578 [0.505, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.095, 10.098], loss: 0.001323, mae: 0.040432, mean_q: 1.171986
 394000/1000000: episode: 3940, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.956, mean reward: 0.580 [0.510, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.336, 10.123], loss: 0.001364, mae: 0.040364, mean_q: 1.169620
 394100/1000000: episode: 3941, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.905, mean reward: 0.599 [0.502, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.898, 10.330], loss: 0.001446, mae: 0.040983, mean_q: 1.168290
 394200/1000000: episode: 3942, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 60.424, mean reward: 0.604 [0.528, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.138, 10.333], loss: 0.001429, mae: 0.041116, mean_q: 1.166945
 394300/1000000: episode: 3943, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.966, mean reward: 0.600 [0.502, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.397, 10.098], loss: 0.001478, mae: 0.041560, mean_q: 1.171191
 394400/1000000: episode: 3944, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 58.776, mean reward: 0.588 [0.506, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.516, 10.098], loss: 0.001371, mae: 0.039761, mean_q: 1.170428
 394500/1000000: episode: 3945, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.967, mean reward: 0.590 [0.506, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.348, 10.245], loss: 0.001346, mae: 0.039659, mean_q: 1.167274
 394600/1000000: episode: 3946, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 56.944, mean reward: 0.569 [0.507, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.163, 10.167], loss: 0.001357, mae: 0.040353, mean_q: 1.167336
 394700/1000000: episode: 3947, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.408, mean reward: 0.574 [0.508, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.535, 10.146], loss: 0.001403, mae: 0.040795, mean_q: 1.170739
 394800/1000000: episode: 3948, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.314, mean reward: 0.593 [0.505, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.873, 10.098], loss: 0.001454, mae: 0.041148, mean_q: 1.169122
 394900/1000000: episode: 3949, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.191, mean reward: 0.582 [0.513, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.108, 10.098], loss: 0.001496, mae: 0.041690, mean_q: 1.168080
 395000/1000000: episode: 3950, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 63.050, mean reward: 0.630 [0.512, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.117, 10.098], loss: 0.001438, mae: 0.041290, mean_q: 1.162897
 395100/1000000: episode: 3951, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.741, mean reward: 0.597 [0.515, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.513, 10.098], loss: 0.001367, mae: 0.040311, mean_q: 1.173535
 395200/1000000: episode: 3952, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.788, mean reward: 0.608 [0.517, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.086, 10.151], loss: 0.001379, mae: 0.040222, mean_q: 1.167207
 395300/1000000: episode: 3953, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.469, mean reward: 0.595 [0.503, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.651, 10.098], loss: 0.001344, mae: 0.039490, mean_q: 1.169042
 395400/1000000: episode: 3954, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 56.731, mean reward: 0.567 [0.502, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.970, 10.142], loss: 0.001422, mae: 0.041135, mean_q: 1.171875
 395500/1000000: episode: 3955, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 61.209, mean reward: 0.612 [0.506, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.626, 10.098], loss: 0.001394, mae: 0.040811, mean_q: 1.171894
 395600/1000000: episode: 3956, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.191, mean reward: 0.562 [0.500, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.069, 10.098], loss: 0.001367, mae: 0.040256, mean_q: 1.170251
 395700/1000000: episode: 3957, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.973, mean reward: 0.620 [0.511, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.588, 10.098], loss: 0.001349, mae: 0.039788, mean_q: 1.168387
 395800/1000000: episode: 3958, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.897, mean reward: 0.579 [0.504, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.750, 10.236], loss: 0.001424, mae: 0.041447, mean_q: 1.168515
 395900/1000000: episode: 3959, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.593, mean reward: 0.576 [0.502, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.701, 10.098], loss: 0.001383, mae: 0.039718, mean_q: 1.166131
 396000/1000000: episode: 3960, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.873, mean reward: 0.599 [0.507, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.269, 10.393], loss: 0.001376, mae: 0.040964, mean_q: 1.166309
 396100/1000000: episode: 3961, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.318, mean reward: 0.593 [0.505, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.384, 10.231], loss: 0.001484, mae: 0.041474, mean_q: 1.168130
 396200/1000000: episode: 3962, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.046, mean reward: 0.590 [0.508, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.917, 10.188], loss: 0.001412, mae: 0.040652, mean_q: 1.170978
 396300/1000000: episode: 3963, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.098, mean reward: 0.601 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.959, 10.179], loss: 0.001376, mae: 0.039889, mean_q: 1.169750
 396400/1000000: episode: 3964, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.631, mean reward: 0.596 [0.511, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.827, 10.257], loss: 0.001348, mae: 0.039825, mean_q: 1.169575
 396500/1000000: episode: 3965, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.430, mean reward: 0.574 [0.504, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.630, 10.225], loss: 0.001360, mae: 0.040210, mean_q: 1.166190
 396600/1000000: episode: 3966, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.451, mean reward: 0.585 [0.506, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.145, 10.141], loss: 0.001393, mae: 0.040564, mean_q: 1.164997
 396700/1000000: episode: 3967, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 68.745, mean reward: 0.687 [0.512, 0.961], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.363, 10.482], loss: 0.001354, mae: 0.040609, mean_q: 1.165952
 396800/1000000: episode: 3968, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.238, mean reward: 0.592 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.715, 10.098], loss: 0.001342, mae: 0.040187, mean_q: 1.169809
 396900/1000000: episode: 3969, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.133, mean reward: 0.591 [0.508, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.037, 10.098], loss: 0.001648, mae: 0.043274, mean_q: 1.166947
 397000/1000000: episode: 3970, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.012, mean reward: 0.590 [0.501, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.209, 10.203], loss: 0.001519, mae: 0.042161, mean_q: 1.170330
 397100/1000000: episode: 3971, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.628, mean reward: 0.586 [0.507, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.810, 10.098], loss: 0.001459, mae: 0.041091, mean_q: 1.168217
 397200/1000000: episode: 3972, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 62.461, mean reward: 0.625 [0.512, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.376, 10.372], loss: 0.001515, mae: 0.041738, mean_q: 1.169657
 397300/1000000: episode: 3973, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.840, mean reward: 0.598 [0.510, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.025, 10.121], loss: 0.001448, mae: 0.041043, mean_q: 1.170300
 397400/1000000: episode: 3974, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.464, mean reward: 0.595 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.933, 10.098], loss: 0.001417, mae: 0.040727, mean_q: 1.171636
 397500/1000000: episode: 3975, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.302, mean reward: 0.573 [0.499, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.660, 10.194], loss: 0.001421, mae: 0.040764, mean_q: 1.168401
 397600/1000000: episode: 3976, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.881, mean reward: 0.579 [0.502, 0.949], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.260, 10.098], loss: 0.001441, mae: 0.041269, mean_q: 1.170138
 397700/1000000: episode: 3977, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.860, mean reward: 0.569 [0.501, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.679, 10.149], loss: 0.001459, mae: 0.041479, mean_q: 1.169314
 397800/1000000: episode: 3978, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.345, mean reward: 0.573 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.522, 10.098], loss: 0.001544, mae: 0.042533, mean_q: 1.170571
 397900/1000000: episode: 3979, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 57.623, mean reward: 0.576 [0.498, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.391, 10.098], loss: 0.001532, mae: 0.042416, mean_q: 1.165933
 398000/1000000: episode: 3980, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.635, mean reward: 0.576 [0.511, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.877, 10.098], loss: 0.001510, mae: 0.041732, mean_q: 1.166569
 398100/1000000: episode: 3981, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.471, mean reward: 0.585 [0.500, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.065, 10.112], loss: 0.001451, mae: 0.041161, mean_q: 1.163682
 398200/1000000: episode: 3982, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.285, mean reward: 0.583 [0.510, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.038, 10.103], loss: 0.001519, mae: 0.042274, mean_q: 1.169854
 398300/1000000: episode: 3983, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.404, mean reward: 0.584 [0.508, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.768, 10.098], loss: 0.001498, mae: 0.041844, mean_q: 1.168506
 398400/1000000: episode: 3984, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.549, mean reward: 0.595 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.907, 10.252], loss: 0.001476, mae: 0.041410, mean_q: 1.168012
 398500/1000000: episode: 3985, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.835, mean reward: 0.568 [0.502, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.744, 10.149], loss: 0.001506, mae: 0.041581, mean_q: 1.165982
 398600/1000000: episode: 3986, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.170, mean reward: 0.582 [0.505, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.526, 10.212], loss: 0.001510, mae: 0.042403, mean_q: 1.169236
 398700/1000000: episode: 3987, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 56.723, mean reward: 0.567 [0.498, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.142, 10.217], loss: 0.001486, mae: 0.041595, mean_q: 1.168938
 398800/1000000: episode: 3988, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 63.499, mean reward: 0.635 [0.514, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.209, 10.313], loss: 0.001611, mae: 0.043424, mean_q: 1.171091
 398900/1000000: episode: 3989, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.920, mean reward: 0.599 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.973, 10.331], loss: 0.001476, mae: 0.041850, mean_q: 1.170298
 399000/1000000: episode: 3990, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.498, mean reward: 0.605 [0.500, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.887, 10.108], loss: 0.001477, mae: 0.041756, mean_q: 1.167334
 399100/1000000: episode: 3991, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.095, mean reward: 0.591 [0.512, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.312, 10.397], loss: 0.001560, mae: 0.043296, mean_q: 1.172040
 399200/1000000: episode: 3992, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.976, mean reward: 0.600 [0.502, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.743, 10.098], loss: 0.001570, mae: 0.042943, mean_q: 1.167470
 399300/1000000: episode: 3993, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.005, mean reward: 0.590 [0.504, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.991, 10.098], loss: 0.001517, mae: 0.042303, mean_q: 1.172926
 399400/1000000: episode: 3994, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.977, mean reward: 0.590 [0.514, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-2.596, 10.098], loss: 0.001399, mae: 0.041134, mean_q: 1.170208
 399500/1000000: episode: 3995, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 61.323, mean reward: 0.613 [0.506, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.402, 10.098], loss: 0.001482, mae: 0.041923, mean_q: 1.173979
 399600/1000000: episode: 3996, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.662, mean reward: 0.577 [0.506, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.395, 10.118], loss: 0.001448, mae: 0.041908, mean_q: 1.172895
 399700/1000000: episode: 3997, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.386, mean reward: 0.604 [0.508, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.906, 10.098], loss: 0.001521, mae: 0.042887, mean_q: 1.175776
 399800/1000000: episode: 3998, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.734, mean reward: 0.577 [0.501, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.252, 10.222], loss: 0.001454, mae: 0.041737, mean_q: 1.169697
 399900/1000000: episode: 3999, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 56.815, mean reward: 0.568 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.789, 10.098], loss: 0.001435, mae: 0.040941, mean_q: 1.171501
 400000/1000000: episode: 4000, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 61.791, mean reward: 0.618 [0.505, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.635, 10.098], loss: 0.001494, mae: 0.041949, mean_q: 1.170015
 400100/1000000: episode: 4001, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.266, mean reward: 0.583 [0.510, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.690, 10.098], loss: 0.001370, mae: 0.040552, mean_q: 1.170150
 400200/1000000: episode: 4002, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.322, mean reward: 0.583 [0.500, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.499, 10.298], loss: 0.001348, mae: 0.040268, mean_q: 1.169657
 400300/1000000: episode: 4003, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.243, mean reward: 0.592 [0.504, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.022, 10.098], loss: 0.001579, mae: 0.042847, mean_q: 1.170730
 400400/1000000: episode: 4004, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.996, mean reward: 0.580 [0.503, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.236, 10.186], loss: 0.001442, mae: 0.041154, mean_q: 1.169685
 400500/1000000: episode: 4005, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.357, mean reward: 0.574 [0.501, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.998, 10.145], loss: 0.001441, mae: 0.041125, mean_q: 1.167273
 400600/1000000: episode: 4006, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.663, mean reward: 0.587 [0.504, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.657, 10.129], loss: 0.001453, mae: 0.041765, mean_q: 1.172096
 400700/1000000: episode: 4007, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.572, mean reward: 0.586 [0.518, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.106, 10.098], loss: 0.001485, mae: 0.041860, mean_q: 1.168834
 400800/1000000: episode: 4008, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.762, mean reward: 0.578 [0.507, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.440, 10.098], loss: 0.001493, mae: 0.042049, mean_q: 1.166471
 400900/1000000: episode: 4009, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.538, mean reward: 0.585 [0.501, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.164, 10.098], loss: 0.001425, mae: 0.040724, mean_q: 1.165585
 401000/1000000: episode: 4010, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.278, mean reward: 0.593 [0.505, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.009, 10.098], loss: 0.001427, mae: 0.041022, mean_q: 1.166361
 401100/1000000: episode: 4011, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 57.064, mean reward: 0.571 [0.501, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.415, 10.177], loss: 0.001452, mae: 0.041845, mean_q: 1.168764
 401200/1000000: episode: 4012, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.154, mean reward: 0.572 [0.507, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.329, 10.098], loss: 0.001541, mae: 0.042712, mean_q: 1.166568
 401300/1000000: episode: 4013, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.415, mean reward: 0.604 [0.516, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.173, 10.173], loss: 0.001324, mae: 0.040025, mean_q: 1.164741
 401400/1000000: episode: 4014, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.270, mean reward: 0.583 [0.501, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.864, 10.110], loss: 0.001523, mae: 0.042675, mean_q: 1.168545
 401500/1000000: episode: 4015, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.643, mean reward: 0.576 [0.500, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.070, 10.252], loss: 0.001415, mae: 0.040790, mean_q: 1.166103
 401600/1000000: episode: 4016, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.124, mean reward: 0.601 [0.514, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-2.034, 10.141], loss: 0.001471, mae: 0.042109, mean_q: 1.167363
 401700/1000000: episode: 4017, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.403, mean reward: 0.594 [0.514, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.079, 10.335], loss: 0.001479, mae: 0.041519, mean_q: 1.165422
 401800/1000000: episode: 4018, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 60.680, mean reward: 0.607 [0.498, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.537, 10.206], loss: 0.001438, mae: 0.041533, mean_q: 1.161174
 401900/1000000: episode: 4019, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.336, mean reward: 0.613 [0.510, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.643, 10.098], loss: 0.001421, mae: 0.041690, mean_q: 1.162085
 402000/1000000: episode: 4020, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.352, mean reward: 0.574 [0.504, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.327, 10.189], loss: 0.001385, mae: 0.040653, mean_q: 1.161819
 402100/1000000: episode: 4021, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.092, mean reward: 0.591 [0.508, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.402, 10.146], loss: 0.001368, mae: 0.040437, mean_q: 1.164631
 402200/1000000: episode: 4022, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.668, mean reward: 0.567 [0.503, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.822, 10.098], loss: 0.001498, mae: 0.042472, mean_q: 1.164705
 402300/1000000: episode: 4023, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.782, mean reward: 0.588 [0.509, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.453, 10.221], loss: 0.001436, mae: 0.041178, mean_q: 1.164328
 402400/1000000: episode: 4024, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 66.368, mean reward: 0.664 [0.508, 0.889], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.969, 10.098], loss: 0.001407, mae: 0.040954, mean_q: 1.160299
 402500/1000000: episode: 4025, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.959, mean reward: 0.580 [0.510, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.623, 10.153], loss: 0.001373, mae: 0.040379, mean_q: 1.160845
 402600/1000000: episode: 4026, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.122, mean reward: 0.591 [0.509, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.054, 10.098], loss: 0.001511, mae: 0.042442, mean_q: 1.163893
 402700/1000000: episode: 4027, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.076, mean reward: 0.571 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.954, 10.098], loss: 0.001437, mae: 0.041730, mean_q: 1.164419
 402800/1000000: episode: 4028, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.878, mean reward: 0.579 [0.503, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.750, 10.230], loss: 0.001456, mae: 0.041962, mean_q: 1.167400
 402900/1000000: episode: 4029, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.844, mean reward: 0.588 [0.507, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-2.065, 10.098], loss: 0.001444, mae: 0.041446, mean_q: 1.164853
 403000/1000000: episode: 4030, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 56.882, mean reward: 0.569 [0.504, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.022, 10.098], loss: 0.001436, mae: 0.041813, mean_q: 1.162139
 403100/1000000: episode: 4031, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.960, mean reward: 0.590 [0.499, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.518, 10.254], loss: 0.001574, mae: 0.043367, mean_q: 1.167995
 403200/1000000: episode: 4032, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.969, mean reward: 0.590 [0.503, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.009, 10.133], loss: 0.001570, mae: 0.043566, mean_q: 1.165913
 403300/1000000: episode: 4033, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 60.568, mean reward: 0.606 [0.514, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.053, 10.262], loss: 0.001586, mae: 0.042955, mean_q: 1.164579
 403400/1000000: episode: 4034, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.329, mean reward: 0.603 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.917, 10.446], loss: 0.001442, mae: 0.041540, mean_q: 1.165290
 403500/1000000: episode: 4035, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.418, mean reward: 0.574 [0.502, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.603, 10.244], loss: 0.001477, mae: 0.041909, mean_q: 1.168818
 403600/1000000: episode: 4036, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 60.876, mean reward: 0.609 [0.500, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.409, 10.245], loss: 0.001449, mae: 0.041473, mean_q: 1.167475
 403700/1000000: episode: 4037, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 56.697, mean reward: 0.567 [0.503, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.515, 10.164], loss: 0.001432, mae: 0.041404, mean_q: 1.167541
 403800/1000000: episode: 4038, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.225, mean reward: 0.582 [0.510, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.760, 10.133], loss: 0.001458, mae: 0.042023, mean_q: 1.165354
 403900/1000000: episode: 4039, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.937, mean reward: 0.589 [0.509, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.034, 10.152], loss: 0.001419, mae: 0.041639, mean_q: 1.164605
 404000/1000000: episode: 4040, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.197, mean reward: 0.582 [0.507, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.477, 10.206], loss: 0.001443, mae: 0.041748, mean_q: 1.165870
 404100/1000000: episode: 4041, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.999, mean reward: 0.590 [0.500, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.975, 10.111], loss: 0.001534, mae: 0.042476, mean_q: 1.170127
 404200/1000000: episode: 4042, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.654, mean reward: 0.587 [0.502, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.549, 10.121], loss: 0.001431, mae: 0.040618, mean_q: 1.164899
 404300/1000000: episode: 4043, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.667, mean reward: 0.577 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.580, 10.184], loss: 0.001463, mae: 0.041454, mean_q: 1.159768
 404400/1000000: episode: 4044, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.131, mean reward: 0.571 [0.500, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.807, 10.098], loss: 0.001488, mae: 0.041875, mean_q: 1.164981
 404500/1000000: episode: 4045, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.046, mean reward: 0.580 [0.499, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.744, 10.098], loss: 0.001474, mae: 0.041803, mean_q: 1.162300
 404600/1000000: episode: 4046, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.268, mean reward: 0.583 [0.502, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.575, 10.098], loss: 0.001427, mae: 0.041180, mean_q: 1.161169
 404700/1000000: episode: 4047, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.751, mean reward: 0.578 [0.506, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.634, 10.237], loss: 0.001488, mae: 0.041953, mean_q: 1.162670
 404800/1000000: episode: 4048, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.434, mean reward: 0.594 [0.511, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.002, 10.098], loss: 0.001339, mae: 0.040203, mean_q: 1.160791
 404900/1000000: episode: 4049, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.820, mean reward: 0.608 [0.505, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.501, 10.295], loss: 0.001454, mae: 0.041943, mean_q: 1.162514
 405000/1000000: episode: 4050, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 61.514, mean reward: 0.615 [0.502, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.867, 10.098], loss: 0.001455, mae: 0.041574, mean_q: 1.163728
 405100/1000000: episode: 4051, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.629, mean reward: 0.606 [0.511, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.254, 10.261], loss: 0.001407, mae: 0.040678, mean_q: 1.163440
 405200/1000000: episode: 4052, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.078, mean reward: 0.591 [0.500, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.660, 10.098], loss: 0.001413, mae: 0.041476, mean_q: 1.163617
 405300/1000000: episode: 4053, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.700, mean reward: 0.587 [0.517, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.853, 10.110], loss: 0.001447, mae: 0.041883, mean_q: 1.164834
 405400/1000000: episode: 4054, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.804, mean reward: 0.578 [0.502, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.151, 10.125], loss: 0.001434, mae: 0.041653, mean_q: 1.164369
 405500/1000000: episode: 4055, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.511, mean reward: 0.595 [0.508, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.818, 10.137], loss: 0.001456, mae: 0.041772, mean_q: 1.166226
 405600/1000000: episode: 4056, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 56.854, mean reward: 0.569 [0.505, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.689, 10.284], loss: 0.001371, mae: 0.040473, mean_q: 1.166493
 405700/1000000: episode: 4057, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.663, mean reward: 0.597 [0.509, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.499, 10.098], loss: 0.001360, mae: 0.040294, mean_q: 1.166881
 405800/1000000: episode: 4058, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 57.391, mean reward: 0.574 [0.506, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.677, 10.098], loss: 0.001398, mae: 0.041113, mean_q: 1.164247
 405900/1000000: episode: 4059, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.802, mean reward: 0.588 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.666, 10.359], loss: 0.001478, mae: 0.042263, mean_q: 1.165317
 406000/1000000: episode: 4060, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 61.062, mean reward: 0.611 [0.506, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.544, 10.455], loss: 0.001392, mae: 0.040995, mean_q: 1.167916
 406100/1000000: episode: 4061, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.913, mean reward: 0.609 [0.513, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.289, 10.098], loss: 0.001454, mae: 0.041883, mean_q: 1.164515
 406200/1000000: episode: 4062, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 60.185, mean reward: 0.602 [0.499, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.154, 10.098], loss: 0.001480, mae: 0.042027, mean_q: 1.166270
 406300/1000000: episode: 4063, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.347, mean reward: 0.593 [0.500, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.655, 10.175], loss: 0.001475, mae: 0.042366, mean_q: 1.168139
 406400/1000000: episode: 4064, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.778, mean reward: 0.618 [0.510, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.459, 10.171], loss: 0.001474, mae: 0.041843, mean_q: 1.169974
 406500/1000000: episode: 4065, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.757, mean reward: 0.588 [0.501, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.328, 10.118], loss: 0.001610, mae: 0.043738, mean_q: 1.172004
 406600/1000000: episode: 4066, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.538, mean reward: 0.575 [0.498, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.155, 10.098], loss: 0.001427, mae: 0.041275, mean_q: 1.165404
 406700/1000000: episode: 4067, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.383, mean reward: 0.574 [0.505, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.108, 10.098], loss: 0.001463, mae: 0.041931, mean_q: 1.169149
 406800/1000000: episode: 4068, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 59.547, mean reward: 0.595 [0.512, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.266, 10.098], loss: 0.001563, mae: 0.042972, mean_q: 1.167227
 406900/1000000: episode: 4069, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.386, mean reward: 0.604 [0.506, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.440, 10.288], loss: 0.001456, mae: 0.041954, mean_q: 1.169371
 407000/1000000: episode: 4070, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.365, mean reward: 0.594 [0.516, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.529, 10.324], loss: 0.001423, mae: 0.041796, mean_q: 1.170971
 407100/1000000: episode: 4071, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.777, mean reward: 0.578 [0.503, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.373, 10.126], loss: 0.001453, mae: 0.042024, mean_q: 1.165253
 407200/1000000: episode: 4072, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.604, mean reward: 0.586 [0.506, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.741, 10.216], loss: 0.001548, mae: 0.043167, mean_q: 1.168306
 407300/1000000: episode: 4073, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.119, mean reward: 0.591 [0.510, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.380, 10.403], loss: 0.001403, mae: 0.040636, mean_q: 1.164389
 407400/1000000: episode: 4074, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.353, mean reward: 0.594 [0.504, 0.901], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.826, 10.263], loss: 0.001573, mae: 0.043438, mean_q: 1.168071
 407500/1000000: episode: 4075, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.914, mean reward: 0.589 [0.507, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.614, 10.263], loss: 0.001549, mae: 0.042823, mean_q: 1.169477
 407600/1000000: episode: 4076, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.753, mean reward: 0.578 [0.508, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.005, 10.114], loss: 0.001546, mae: 0.043282, mean_q: 1.165746
 407700/1000000: episode: 4077, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.855, mean reward: 0.579 [0.510, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.549, 10.125], loss: 0.001458, mae: 0.042024, mean_q: 1.168921
 407800/1000000: episode: 4078, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.080, mean reward: 0.601 [0.504, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.743, 10.228], loss: 0.001579, mae: 0.043329, mean_q: 1.168000
 407900/1000000: episode: 4079, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.415, mean reward: 0.584 [0.508, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.109, 10.133], loss: 0.001453, mae: 0.041617, mean_q: 1.164843
 408000/1000000: episode: 4080, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.588, mean reward: 0.606 [0.498, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.360, 10.176], loss: 0.001515, mae: 0.042701, mean_q: 1.168006
 408100/1000000: episode: 4081, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.390, mean reward: 0.604 [0.500, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.204, 10.098], loss: 0.001558, mae: 0.043154, mean_q: 1.166620
 408200/1000000: episode: 4082, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.944, mean reward: 0.609 [0.507, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.113, 10.098], loss: 0.001570, mae: 0.043632, mean_q: 1.171373
 408300/1000000: episode: 4083, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.534, mean reward: 0.615 [0.514, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.708, 10.098], loss: 0.001604, mae: 0.043954, mean_q: 1.169331
 408400/1000000: episode: 4084, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.495, mean reward: 0.595 [0.511, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.533, 10.098], loss: 0.001457, mae: 0.042249, mean_q: 1.172890
 408500/1000000: episode: 4085, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.953, mean reward: 0.590 [0.502, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.969, 10.098], loss: 0.001504, mae: 0.043319, mean_q: 1.169582
 408600/1000000: episode: 4086, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.560, mean reward: 0.586 [0.500, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.622, 10.231], loss: 0.001372, mae: 0.041095, mean_q: 1.170431
 408700/1000000: episode: 4087, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.291, mean reward: 0.573 [0.497, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.915, 10.266], loss: 0.001459, mae: 0.042092, mean_q: 1.167320
 408800/1000000: episode: 4088, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 56.884, mean reward: 0.569 [0.501, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.967, 10.098], loss: 0.001539, mae: 0.043322, mean_q: 1.170318
 408900/1000000: episode: 4089, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.693, mean reward: 0.587 [0.507, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.333, 10.098], loss: 0.001460, mae: 0.042122, mean_q: 1.170163
 409000/1000000: episode: 4090, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.137, mean reward: 0.581 [0.507, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.914, 10.098], loss: 0.001486, mae: 0.042263, mean_q: 1.168612
 409100/1000000: episode: 4091, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 60.029, mean reward: 0.600 [0.507, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.905, 10.143], loss: 0.001439, mae: 0.041627, mean_q: 1.168873
 409200/1000000: episode: 4092, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.396, mean reward: 0.584 [0.509, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.211, 10.220], loss: 0.001498, mae: 0.042322, mean_q: 1.168174
 409300/1000000: episode: 4093, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 61.145, mean reward: 0.611 [0.501, 0.892], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.192, 10.098], loss: 0.001427, mae: 0.042079, mean_q: 1.168636
 409400/1000000: episode: 4094, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.357, mean reward: 0.604 [0.515, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.487, 10.098], loss: 0.001468, mae: 0.042543, mean_q: 1.171390
 409500/1000000: episode: 4095, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.116, mean reward: 0.581 [0.509, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.919, 10.225], loss: 0.001536, mae: 0.043088, mean_q: 1.176885
 409600/1000000: episode: 4096, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.638, mean reward: 0.596 [0.508, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.832, 10.282], loss: 0.001461, mae: 0.041870, mean_q: 1.172045
 409700/1000000: episode: 4097, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.981, mean reward: 0.600 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.695, 10.098], loss: 0.001520, mae: 0.042698, mean_q: 1.176982
 409800/1000000: episode: 4098, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.560, mean reward: 0.586 [0.503, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.586, 10.098], loss: 0.001527, mae: 0.043340, mean_q: 1.173274
 409900/1000000: episode: 4099, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.426, mean reward: 0.574 [0.504, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.127, 10.168], loss: 0.001568, mae: 0.043354, mean_q: 1.171165
 410000/1000000: episode: 4100, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.432, mean reward: 0.594 [0.505, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.175, 10.200], loss: 0.001525, mae: 0.042641, mean_q: 1.166234
 410100/1000000: episode: 4101, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.019, mean reward: 0.600 [0.505, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.031, 10.145], loss: 0.001494, mae: 0.042647, mean_q: 1.169417
 410200/1000000: episode: 4102, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.557, mean reward: 0.586 [0.504, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.923, 10.098], loss: 0.001602, mae: 0.043722, mean_q: 1.167226
 410300/1000000: episode: 4103, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.805, mean reward: 0.588 [0.510, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.696, 10.211], loss: 0.001544, mae: 0.043757, mean_q: 1.173299
 410400/1000000: episode: 4104, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.072, mean reward: 0.571 [0.502, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.494, 10.098], loss: 0.001558, mae: 0.043289, mean_q: 1.170256
 410500/1000000: episode: 4105, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.847, mean reward: 0.588 [0.512, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-2.223, 10.098], loss: 0.001540, mae: 0.043265, mean_q: 1.170826
 410600/1000000: episode: 4106, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.150, mean reward: 0.581 [0.519, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.088, 10.098], loss: 0.001476, mae: 0.042196, mean_q: 1.169305
 410700/1000000: episode: 4107, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.888, mean reward: 0.589 [0.507, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.761, 10.098], loss: 0.001466, mae: 0.042486, mean_q: 1.169362
 410800/1000000: episode: 4108, duration: 0.521s, episode steps: 100, steps per second: 192, episode reward: 63.036, mean reward: 0.630 [0.512, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.281, 10.459], loss: 0.001568, mae: 0.043480, mean_q: 1.169788
 410900/1000000: episode: 4109, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.493, mean reward: 0.585 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.688, 10.149], loss: 0.001493, mae: 0.042859, mean_q: 1.171414
 411000/1000000: episode: 4110, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 60.682, mean reward: 0.607 [0.503, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.562, 10.098], loss: 0.001447, mae: 0.041943, mean_q: 1.172618
 411100/1000000: episode: 4111, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.989, mean reward: 0.580 [0.505, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.313, 10.098], loss: 0.001486, mae: 0.042438, mean_q: 1.167635
 411200/1000000: episode: 4112, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.259, mean reward: 0.563 [0.500, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.233, 10.170], loss: 0.001442, mae: 0.041754, mean_q: 1.169954
 411300/1000000: episode: 4113, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 56.965, mean reward: 0.570 [0.504, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.478, 10.111], loss: 0.001425, mae: 0.041392, mean_q: 1.171288
 411400/1000000: episode: 4114, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.277, mean reward: 0.573 [0.507, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.759, 10.098], loss: 0.001338, mae: 0.040120, mean_q: 1.163930
 411500/1000000: episode: 4115, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.037, mean reward: 0.570 [0.505, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.031, 10.108], loss: 0.001507, mae: 0.042474, mean_q: 1.165650
 411600/1000000: episode: 4116, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 62.620, mean reward: 0.626 [0.523, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.885, 10.342], loss: 0.001419, mae: 0.041318, mean_q: 1.162917
 411700/1000000: episode: 4117, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.187, mean reward: 0.572 [0.510, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.757, 10.098], loss: 0.001419, mae: 0.041026, mean_q: 1.166175
 411800/1000000: episode: 4118, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.677, mean reward: 0.587 [0.508, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.280, 10.098], loss: 0.001390, mae: 0.041067, mean_q: 1.166117
 411900/1000000: episode: 4119, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 62.732, mean reward: 0.627 [0.503, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.465, 10.411], loss: 0.001404, mae: 0.041104, mean_q: 1.166702
 412000/1000000: episode: 4120, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.536, mean reward: 0.595 [0.500, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.295, 10.098], loss: 0.001467, mae: 0.041960, mean_q: 1.170950
 412100/1000000: episode: 4121, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.820, mean reward: 0.588 [0.503, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.498, 10.098], loss: 0.001497, mae: 0.042376, mean_q: 1.172087
 412200/1000000: episode: 4122, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.584, mean reward: 0.586 [0.509, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.579, 10.098], loss: 0.001432, mae: 0.041961, mean_q: 1.169848
 412300/1000000: episode: 4123, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.066, mean reward: 0.581 [0.505, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.527, 10.190], loss: 0.001447, mae: 0.042000, mean_q: 1.169289
 412400/1000000: episode: 4124, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.418, mean reward: 0.604 [0.511, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.289, 10.098], loss: 0.001360, mae: 0.040520, mean_q: 1.166629
 412500/1000000: episode: 4125, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 56.024, mean reward: 0.560 [0.505, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.527, 10.209], loss: 0.001480, mae: 0.042545, mean_q: 1.165105
 412600/1000000: episode: 4126, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.064, mean reward: 0.591 [0.503, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.369, 10.184], loss: 0.001488, mae: 0.042222, mean_q: 1.169634
 412700/1000000: episode: 4127, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.604, mean reward: 0.586 [0.506, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.508, 10.098], loss: 0.001525, mae: 0.043146, mean_q: 1.169876
 412800/1000000: episode: 4128, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.950, mean reward: 0.600 [0.521, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.997, 10.168], loss: 0.001382, mae: 0.040686, mean_q: 1.165925
 412900/1000000: episode: 4129, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.803, mean reward: 0.588 [0.513, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.634, 10.361], loss: 0.001449, mae: 0.041532, mean_q: 1.169190
 413000/1000000: episode: 4130, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.791, mean reward: 0.618 [0.501, 0.893], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.829, 10.098], loss: 0.001442, mae: 0.042054, mean_q: 1.168837
 413100/1000000: episode: 4131, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.498, mean reward: 0.595 [0.504, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.769, 10.291], loss: 0.001458, mae: 0.041993, mean_q: 1.166785
 413200/1000000: episode: 4132, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.404, mean reward: 0.584 [0.502, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.982, 10.106], loss: 0.001512, mae: 0.042519, mean_q: 1.168450
 413300/1000000: episode: 4133, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.372, mean reward: 0.574 [0.504, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.835, 10.182], loss: 0.001431, mae: 0.041717, mean_q: 1.167687
 413400/1000000: episode: 4134, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.916, mean reward: 0.579 [0.506, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.980, 10.140], loss: 0.001469, mae: 0.042067, mean_q: 1.164391
 413500/1000000: episode: 4135, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.131, mean reward: 0.601 [0.504, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.150, 10.254], loss: 0.001428, mae: 0.041708, mean_q: 1.164971
 413600/1000000: episode: 4136, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.248, mean reward: 0.582 [0.507, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.697, 10.098], loss: 0.001465, mae: 0.042109, mean_q: 1.167244
 413700/1000000: episode: 4137, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.549, mean reward: 0.585 [0.508, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.675, 10.098], loss: 0.001501, mae: 0.042790, mean_q: 1.166231
 413800/1000000: episode: 4138, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.181, mean reward: 0.592 [0.508, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.210, 10.256], loss: 0.001439, mae: 0.041390, mean_q: 1.161923
 413900/1000000: episode: 4139, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 63.541, mean reward: 0.635 [0.513, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.273, 10.427], loss: 0.001469, mae: 0.041991, mean_q: 1.168280
 414000/1000000: episode: 4140, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.519, mean reward: 0.575 [0.506, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.282, 10.153], loss: 0.001511, mae: 0.042578, mean_q: 1.167923
 414100/1000000: episode: 4141, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.040, mean reward: 0.570 [0.504, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.737, 10.098], loss: 0.001488, mae: 0.041849, mean_q: 1.169854
 414200/1000000: episode: 4142, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.261, mean reward: 0.573 [0.498, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.964, 10.098], loss: 0.001504, mae: 0.042801, mean_q: 1.166296
 414300/1000000: episode: 4143, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.512, mean reward: 0.585 [0.497, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.548, 10.098], loss: 0.001470, mae: 0.041711, mean_q: 1.165228
 414400/1000000: episode: 4144, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.049, mean reward: 0.590 [0.503, 0.865], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.664, 10.196], loss: 0.001557, mae: 0.043162, mean_q: 1.163456
 414500/1000000: episode: 4145, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.865, mean reward: 0.589 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.495, 10.098], loss: 0.001341, mae: 0.040144, mean_q: 1.162527
 414600/1000000: episode: 4146, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 60.035, mean reward: 0.600 [0.521, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.460, 10.098], loss: 0.001407, mae: 0.041019, mean_q: 1.163507
 414700/1000000: episode: 4147, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.202, mean reward: 0.582 [0.505, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.508, 10.098], loss: 0.001291, mae: 0.039306, mean_q: 1.164952
 414800/1000000: episode: 4148, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.478, mean reward: 0.585 [0.506, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.928, 10.286], loss: 0.001485, mae: 0.042313, mean_q: 1.164501
 414900/1000000: episode: 4149, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.515, mean reward: 0.595 [0.506, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.158, 10.387], loss: 0.001393, mae: 0.041020, mean_q: 1.163080
 415000/1000000: episode: 4150, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.557, mean reward: 0.576 [0.508, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.314, 10.242], loss: 0.001354, mae: 0.040510, mean_q: 1.163615
 415100/1000000: episode: 4151, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.720, mean reward: 0.607 [0.502, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.956, 10.250], loss: 0.001427, mae: 0.041075, mean_q: 1.163856
 415200/1000000: episode: 4152, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.895, mean reward: 0.589 [0.504, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.145, 10.105], loss: 0.001383, mae: 0.040574, mean_q: 1.162499
 415300/1000000: episode: 4153, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.121, mean reward: 0.581 [0.509, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.391, 10.098], loss: 0.001340, mae: 0.040542, mean_q: 1.164470
 415400/1000000: episode: 4154, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.051, mean reward: 0.591 [0.504, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.732, 10.098], loss: 0.001470, mae: 0.041812, mean_q: 1.165830
 415500/1000000: episode: 4155, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 60.794, mean reward: 0.608 [0.507, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.496, 10.098], loss: 0.001389, mae: 0.040571, mean_q: 1.164937
 415600/1000000: episode: 4156, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.160, mean reward: 0.592 [0.505, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.404, 10.098], loss: 0.001470, mae: 0.041442, mean_q: 1.166152
 415700/1000000: episode: 4157, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.432, mean reward: 0.584 [0.509, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.800, 10.098], loss: 0.001545, mae: 0.043527, mean_q: 1.167536
 415800/1000000: episode: 4158, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.607, mean reward: 0.576 [0.501, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.399, 10.117], loss: 0.001507, mae: 0.042788, mean_q: 1.167503
 415900/1000000: episode: 4159, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.533, mean reward: 0.585 [0.501, 0.879], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.648, 10.203], loss: 0.001426, mae: 0.040521, mean_q: 1.163015
 416000/1000000: episode: 4160, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.956, mean reward: 0.610 [0.501, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.273, 10.152], loss: 0.001465, mae: 0.042142, mean_q: 1.163433
 416100/1000000: episode: 4161, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.936, mean reward: 0.579 [0.511, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.563, 10.098], loss: 0.001387, mae: 0.040902, mean_q: 1.165095
 416200/1000000: episode: 4162, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.197, mean reward: 0.602 [0.514, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.788, 10.098], loss: 0.001553, mae: 0.042738, mean_q: 1.168133
 416300/1000000: episode: 4163, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.532, mean reward: 0.595 [0.498, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.568, 10.098], loss: 0.001492, mae: 0.041935, mean_q: 1.166854
 416400/1000000: episode: 4164, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.164, mean reward: 0.572 [0.508, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.114, 10.098], loss: 0.001450, mae: 0.041828, mean_q: 1.167433
 416500/1000000: episode: 4165, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.508, mean reward: 0.595 [0.504, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.524, 10.098], loss: 0.001467, mae: 0.041378, mean_q: 1.166112
 416600/1000000: episode: 4166, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.623, mean reward: 0.576 [0.500, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.618, 10.159], loss: 0.001483, mae: 0.042086, mean_q: 1.166264
 416700/1000000: episode: 4167, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.458, mean reward: 0.585 [0.508, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.675, 10.127], loss: 0.001581, mae: 0.042908, mean_q: 1.166399
 416800/1000000: episode: 4168, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.491, mean reward: 0.585 [0.505, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-2.077, 10.172], loss: 0.001617, mae: 0.043427, mean_q: 1.168666
 416900/1000000: episode: 4169, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 63.587, mean reward: 0.636 [0.501, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.565, 10.348], loss: 0.001510, mae: 0.042402, mean_q: 1.162573
 417000/1000000: episode: 4170, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.822, mean reward: 0.598 [0.505, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.297, 10.202], loss: 0.001407, mae: 0.041348, mean_q: 1.164423
 417100/1000000: episode: 4171, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.995, mean reward: 0.570 [0.501, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.368, 10.194], loss: 0.001550, mae: 0.042904, mean_q: 1.168796
 417200/1000000: episode: 4172, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.497, mean reward: 0.585 [0.508, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.477, 10.098], loss: 0.001519, mae: 0.042510, mean_q: 1.166245
 417300/1000000: episode: 4173, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.233, mean reward: 0.572 [0.503, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.591, 10.217], loss: 0.001574, mae: 0.043439, mean_q: 1.166373
 417400/1000000: episode: 4174, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.932, mean reward: 0.609 [0.506, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.551, 10.098], loss: 0.001464, mae: 0.041367, mean_q: 1.165795
 417500/1000000: episode: 4175, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 62.126, mean reward: 0.621 [0.502, 0.901], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.754, 10.098], loss: 0.001470, mae: 0.042255, mean_q: 1.166454
 417600/1000000: episode: 4176, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.867, mean reward: 0.609 [0.512, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.107, 10.098], loss: 0.001629, mae: 0.043796, mean_q: 1.170079
 417700/1000000: episode: 4177, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.653, mean reward: 0.587 [0.500, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.022, 10.147], loss: 0.001618, mae: 0.043896, mean_q: 1.171101
 417800/1000000: episode: 4178, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.147, mean reward: 0.581 [0.502, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.581, 10.327], loss: 0.001503, mae: 0.042071, mean_q: 1.168047
 417900/1000000: episode: 4179, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 56.479, mean reward: 0.565 [0.500, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.645, 10.126], loss: 0.001582, mae: 0.043452, mean_q: 1.168251
 418000/1000000: episode: 4180, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.837, mean reward: 0.588 [0.513, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.750, 10.098], loss: 0.001414, mae: 0.040688, mean_q: 1.164748
 418100/1000000: episode: 4181, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.103, mean reward: 0.591 [0.502, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.849, 10.098], loss: 0.001602, mae: 0.042862, mean_q: 1.166950
 418200/1000000: episode: 4182, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.171, mean reward: 0.602 [0.510, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.530, 10.098], loss: 0.001575, mae: 0.042295, mean_q: 1.163809
 418300/1000000: episode: 4183, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 63.697, mean reward: 0.637 [0.534, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.860, 10.387], loss: 0.001536, mae: 0.042354, mean_q: 1.165496
 418400/1000000: episode: 4184, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 63.501, mean reward: 0.635 [0.526, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.427, 10.098], loss: 0.001548, mae: 0.042937, mean_q: 1.167860
 418500/1000000: episode: 4185, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 62.982, mean reward: 0.630 [0.511, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.986, 10.098], loss: 0.001617, mae: 0.043024, mean_q: 1.172436
 418600/1000000: episode: 4186, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.969, mean reward: 0.570 [0.505, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.212, 10.098], loss: 0.001602, mae: 0.042650, mean_q: 1.174727
 418700/1000000: episode: 4187, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.934, mean reward: 0.589 [0.503, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.898, 10.288], loss: 0.001479, mae: 0.041708, mean_q: 1.174173
 418800/1000000: episode: 4188, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.765, mean reward: 0.578 [0.502, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.465, 10.098], loss: 0.001592, mae: 0.043659, mean_q: 1.173708
 418900/1000000: episode: 4189, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.593, mean reward: 0.596 [0.509, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.119, 10.098], loss: 0.001591, mae: 0.043259, mean_q: 1.170857
 419000/1000000: episode: 4190, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.478, mean reward: 0.605 [0.511, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.706, 10.343], loss: 0.001539, mae: 0.042969, mean_q: 1.168165
 419100/1000000: episode: 4191, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.723, mean reward: 0.577 [0.503, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.981, 10.098], loss: 0.001671, mae: 0.044565, mean_q: 1.170727
 419200/1000000: episode: 4192, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.194, mean reward: 0.592 [0.499, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.309, 10.182], loss: 0.001612, mae: 0.043443, mean_q: 1.166271
 419300/1000000: episode: 4193, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.611, mean reward: 0.586 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.254, 10.310], loss: 0.001652, mae: 0.043963, mean_q: 1.173362
 419400/1000000: episode: 4194, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.062, mean reward: 0.591 [0.500, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.308, 10.098], loss: 0.001499, mae: 0.042519, mean_q: 1.171063
 419500/1000000: episode: 4195, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.851, mean reward: 0.619 [0.508, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.134, 10.333], loss: 0.001644, mae: 0.044767, mean_q: 1.172724
 419600/1000000: episode: 4196, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.613, mean reward: 0.576 [0.507, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.609, 10.329], loss: 0.001513, mae: 0.042669, mean_q: 1.172143
 419700/1000000: episode: 4197, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.452, mean reward: 0.605 [0.530, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.543, 10.325], loss: 0.001609, mae: 0.044252, mean_q: 1.174814
 419800/1000000: episode: 4198, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.702, mean reward: 0.607 [0.499, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.007, 10.098], loss: 0.001628, mae: 0.043855, mean_q: 1.174490
 419900/1000000: episode: 4199, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.712, mean reward: 0.577 [0.506, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.808, 10.128], loss: 0.001618, mae: 0.043665, mean_q: 1.173614
 420000/1000000: episode: 4200, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.200, mean reward: 0.582 [0.498, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.426, 10.169], loss: 0.001654, mae: 0.043968, mean_q: 1.173242
 420100/1000000: episode: 4201, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.247, mean reward: 0.562 [0.505, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.352, 10.171], loss: 0.001528, mae: 0.042262, mean_q: 1.172235
 420200/1000000: episode: 4202, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 61.545, mean reward: 0.615 [0.502, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.456, 10.098], loss: 0.001573, mae: 0.042716, mean_q: 1.176150
 420300/1000000: episode: 4203, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 62.481, mean reward: 0.625 [0.504, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.760, 10.301], loss: 0.001638, mae: 0.044135, mean_q: 1.175735
 420400/1000000: episode: 4204, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.106, mean reward: 0.591 [0.504, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.764, 10.159], loss: 0.001502, mae: 0.041681, mean_q: 1.174189
 420500/1000000: episode: 4205, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.249, mean reward: 0.592 [0.504, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.074, 10.249], loss: 0.001601, mae: 0.043286, mean_q: 1.175391
 420600/1000000: episode: 4206, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.877, mean reward: 0.599 [0.508, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.723, 10.098], loss: 0.001625, mae: 0.042914, mean_q: 1.176334
 420700/1000000: episode: 4207, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 57.915, mean reward: 0.579 [0.504, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.551, 10.153], loss: 0.001527, mae: 0.042012, mean_q: 1.173507
 420800/1000000: episode: 4208, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.453, mean reward: 0.575 [0.503, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.049, 10.193], loss: 0.001534, mae: 0.042466, mean_q: 1.176473
 420900/1000000: episode: 4209, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.124, mean reward: 0.601 [0.505, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.614, 10.129], loss: 0.001503, mae: 0.041733, mean_q: 1.173122
 421000/1000000: episode: 4210, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.900, mean reward: 0.599 [0.516, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.457, 10.098], loss: 0.001572, mae: 0.042607, mean_q: 1.173074
 421100/1000000: episode: 4211, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.168, mean reward: 0.592 [0.498, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.855, 10.098], loss: 0.001651, mae: 0.044138, mean_q: 1.176914
 421200/1000000: episode: 4212, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.039, mean reward: 0.610 [0.504, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.991, 10.098], loss: 0.001489, mae: 0.042156, mean_q: 1.173759
 421300/1000000: episode: 4213, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.092, mean reward: 0.571 [0.511, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.592, 10.098], loss: 0.001644, mae: 0.043711, mean_q: 1.175511
 421400/1000000: episode: 4214, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 56.896, mean reward: 0.569 [0.504, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.125, 10.170], loss: 0.001557, mae: 0.042807, mean_q: 1.176107
 421500/1000000: episode: 4215, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.935, mean reward: 0.609 [0.517, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.210, 10.098], loss: 0.001685, mae: 0.044651, mean_q: 1.174595
 421600/1000000: episode: 4216, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.959, mean reward: 0.580 [0.503, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.780, 10.236], loss: 0.001500, mae: 0.041855, mean_q: 1.173884
 421700/1000000: episode: 4217, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.662, mean reward: 0.587 [0.500, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.993, 10.098], loss: 0.001599, mae: 0.043440, mean_q: 1.173292
 421800/1000000: episode: 4218, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.678, mean reward: 0.587 [0.501, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.678, 10.098], loss: 0.001589, mae: 0.042344, mean_q: 1.172390
 421900/1000000: episode: 4219, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.287, mean reward: 0.583 [0.506, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.539, 10.135], loss: 0.001586, mae: 0.043187, mean_q: 1.171837
 422000/1000000: episode: 4220, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.650, mean reward: 0.596 [0.510, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.270, 10.392], loss: 0.001661, mae: 0.043618, mean_q: 1.175088
 422100/1000000: episode: 4221, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.013, mean reward: 0.570 [0.508, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.141, 10.229], loss: 0.001634, mae: 0.043895, mean_q: 1.177164
 422200/1000000: episode: 4222, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.565, mean reward: 0.616 [0.507, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.936, 10.234], loss: 0.001718, mae: 0.044569, mean_q: 1.176417
 422300/1000000: episode: 4223, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.459, mean reward: 0.615 [0.500, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.495, 10.098], loss: 0.001716, mae: 0.044319, mean_q: 1.177248
 422400/1000000: episode: 4224, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.861, mean reward: 0.599 [0.504, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.114, 10.241], loss: 0.001804, mae: 0.044899, mean_q: 1.176768
 422500/1000000: episode: 4225, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.958, mean reward: 0.590 [0.509, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.484, 10.098], loss: 0.001637, mae: 0.043052, mean_q: 1.175014
 422600/1000000: episode: 4226, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.516, mean reward: 0.605 [0.518, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.332, 10.098], loss: 0.001700, mae: 0.043977, mean_q: 1.176390
 422700/1000000: episode: 4227, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.812, mean reward: 0.598 [0.512, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.030, 10.289], loss: 0.001645, mae: 0.043306, mean_q: 1.172775
 422800/1000000: episode: 4228, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 62.433, mean reward: 0.624 [0.521, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.640, 10.347], loss: 0.001448, mae: 0.041519, mean_q: 1.175358
 422900/1000000: episode: 4229, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.851, mean reward: 0.589 [0.507, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.220, 10.098], loss: 0.001669, mae: 0.044165, mean_q: 1.180041
 423000/1000000: episode: 4230, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.725, mean reward: 0.587 [0.504, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.283, 10.098], loss: 0.001643, mae: 0.044043, mean_q: 1.175686
 423100/1000000: episode: 4231, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 61.253, mean reward: 0.613 [0.509, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.791, 10.289], loss: 0.001577, mae: 0.042562, mean_q: 1.175727
 423200/1000000: episode: 4232, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.542, mean reward: 0.575 [0.502, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.639, 10.181], loss: 0.001667, mae: 0.044606, mean_q: 1.175835
 423300/1000000: episode: 4233, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.681, mean reward: 0.607 [0.511, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.018, 10.404], loss: 0.001570, mae: 0.043261, mean_q: 1.174696
 423400/1000000: episode: 4234, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 61.127, mean reward: 0.611 [0.512, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.320, 10.283], loss: 0.001566, mae: 0.042589, mean_q: 1.173723
 423500/1000000: episode: 4235, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.037, mean reward: 0.600 [0.500, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.616, 10.231], loss: 0.001552, mae: 0.042510, mean_q: 1.174850
 423600/1000000: episode: 4236, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 55.737, mean reward: 0.557 [0.502, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.637, 10.154], loss: 0.001508, mae: 0.041633, mean_q: 1.173743
 423700/1000000: episode: 4237, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.853, mean reward: 0.609 [0.504, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.168, 10.401], loss: 0.001681, mae: 0.043715, mean_q: 1.177287
 423800/1000000: episode: 4238, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.927, mean reward: 0.589 [0.508, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.128, 10.286], loss: 0.001584, mae: 0.042519, mean_q: 1.174372
 423900/1000000: episode: 4239, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.783, mean reward: 0.608 [0.530, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.337, 10.098], loss: 0.001534, mae: 0.042765, mean_q: 1.173275
 424000/1000000: episode: 4240, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.005, mean reward: 0.590 [0.502, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.120, 10.153], loss: 0.001635, mae: 0.043287, mean_q: 1.174966
 424100/1000000: episode: 4241, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 61.304, mean reward: 0.613 [0.504, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.163, 10.098], loss: 0.001609, mae: 0.043223, mean_q: 1.175942
 424200/1000000: episode: 4242, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.502, mean reward: 0.595 [0.509, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.024, 10.098], loss: 0.001539, mae: 0.042160, mean_q: 1.173883
 424300/1000000: episode: 4243, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.286, mean reward: 0.593 [0.510, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.044, 10.349], loss: 0.001605, mae: 0.043461, mean_q: 1.175991
 424400/1000000: episode: 4244, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.448, mean reward: 0.564 [0.510, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.601, 10.103], loss: 0.001571, mae: 0.042590, mean_q: 1.173461
 424500/1000000: episode: 4245, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.656, mean reward: 0.587 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.315, 10.098], loss: 0.001640, mae: 0.043837, mean_q: 1.179231
 424600/1000000: episode: 4246, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.233, mean reward: 0.582 [0.507, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.472, 10.098], loss: 0.001660, mae: 0.044013, mean_q: 1.176063
 424700/1000000: episode: 4247, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 56.855, mean reward: 0.569 [0.505, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.834, 10.164], loss: 0.001563, mae: 0.042358, mean_q: 1.169791
 424800/1000000: episode: 4248, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 55.904, mean reward: 0.559 [0.508, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.955, 10.098], loss: 0.001592, mae: 0.042718, mean_q: 1.173081
 424900/1000000: episode: 4249, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.775, mean reward: 0.578 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.062, 10.156], loss: 0.001560, mae: 0.042820, mean_q: 1.172472
 425000/1000000: episode: 4250, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.557, mean reward: 0.596 [0.508, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.904, 10.162], loss: 0.001590, mae: 0.043052, mean_q: 1.171753
 425100/1000000: episode: 4251, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 57.656, mean reward: 0.577 [0.500, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.578, 10.127], loss: 0.001657, mae: 0.043571, mean_q: 1.174175
 425200/1000000: episode: 4252, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.453, mean reward: 0.585 [0.505, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.872, 10.098], loss: 0.001628, mae: 0.043349, mean_q: 1.168598
 425300/1000000: episode: 4253, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.044, mean reward: 0.570 [0.502, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.506, 10.105], loss: 0.001603, mae: 0.043432, mean_q: 1.169785
 425400/1000000: episode: 4254, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.185, mean reward: 0.592 [0.512, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.597, 10.098], loss: 0.001581, mae: 0.042877, mean_q: 1.168403
 425500/1000000: episode: 4255, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.832, mean reward: 0.588 [0.505, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.321, 10.206], loss: 0.001498, mae: 0.042526, mean_q: 1.168897
 425600/1000000: episode: 4256, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.120, mean reward: 0.581 [0.502, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.722, 10.098], loss: 0.001659, mae: 0.043966, mean_q: 1.168373
 425700/1000000: episode: 4257, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 56.580, mean reward: 0.566 [0.507, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.408, 10.098], loss: 0.001576, mae: 0.042966, mean_q: 1.164272
 425800/1000000: episode: 4258, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.342, mean reward: 0.593 [0.506, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.505, 10.367], loss: 0.001627, mae: 0.043900, mean_q: 1.165901
 425900/1000000: episode: 4259, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 56.895, mean reward: 0.569 [0.507, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.949, 10.098], loss: 0.001526, mae: 0.042244, mean_q: 1.166193
 426000/1000000: episode: 4260, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.939, mean reward: 0.579 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.934, 10.129], loss: 0.001550, mae: 0.043197, mean_q: 1.166401
 426100/1000000: episode: 4261, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.477, mean reward: 0.575 [0.501, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.949, 10.223], loss: 0.001457, mae: 0.041575, mean_q: 1.164948
 426200/1000000: episode: 4262, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.544, mean reward: 0.565 [0.498, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.877, 10.158], loss: 0.001492, mae: 0.041428, mean_q: 1.163885
 426300/1000000: episode: 4263, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.996, mean reward: 0.580 [0.501, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.137, 10.181], loss: 0.001622, mae: 0.043265, mean_q: 1.165493
 426400/1000000: episode: 4264, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.745, mean reward: 0.587 [0.510, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.199, 10.098], loss: 0.001562, mae: 0.043331, mean_q: 1.168132
 426500/1000000: episode: 4265, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 61.065, mean reward: 0.611 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.312, 10.098], loss: 0.001522, mae: 0.042271, mean_q: 1.164718
 426600/1000000: episode: 4266, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.613, mean reward: 0.586 [0.512, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.649, 10.098], loss: 0.001485, mae: 0.041897, mean_q: 1.167040
 426700/1000000: episode: 4267, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.276, mean reward: 0.583 [0.505, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.140, 10.185], loss: 0.001520, mae: 0.042321, mean_q: 1.165503
 426800/1000000: episode: 4268, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.333, mean reward: 0.603 [0.499, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.881, 10.275], loss: 0.001643, mae: 0.044393, mean_q: 1.163042
 426900/1000000: episode: 4269, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.123, mean reward: 0.591 [0.509, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.856, 10.228], loss: 0.001570, mae: 0.043540, mean_q: 1.168739
 427000/1000000: episode: 4270, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 59.288, mean reward: 0.593 [0.507, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.284, 10.098], loss: 0.001458, mae: 0.042201, mean_q: 1.164832
 427100/1000000: episode: 4271, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.877, mean reward: 0.579 [0.508, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.587, 10.098], loss: 0.001487, mae: 0.042235, mean_q: 1.169396
 427200/1000000: episode: 4272, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.179, mean reward: 0.602 [0.519, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-1.119, 10.098], loss: 0.001505, mae: 0.042204, mean_q: 1.161947
 427300/1000000: episode: 4273, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 60.557, mean reward: 0.606 [0.510, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.270, 10.262], loss: 0.001496, mae: 0.042454, mean_q: 1.166854
 427400/1000000: episode: 4274, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.866, mean reward: 0.579 [0.508, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.827, 10.098], loss: 0.001589, mae: 0.043128, mean_q: 1.164657
 427500/1000000: episode: 4275, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.180, mean reward: 0.602 [0.510, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.009, 10.173], loss: 0.001553, mae: 0.042878, mean_q: 1.166732
 427600/1000000: episode: 4276, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.917, mean reward: 0.589 [0.505, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.999, 10.185], loss: 0.001458, mae: 0.041614, mean_q: 1.162042
 427700/1000000: episode: 4277, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.766, mean reward: 0.588 [0.512, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.896, 10.177], loss: 0.001515, mae: 0.042403, mean_q: 1.164704
 427800/1000000: episode: 4278, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.802, mean reward: 0.578 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.831, 10.325], loss: 0.001508, mae: 0.041786, mean_q: 1.163810
 427900/1000000: episode: 4279, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.167, mean reward: 0.592 [0.514, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.173, 10.299], loss: 0.001425, mae: 0.041164, mean_q: 1.163667
 428000/1000000: episode: 4280, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 61.205, mean reward: 0.612 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.227, 10.160], loss: 0.001458, mae: 0.041509, mean_q: 1.163617
 428100/1000000: episode: 4281, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.402, mean reward: 0.624 [0.513, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.819, 10.098], loss: 0.001493, mae: 0.042497, mean_q: 1.165942
 428200/1000000: episode: 4282, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 64.871, mean reward: 0.649 [0.519, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.809, 10.098], loss: 0.001508, mae: 0.042366, mean_q: 1.164797
 428300/1000000: episode: 4283, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.653, mean reward: 0.577 [0.503, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.646, 10.272], loss: 0.001445, mae: 0.041531, mean_q: 1.162480
 428400/1000000: episode: 4284, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.753, mean reward: 0.608 [0.499, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.231, 10.227], loss: 0.001529, mae: 0.042755, mean_q: 1.167534
 428500/1000000: episode: 4285, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.420, mean reward: 0.574 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.717, 10.138], loss: 0.001413, mae: 0.041274, mean_q: 1.168176
 428600/1000000: episode: 4286, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.488, mean reward: 0.575 [0.501, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.785, 10.098], loss: 0.001459, mae: 0.041816, mean_q: 1.164636
 428700/1000000: episode: 4287, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 61.687, mean reward: 0.617 [0.502, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.543, 10.098], loss: 0.001380, mae: 0.040509, mean_q: 1.163035
 428800/1000000: episode: 4288, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.469, mean reward: 0.575 [0.497, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.873, 10.344], loss: 0.001497, mae: 0.042472, mean_q: 1.163227
 428900/1000000: episode: 4289, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.486, mean reward: 0.605 [0.506, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.331, 10.213], loss: 0.001467, mae: 0.041972, mean_q: 1.164532
 429000/1000000: episode: 4290, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.176, mean reward: 0.582 [0.498, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.732, 10.158], loss: 0.001476, mae: 0.041705, mean_q: 1.160759
 429100/1000000: episode: 4291, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.158, mean reward: 0.572 [0.505, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.328, 10.098], loss: 0.001496, mae: 0.042564, mean_q: 1.163870
 429200/1000000: episode: 4292, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.595, mean reward: 0.606 [0.514, 0.874], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.779, 10.098], loss: 0.001446, mae: 0.041615, mean_q: 1.163965
 429300/1000000: episode: 4293, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.101, mean reward: 0.591 [0.510, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.436, 10.098], loss: 0.001375, mae: 0.040823, mean_q: 1.161535
 429400/1000000: episode: 4294, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.337, mean reward: 0.593 [0.509, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.246, 10.098], loss: 0.001421, mae: 0.041548, mean_q: 1.166169
 429500/1000000: episode: 4295, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.002, mean reward: 0.580 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.521, 10.098], loss: 0.001492, mae: 0.042145, mean_q: 1.161689
 429600/1000000: episode: 4296, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.074, mean reward: 0.591 [0.510, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.692, 10.098], loss: 0.001375, mae: 0.041094, mean_q: 1.161188
 429700/1000000: episode: 4297, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.982, mean reward: 0.580 [0.503, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.408, 10.203], loss: 0.001386, mae: 0.040732, mean_q: 1.163232
 429800/1000000: episode: 4298, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.188, mean reward: 0.592 [0.515, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.541, 10.311], loss: 0.001501, mae: 0.042510, mean_q: 1.164615
 429900/1000000: episode: 4299, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 62.683, mean reward: 0.627 [0.511, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.988, 10.386], loss: 0.001412, mae: 0.041020, mean_q: 1.163343
 430000/1000000: episode: 4300, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.497, mean reward: 0.575 [0.502, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.602, 10.186], loss: 0.001362, mae: 0.040461, mean_q: 1.162481
 430100/1000000: episode: 4301, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.074, mean reward: 0.591 [0.505, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.370, 10.098], loss: 0.001452, mae: 0.041464, mean_q: 1.164564
 430200/1000000: episode: 4302, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.781, mean reward: 0.578 [0.502, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.719, 10.098], loss: 0.001373, mae: 0.041099, mean_q: 1.167127
 430300/1000000: episode: 4303, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.104, mean reward: 0.581 [0.502, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.095, 10.194], loss: 0.001516, mae: 0.042440, mean_q: 1.167551
 430400/1000000: episode: 4304, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.684, mean reward: 0.587 [0.498, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.823, 10.098], loss: 0.001415, mae: 0.041373, mean_q: 1.165789
 430500/1000000: episode: 4305, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.792, mean reward: 0.608 [0.516, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.862, 10.098], loss: 0.001389, mae: 0.041358, mean_q: 1.163733
 430600/1000000: episode: 4306, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.662, mean reward: 0.617 [0.505, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.657, 10.400], loss: 0.001460, mae: 0.041776, mean_q: 1.167908
 430700/1000000: episode: 4307, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.833, mean reward: 0.598 [0.506, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.212, 10.098], loss: 0.001445, mae: 0.041871, mean_q: 1.166984
 430800/1000000: episode: 4308, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.758, mean reward: 0.608 [0.510, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.194, 10.415], loss: 0.001382, mae: 0.041201, mean_q: 1.171915
 430900/1000000: episode: 4309, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 62.263, mean reward: 0.623 [0.506, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.894, 10.335], loss: 0.001393, mae: 0.041343, mean_q: 1.173194
 431000/1000000: episode: 4310, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.837, mean reward: 0.578 [0.508, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.209, 10.098], loss: 0.001340, mae: 0.040067, mean_q: 1.169997
 431100/1000000: episode: 4311, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.471, mean reward: 0.575 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.035, 10.098], loss: 0.001404, mae: 0.041163, mean_q: 1.176157
 431200/1000000: episode: 4312, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 62.808, mean reward: 0.628 [0.509, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.716, 10.098], loss: 0.001492, mae: 0.042414, mean_q: 1.174671
 431300/1000000: episode: 4313, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.808, mean reward: 0.578 [0.509, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.883, 10.098], loss: 0.001416, mae: 0.041236, mean_q: 1.175322
 431400/1000000: episode: 4314, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.569, mean reward: 0.616 [0.502, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.450, 10.098], loss: 0.001525, mae: 0.042620, mean_q: 1.177897
 431500/1000000: episode: 4315, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.257, mean reward: 0.573 [0.503, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.824, 10.217], loss: 0.001480, mae: 0.042016, mean_q: 1.177471
 431600/1000000: episode: 4316, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.934, mean reward: 0.579 [0.499, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.270, 10.385], loss: 0.001420, mae: 0.040872, mean_q: 1.173717
 431700/1000000: episode: 4317, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.887, mean reward: 0.579 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.236, 10.098], loss: 0.001449, mae: 0.042253, mean_q: 1.178308
 431800/1000000: episode: 4318, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.938, mean reward: 0.589 [0.510, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.394, 10.131], loss: 0.001464, mae: 0.041780, mean_q: 1.175587
 431900/1000000: episode: 4319, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.899, mean reward: 0.599 [0.504, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.629, 10.452], loss: 0.001343, mae: 0.040347, mean_q: 1.173181
 432000/1000000: episode: 4320, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.705, mean reward: 0.587 [0.503, 0.864], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.471, 10.296], loss: 0.001347, mae: 0.040268, mean_q: 1.173713
 432100/1000000: episode: 4321, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.485, mean reward: 0.585 [0.505, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.137, 10.182], loss: 0.001390, mae: 0.041052, mean_q: 1.176680
 432200/1000000: episode: 4322, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.656, mean reward: 0.587 [0.497, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.661, 10.340], loss: 0.001403, mae: 0.041213, mean_q: 1.179718
 432300/1000000: episode: 4323, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.054, mean reward: 0.591 [0.510, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.022, 10.170], loss: 0.001419, mae: 0.041139, mean_q: 1.176792
 432400/1000000: episode: 4324, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 61.154, mean reward: 0.612 [0.502, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.626, 10.098], loss: 0.001383, mae: 0.041046, mean_q: 1.173609
 432500/1000000: episode: 4325, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.429, mean reward: 0.594 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.110, 10.268], loss: 0.001358, mae: 0.040369, mean_q: 1.174790
 432600/1000000: episode: 4326, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.564, mean reward: 0.576 [0.502, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.501, 10.171], loss: 0.001430, mae: 0.041328, mean_q: 1.176711
 432700/1000000: episode: 4327, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.454, mean reward: 0.585 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.679, 10.098], loss: 0.001498, mae: 0.042383, mean_q: 1.172907
 432800/1000000: episode: 4328, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.094, mean reward: 0.581 [0.503, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.347, 10.122], loss: 0.001460, mae: 0.041512, mean_q: 1.172215
 432900/1000000: episode: 4329, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.601, mean reward: 0.606 [0.509, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.375, 10.098], loss: 0.001378, mae: 0.040436, mean_q: 1.173543
 433000/1000000: episode: 4330, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 64.075, mean reward: 0.641 [0.510, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.598, 10.098], loss: 0.001429, mae: 0.041172, mean_q: 1.171786
 433100/1000000: episode: 4331, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 59.782, mean reward: 0.598 [0.502, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.814, 10.098], loss: 0.001367, mae: 0.040441, mean_q: 1.174757
 433200/1000000: episode: 4332, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 61.148, mean reward: 0.611 [0.502, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.153, 10.364], loss: 0.001485, mae: 0.041417, mean_q: 1.174609
 433300/1000000: episode: 4333, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.263, mean reward: 0.593 [0.502, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.851, 10.145], loss: 0.001432, mae: 0.041278, mean_q: 1.176888
 433400/1000000: episode: 4334, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.392, mean reward: 0.594 [0.518, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.259, 10.157], loss: 0.001412, mae: 0.040828, mean_q: 1.171368
 433500/1000000: episode: 4335, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.501, mean reward: 0.585 [0.511, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.649, 10.098], loss: 0.001478, mae: 0.041828, mean_q: 1.174770
 433600/1000000: episode: 4336, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.694, mean reward: 0.597 [0.515, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.838, 10.219], loss: 0.001499, mae: 0.041661, mean_q: 1.172333
 433700/1000000: episode: 4337, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.678, mean reward: 0.597 [0.508, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.673, 10.098], loss: 0.001452, mae: 0.040805, mean_q: 1.174594
 433800/1000000: episode: 4338, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.979, mean reward: 0.590 [0.509, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.580, 10.173], loss: 0.001442, mae: 0.041446, mean_q: 1.173994
 433900/1000000: episode: 4339, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 56.692, mean reward: 0.567 [0.507, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.769, 10.098], loss: 0.001649, mae: 0.043349, mean_q: 1.178072
 434000/1000000: episode: 4340, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.846, mean reward: 0.618 [0.513, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.671, 10.467], loss: 0.001552, mae: 0.042704, mean_q: 1.176415
 434100/1000000: episode: 4341, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.513, mean reward: 0.575 [0.497, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.665, 10.137], loss: 0.001658, mae: 0.043836, mean_q: 1.173664
 434200/1000000: episode: 4342, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.507, mean reward: 0.585 [0.506, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.363, 10.098], loss: 0.001590, mae: 0.042697, mean_q: 1.174851
 434300/1000000: episode: 4343, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.828, mean reward: 0.578 [0.504, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.549, 10.224], loss: 0.001580, mae: 0.042677, mean_q: 1.173192
 434400/1000000: episode: 4344, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.621, mean reward: 0.596 [0.510, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.227, 10.098], loss: 0.001489, mae: 0.041479, mean_q: 1.173400
 434500/1000000: episode: 4345, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.108, mean reward: 0.611 [0.529, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.613, 10.098], loss: 0.001560, mae: 0.042665, mean_q: 1.174318
 434600/1000000: episode: 4346, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.824, mean reward: 0.608 [0.509, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.592, 10.251], loss: 0.001595, mae: 0.042481, mean_q: 1.175771
 434700/1000000: episode: 4347, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.495, mean reward: 0.575 [0.500, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.604, 10.176], loss: 0.001519, mae: 0.042172, mean_q: 1.176800
 434800/1000000: episode: 4348, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.280, mean reward: 0.573 [0.503, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.406, 10.168], loss: 0.001590, mae: 0.043031, mean_q: 1.175909
 434900/1000000: episode: 4349, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.008, mean reward: 0.580 [0.506, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.054, 10.281], loss: 0.001549, mae: 0.042459, mean_q: 1.174086
 435000/1000000: episode: 4350, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.005, mean reward: 0.570 [0.504, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.346, 10.098], loss: 0.001470, mae: 0.040960, mean_q: 1.171730
 435100/1000000: episode: 4351, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.753, mean reward: 0.608 [0.505, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.437, 10.323], loss: 0.001483, mae: 0.041913, mean_q: 1.168327
 435200/1000000: episode: 4352, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 58.089, mean reward: 0.581 [0.512, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.427, 10.098], loss: 0.001521, mae: 0.042493, mean_q: 1.175356
 435300/1000000: episode: 4353, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.430, mean reward: 0.584 [0.503, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.501, 10.098], loss: 0.001525, mae: 0.042680, mean_q: 1.176841
 435400/1000000: episode: 4354, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.916, mean reward: 0.599 [0.508, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.319, 10.388], loss: 0.001525, mae: 0.042053, mean_q: 1.173761
 435500/1000000: episode: 4355, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.756, mean reward: 0.578 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.690, 10.139], loss: 0.001646, mae: 0.043385, mean_q: 1.174498
 435600/1000000: episode: 4356, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.154, mean reward: 0.592 [0.503, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.090, 10.294], loss: 0.001444, mae: 0.041441, mean_q: 1.170410
 435700/1000000: episode: 4357, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.675, mean reward: 0.577 [0.500, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.833, 10.220], loss: 0.001449, mae: 0.041144, mean_q: 1.173815
 435800/1000000: episode: 4358, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.895, mean reward: 0.579 [0.501, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.958, 10.246], loss: 0.001549, mae: 0.042143, mean_q: 1.172598
 435900/1000000: episode: 4359, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.975, mean reward: 0.590 [0.499, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.090, 10.497], loss: 0.001442, mae: 0.041031, mean_q: 1.166335
 436000/1000000: episode: 4360, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 64.778, mean reward: 0.648 [0.500, 0.950], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.118, 10.098], loss: 0.001497, mae: 0.041759, mean_q: 1.168143
 436100/1000000: episode: 4361, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.546, mean reward: 0.595 [0.506, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.955, 10.098], loss: 0.001599, mae: 0.042287, mean_q: 1.170905
 436200/1000000: episode: 4362, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.545, mean reward: 0.595 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.712, 10.098], loss: 0.001491, mae: 0.041105, mean_q: 1.169702
 436300/1000000: episode: 4363, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.211, mean reward: 0.582 [0.498, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.894, 10.169], loss: 0.001570, mae: 0.042299, mean_q: 1.171750
 436400/1000000: episode: 4364, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.008, mean reward: 0.600 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.824, 10.369], loss: 0.001375, mae: 0.040273, mean_q: 1.169317
 436500/1000000: episode: 4365, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 63.252, mean reward: 0.633 [0.511, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.821, 10.308], loss: 0.001550, mae: 0.041964, mean_q: 1.171837
 436600/1000000: episode: 4366, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.009, mean reward: 0.590 [0.501, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.696, 10.325], loss: 0.001671, mae: 0.044243, mean_q: 1.178824
 436700/1000000: episode: 4367, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 59.808, mean reward: 0.598 [0.520, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.077, 10.340], loss: 0.001583, mae: 0.042247, mean_q: 1.177240
 436800/1000000: episode: 4368, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.359, mean reward: 0.594 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.508, 10.254], loss: 0.001478, mae: 0.041115, mean_q: 1.173689
 436900/1000000: episode: 4369, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.607, mean reward: 0.576 [0.503, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.452, 10.098], loss: 0.001461, mae: 0.040887, mean_q: 1.175379
 437000/1000000: episode: 4370, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.846, mean reward: 0.588 [0.504, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.280, 10.098], loss: 0.001472, mae: 0.041654, mean_q: 1.172617
 437100/1000000: episode: 4371, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.619, mean reward: 0.596 [0.505, 0.939], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.758, 10.098], loss: 0.001507, mae: 0.041663, mean_q: 1.173141
 437200/1000000: episode: 4372, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.428, mean reward: 0.574 [0.508, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.103, 10.164], loss: 0.001491, mae: 0.041744, mean_q: 1.173842
 437300/1000000: episode: 4373, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.309, mean reward: 0.583 [0.497, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.657, 10.324], loss: 0.001493, mae: 0.041980, mean_q: 1.170058
 437400/1000000: episode: 4374, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.307, mean reward: 0.583 [0.504, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.184, 10.115], loss: 0.001562, mae: 0.042470, mean_q: 1.174685
 437500/1000000: episode: 4375, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 62.407, mean reward: 0.624 [0.501, 0.899], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.024, 10.108], loss: 0.001471, mae: 0.041485, mean_q: 1.172377
 437600/1000000: episode: 4376, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.875, mean reward: 0.589 [0.517, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.412, 10.098], loss: 0.001399, mae: 0.040384, mean_q: 1.173807
 437700/1000000: episode: 4377, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.583, mean reward: 0.566 [0.502, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.658, 10.098], loss: 0.001541, mae: 0.042119, mean_q: 1.171812
 437800/1000000: episode: 4378, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.397, mean reward: 0.574 [0.502, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.887, 10.210], loss: 0.001456, mae: 0.040962, mean_q: 1.174019
 437900/1000000: episode: 4379, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.497, mean reward: 0.585 [0.502, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.351, 10.189], loss: 0.001547, mae: 0.042536, mean_q: 1.173026
 438000/1000000: episode: 4380, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 59.867, mean reward: 0.599 [0.499, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.509, 10.098], loss: 0.001376, mae: 0.040216, mean_q: 1.169916
 438100/1000000: episode: 4381, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 58.113, mean reward: 0.581 [0.512, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.570, 10.193], loss: 0.001432, mae: 0.040846, mean_q: 1.164149
 438200/1000000: episode: 4382, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.928, mean reward: 0.579 [0.510, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.655, 10.193], loss: 0.001447, mae: 0.040556, mean_q: 1.169757
 438300/1000000: episode: 4383, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.569, mean reward: 0.576 [0.504, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.789, 10.106], loss: 0.001458, mae: 0.040857, mean_q: 1.167584
 438400/1000000: episode: 4384, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.918, mean reward: 0.579 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.082, 10.098], loss: 0.001489, mae: 0.041938, mean_q: 1.171251
 438500/1000000: episode: 4385, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.644, mean reward: 0.576 [0.500, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.567, 10.098], loss: 0.001393, mae: 0.040801, mean_q: 1.168784
 438600/1000000: episode: 4386, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.568, mean reward: 0.586 [0.498, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.840, 10.121], loss: 0.001385, mae: 0.040756, mean_q: 1.166792
 438700/1000000: episode: 4387, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.854, mean reward: 0.589 [0.505, 0.909], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.131, 10.204], loss: 0.001447, mae: 0.041152, mean_q: 1.165907
 438800/1000000: episode: 4388, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.241, mean reward: 0.592 [0.503, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.959, 10.503], loss: 0.001489, mae: 0.041831, mean_q: 1.167207
 438900/1000000: episode: 4389, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.264, mean reward: 0.583 [0.500, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.377, 10.098], loss: 0.001433, mae: 0.041126, mean_q: 1.169460
 439000/1000000: episode: 4390, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.735, mean reward: 0.597 [0.509, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.960, 10.098], loss: 0.001401, mae: 0.040625, mean_q: 1.163828
 439100/1000000: episode: 4391, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.833, mean reward: 0.598 [0.503, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.232, 10.200], loss: 0.001313, mae: 0.039230, mean_q: 1.163525
 439200/1000000: episode: 4392, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.344, mean reward: 0.573 [0.500, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.570, 10.098], loss: 0.001346, mae: 0.039828, mean_q: 1.164505
 439300/1000000: episode: 4393, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.134, mean reward: 0.581 [0.499, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.701, 10.098], loss: 0.001415, mae: 0.040850, mean_q: 1.164047
 439400/1000000: episode: 4394, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.199, mean reward: 0.582 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.036, 10.206], loss: 0.001452, mae: 0.041197, mean_q: 1.165025
 439500/1000000: episode: 4395, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.508, mean reward: 0.595 [0.504, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.541, 10.098], loss: 0.001373, mae: 0.040548, mean_q: 1.166302
 439600/1000000: episode: 4396, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 56.995, mean reward: 0.570 [0.501, 0.661], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.926, 10.098], loss: 0.001298, mae: 0.038879, mean_q: 1.160755
 439700/1000000: episode: 4397, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.969, mean reward: 0.580 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.355, 10.098], loss: 0.001488, mae: 0.041288, mean_q: 1.160149
 439800/1000000: episode: 4398, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.292, mean reward: 0.573 [0.502, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.642, 10.221], loss: 0.001412, mae: 0.040359, mean_q: 1.163290
 439900/1000000: episode: 4399, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.381, mean reward: 0.614 [0.509, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.148, 10.098], loss: 0.001381, mae: 0.040376, mean_q: 1.165127
 440000/1000000: episode: 4400, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.568, mean reward: 0.576 [0.508, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.647, 10.098], loss: 0.001438, mae: 0.040628, mean_q: 1.164644
 440100/1000000: episode: 4401, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.343, mean reward: 0.603 [0.507, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.949, 10.146], loss: 0.001441, mae: 0.040580, mean_q: 1.167712
 440200/1000000: episode: 4402, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.130, mean reward: 0.581 [0.507, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.899, 10.254], loss: 0.001452, mae: 0.041305, mean_q: 1.165324
 440300/1000000: episode: 4403, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.868, mean reward: 0.589 [0.502, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.828, 10.223], loss: 0.001461, mae: 0.041090, mean_q: 1.169395
 440400/1000000: episode: 4404, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.114, mean reward: 0.601 [0.509, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.751, 10.098], loss: 0.001431, mae: 0.040532, mean_q: 1.165022
 440500/1000000: episode: 4405, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.166, mean reward: 0.582 [0.502, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.517, 10.098], loss: 0.001443, mae: 0.041061, mean_q: 1.165891
 440600/1000000: episode: 4406, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.088, mean reward: 0.571 [0.505, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.947, 10.098], loss: 0.001453, mae: 0.040954, mean_q: 1.167137
 440700/1000000: episode: 4407, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 58.986, mean reward: 0.590 [0.501, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.775, 10.111], loss: 0.001435, mae: 0.040233, mean_q: 1.167249
 440800/1000000: episode: 4408, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.944, mean reward: 0.599 [0.513, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.470, 10.459], loss: 0.001489, mae: 0.041361, mean_q: 1.166506
 440900/1000000: episode: 4409, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.508, mean reward: 0.585 [0.508, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.941, 10.177], loss: 0.001526, mae: 0.041757, mean_q: 1.165474
 441000/1000000: episode: 4410, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.408, mean reward: 0.594 [0.503, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.038, 10.253], loss: 0.001458, mae: 0.040467, mean_q: 1.163413
 441100/1000000: episode: 4411, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.120, mean reward: 0.581 [0.508, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.831, 10.204], loss: 0.001374, mae: 0.040247, mean_q: 1.163009
 441200/1000000: episode: 4412, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.516, mean reward: 0.595 [0.498, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.072, 10.098], loss: 0.001355, mae: 0.039586, mean_q: 1.164128
 441300/1000000: episode: 4413, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.456, mean reward: 0.595 [0.502, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.968, 10.331], loss: 0.001473, mae: 0.041069, mean_q: 1.162206
 441400/1000000: episode: 4414, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.993, mean reward: 0.600 [0.508, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.393, 10.098], loss: 0.001363, mae: 0.039929, mean_q: 1.164700
 441500/1000000: episode: 4415, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.757, mean reward: 0.598 [0.505, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.656, 10.098], loss: 0.001334, mae: 0.039659, mean_q: 1.163036
 441600/1000000: episode: 4416, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 62.009, mean reward: 0.620 [0.510, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.731, 10.098], loss: 0.001438, mae: 0.041188, mean_q: 1.163008
 441700/1000000: episode: 4417, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.591, mean reward: 0.616 [0.503, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.833, 10.115], loss: 0.001499, mae: 0.041148, mean_q: 1.164484
 441800/1000000: episode: 4418, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.830, mean reward: 0.608 [0.507, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.817, 10.098], loss: 0.001398, mae: 0.039999, mean_q: 1.165370
 441900/1000000: episode: 4419, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 62.010, mean reward: 0.620 [0.508, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.610, 10.350], loss: 0.001387, mae: 0.040157, mean_q: 1.162778
 442000/1000000: episode: 4420, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 60.104, mean reward: 0.601 [0.500, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.783, 10.098], loss: 0.001468, mae: 0.040855, mean_q: 1.167316
 442100/1000000: episode: 4421, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 59.008, mean reward: 0.590 [0.503, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.687, 10.233], loss: 0.001406, mae: 0.039958, mean_q: 1.163270
 442200/1000000: episode: 4422, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.128, mean reward: 0.581 [0.502, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.589, 10.098], loss: 0.001382, mae: 0.040090, mean_q: 1.166633
 442300/1000000: episode: 4423, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 61.257, mean reward: 0.613 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.013, 10.249], loss: 0.001387, mae: 0.040138, mean_q: 1.166556
 442400/1000000: episode: 4424, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.688, mean reward: 0.587 [0.503, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.465, 10.111], loss: 0.001442, mae: 0.041222, mean_q: 1.170344
 442500/1000000: episode: 4425, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.769, mean reward: 0.588 [0.505, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.344, 10.216], loss: 0.001379, mae: 0.039990, mean_q: 1.166992
 442600/1000000: episode: 4426, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.755, mean reward: 0.588 [0.504, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.698, 10.098], loss: 0.001446, mae: 0.040162, mean_q: 1.167895
 442700/1000000: episode: 4427, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.400, mean reward: 0.574 [0.504, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.577, 10.098], loss: 0.001378, mae: 0.039687, mean_q: 1.168646
 442800/1000000: episode: 4428, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.952, mean reward: 0.580 [0.510, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.822, 10.256], loss: 0.001439, mae: 0.040357, mean_q: 1.167449
 442900/1000000: episode: 4429, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.075, mean reward: 0.581 [0.504, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.406, 10.098], loss: 0.001460, mae: 0.040747, mean_q: 1.169068
 443000/1000000: episode: 4430, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.608, mean reward: 0.586 [0.506, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.649, 10.353], loss: 0.001411, mae: 0.039939, mean_q: 1.164060
 443100/1000000: episode: 4431, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.974, mean reward: 0.590 [0.504, 0.895], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.808, 10.136], loss: 0.001483, mae: 0.040778, mean_q: 1.168306
 443200/1000000: episode: 4432, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.769, mean reward: 0.608 [0.504, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.729, 10.268], loss: 0.001413, mae: 0.040338, mean_q: 1.165831
 443300/1000000: episode: 4433, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.875, mean reward: 0.579 [0.501, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.575, 10.098], loss: 0.001371, mae: 0.039426, mean_q: 1.164652
 443400/1000000: episode: 4434, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 65.324, mean reward: 0.653 [0.520, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.920, 10.098], loss: 0.001352, mae: 0.039930, mean_q: 1.168567
 443500/1000000: episode: 4435, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.682, mean reward: 0.587 [0.501, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.255, 10.098], loss: 0.001515, mae: 0.041151, mean_q: 1.169933
 443600/1000000: episode: 4436, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 56.997, mean reward: 0.570 [0.506, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.592, 10.168], loss: 0.001356, mae: 0.039440, mean_q: 1.169608
 443700/1000000: episode: 4437, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.312, mean reward: 0.613 [0.517, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.526, 10.205], loss: 0.001373, mae: 0.039817, mean_q: 1.172063
 443800/1000000: episode: 4438, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.734, mean reward: 0.577 [0.504, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.801, 10.098], loss: 0.001283, mae: 0.038285, mean_q: 1.170073
 443900/1000000: episode: 4439, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.213, mean reward: 0.572 [0.506, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.802, 10.098], loss: 0.001356, mae: 0.039917, mean_q: 1.173674
 444000/1000000: episode: 4440, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.930, mean reward: 0.619 [0.507, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.629, 10.098], loss: 0.001269, mae: 0.038591, mean_q: 1.169650
 444100/1000000: episode: 4441, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.312, mean reward: 0.593 [0.507, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.986, 10.098], loss: 0.001522, mae: 0.042387, mean_q: 1.177254
 444200/1000000: episode: 4442, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 62.731, mean reward: 0.627 [0.504, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.993, 10.422], loss: 0.001433, mae: 0.041409, mean_q: 1.171857
 444300/1000000: episode: 4443, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.324, mean reward: 0.583 [0.499, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.515, 10.150], loss: 0.001389, mae: 0.040355, mean_q: 1.171798
 444400/1000000: episode: 4444, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.281, mean reward: 0.573 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.909, 10.120], loss: 0.001401, mae: 0.040398, mean_q: 1.173066
 444500/1000000: episode: 4445, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.062, mean reward: 0.591 [0.506, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.591, 10.098], loss: 0.001448, mae: 0.041310, mean_q: 1.172148
 444600/1000000: episode: 4446, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.718, mean reward: 0.587 [0.516, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.827, 10.098], loss: 0.001405, mae: 0.040574, mean_q: 1.174239
 444700/1000000: episode: 4447, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 61.776, mean reward: 0.618 [0.503, 0.915], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.870, 10.305], loss: 0.001454, mae: 0.041067, mean_q: 1.175187
 444800/1000000: episode: 4448, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.089, mean reward: 0.571 [0.500, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.536, 10.133], loss: 0.001385, mae: 0.040337, mean_q: 1.174852
 444900/1000000: episode: 4449, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.571, mean reward: 0.586 [0.506, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.586, 10.112], loss: 0.001409, mae: 0.040276, mean_q: 1.169690
 445000/1000000: episode: 4450, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.204, mean reward: 0.582 [0.506, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.653, 10.098], loss: 0.001334, mae: 0.040097, mean_q: 1.172148
 445100/1000000: episode: 4451, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.477, mean reward: 0.605 [0.507, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.887, 10.124], loss: 0.001392, mae: 0.040544, mean_q: 1.175740
 445200/1000000: episode: 4452, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.347, mean reward: 0.573 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.147, 10.163], loss: 0.001415, mae: 0.040911, mean_q: 1.173621
 445300/1000000: episode: 4453, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.260, mean reward: 0.603 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.658, 10.098], loss: 0.001383, mae: 0.040851, mean_q: 1.175924
 445400/1000000: episode: 4454, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.924, mean reward: 0.609 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.136, 10.098], loss: 0.001353, mae: 0.039699, mean_q: 1.172031
 445500/1000000: episode: 4455, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.125, mean reward: 0.601 [0.507, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.670, 10.098], loss: 0.001430, mae: 0.040816, mean_q: 1.178113
 445600/1000000: episode: 4456, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.286, mean reward: 0.583 [0.504, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.859, 10.148], loss: 0.001363, mae: 0.040170, mean_q: 1.179368
 445700/1000000: episode: 4457, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.817, mean reward: 0.598 [0.501, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.043, 10.402], loss: 0.001396, mae: 0.039908, mean_q: 1.175174
 445800/1000000: episode: 4458, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.871, mean reward: 0.599 [0.503, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.259, 10.157], loss: 0.001479, mae: 0.041606, mean_q: 1.178460
 445900/1000000: episode: 4459, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 64.134, mean reward: 0.641 [0.510, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.689, 10.098], loss: 0.001355, mae: 0.040607, mean_q: 1.175259
 446000/1000000: episode: 4460, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.086, mean reward: 0.591 [0.514, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.624, 10.160], loss: 0.001494, mae: 0.042079, mean_q: 1.177650
 446100/1000000: episode: 4461, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.601, mean reward: 0.606 [0.519, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.896, 10.358], loss: 0.001487, mae: 0.041165, mean_q: 1.177317
 446200/1000000: episode: 4462, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.291, mean reward: 0.603 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.445, 10.098], loss: 0.001389, mae: 0.040671, mean_q: 1.175397
 446300/1000000: episode: 4463, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.533, mean reward: 0.575 [0.505, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.520, 10.328], loss: 0.001331, mae: 0.040191, mean_q: 1.179312
 446400/1000000: episode: 4464, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.005, mean reward: 0.610 [0.502, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.836, 10.278], loss: 0.001354, mae: 0.040468, mean_q: 1.180277
 446500/1000000: episode: 4465, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.413, mean reward: 0.574 [0.499, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.874, 10.098], loss: 0.001311, mae: 0.039406, mean_q: 1.178695
 446600/1000000: episode: 4466, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.135, mean reward: 0.581 [0.505, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.387, 10.098], loss: 0.001432, mae: 0.041144, mean_q: 1.177750
 446700/1000000: episode: 4467, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.675, mean reward: 0.597 [0.502, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.397, 10.187], loss: 0.001352, mae: 0.040174, mean_q: 1.171618
 446800/1000000: episode: 4468, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.419, mean reward: 0.584 [0.505, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.297, 10.225], loss: 0.001348, mae: 0.040311, mean_q: 1.173992
 446900/1000000: episode: 4469, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.563, mean reward: 0.586 [0.512, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.435, 10.308], loss: 0.001318, mae: 0.039253, mean_q: 1.171229
 447000/1000000: episode: 4470, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 64.783, mean reward: 0.648 [0.506, 0.917], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.937, 10.467], loss: 0.001368, mae: 0.040634, mean_q: 1.176424
 447100/1000000: episode: 4471, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.533, mean reward: 0.585 [0.511, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.675, 10.098], loss: 0.001397, mae: 0.040184, mean_q: 1.177588
 447200/1000000: episode: 4472, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.904, mean reward: 0.599 [0.507, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.352, 10.269], loss: 0.001360, mae: 0.039873, mean_q: 1.173027
 447300/1000000: episode: 4473, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 62.183, mean reward: 0.622 [0.508, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.270, 10.316], loss: 0.001440, mae: 0.041495, mean_q: 1.180970
 447400/1000000: episode: 4474, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.161, mean reward: 0.602 [0.512, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.054, 10.310], loss: 0.001385, mae: 0.040211, mean_q: 1.173370
 447500/1000000: episode: 4475, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.998, mean reward: 0.590 [0.499, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.548, 10.098], loss: 0.001392, mae: 0.040463, mean_q: 1.180178
 447600/1000000: episode: 4476, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.370, mean reward: 0.574 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.745, 10.119], loss: 0.001361, mae: 0.040095, mean_q: 1.178824
 447700/1000000: episode: 4477, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.141, mean reward: 0.591 [0.504, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.691, 10.134], loss: 0.001579, mae: 0.043175, mean_q: 1.177555
 447800/1000000: episode: 4478, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.485, mean reward: 0.585 [0.503, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.053, 10.335], loss: 0.001478, mae: 0.041489, mean_q: 1.175839
 447900/1000000: episode: 4479, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.887, mean reward: 0.589 [0.505, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.352, 10.229], loss: 0.001381, mae: 0.040798, mean_q: 1.177439
 448000/1000000: episode: 4480, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.475, mean reward: 0.575 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.814, 10.197], loss: 0.001454, mae: 0.041652, mean_q: 1.180801
 448100/1000000: episode: 4481, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.541, mean reward: 0.585 [0.503, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.881, 10.098], loss: 0.001380, mae: 0.040533, mean_q: 1.180127
 448200/1000000: episode: 4482, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.698, mean reward: 0.587 [0.513, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.120, 10.208], loss: 0.001339, mae: 0.039983, mean_q: 1.177716
 448300/1000000: episode: 4483, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.866, mean reward: 0.589 [0.501, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.686, 10.098], loss: 0.001315, mae: 0.039781, mean_q: 1.171973
 448400/1000000: episode: 4484, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.393, mean reward: 0.594 [0.510, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.674, 10.328], loss: 0.001431, mae: 0.041064, mean_q: 1.178675
 448500/1000000: episode: 4485, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 62.778, mean reward: 0.628 [0.504, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.641, 10.098], loss: 0.001373, mae: 0.040090, mean_q: 1.177699
 448600/1000000: episode: 4486, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.048, mean reward: 0.580 [0.500, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.472, 10.177], loss: 0.001387, mae: 0.040659, mean_q: 1.174739
 448700/1000000: episode: 4487, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.565, mean reward: 0.596 [0.509, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.482, 10.098], loss: 0.001355, mae: 0.040354, mean_q: 1.175135
 448800/1000000: episode: 4488, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 56.497, mean reward: 0.565 [0.509, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.750, 10.232], loss: 0.001410, mae: 0.040981, mean_q: 1.175582
 448900/1000000: episode: 4489, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 57.705, mean reward: 0.577 [0.506, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.593, 10.098], loss: 0.001434, mae: 0.041288, mean_q: 1.176742
 449000/1000000: episode: 4490, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 56.187, mean reward: 0.562 [0.503, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.699, 10.098], loss: 0.001396, mae: 0.040578, mean_q: 1.174013
 449100/1000000: episode: 4491, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.474, mean reward: 0.595 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.610, 10.375], loss: 0.001414, mae: 0.040332, mean_q: 1.172695
 449200/1000000: episode: 4492, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.338, mean reward: 0.583 [0.498, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.166, 10.120], loss: 0.001345, mae: 0.040059, mean_q: 1.171936
 449300/1000000: episode: 4493, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.345, mean reward: 0.573 [0.499, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-2.037, 10.098], loss: 0.001377, mae: 0.039827, mean_q: 1.172433
 449400/1000000: episode: 4494, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 62.740, mean reward: 0.627 [0.504, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.570, 10.333], loss: 0.001444, mae: 0.040876, mean_q: 1.171370
 449500/1000000: episode: 4495, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 63.160, mean reward: 0.632 [0.523, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-2.028, 10.098], loss: 0.001467, mae: 0.040944, mean_q: 1.175473
 449600/1000000: episode: 4496, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.201, mean reward: 0.582 [0.501, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.031, 10.175], loss: 0.001472, mae: 0.041736, mean_q: 1.176819
 449700/1000000: episode: 4497, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.817, mean reward: 0.588 [0.505, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.340, 10.098], loss: 0.001415, mae: 0.041169, mean_q: 1.175710
 449800/1000000: episode: 4498, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.648, mean reward: 0.576 [0.512, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.633, 10.157], loss: 0.001421, mae: 0.041048, mean_q: 1.174325
 449900/1000000: episode: 4499, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.694, mean reward: 0.577 [0.507, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.797, 10.098], loss: 0.001458, mae: 0.041716, mean_q: 1.177258
 450000/1000000: episode: 4500, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 56.721, mean reward: 0.567 [0.511, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.315, 10.158], loss: 0.001316, mae: 0.039219, mean_q: 1.170467
 450100/1000000: episode: 4501, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 61.213, mean reward: 0.612 [0.504, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.570, 10.098], loss: 0.001425, mae: 0.040566, mean_q: 1.169748
 450200/1000000: episode: 4502, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.897, mean reward: 0.579 [0.516, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.263, 10.098], loss: 0.001464, mae: 0.041900, mean_q: 1.172700
 450300/1000000: episode: 4503, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.413, mean reward: 0.594 [0.499, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.938, 10.214], loss: 0.001353, mae: 0.040150, mean_q: 1.172783
 450400/1000000: episode: 4504, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.799, mean reward: 0.588 [0.514, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.566, 10.235], loss: 0.001410, mae: 0.040849, mean_q: 1.169648
 450500/1000000: episode: 4505, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.342, mean reward: 0.573 [0.502, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.506, 10.098], loss: 0.001483, mae: 0.041314, mean_q: 1.173042
 450600/1000000: episode: 4506, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.993, mean reward: 0.580 [0.500, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.059, 10.189], loss: 0.001388, mae: 0.040413, mean_q: 1.173833
 450700/1000000: episode: 4507, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 67.718, mean reward: 0.677 [0.514, 0.882], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.551, 10.098], loss: 0.001411, mae: 0.041085, mean_q: 1.174963
 450800/1000000: episode: 4508, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.720, mean reward: 0.587 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.261, 10.098], loss: 0.001412, mae: 0.041354, mean_q: 1.170209
 450900/1000000: episode: 4509, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.479, mean reward: 0.595 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.855, 10.118], loss: 0.001437, mae: 0.041186, mean_q: 1.170266
 451000/1000000: episode: 4510, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.282, mean reward: 0.603 [0.504, 0.912], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.676, 10.225], loss: 0.001478, mae: 0.041824, mean_q: 1.172541
 451100/1000000: episode: 4511, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.063, mean reward: 0.591 [0.501, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.536, 10.302], loss: 0.001403, mae: 0.040291, mean_q: 1.171830
 451200/1000000: episode: 4512, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.486, mean reward: 0.575 [0.500, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.682, 10.189], loss: 0.001501, mae: 0.041871, mean_q: 1.171674
 451300/1000000: episode: 4513, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.379, mean reward: 0.604 [0.508, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.654, 10.364], loss: 0.001478, mae: 0.041557, mean_q: 1.174887
 451400/1000000: episode: 4514, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.014, mean reward: 0.600 [0.500, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.139, 10.345], loss: 0.001466, mae: 0.041302, mean_q: 1.172024
 451500/1000000: episode: 4515, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.083, mean reward: 0.581 [0.518, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.460, 10.229], loss: 0.001386, mae: 0.040432, mean_q: 1.171332
 451600/1000000: episode: 4516, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.640, mean reward: 0.576 [0.505, 0.666], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.551, 10.148], loss: 0.001513, mae: 0.041077, mean_q: 1.169895
 451700/1000000: episode: 4517, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.262, mean reward: 0.573 [0.499, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.043, 10.109], loss: 0.001546, mae: 0.042502, mean_q: 1.171632
 451800/1000000: episode: 4518, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.527, mean reward: 0.575 [0.510, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.961, 10.098], loss: 0.001465, mae: 0.041500, mean_q: 1.170007
 451900/1000000: episode: 4519, duration: 0.604s, episode steps: 100, steps per second: 165, episode reward: 58.977, mean reward: 0.590 [0.499, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.496, 10.098], loss: 0.001419, mae: 0.040343, mean_q: 1.167894
 452000/1000000: episode: 4520, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.498, mean reward: 0.575 [0.502, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.530, 10.201], loss: 0.001405, mae: 0.040437, mean_q: 1.170629
 452100/1000000: episode: 4521, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 63.001, mean reward: 0.630 [0.513, 0.885], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.162, 10.643], loss: 0.001465, mae: 0.041773, mean_q: 1.168855
 452200/1000000: episode: 4522, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.786, mean reward: 0.578 [0.499, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.695, 10.194], loss: 0.001392, mae: 0.040589, mean_q: 1.169790
 452300/1000000: episode: 4523, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.012, mean reward: 0.600 [0.507, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.781, 10.398], loss: 0.001473, mae: 0.041403, mean_q: 1.167820
 452400/1000000: episode: 4524, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.579, mean reward: 0.596 [0.500, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.651, 10.257], loss: 0.001418, mae: 0.040719, mean_q: 1.168476
 452500/1000000: episode: 4525, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.652, mean reward: 0.577 [0.500, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.646, 10.098], loss: 0.001425, mae: 0.040918, mean_q: 1.164886
 452600/1000000: episode: 4526, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.900, mean reward: 0.599 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.503, 10.136], loss: 0.001458, mae: 0.041309, mean_q: 1.167627
 452700/1000000: episode: 4527, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 60.213, mean reward: 0.602 [0.501, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.775, 10.098], loss: 0.001366, mae: 0.040138, mean_q: 1.171411
 452800/1000000: episode: 4528, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.414, mean reward: 0.594 [0.502, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.329, 10.127], loss: 0.001394, mae: 0.040499, mean_q: 1.167296
 452900/1000000: episode: 4529, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.037, mean reward: 0.590 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.274, 10.106], loss: 0.001451, mae: 0.041031, mean_q: 1.164943
 453000/1000000: episode: 4530, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.337, mean reward: 0.573 [0.500, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.576, 10.189], loss: 0.001419, mae: 0.040974, mean_q: 1.166395
 453100/1000000: episode: 4531, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.903, mean reward: 0.629 [0.516, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.654, 10.205], loss: 0.001539, mae: 0.042365, mean_q: 1.166424
 453200/1000000: episode: 4532, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.937, mean reward: 0.589 [0.504, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.684, 10.348], loss: 0.001538, mae: 0.042536, mean_q: 1.165583
 453300/1000000: episode: 4533, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 59.323, mean reward: 0.593 [0.504, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.850, 10.203], loss: 0.001466, mae: 0.041815, mean_q: 1.169953
 453400/1000000: episode: 4534, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.484, mean reward: 0.585 [0.505, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.217, 10.098], loss: 0.001385, mae: 0.040630, mean_q: 1.171164
 453500/1000000: episode: 4535, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.517, mean reward: 0.575 [0.500, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.587, 10.189], loss: 0.001479, mae: 0.041418, mean_q: 1.167656
 453600/1000000: episode: 4536, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 56.908, mean reward: 0.569 [0.498, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.602, 10.199], loss: 0.001377, mae: 0.039947, mean_q: 1.168535
 453700/1000000: episode: 4537, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.045, mean reward: 0.580 [0.502, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.663, 10.211], loss: 0.001511, mae: 0.041740, mean_q: 1.167340
 453800/1000000: episode: 4538, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 61.315, mean reward: 0.613 [0.504, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.900, 10.127], loss: 0.001579, mae: 0.042449, mean_q: 1.169544
 453900/1000000: episode: 4539, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.960, mean reward: 0.590 [0.500, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.021, 10.098], loss: 0.001497, mae: 0.041338, mean_q: 1.167194
 454000/1000000: episode: 4540, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 58.668, mean reward: 0.587 [0.504, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.642, 10.098], loss: 0.001465, mae: 0.041283, mean_q: 1.168362
 454100/1000000: episode: 4541, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.013, mean reward: 0.570 [0.512, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.148, 10.139], loss: 0.001415, mae: 0.041071, mean_q: 1.167458
 454200/1000000: episode: 4542, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 62.844, mean reward: 0.628 [0.517, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.876, 10.098], loss: 0.001404, mae: 0.040611, mean_q: 1.167720
 454300/1000000: episode: 4543, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.268, mean reward: 0.583 [0.500, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.160, 10.251], loss: 0.001429, mae: 0.041213, mean_q: 1.172477
 454400/1000000: episode: 4544, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 61.412, mean reward: 0.614 [0.497, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.109, 10.151], loss: 0.001537, mae: 0.042003, mean_q: 1.173366
 454500/1000000: episode: 4545, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.180, mean reward: 0.572 [0.500, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.325, 10.098], loss: 0.001463, mae: 0.041331, mean_q: 1.167526
 454600/1000000: episode: 4546, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.865, mean reward: 0.599 [0.508, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.692, 10.098], loss: 0.001550, mae: 0.042814, mean_q: 1.172769
 454700/1000000: episode: 4547, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.817, mean reward: 0.598 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.503, 10.288], loss: 0.001529, mae: 0.042688, mean_q: 1.171241
 454800/1000000: episode: 4548, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 60.394, mean reward: 0.604 [0.507, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.428, 10.251], loss: 0.001547, mae: 0.041942, mean_q: 1.169076
 454900/1000000: episode: 4549, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.402, mean reward: 0.594 [0.511, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.756, 10.098], loss: 0.001589, mae: 0.042768, mean_q: 1.174378
 455000/1000000: episode: 4550, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.226, mean reward: 0.582 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.685, 10.271], loss: 0.001664, mae: 0.043633, mean_q: 1.172004
 455100/1000000: episode: 4551, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.531, mean reward: 0.605 [0.500, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.782, 10.098], loss: 0.001439, mae: 0.040932, mean_q: 1.172549
 455200/1000000: episode: 4552, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.315, mean reward: 0.583 [0.501, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.218, 10.219], loss: 0.001622, mae: 0.043527, mean_q: 1.172730
 455300/1000000: episode: 4553, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.823, mean reward: 0.578 [0.508, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.705, 10.098], loss: 0.001465, mae: 0.041073, mean_q: 1.169120
 455400/1000000: episode: 4554, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.499, mean reward: 0.585 [0.508, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.306, 10.271], loss: 0.001604, mae: 0.043092, mean_q: 1.171672
 455500/1000000: episode: 4555, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 63.722, mean reward: 0.637 [0.534, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.906, 10.098], loss: 0.001573, mae: 0.043190, mean_q: 1.174640
 455600/1000000: episode: 4556, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.971, mean reward: 0.630 [0.499, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.895, 10.450], loss: 0.001537, mae: 0.042296, mean_q: 1.177544
 455700/1000000: episode: 4557, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.462, mean reward: 0.605 [0.503, 0.962], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.681, 10.365], loss: 0.001592, mae: 0.043128, mean_q: 1.174997
 455800/1000000: episode: 4558, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.543, mean reward: 0.585 [0.500, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.406, 10.098], loss: 0.001598, mae: 0.042646, mean_q: 1.173177
 455900/1000000: episode: 4559, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.159, mean reward: 0.582 [0.504, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.943, 10.194], loss: 0.001575, mae: 0.042330, mean_q: 1.170373
 456000/1000000: episode: 4560, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 56.984, mean reward: 0.570 [0.505, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.230, 10.213], loss: 0.001600, mae: 0.043264, mean_q: 1.176939
 456100/1000000: episode: 4561, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.657, mean reward: 0.587 [0.510, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.772, 10.267], loss: 0.001468, mae: 0.041432, mean_q: 1.170635
 456200/1000000: episode: 4562, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.955, mean reward: 0.590 [0.507, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.024, 10.098], loss: 0.001557, mae: 0.042510, mean_q: 1.170634
 456300/1000000: episode: 4563, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.833, mean reward: 0.608 [0.510, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.302, 10.374], loss: 0.001548, mae: 0.042533, mean_q: 1.169165
 456400/1000000: episode: 4564, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 58.988, mean reward: 0.590 [0.507, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.061, 10.098], loss: 0.001523, mae: 0.041732, mean_q: 1.168412
 456500/1000000: episode: 4565, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.694, mean reward: 0.577 [0.502, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.580, 10.390], loss: 0.001612, mae: 0.043179, mean_q: 1.174247
 456600/1000000: episode: 4566, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.811, mean reward: 0.588 [0.506, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.037, 10.394], loss: 0.001712, mae: 0.044251, mean_q: 1.172448
 456700/1000000: episode: 4567, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.572, mean reward: 0.586 [0.500, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.682, 10.098], loss: 0.001575, mae: 0.042426, mean_q: 1.171257
 456800/1000000: episode: 4568, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 65.743, mean reward: 0.657 [0.529, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.228, 10.098], loss: 0.001489, mae: 0.041758, mean_q: 1.169877
 456900/1000000: episode: 4569, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.393, mean reward: 0.604 [0.517, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.872, 10.098], loss: 0.001564, mae: 0.042383, mean_q: 1.176397
 457000/1000000: episode: 4570, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.300, mean reward: 0.603 [0.509, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.909, 10.142], loss: 0.001680, mae: 0.044332, mean_q: 1.176165
 457100/1000000: episode: 4571, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.205, mean reward: 0.572 [0.501, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.634, 10.131], loss: 0.001538, mae: 0.041723, mean_q: 1.178362
 457200/1000000: episode: 4572, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.376, mean reward: 0.584 [0.515, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.463, 10.098], loss: 0.001607, mae: 0.042888, mean_q: 1.177380
 457300/1000000: episode: 4573, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.498, mean reward: 0.595 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.597, 10.181], loss: 0.001541, mae: 0.042204, mean_q: 1.172533
 457400/1000000: episode: 4574, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.741, mean reward: 0.577 [0.502, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.132, 10.098], loss: 0.001636, mae: 0.043678, mean_q: 1.178598
 457500/1000000: episode: 4575, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.659, mean reward: 0.617 [0.511, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.868, 10.352], loss: 0.001474, mae: 0.041334, mean_q: 1.173540
 457600/1000000: episode: 4576, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.027, mean reward: 0.580 [0.506, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.161, 10.098], loss: 0.001538, mae: 0.042566, mean_q: 1.179112
 457700/1000000: episode: 4577, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.422, mean reward: 0.604 [0.504, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.111, 10.098], loss: 0.001480, mae: 0.041557, mean_q: 1.173215
 457800/1000000: episode: 4578, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 65.737, mean reward: 0.657 [0.500, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.600, 10.366], loss: 0.001672, mae: 0.043977, mean_q: 1.177329
 457900/1000000: episode: 4579, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 60.760, mean reward: 0.608 [0.503, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.358, 10.179], loss: 0.001542, mae: 0.041722, mean_q: 1.176664
 458000/1000000: episode: 4580, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.819, mean reward: 0.598 [0.521, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.169, 10.174], loss: 0.001559, mae: 0.042487, mean_q: 1.181067
 458100/1000000: episode: 4581, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.677, mean reward: 0.597 [0.504, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.698, 10.098], loss: 0.001573, mae: 0.043227, mean_q: 1.178366
 458200/1000000: episode: 4582, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.173, mean reward: 0.602 [0.508, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.776, 10.295], loss: 0.001485, mae: 0.041720, mean_q: 1.178352
 458300/1000000: episode: 4583, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.543, mean reward: 0.585 [0.501, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.810, 10.232], loss: 0.001494, mae: 0.041934, mean_q: 1.179186
 458400/1000000: episode: 4584, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.165, mean reward: 0.592 [0.498, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.926, 10.098], loss: 0.001515, mae: 0.042270, mean_q: 1.182779
 458500/1000000: episode: 4585, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.122, mean reward: 0.581 [0.502, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.975, 10.098], loss: 0.001470, mae: 0.041675, mean_q: 1.175792
 458600/1000000: episode: 4586, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.768, mean reward: 0.588 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.180, 10.098], loss: 0.001521, mae: 0.042333, mean_q: 1.177093
 458700/1000000: episode: 4587, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.108, mean reward: 0.571 [0.498, 0.666], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.711, 10.098], loss: 0.001554, mae: 0.042771, mean_q: 1.181859
 458800/1000000: episode: 4588, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.508, mean reward: 0.575 [0.507, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.796, 10.098], loss: 0.001448, mae: 0.041568, mean_q: 1.179243
 458900/1000000: episode: 4589, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 57.813, mean reward: 0.578 [0.503, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.647, 10.098], loss: 0.001529, mae: 0.042599, mean_q: 1.179564
 459000/1000000: episode: 4590, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.178, mean reward: 0.582 [0.504, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.535, 10.098], loss: 0.001516, mae: 0.042154, mean_q: 1.177494
 459100/1000000: episode: 4591, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 59.477, mean reward: 0.595 [0.508, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.959, 10.098], loss: 0.001566, mae: 0.043043, mean_q: 1.181895
 459200/1000000: episode: 4592, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 62.372, mean reward: 0.624 [0.507, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.542, 10.161], loss: 0.001518, mae: 0.042339, mean_q: 1.175755
 459300/1000000: episode: 4593, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.350, mean reward: 0.613 [0.518, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.659, 10.098], loss: 0.001548, mae: 0.041786, mean_q: 1.178045
 459400/1000000: episode: 4594, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.787, mean reward: 0.578 [0.503, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.781, 10.098], loss: 0.001503, mae: 0.041518, mean_q: 1.178556
 459500/1000000: episode: 4595, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.380, mean reward: 0.574 [0.497, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.393, 10.098], loss: 0.001517, mae: 0.042297, mean_q: 1.180997
 459600/1000000: episode: 4596, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 62.224, mean reward: 0.622 [0.533, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.336, 10.281], loss: 0.001542, mae: 0.042695, mean_q: 1.181342
 459700/1000000: episode: 4597, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.084, mean reward: 0.611 [0.507, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.882, 10.489], loss: 0.001519, mae: 0.042042, mean_q: 1.179568
 459800/1000000: episode: 4598, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.369, mean reward: 0.604 [0.516, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.721, 10.330], loss: 0.001479, mae: 0.041793, mean_q: 1.176671
 459900/1000000: episode: 4599, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.297, mean reward: 0.593 [0.507, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.871, 10.098], loss: 0.001438, mae: 0.041202, mean_q: 1.177243
 460000/1000000: episode: 4600, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.041, mean reward: 0.580 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.392, 10.098], loss: 0.001616, mae: 0.043286, mean_q: 1.180000
 460100/1000000: episode: 4601, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.172, mean reward: 0.572 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.304, 10.127], loss: 0.001384, mae: 0.039960, mean_q: 1.175475
 460200/1000000: episode: 4602, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 63.953, mean reward: 0.640 [0.507, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.738, 10.193], loss: 0.001367, mae: 0.039861, mean_q: 1.176748
 460300/1000000: episode: 4603, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.234, mean reward: 0.592 [0.502, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.965, 10.273], loss: 0.001484, mae: 0.041332, mean_q: 1.181185
 460400/1000000: episode: 4604, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.697, mean reward: 0.597 [0.515, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.685, 10.098], loss: 0.001425, mae: 0.040984, mean_q: 1.181974
 460500/1000000: episode: 4605, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.132, mean reward: 0.581 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.178, 10.249], loss: 0.001421, mae: 0.040819, mean_q: 1.179602
 460600/1000000: episode: 4606, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.317, mean reward: 0.583 [0.507, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.291, 10.178], loss: 0.001377, mae: 0.040064, mean_q: 1.173525
 460700/1000000: episode: 4607, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.668, mean reward: 0.597 [0.504, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.916, 10.123], loss: 0.001401, mae: 0.040614, mean_q: 1.173466
 460800/1000000: episode: 4608, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.262, mean reward: 0.573 [0.503, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.807, 10.098], loss: 0.001397, mae: 0.040683, mean_q: 1.175435
 460900/1000000: episode: 4609, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.139, mean reward: 0.591 [0.511, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.553, 10.139], loss: 0.001490, mae: 0.042012, mean_q: 1.176797
 461000/1000000: episode: 4610, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.953, mean reward: 0.570 [0.501, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.594, 10.098], loss: 0.001498, mae: 0.041914, mean_q: 1.178919
 461100/1000000: episode: 4611, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.426, mean reward: 0.574 [0.505, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.639, 10.379], loss: 0.001463, mae: 0.042121, mean_q: 1.180299
 461200/1000000: episode: 4612, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.932, mean reward: 0.589 [0.503, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.991, 10.098], loss: 0.001357, mae: 0.040520, mean_q: 1.179544
 461300/1000000: episode: 4613, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.159, mean reward: 0.582 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.482, 10.165], loss: 0.001416, mae: 0.041262, mean_q: 1.174904
 461400/1000000: episode: 4614, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.949, mean reward: 0.599 [0.499, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.802, 10.098], loss: 0.001487, mae: 0.041715, mean_q: 1.171654
 461500/1000000: episode: 4615, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.294, mean reward: 0.573 [0.500, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.077, 10.213], loss: 0.001496, mae: 0.041627, mean_q: 1.174896
 461600/1000000: episode: 4616, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 61.219, mean reward: 0.612 [0.506, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.029, 10.098], loss: 0.001420, mae: 0.041103, mean_q: 1.175923
 461700/1000000: episode: 4617, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.976, mean reward: 0.580 [0.502, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.505, 10.155], loss: 0.001496, mae: 0.042091, mean_q: 1.175057
 461800/1000000: episode: 4618, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 57.510, mean reward: 0.575 [0.499, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.355, 10.125], loss: 0.001395, mae: 0.040821, mean_q: 1.172344
 461900/1000000: episode: 4619, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.982, mean reward: 0.590 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.480, 10.098], loss: 0.001378, mae: 0.041027, mean_q: 1.170654
 462000/1000000: episode: 4620, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.850, mean reward: 0.589 [0.505, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.382, 10.206], loss: 0.001415, mae: 0.041019, mean_q: 1.170561
 462100/1000000: episode: 4621, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.413, mean reward: 0.584 [0.504, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.422, 10.103], loss: 0.001402, mae: 0.041246, mean_q: 1.172393
 462200/1000000: episode: 4622, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.802, mean reward: 0.618 [0.509, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.882, 10.098], loss: 0.001370, mae: 0.040427, mean_q: 1.172987
 462300/1000000: episode: 4623, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.343, mean reward: 0.603 [0.518, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.566, 10.238], loss: 0.001365, mae: 0.040282, mean_q: 1.174990
 462400/1000000: episode: 4624, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.480, mean reward: 0.575 [0.501, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.578, 10.144], loss: 0.001344, mae: 0.039640, mean_q: 1.172395
 462500/1000000: episode: 4625, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.304, mean reward: 0.583 [0.508, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.567, 10.210], loss: 0.001417, mae: 0.041002, mean_q: 1.169352
 462600/1000000: episode: 4626, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.495, mean reward: 0.575 [0.504, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.273, 10.191], loss: 0.001387, mae: 0.041024, mean_q: 1.173007
 462700/1000000: episode: 4627, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.071, mean reward: 0.591 [0.510, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.542, 10.423], loss: 0.001414, mae: 0.041305, mean_q: 1.171906
 462800/1000000: episode: 4628, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.938, mean reward: 0.579 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.487, 10.102], loss: 0.001374, mae: 0.040589, mean_q: 1.171692
 462900/1000000: episode: 4629, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.181, mean reward: 0.572 [0.502, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.599, 10.098], loss: 0.001391, mae: 0.041037, mean_q: 1.166052
 463000/1000000: episode: 4630, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.660, mean reward: 0.597 [0.502, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.744, 10.233], loss: 0.001417, mae: 0.042025, mean_q: 1.166482
 463100/1000000: episode: 4631, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.466, mean reward: 0.575 [0.504, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.906, 10.201], loss: 0.001378, mae: 0.040554, mean_q: 1.166429
 463200/1000000: episode: 4632, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.202, mean reward: 0.582 [0.500, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.126, 10.098], loss: 0.001310, mae: 0.040002, mean_q: 1.166564
 463300/1000000: episode: 4633, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.592, mean reward: 0.596 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.136, 10.098], loss: 0.001409, mae: 0.040910, mean_q: 1.166430
 463400/1000000: episode: 4634, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.134, mean reward: 0.591 [0.506, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.202, 10.225], loss: 0.001424, mae: 0.041707, mean_q: 1.168673
 463500/1000000: episode: 4635, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.140, mean reward: 0.581 [0.509, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.948, 10.160], loss: 0.001381, mae: 0.040720, mean_q: 1.164321
 463600/1000000: episode: 4636, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.292, mean reward: 0.573 [0.499, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.679, 10.098], loss: 0.001350, mae: 0.040637, mean_q: 1.164692
 463700/1000000: episode: 4637, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.851, mean reward: 0.589 [0.507, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.196, 10.251], loss: 0.001330, mae: 0.040217, mean_q: 1.166513
 463800/1000000: episode: 4638, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.113, mean reward: 0.581 [0.501, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.871, 10.098], loss: 0.001333, mae: 0.040212, mean_q: 1.166439
 463900/1000000: episode: 4639, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 60.171, mean reward: 0.602 [0.503, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.435, 10.299], loss: 0.001342, mae: 0.040250, mean_q: 1.165618
 464000/1000000: episode: 4640, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.804, mean reward: 0.588 [0.506, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.531, 10.098], loss: 0.001267, mae: 0.039605, mean_q: 1.167602
 464100/1000000: episode: 4641, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.795, mean reward: 0.588 [0.501, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.793, 10.098], loss: 0.001355, mae: 0.040496, mean_q: 1.162631
 464200/1000000: episode: 4642, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.843, mean reward: 0.578 [0.504, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.872, 10.098], loss: 0.001354, mae: 0.040737, mean_q: 1.164371
 464300/1000000: episode: 4643, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.673, mean reward: 0.577 [0.510, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.860, 10.161], loss: 0.001343, mae: 0.040477, mean_q: 1.162277
 464400/1000000: episode: 4644, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.153, mean reward: 0.592 [0.502, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.841, 10.098], loss: 0.001404, mae: 0.041398, mean_q: 1.164792
 464500/1000000: episode: 4645, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.511, mean reward: 0.575 [0.503, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.866, 10.098], loss: 0.001317, mae: 0.039559, mean_q: 1.165262
 464600/1000000: episode: 4646, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.121, mean reward: 0.571 [0.504, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.654, 10.098], loss: 0.001438, mae: 0.041604, mean_q: 1.162561
 464700/1000000: episode: 4647, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.262, mean reward: 0.583 [0.506, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.615, 10.122], loss: 0.001338, mae: 0.040019, mean_q: 1.162775
 464800/1000000: episode: 4648, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.753, mean reward: 0.588 [0.516, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.280, 10.138], loss: 0.001378, mae: 0.040670, mean_q: 1.162703
 464900/1000000: episode: 4649, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.879, mean reward: 0.589 [0.500, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.800, 10.098], loss: 0.001388, mae: 0.039996, mean_q: 1.161936
 465000/1000000: episode: 4650, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.624, mean reward: 0.596 [0.515, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.178, 10.098], loss: 0.001356, mae: 0.039967, mean_q: 1.159561
 465100/1000000: episode: 4651, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.630, mean reward: 0.576 [0.507, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-2.083, 10.338], loss: 0.001366, mae: 0.040923, mean_q: 1.160536
 465200/1000000: episode: 4652, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.146, mean reward: 0.591 [0.509, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.670, 10.098], loss: 0.001401, mae: 0.040322, mean_q: 1.160535
 465300/1000000: episode: 4653, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.332, mean reward: 0.563 [0.505, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.825, 10.200], loss: 0.001421, mae: 0.040766, mean_q: 1.163474
 465400/1000000: episode: 4654, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.084, mean reward: 0.591 [0.507, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.627, 10.098], loss: 0.001348, mae: 0.040445, mean_q: 1.161032
 465500/1000000: episode: 4655, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.138, mean reward: 0.581 [0.512, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.765, 10.197], loss: 0.001343, mae: 0.039734, mean_q: 1.157060
 465600/1000000: episode: 4656, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.496, mean reward: 0.585 [0.507, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.107, 10.098], loss: 0.001364, mae: 0.040042, mean_q: 1.158261
 465700/1000000: episode: 4657, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.355, mean reward: 0.594 [0.501, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.459, 10.098], loss: 0.001412, mae: 0.041375, mean_q: 1.160086
 465800/1000000: episode: 4658, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.134, mean reward: 0.581 [0.508, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.787, 10.136], loss: 0.001345, mae: 0.039768, mean_q: 1.157367
 465900/1000000: episode: 4659, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.278, mean reward: 0.573 [0.505, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.872, 10.098], loss: 0.001467, mae: 0.041876, mean_q: 1.159039
 466000/1000000: episode: 4660, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.908, mean reward: 0.579 [0.504, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.722, 10.123], loss: 0.001319, mae: 0.039002, mean_q: 1.158979
 466100/1000000: episode: 4661, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.318, mean reward: 0.603 [0.509, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.007, 10.098], loss: 0.001351, mae: 0.040261, mean_q: 1.158441
 466200/1000000: episode: 4662, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 56.991, mean reward: 0.570 [0.501, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.384, 10.114], loss: 0.001430, mae: 0.041165, mean_q: 1.158538
 466300/1000000: episode: 4663, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.691, mean reward: 0.597 [0.508, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.786, 10.098], loss: 0.001491, mae: 0.041767, mean_q: 1.159005
 466400/1000000: episode: 4664, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.237, mean reward: 0.602 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.218, 10.374], loss: 0.001477, mae: 0.041571, mean_q: 1.157447
 466500/1000000: episode: 4665, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.985, mean reward: 0.580 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.824, 10.098], loss: 0.001436, mae: 0.040829, mean_q: 1.156073
 466600/1000000: episode: 4666, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.311, mean reward: 0.573 [0.509, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.218, 10.262], loss: 0.001548, mae: 0.042846, mean_q: 1.160004
 466700/1000000: episode: 4667, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 56.698, mean reward: 0.567 [0.502, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.728, 10.160], loss: 0.001483, mae: 0.041950, mean_q: 1.155558
 466800/1000000: episode: 4668, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.639, mean reward: 0.586 [0.514, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.585, 10.264], loss: 0.001459, mae: 0.041325, mean_q: 1.157864
 466900/1000000: episode: 4669, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.536, mean reward: 0.595 [0.504, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.625, 10.098], loss: 0.001479, mae: 0.041651, mean_q: 1.156210
 467000/1000000: episode: 4670, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.325, mean reward: 0.613 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.781, 10.272], loss: 0.001523, mae: 0.041904, mean_q: 1.159684
 467100/1000000: episode: 4671, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.256, mean reward: 0.573 [0.503, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.828, 10.101], loss: 0.001426, mae: 0.040958, mean_q: 1.157043
 467200/1000000: episode: 4672, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.635, mean reward: 0.606 [0.508, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.049, 10.098], loss: 0.001463, mae: 0.041636, mean_q: 1.159163
 467300/1000000: episode: 4673, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.314, mean reward: 0.593 [0.515, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.774, 10.278], loss: 0.001520, mae: 0.042092, mean_q: 1.157042
 467400/1000000: episode: 4674, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.399, mean reward: 0.604 [0.509, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.771, 10.098], loss: 0.001369, mae: 0.040333, mean_q: 1.153781
 467500/1000000: episode: 4675, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 62.801, mean reward: 0.628 [0.512, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.331, 10.098], loss: 0.001453, mae: 0.041076, mean_q: 1.160784
 467600/1000000: episode: 4676, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 61.284, mean reward: 0.613 [0.516, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.724, 10.165], loss: 0.001410, mae: 0.041258, mean_q: 1.161287
 467700/1000000: episode: 4677, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.248, mean reward: 0.572 [0.507, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.205, 10.098], loss: 0.001562, mae: 0.042276, mean_q: 1.159308
 467800/1000000: episode: 4678, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.645, mean reward: 0.576 [0.508, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.127, 10.264], loss: 0.001472, mae: 0.042319, mean_q: 1.161874
 467900/1000000: episode: 4679, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.547, mean reward: 0.605 [0.515, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.332, 10.098], loss: 0.001373, mae: 0.039712, mean_q: 1.158915
 468000/1000000: episode: 4680, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.829, mean reward: 0.568 [0.500, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.796, 10.098], loss: 0.001389, mae: 0.040758, mean_q: 1.161667
 468100/1000000: episode: 4681, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.676, mean reward: 0.577 [0.511, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.979, 10.188], loss: 0.001338, mae: 0.040109, mean_q: 1.162183
 468200/1000000: episode: 4682, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.848, mean reward: 0.568 [0.511, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.282, 10.220], loss: 0.001349, mae: 0.040372, mean_q: 1.161078
 468300/1000000: episode: 4683, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.367, mean reward: 0.574 [0.499, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.339, 10.182], loss: 0.001371, mae: 0.039883, mean_q: 1.158647
 468400/1000000: episode: 4684, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.977, mean reward: 0.590 [0.502, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.945, 10.098], loss: 0.001427, mae: 0.040900, mean_q: 1.164514
 468500/1000000: episode: 4685, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.337, mean reward: 0.583 [0.501, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.981, 10.274], loss: 0.001428, mae: 0.040775, mean_q: 1.159593
 468600/1000000: episode: 4686, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 56.321, mean reward: 0.563 [0.498, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.237, 10.098], loss: 0.001436, mae: 0.040790, mean_q: 1.155542
 468700/1000000: episode: 4687, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.568, mean reward: 0.576 [0.502, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.297, 10.118], loss: 0.001453, mae: 0.040968, mean_q: 1.158547
 468800/1000000: episode: 4688, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.490, mean reward: 0.585 [0.510, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.595, 10.111], loss: 0.001445, mae: 0.041434, mean_q: 1.160784
 468900/1000000: episode: 4689, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 64.208, mean reward: 0.642 [0.511, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.397, 10.353], loss: 0.001494, mae: 0.041619, mean_q: 1.162900
 469000/1000000: episode: 4690, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.969, mean reward: 0.580 [0.503, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.804, 10.098], loss: 0.001524, mae: 0.041907, mean_q: 1.165319
 469100/1000000: episode: 4691, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.566, mean reward: 0.576 [0.511, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.139, 10.098], loss: 0.001568, mae: 0.042573, mean_q: 1.163274
 469200/1000000: episode: 4692, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.530, mean reward: 0.565 [0.499, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.499, 10.098], loss: 0.001381, mae: 0.040638, mean_q: 1.158535
 469300/1000000: episode: 4693, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 62.540, mean reward: 0.625 [0.504, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.718, 10.354], loss: 0.001494, mae: 0.041483, mean_q: 1.155635
 469400/1000000: episode: 4694, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 55.970, mean reward: 0.560 [0.500, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.975, 10.212], loss: 0.001356, mae: 0.040231, mean_q: 1.159452
 469500/1000000: episode: 4695, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.754, mean reward: 0.578 [0.503, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.110, 10.098], loss: 0.001453, mae: 0.040704, mean_q: 1.157403
 469600/1000000: episode: 4696, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 62.025, mean reward: 0.620 [0.507, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.956, 10.270], loss: 0.001450, mae: 0.041202, mean_q: 1.161550
 469700/1000000: episode: 4697, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.988, mean reward: 0.580 [0.502, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.257, 10.131], loss: 0.001485, mae: 0.041326, mean_q: 1.160214
 469800/1000000: episode: 4698, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.729, mean reward: 0.567 [0.501, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.382, 10.153], loss: 0.001516, mae: 0.042079, mean_q: 1.162739
 469900/1000000: episode: 4699, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 60.648, mean reward: 0.606 [0.532, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.048, 10.345], loss: 0.001432, mae: 0.040937, mean_q: 1.159538
 470000/1000000: episode: 4700, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.365, mean reward: 0.574 [0.501, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.586, 10.182], loss: 0.001389, mae: 0.040568, mean_q: 1.160258
 470100/1000000: episode: 4701, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 62.915, mean reward: 0.629 [0.514, 0.863], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.010, 10.098], loss: 0.001485, mae: 0.041498, mean_q: 1.160696
 470200/1000000: episode: 4702, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.053, mean reward: 0.591 [0.512, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-2.374, 10.393], loss: 0.001447, mae: 0.041586, mean_q: 1.167720
 470300/1000000: episode: 4703, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.715, mean reward: 0.587 [0.502, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.753, 10.122], loss: 0.001420, mae: 0.041144, mean_q: 1.161752
 470400/1000000: episode: 4704, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.504, mean reward: 0.585 [0.514, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.756, 10.186], loss: 0.001440, mae: 0.041506, mean_q: 1.162653
 470500/1000000: episode: 4705, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 57.711, mean reward: 0.577 [0.500, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.911, 10.216], loss: 0.001492, mae: 0.041992, mean_q: 1.165426
 470600/1000000: episode: 4706, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.979, mean reward: 0.590 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.183, 10.178], loss: 0.001452, mae: 0.041591, mean_q: 1.163939
 470700/1000000: episode: 4707, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.678, mean reward: 0.597 [0.503, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.165, 10.325], loss: 0.001489, mae: 0.042183, mean_q: 1.161840
 470800/1000000: episode: 4708, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: 58.606, mean reward: 0.586 [0.507, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.400, 10.098], loss: 0.001520, mae: 0.041976, mean_q: 1.164850
 470900/1000000: episode: 4709, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.381, mean reward: 0.584 [0.502, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.028, 10.098], loss: 0.001463, mae: 0.041084, mean_q: 1.158987
 471000/1000000: episode: 4710, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 60.050, mean reward: 0.600 [0.507, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.712, 10.098], loss: 0.001458, mae: 0.041005, mean_q: 1.162316
 471100/1000000: episode: 4711, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.671, mean reward: 0.607 [0.505, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.716, 10.098], loss: 0.001452, mae: 0.041212, mean_q: 1.166359
 471200/1000000: episode: 4712, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.042, mean reward: 0.600 [0.502, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.446 [-0.826, 10.423], loss: 0.001485, mae: 0.041696, mean_q: 1.167066
 471300/1000000: episode: 4713, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.947, mean reward: 0.589 [0.503, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.397, 10.098], loss: 0.001373, mae: 0.040225, mean_q: 1.165144
 471400/1000000: episode: 4714, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 63.156, mean reward: 0.632 [0.516, 0.867], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.380, 10.509], loss: 0.001497, mae: 0.042048, mean_q: 1.168068
 471500/1000000: episode: 4715, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 62.281, mean reward: 0.623 [0.505, 0.869], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.995, 10.510], loss: 0.001409, mae: 0.040602, mean_q: 1.168551
 471600/1000000: episode: 4716, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 57.559, mean reward: 0.576 [0.509, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.914, 10.098], loss: 0.001493, mae: 0.041758, mean_q: 1.171525
 471700/1000000: episode: 4717, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.012, mean reward: 0.580 [0.501, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.616, 10.209], loss: 0.001533, mae: 0.042098, mean_q: 1.167651
 471800/1000000: episode: 4718, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.527, mean reward: 0.585 [0.505, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.115, 10.098], loss: 0.001498, mae: 0.042307, mean_q: 1.170747
 471900/1000000: episode: 4719, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 59.962, mean reward: 0.600 [0.503, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.151, 10.415], loss: 0.001540, mae: 0.042091, mean_q: 1.168732
 472000/1000000: episode: 4720, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 61.291, mean reward: 0.613 [0.526, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.550, 10.098], loss: 0.001622, mae: 0.043529, mean_q: 1.174302
 472100/1000000: episode: 4721, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.101, mean reward: 0.601 [0.510, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.509, 10.098], loss: 0.001473, mae: 0.041406, mean_q: 1.170401
 472200/1000000: episode: 4722, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 62.060, mean reward: 0.621 [0.516, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.101, 10.489], loss: 0.001467, mae: 0.040795, mean_q: 1.169432
 472300/1000000: episode: 4723, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.382, mean reward: 0.584 [0.507, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.644, 10.268], loss: 0.001430, mae: 0.040191, mean_q: 1.169728
 472400/1000000: episode: 4724, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.895, mean reward: 0.599 [0.517, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.029, 10.376], loss: 0.001491, mae: 0.041372, mean_q: 1.174366
 472500/1000000: episode: 4725, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.941, mean reward: 0.579 [0.503, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.939, 10.202], loss: 0.001453, mae: 0.041634, mean_q: 1.170571
 472600/1000000: episode: 4726, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.064, mean reward: 0.581 [0.501, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.006, 10.354], loss: 0.001496, mae: 0.041992, mean_q: 1.167495
 472700/1000000: episode: 4727, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.498, mean reward: 0.575 [0.500, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.648, 10.110], loss: 0.001528, mae: 0.042545, mean_q: 1.167325
 472800/1000000: episode: 4728, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.242, mean reward: 0.592 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-2.441, 10.098], loss: 0.001495, mae: 0.041882, mean_q: 1.166677
 472900/1000000: episode: 4729, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.471, mean reward: 0.605 [0.505, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.460, 10.368], loss: 0.001489, mae: 0.041184, mean_q: 1.165541
 473000/1000000: episode: 4730, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.232, mean reward: 0.562 [0.505, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.232, 10.098], loss: 0.001415, mae: 0.040780, mean_q: 1.167079
 473100/1000000: episode: 4731, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.642, mean reward: 0.586 [0.506, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.179, 10.123], loss: 0.001426, mae: 0.040604, mean_q: 1.170917
 473200/1000000: episode: 4732, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.612, mean reward: 0.596 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.339, 10.098], loss: 0.001465, mae: 0.041418, mean_q: 1.168058
 473300/1000000: episode: 4733, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.956, mean reward: 0.610 [0.504, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.981, 10.155], loss: 0.001429, mae: 0.040497, mean_q: 1.170252
 473400/1000000: episode: 4734, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.072, mean reward: 0.591 [0.507, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.376, 10.098], loss: 0.001458, mae: 0.040942, mean_q: 1.170720
 473500/1000000: episode: 4735, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.336, mean reward: 0.573 [0.501, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.425, 10.098], loss: 0.001365, mae: 0.040144, mean_q: 1.168527
 473600/1000000: episode: 4736, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.746, mean reward: 0.607 [0.504, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.984, 10.098], loss: 0.001542, mae: 0.042124, mean_q: 1.171653
 473700/1000000: episode: 4737, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.110, mean reward: 0.601 [0.503, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.644, 10.240], loss: 0.001422, mae: 0.040942, mean_q: 1.169320
 473800/1000000: episode: 4738, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.099, mean reward: 0.581 [0.513, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.676, 10.203], loss: 0.001498, mae: 0.041838, mean_q: 1.172892
 473900/1000000: episode: 4739, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.530, mean reward: 0.565 [0.502, 0.669], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.286, 10.098], loss: 0.001402, mae: 0.040140, mean_q: 1.171950
 474000/1000000: episode: 4740, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.408, mean reward: 0.604 [0.504, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.963, 10.098], loss: 0.001508, mae: 0.040956, mean_q: 1.169789
 474100/1000000: episode: 4741, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.772, mean reward: 0.578 [0.500, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.184, 10.246], loss: 0.001457, mae: 0.041466, mean_q: 1.169133
 474200/1000000: episode: 4742, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 61.023, mean reward: 0.610 [0.517, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.571, 10.271], loss: 0.001446, mae: 0.040903, mean_q: 1.173900
 474300/1000000: episode: 4743, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.683, mean reward: 0.607 [0.505, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.768, 10.134], loss: 0.001575, mae: 0.042986, mean_q: 1.172491
 474400/1000000: episode: 4744, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.865, mean reward: 0.589 [0.499, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.514, 10.098], loss: 0.001482, mae: 0.041574, mean_q: 1.174367
 474500/1000000: episode: 4745, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.759, mean reward: 0.598 [0.510, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.759, 10.098], loss: 0.001529, mae: 0.042195, mean_q: 1.176255
 474600/1000000: episode: 4746, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.488, mean reward: 0.615 [0.505, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.432, 10.098], loss: 0.001435, mae: 0.040958, mean_q: 1.173293
 474700/1000000: episode: 4747, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.827, mean reward: 0.588 [0.497, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.299, 10.167], loss: 0.001409, mae: 0.041333, mean_q: 1.178174
 474800/1000000: episode: 4748, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.717, mean reward: 0.577 [0.500, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.956, 10.154], loss: 0.001489, mae: 0.041518, mean_q: 1.173558
 474900/1000000: episode: 4749, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.478, mean reward: 0.605 [0.513, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.038, 10.350], loss: 0.001566, mae: 0.042346, mean_q: 1.175456
 475000/1000000: episode: 4750, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 56.385, mean reward: 0.564 [0.505, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.510, 10.112], loss: 0.001475, mae: 0.041720, mean_q: 1.176000
 475100/1000000: episode: 4751, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.299, mean reward: 0.583 [0.502, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.141, 10.098], loss: 0.001444, mae: 0.041177, mean_q: 1.175070
 475200/1000000: episode: 4752, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.923, mean reward: 0.599 [0.501, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.147, 10.240], loss: 0.001465, mae: 0.041607, mean_q: 1.172937
 475300/1000000: episode: 4753, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.183, mean reward: 0.582 [0.509, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.463, 10.246], loss: 0.001460, mae: 0.041196, mean_q: 1.173178
 475400/1000000: episode: 4754, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 56.856, mean reward: 0.569 [0.500, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.866, 10.119], loss: 0.001590, mae: 0.042708, mean_q: 1.173688
 475500/1000000: episode: 4755, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.507, mean reward: 0.575 [0.504, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.355, 10.098], loss: 0.001608, mae: 0.043317, mean_q: 1.169415
 475600/1000000: episode: 4756, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.639, mean reward: 0.596 [0.504, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.508, 10.179], loss: 0.001500, mae: 0.042678, mean_q: 1.168700
 475700/1000000: episode: 4757, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.848, mean reward: 0.588 [0.508, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.864, 10.098], loss: 0.001437, mae: 0.041123, mean_q: 1.173644
 475800/1000000: episode: 4758, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 57.552, mean reward: 0.576 [0.508, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.602, 10.098], loss: 0.001456, mae: 0.041025, mean_q: 1.172737
 475900/1000000: episode: 4759, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 64.734, mean reward: 0.647 [0.505, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.521, 10.098], loss: 0.001502, mae: 0.042038, mean_q: 1.171717
 476000/1000000: episode: 4760, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.548, mean reward: 0.575 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.351, 10.098], loss: 0.001440, mae: 0.040927, mean_q: 1.174578
 476100/1000000: episode: 4761, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.929, mean reward: 0.599 [0.501, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.620, 10.098], loss: 0.001393, mae: 0.039687, mean_q: 1.171509
 476200/1000000: episode: 4762, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 62.078, mean reward: 0.621 [0.511, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.914, 10.098], loss: 0.001396, mae: 0.040625, mean_q: 1.168850
 476300/1000000: episode: 4763, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.488, mean reward: 0.585 [0.501, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.851, 10.098], loss: 0.001526, mae: 0.042755, mean_q: 1.174695
 476400/1000000: episode: 4764, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 62.180, mean reward: 0.622 [0.515, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.934, 10.337], loss: 0.001466, mae: 0.041459, mean_q: 1.176620
 476500/1000000: episode: 4765, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.968, mean reward: 0.610 [0.506, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.526, 10.098], loss: 0.001447, mae: 0.041548, mean_q: 1.171018
 476600/1000000: episode: 4766, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.163, mean reward: 0.582 [0.508, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.663, 10.098], loss: 0.001531, mae: 0.042215, mean_q: 1.174987
 476700/1000000: episode: 4767, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.562, mean reward: 0.576 [0.505, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.190, 10.098], loss: 0.001398, mae: 0.040444, mean_q: 1.172328
 476800/1000000: episode: 4768, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.970, mean reward: 0.600 [0.507, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.863, 10.098], loss: 0.001436, mae: 0.041242, mean_q: 1.175936
 476900/1000000: episode: 4769, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.087, mean reward: 0.601 [0.506, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.187, 10.296], loss: 0.001396, mae: 0.039777, mean_q: 1.175647
 477000/1000000: episode: 4770, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.162, mean reward: 0.602 [0.507, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.270, 10.098], loss: 0.001340, mae: 0.039848, mean_q: 1.168418
 477100/1000000: episode: 4771, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.124, mean reward: 0.591 [0.507, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.577, 10.103], loss: 0.001307, mae: 0.039117, mean_q: 1.172925
 477200/1000000: episode: 4772, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.954, mean reward: 0.620 [0.499, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.866, 10.098], loss: 0.001366, mae: 0.040182, mean_q: 1.170453
 477300/1000000: episode: 4773, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.987, mean reward: 0.600 [0.511, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.969, 10.098], loss: 0.001353, mae: 0.039513, mean_q: 1.168792
 477400/1000000: episode: 4774, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.429, mean reward: 0.614 [0.512, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.457, 10.098], loss: 0.001349, mae: 0.040050, mean_q: 1.172758
 477500/1000000: episode: 4775, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 58.123, mean reward: 0.581 [0.510, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.235, 10.098], loss: 0.001390, mae: 0.040144, mean_q: 1.170428
 477600/1000000: episode: 4776, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.559, mean reward: 0.606 [0.498, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.539, 10.238], loss: 0.001360, mae: 0.040045, mean_q: 1.172218
 477700/1000000: episode: 4777, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.363, mean reward: 0.574 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.294, 10.128], loss: 0.001395, mae: 0.040648, mean_q: 1.174987
 477800/1000000: episode: 4778, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.987, mean reward: 0.610 [0.504, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.794, 10.586], loss: 0.001501, mae: 0.041797, mean_q: 1.175555
 477900/1000000: episode: 4779, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.530, mean reward: 0.585 [0.504, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.588, 10.337], loss: 0.001479, mae: 0.041246, mean_q: 1.176095
 478000/1000000: episode: 4780, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 57.794, mean reward: 0.578 [0.502, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.797, 10.135], loss: 0.001449, mae: 0.041177, mean_q: 1.173486
 478100/1000000: episode: 4781, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.823, mean reward: 0.598 [0.510, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.451, 10.098], loss: 0.001443, mae: 0.041014, mean_q: 1.173078
 478200/1000000: episode: 4782, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.065, mean reward: 0.581 [0.512, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.097, 10.145], loss: 0.001519, mae: 0.041683, mean_q: 1.175701
 478300/1000000: episode: 4783, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.665, mean reward: 0.617 [0.519, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.022, 10.193], loss: 0.001444, mae: 0.041624, mean_q: 1.176300
 478400/1000000: episode: 4784, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 60.376, mean reward: 0.604 [0.499, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.068, 10.098], loss: 0.001447, mae: 0.041039, mean_q: 1.176434
 478500/1000000: episode: 4785, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.310, mean reward: 0.603 [0.516, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.833, 10.098], loss: 0.001368, mae: 0.040485, mean_q: 1.173471
 478600/1000000: episode: 4786, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.773, mean reward: 0.588 [0.505, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.219, 10.392], loss: 0.001388, mae: 0.040192, mean_q: 1.178844
 478700/1000000: episode: 4787, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.210, mean reward: 0.582 [0.507, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.460, 10.098], loss: 0.001391, mae: 0.040577, mean_q: 1.171009
 478800/1000000: episode: 4788, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.362, mean reward: 0.574 [0.503, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.988, 10.098], loss: 0.001446, mae: 0.041482, mean_q: 1.173557
 478900/1000000: episode: 4789, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.503, mean reward: 0.605 [0.502, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.912, 10.098], loss: 0.001416, mae: 0.041235, mean_q: 1.173341
 479000/1000000: episode: 4790, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 58.956, mean reward: 0.590 [0.502, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.795, 10.098], loss: 0.001366, mae: 0.040465, mean_q: 1.175029
 479100/1000000: episode: 4791, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.660, mean reward: 0.587 [0.507, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.587, 10.106], loss: 0.001395, mae: 0.040730, mean_q: 1.176289
 479200/1000000: episode: 4792, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.889, mean reward: 0.599 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.941, 10.165], loss: 0.001391, mae: 0.040681, mean_q: 1.174367
 479300/1000000: episode: 4793, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 56.985, mean reward: 0.570 [0.500, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.520, 10.218], loss: 0.001379, mae: 0.040720, mean_q: 1.173949
 479400/1000000: episode: 4794, duration: 0.523s, episode steps: 100, steps per second: 191, episode reward: 57.119, mean reward: 0.571 [0.503, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.730, 10.195], loss: 0.001364, mae: 0.040185, mean_q: 1.174860
 479500/1000000: episode: 4795, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.953, mean reward: 0.580 [0.501, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.694, 10.130], loss: 0.001394, mae: 0.041323, mean_q: 1.172166
 479600/1000000: episode: 4796, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 61.695, mean reward: 0.617 [0.512, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.774, 10.118], loss: 0.001376, mae: 0.040309, mean_q: 1.171240
 479700/1000000: episode: 4797, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 62.046, mean reward: 0.620 [0.515, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.628, 10.276], loss: 0.001309, mae: 0.039500, mean_q: 1.172566
 479800/1000000: episode: 4798, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 61.789, mean reward: 0.618 [0.511, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.045, 10.098], loss: 0.001353, mae: 0.040182, mean_q: 1.171717
 479900/1000000: episode: 4799, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.869, mean reward: 0.589 [0.507, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.984, 10.242], loss: 0.001298, mae: 0.039504, mean_q: 1.176053
 480000/1000000: episode: 4800, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.028, mean reward: 0.600 [0.510, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.922, 10.098], loss: 0.001300, mae: 0.039225, mean_q: 1.174037
 480100/1000000: episode: 4801, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.736, mean reward: 0.577 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.821, 10.205], loss: 0.001309, mae: 0.039026, mean_q: 1.177492
 480200/1000000: episode: 4802, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.179, mean reward: 0.592 [0.512, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.923, 10.098], loss: 0.001424, mae: 0.040822, mean_q: 1.175027
 480300/1000000: episode: 4803, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 61.254, mean reward: 0.613 [0.510, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.499, 10.302], loss: 0.001333, mae: 0.039627, mean_q: 1.177950
 480400/1000000: episode: 4804, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.293, mean reward: 0.583 [0.502, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.010, 10.098], loss: 0.001301, mae: 0.039465, mean_q: 1.175861
 480500/1000000: episode: 4805, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.679, mean reward: 0.587 [0.499, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.109, 10.098], loss: 0.001372, mae: 0.040365, mean_q: 1.175421
 480600/1000000: episode: 4806, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 56.555, mean reward: 0.566 [0.498, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.485, 10.128], loss: 0.001381, mae: 0.040175, mean_q: 1.176809
 480700/1000000: episode: 4807, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.330, mean reward: 0.583 [0.505, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.892, 10.268], loss: 0.001360, mae: 0.040526, mean_q: 1.176551
 480800/1000000: episode: 4808, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.374, mean reward: 0.594 [0.498, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.229, 10.313], loss: 0.001389, mae: 0.040781, mean_q: 1.176410
 480900/1000000: episode: 4809, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.176, mean reward: 0.592 [0.512, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.474, 10.098], loss: 0.001505, mae: 0.041962, mean_q: 1.179435
 481000/1000000: episode: 4810, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 63.091, mean reward: 0.631 [0.514, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.118, 10.098], loss: 0.001467, mae: 0.042143, mean_q: 1.180410
 481100/1000000: episode: 4811, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.835, mean reward: 0.598 [0.503, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.446 [-0.805, 10.569], loss: 0.001405, mae: 0.040811, mean_q: 1.174608
 481200/1000000: episode: 4812, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.245, mean reward: 0.592 [0.507, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.291, 10.170], loss: 0.001487, mae: 0.042111, mean_q: 1.177267
 481300/1000000: episode: 4813, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 60.557, mean reward: 0.606 [0.506, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.875, 10.403], loss: 0.001447, mae: 0.041342, mean_q: 1.174153
 481400/1000000: episode: 4814, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.790, mean reward: 0.578 [0.506, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.739, 10.098], loss: 0.001444, mae: 0.041730, mean_q: 1.175449
 481500/1000000: episode: 4815, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.361, mean reward: 0.574 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.618, 10.297], loss: 0.001486, mae: 0.042140, mean_q: 1.174496
 481600/1000000: episode: 4816, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.271, mean reward: 0.583 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.854, 10.098], loss: 0.001373, mae: 0.040553, mean_q: 1.173786
 481700/1000000: episode: 4817, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.533, mean reward: 0.605 [0.510, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.181, 10.098], loss: 0.001423, mae: 0.040988, mean_q: 1.176420
 481800/1000000: episode: 4818, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.106, mean reward: 0.591 [0.503, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.465, 10.098], loss: 0.001482, mae: 0.041804, mean_q: 1.177192
 481900/1000000: episode: 4819, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.340, mean reward: 0.573 [0.512, 0.855], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.540, 10.098], loss: 0.001408, mae: 0.041020, mean_q: 1.176118
 482000/1000000: episode: 4820, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.718, mean reward: 0.577 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.871, 10.147], loss: 0.001356, mae: 0.040869, mean_q: 1.175761
 482100/1000000: episode: 4821, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.567, mean reward: 0.576 [0.503, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.918, 10.098], loss: 0.001348, mae: 0.039953, mean_q: 1.175717
 482200/1000000: episode: 4822, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.760, mean reward: 0.588 [0.499, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.712, 10.098], loss: 0.001535, mae: 0.042617, mean_q: 1.172733
 482300/1000000: episode: 4823, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.698, mean reward: 0.577 [0.510, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.184, 10.146], loss: 0.001430, mae: 0.040969, mean_q: 1.174158
 482400/1000000: episode: 4824, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.173, mean reward: 0.572 [0.503, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.757, 10.170], loss: 0.001437, mae: 0.041313, mean_q: 1.169150
 482500/1000000: episode: 4825, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 61.028, mean reward: 0.610 [0.519, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.735, 10.098], loss: 0.001432, mae: 0.041339, mean_q: 1.170648
 482600/1000000: episode: 4826, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.231, mean reward: 0.592 [0.514, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.559, 10.259], loss: 0.001425, mae: 0.040837, mean_q: 1.168773
 482700/1000000: episode: 4827, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.333, mean reward: 0.583 [0.508, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.645, 10.178], loss: 0.001411, mae: 0.041075, mean_q: 1.171406
 482800/1000000: episode: 4828, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.999, mean reward: 0.600 [0.510, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.487, 10.331], loss: 0.001341, mae: 0.039719, mean_q: 1.165981
 482900/1000000: episode: 4829, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.715, mean reward: 0.587 [0.502, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.008, 10.366], loss: 0.001423, mae: 0.041241, mean_q: 1.168081
 483000/1000000: episode: 4830, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.628, mean reward: 0.606 [0.505, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.007, 10.098], loss: 0.001420, mae: 0.041295, mean_q: 1.167847
 483100/1000000: episode: 4831, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.901, mean reward: 0.599 [0.503, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.953, 10.098], loss: 0.001420, mae: 0.041035, mean_q: 1.171230
 483200/1000000: episode: 4832, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.447, mean reward: 0.584 [0.499, 0.912], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.753, 10.130], loss: 0.001459, mae: 0.041346, mean_q: 1.170844
 483300/1000000: episode: 4833, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.062, mean reward: 0.581 [0.513, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.988, 10.098], loss: 0.001434, mae: 0.040847, mean_q: 1.166540
 483400/1000000: episode: 4834, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.654, mean reward: 0.587 [0.507, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.393, 10.098], loss: 0.001412, mae: 0.040857, mean_q: 1.167774
 483500/1000000: episode: 4835, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.848, mean reward: 0.588 [0.503, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.846, 10.315], loss: 0.001558, mae: 0.042549, mean_q: 1.167961
 483600/1000000: episode: 4836, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.573, mean reward: 0.586 [0.498, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.564, 10.156], loss: 0.001456, mae: 0.041699, mean_q: 1.170701
 483700/1000000: episode: 4837, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 65.077, mean reward: 0.651 [0.514, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.744, 10.098], loss: 0.001528, mae: 0.042654, mean_q: 1.173998
 483800/1000000: episode: 4838, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.675, mean reward: 0.587 [0.503, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.269, 10.129], loss: 0.001452, mae: 0.041233, mean_q: 1.173872
 483900/1000000: episode: 4839, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.713, mean reward: 0.577 [0.505, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.568, 10.271], loss: 0.001570, mae: 0.042764, mean_q: 1.173186
 484000/1000000: episode: 4840, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.229, mean reward: 0.602 [0.509, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.278, 10.163], loss: 0.001587, mae: 0.042664, mean_q: 1.166941
 484100/1000000: episode: 4841, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.144, mean reward: 0.581 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.090, 10.098], loss: 0.001368, mae: 0.039816, mean_q: 1.170040
 484200/1000000: episode: 4842, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.759, mean reward: 0.588 [0.510, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.302, 10.152], loss: 0.001484, mae: 0.041650, mean_q: 1.173334
 484300/1000000: episode: 4843, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 57.819, mean reward: 0.578 [0.508, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.057, 10.098], loss: 0.001503, mae: 0.041626, mean_q: 1.171721
 484400/1000000: episode: 4844, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.467, mean reward: 0.595 [0.510, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.727, 10.108], loss: 0.001442, mae: 0.040409, mean_q: 1.174876
 484500/1000000: episode: 4845, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.750, mean reward: 0.577 [0.497, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.563, 10.098], loss: 0.001445, mae: 0.040787, mean_q: 1.170902
 484600/1000000: episode: 4846, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.858, mean reward: 0.599 [0.504, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.863, 10.098], loss: 0.001468, mae: 0.041160, mean_q: 1.167191
 484700/1000000: episode: 4847, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.914, mean reward: 0.579 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.907, 10.156], loss: 0.001497, mae: 0.042128, mean_q: 1.171542
 484800/1000000: episode: 4848, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 61.490, mean reward: 0.615 [0.512, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.407, 10.328], loss: 0.001513, mae: 0.042486, mean_q: 1.169324
 484900/1000000: episode: 4849, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.687, mean reward: 0.597 [0.503, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.880, 10.299], loss: 0.001533, mae: 0.042598, mean_q: 1.170490
 485000/1000000: episode: 4850, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.798, mean reward: 0.578 [0.500, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.723, 10.098], loss: 0.001446, mae: 0.040366, mean_q: 1.171861
 485100/1000000: episode: 4851, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.505, mean reward: 0.605 [0.509, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.693, 10.149], loss: 0.001417, mae: 0.040275, mean_q: 1.169072
 485200/1000000: episode: 4852, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 56.184, mean reward: 0.562 [0.500, 0.653], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.820, 10.098], loss: 0.001408, mae: 0.040351, mean_q: 1.171008
 485300/1000000: episode: 4853, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.194, mean reward: 0.572 [0.501, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.695, 10.098], loss: 0.001361, mae: 0.040337, mean_q: 1.167477
 485400/1000000: episode: 4854, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.834, mean reward: 0.578 [0.498, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.979, 10.098], loss: 0.001533, mae: 0.042404, mean_q: 1.170822
 485500/1000000: episode: 4855, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.787, mean reward: 0.598 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.511, 10.098], loss: 0.001575, mae: 0.042082, mean_q: 1.167595
 485600/1000000: episode: 4856, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.614, mean reward: 0.586 [0.509, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.444, 10.142], loss: 0.001475, mae: 0.041549, mean_q: 1.166240
 485700/1000000: episode: 4857, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.551, mean reward: 0.596 [0.505, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.841, 10.098], loss: 0.001506, mae: 0.041512, mean_q: 1.168447
 485800/1000000: episode: 4858, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.391, mean reward: 0.584 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.718, 10.163], loss: 0.001470, mae: 0.041675, mean_q: 1.173385
 485900/1000000: episode: 4859, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 57.318, mean reward: 0.573 [0.500, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.431, 10.098], loss: 0.001368, mae: 0.039761, mean_q: 1.169150
 486000/1000000: episode: 4860, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.262, mean reward: 0.593 [0.502, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.867, 10.098], loss: 0.001428, mae: 0.040673, mean_q: 1.164787
 486100/1000000: episode: 4861, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.914, mean reward: 0.589 [0.499, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.189, 10.098], loss: 0.001379, mae: 0.040228, mean_q: 1.161591
 486200/1000000: episode: 4862, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.861, mean reward: 0.589 [0.501, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.202, 10.256], loss: 0.001537, mae: 0.042355, mean_q: 1.167469
 486300/1000000: episode: 4863, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.395, mean reward: 0.574 [0.502, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.593, 10.124], loss: 0.001479, mae: 0.041485, mean_q: 1.164293
 486400/1000000: episode: 4864, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.399, mean reward: 0.604 [0.504, 0.886], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.153, 10.157], loss: 0.001297, mae: 0.039257, mean_q: 1.160720
 486500/1000000: episode: 4865, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.281, mean reward: 0.573 [0.498, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.785, 10.098], loss: 0.001473, mae: 0.041722, mean_q: 1.165810
 486600/1000000: episode: 4866, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 56.786, mean reward: 0.568 [0.503, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.406, 10.098], loss: 0.001428, mae: 0.040448, mean_q: 1.164986
 486700/1000000: episode: 4867, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.251, mean reward: 0.573 [0.502, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.568, 10.098], loss: 0.001373, mae: 0.040513, mean_q: 1.161914
 486800/1000000: episode: 4868, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.319, mean reward: 0.593 [0.509, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.179, 10.098], loss: 0.001362, mae: 0.039878, mean_q: 1.163637
 486900/1000000: episode: 4869, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.743, mean reward: 0.577 [0.504, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.035, 10.195], loss: 0.001464, mae: 0.041901, mean_q: 1.166125
 487000/1000000: episode: 4870, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.955, mean reward: 0.590 [0.517, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.316, 10.098], loss: 0.001426, mae: 0.041217, mean_q: 1.163028
 487100/1000000: episode: 4871, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.647, mean reward: 0.586 [0.508, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.299, 10.272], loss: 0.001401, mae: 0.040733, mean_q: 1.164919
 487200/1000000: episode: 4872, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.267, mean reward: 0.583 [0.500, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.232, 10.334], loss: 0.001374, mae: 0.040591, mean_q: 1.165687
 487300/1000000: episode: 4873, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.634, mean reward: 0.596 [0.500, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.460, 10.500], loss: 0.001439, mae: 0.040913, mean_q: 1.166147
 487400/1000000: episode: 4874, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.551, mean reward: 0.586 [0.504, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.418, 10.098], loss: 0.001361, mae: 0.040092, mean_q: 1.163663
 487500/1000000: episode: 4875, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.950, mean reward: 0.600 [0.502, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.494, 10.236], loss: 0.001430, mae: 0.041088, mean_q: 1.165524
 487600/1000000: episode: 4876, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.917, mean reward: 0.579 [0.505, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.394, 10.146], loss: 0.001413, mae: 0.041139, mean_q: 1.165759
 487700/1000000: episode: 4877, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.505, mean reward: 0.615 [0.507, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.718, 10.267], loss: 0.001378, mae: 0.040516, mean_q: 1.162073
 487800/1000000: episode: 4878, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 56.912, mean reward: 0.569 [0.506, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.758, 10.160], loss: 0.001433, mae: 0.041155, mean_q: 1.166296
 487900/1000000: episode: 4879, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.225, mean reward: 0.572 [0.505, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.212, 10.101], loss: 0.001383, mae: 0.040772, mean_q: 1.166126
 488000/1000000: episode: 4880, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.204, mean reward: 0.582 [0.503, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.495, 10.098], loss: 0.001320, mae: 0.039941, mean_q: 1.162136
 488100/1000000: episode: 4881, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 56.284, mean reward: 0.563 [0.507, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.273, 10.138], loss: 0.001219, mae: 0.038125, mean_q: 1.160420
 488200/1000000: episode: 4882, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.523, mean reward: 0.575 [0.505, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.528, 10.098], loss: 0.001233, mae: 0.038281, mean_q: 1.155614
 488300/1000000: episode: 4883, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 59.833, mean reward: 0.598 [0.506, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.182, 10.098], loss: 0.001362, mae: 0.040418, mean_q: 1.160600
 488400/1000000: episode: 4884, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.242, mean reward: 0.582 [0.512, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.350, 10.299], loss: 0.001312, mae: 0.039161, mean_q: 1.163289
 488500/1000000: episode: 4885, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.500, mean reward: 0.585 [0.502, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.177, 10.152], loss: 0.001320, mae: 0.039830, mean_q: 1.161997
 488600/1000000: episode: 4886, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 57.924, mean reward: 0.579 [0.507, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.296, 10.098], loss: 0.001343, mae: 0.040242, mean_q: 1.162256
 488700/1000000: episode: 4887, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.826, mean reward: 0.578 [0.506, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.219, 10.098], loss: 0.001261, mae: 0.039159, mean_q: 1.158038
 488800/1000000: episode: 4888, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 56.547, mean reward: 0.565 [0.503, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.830, 10.126], loss: 0.001322, mae: 0.039700, mean_q: 1.158345
 488900/1000000: episode: 4889, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.017, mean reward: 0.590 [0.506, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.610, 10.098], loss: 0.001390, mae: 0.040538, mean_q: 1.158782
 489000/1000000: episode: 4890, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.840, mean reward: 0.598 [0.503, 0.843], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.754, 10.222], loss: 0.001322, mae: 0.039683, mean_q: 1.157542
 489100/1000000: episode: 4891, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.084, mean reward: 0.571 [0.501, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.784, 10.239], loss: 0.001343, mae: 0.039712, mean_q: 1.156807
 489200/1000000: episode: 4892, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.448, mean reward: 0.614 [0.506, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.230, 10.098], loss: 0.001303, mae: 0.039269, mean_q: 1.156545
 489300/1000000: episode: 4893, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.518, mean reward: 0.605 [0.506, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.561, 10.098], loss: 0.001275, mae: 0.039642, mean_q: 1.159184
 489400/1000000: episode: 4894, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.536, mean reward: 0.575 [0.500, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.837, 10.164], loss: 0.001388, mae: 0.040520, mean_q: 1.159992
 489500/1000000: episode: 4895, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.856, mean reward: 0.589 [0.512, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.242, 10.098], loss: 0.001344, mae: 0.039361, mean_q: 1.157139
 489600/1000000: episode: 4896, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 62.426, mean reward: 0.624 [0.511, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.125, 10.342], loss: 0.001428, mae: 0.040372, mean_q: 1.157455
 489700/1000000: episode: 4897, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.231, mean reward: 0.592 [0.508, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.948, 10.272], loss: 0.001426, mae: 0.041128, mean_q: 1.159423
 489800/1000000: episode: 4898, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.203, mean reward: 0.572 [0.505, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.237, 10.228], loss: 0.001466, mae: 0.041520, mean_q: 1.160498
 489900/1000000: episode: 4899, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.436, mean reward: 0.594 [0.505, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.799, 10.098], loss: 0.001391, mae: 0.040323, mean_q: 1.157283
 490000/1000000: episode: 4900, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 63.071, mean reward: 0.631 [0.499, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.597, 10.514], loss: 0.001413, mae: 0.040996, mean_q: 1.163078
 490100/1000000: episode: 4901, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.748, mean reward: 0.577 [0.506, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.115, 10.133], loss: 0.001430, mae: 0.041022, mean_q: 1.158561
 490200/1000000: episode: 4902, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.776, mean reward: 0.598 [0.504, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.977, 10.098], loss: 0.001314, mae: 0.039738, mean_q: 1.159534
 490300/1000000: episode: 4903, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.802, mean reward: 0.598 [0.500, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.829, 10.098], loss: 0.001330, mae: 0.039936, mean_q: 1.162063
 490400/1000000: episode: 4904, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.219, mean reward: 0.572 [0.508, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.879, 10.098], loss: 0.001397, mae: 0.040383, mean_q: 1.159005
 490500/1000000: episode: 4905, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.002, mean reward: 0.590 [0.503, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-0.357, 10.098], loss: 0.001605, mae: 0.043397, mean_q: 1.159740
 490600/1000000: episode: 4906, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.265, mean reward: 0.603 [0.514, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.325, 10.155], loss: 0.001402, mae: 0.040664, mean_q: 1.162071
 490700/1000000: episode: 4907, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 57.676, mean reward: 0.577 [0.509, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.343, 10.225], loss: 0.001510, mae: 0.041812, mean_q: 1.164721
 490800/1000000: episode: 4908, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.026, mean reward: 0.570 [0.499, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.626, 10.216], loss: 0.001545, mae: 0.042622, mean_q: 1.161492
 490900/1000000: episode: 4909, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.348, mean reward: 0.593 [0.509, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.468, 10.242], loss: 0.001425, mae: 0.041417, mean_q: 1.162287
 491000/1000000: episode: 4910, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.942, mean reward: 0.579 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.445 [-0.224, 10.420], loss: 0.001509, mae: 0.041867, mean_q: 1.162164
 491100/1000000: episode: 4911, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.181, mean reward: 0.592 [0.501, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.772, 10.412], loss: 0.001625, mae: 0.043513, mean_q: 1.161320
 491200/1000000: episode: 4912, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.573, mean reward: 0.586 [0.503, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.833, 10.098], loss: 0.001471, mae: 0.041643, mean_q: 1.162201
 491300/1000000: episode: 4913, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.094, mean reward: 0.581 [0.501, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.227, 10.098], loss: 0.001348, mae: 0.039707, mean_q: 1.160887
 491400/1000000: episode: 4914, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.144, mean reward: 0.581 [0.508, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.621, 10.098], loss: 0.001486, mae: 0.041510, mean_q: 1.162610
 491500/1000000: episode: 4915, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.333, mean reward: 0.583 [0.508, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.292, 10.098], loss: 0.001533, mae: 0.041734, mean_q: 1.162220
 491600/1000000: episode: 4916, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.923, mean reward: 0.589 [0.506, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.216, 10.098], loss: 0.001546, mae: 0.042814, mean_q: 1.161852
 491700/1000000: episode: 4917, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.191, mean reward: 0.602 [0.508, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.170, 10.169], loss: 0.001510, mae: 0.041698, mean_q: 1.164708
 491800/1000000: episode: 4918, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.643, mean reward: 0.586 [0.507, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.537, 10.129], loss: 0.001501, mae: 0.041686, mean_q: 1.162468
 491900/1000000: episode: 4919, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.736, mean reward: 0.587 [0.498, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.763, 10.098], loss: 0.001448, mae: 0.041367, mean_q: 1.161233
 492000/1000000: episode: 4920, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.854, mean reward: 0.579 [0.510, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.229, 10.222], loss: 0.001603, mae: 0.042834, mean_q: 1.164209
 492100/1000000: episode: 4921, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.096, mean reward: 0.601 [0.500, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.413, 10.098], loss: 0.001506, mae: 0.042382, mean_q: 1.162544
 492200/1000000: episode: 4922, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.305, mean reward: 0.603 [0.506, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.634, 10.211], loss: 0.001530, mae: 0.042108, mean_q: 1.163937
 492300/1000000: episode: 4923, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.121, mean reward: 0.591 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.687, 10.098], loss: 0.001463, mae: 0.041386, mean_q: 1.162907
 492400/1000000: episode: 4924, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.069, mean reward: 0.601 [0.500, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.984, 10.343], loss: 0.001489, mae: 0.042064, mean_q: 1.164551
 492500/1000000: episode: 4925, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.384, mean reward: 0.604 [0.504, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.606, 10.143], loss: 0.001411, mae: 0.040707, mean_q: 1.163456
 492600/1000000: episode: 4926, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.005, mean reward: 0.590 [0.509, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.918, 10.105], loss: 0.001542, mae: 0.042516, mean_q: 1.167070
 492700/1000000: episode: 4927, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.624, mean reward: 0.576 [0.501, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.818, 10.101], loss: 0.001435, mae: 0.040906, mean_q: 1.161852
 492800/1000000: episode: 4928, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.602, mean reward: 0.596 [0.516, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.878, 10.276], loss: 0.001559, mae: 0.042281, mean_q: 1.163636
 492900/1000000: episode: 4929, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 61.179, mean reward: 0.612 [0.515, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.498, 10.098], loss: 0.001636, mae: 0.043576, mean_q: 1.166069
 493000/1000000: episode: 4930, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.736, mean reward: 0.587 [0.508, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.205, 10.225], loss: 0.001537, mae: 0.042342, mean_q: 1.168826
 493100/1000000: episode: 4931, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.708, mean reward: 0.617 [0.506, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.523, 10.329], loss: 0.001504, mae: 0.041644, mean_q: 1.165508
 493200/1000000: episode: 4932, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.907, mean reward: 0.569 [0.505, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.637, 10.098], loss: 0.001672, mae: 0.043970, mean_q: 1.168835
 493300/1000000: episode: 4933, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.437, mean reward: 0.594 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.711, 10.233], loss: 0.001568, mae: 0.042200, mean_q: 1.167316
 493400/1000000: episode: 4934, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.613, mean reward: 0.596 [0.511, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.568, 10.098], loss: 0.001675, mae: 0.043960, mean_q: 1.170782
 493500/1000000: episode: 4935, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.079, mean reward: 0.591 [0.499, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-2.251, 10.120], loss: 0.001705, mae: 0.043469, mean_q: 1.169156
 493600/1000000: episode: 4936, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 59.615, mean reward: 0.596 [0.503, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.623, 10.253], loss: 0.001540, mae: 0.042115, mean_q: 1.167038
 493700/1000000: episode: 4937, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.698, mean reward: 0.587 [0.503, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.321, 10.114], loss: 0.001513, mae: 0.041652, mean_q: 1.167559
 493800/1000000: episode: 4938, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.122, mean reward: 0.581 [0.506, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.712, 10.098], loss: 0.001691, mae: 0.044045, mean_q: 1.169018
 493900/1000000: episode: 4939, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.918, mean reward: 0.609 [0.502, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.254, 10.098], loss: 0.001485, mae: 0.042439, mean_q: 1.173592
 494000/1000000: episode: 4940, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.208, mean reward: 0.592 [0.517, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.354, 10.164], loss: 0.001640, mae: 0.043096, mean_q: 1.173798
 494100/1000000: episode: 4941, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.812, mean reward: 0.588 [0.503, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.830, 10.098], loss: 0.001628, mae: 0.043900, mean_q: 1.170602
 494200/1000000: episode: 4942, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 58.915, mean reward: 0.589 [0.507, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.701, 10.298], loss: 0.001566, mae: 0.042301, mean_q: 1.167713
 494300/1000000: episode: 4943, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.615, mean reward: 0.586 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.204, 10.098], loss: 0.001515, mae: 0.042139, mean_q: 1.172214
 494400/1000000: episode: 4944, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.984, mean reward: 0.580 [0.498, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.362, 10.199], loss: 0.001571, mae: 0.042560, mean_q: 1.168310
 494500/1000000: episode: 4945, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.399, mean reward: 0.564 [0.503, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.655, 10.138], loss: 0.001486, mae: 0.041580, mean_q: 1.170467
 494600/1000000: episode: 4946, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.123, mean reward: 0.581 [0.513, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.180, 10.207], loss: 0.001572, mae: 0.042508, mean_q: 1.170443
 494700/1000000: episode: 4947, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.963, mean reward: 0.580 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.902, 10.139], loss: 0.001568, mae: 0.042703, mean_q: 1.168542
 494800/1000000: episode: 4948, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.872, mean reward: 0.579 [0.498, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.116, 10.098], loss: 0.001476, mae: 0.041899, mean_q: 1.170335
 494900/1000000: episode: 4949, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.286, mean reward: 0.583 [0.505, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.182, 10.098], loss: 0.001517, mae: 0.042306, mean_q: 1.168490
 495000/1000000: episode: 4950, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.400, mean reward: 0.594 [0.506, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.655, 10.200], loss: 0.001509, mae: 0.041949, mean_q: 1.165007
 495100/1000000: episode: 4951, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 62.675, mean reward: 0.627 [0.508, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.012, 10.098], loss: 0.001529, mae: 0.042417, mean_q: 1.166645
 495200/1000000: episode: 4952, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 65.091, mean reward: 0.651 [0.506, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.708, 10.539], loss: 0.001506, mae: 0.042012, mean_q: 1.168188
 495300/1000000: episode: 4953, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.987, mean reward: 0.590 [0.509, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.063, 10.098], loss: 0.001527, mae: 0.042433, mean_q: 1.170927
 495400/1000000: episode: 4954, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.645, mean reward: 0.596 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.667, 10.199], loss: 0.001489, mae: 0.041809, mean_q: 1.170773
 495500/1000000: episode: 4955, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.062, mean reward: 0.571 [0.501, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.283, 10.153], loss: 0.001450, mae: 0.041367, mean_q: 1.167793
 495600/1000000: episode: 4956, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.340, mean reward: 0.583 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.204, 10.098], loss: 0.001515, mae: 0.041651, mean_q: 1.171205
 495700/1000000: episode: 4957, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.392, mean reward: 0.594 [0.504, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.112, 10.154], loss: 0.001444, mae: 0.041156, mean_q: 1.172221
 495800/1000000: episode: 4958, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.486, mean reward: 0.575 [0.505, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.617, 10.098], loss: 0.001398, mae: 0.040760, mean_q: 1.169172
 495900/1000000: episode: 4959, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.171, mean reward: 0.572 [0.504, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.236, 10.185], loss: 0.001465, mae: 0.041652, mean_q: 1.170341
 496000/1000000: episode: 4960, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.690, mean reward: 0.587 [0.503, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.044, 10.098], loss: 0.001380, mae: 0.039999, mean_q: 1.169341
 496100/1000000: episode: 4961, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.662, mean reward: 0.587 [0.505, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.115, 10.098], loss: 0.001421, mae: 0.040639, mean_q: 1.168878
 496200/1000000: episode: 4962, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.007, mean reward: 0.570 [0.506, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.407, 10.228], loss: 0.001501, mae: 0.042497, mean_q: 1.168760
 496300/1000000: episode: 4963, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.123, mean reward: 0.611 [0.514, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.670, 10.277], loss: 0.001470, mae: 0.042123, mean_q: 1.170203
 496400/1000000: episode: 4964, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 60.553, mean reward: 0.606 [0.502, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.948, 10.098], loss: 0.001479, mae: 0.041775, mean_q: 1.169048
 496500/1000000: episode: 4965, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.976, mean reward: 0.580 [0.511, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.948, 10.098], loss: 0.001477, mae: 0.042177, mean_q: 1.167648
 496600/1000000: episode: 4966, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.061, mean reward: 0.571 [0.505, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.811, 10.098], loss: 0.001441, mae: 0.041202, mean_q: 1.168225
 496700/1000000: episode: 4967, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.808, mean reward: 0.588 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.705, 10.098], loss: 0.001453, mae: 0.041539, mean_q: 1.169316
 496800/1000000: episode: 4968, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.743, mean reward: 0.587 [0.502, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.041, 10.102], loss: 0.001524, mae: 0.043113, mean_q: 1.168614
 496900/1000000: episode: 4969, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.891, mean reward: 0.579 [0.505, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.999, 10.098], loss: 0.001511, mae: 0.043127, mean_q: 1.166774
 497000/1000000: episode: 4970, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.341, mean reward: 0.573 [0.498, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.921, 10.161], loss: 0.001386, mae: 0.040774, mean_q: 1.167518
 497100/1000000: episode: 4971, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.145, mean reward: 0.581 [0.509, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.287, 10.098], loss: 0.001628, mae: 0.044448, mean_q: 1.170839
 497200/1000000: episode: 4972, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.578, mean reward: 0.576 [0.500, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.853, 10.218], loss: 0.001563, mae: 0.043774, mean_q: 1.168676
 497300/1000000: episode: 4973, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.562, mean reward: 0.596 [0.506, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.413, 10.145], loss: 0.001530, mae: 0.043233, mean_q: 1.169539
 497400/1000000: episode: 4974, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.424, mean reward: 0.584 [0.502, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-2.077, 10.098], loss: 0.001611, mae: 0.043806, mean_q: 1.169836
 497500/1000000: episode: 4975, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.957, mean reward: 0.580 [0.499, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.859, 10.158], loss: 0.001447, mae: 0.041637, mean_q: 1.165470
 497600/1000000: episode: 4976, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.511, mean reward: 0.575 [0.498, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.693, 10.098], loss: 0.001364, mae: 0.040797, mean_q: 1.165629
 497700/1000000: episode: 4977, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.384, mean reward: 0.574 [0.503, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.419, 10.098], loss: 0.001506, mae: 0.042504, mean_q: 1.162272
 497800/1000000: episode: 4978, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.512, mean reward: 0.595 [0.510, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.562, 10.318], loss: 0.001468, mae: 0.042029, mean_q: 1.164651
 497900/1000000: episode: 4979, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.611, mean reward: 0.576 [0.506, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.875, 10.098], loss: 0.001525, mae: 0.042739, mean_q: 1.163170
 498000/1000000: episode: 4980, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 57.639, mean reward: 0.576 [0.503, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.802, 10.098], loss: 0.001598, mae: 0.043701, mean_q: 1.161777
 498100/1000000: episode: 4981, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.881, mean reward: 0.589 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.008, 10.098], loss: 0.001482, mae: 0.042549, mean_q: 1.159358
 498200/1000000: episode: 4982, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.625, mean reward: 0.586 [0.498, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.683, 10.098], loss: 0.001429, mae: 0.041950, mean_q: 1.162451
 498300/1000000: episode: 4983, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.127, mean reward: 0.571 [0.499, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.183, 10.163], loss: 0.001497, mae: 0.042558, mean_q: 1.158995
 498400/1000000: episode: 4984, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.610, mean reward: 0.576 [0.504, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.790, 10.109], loss: 0.001425, mae: 0.041505, mean_q: 1.159448
 498500/1000000: episode: 4985, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 62.271, mean reward: 0.623 [0.509, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.266, 10.229], loss: 0.001438, mae: 0.041584, mean_q: 1.160658
 498600/1000000: episode: 4986, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.762, mean reward: 0.598 [0.499, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.813, 10.098], loss: 0.001408, mae: 0.041228, mean_q: 1.159701
 498700/1000000: episode: 4987, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.921, mean reward: 0.589 [0.508, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.132, 10.098], loss: 0.001419, mae: 0.041461, mean_q: 1.157881
 498800/1000000: episode: 4988, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.224, mean reward: 0.592 [0.514, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.955, 10.177], loss: 0.001476, mae: 0.042222, mean_q: 1.161081
 498900/1000000: episode: 4989, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.790, mean reward: 0.598 [0.506, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.039, 10.246], loss: 0.001487, mae: 0.042957, mean_q: 1.162546
 499000/1000000: episode: 4990, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.751, mean reward: 0.588 [0.503, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.168, 10.165], loss: 0.001395, mae: 0.040988, mean_q: 1.159393
 499100/1000000: episode: 4991, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.833, mean reward: 0.578 [0.503, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.728, 10.098], loss: 0.001443, mae: 0.042157, mean_q: 1.158756
 499200/1000000: episode: 4992, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.014, mean reward: 0.590 [0.507, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.943, 10.098], loss: 0.001507, mae: 0.042779, mean_q: 1.160443
 499300/1000000: episode: 4993, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.014, mean reward: 0.590 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.804, 10.098], loss: 0.001369, mae: 0.040994, mean_q: 1.161016
 499400/1000000: episode: 4994, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.930, mean reward: 0.579 [0.521, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.783, 10.098], loss: 0.001508, mae: 0.042587, mean_q: 1.163272
 499500/1000000: episode: 4995, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.211, mean reward: 0.602 [0.506, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.542, 10.098], loss: 0.001515, mae: 0.042694, mean_q: 1.161474
 499600/1000000: episode: 4996, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.293, mean reward: 0.593 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.525, 10.098], loss: 0.001446, mae: 0.041322, mean_q: 1.162843
 499700/1000000: episode: 4997, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.780, mean reward: 0.578 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.687, 10.098], loss: 0.001419, mae: 0.041563, mean_q: 1.163086
 499800/1000000: episode: 4998, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.903, mean reward: 0.599 [0.502, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.490, 10.098], loss: 0.001534, mae: 0.043268, mean_q: 1.163694
 499900/1000000: episode: 4999, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.857, mean reward: 0.599 [0.501, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.728, 10.098], loss: 0.001418, mae: 0.041124, mean_q: 1.162603
 500000/1000000: episode: 5000, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.595, mean reward: 0.576 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.526, 10.258], loss: 0.001485, mae: 0.041466, mean_q: 1.158779
 500100/1000000: episode: 5001, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.994, mean reward: 0.590 [0.511, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.885, 10.436], loss: 0.001440, mae: 0.041146, mean_q: 1.160668
 500200/1000000: episode: 5002, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.232, mean reward: 0.582 [0.501, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.357, 10.098], loss: 0.001491, mae: 0.042048, mean_q: 1.159742
 500300/1000000: episode: 5003, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.513, mean reward: 0.605 [0.504, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.092, 10.309], loss: 0.001389, mae: 0.041234, mean_q: 1.162793
 500400/1000000: episode: 5004, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.824, mean reward: 0.588 [0.501, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.095, 10.098], loss: 0.001510, mae: 0.042636, mean_q: 1.155982
 500500/1000000: episode: 5005, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.508, mean reward: 0.575 [0.505, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.865, 10.118], loss: 0.001478, mae: 0.042080, mean_q: 1.160684
 500600/1000000: episode: 5006, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.976, mean reward: 0.610 [0.517, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.460, 10.187], loss: 0.001373, mae: 0.040544, mean_q: 1.159896
 500700/1000000: episode: 5007, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.192, mean reward: 0.572 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.259, 10.227], loss: 0.001472, mae: 0.042138, mean_q: 1.159260
 500800/1000000: episode: 5008, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.625, mean reward: 0.596 [0.507, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.556, 10.163], loss: 0.001374, mae: 0.040953, mean_q: 1.160347
 500900/1000000: episode: 5009, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.196, mean reward: 0.592 [0.511, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.455, 10.098], loss: 0.001492, mae: 0.042559, mean_q: 1.163747
 501000/1000000: episode: 5010, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.913, mean reward: 0.609 [0.511, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.847, 10.293], loss: 0.001447, mae: 0.041668, mean_q: 1.162306
 501100/1000000: episode: 5011, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.445, mean reward: 0.574 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.031, 10.098], loss: 0.001470, mae: 0.041914, mean_q: 1.161291
 501200/1000000: episode: 5012, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.946, mean reward: 0.589 [0.509, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.482, 10.114], loss: 0.001580, mae: 0.043120, mean_q: 1.163501
 501300/1000000: episode: 5013, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.747, mean reward: 0.587 [0.510, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.032, 10.098], loss: 0.001438, mae: 0.041665, mean_q: 1.164164
 501400/1000000: episode: 5014, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.045, mean reward: 0.600 [0.510, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.789, 10.098], loss: 0.001381, mae: 0.040503, mean_q: 1.159990
 501500/1000000: episode: 5015, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.063, mean reward: 0.581 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.600, 10.123], loss: 0.001431, mae: 0.041242, mean_q: 1.161020
 501600/1000000: episode: 5016, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.799, mean reward: 0.588 [0.498, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.885, 10.098], loss: 0.001513, mae: 0.041764, mean_q: 1.160437
 501700/1000000: episode: 5017, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.479, mean reward: 0.615 [0.515, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.539, 10.227], loss: 0.001373, mae: 0.041046, mean_q: 1.157637
 501800/1000000: episode: 5018, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.443, mean reward: 0.594 [0.500, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.235, 10.098], loss: 0.001475, mae: 0.041548, mean_q: 1.160517
 501900/1000000: episode: 5019, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 62.186, mean reward: 0.622 [0.507, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.379, 10.233], loss: 0.001435, mae: 0.041470, mean_q: 1.163655
 502000/1000000: episode: 5020, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.496, mean reward: 0.575 [0.502, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.918, 10.098], loss: 0.001470, mae: 0.041520, mean_q: 1.164316
 502100/1000000: episode: 5021, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 61.471, mean reward: 0.615 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.643, 10.343], loss: 0.001442, mae: 0.041393, mean_q: 1.163913
 502200/1000000: episode: 5022, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.743, mean reward: 0.577 [0.497, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.697, 10.098], loss: 0.001400, mae: 0.041164, mean_q: 1.166696
 502300/1000000: episode: 5023, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.395, mean reward: 0.594 [0.523, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.878, 10.300], loss: 0.001400, mae: 0.040756, mean_q: 1.164669
 502400/1000000: episode: 5024, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.750, mean reward: 0.577 [0.507, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.035, 10.242], loss: 0.001345, mae: 0.040199, mean_q: 1.165391
 502500/1000000: episode: 5025, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.577, mean reward: 0.576 [0.504, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.566, 10.098], loss: 0.001427, mae: 0.041549, mean_q: 1.164884
 502600/1000000: episode: 5026, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.996, mean reward: 0.600 [0.513, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.188, 10.098], loss: 0.001370, mae: 0.040351, mean_q: 1.164981
 502700/1000000: episode: 5027, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.722, mean reward: 0.617 [0.516, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.140, 10.098], loss: 0.001417, mae: 0.041528, mean_q: 1.168011
 502800/1000000: episode: 5028, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 57.688, mean reward: 0.577 [0.499, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.266, 10.098], loss: 0.001445, mae: 0.041691, mean_q: 1.168693
 502900/1000000: episode: 5029, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.696, mean reward: 0.577 [0.499, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.789, 10.233], loss: 0.001492, mae: 0.042566, mean_q: 1.168427
 503000/1000000: episode: 5030, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.719, mean reward: 0.597 [0.499, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.273, 10.305], loss: 0.001380, mae: 0.040685, mean_q: 1.167838
 503100/1000000: episode: 5031, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.043, mean reward: 0.580 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.532, 10.123], loss: 0.001362, mae: 0.040749, mean_q: 1.168204
 503200/1000000: episode: 5032, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 63.965, mean reward: 0.640 [0.518, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.372, 10.288], loss: 0.001444, mae: 0.041088, mean_q: 1.169983
 503300/1000000: episode: 5033, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 56.708, mean reward: 0.567 [0.502, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.556, 10.199], loss: 0.001411, mae: 0.041388, mean_q: 1.170529
 503400/1000000: episode: 5034, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.074, mean reward: 0.581 [0.511, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.139, 10.098], loss: 0.001471, mae: 0.041995, mean_q: 1.174111
 503500/1000000: episode: 5035, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.224, mean reward: 0.592 [0.505, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.292, 10.175], loss: 0.001485, mae: 0.042054, mean_q: 1.172187
 503600/1000000: episode: 5036, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.057, mean reward: 0.591 [0.524, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.646, 10.098], loss: 0.001407, mae: 0.040770, mean_q: 1.168446
 503700/1000000: episode: 5037, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.823, mean reward: 0.598 [0.510, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.806, 10.122], loss: 0.001328, mae: 0.040107, mean_q: 1.168526
 503800/1000000: episode: 5038, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.493, mean reward: 0.585 [0.500, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.619, 10.098], loss: 0.001375, mae: 0.040624, mean_q: 1.167942
 503900/1000000: episode: 5039, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.682, mean reward: 0.577 [0.506, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.271, 10.098], loss: 0.001402, mae: 0.041373, mean_q: 1.169812
 504000/1000000: episode: 5040, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.566, mean reward: 0.606 [0.510, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.528, 10.098], loss: 0.001412, mae: 0.041421, mean_q: 1.171807
 504100/1000000: episode: 5041, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.534, mean reward: 0.595 [0.510, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.828, 10.098], loss: 0.001381, mae: 0.040613, mean_q: 1.172587
 504200/1000000: episode: 5042, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.135, mean reward: 0.601 [0.520, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.175, 10.260], loss: 0.001336, mae: 0.040210, mean_q: 1.174192
 504300/1000000: episode: 5043, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.629, mean reward: 0.576 [0.501, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.463, 10.098], loss: 0.001533, mae: 0.042832, mean_q: 1.171203
 504400/1000000: episode: 5044, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 58.110, mean reward: 0.581 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.395, 10.098], loss: 0.001407, mae: 0.041607, mean_q: 1.170602
 504500/1000000: episode: 5045, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 60.811, mean reward: 0.608 [0.512, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.045, 10.356], loss: 0.001408, mae: 0.040985, mean_q: 1.170443
 504600/1000000: episode: 5046, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.045, mean reward: 0.590 [0.509, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.835, 10.225], loss: 0.001397, mae: 0.040956, mean_q: 1.169198
 504700/1000000: episode: 5047, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.238, mean reward: 0.582 [0.510, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.142, 10.098], loss: 0.001364, mae: 0.040296, mean_q: 1.173690
 504800/1000000: episode: 5048, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.927, mean reward: 0.589 [0.510, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.253, 10.223], loss: 0.001424, mae: 0.041005, mean_q: 1.168866
 504900/1000000: episode: 5049, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.981, mean reward: 0.570 [0.501, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.874, 10.140], loss: 0.001421, mae: 0.040822, mean_q: 1.169457
 505000/1000000: episode: 5050, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.278, mean reward: 0.593 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.419, 10.105], loss: 0.001441, mae: 0.041498, mean_q: 1.172830
 505100/1000000: episode: 5051, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.975, mean reward: 0.590 [0.499, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.258, 10.098], loss: 0.001462, mae: 0.041692, mean_q: 1.171305
 505200/1000000: episode: 5052, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.301, mean reward: 0.573 [0.503, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.180, 10.098], loss: 0.001433, mae: 0.041267, mean_q: 1.169856
 505300/1000000: episode: 5053, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.374, mean reward: 0.584 [0.504, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.317, 10.268], loss: 0.001336, mae: 0.039818, mean_q: 1.166063
 505400/1000000: episode: 5054, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.631, mean reward: 0.596 [0.509, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.761, 10.098], loss: 0.001447, mae: 0.041332, mean_q: 1.164904
 505500/1000000: episode: 5055, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.993, mean reward: 0.580 [0.507, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.537, 10.174], loss: 0.001411, mae: 0.040861, mean_q: 1.167418
 505600/1000000: episode: 5056, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 57.474, mean reward: 0.575 [0.501, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.938, 10.098], loss: 0.001493, mae: 0.042283, mean_q: 1.165917
 505700/1000000: episode: 5057, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 56.557, mean reward: 0.566 [0.499, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.301, 10.122], loss: 0.001414, mae: 0.040988, mean_q: 1.166144
 505800/1000000: episode: 5058, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.314, mean reward: 0.603 [0.526, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.834, 10.098], loss: 0.001496, mae: 0.042371, mean_q: 1.169218
 505900/1000000: episode: 5059, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 63.377, mean reward: 0.634 [0.528, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.583, 10.098], loss: 0.001399, mae: 0.040697, mean_q: 1.169238
 506000/1000000: episode: 5060, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.069, mean reward: 0.601 [0.503, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.219, 10.098], loss: 0.001433, mae: 0.041879, mean_q: 1.169684
 506100/1000000: episode: 5061, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.273, mean reward: 0.593 [0.501, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.300, 10.300], loss: 0.001426, mae: 0.041626, mean_q: 1.168012
 506200/1000000: episode: 5062, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.586, mean reward: 0.606 [0.517, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.844, 10.098], loss: 0.001455, mae: 0.041808, mean_q: 1.172401
 506300/1000000: episode: 5063, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.070, mean reward: 0.591 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.726, 10.191], loss: 0.001403, mae: 0.041379, mean_q: 1.170218
 506400/1000000: episode: 5064, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.703, mean reward: 0.587 [0.503, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.632, 10.098], loss: 0.001427, mae: 0.040850, mean_q: 1.170420
 506500/1000000: episode: 5065, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.321, mean reward: 0.573 [0.509, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.805, 10.206], loss: 0.001379, mae: 0.040650, mean_q: 1.172565
 506600/1000000: episode: 5066, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.136, mean reward: 0.581 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.755, 10.098], loss: 0.001494, mae: 0.041589, mean_q: 1.173114
 506700/1000000: episode: 5067, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.989, mean reward: 0.580 [0.501, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.708, 10.099], loss: 0.001452, mae: 0.041268, mean_q: 1.168993
 506800/1000000: episode: 5068, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.762, mean reward: 0.588 [0.510, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.857, 10.318], loss: 0.001472, mae: 0.041420, mean_q: 1.168611
 506900/1000000: episode: 5069, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.722, mean reward: 0.577 [0.501, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.594, 10.098], loss: 0.001329, mae: 0.039448, mean_q: 1.168247
 507000/1000000: episode: 5070, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.536, mean reward: 0.585 [0.501, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.947, 10.153], loss: 0.001407, mae: 0.040614, mean_q: 1.169060
 507100/1000000: episode: 5071, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 57.879, mean reward: 0.579 [0.502, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.716, 10.098], loss: 0.001445, mae: 0.041283, mean_q: 1.166942
 507200/1000000: episode: 5072, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.421, mean reward: 0.594 [0.498, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.675, 10.098], loss: 0.001476, mae: 0.041749, mean_q: 1.166961
 507300/1000000: episode: 5073, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.022, mean reward: 0.580 [0.505, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.928, 10.160], loss: 0.001420, mae: 0.040860, mean_q: 1.165701
 507400/1000000: episode: 5074, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.668, mean reward: 0.587 [0.511, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.904, 10.171], loss: 0.001398, mae: 0.040631, mean_q: 1.168415
 507500/1000000: episode: 5075, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.861, mean reward: 0.599 [0.508, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.868, 10.271], loss: 0.001336, mae: 0.040239, mean_q: 1.163805
 507600/1000000: episode: 5076, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 56.733, mean reward: 0.567 [0.504, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.459, 10.098], loss: 0.001403, mae: 0.040520, mean_q: 1.165696
 507700/1000000: episode: 5077, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.737, mean reward: 0.587 [0.512, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.587, 10.372], loss: 0.001390, mae: 0.040838, mean_q: 1.164884
 507800/1000000: episode: 5078, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.773, mean reward: 0.578 [0.508, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.732, 10.245], loss: 0.001410, mae: 0.040661, mean_q: 1.163647
 507900/1000000: episode: 5079, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.920, mean reward: 0.619 [0.506, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.937, 10.098], loss: 0.001488, mae: 0.041697, mean_q: 1.164702
 508000/1000000: episode: 5080, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 56.921, mean reward: 0.569 [0.499, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.556, 10.272], loss: 0.001458, mae: 0.041449, mean_q: 1.166137
 508100/1000000: episode: 5081, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.010, mean reward: 0.590 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.900, 10.123], loss: 0.001511, mae: 0.041775, mean_q: 1.163576
 508200/1000000: episode: 5082, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.383, mean reward: 0.574 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.172, 10.323], loss: 0.001378, mae: 0.041328, mean_q: 1.161521
 508300/1000000: episode: 5083, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.941, mean reward: 0.589 [0.503, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.549, 10.311], loss: 0.001391, mae: 0.040220, mean_q: 1.161906
 508400/1000000: episode: 5084, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 60.306, mean reward: 0.603 [0.501, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.373, 10.205], loss: 0.001295, mae: 0.038884, mean_q: 1.161304
 508500/1000000: episode: 5085, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.585, mean reward: 0.596 [0.507, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.574, 10.098], loss: 0.001479, mae: 0.041977, mean_q: 1.164649
 508600/1000000: episode: 5086, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.911, mean reward: 0.579 [0.507, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.527, 10.098], loss: 0.001478, mae: 0.042013, mean_q: 1.165487
 508700/1000000: episode: 5087, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.114, mean reward: 0.591 [0.507, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.163, 10.284], loss: 0.001432, mae: 0.040915, mean_q: 1.161193
 508800/1000000: episode: 5088, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.620, mean reward: 0.576 [0.505, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.440, 10.098], loss: 0.001408, mae: 0.040996, mean_q: 1.163006
 508900/1000000: episode: 5089, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.619, mean reward: 0.586 [0.502, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.351, 10.098], loss: 0.001433, mae: 0.041269, mean_q: 1.163544
 509000/1000000: episode: 5090, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 56.929, mean reward: 0.569 [0.508, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.529, 10.115], loss: 0.001416, mae: 0.040986, mean_q: 1.160472
 509100/1000000: episode: 5091, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 63.170, mean reward: 0.632 [0.512, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.922, 10.495], loss: 0.001413, mae: 0.041226, mean_q: 1.160835
 509200/1000000: episode: 5092, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.884, mean reward: 0.569 [0.511, 0.649], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.722, 10.098], loss: 0.001520, mae: 0.042024, mean_q: 1.162984
 509300/1000000: episode: 5093, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.667, mean reward: 0.607 [0.526, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.683, 10.378], loss: 0.001415, mae: 0.040909, mean_q: 1.165061
 509400/1000000: episode: 5094, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.912, mean reward: 0.599 [0.513, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.923, 10.350], loss: 0.001479, mae: 0.041877, mean_q: 1.164022
 509500/1000000: episode: 5095, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.103, mean reward: 0.581 [0.500, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.617, 10.098], loss: 0.001414, mae: 0.041003, mean_q: 1.160509
 509600/1000000: episode: 5096, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.865, mean reward: 0.599 [0.515, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.568, 10.098], loss: 0.001450, mae: 0.041610, mean_q: 1.163374
 509700/1000000: episode: 5097, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.875, mean reward: 0.579 [0.501, 0.869], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.323, 10.138], loss: 0.001444, mae: 0.041784, mean_q: 1.169527
 509800/1000000: episode: 5098, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.825, mean reward: 0.598 [0.514, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.770, 10.175], loss: 0.001476, mae: 0.041800, mean_q: 1.161432
 509900/1000000: episode: 5099, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 60.641, mean reward: 0.606 [0.506, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.209, 10.125], loss: 0.001339, mae: 0.040117, mean_q: 1.163679
 510000/1000000: episode: 5100, duration: 0.520s, episode steps: 100, steps per second: 192, episode reward: 60.934, mean reward: 0.609 [0.505, 0.875], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.469, 10.098], loss: 0.001472, mae: 0.041741, mean_q: 1.165904
 510100/1000000: episode: 5101, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.615, mean reward: 0.576 [0.498, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.807, 10.098], loss: 0.001504, mae: 0.041877, mean_q: 1.161143
 510200/1000000: episode: 5102, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.812, mean reward: 0.588 [0.510, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.775, 10.170], loss: 0.001543, mae: 0.042384, mean_q: 1.167051
 510300/1000000: episode: 5103, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.719, mean reward: 0.617 [0.503, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.568, 10.098], loss: 0.001399, mae: 0.040672, mean_q: 1.165321
 510400/1000000: episode: 5104, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.464, mean reward: 0.575 [0.498, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.770, 10.117], loss: 0.001457, mae: 0.041474, mean_q: 1.159876
 510500/1000000: episode: 5105, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.960, mean reward: 0.600 [0.508, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.678, 10.098], loss: 0.001434, mae: 0.041227, mean_q: 1.164937
 510600/1000000: episode: 5106, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.697, mean reward: 0.587 [0.504, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.686, 10.098], loss: 0.001479, mae: 0.041666, mean_q: 1.166736
 510700/1000000: episode: 5107, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.337, mean reward: 0.573 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.406, 10.098], loss: 0.001452, mae: 0.041415, mean_q: 1.165728
 510800/1000000: episode: 5108, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.951, mean reward: 0.600 [0.508, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.562, 10.098], loss: 0.001502, mae: 0.042150, mean_q: 1.164394
 510900/1000000: episode: 5109, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.265, mean reward: 0.593 [0.503, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.401, 10.138], loss: 0.001485, mae: 0.041968, mean_q: 1.164829
 511000/1000000: episode: 5110, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.791, mean reward: 0.588 [0.509, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.636, 10.098], loss: 0.001495, mae: 0.042161, mean_q: 1.165536
 511100/1000000: episode: 5111, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.474, mean reward: 0.575 [0.502, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.632, 10.322], loss: 0.001455, mae: 0.041414, mean_q: 1.163412
 511200/1000000: episode: 5112, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.403, mean reward: 0.584 [0.500, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.572, 10.173], loss: 0.001478, mae: 0.041953, mean_q: 1.163415
 511300/1000000: episode: 5113, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.768, mean reward: 0.578 [0.505, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.087, 10.196], loss: 0.001549, mae: 0.043074, mean_q: 1.164046
 511400/1000000: episode: 5114, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.122, mean reward: 0.581 [0.516, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.809, 10.098], loss: 0.001551, mae: 0.043248, mean_q: 1.165826
 511500/1000000: episode: 5115, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 65.483, mean reward: 0.655 [0.502, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.204, 10.367], loss: 0.001432, mae: 0.041211, mean_q: 1.164282
 511600/1000000: episode: 5116, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.991, mean reward: 0.590 [0.508, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.544, 10.098], loss: 0.001502, mae: 0.041965, mean_q: 1.166141
 511700/1000000: episode: 5117, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.064, mean reward: 0.601 [0.505, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.900, 10.412], loss: 0.001487, mae: 0.042394, mean_q: 1.164838
 511800/1000000: episode: 5118, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.514, mean reward: 0.575 [0.507, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.632, 10.212], loss: 0.001478, mae: 0.041495, mean_q: 1.163304
 511900/1000000: episode: 5119, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.282, mean reward: 0.593 [0.506, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.901, 10.179], loss: 0.001506, mae: 0.042450, mean_q: 1.165293
 512000/1000000: episode: 5120, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.030, mean reward: 0.600 [0.513, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.123, 10.337], loss: 0.001417, mae: 0.040947, mean_q: 1.167438
 512100/1000000: episode: 5121, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.089, mean reward: 0.611 [0.501, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.826, 10.098], loss: 0.001573, mae: 0.043374, mean_q: 1.169539
 512200/1000000: episode: 5122, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.510, mean reward: 0.575 [0.501, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.786, 10.102], loss: 0.001433, mae: 0.041368, mean_q: 1.167154
 512300/1000000: episode: 5123, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 56.470, mean reward: 0.565 [0.503, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.289, 10.098], loss: 0.001530, mae: 0.042729, mean_q: 1.168494
 512400/1000000: episode: 5124, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.896, mean reward: 0.579 [0.512, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.446, 10.098], loss: 0.001463, mae: 0.041585, mean_q: 1.167974
 512500/1000000: episode: 5125, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 60.909, mean reward: 0.609 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.637, 10.205], loss: 0.001454, mae: 0.041351, mean_q: 1.168169
 512600/1000000: episode: 5126, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.618, mean reward: 0.586 [0.498, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.184, 10.181], loss: 0.001532, mae: 0.042611, mean_q: 1.169580
 512700/1000000: episode: 5127, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.120, mean reward: 0.581 [0.502, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.323, 10.098], loss: 0.001533, mae: 0.042873, mean_q: 1.169258
 512800/1000000: episode: 5128, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.347, mean reward: 0.583 [0.511, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.336, 10.098], loss: 0.001384, mae: 0.040381, mean_q: 1.166734
 512900/1000000: episode: 5129, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.484, mean reward: 0.585 [0.500, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.745, 10.098], loss: 0.001415, mae: 0.041174, mean_q: 1.169543
 513000/1000000: episode: 5130, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.821, mean reward: 0.568 [0.500, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.066, 10.098], loss: 0.001461, mae: 0.041758, mean_q: 1.167696
 513100/1000000: episode: 5131, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.277, mean reward: 0.603 [0.505, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.941, 10.098], loss: 0.001515, mae: 0.042221, mean_q: 1.166564
 513200/1000000: episode: 5132, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.829, mean reward: 0.568 [0.501, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.643, 10.172], loss: 0.001503, mae: 0.042021, mean_q: 1.166935
 513300/1000000: episode: 5133, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.821, mean reward: 0.598 [0.516, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.956, 10.355], loss: 0.001465, mae: 0.041559, mean_q: 1.166854
 513400/1000000: episode: 5134, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.629, mean reward: 0.596 [0.504, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.148, 10.098], loss: 0.001439, mae: 0.041119, mean_q: 1.168533
 513500/1000000: episode: 5135, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.324, mean reward: 0.573 [0.504, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.827, 10.205], loss: 0.001474, mae: 0.041438, mean_q: 1.168638
 513600/1000000: episode: 5136, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.963, mean reward: 0.580 [0.510, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.349, 10.194], loss: 0.001453, mae: 0.041515, mean_q: 1.170649
 513700/1000000: episode: 5137, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.716, mean reward: 0.577 [0.510, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.482, 10.098], loss: 0.001400, mae: 0.040812, mean_q: 1.171051
 513800/1000000: episode: 5138, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.449, mean reward: 0.584 [0.505, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.846, 10.212], loss: 0.001374, mae: 0.040042, mean_q: 1.165727
 513900/1000000: episode: 5139, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.295, mean reward: 0.583 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.331, 10.098], loss: 0.001378, mae: 0.040728, mean_q: 1.167937
 514000/1000000: episode: 5140, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.401, mean reward: 0.604 [0.509, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.841, 10.292], loss: 0.001389, mae: 0.039903, mean_q: 1.168356
 514100/1000000: episode: 5141, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 61.587, mean reward: 0.616 [0.518, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.844, 10.098], loss: 0.001473, mae: 0.041614, mean_q: 1.169116
 514200/1000000: episode: 5142, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.189, mean reward: 0.582 [0.509, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.943, 10.300], loss: 0.001440, mae: 0.040687, mean_q: 1.170640
 514300/1000000: episode: 5143, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.464, mean reward: 0.585 [0.515, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.484, 10.299], loss: 0.001480, mae: 0.041644, mean_q: 1.167679
 514400/1000000: episode: 5144, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.727, mean reward: 0.587 [0.502, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.806, 10.098], loss: 0.001434, mae: 0.040946, mean_q: 1.170044
 514500/1000000: episode: 5145, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.645, mean reward: 0.586 [0.503, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.542, 10.206], loss: 0.001398, mae: 0.040575, mean_q: 1.164348
 514600/1000000: episode: 5146, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.968, mean reward: 0.590 [0.504, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.159, 10.098], loss: 0.001422, mae: 0.041384, mean_q: 1.168042
 514700/1000000: episode: 5147, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.349, mean reward: 0.583 [0.505, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.825, 10.098], loss: 0.001475, mae: 0.041622, mean_q: 1.168033
 514800/1000000: episode: 5148, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.892, mean reward: 0.579 [0.505, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.961, 10.231], loss: 0.001515, mae: 0.042620, mean_q: 1.166344
 514900/1000000: episode: 5149, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.444, mean reward: 0.604 [0.506, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.886, 10.098], loss: 0.001282, mae: 0.038910, mean_q: 1.163743
 515000/1000000: episode: 5150, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.113, mean reward: 0.571 [0.503, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.347, 10.244], loss: 0.001409, mae: 0.040484, mean_q: 1.164614
 515100/1000000: episode: 5151, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.278, mean reward: 0.583 [0.507, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.041, 10.200], loss: 0.001362, mae: 0.040367, mean_q: 1.162193
 515200/1000000: episode: 5152, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.110, mean reward: 0.591 [0.501, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.143, 10.098], loss: 0.001284, mae: 0.038804, mean_q: 1.160440
 515300/1000000: episode: 5153, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 59.922, mean reward: 0.599 [0.504, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.514, 10.336], loss: 0.001445, mae: 0.041363, mean_q: 1.163356
 515400/1000000: episode: 5154, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 59.259, mean reward: 0.593 [0.500, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.879, 10.098], loss: 0.001557, mae: 0.042632, mean_q: 1.166430
 515500/1000000: episode: 5155, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.077, mean reward: 0.591 [0.499, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.234, 10.108], loss: 0.001358, mae: 0.040402, mean_q: 1.163769
 515600/1000000: episode: 5156, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.449, mean reward: 0.594 [0.498, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.832, 10.189], loss: 0.001436, mae: 0.040834, mean_q: 1.166315
 515700/1000000: episode: 5157, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.317, mean reward: 0.573 [0.507, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.036, 10.098], loss: 0.001433, mae: 0.040782, mean_q: 1.165556
 515800/1000000: episode: 5158, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 61.236, mean reward: 0.612 [0.506, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.577, 10.098], loss: 0.001475, mae: 0.041796, mean_q: 1.167049
 515900/1000000: episode: 5159, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.990, mean reward: 0.610 [0.500, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.616, 10.472], loss: 0.001397, mae: 0.040479, mean_q: 1.164952
 516000/1000000: episode: 5160, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.652, mean reward: 0.587 [0.505, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.671, 10.098], loss: 0.001402, mae: 0.040809, mean_q: 1.168602
 516100/1000000: episode: 5161, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 62.182, mean reward: 0.622 [0.518, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.689, 10.298], loss: 0.001357, mae: 0.040023, mean_q: 1.166429
 516200/1000000: episode: 5162, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.965, mean reward: 0.580 [0.514, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.443, 10.272], loss: 0.001472, mae: 0.041787, mean_q: 1.171189
 516300/1000000: episode: 5163, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.425, mean reward: 0.594 [0.503, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.836, 10.201], loss: 0.001464, mae: 0.041194, mean_q: 1.168413
 516400/1000000: episode: 5164, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.625, mean reward: 0.606 [0.502, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.915, 10.099], loss: 0.001492, mae: 0.041719, mean_q: 1.167212
 516500/1000000: episode: 5165, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.126, mean reward: 0.581 [0.504, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.951, 10.098], loss: 0.001386, mae: 0.040373, mean_q: 1.165450
 516600/1000000: episode: 5166, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.174, mean reward: 0.592 [0.506, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.956, 10.280], loss: 0.001500, mae: 0.042202, mean_q: 1.165488
 516700/1000000: episode: 5167, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.117, mean reward: 0.571 [0.498, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.970, 10.154], loss: 0.001397, mae: 0.040545, mean_q: 1.164937
 516800/1000000: episode: 5168, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 56.996, mean reward: 0.570 [0.500, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.666, 10.098], loss: 0.001333, mae: 0.040019, mean_q: 1.165276
 516900/1000000: episode: 5169, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.985, mean reward: 0.590 [0.509, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.931, 10.098], loss: 0.001309, mae: 0.039178, mean_q: 1.165273
 517000/1000000: episode: 5170, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.172, mean reward: 0.582 [0.499, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.650, 10.098], loss: 0.001545, mae: 0.041925, mean_q: 1.164019
 517100/1000000: episode: 5171, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.879, mean reward: 0.579 [0.511, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.812, 10.178], loss: 0.001472, mae: 0.041381, mean_q: 1.161615
 517200/1000000: episode: 5172, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 63.606, mean reward: 0.636 [0.520, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.342, 10.276], loss: 0.001461, mae: 0.041204, mean_q: 1.166804
 517300/1000000: episode: 5173, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.874, mean reward: 0.579 [0.499, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.320, 10.304], loss: 0.001358, mae: 0.040036, mean_q: 1.164274
 517400/1000000: episode: 5174, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.197, mean reward: 0.582 [0.501, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.491, 10.338], loss: 0.001432, mae: 0.040732, mean_q: 1.167735
 517500/1000000: episode: 5175, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.570, mean reward: 0.586 [0.499, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.953, 10.214], loss: 0.001438, mae: 0.041313, mean_q: 1.169579
 517600/1000000: episode: 5176, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.200, mean reward: 0.562 [0.506, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.763, 10.098], loss: 0.001484, mae: 0.042031, mean_q: 1.163793
 517700/1000000: episode: 5177, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.389, mean reward: 0.584 [0.514, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.004, 10.100], loss: 0.001365, mae: 0.040067, mean_q: 1.165060
 517800/1000000: episode: 5178, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.453, mean reward: 0.575 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.974, 10.127], loss: 0.001430, mae: 0.041448, mean_q: 1.163604
 517900/1000000: episode: 5179, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.724, mean reward: 0.597 [0.500, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.463, 10.370], loss: 0.001340, mae: 0.039498, mean_q: 1.165235
 518000/1000000: episode: 5180, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.106, mean reward: 0.591 [0.500, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.727, 10.098], loss: 0.001488, mae: 0.041777, mean_q: 1.165366
 518100/1000000: episode: 5181, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.080, mean reward: 0.571 [0.499, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.974, 10.116], loss: 0.001499, mae: 0.041101, mean_q: 1.166805
 518200/1000000: episode: 5182, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.449, mean reward: 0.594 [0.506, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.258, 10.281], loss: 0.001556, mae: 0.041977, mean_q: 1.168827
 518300/1000000: episode: 5183, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.434, mean reward: 0.574 [0.503, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.292, 10.180], loss: 0.001540, mae: 0.041577, mean_q: 1.167600
 518400/1000000: episode: 5184, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.011, mean reward: 0.600 [0.515, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.812, 10.098], loss: 0.001415, mae: 0.040553, mean_q: 1.164653
 518500/1000000: episode: 5185, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.930, mean reward: 0.589 [0.506, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.192, 10.098], loss: 0.001507, mae: 0.041446, mean_q: 1.165390
 518600/1000000: episode: 5186, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.637, mean reward: 0.576 [0.500, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.596, 10.166], loss: 0.001504, mae: 0.041925, mean_q: 1.164370
 518700/1000000: episode: 5187, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.419, mean reward: 0.584 [0.514, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.740, 10.098], loss: 0.001479, mae: 0.041784, mean_q: 1.165437
 518800/1000000: episode: 5188, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.575, mean reward: 0.586 [0.511, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.589, 10.444], loss: 0.001392, mae: 0.040336, mean_q: 1.164784
 518900/1000000: episode: 5189, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.619, mean reward: 0.596 [0.503, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.875, 10.098], loss: 0.001379, mae: 0.039929, mean_q: 1.160530
 519000/1000000: episode: 5190, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 60.230, mean reward: 0.602 [0.511, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.241, 10.098], loss: 0.001542, mae: 0.042240, mean_q: 1.162792
 519100/1000000: episode: 5191, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.488, mean reward: 0.575 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.537, 10.209], loss: 0.001417, mae: 0.040895, mean_q: 1.164609
 519200/1000000: episode: 5192, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.728, mean reward: 0.617 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.223, 10.098], loss: 0.001357, mae: 0.039988, mean_q: 1.161783
 519300/1000000: episode: 5193, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.053, mean reward: 0.581 [0.501, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.506, 10.098], loss: 0.001483, mae: 0.041263, mean_q: 1.166530
 519400/1000000: episode: 5194, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.007, mean reward: 0.590 [0.510, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.206, 10.118], loss: 0.001402, mae: 0.040271, mean_q: 1.163815
 519500/1000000: episode: 5195, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.411, mean reward: 0.574 [0.503, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.125, 10.305], loss: 0.001440, mae: 0.041286, mean_q: 1.164732
 519600/1000000: episode: 5196, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.730, mean reward: 0.597 [0.513, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.247, 10.354], loss: 0.001455, mae: 0.040981, mean_q: 1.162735
 519700/1000000: episode: 5197, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.496, mean reward: 0.585 [0.506, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.843, 10.139], loss: 0.001515, mae: 0.042008, mean_q: 1.165555
 519800/1000000: episode: 5198, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.431, mean reward: 0.574 [0.503, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.220, 10.118], loss: 0.001427, mae: 0.040554, mean_q: 1.164236
 519900/1000000: episode: 5199, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.907, mean reward: 0.599 [0.512, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.148, 10.098], loss: 0.001390, mae: 0.039790, mean_q: 1.166250
 520000/1000000: episode: 5200, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.642, mean reward: 0.586 [0.498, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.738, 10.274], loss: 0.001460, mae: 0.041061, mean_q: 1.166622
 520100/1000000: episode: 5201, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.142, mean reward: 0.601 [0.514, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.845, 10.296], loss: 0.001454, mae: 0.040658, mean_q: 1.165399
 520200/1000000: episode: 5202, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 59.002, mean reward: 0.590 [0.508, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.678, 10.210], loss: 0.001486, mae: 0.040698, mean_q: 1.166059
 520300/1000000: episode: 5203, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.239, mean reward: 0.582 [0.505, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.778, 10.164], loss: 0.001530, mae: 0.042124, mean_q: 1.165064
 520400/1000000: episode: 5204, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 57.882, mean reward: 0.579 [0.507, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.571, 10.098], loss: 0.001439, mae: 0.040535, mean_q: 1.164597
 520500/1000000: episode: 5205, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 61.117, mean reward: 0.611 [0.501, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.283, 10.098], loss: 0.001384, mae: 0.039960, mean_q: 1.168439
 520600/1000000: episode: 5206, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.576, mean reward: 0.616 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.463, 10.297], loss: 0.001437, mae: 0.040996, mean_q: 1.164825
 520700/1000000: episode: 5207, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.471, mean reward: 0.575 [0.497, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.160, 10.098], loss: 0.001431, mae: 0.040530, mean_q: 1.168885
 520800/1000000: episode: 5208, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.596, mean reward: 0.576 [0.503, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.277, 10.098], loss: 0.001440, mae: 0.040784, mean_q: 1.164953
 520900/1000000: episode: 5209, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.594, mean reward: 0.586 [0.499, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.333, 10.098], loss: 0.001442, mae: 0.040788, mean_q: 1.164981
 521000/1000000: episode: 5210, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.976, mean reward: 0.590 [0.513, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.787, 10.250], loss: 0.001378, mae: 0.040384, mean_q: 1.168014
 521100/1000000: episode: 5211, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.183, mean reward: 0.602 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.350, 10.098], loss: 0.001453, mae: 0.041132, mean_q: 1.160759
 521200/1000000: episode: 5212, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 62.930, mean reward: 0.629 [0.516, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.133, 10.236], loss: 0.001414, mae: 0.040387, mean_q: 1.162100
 521300/1000000: episode: 5213, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.517, mean reward: 0.575 [0.506, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.747, 10.131], loss: 0.001397, mae: 0.040676, mean_q: 1.163111
 521400/1000000: episode: 5214, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.312, mean reward: 0.573 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.539, 10.378], loss: 0.001497, mae: 0.041494, mean_q: 1.160912
 521500/1000000: episode: 5215, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.641, mean reward: 0.576 [0.509, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.711, 10.289], loss: 0.001389, mae: 0.040223, mean_q: 1.163345
 521600/1000000: episode: 5216, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.620, mean reward: 0.586 [0.512, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.712, 10.174], loss: 0.001501, mae: 0.042527, mean_q: 1.163130
 521700/1000000: episode: 5217, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.176, mean reward: 0.572 [0.500, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.473, 10.098], loss: 0.001348, mae: 0.040022, mean_q: 1.161536
 521800/1000000: episode: 5218, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.350, mean reward: 0.594 [0.505, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.868, 10.145], loss: 0.001495, mae: 0.042105, mean_q: 1.163918
 521900/1000000: episode: 5219, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.642, mean reward: 0.566 [0.499, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-2.695, 10.098], loss: 0.001487, mae: 0.041680, mean_q: 1.166584
 522000/1000000: episode: 5220, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.235, mean reward: 0.582 [0.500, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.770, 10.120], loss: 0.001458, mae: 0.040694, mean_q: 1.163395
 522100/1000000: episode: 5221, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.901, mean reward: 0.589 [0.499, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.388, 10.098], loss: 0.001419, mae: 0.041443, mean_q: 1.163056
 522200/1000000: episode: 5222, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.241, mean reward: 0.582 [0.501, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.537, 10.232], loss: 0.001441, mae: 0.040816, mean_q: 1.161649
 522300/1000000: episode: 5223, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.002, mean reward: 0.570 [0.503, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.308, 10.126], loss: 0.001383, mae: 0.040129, mean_q: 1.162756
 522400/1000000: episode: 5224, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.950, mean reward: 0.589 [0.508, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.537, 10.098], loss: 0.001492, mae: 0.041736, mean_q: 1.161492
 522500/1000000: episode: 5225, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.003, mean reward: 0.570 [0.499, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.363, 10.217], loss: 0.001380, mae: 0.040101, mean_q: 1.161560
 522600/1000000: episode: 5226, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.927, mean reward: 0.569 [0.501, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.714, 10.162], loss: 0.001405, mae: 0.040363, mean_q: 1.162492
 522700/1000000: episode: 5227, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.482, mean reward: 0.585 [0.515, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.523, 10.098], loss: 0.001415, mae: 0.041071, mean_q: 1.161433
 522800/1000000: episode: 5228, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.654, mean reward: 0.607 [0.509, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.334, 10.160], loss: 0.001470, mae: 0.041116, mean_q: 1.160435
 522900/1000000: episode: 5229, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.329, mean reward: 0.583 [0.510, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.753, 10.156], loss: 0.001339, mae: 0.039541, mean_q: 1.161107
 523000/1000000: episode: 5230, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.461, mean reward: 0.575 [0.502, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.325, 10.098], loss: 0.001338, mae: 0.038979, mean_q: 1.159493
 523100/1000000: episode: 5231, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.925, mean reward: 0.599 [0.508, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.703, 10.152], loss: 0.001332, mae: 0.039894, mean_q: 1.162334
 523200/1000000: episode: 5232, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 56.186, mean reward: 0.562 [0.505, 0.670], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.405, 10.159], loss: 0.001367, mae: 0.039404, mean_q: 1.156511
 523300/1000000: episode: 5233, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.674, mean reward: 0.617 [0.502, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.890, 10.098], loss: 0.001452, mae: 0.040253, mean_q: 1.159920
 523400/1000000: episode: 5234, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.605, mean reward: 0.586 [0.501, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.877, 10.158], loss: 0.001394, mae: 0.040547, mean_q: 1.162688
 523500/1000000: episode: 5235, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 61.371, mean reward: 0.614 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-2.240, 10.288], loss: 0.001411, mae: 0.040414, mean_q: 1.159510
 523600/1000000: episode: 5236, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.372, mean reward: 0.584 [0.507, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.407, 10.286], loss: 0.001392, mae: 0.040354, mean_q: 1.161594
 523700/1000000: episode: 5237, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.761, mean reward: 0.598 [0.502, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.501, 10.503], loss: 0.001451, mae: 0.040751, mean_q: 1.160052
 523800/1000000: episode: 5238, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 57.910, mean reward: 0.579 [0.502, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.264, 10.144], loss: 0.001429, mae: 0.040743, mean_q: 1.162813
 523900/1000000: episode: 5239, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.326, mean reward: 0.573 [0.501, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.768, 10.098], loss: 0.001375, mae: 0.040436, mean_q: 1.162603
 524000/1000000: episode: 5240, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.279, mean reward: 0.603 [0.499, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.498, 10.098], loss: 0.001354, mae: 0.039941, mean_q: 1.160842
 524100/1000000: episode: 5241, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.042, mean reward: 0.600 [0.518, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.468, 10.295], loss: 0.001445, mae: 0.041100, mean_q: 1.162076
 524200/1000000: episode: 5242, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.448, mean reward: 0.584 [0.513, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.988, 10.098], loss: 0.001327, mae: 0.039691, mean_q: 1.158383
 524300/1000000: episode: 5243, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.525, mean reward: 0.605 [0.504, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.803, 10.098], loss: 0.001327, mae: 0.039402, mean_q: 1.160480
 524400/1000000: episode: 5244, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.993, mean reward: 0.610 [0.507, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.660, 10.218], loss: 0.001423, mae: 0.041276, mean_q: 1.160756
 524500/1000000: episode: 5245, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 62.647, mean reward: 0.626 [0.508, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.409 [-1.578, 10.098], loss: 0.001406, mae: 0.040763, mean_q: 1.161201
 524600/1000000: episode: 5246, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.502, mean reward: 0.565 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.085, 10.098], loss: 0.001438, mae: 0.041365, mean_q: 1.168737
 524700/1000000: episode: 5247, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.903, mean reward: 0.599 [0.505, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.876, 10.376], loss: 0.001361, mae: 0.039911, mean_q: 1.167094
 524800/1000000: episode: 5248, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.216, mean reward: 0.592 [0.507, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.187, 10.108], loss: 0.001386, mae: 0.039949, mean_q: 1.167486
 524900/1000000: episode: 5249, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.692, mean reward: 0.607 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.690, 10.265], loss: 0.001351, mae: 0.039879, mean_q: 1.168563
 525000/1000000: episode: 5250, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.247, mean reward: 0.612 [0.516, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.741, 10.098], loss: 0.001371, mae: 0.039880, mean_q: 1.164320
 525100/1000000: episode: 5251, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.179, mean reward: 0.572 [0.507, 0.670], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.503, 10.098], loss: 0.001306, mae: 0.039369, mean_q: 1.165708
 525200/1000000: episode: 5252, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.438, mean reward: 0.584 [0.524, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.586, 10.098], loss: 0.001325, mae: 0.039753, mean_q: 1.168602
 525300/1000000: episode: 5253, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.078, mean reward: 0.591 [0.521, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.988, 10.098], loss: 0.001286, mae: 0.039225, mean_q: 1.167892
 525400/1000000: episode: 5254, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.769, mean reward: 0.578 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.512, 10.098], loss: 0.001302, mae: 0.039293, mean_q: 1.165100
 525500/1000000: episode: 5255, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.398, mean reward: 0.594 [0.503, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.789, 10.251], loss: 0.001351, mae: 0.039911, mean_q: 1.167982
 525600/1000000: episode: 5256, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.744, mean reward: 0.607 [0.510, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.832, 10.098], loss: 0.001313, mae: 0.039327, mean_q: 1.165091
 525700/1000000: episode: 5257, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.669, mean reward: 0.587 [0.500, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.630, 10.122], loss: 0.001366, mae: 0.039949, mean_q: 1.164956
 525800/1000000: episode: 5258, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.055, mean reward: 0.591 [0.503, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.056, 10.098], loss: 0.001384, mae: 0.040000, mean_q: 1.168094
 525900/1000000: episode: 5259, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.053, mean reward: 0.581 [0.504, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.933, 10.207], loss: 0.001304, mae: 0.039295, mean_q: 1.164657
 526000/1000000: episode: 5260, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.794, mean reward: 0.608 [0.504, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.834, 10.426], loss: 0.001457, mae: 0.041031, mean_q: 1.167686
 526100/1000000: episode: 5261, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.587, mean reward: 0.586 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.911, 10.340], loss: 0.001360, mae: 0.039115, mean_q: 1.167787
 526200/1000000: episode: 5262, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.793, mean reward: 0.578 [0.503, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.469, 10.098], loss: 0.001350, mae: 0.039968, mean_q: 1.163553
 526300/1000000: episode: 5263, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.297, mean reward: 0.573 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.951, 10.101], loss: 0.001353, mae: 0.039413, mean_q: 1.162968
 526400/1000000: episode: 5264, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.603, mean reward: 0.586 [0.509, 0.858], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.553, 10.098], loss: 0.001469, mae: 0.041218, mean_q: 1.166140
 526500/1000000: episode: 5265, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 56.950, mean reward: 0.569 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.772, 10.146], loss: 0.001362, mae: 0.039633, mean_q: 1.164477
 526600/1000000: episode: 5266, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.545, mean reward: 0.575 [0.503, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.562, 10.241], loss: 0.001323, mae: 0.039572, mean_q: 1.165938
 526700/1000000: episode: 5267, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.948, mean reward: 0.599 [0.514, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.803, 10.263], loss: 0.001382, mae: 0.040000, mean_q: 1.164277
 526800/1000000: episode: 5268, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.050, mean reward: 0.601 [0.507, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.845, 10.098], loss: 0.001494, mae: 0.041499, mean_q: 1.169282
 526900/1000000: episode: 5269, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.560, mean reward: 0.596 [0.511, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.715, 10.180], loss: 0.001336, mae: 0.039575, mean_q: 1.164843
 527000/1000000: episode: 5270, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.801, mean reward: 0.578 [0.498, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.076, 10.102], loss: 0.001435, mae: 0.040548, mean_q: 1.166261
 527100/1000000: episode: 5271, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.638, mean reward: 0.576 [0.498, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.890, 10.259], loss: 0.001414, mae: 0.040427, mean_q: 1.165761
 527200/1000000: episode: 5272, duration: 0.622s, episode steps: 100, steps per second: 161, episode reward: 56.518, mean reward: 0.565 [0.500, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.621, 10.162], loss: 0.001463, mae: 0.041478, mean_q: 1.167343
 527300/1000000: episode: 5273, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 58.831, mean reward: 0.588 [0.505, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.542, 10.124], loss: 0.001366, mae: 0.039924, mean_q: 1.167699
 527400/1000000: episode: 5274, duration: 0.627s, episode steps: 100, steps per second: 159, episode reward: 56.146, mean reward: 0.561 [0.504, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.921, 10.187], loss: 0.001312, mae: 0.039645, mean_q: 1.163978
 527500/1000000: episode: 5275, duration: 0.634s, episode steps: 100, steps per second: 158, episode reward: 58.358, mean reward: 0.584 [0.505, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.350, 10.282], loss: 0.001429, mae: 0.041329, mean_q: 1.164373
 527600/1000000: episode: 5276, duration: 0.639s, episode steps: 100, steps per second: 156, episode reward: 57.608, mean reward: 0.576 [0.499, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.543, 10.255], loss: 0.001378, mae: 0.040439, mean_q: 1.168483
 527700/1000000: episode: 5277, duration: 0.650s, episode steps: 100, steps per second: 154, episode reward: 58.179, mean reward: 0.582 [0.500, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.747, 10.098], loss: 0.001337, mae: 0.039975, mean_q: 1.166799
 527800/1000000: episode: 5278, duration: 0.637s, episode steps: 100, steps per second: 157, episode reward: 61.113, mean reward: 0.611 [0.502, 0.990], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.004, 10.144], loss: 0.001377, mae: 0.040491, mean_q: 1.164276
 527900/1000000: episode: 5279, duration: 0.646s, episode steps: 100, steps per second: 155, episode reward: 58.207, mean reward: 0.582 [0.499, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.629, 10.098], loss: 0.001412, mae: 0.040624, mean_q: 1.166906
 528000/1000000: episode: 5280, duration: 0.650s, episode steps: 100, steps per second: 154, episode reward: 59.211, mean reward: 0.592 [0.508, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.089, 10.291], loss: 0.001383, mae: 0.040357, mean_q: 1.168054
 528100/1000000: episode: 5281, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.740, mean reward: 0.567 [0.498, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.680, 10.168], loss: 0.001353, mae: 0.040534, mean_q: 1.165440
 528200/1000000: episode: 5282, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.008, mean reward: 0.590 [0.502, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.212, 10.274], loss: 0.001301, mae: 0.039244, mean_q: 1.165276
 528300/1000000: episode: 5283, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 62.334, mean reward: 0.623 [0.519, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.782, 10.187], loss: 0.001495, mae: 0.041766, mean_q: 1.166228
 528400/1000000: episode: 5284, duration: 0.524s, episode steps: 100, steps per second: 191, episode reward: 59.089, mean reward: 0.591 [0.511, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.767, 10.098], loss: 0.001481, mae: 0.041551, mean_q: 1.163846
 528500/1000000: episode: 5285, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.296, mean reward: 0.613 [0.502, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.816, 10.098], loss: 0.001393, mae: 0.040078, mean_q: 1.167813
 528600/1000000: episode: 5286, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.988, mean reward: 0.600 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.832, 10.241], loss: 0.001420, mae: 0.040237, mean_q: 1.165522
 528700/1000000: episode: 5287, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.850, mean reward: 0.599 [0.501, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.318, 10.109], loss: 0.001554, mae: 0.042709, mean_q: 1.162492
 528800/1000000: episode: 5288, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.822, mean reward: 0.588 [0.510, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.819, 10.098], loss: 0.001419, mae: 0.040664, mean_q: 1.168432
 528900/1000000: episode: 5289, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.155, mean reward: 0.582 [0.502, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.191, 10.098], loss: 0.001547, mae: 0.042431, mean_q: 1.169677
 529000/1000000: episode: 5290, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.289, mean reward: 0.583 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.412, 10.098], loss: 0.001359, mae: 0.040169, mean_q: 1.164837
 529100/1000000: episode: 5291, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.115, mean reward: 0.591 [0.499, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.579, 10.098], loss: 0.001563, mae: 0.042351, mean_q: 1.166728
 529200/1000000: episode: 5292, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.787, mean reward: 0.578 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.985, 10.300], loss: 0.001491, mae: 0.041870, mean_q: 1.168382
 529300/1000000: episode: 5293, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.581, mean reward: 0.586 [0.507, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.358, 10.188], loss: 0.001549, mae: 0.042222, mean_q: 1.164725
 529400/1000000: episode: 5294, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.384, mean reward: 0.574 [0.506, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.141, 10.343], loss: 0.001519, mae: 0.042338, mean_q: 1.165602
 529500/1000000: episode: 5295, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.670, mean reward: 0.587 [0.504, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.190, 10.122], loss: 0.001480, mae: 0.041788, mean_q: 1.164148
 529600/1000000: episode: 5296, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.954, mean reward: 0.600 [0.512, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.614, 10.185], loss: 0.001495, mae: 0.041931, mean_q: 1.164850
 529700/1000000: episode: 5297, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.406, mean reward: 0.574 [0.504, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.787, 10.098], loss: 0.001536, mae: 0.042634, mean_q: 1.165043
 529800/1000000: episode: 5298, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.018, mean reward: 0.580 [0.506, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.039, 10.098], loss: 0.001501, mae: 0.042189, mean_q: 1.167021
 529900/1000000: episode: 5299, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.647, mean reward: 0.606 [0.501, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.393, 10.098], loss: 0.001540, mae: 0.042709, mean_q: 1.160608
 530000/1000000: episode: 5300, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.545, mean reward: 0.585 [0.505, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.762, 10.174], loss: 0.001603, mae: 0.043554, mean_q: 1.164718
 530100/1000000: episode: 5301, duration: 0.648s, episode steps: 100, steps per second: 154, episode reward: 57.238, mean reward: 0.572 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.024, 10.138], loss: 0.001548, mae: 0.042903, mean_q: 1.163365
 530200/1000000: episode: 5302, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.527, mean reward: 0.565 [0.501, 0.659], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.437, 10.098], loss: 0.001437, mae: 0.040938, mean_q: 1.157121
 530300/1000000: episode: 5303, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 57.810, mean reward: 0.578 [0.506, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.756, 10.098], loss: 0.001560, mae: 0.042223, mean_q: 1.160782
 530400/1000000: episode: 5304, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.146, mean reward: 0.571 [0.501, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.833, 10.098], loss: 0.001520, mae: 0.042569, mean_q: 1.159246
 530500/1000000: episode: 5305, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.939, mean reward: 0.599 [0.505, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.178, 10.098], loss: 0.001556, mae: 0.042661, mean_q: 1.160763
 530600/1000000: episode: 5306, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.519, mean reward: 0.595 [0.513, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.338, 10.112], loss: 0.001571, mae: 0.043299, mean_q: 1.160136
 530700/1000000: episode: 5307, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.794, mean reward: 0.608 [0.503, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.476, 10.367], loss: 0.001598, mae: 0.043643, mean_q: 1.162564
 530800/1000000: episode: 5308, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.252, mean reward: 0.613 [0.507, 0.882], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.893, 10.098], loss: 0.001547, mae: 0.042981, mean_q: 1.161245
 530900/1000000: episode: 5309, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 62.200, mean reward: 0.622 [0.503, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.943, 10.098], loss: 0.001561, mae: 0.043765, mean_q: 1.162010
 531000/1000000: episode: 5310, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.597, mean reward: 0.586 [0.507, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.701, 10.098], loss: 0.001589, mae: 0.043083, mean_q: 1.162425
 531100/1000000: episode: 5311, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 62.807, mean reward: 0.628 [0.508, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.935, 10.098], loss: 0.001426, mae: 0.041520, mean_q: 1.161750
 531200/1000000: episode: 5312, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 58.612, mean reward: 0.586 [0.508, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.908, 10.285], loss: 0.001556, mae: 0.042362, mean_q: 1.162490
 531300/1000000: episode: 5313, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.745, mean reward: 0.597 [0.503, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.794, 10.098], loss: 0.001595, mae: 0.043423, mean_q: 1.167631
 531400/1000000: episode: 5314, duration: 0.608s, episode steps: 100, steps per second: 165, episode reward: 59.311, mean reward: 0.593 [0.500, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.701, 10.161], loss: 0.001661, mae: 0.044668, mean_q: 1.166442
 531500/1000000: episode: 5315, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.074, mean reward: 0.581 [0.500, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.569, 10.138], loss: 0.001470, mae: 0.041885, mean_q: 1.164737
 531600/1000000: episode: 5316, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.518, mean reward: 0.575 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.364, 10.302], loss: 0.001441, mae: 0.041432, mean_q: 1.164860
 531700/1000000: episode: 5317, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.694, mean reward: 0.597 [0.505, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.579, 10.098], loss: 0.001590, mae: 0.043401, mean_q: 1.165146
 531800/1000000: episode: 5318, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.835, mean reward: 0.588 [0.497, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.830, 10.189], loss: 0.001614, mae: 0.044146, mean_q: 1.168480
 531900/1000000: episode: 5319, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.979, mean reward: 0.610 [0.510, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.830, 10.098], loss: 0.001451, mae: 0.041990, mean_q: 1.164109
 532000/1000000: episode: 5320, duration: 0.650s, episode steps: 100, steps per second: 154, episode reward: 57.390, mean reward: 0.574 [0.505, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.542, 10.163], loss: 0.001650, mae: 0.043955, mean_q: 1.165075
 532100/1000000: episode: 5321, duration: 0.633s, episode steps: 100, steps per second: 158, episode reward: 57.200, mean reward: 0.572 [0.507, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.251, 10.161], loss: 0.001542, mae: 0.042987, mean_q: 1.167247
 532200/1000000: episode: 5322, duration: 0.643s, episode steps: 100, steps per second: 156, episode reward: 58.286, mean reward: 0.583 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.590, 10.195], loss: 0.001532, mae: 0.042546, mean_q: 1.162989
 532300/1000000: episode: 5323, duration: 0.637s, episode steps: 100, steps per second: 157, episode reward: 57.972, mean reward: 0.580 [0.512, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.406, 10.098], loss: 0.001539, mae: 0.043183, mean_q: 1.163972
 532400/1000000: episode: 5324, duration: 0.642s, episode steps: 100, steps per second: 156, episode reward: 57.940, mean reward: 0.579 [0.501, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.928, 10.223], loss: 0.001629, mae: 0.043969, mean_q: 1.166613
 532500/1000000: episode: 5325, duration: 0.664s, episode steps: 100, steps per second: 151, episode reward: 56.753, mean reward: 0.568 [0.497, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.678, 10.198], loss: 0.001509, mae: 0.042512, mean_q: 1.164808
 532600/1000000: episode: 5326, duration: 0.643s, episode steps: 100, steps per second: 156, episode reward: 58.107, mean reward: 0.581 [0.502, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.658, 10.098], loss: 0.001570, mae: 0.042815, mean_q: 1.165981
 532700/1000000: episode: 5327, duration: 0.668s, episode steps: 100, steps per second: 150, episode reward: 58.022, mean reward: 0.580 [0.515, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.428, 10.098], loss: 0.001655, mae: 0.044197, mean_q: 1.165875
 532800/1000000: episode: 5328, duration: 0.633s, episode steps: 100, steps per second: 158, episode reward: 58.874, mean reward: 0.589 [0.497, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.545, 10.215], loss: 0.001665, mae: 0.043855, mean_q: 1.168608
 532900/1000000: episode: 5329, duration: 0.670s, episode steps: 100, steps per second: 149, episode reward: 59.336, mean reward: 0.593 [0.498, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.177, 10.098], loss: 0.001605, mae: 0.043767, mean_q: 1.165495
 533000/1000000: episode: 5330, duration: 0.647s, episode steps: 100, steps per second: 154, episode reward: 59.661, mean reward: 0.597 [0.504, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.062, 10.098], loss: 0.001517, mae: 0.042657, mean_q: 1.163480
 533100/1000000: episode: 5331, duration: 0.648s, episode steps: 100, steps per second: 154, episode reward: 59.342, mean reward: 0.593 [0.510, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.594, 10.098], loss: 0.001591, mae: 0.043382, mean_q: 1.167484
 533200/1000000: episode: 5332, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.518, mean reward: 0.585 [0.505, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.874, 10.098], loss: 0.001471, mae: 0.041631, mean_q: 1.165500
 533300/1000000: episode: 5333, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.963, mean reward: 0.580 [0.511, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.044, 10.323], loss: 0.001515, mae: 0.042892, mean_q: 1.164743
 533400/1000000: episode: 5334, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 64.395, mean reward: 0.644 [0.505, 0.872], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.572, 10.098], loss: 0.001617, mae: 0.044178, mean_q: 1.163536
 533500/1000000: episode: 5335, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.689, mean reward: 0.577 [0.503, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.692, 10.232], loss: 0.001529, mae: 0.042893, mean_q: 1.166408
 533600/1000000: episode: 5336, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.739, mean reward: 0.607 [0.510, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.984, 10.098], loss: 0.001470, mae: 0.041626, mean_q: 1.162771
 533700/1000000: episode: 5337, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.729, mean reward: 0.587 [0.508, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.112, 10.098], loss: 0.001399, mae: 0.041192, mean_q: 1.162805
 533800/1000000: episode: 5338, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.902, mean reward: 0.579 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.035, 10.098], loss: 0.001576, mae: 0.042842, mean_q: 1.166071
 533900/1000000: episode: 5339, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 56.754, mean reward: 0.568 [0.500, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.955, 10.260], loss: 0.001494, mae: 0.042469, mean_q: 1.161398
 534000/1000000: episode: 5340, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.140, mean reward: 0.611 [0.509, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.379, 10.173], loss: 0.001553, mae: 0.043018, mean_q: 1.164696
 534100/1000000: episode: 5341, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.979, mean reward: 0.590 [0.510, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.684, 10.214], loss: 0.001394, mae: 0.040709, mean_q: 1.162749
 534200/1000000: episode: 5342, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.224, mean reward: 0.592 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.814, 10.098], loss: 0.001613, mae: 0.044162, mean_q: 1.163780
 534300/1000000: episode: 5343, duration: 0.676s, episode steps: 100, steps per second: 148, episode reward: 59.154, mean reward: 0.592 [0.505, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.322, 10.098], loss: 0.001447, mae: 0.041867, mean_q: 1.163028
 534400/1000000: episode: 5344, duration: 0.656s, episode steps: 100, steps per second: 152, episode reward: 61.352, mean reward: 0.614 [0.518, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.328, 10.098], loss: 0.001427, mae: 0.041187, mean_q: 1.166375
 534500/1000000: episode: 5345, duration: 0.663s, episode steps: 100, steps per second: 151, episode reward: 58.816, mean reward: 0.588 [0.507, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.520, 10.098], loss: 0.001413, mae: 0.041067, mean_q: 1.166148
 534600/1000000: episode: 5346, duration: 0.676s, episode steps: 100, steps per second: 148, episode reward: 59.747, mean reward: 0.597 [0.506, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.117, 10.098], loss: 0.001533, mae: 0.042531, mean_q: 1.167632
 534700/1000000: episode: 5347, duration: 0.652s, episode steps: 100, steps per second: 153, episode reward: 60.194, mean reward: 0.602 [0.513, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.550, 10.378], loss: 0.001496, mae: 0.042404, mean_q: 1.166628
 534800/1000000: episode: 5348, duration: 0.664s, episode steps: 100, steps per second: 151, episode reward: 58.584, mean reward: 0.586 [0.502, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.634, 10.098], loss: 0.001514, mae: 0.042679, mean_q: 1.169916
 534900/1000000: episode: 5349, duration: 0.659s, episode steps: 100, steps per second: 152, episode reward: 58.971, mean reward: 0.590 [0.508, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.659, 10.260], loss: 0.001430, mae: 0.040966, mean_q: 1.166524
 535000/1000000: episode: 5350, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.047, mean reward: 0.590 [0.513, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.757, 10.098], loss: 0.001453, mae: 0.041307, mean_q: 1.166981
 535100/1000000: episode: 5351, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.808, mean reward: 0.588 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.669, 10.098], loss: 0.001459, mae: 0.041303, mean_q: 1.171064
 535200/1000000: episode: 5352, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.103, mean reward: 0.601 [0.516, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.589, 10.238], loss: 0.001519, mae: 0.041968, mean_q: 1.168405
 535300/1000000: episode: 5353, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.664, mean reward: 0.587 [0.499, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.065, 10.098], loss: 0.001602, mae: 0.043537, mean_q: 1.167875
 535400/1000000: episode: 5354, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.693, mean reward: 0.567 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.203, 10.098], loss: 0.001455, mae: 0.041628, mean_q: 1.169293
 535500/1000000: episode: 5355, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 59.606, mean reward: 0.596 [0.505, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.801, 10.186], loss: 0.001430, mae: 0.041350, mean_q: 1.169022
 535600/1000000: episode: 5356, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.075, mean reward: 0.571 [0.505, 0.664], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.919, 10.143], loss: 0.001386, mae: 0.040576, mean_q: 1.167587
 535700/1000000: episode: 5357, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 61.026, mean reward: 0.610 [0.503, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.562, 10.098], loss: 0.001461, mae: 0.042107, mean_q: 1.169195
 535800/1000000: episode: 5358, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 61.393, mean reward: 0.614 [0.500, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.192, 10.561], loss: 0.001443, mae: 0.041264, mean_q: 1.166593
 535900/1000000: episode: 5359, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.848, mean reward: 0.598 [0.503, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.259, 10.355], loss: 0.001482, mae: 0.041773, mean_q: 1.170752
 536000/1000000: episode: 5360, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.356, mean reward: 0.584 [0.502, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.455, 10.098], loss: 0.001518, mae: 0.042036, mean_q: 1.173388
 536100/1000000: episode: 5361, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 60.329, mean reward: 0.603 [0.519, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.367, 10.475], loss: 0.001463, mae: 0.041940, mean_q: 1.170767
 536200/1000000: episode: 5362, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.088, mean reward: 0.581 [0.501, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.908, 10.108], loss: 0.001486, mae: 0.041936, mean_q: 1.164674
 536300/1000000: episode: 5363, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.063, mean reward: 0.581 [0.502, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.677, 10.098], loss: 0.001501, mae: 0.041967, mean_q: 1.168024
 536400/1000000: episode: 5364, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 61.012, mean reward: 0.610 [0.516, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.869, 10.098], loss: 0.001613, mae: 0.042867, mean_q: 1.169560
 536500/1000000: episode: 5365, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.139, mean reward: 0.571 [0.503, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.659, 10.102], loss: 0.001425, mae: 0.040807, mean_q: 1.169822
 536600/1000000: episode: 5366, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.682, mean reward: 0.577 [0.510, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.734, 10.098], loss: 0.001563, mae: 0.042120, mean_q: 1.167202
 536700/1000000: episode: 5367, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.928, mean reward: 0.579 [0.508, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.331, 10.147], loss: 0.001546, mae: 0.042720, mean_q: 1.168130
 536800/1000000: episode: 5368, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.699, mean reward: 0.577 [0.503, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.380, 10.199], loss: 0.001436, mae: 0.040673, mean_q: 1.168951
 536900/1000000: episode: 5369, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.984, mean reward: 0.600 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.394, 10.379], loss: 0.001445, mae: 0.041445, mean_q: 1.164573
 537000/1000000: episode: 5370, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.901, mean reward: 0.609 [0.506, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.480, 10.308], loss: 0.001448, mae: 0.041233, mean_q: 1.168314
 537100/1000000: episode: 5371, duration: 0.639s, episode steps: 100, steps per second: 156, episode reward: 58.899, mean reward: 0.589 [0.509, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.446, 10.098], loss: 0.001453, mae: 0.041145, mean_q: 1.168926
 537200/1000000: episode: 5372, duration: 0.646s, episode steps: 100, steps per second: 155, episode reward: 62.089, mean reward: 0.621 [0.505, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.859, 10.098], loss: 0.001419, mae: 0.040564, mean_q: 1.167069
 537300/1000000: episode: 5373, duration: 0.654s, episode steps: 100, steps per second: 153, episode reward: 58.805, mean reward: 0.588 [0.504, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.562, 10.274], loss: 0.001521, mae: 0.042235, mean_q: 1.172206
 537400/1000000: episode: 5374, duration: 0.646s, episode steps: 100, steps per second: 155, episode reward: 59.217, mean reward: 0.592 [0.510, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.316, 10.098], loss: 0.001408, mae: 0.041085, mean_q: 1.169987
 537500/1000000: episode: 5375, duration: 0.655s, episode steps: 100, steps per second: 153, episode reward: 59.566, mean reward: 0.596 [0.502, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.527, 10.135], loss: 0.001443, mae: 0.040850, mean_q: 1.173486
 537600/1000000: episode: 5376, duration: 0.645s, episode steps: 100, steps per second: 155, episode reward: 57.500, mean reward: 0.575 [0.501, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.212, 10.136], loss: 0.001449, mae: 0.040821, mean_q: 1.171149
 537700/1000000: episode: 5377, duration: 0.677s, episode steps: 100, steps per second: 148, episode reward: 58.173, mean reward: 0.582 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.455, 10.245], loss: 0.001492, mae: 0.041580, mean_q: 1.171402
 537800/1000000: episode: 5378, duration: 0.625s, episode steps: 100, steps per second: 160, episode reward: 59.284, mean reward: 0.593 [0.515, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.374, 10.221], loss: 0.001560, mae: 0.042991, mean_q: 1.174158
 537900/1000000: episode: 5379, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 60.156, mean reward: 0.602 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.035, 10.211], loss: 0.001550, mae: 0.042285, mean_q: 1.172579
 538000/1000000: episode: 5380, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.913, mean reward: 0.589 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.396, 10.098], loss: 0.001503, mae: 0.041663, mean_q: 1.173593
 538100/1000000: episode: 5381, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.523, mean reward: 0.585 [0.512, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.980, 10.155], loss: 0.001451, mae: 0.040925, mean_q: 1.171096
 538200/1000000: episode: 5382, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 64.277, mean reward: 0.643 [0.507, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.892, 10.350], loss: 0.001459, mae: 0.041164, mean_q: 1.170546
 538300/1000000: episode: 5383, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.652, mean reward: 0.577 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.774, 10.377], loss: 0.001376, mae: 0.040352, mean_q: 1.173667
 538400/1000000: episode: 5384, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.456, mean reward: 0.595 [0.506, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.412, 10.123], loss: 0.001375, mae: 0.040328, mean_q: 1.172799
 538500/1000000: episode: 5385, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.646, mean reward: 0.596 [0.513, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.568, 10.104], loss: 0.001490, mae: 0.042256, mean_q: 1.171988
 538600/1000000: episode: 5386, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 62.075, mean reward: 0.621 [0.517, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.350, 10.235], loss: 0.001608, mae: 0.042981, mean_q: 1.175500
 538700/1000000: episode: 5387, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.191, mean reward: 0.582 [0.505, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.502, 10.192], loss: 0.001475, mae: 0.041516, mean_q: 1.175759
 538800/1000000: episode: 5388, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.378, mean reward: 0.584 [0.501, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.914, 10.213], loss: 0.001535, mae: 0.042091, mean_q: 1.174326
 538900/1000000: episode: 5389, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.809, mean reward: 0.578 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.720, 10.265], loss: 0.001493, mae: 0.041323, mean_q: 1.171403
 539000/1000000: episode: 5390, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.917, mean reward: 0.579 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.884, 10.268], loss: 0.001556, mae: 0.042529, mean_q: 1.172817
 539100/1000000: episode: 5391, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.906, mean reward: 0.579 [0.503, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.136, 10.098], loss: 0.001500, mae: 0.041554, mean_q: 1.173512
 539200/1000000: episode: 5392, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.254, mean reward: 0.583 [0.508, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.595, 10.098], loss: 0.001419, mae: 0.041038, mean_q: 1.175165
 539300/1000000: episode: 5393, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.493, mean reward: 0.575 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.267, 10.151], loss: 0.001500, mae: 0.041834, mean_q: 1.167519
 539400/1000000: episode: 5394, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.027, mean reward: 0.560 [0.500, 0.655], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.401, 10.136], loss: 0.001505, mae: 0.041990, mean_q: 1.169230
 539500/1000000: episode: 5395, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.647, mean reward: 0.616 [0.505, 0.903], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.267, 10.371], loss: 0.001535, mae: 0.041767, mean_q: 1.170596
 539600/1000000: episode: 5396, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.993, mean reward: 0.580 [0.500, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.338, 10.136], loss: 0.001506, mae: 0.041827, mean_q: 1.172414
 539700/1000000: episode: 5397, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.131, mean reward: 0.591 [0.506, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.942, 10.098], loss: 0.001461, mae: 0.041264, mean_q: 1.168603
 539800/1000000: episode: 5398, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.976, mean reward: 0.580 [0.500, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.440, 10.164], loss: 0.001522, mae: 0.042192, mean_q: 1.168368
 539900/1000000: episode: 5399, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.476, mean reward: 0.575 [0.502, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.318, 10.128], loss: 0.001598, mae: 0.043284, mean_q: 1.166539
 540000/1000000: episode: 5400, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.505, mean reward: 0.585 [0.506, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.340, 10.098], loss: 0.001507, mae: 0.041701, mean_q: 1.167812
 540100/1000000: episode: 5401, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 62.912, mean reward: 0.629 [0.510, 0.843], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.087, 10.098], loss: 0.001403, mae: 0.040533, mean_q: 1.168307
 540200/1000000: episode: 5402, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 63.447, mean reward: 0.634 [0.504, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.092, 10.482], loss: 0.001408, mae: 0.040371, mean_q: 1.166703
 540300/1000000: episode: 5403, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 62.199, mean reward: 0.622 [0.504, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.300, 10.098], loss: 0.001524, mae: 0.041965, mean_q: 1.172216
 540400/1000000: episode: 5404, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.859, mean reward: 0.579 [0.502, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.119, 10.098], loss: 0.001458, mae: 0.041467, mean_q: 1.173099
 540500/1000000: episode: 5405, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.758, mean reward: 0.598 [0.502, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.258, 10.375], loss: 0.001589, mae: 0.043026, mean_q: 1.176512
 540600/1000000: episode: 5406, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.258, mean reward: 0.613 [0.507, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.209, 10.160], loss: 0.001574, mae: 0.042886, mean_q: 1.177933
 540700/1000000: episode: 5407, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.428, mean reward: 0.584 [0.508, 0.879], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.621, 10.098], loss: 0.001431, mae: 0.039726, mean_q: 1.171554
 540800/1000000: episode: 5408, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.451, mean reward: 0.585 [0.506, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.225, 10.098], loss: 0.001453, mae: 0.041102, mean_q: 1.172339
 540900/1000000: episode: 5409, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.923, mean reward: 0.599 [0.506, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.822, 10.329], loss: 0.001542, mae: 0.042305, mean_q: 1.174361
 541000/1000000: episode: 5410, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.878, mean reward: 0.579 [0.501, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.857, 10.098], loss: 0.001531, mae: 0.041728, mean_q: 1.170928
 541100/1000000: episode: 5411, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.632, mean reward: 0.586 [0.512, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.285, 10.102], loss: 0.001586, mae: 0.043333, mean_q: 1.175810
 541200/1000000: episode: 5412, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.558, mean reward: 0.586 [0.505, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.624, 10.248], loss: 0.001721, mae: 0.044972, mean_q: 1.170927
 541300/1000000: episode: 5413, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.760, mean reward: 0.578 [0.502, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.244, 10.098], loss: 0.001578, mae: 0.042373, mean_q: 1.172522
 541400/1000000: episode: 5414, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 66.059, mean reward: 0.661 [0.508, 0.846], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.161, 10.489], loss: 0.001622, mae: 0.043374, mean_q: 1.172648
 541500/1000000: episode: 5415, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.586, mean reward: 0.616 [0.512, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.906, 10.098], loss: 0.001514, mae: 0.041961, mean_q: 1.170493
 541600/1000000: episode: 5416, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.798, mean reward: 0.608 [0.503, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.080, 10.098], loss: 0.001545, mae: 0.042423, mean_q: 1.174366
 541700/1000000: episode: 5417, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.262, mean reward: 0.603 [0.507, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.881, 10.144], loss: 0.001550, mae: 0.042739, mean_q: 1.178676
 541800/1000000: episode: 5418, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.652, mean reward: 0.587 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.579, 10.295], loss: 0.001571, mae: 0.043028, mean_q: 1.178130
 541900/1000000: episode: 5419, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.756, mean reward: 0.588 [0.503, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.301, 10.131], loss: 0.001518, mae: 0.042684, mean_q: 1.176971
 542000/1000000: episode: 5420, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.596, mean reward: 0.586 [0.505, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.835, 10.237], loss: 0.001604, mae: 0.043182, mean_q: 1.178253
 542100/1000000: episode: 5421, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.857, mean reward: 0.589 [0.521, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.791, 10.242], loss: 0.001623, mae: 0.043609, mean_q: 1.177860
 542200/1000000: episode: 5422, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.800, mean reward: 0.578 [0.499, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.574, 10.101], loss: 0.001504, mae: 0.041502, mean_q: 1.177289
 542300/1000000: episode: 5423, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.328, mean reward: 0.573 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.795, 10.098], loss: 0.001557, mae: 0.043246, mean_q: 1.176519
 542400/1000000: episode: 5424, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.413, mean reward: 0.594 [0.499, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.201, 10.098], loss: 0.001516, mae: 0.042519, mean_q: 1.178177
 542500/1000000: episode: 5425, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.699, mean reward: 0.627 [0.516, 0.854], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.133, 10.258], loss: 0.001443, mae: 0.041173, mean_q: 1.172207
 542600/1000000: episode: 5426, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.414, mean reward: 0.584 [0.512, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.440, 10.098], loss: 0.001551, mae: 0.042520, mean_q: 1.174787
 542700/1000000: episode: 5427, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.356, mean reward: 0.574 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.152, 10.098], loss: 0.001513, mae: 0.042158, mean_q: 1.171900
 542800/1000000: episode: 5428, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 62.294, mean reward: 0.623 [0.517, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.734, 10.351], loss: 0.001478, mae: 0.041168, mean_q: 1.175325
 542900/1000000: episode: 5429, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.623, mean reward: 0.586 [0.511, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.555, 10.298], loss: 0.001525, mae: 0.042569, mean_q: 1.176045
 543000/1000000: episode: 5430, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.136, mean reward: 0.581 [0.501, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.263, 10.098], loss: 0.001524, mae: 0.042790, mean_q: 1.177323
 543100/1000000: episode: 5431, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 62.432, mean reward: 0.624 [0.509, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.433, 10.316], loss: 0.001579, mae: 0.042427, mean_q: 1.176353
 543200/1000000: episode: 5432, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 60.898, mean reward: 0.609 [0.514, 0.863], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-1.547, 10.098], loss: 0.001560, mae: 0.042512, mean_q: 1.171834
 543300/1000000: episode: 5433, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.178, mean reward: 0.592 [0.499, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.391, 10.250], loss: 0.001582, mae: 0.042931, mean_q: 1.177424
 543400/1000000: episode: 5434, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.389, mean reward: 0.594 [0.505, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.873, 10.102], loss: 0.001554, mae: 0.042440, mean_q: 1.173795
 543500/1000000: episode: 5435, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.493, mean reward: 0.575 [0.498, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.265, 10.144], loss: 0.001633, mae: 0.043779, mean_q: 1.172927
 543600/1000000: episode: 5436, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.337, mean reward: 0.593 [0.505, 0.843], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.789, 10.262], loss: 0.001659, mae: 0.043486, mean_q: 1.173085
 543700/1000000: episode: 5437, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.449, mean reward: 0.594 [0.508, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.316, 10.106], loss: 0.001573, mae: 0.042751, mean_q: 1.174032
 543800/1000000: episode: 5438, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.239, mean reward: 0.612 [0.516, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.803, 10.184], loss: 0.001684, mae: 0.043575, mean_q: 1.174664
 543900/1000000: episode: 5439, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.754, mean reward: 0.568 [0.505, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.945, 10.098], loss: 0.001673, mae: 0.043948, mean_q: 1.177678
 544000/1000000: episode: 5440, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.865, mean reward: 0.589 [0.497, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.689, 10.287], loss: 0.001638, mae: 0.043324, mean_q: 1.179329
 544100/1000000: episode: 5441, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.385, mean reward: 0.574 [0.508, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.957, 10.101], loss: 0.001700, mae: 0.044239, mean_q: 1.178912
 544200/1000000: episode: 5442, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 56.926, mean reward: 0.569 [0.499, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.827, 10.098], loss: 0.001631, mae: 0.043268, mean_q: 1.176960
 544300/1000000: episode: 5443, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.118, mean reward: 0.591 [0.499, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.833, 10.202], loss: 0.001539, mae: 0.042015, mean_q: 1.175156
 544400/1000000: episode: 5444, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.539, mean reward: 0.575 [0.511, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.430, 10.303], loss: 0.001518, mae: 0.042497, mean_q: 1.175581
 544500/1000000: episode: 5445, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.695, mean reward: 0.587 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.733, 10.231], loss: 0.001518, mae: 0.042257, mean_q: 1.172997
 544600/1000000: episode: 5446, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.858, mean reward: 0.609 [0.505, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.260, 10.098], loss: 0.001581, mae: 0.042615, mean_q: 1.172789
 544700/1000000: episode: 5447, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.633, mean reward: 0.596 [0.510, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.272, 10.236], loss: 0.001529, mae: 0.042160, mean_q: 1.175447
 544800/1000000: episode: 5448, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.037, mean reward: 0.570 [0.501, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.308, 10.110], loss: 0.001540, mae: 0.042507, mean_q: 1.177093
 544900/1000000: episode: 5449, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.261, mean reward: 0.603 [0.505, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.398, 10.360], loss: 0.001546, mae: 0.042773, mean_q: 1.177502
 545000/1000000: episode: 5450, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 60.321, mean reward: 0.603 [0.517, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-2.836, 10.190], loss: 0.001571, mae: 0.043017, mean_q: 1.176685
 545100/1000000: episode: 5451, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.827, mean reward: 0.578 [0.508, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.722, 10.241], loss: 0.001626, mae: 0.043713, mean_q: 1.175766
 545200/1000000: episode: 5452, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 56.462, mean reward: 0.565 [0.509, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.655, 10.098], loss: 0.001607, mae: 0.043195, mean_q: 1.173591
 545300/1000000: episode: 5453, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.439, mean reward: 0.584 [0.501, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.916, 10.218], loss: 0.001586, mae: 0.043186, mean_q: 1.171749
 545400/1000000: episode: 5454, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.618, mean reward: 0.576 [0.506, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.275, 10.381], loss: 0.001662, mae: 0.044154, mean_q: 1.175660
 545500/1000000: episode: 5455, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.641, mean reward: 0.586 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.136, 10.098], loss: 0.001635, mae: 0.043167, mean_q: 1.172296
 545600/1000000: episode: 5456, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.911, mean reward: 0.579 [0.507, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.769, 10.098], loss: 0.001520, mae: 0.041858, mean_q: 1.168703
 545700/1000000: episode: 5457, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.730, mean reward: 0.577 [0.505, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.978, 10.251], loss: 0.001612, mae: 0.043022, mean_q: 1.170822
 545800/1000000: episode: 5458, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 63.239, mean reward: 0.632 [0.502, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.548, 10.427], loss: 0.001697, mae: 0.044996, mean_q: 1.169025
 545900/1000000: episode: 5459, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.040, mean reward: 0.580 [0.503, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.513, 10.165], loss: 0.001594, mae: 0.043157, mean_q: 1.172133
 546000/1000000: episode: 5460, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.061, mean reward: 0.591 [0.505, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.672, 10.513], loss: 0.001519, mae: 0.042386, mean_q: 1.174754
 546100/1000000: episode: 5461, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.693, mean reward: 0.587 [0.499, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.043, 10.098], loss: 0.001560, mae: 0.042867, mean_q: 1.172825
 546200/1000000: episode: 5462, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.306, mean reward: 0.603 [0.524, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.790, 10.250], loss: 0.001616, mae: 0.043524, mean_q: 1.173573
 546300/1000000: episode: 5463, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.106, mean reward: 0.571 [0.504, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.502, 10.238], loss: 0.001660, mae: 0.043880, mean_q: 1.174707
 546400/1000000: episode: 5464, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.126, mean reward: 0.581 [0.502, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.404, 10.098], loss: 0.001617, mae: 0.043399, mean_q: 1.170163
 546500/1000000: episode: 5465, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.173, mean reward: 0.572 [0.501, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.795, 10.098], loss: 0.001505, mae: 0.041899, mean_q: 1.169335
 546600/1000000: episode: 5466, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.265, mean reward: 0.593 [0.511, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.947, 10.098], loss: 0.001628, mae: 0.043825, mean_q: 1.166335
 546700/1000000: episode: 5467, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 61.493, mean reward: 0.615 [0.511, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.401, 10.098], loss: 0.001589, mae: 0.042521, mean_q: 1.165154
 546800/1000000: episode: 5468, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 62.499, mean reward: 0.625 [0.511, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.436, 10.098], loss: 0.001574, mae: 0.042697, mean_q: 1.165927
 546900/1000000: episode: 5469, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.686, mean reward: 0.587 [0.505, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.316, 10.116], loss: 0.001505, mae: 0.042299, mean_q: 1.166303
 547000/1000000: episode: 5470, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.161, mean reward: 0.582 [0.500, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.416, 10.098], loss: 0.001413, mae: 0.041070, mean_q: 1.165446
 547100/1000000: episode: 5471, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.189, mean reward: 0.582 [0.500, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.679, 10.214], loss: 0.001524, mae: 0.041945, mean_q: 1.168040
 547200/1000000: episode: 5472, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.983, mean reward: 0.570 [0.510, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.625, 10.098], loss: 0.001492, mae: 0.042151, mean_q: 1.169965
 547300/1000000: episode: 5473, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.866, mean reward: 0.569 [0.502, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.396, 10.098], loss: 0.001440, mae: 0.041086, mean_q: 1.165394
 547400/1000000: episode: 5474, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.112, mean reward: 0.621 [0.504, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.104, 10.571], loss: 0.001545, mae: 0.042409, mean_q: 1.165692
 547500/1000000: episode: 5475, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.654, mean reward: 0.607 [0.503, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.351, 10.098], loss: 0.001469, mae: 0.041911, mean_q: 1.165161
 547600/1000000: episode: 5476, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.933, mean reward: 0.579 [0.500, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.169, 10.098], loss: 0.001512, mae: 0.042162, mean_q: 1.165093
 547700/1000000: episode: 5477, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.891, mean reward: 0.609 [0.499, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.243, 10.098], loss: 0.001447, mae: 0.041633, mean_q: 1.165511
 547800/1000000: episode: 5478, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 61.151, mean reward: 0.612 [0.508, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.088, 10.433], loss: 0.001504, mae: 0.041909, mean_q: 1.166027
 547900/1000000: episode: 5479, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.484, mean reward: 0.585 [0.504, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.385, 10.098], loss: 0.001482, mae: 0.041950, mean_q: 1.165821
 548000/1000000: episode: 5480, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.321, mean reward: 0.583 [0.505, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.071, 10.108], loss: 0.001593, mae: 0.043365, mean_q: 1.168090
 548100/1000000: episode: 5481, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 62.218, mean reward: 0.622 [0.499, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.445, 10.419], loss: 0.001572, mae: 0.042756, mean_q: 1.166234
 548200/1000000: episode: 5482, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.560, mean reward: 0.606 [0.512, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.945, 10.098], loss: 0.001445, mae: 0.041541, mean_q: 1.168160
 548300/1000000: episode: 5483, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.502, mean reward: 0.605 [0.507, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.521, 10.449], loss: 0.001487, mae: 0.041458, mean_q: 1.169105
 548400/1000000: episode: 5484, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.190, mean reward: 0.602 [0.510, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.827, 10.378], loss: 0.001466, mae: 0.041686, mean_q: 1.167729
 548500/1000000: episode: 5485, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.701, mean reward: 0.587 [0.500, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.737, 10.098], loss: 0.001567, mae: 0.042271, mean_q: 1.169749
 548600/1000000: episode: 5486, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.724, mean reward: 0.597 [0.510, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.409 [-1.228, 10.098], loss: 0.001442, mae: 0.041391, mean_q: 1.170035
 548700/1000000: episode: 5487, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.973, mean reward: 0.580 [0.504, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.182, 10.109], loss: 0.001431, mae: 0.041449, mean_q: 1.170364
 548800/1000000: episode: 5488, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.529, mean reward: 0.595 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.827, 10.098], loss: 0.001466, mae: 0.041624, mean_q: 1.165461
 548900/1000000: episode: 5489, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 60.551, mean reward: 0.606 [0.498, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.913, 10.350], loss: 0.001427, mae: 0.041307, mean_q: 1.170138
 549000/1000000: episode: 5490, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.478, mean reward: 0.585 [0.505, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.061, 10.175], loss: 0.001481, mae: 0.042147, mean_q: 1.169419
 549100/1000000: episode: 5491, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.410, mean reward: 0.594 [0.509, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.828, 10.165], loss: 0.001470, mae: 0.041832, mean_q: 1.170971
 549200/1000000: episode: 5492, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.653, mean reward: 0.577 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.856, 10.098], loss: 0.001500, mae: 0.042114, mean_q: 1.169631
 549300/1000000: episode: 5493, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.696, mean reward: 0.577 [0.501, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.182, 10.098], loss: 0.001537, mae: 0.043033, mean_q: 1.173155
 549400/1000000: episode: 5494, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.224, mean reward: 0.582 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.651, 10.098], loss: 0.001402, mae: 0.040830, mean_q: 1.172176
 549500/1000000: episode: 5495, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.695, mean reward: 0.607 [0.508, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.998, 10.129], loss: 0.001390, mae: 0.040803, mean_q: 1.169798
 549600/1000000: episode: 5496, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.883, mean reward: 0.599 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.845, 10.143], loss: 0.001436, mae: 0.041210, mean_q: 1.171646
 549700/1000000: episode: 5497, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.740, mean reward: 0.577 [0.503, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.046, 10.308], loss: 0.001420, mae: 0.041032, mean_q: 1.168814
 549800/1000000: episode: 5498, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.902, mean reward: 0.589 [0.499, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.727, 10.233], loss: 0.001485, mae: 0.042217, mean_q: 1.167099
 549900/1000000: episode: 5499, duration: 0.781s, episode steps: 100, steps per second: 128, episode reward: 59.000, mean reward: 0.590 [0.497, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.823, 10.098], loss: 0.001467, mae: 0.042110, mean_q: 1.170909
 550000/1000000: episode: 5500, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.339, mean reward: 0.593 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.628, 10.098], loss: 0.001469, mae: 0.041929, mean_q: 1.170386
 550100/1000000: episode: 5501, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 63.645, mean reward: 0.636 [0.515, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.861, 10.451], loss: 0.001503, mae: 0.042574, mean_q: 1.170234
 550200/1000000: episode: 5502, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.614, mean reward: 0.576 [0.504, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.948, 10.098], loss: 0.001484, mae: 0.042071, mean_q: 1.177288
 550300/1000000: episode: 5503, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.825, mean reward: 0.578 [0.499, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.571, 10.098], loss: 0.001501, mae: 0.042242, mean_q: 1.167761
 550400/1000000: episode: 5504, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 62.333, mean reward: 0.623 [0.509, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.516, 10.098], loss: 0.001462, mae: 0.041709, mean_q: 1.172566
 550500/1000000: episode: 5505, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.312, mean reward: 0.573 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.462, 10.378], loss: 0.001478, mae: 0.042158, mean_q: 1.173706
 550600/1000000: episode: 5506, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.586, mean reward: 0.576 [0.507, 0.662], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.248, 10.159], loss: 0.001468, mae: 0.041845, mean_q: 1.174111
 550700/1000000: episode: 5507, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 61.985, mean reward: 0.620 [0.499, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.245, 10.098], loss: 0.001466, mae: 0.041181, mean_q: 1.172871
 550800/1000000: episode: 5508, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.245, mean reward: 0.592 [0.504, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.025, 10.156], loss: 0.001406, mae: 0.040649, mean_q: 1.174007
 550900/1000000: episode: 5509, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 57.020, mean reward: 0.570 [0.499, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.491, 10.185], loss: 0.001382, mae: 0.040554, mean_q: 1.171317
 551000/1000000: episode: 5510, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.854, mean reward: 0.589 [0.510, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.186, 10.249], loss: 0.001445, mae: 0.041600, mean_q: 1.173472
 551100/1000000: episode: 5511, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.569, mean reward: 0.596 [0.499, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.972, 10.098], loss: 0.001466, mae: 0.041733, mean_q: 1.175676
 551200/1000000: episode: 5512, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 60.834, mean reward: 0.608 [0.499, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.928, 10.218], loss: 0.001486, mae: 0.041618, mean_q: 1.171458
 551300/1000000: episode: 5513, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.213, mean reward: 0.592 [0.504, 0.898], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.502, 10.150], loss: 0.001575, mae: 0.043627, mean_q: 1.172606
 551400/1000000: episode: 5514, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 60.208, mean reward: 0.602 [0.498, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.461, 10.098], loss: 0.001520, mae: 0.042339, mean_q: 1.175557
 551500/1000000: episode: 5515, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 55.563, mean reward: 0.556 [0.499, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.587, 10.098], loss: 0.001537, mae: 0.042360, mean_q: 1.175682
 551600/1000000: episode: 5516, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 66.825, mean reward: 0.668 [0.519, 0.876], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.557, 10.098], loss: 0.001663, mae: 0.043678, mean_q: 1.173895
 551700/1000000: episode: 5517, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.310, mean reward: 0.613 [0.505, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.477, 10.098], loss: 0.001522, mae: 0.042541, mean_q: 1.178318
 551800/1000000: episode: 5518, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.410, mean reward: 0.594 [0.510, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.677, 10.354], loss: 0.001597, mae: 0.043329, mean_q: 1.179229
 551900/1000000: episode: 5519, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.503, mean reward: 0.575 [0.507, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.609, 10.311], loss: 0.001672, mae: 0.044621, mean_q: 1.176947
 552000/1000000: episode: 5520, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.984, mean reward: 0.590 [0.505, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.280, 10.108], loss: 0.001503, mae: 0.042435, mean_q: 1.174795
 552100/1000000: episode: 5521, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.335, mean reward: 0.583 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.323, 10.221], loss: 0.001533, mae: 0.042646, mean_q: 1.175076
 552200/1000000: episode: 5522, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.125, mean reward: 0.601 [0.510, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.273, 10.098], loss: 0.001609, mae: 0.043674, mean_q: 1.177977
 552300/1000000: episode: 5523, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.741, mean reward: 0.607 [0.518, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.863, 10.225], loss: 0.001589, mae: 0.043313, mean_q: 1.179023
 552400/1000000: episode: 5524, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.907, mean reward: 0.599 [0.511, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.782, 10.098], loss: 0.001509, mae: 0.042341, mean_q: 1.178651
 552500/1000000: episode: 5525, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.754, mean reward: 0.578 [0.519, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.266, 10.098], loss: 0.001667, mae: 0.044618, mean_q: 1.179145
 552600/1000000: episode: 5526, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 63.944, mean reward: 0.639 [0.508, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.523, 10.486], loss: 0.001505, mae: 0.042130, mean_q: 1.178310
 552700/1000000: episode: 5527, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.100, mean reward: 0.581 [0.500, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.692, 10.098], loss: 0.001531, mae: 0.042026, mean_q: 1.180048
 552800/1000000: episode: 5528, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.490, mean reward: 0.575 [0.497, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.298, 10.227], loss: 0.001451, mae: 0.041244, mean_q: 1.175368
 552900/1000000: episode: 5529, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.464, mean reward: 0.595 [0.505, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.288, 10.226], loss: 0.001432, mae: 0.040966, mean_q: 1.174473
 553000/1000000: episode: 5530, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.969, mean reward: 0.580 [0.502, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.083, 10.285], loss: 0.001460, mae: 0.041415, mean_q: 1.174844
 553100/1000000: episode: 5531, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.759, mean reward: 0.598 [0.512, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.841, 10.098], loss: 0.001501, mae: 0.041902, mean_q: 1.176106
 553200/1000000: episode: 5532, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.044, mean reward: 0.600 [0.502, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.654, 10.098], loss: 0.001498, mae: 0.042682, mean_q: 1.174916
 553300/1000000: episode: 5533, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.449, mean reward: 0.614 [0.503, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.717, 10.098], loss: 0.001538, mae: 0.043050, mean_q: 1.176873
 553400/1000000: episode: 5534, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.163, mean reward: 0.582 [0.498, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.798, 10.098], loss: 0.001520, mae: 0.042425, mean_q: 1.173508
 553500/1000000: episode: 5535, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.349, mean reward: 0.593 [0.505, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.662, 10.353], loss: 0.001546, mae: 0.042591, mean_q: 1.177690
 553600/1000000: episode: 5536, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 69.529, mean reward: 0.695 [0.514, 0.956], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.915, 10.629], loss: 0.001528, mae: 0.042164, mean_q: 1.181920
 553700/1000000: episode: 5537, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.480, mean reward: 0.595 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.500, 10.303], loss: 0.001496, mae: 0.042202, mean_q: 1.180360
 553800/1000000: episode: 5538, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.858, mean reward: 0.579 [0.501, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.799, 10.145], loss: 0.001523, mae: 0.042077, mean_q: 1.179164
 553900/1000000: episode: 5539, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 63.960, mean reward: 0.640 [0.513, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.121, 10.338], loss: 0.001533, mae: 0.042485, mean_q: 1.180533
 554000/1000000: episode: 5540, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.427, mean reward: 0.584 [0.502, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.436, 10.098], loss: 0.001423, mae: 0.041131, mean_q: 1.180403
 554100/1000000: episode: 5541, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 60.263, mean reward: 0.603 [0.500, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.897, 10.098], loss: 0.001582, mae: 0.043310, mean_q: 1.180733
 554200/1000000: episode: 5542, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.702, mean reward: 0.587 [0.506, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.310, 10.281], loss: 0.001496, mae: 0.042134, mean_q: 1.182484
 554300/1000000: episode: 5543, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.814, mean reward: 0.568 [0.503, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.597, 10.098], loss: 0.001558, mae: 0.042564, mean_q: 1.182625
 554400/1000000: episode: 5544, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.042, mean reward: 0.580 [0.514, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.301, 10.250], loss: 0.001506, mae: 0.041505, mean_q: 1.183743
 554500/1000000: episode: 5545, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.890, mean reward: 0.579 [0.511, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.901, 10.170], loss: 0.001474, mae: 0.041946, mean_q: 1.182253
 554600/1000000: episode: 5546, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.733, mean reward: 0.567 [0.499, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.764, 10.169], loss: 0.001371, mae: 0.040450, mean_q: 1.179975
 554700/1000000: episode: 5547, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.500, mean reward: 0.585 [0.498, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.376, 10.098], loss: 0.001563, mae: 0.042284, mean_q: 1.179380
 554800/1000000: episode: 5548, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.239, mean reward: 0.572 [0.504, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.688, 10.154], loss: 0.001547, mae: 0.041965, mean_q: 1.181890
 554900/1000000: episode: 5549, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.690, mean reward: 0.587 [0.501, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.737, 10.143], loss: 0.001539, mae: 0.042208, mean_q: 1.182466
 555000/1000000: episode: 5550, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 64.145, mean reward: 0.641 [0.500, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.672, 10.098], loss: 0.001478, mae: 0.042011, mean_q: 1.179960
 555100/1000000: episode: 5551, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.140, mean reward: 0.601 [0.509, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.442, 10.173], loss: 0.001468, mae: 0.041053, mean_q: 1.183063
 555200/1000000: episode: 5552, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.233, mean reward: 0.592 [0.509, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.027, 10.098], loss: 0.001571, mae: 0.042778, mean_q: 1.181483
 555300/1000000: episode: 5553, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.564, mean reward: 0.566 [0.504, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.821, 10.180], loss: 0.001387, mae: 0.040276, mean_q: 1.178725
 555400/1000000: episode: 5554, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 56.981, mean reward: 0.570 [0.499, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.539, 10.249], loss: 0.001502, mae: 0.041509, mean_q: 1.177896
 555500/1000000: episode: 5555, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.691, mean reward: 0.577 [0.498, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.319, 10.138], loss: 0.001417, mae: 0.041013, mean_q: 1.178995
 555600/1000000: episode: 5556, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.738, mean reward: 0.587 [0.511, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.949, 10.098], loss: 0.001447, mae: 0.041270, mean_q: 1.178145
 555700/1000000: episode: 5557, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.738, mean reward: 0.587 [0.501, 0.942], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.396, 10.135], loss: 0.001434, mae: 0.040580, mean_q: 1.180584
 555800/1000000: episode: 5558, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.754, mean reward: 0.598 [0.504, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.634, 10.098], loss: 0.001441, mae: 0.041163, mean_q: 1.177913
 555900/1000000: episode: 5559, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.242, mean reward: 0.612 [0.498, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.230, 10.159], loss: 0.001486, mae: 0.041209, mean_q: 1.178796
 556000/1000000: episode: 5560, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.092, mean reward: 0.601 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.421, 10.111], loss: 0.001612, mae: 0.042962, mean_q: 1.181335
 556100/1000000: episode: 5561, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.617, mean reward: 0.586 [0.504, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.195, 10.098], loss: 0.001529, mae: 0.042380, mean_q: 1.180933
 556200/1000000: episode: 5562, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 56.458, mean reward: 0.565 [0.501, 0.661], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.605, 10.098], loss: 0.001497, mae: 0.041476, mean_q: 1.177750
 556300/1000000: episode: 5563, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.949, mean reward: 0.589 [0.510, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.181, 10.174], loss: 0.001464, mae: 0.041417, mean_q: 1.182621
 556400/1000000: episode: 5564, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.518, mean reward: 0.615 [0.521, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.443, 10.098], loss: 0.001423, mae: 0.040812, mean_q: 1.174958
 556500/1000000: episode: 5565, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.210, mean reward: 0.572 [0.498, 0.893], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.821, 10.098], loss: 0.001514, mae: 0.042192, mean_q: 1.178017
 556600/1000000: episode: 5566, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.428, mean reward: 0.584 [0.498, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.926, 10.098], loss: 0.001462, mae: 0.041748, mean_q: 1.175162
 556700/1000000: episode: 5567, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.876, mean reward: 0.589 [0.508, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.078, 10.196], loss: 0.001272, mae: 0.039077, mean_q: 1.172574
 556800/1000000: episode: 5568, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.778, mean reward: 0.598 [0.502, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.861, 10.098], loss: 0.001461, mae: 0.041091, mean_q: 1.169400
 556900/1000000: episode: 5569, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.808, mean reward: 0.588 [0.502, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.308, 10.264], loss: 0.001511, mae: 0.041905, mean_q: 1.175106
 557000/1000000: episode: 5570, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.606, mean reward: 0.576 [0.501, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.547, 10.098], loss: 0.001519, mae: 0.041990, mean_q: 1.174932
 557100/1000000: episode: 5571, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.334, mean reward: 0.593 [0.507, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.175, 10.197], loss: 0.001400, mae: 0.040257, mean_q: 1.174043
 557200/1000000: episode: 5572, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.016, mean reward: 0.570 [0.503, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.778, 10.221], loss: 0.001431, mae: 0.040391, mean_q: 1.170302
 557300/1000000: episode: 5573, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.371, mean reward: 0.604 [0.510, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.654, 10.098], loss: 0.001532, mae: 0.042140, mean_q: 1.172947
 557400/1000000: episode: 5574, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.689, mean reward: 0.617 [0.504, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.694, 10.098], loss: 0.001395, mae: 0.040728, mean_q: 1.173868
 557500/1000000: episode: 5575, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.804, mean reward: 0.578 [0.504, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.624, 10.098], loss: 0.001590, mae: 0.042147, mean_q: 1.172709
 557600/1000000: episode: 5576, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 60.031, mean reward: 0.600 [0.512, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.875, 10.119], loss: 0.001476, mae: 0.041277, mean_q: 1.171906
 557700/1000000: episode: 5577, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.083, mean reward: 0.591 [0.504, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.737, 10.301], loss: 0.001537, mae: 0.042711, mean_q: 1.175191
 557800/1000000: episode: 5578, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.768, mean reward: 0.578 [0.510, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.847, 10.098], loss: 0.001365, mae: 0.040415, mean_q: 1.170396
 557900/1000000: episode: 5579, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.944, mean reward: 0.579 [0.499, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.447, 10.098], loss: 0.001482, mae: 0.042192, mean_q: 1.172766
 558000/1000000: episode: 5580, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.428, mean reward: 0.574 [0.506, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.748, 10.098], loss: 0.001386, mae: 0.040842, mean_q: 1.170391
 558100/1000000: episode: 5581, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.595, mean reward: 0.596 [0.506, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.962, 10.171], loss: 0.001390, mae: 0.040865, mean_q: 1.167182
 558200/1000000: episode: 5582, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.903, mean reward: 0.599 [0.506, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.787, 10.098], loss: 0.001391, mae: 0.040632, mean_q: 1.171640
 558300/1000000: episode: 5583, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.664, mean reward: 0.577 [0.500, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.772, 10.175], loss: 0.001542, mae: 0.042191, mean_q: 1.173224
 558400/1000000: episode: 5584, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.653, mean reward: 0.577 [0.512, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.146, 10.257], loss: 0.001328, mae: 0.039545, mean_q: 1.165789
 558500/1000000: episode: 5585, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.518, mean reward: 0.605 [0.506, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.624, 10.098], loss: 0.001457, mae: 0.041040, mean_q: 1.168236
 558600/1000000: episode: 5586, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.106, mean reward: 0.591 [0.516, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.703, 10.098], loss: 0.001421, mae: 0.041148, mean_q: 1.167006
 558700/1000000: episode: 5587, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.480, mean reward: 0.595 [0.516, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.808, 10.098], loss: 0.001406, mae: 0.040802, mean_q: 1.168461
 558800/1000000: episode: 5588, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 64.096, mean reward: 0.641 [0.517, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.837, 10.098], loss: 0.001360, mae: 0.040143, mean_q: 1.168084
 558900/1000000: episode: 5589, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.186, mean reward: 0.602 [0.499, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.824, 10.359], loss: 0.001452, mae: 0.041712, mean_q: 1.164422
 559000/1000000: episode: 5590, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.950, mean reward: 0.580 [0.501, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.577, 10.240], loss: 0.001425, mae: 0.040952, mean_q: 1.165743
 559100/1000000: episode: 5591, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.536, mean reward: 0.585 [0.505, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.490, 10.251], loss: 0.001473, mae: 0.041998, mean_q: 1.165682
 559200/1000000: episode: 5592, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.426, mean reward: 0.604 [0.503, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.212, 10.331], loss: 0.001501, mae: 0.041732, mean_q: 1.165735
 559300/1000000: episode: 5593, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.880, mean reward: 0.599 [0.501, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.342, 10.160], loss: 0.001429, mae: 0.041083, mean_q: 1.165118
 559400/1000000: episode: 5594, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.516, mean reward: 0.605 [0.501, 0.901], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.414, 10.098], loss: 0.001488, mae: 0.041727, mean_q: 1.168935
 559500/1000000: episode: 5595, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.528, mean reward: 0.595 [0.503, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.094, 10.224], loss: 0.001546, mae: 0.042612, mean_q: 1.168729
 559600/1000000: episode: 5596, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.506, mean reward: 0.595 [0.511, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.087, 10.129], loss: 0.001453, mae: 0.041468, mean_q: 1.169418
 559700/1000000: episode: 5597, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 61.870, mean reward: 0.619 [0.504, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.756, 10.098], loss: 0.001525, mae: 0.042668, mean_q: 1.170027
 559800/1000000: episode: 5598, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.123, mean reward: 0.571 [0.503, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.631, 10.273], loss: 0.001455, mae: 0.041580, mean_q: 1.174097
 559900/1000000: episode: 5599, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.346, mean reward: 0.573 [0.504, 0.639], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.321, 10.098], loss: 0.001529, mae: 0.042496, mean_q: 1.172781
 560000/1000000: episode: 5600, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.527, mean reward: 0.585 [0.506, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.170, 10.265], loss: 0.001615, mae: 0.043406, mean_q: 1.168616
 560100/1000000: episode: 5601, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.933, mean reward: 0.599 [0.506, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.986, 10.332], loss: 0.001439, mae: 0.040988, mean_q: 1.168909
 560200/1000000: episode: 5602, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.787, mean reward: 0.578 [0.508, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.670, 10.282], loss: 0.001458, mae: 0.041111, mean_q: 1.168332
 560300/1000000: episode: 5603, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.465, mean reward: 0.575 [0.500, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.640, 10.098], loss: 0.001557, mae: 0.042517, mean_q: 1.168500
 560400/1000000: episode: 5604, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.215, mean reward: 0.592 [0.508, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.978, 10.242], loss: 0.001552, mae: 0.042491, mean_q: 1.165285
 560500/1000000: episode: 5605, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.847, mean reward: 0.598 [0.504, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.854, 10.385], loss: 0.001481, mae: 0.041814, mean_q: 1.166771
 560600/1000000: episode: 5606, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.640, mean reward: 0.576 [0.500, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.726, 10.178], loss: 0.001526, mae: 0.041952, mean_q: 1.169055
 560700/1000000: episode: 5607, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 62.884, mean reward: 0.629 [0.513, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.409, 10.098], loss: 0.001534, mae: 0.041905, mean_q: 1.170290
 560800/1000000: episode: 5608, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 64.604, mean reward: 0.646 [0.512, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.318, 10.098], loss: 0.001476, mae: 0.041784, mean_q: 1.170107
 560900/1000000: episode: 5609, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.372, mean reward: 0.574 [0.500, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.421, 10.098], loss: 0.001577, mae: 0.042915, mean_q: 1.173346
 561000/1000000: episode: 5610, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.882, mean reward: 0.579 [0.501, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.290, 10.117], loss: 0.001546, mae: 0.042262, mean_q: 1.170784
 561100/1000000: episode: 5611, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.283, mean reward: 0.583 [0.509, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.481, 10.144], loss: 0.001491, mae: 0.041755, mean_q: 1.170753
 561200/1000000: episode: 5612, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.912, mean reward: 0.579 [0.500, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.259, 10.098], loss: 0.001506, mae: 0.041830, mean_q: 1.171398
 561300/1000000: episode: 5613, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.206, mean reward: 0.592 [0.506, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.744, 10.147], loss: 0.001599, mae: 0.043348, mean_q: 1.170409
 561400/1000000: episode: 5614, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.112, mean reward: 0.591 [0.511, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.050, 10.098], loss: 0.001499, mae: 0.041983, mean_q: 1.172060
 561500/1000000: episode: 5615, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.285, mean reward: 0.573 [0.502, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.467, 10.140], loss: 0.001591, mae: 0.043197, mean_q: 1.172208
 561600/1000000: episode: 5616, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.825, mean reward: 0.588 [0.507, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.810, 10.098], loss: 0.001604, mae: 0.043198, mean_q: 1.174668
 561700/1000000: episode: 5617, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.764, mean reward: 0.588 [0.501, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.561, 10.231], loss: 0.001564, mae: 0.042673, mean_q: 1.170629
 561800/1000000: episode: 5618, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 56.791, mean reward: 0.568 [0.504, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.691, 10.098], loss: 0.001503, mae: 0.042104, mean_q: 1.170532
 561900/1000000: episode: 5619, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.213, mean reward: 0.582 [0.508, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.231, 10.118], loss: 0.001445, mae: 0.041307, mean_q: 1.167408
 562000/1000000: episode: 5620, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 62.918, mean reward: 0.629 [0.501, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.515, 10.230], loss: 0.001466, mae: 0.041857, mean_q: 1.170021
 562100/1000000: episode: 5621, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.676, mean reward: 0.577 [0.504, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.713, 10.098], loss: 0.001588, mae: 0.043099, mean_q: 1.172443
 562200/1000000: episode: 5622, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 56.259, mean reward: 0.563 [0.502, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.603, 10.098], loss: 0.001472, mae: 0.041682, mean_q: 1.169917
 562300/1000000: episode: 5623, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.611, mean reward: 0.576 [0.506, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.282, 10.098], loss: 0.001549, mae: 0.042152, mean_q: 1.170748
 562400/1000000: episode: 5624, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.036, mean reward: 0.570 [0.508, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.357, 10.098], loss: 0.001513, mae: 0.042016, mean_q: 1.169268
 562500/1000000: episode: 5625, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.674, mean reward: 0.587 [0.497, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.643, 10.098], loss: 0.001530, mae: 0.042376, mean_q: 1.168307
 562600/1000000: episode: 5626, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.128, mean reward: 0.571 [0.505, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.684, 10.174], loss: 0.001571, mae: 0.043243, mean_q: 1.171004
 562700/1000000: episode: 5627, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.655, mean reward: 0.587 [0.500, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.546, 10.098], loss: 0.001521, mae: 0.042071, mean_q: 1.167799
 562800/1000000: episode: 5628, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.666, mean reward: 0.597 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.496, 10.172], loss: 0.001552, mae: 0.042383, mean_q: 1.166780
 562900/1000000: episode: 5629, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.968, mean reward: 0.590 [0.507, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.147, 10.149], loss: 0.001534, mae: 0.042282, mean_q: 1.170587
 563000/1000000: episode: 5630, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.176, mean reward: 0.572 [0.501, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.512, 10.098], loss: 0.001438, mae: 0.040873, mean_q: 1.165876
 563100/1000000: episode: 5631, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.283, mean reward: 0.573 [0.504, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.425, 10.124], loss: 0.001588, mae: 0.042810, mean_q: 1.164641
 563200/1000000: episode: 5632, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.533, mean reward: 0.575 [0.501, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.513, 10.098], loss: 0.001591, mae: 0.042942, mean_q: 1.167506
 563300/1000000: episode: 5633, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.251, mean reward: 0.583 [0.510, 0.915], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.579, 10.098], loss: 0.001606, mae: 0.042802, mean_q: 1.168646
 563400/1000000: episode: 5634, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 62.147, mean reward: 0.621 [0.517, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.900, 10.098], loss: 0.001745, mae: 0.043525, mean_q: 1.170841
 563500/1000000: episode: 5635, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.671, mean reward: 0.577 [0.500, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.336, 10.127], loss: 0.001507, mae: 0.042327, mean_q: 1.165844
 563600/1000000: episode: 5636, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.931, mean reward: 0.579 [0.504, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.668, 10.114], loss: 0.001633, mae: 0.043302, mean_q: 1.168555
 563700/1000000: episode: 5637, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 56.818, mean reward: 0.568 [0.499, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.570, 10.129], loss: 0.001644, mae: 0.043810, mean_q: 1.167942
 563800/1000000: episode: 5638, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.523, mean reward: 0.575 [0.504, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.953, 10.098], loss: 0.001558, mae: 0.042108, mean_q: 1.162686
 563900/1000000: episode: 5639, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.445, mean reward: 0.584 [0.507, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.268, 10.134], loss: 0.001686, mae: 0.044091, mean_q: 1.163500
 564000/1000000: episode: 5640, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.114, mean reward: 0.611 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.910, 10.181], loss: 0.001625, mae: 0.043055, mean_q: 1.167871
 564100/1000000: episode: 5641, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.712, mean reward: 0.587 [0.513, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.436, 10.098], loss: 0.001627, mae: 0.043118, mean_q: 1.163351
 564200/1000000: episode: 5642, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 60.073, mean reward: 0.601 [0.505, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.913, 10.098], loss: 0.001487, mae: 0.041328, mean_q: 1.163584
 564300/1000000: episode: 5643, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.245, mean reward: 0.602 [0.510, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.527, 10.181], loss: 0.001508, mae: 0.041939, mean_q: 1.165796
 564400/1000000: episode: 5644, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.435, mean reward: 0.604 [0.508, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.706, 10.098], loss: 0.001427, mae: 0.040831, mean_q: 1.161848
 564500/1000000: episode: 5645, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.951, mean reward: 0.590 [0.510, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.935, 10.098], loss: 0.001474, mae: 0.041713, mean_q: 1.163054
 564600/1000000: episode: 5646, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.361, mean reward: 0.574 [0.499, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.503, 10.098], loss: 0.001511, mae: 0.041678, mean_q: 1.160420
 564700/1000000: episode: 5647, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.983, mean reward: 0.580 [0.502, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.096, 10.116], loss: 0.001469, mae: 0.041356, mean_q: 1.159344
 564800/1000000: episode: 5648, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.751, mean reward: 0.588 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.613, 10.253], loss: 0.001555, mae: 0.042899, mean_q: 1.163330
 564900/1000000: episode: 5649, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.930, mean reward: 0.579 [0.503, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.737, 10.111], loss: 0.001461, mae: 0.041398, mean_q: 1.161687
 565000/1000000: episode: 5650, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.329, mean reward: 0.603 [0.519, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.571, 10.098], loss: 0.001549, mae: 0.042367, mean_q: 1.158562
 565100/1000000: episode: 5651, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.141, mean reward: 0.591 [0.508, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.327, 10.098], loss: 0.001464, mae: 0.041655, mean_q: 1.160181
 565200/1000000: episode: 5652, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 56.707, mean reward: 0.567 [0.507, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.550, 10.098], loss: 0.001556, mae: 0.042686, mean_q: 1.160927
 565300/1000000: episode: 5653, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.121, mean reward: 0.601 [0.506, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.885, 10.224], loss: 0.001425, mae: 0.041205, mean_q: 1.155563
 565400/1000000: episode: 5654, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.677, mean reward: 0.607 [0.509, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.479, 10.215], loss: 0.001527, mae: 0.041549, mean_q: 1.160520
 565500/1000000: episode: 5655, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.871, mean reward: 0.589 [0.504, 0.904], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.791, 10.149], loss: 0.001537, mae: 0.042325, mean_q: 1.162328
 565600/1000000: episode: 5656, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.558, mean reward: 0.596 [0.511, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.208, 10.155], loss: 0.001504, mae: 0.041446, mean_q: 1.164935
 565700/1000000: episode: 5657, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.019, mean reward: 0.600 [0.506, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.932, 10.098], loss: 0.001546, mae: 0.042330, mean_q: 1.162187
 565800/1000000: episode: 5658, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.499, mean reward: 0.595 [0.508, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.907, 10.240], loss: 0.001455, mae: 0.041479, mean_q: 1.161558
 565900/1000000: episode: 5659, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.706, mean reward: 0.617 [0.513, 0.884], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.935, 10.098], loss: 0.001513, mae: 0.042267, mean_q: 1.161059
 566000/1000000: episode: 5660, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.294, mean reward: 0.613 [0.510, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.342, 10.463], loss: 0.001357, mae: 0.040084, mean_q: 1.159684
 566100/1000000: episode: 5661, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.437, mean reward: 0.574 [0.505, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.730, 10.138], loss: 0.001465, mae: 0.041906, mean_q: 1.163287
 566200/1000000: episode: 5662, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.001, mean reward: 0.590 [0.501, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.823, 10.129], loss: 0.001480, mae: 0.041259, mean_q: 1.160930
 566300/1000000: episode: 5663, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.137, mean reward: 0.581 [0.502, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.807, 10.262], loss: 0.001469, mae: 0.041910, mean_q: 1.164418
 566400/1000000: episode: 5664, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.452, mean reward: 0.585 [0.499, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.139, 10.098], loss: 0.001388, mae: 0.040517, mean_q: 1.161273
 566500/1000000: episode: 5665, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.693, mean reward: 0.597 [0.511, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.533, 10.231], loss: 0.001631, mae: 0.043302, mean_q: 1.164338
 566600/1000000: episode: 5666, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 62.469, mean reward: 0.625 [0.512, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-2.094, 10.098], loss: 0.001464, mae: 0.041747, mean_q: 1.163620
 566700/1000000: episode: 5667, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.821, mean reward: 0.608 [0.518, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.412, 10.098], loss: 0.001479, mae: 0.041476, mean_q: 1.166640
 566800/1000000: episode: 5668, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.399, mean reward: 0.574 [0.510, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.673, 10.098], loss: 0.001472, mae: 0.041577, mean_q: 1.165420
 566900/1000000: episode: 5669, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.033, mean reward: 0.570 [0.497, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.262, 10.133], loss: 0.001525, mae: 0.042447, mean_q: 1.166591
 567000/1000000: episode: 5670, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 55.986, mean reward: 0.560 [0.501, 0.662], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.578, 10.279], loss: 0.001505, mae: 0.042935, mean_q: 1.167047
 567100/1000000: episode: 5671, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.091, mean reward: 0.581 [0.506, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.802, 10.181], loss: 0.001486, mae: 0.041488, mean_q: 1.166725
 567200/1000000: episode: 5672, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.263, mean reward: 0.563 [0.502, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.311, 10.162], loss: 0.001527, mae: 0.042204, mean_q: 1.162808
 567300/1000000: episode: 5673, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.724, mean reward: 0.577 [0.503, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.869, 10.098], loss: 0.001489, mae: 0.042288, mean_q: 1.161986
 567400/1000000: episode: 5674, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.190, mean reward: 0.582 [0.509, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.727, 10.364], loss: 0.001438, mae: 0.040862, mean_q: 1.168145
 567500/1000000: episode: 5675, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.161, mean reward: 0.582 [0.506, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.720, 10.098], loss: 0.001419, mae: 0.041243, mean_q: 1.163224
 567600/1000000: episode: 5676, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.721, mean reward: 0.597 [0.503, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.734, 10.213], loss: 0.001497, mae: 0.041366, mean_q: 1.161270
 567700/1000000: episode: 5677, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 62.292, mean reward: 0.623 [0.506, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.117, 10.118], loss: 0.001461, mae: 0.041064, mean_q: 1.160388
 567800/1000000: episode: 5678, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.410, mean reward: 0.584 [0.512, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.380, 10.140], loss: 0.001419, mae: 0.041126, mean_q: 1.167369
 567900/1000000: episode: 5679, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 57.982, mean reward: 0.580 [0.508, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.015, 10.098], loss: 0.001492, mae: 0.042117, mean_q: 1.166768
 568000/1000000: episode: 5680, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.129, mean reward: 0.591 [0.497, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.287, 10.098], loss: 0.001434, mae: 0.041399, mean_q: 1.166167
 568100/1000000: episode: 5681, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.362, mean reward: 0.604 [0.500, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.293, 10.347], loss: 0.001395, mae: 0.040872, mean_q: 1.167113
 568200/1000000: episode: 5682, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.239, mean reward: 0.612 [0.512, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.889, 10.438], loss: 0.001503, mae: 0.042065, mean_q: 1.165461
 568300/1000000: episode: 5683, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.825, mean reward: 0.598 [0.508, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.569, 10.286], loss: 0.001344, mae: 0.040288, mean_q: 1.170028
 568400/1000000: episode: 5684, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.376, mean reward: 0.584 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.932, 10.098], loss: 0.001551, mae: 0.042674, mean_q: 1.168896
 568500/1000000: episode: 5685, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.714, mean reward: 0.577 [0.507, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.138, 10.098], loss: 0.001444, mae: 0.041875, mean_q: 1.169725
 568600/1000000: episode: 5686, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.565, mean reward: 0.596 [0.507, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.422, 10.098], loss: 0.001495, mae: 0.041879, mean_q: 1.166050
 568700/1000000: episode: 5687, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.084, mean reward: 0.591 [0.507, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.804, 10.330], loss: 0.001472, mae: 0.041820, mean_q: 1.168675
 568800/1000000: episode: 5688, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 59.640, mean reward: 0.596 [0.505, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.684, 10.238], loss: 0.001362, mae: 0.040280, mean_q: 1.170306
 568900/1000000: episode: 5689, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.763, mean reward: 0.598 [0.507, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.667, 10.172], loss: 0.001532, mae: 0.042168, mean_q: 1.170133
 569000/1000000: episode: 5690, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 63.752, mean reward: 0.638 [0.503, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.615, 10.385], loss: 0.001471, mae: 0.041722, mean_q: 1.173620
 569100/1000000: episode: 5691, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.763, mean reward: 0.588 [0.505, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.710, 10.098], loss: 0.001411, mae: 0.040967, mean_q: 1.171731
 569200/1000000: episode: 5692, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.378, mean reward: 0.584 [0.507, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.326, 10.098], loss: 0.001398, mae: 0.040987, mean_q: 1.172306
 569300/1000000: episode: 5693, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.177, mean reward: 0.602 [0.507, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.750, 10.098], loss: 0.001405, mae: 0.041149, mean_q: 1.170319
 569400/1000000: episode: 5694, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.875, mean reward: 0.609 [0.524, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.549, 10.098], loss: 0.001456, mae: 0.041343, mean_q: 1.169723
 569500/1000000: episode: 5695, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.579, mean reward: 0.586 [0.504, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.016, 10.115], loss: 0.001391, mae: 0.040582, mean_q: 1.171873
 569600/1000000: episode: 5696, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 62.055, mean reward: 0.621 [0.498, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.363, 10.098], loss: 0.001452, mae: 0.041527, mean_q: 1.172862
 569700/1000000: episode: 5697, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.192, mean reward: 0.592 [0.508, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.432, 10.279], loss: 0.001463, mae: 0.041517, mean_q: 1.170848
 569800/1000000: episode: 5698, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.559, mean reward: 0.566 [0.498, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.821, 10.098], loss: 0.001338, mae: 0.039540, mean_q: 1.169660
 569900/1000000: episode: 5699, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.790, mean reward: 0.608 [0.521, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.971, 10.098], loss: 0.001434, mae: 0.041198, mean_q: 1.170157
 570000/1000000: episode: 5700, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.461, mean reward: 0.575 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.466, 10.145], loss: 0.001399, mae: 0.041082, mean_q: 1.173577
 570100/1000000: episode: 5701, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.357, mean reward: 0.594 [0.507, 0.878], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-2.072, 10.125], loss: 0.001484, mae: 0.041989, mean_q: 1.173594
 570200/1000000: episode: 5702, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.797, mean reward: 0.588 [0.508, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.038, 10.098], loss: 0.001462, mae: 0.041014, mean_q: 1.172240
 570300/1000000: episode: 5703, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.874, mean reward: 0.579 [0.502, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.502, 10.163], loss: 0.001391, mae: 0.040196, mean_q: 1.170166
 570400/1000000: episode: 5704, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.071, mean reward: 0.591 [0.505, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-1.090, 10.360], loss: 0.001387, mae: 0.040731, mean_q: 1.173167
 570500/1000000: episode: 5705, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.868, mean reward: 0.599 [0.498, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.123, 10.098], loss: 0.001453, mae: 0.041407, mean_q: 1.172006
 570600/1000000: episode: 5706, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 56.878, mean reward: 0.569 [0.505, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.711, 10.145], loss: 0.001412, mae: 0.040327, mean_q: 1.173734
 570700/1000000: episode: 5707, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.343, mean reward: 0.603 [0.505, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.947, 10.174], loss: 0.001437, mae: 0.040949, mean_q: 1.168066
 570800/1000000: episode: 5708, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.979, mean reward: 0.590 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.191, 10.123], loss: 0.001498, mae: 0.041929, mean_q: 1.175139
 570900/1000000: episode: 5709, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.809, mean reward: 0.608 [0.516, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.500, 10.162], loss: 0.001365, mae: 0.040002, mean_q: 1.169738
 571000/1000000: episode: 5710, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.918, mean reward: 0.579 [0.507, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.902, 10.098], loss: 0.001367, mae: 0.039843, mean_q: 1.170373
 571100/1000000: episode: 5711, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.085, mean reward: 0.591 [0.508, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.694, 10.182], loss: 0.001391, mae: 0.039660, mean_q: 1.168891
 571200/1000000: episode: 5712, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.828, mean reward: 0.568 [0.507, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.036, 10.193], loss: 0.001405, mae: 0.040233, mean_q: 1.171706
 571300/1000000: episode: 5713, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.302, mean reward: 0.593 [0.524, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.537, 10.166], loss: 0.001568, mae: 0.042836, mean_q: 1.168824
 571400/1000000: episode: 5714, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.050, mean reward: 0.611 [0.504, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.253, 10.612], loss: 0.001440, mae: 0.041480, mean_q: 1.170750
 571500/1000000: episode: 5715, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.394, mean reward: 0.594 [0.502, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.804, 10.213], loss: 0.001556, mae: 0.042481, mean_q: 1.174900
 571600/1000000: episode: 5716, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.124, mean reward: 0.591 [0.500, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.825, 10.214], loss: 0.001500, mae: 0.042020, mean_q: 1.168487
 571700/1000000: episode: 5717, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.433, mean reward: 0.584 [0.505, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.944, 10.099], loss: 0.001418, mae: 0.041459, mean_q: 1.168128
 571800/1000000: episode: 5718, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 62.713, mean reward: 0.627 [0.506, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.615, 10.115], loss: 0.001377, mae: 0.040517, mean_q: 1.169851
 571900/1000000: episode: 5719, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.829, mean reward: 0.588 [0.502, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.199, 10.136], loss: 0.001417, mae: 0.040555, mean_q: 1.173497
 572000/1000000: episode: 5720, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.691, mean reward: 0.587 [0.505, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.458, 10.118], loss: 0.001427, mae: 0.041412, mean_q: 1.172250
 572100/1000000: episode: 5721, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.293, mean reward: 0.583 [0.506, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.737, 10.287], loss: 0.001522, mae: 0.041561, mean_q: 1.172590
 572200/1000000: episode: 5722, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.588, mean reward: 0.576 [0.503, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.605, 10.232], loss: 0.001485, mae: 0.041972, mean_q: 1.172196
 572300/1000000: episode: 5723, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 60.701, mean reward: 0.607 [0.521, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.539, 10.098], loss: 0.001471, mae: 0.041388, mean_q: 1.172278
 572400/1000000: episode: 5724, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.153, mean reward: 0.602 [0.506, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.204, 10.251], loss: 0.001502, mae: 0.042409, mean_q: 1.174162
 572500/1000000: episode: 5725, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.393, mean reward: 0.604 [0.513, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.720, 10.098], loss: 0.001402, mae: 0.040713, mean_q: 1.176547
 572600/1000000: episode: 5726, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.525, mean reward: 0.575 [0.504, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.549, 10.141], loss: 0.001568, mae: 0.043135, mean_q: 1.177679
 572700/1000000: episode: 5727, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.803, mean reward: 0.588 [0.506, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.838, 10.136], loss: 0.001526, mae: 0.042317, mean_q: 1.180592
 572800/1000000: episode: 5728, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.658, mean reward: 0.587 [0.509, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.204, 10.098], loss: 0.001495, mae: 0.042268, mean_q: 1.173874
 572900/1000000: episode: 5729, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.710, mean reward: 0.577 [0.503, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.023, 10.230], loss: 0.001436, mae: 0.041474, mean_q: 1.175320
 573000/1000000: episode: 5730, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.093, mean reward: 0.571 [0.502, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.154, 10.098], loss: 0.001484, mae: 0.041863, mean_q: 1.173664
 573100/1000000: episode: 5731, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 60.429, mean reward: 0.604 [0.503, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.242, 10.098], loss: 0.001459, mae: 0.041335, mean_q: 1.170376
 573200/1000000: episode: 5732, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.515, mean reward: 0.615 [0.509, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.537, 10.371], loss: 0.001382, mae: 0.040438, mean_q: 1.170241
 573300/1000000: episode: 5733, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 56.932, mean reward: 0.569 [0.507, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.532, 10.129], loss: 0.001453, mae: 0.041744, mean_q: 1.173745
 573400/1000000: episode: 5734, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.765, mean reward: 0.568 [0.510, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.110, 10.161], loss: 0.001449, mae: 0.041566, mean_q: 1.174381
 573500/1000000: episode: 5735, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.561, mean reward: 0.606 [0.504, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.824, 10.238], loss: 0.001536, mae: 0.042352, mean_q: 1.173297
 573600/1000000: episode: 5736, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.613, mean reward: 0.576 [0.508, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.851, 10.155], loss: 0.001474, mae: 0.042392, mean_q: 1.171029
 573700/1000000: episode: 5737, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.377, mean reward: 0.604 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.422, 10.098], loss: 0.001433, mae: 0.041131, mean_q: 1.172657
 573800/1000000: episode: 5738, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.333, mean reward: 0.573 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.457, 10.098], loss: 0.001423, mae: 0.041230, mean_q: 1.169317
 573900/1000000: episode: 5739, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.312, mean reward: 0.593 [0.503, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.331, 10.098], loss: 0.001514, mae: 0.041749, mean_q: 1.171547
 574000/1000000: episode: 5740, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.714, mean reward: 0.617 [0.502, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.773, 10.098], loss: 0.001533, mae: 0.042099, mean_q: 1.172781
 574100/1000000: episode: 5741, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.540, mean reward: 0.575 [0.516, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.560, 10.245], loss: 0.001475, mae: 0.041998, mean_q: 1.171642
 574200/1000000: episode: 5742, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.479, mean reward: 0.595 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.665, 10.208], loss: 0.001453, mae: 0.041304, mean_q: 1.174255
 574300/1000000: episode: 5743, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.715, mean reward: 0.597 [0.505, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.056, 10.339], loss: 0.001500, mae: 0.042215, mean_q: 1.168493
 574400/1000000: episode: 5744, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.853, mean reward: 0.589 [0.505, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.752, 10.098], loss: 0.001417, mae: 0.040716, mean_q: 1.170093
 574500/1000000: episode: 5745, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.600, mean reward: 0.576 [0.504, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.454, 10.241], loss: 0.001385, mae: 0.040300, mean_q: 1.168851
 574600/1000000: episode: 5746, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 56.433, mean reward: 0.564 [0.503, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.560, 10.111], loss: 0.001506, mae: 0.042089, mean_q: 1.166525
 574700/1000000: episode: 5747, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.075, mean reward: 0.591 [0.504, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.619, 10.098], loss: 0.001430, mae: 0.040994, mean_q: 1.169169
 574800/1000000: episode: 5748, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.313, mean reward: 0.583 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.284, 10.098], loss: 0.001442, mae: 0.040878, mean_q: 1.162473
 574900/1000000: episode: 5749, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 58.720, mean reward: 0.587 [0.501, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.297, 10.124], loss: 0.001483, mae: 0.041512, mean_q: 1.164163
 575000/1000000: episode: 5750, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.517, mean reward: 0.595 [0.513, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.307, 10.098], loss: 0.001430, mae: 0.040612, mean_q: 1.165110
 575100/1000000: episode: 5751, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.924, mean reward: 0.599 [0.500, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.650, 10.311], loss: 0.001524, mae: 0.041907, mean_q: 1.163546
 575200/1000000: episode: 5752, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.506, mean reward: 0.575 [0.512, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.435, 10.098], loss: 0.001483, mae: 0.041365, mean_q: 1.167217
 575300/1000000: episode: 5753, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.339, mean reward: 0.593 [0.507, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.929, 10.098], loss: 0.001441, mae: 0.041272, mean_q: 1.165888
 575400/1000000: episode: 5754, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.297, mean reward: 0.583 [0.504, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.820, 10.212], loss: 0.001483, mae: 0.041796, mean_q: 1.169010
 575500/1000000: episode: 5755, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.735, mean reward: 0.587 [0.512, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.367, 10.098], loss: 0.001426, mae: 0.041194, mean_q: 1.169413
 575600/1000000: episode: 5756, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.467, mean reward: 0.605 [0.503, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.693, 10.203], loss: 0.001531, mae: 0.042430, mean_q: 1.169770
 575700/1000000: episode: 5757, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.577, mean reward: 0.576 [0.501, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.216, 10.160], loss: 0.001426, mae: 0.040947, mean_q: 1.167523
 575800/1000000: episode: 5758, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.017, mean reward: 0.600 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.204, 10.243], loss: 0.001484, mae: 0.042324, mean_q: 1.168299
 575900/1000000: episode: 5759, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.045, mean reward: 0.580 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.993, 10.129], loss: 0.001451, mae: 0.040910, mean_q: 1.167258
 576000/1000000: episode: 5760, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.923, mean reward: 0.589 [0.506, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.826, 10.098], loss: 0.001582, mae: 0.042729, mean_q: 1.167215
 576100/1000000: episode: 5761, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.108, mean reward: 0.581 [0.508, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.266, 10.162], loss: 0.001457, mae: 0.041900, mean_q: 1.165205
 576200/1000000: episode: 5762, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.120, mean reward: 0.601 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.869, 10.483], loss: 0.001391, mae: 0.040730, mean_q: 1.167072
 576300/1000000: episode: 5763, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.597, mean reward: 0.566 [0.504, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.570, 10.098], loss: 0.001476, mae: 0.041903, mean_q: 1.167793
 576400/1000000: episode: 5764, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.732, mean reward: 0.577 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.932, 10.098], loss: 0.001441, mae: 0.040864, mean_q: 1.163471
 576500/1000000: episode: 5765, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.514, mean reward: 0.575 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.054, 10.203], loss: 0.001476, mae: 0.041348, mean_q: 1.165001
 576600/1000000: episode: 5766, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.884, mean reward: 0.589 [0.502, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.930, 10.174], loss: 0.001496, mae: 0.041799, mean_q: 1.165463
 576700/1000000: episode: 5767, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.277, mean reward: 0.603 [0.512, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.179, 10.204], loss: 0.001382, mae: 0.040583, mean_q: 1.164529
 576800/1000000: episode: 5768, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.111, mean reward: 0.591 [0.502, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.735, 10.427], loss: 0.001464, mae: 0.040955, mean_q: 1.164089
 576900/1000000: episode: 5769, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.653, mean reward: 0.587 [0.499, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.539, 10.172], loss: 0.001408, mae: 0.040248, mean_q: 1.158919
 577000/1000000: episode: 5770, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.761, mean reward: 0.588 [0.512, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.469, 10.342], loss: 0.001350, mae: 0.039899, mean_q: 1.162009
 577100/1000000: episode: 5771, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 66.078, mean reward: 0.661 [0.532, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.867, 10.364], loss: 0.001377, mae: 0.040248, mean_q: 1.163733
 577200/1000000: episode: 5772, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.248, mean reward: 0.582 [0.501, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.434, 10.181], loss: 0.001476, mae: 0.041218, mean_q: 1.168955
 577300/1000000: episode: 5773, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 60.164, mean reward: 0.602 [0.512, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.057, 10.098], loss: 0.001406, mae: 0.040515, mean_q: 1.164262
 577400/1000000: episode: 5774, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.165, mean reward: 0.592 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.302, 10.257], loss: 0.001530, mae: 0.041841, mean_q: 1.165321
 577500/1000000: episode: 5775, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.129, mean reward: 0.581 [0.502, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.228, 10.344], loss: 0.001499, mae: 0.041474, mean_q: 1.164852
 577600/1000000: episode: 5776, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.656, mean reward: 0.577 [0.499, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.026, 10.098], loss: 0.001457, mae: 0.041751, mean_q: 1.167129
 577700/1000000: episode: 5777, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.652, mean reward: 0.577 [0.501, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.400, 10.205], loss: 0.001455, mae: 0.041447, mean_q: 1.163354
 577800/1000000: episode: 5778, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.286, mean reward: 0.583 [0.500, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.907, 10.242], loss: 0.001523, mae: 0.042465, mean_q: 1.164847
 577900/1000000: episode: 5779, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.349, mean reward: 0.583 [0.508, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.041, 10.098], loss: 0.001431, mae: 0.041237, mean_q: 1.165611
 578000/1000000: episode: 5780, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.889, mean reward: 0.589 [0.507, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.562, 10.098], loss: 0.001382, mae: 0.040611, mean_q: 1.164959
 578100/1000000: episode: 5781, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.683, mean reward: 0.597 [0.505, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.911, 10.403], loss: 0.001454, mae: 0.041638, mean_q: 1.164540
 578200/1000000: episode: 5782, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 57.984, mean reward: 0.580 [0.500, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.722, 10.129], loss: 0.001444, mae: 0.041459, mean_q: 1.162691
 578300/1000000: episode: 5783, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.559, mean reward: 0.586 [0.500, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.747, 10.098], loss: 0.001509, mae: 0.041946, mean_q: 1.163726
 578400/1000000: episode: 5784, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 62.439, mean reward: 0.624 [0.500, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.643, 10.098], loss: 0.001512, mae: 0.042194, mean_q: 1.163541
 578500/1000000: episode: 5785, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.615, mean reward: 0.576 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.924, 10.153], loss: 0.001389, mae: 0.039978, mean_q: 1.164953
 578600/1000000: episode: 5786, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.876, mean reward: 0.609 [0.514, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.548, 10.168], loss: 0.001530, mae: 0.042621, mean_q: 1.167071
 578700/1000000: episode: 5787, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 60.543, mean reward: 0.605 [0.511, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.566, 10.098], loss: 0.001459, mae: 0.041492, mean_q: 1.166471
 578800/1000000: episode: 5788, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.389, mean reward: 0.594 [0.509, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.799, 10.318], loss: 0.001494, mae: 0.042074, mean_q: 1.168597
 578900/1000000: episode: 5789, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 61.829, mean reward: 0.618 [0.502, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.682, 10.098], loss: 0.001529, mae: 0.042038, mean_q: 1.171308
 579000/1000000: episode: 5790, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.722, mean reward: 0.567 [0.501, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.159, 10.234], loss: 0.001533, mae: 0.042720, mean_q: 1.167707
 579100/1000000: episode: 5791, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.387, mean reward: 0.604 [0.510, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.816, 10.404], loss: 0.001494, mae: 0.041921, mean_q: 1.167231
 579200/1000000: episode: 5792, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.468, mean reward: 0.585 [0.503, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.452, 10.098], loss: 0.001413, mae: 0.040940, mean_q: 1.166283
 579300/1000000: episode: 5793, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.072, mean reward: 0.581 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.661, 10.200], loss: 0.001533, mae: 0.041826, mean_q: 1.167009
 579400/1000000: episode: 5794, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.800, mean reward: 0.578 [0.503, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.548, 10.249], loss: 0.001533, mae: 0.041960, mean_q: 1.168019
 579500/1000000: episode: 5795, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.506, mean reward: 0.575 [0.498, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.549, 10.098], loss: 0.001521, mae: 0.041440, mean_q: 1.169279
 579600/1000000: episode: 5796, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.655, mean reward: 0.587 [0.516, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.174, 10.098], loss: 0.001420, mae: 0.040789, mean_q: 1.166663
 579700/1000000: episode: 5797, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.193, mean reward: 0.592 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.366, 10.174], loss: 0.001557, mae: 0.042159, mean_q: 1.166317
 579800/1000000: episode: 5798, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.629, mean reward: 0.586 [0.512, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.002, 10.098], loss: 0.001557, mae: 0.042615, mean_q: 1.168114
 579900/1000000: episode: 5799, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.223, mean reward: 0.582 [0.511, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.334, 10.254], loss: 0.001485, mae: 0.041800, mean_q: 1.166578
 580000/1000000: episode: 5800, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.479, mean reward: 0.585 [0.498, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.716, 10.098], loss: 0.001442, mae: 0.041073, mean_q: 1.168910
 580100/1000000: episode: 5801, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.405, mean reward: 0.574 [0.499, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.764, 10.098], loss: 0.001551, mae: 0.042613, mean_q: 1.168724
 580200/1000000: episode: 5802, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 64.387, mean reward: 0.644 [0.503, 0.863], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.573, 10.386], loss: 0.001660, mae: 0.044058, mean_q: 1.170451
 580300/1000000: episode: 5803, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.538, mean reward: 0.585 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.492, 10.171], loss: 0.001554, mae: 0.042574, mean_q: 1.170105
 580400/1000000: episode: 5804, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.600, mean reward: 0.596 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.970, 10.445], loss: 0.001472, mae: 0.041507, mean_q: 1.170169
 580500/1000000: episode: 5805, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.185, mean reward: 0.602 [0.506, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.850, 10.098], loss: 0.001472, mae: 0.041446, mean_q: 1.167134
 580600/1000000: episode: 5806, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.243, mean reward: 0.582 [0.502, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.621, 10.098], loss: 0.001428, mae: 0.041144, mean_q: 1.172185
 580700/1000000: episode: 5807, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.196, mean reward: 0.582 [0.502, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.705, 10.242], loss: 0.001548, mae: 0.042799, mean_q: 1.172761
 580800/1000000: episode: 5808, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.143, mean reward: 0.601 [0.505, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.702, 10.250], loss: 0.001545, mae: 0.042561, mean_q: 1.168934
 580900/1000000: episode: 5809, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.094, mean reward: 0.581 [0.498, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-2.325, 10.392], loss: 0.001521, mae: 0.041852, mean_q: 1.167255
 581000/1000000: episode: 5810, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.341, mean reward: 0.593 [0.511, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.936, 10.278], loss: 0.001507, mae: 0.041608, mean_q: 1.168942
 581100/1000000: episode: 5811, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.917, mean reward: 0.599 [0.509, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.380, 10.297], loss: 0.001503, mae: 0.041535, mean_q: 1.168880
 581200/1000000: episode: 5812, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.485, mean reward: 0.585 [0.506, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.851, 10.204], loss: 0.001515, mae: 0.042189, mean_q: 1.168094
 581300/1000000: episode: 5813, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.141, mean reward: 0.591 [0.509, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.031, 10.365], loss: 0.001537, mae: 0.042537, mean_q: 1.172334
 581400/1000000: episode: 5814, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.383, mean reward: 0.584 [0.501, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.992, 10.148], loss: 0.001492, mae: 0.041939, mean_q: 1.169688
 581500/1000000: episode: 5815, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 62.459, mean reward: 0.625 [0.512, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.280, 10.445], loss: 0.001434, mae: 0.041431, mean_q: 1.172047
 581600/1000000: episode: 5816, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.386, mean reward: 0.594 [0.505, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.645, 10.251], loss: 0.001424, mae: 0.040982, mean_q: 1.171554
 581700/1000000: episode: 5817, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.384, mean reward: 0.584 [0.508, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.718, 10.106], loss: 0.001475, mae: 0.041477, mean_q: 1.170617
 581800/1000000: episode: 5818, duration: 0.523s, episode steps: 100, steps per second: 191, episode reward: 58.189, mean reward: 0.582 [0.501, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.227, 10.137], loss: 0.001566, mae: 0.043048, mean_q: 1.171833
 581900/1000000: episode: 5819, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.129, mean reward: 0.571 [0.502, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.004, 10.098], loss: 0.001562, mae: 0.042899, mean_q: 1.169484
 582000/1000000: episode: 5820, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.638, mean reward: 0.576 [0.505, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.085, 10.098], loss: 0.001492, mae: 0.042053, mean_q: 1.169301
 582100/1000000: episode: 5821, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.419, mean reward: 0.594 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.877, 10.225], loss: 0.001546, mae: 0.042187, mean_q: 1.166729
 582200/1000000: episode: 5822, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.197, mean reward: 0.582 [0.505, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.579, 10.152], loss: 0.001475, mae: 0.041261, mean_q: 1.166762
 582300/1000000: episode: 5823, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.773, mean reward: 0.588 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.313, 10.098], loss: 0.001441, mae: 0.041129, mean_q: 1.166021
 582400/1000000: episode: 5824, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.587, mean reward: 0.606 [0.510, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.632, 10.238], loss: 0.001484, mae: 0.041569, mean_q: 1.167158
 582500/1000000: episode: 5825, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.182, mean reward: 0.582 [0.505, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.208, 10.104], loss: 0.001540, mae: 0.042397, mean_q: 1.170977
 582600/1000000: episode: 5826, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 66.212, mean reward: 0.662 [0.538, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.416, 10.098], loss: 0.001427, mae: 0.041213, mean_q: 1.167676
 582700/1000000: episode: 5827, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.590, mean reward: 0.586 [0.507, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.226, 10.098], loss: 0.001485, mae: 0.041439, mean_q: 1.172810
 582800/1000000: episode: 5828, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 62.105, mean reward: 0.621 [0.507, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.036, 10.188], loss: 0.001477, mae: 0.041779, mean_q: 1.170371
 582900/1000000: episode: 5829, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.922, mean reward: 0.589 [0.500, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.537, 10.105], loss: 0.001555, mae: 0.042682, mean_q: 1.174385
 583000/1000000: episode: 5830, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.972, mean reward: 0.610 [0.508, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.892, 10.310], loss: 0.001393, mae: 0.041030, mean_q: 1.172650
 583100/1000000: episode: 5831, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.140, mean reward: 0.591 [0.506, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.795, 10.349], loss: 0.001489, mae: 0.042264, mean_q: 1.169444
 583200/1000000: episode: 5832, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.045, mean reward: 0.590 [0.516, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.826, 10.246], loss: 0.001494, mae: 0.042044, mean_q: 1.177487
 583300/1000000: episode: 5833, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.934, mean reward: 0.579 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.247, 10.098], loss: 0.001410, mae: 0.040945, mean_q: 1.174615
 583400/1000000: episode: 5834, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.493, mean reward: 0.585 [0.509, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.391, 10.098], loss: 0.001523, mae: 0.041872, mean_q: 1.171729
 583500/1000000: episode: 5835, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.539, mean reward: 0.585 [0.497, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.421, 10.101], loss: 0.001498, mae: 0.041796, mean_q: 1.172970
 583600/1000000: episode: 5836, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.428, mean reward: 0.584 [0.507, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.690, 10.098], loss: 0.001523, mae: 0.042694, mean_q: 1.175177
 583700/1000000: episode: 5837, duration: 0.650s, episode steps: 100, steps per second: 154, episode reward: 58.902, mean reward: 0.589 [0.504, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.472, 10.098], loss: 0.001486, mae: 0.041852, mean_q: 1.166645
 583800/1000000: episode: 5838, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 57.117, mean reward: 0.571 [0.500, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.911, 10.098], loss: 0.001527, mae: 0.042310, mean_q: 1.170210
 583900/1000000: episode: 5839, duration: 0.683s, episode steps: 100, steps per second: 146, episode reward: 57.971, mean reward: 0.580 [0.499, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.660, 10.155], loss: 0.001474, mae: 0.041995, mean_q: 1.169733
 584000/1000000: episode: 5840, duration: 0.861s, episode steps: 100, steps per second: 116, episode reward: 59.227, mean reward: 0.592 [0.502, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.636, 10.307], loss: 0.001556, mae: 0.042551, mean_q: 1.169809
 584100/1000000: episode: 5841, duration: 0.671s, episode steps: 100, steps per second: 149, episode reward: 59.045, mean reward: 0.590 [0.500, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.574, 10.098], loss: 0.001503, mae: 0.042015, mean_q: 1.170108
 584200/1000000: episode: 5842, duration: 0.651s, episode steps: 100, steps per second: 154, episode reward: 59.242, mean reward: 0.592 [0.510, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.483, 10.098], loss: 0.001484, mae: 0.042536, mean_q: 1.168487
 584300/1000000: episode: 5843, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.666, mean reward: 0.607 [0.505, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.492, 10.272], loss: 0.001445, mae: 0.041407, mean_q: 1.169842
 584400/1000000: episode: 5844, duration: 0.938s, episode steps: 100, steps per second: 107, episode reward: 56.898, mean reward: 0.569 [0.502, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.302, 10.098], loss: 0.001536, mae: 0.043128, mean_q: 1.170344
 584500/1000000: episode: 5845, duration: 0.996s, episode steps: 100, steps per second: 100, episode reward: 59.707, mean reward: 0.597 [0.519, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.325, 10.189], loss: 0.001534, mae: 0.042950, mean_q: 1.167264
 584600/1000000: episode: 5846, duration: 0.790s, episode steps: 100, steps per second: 127, episode reward: 58.426, mean reward: 0.584 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.327, 10.281], loss: 0.001609, mae: 0.043492, mean_q: 1.174730
 584700/1000000: episode: 5847, duration: 1.026s, episode steps: 100, steps per second: 97, episode reward: 59.385, mean reward: 0.594 [0.497, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.331, 10.321], loss: 0.001547, mae: 0.042684, mean_q: 1.171769
 584800/1000000: episode: 5848, duration: 0.809s, episode steps: 100, steps per second: 124, episode reward: 57.894, mean reward: 0.579 [0.503, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.478, 10.098], loss: 0.001485, mae: 0.042196, mean_q: 1.173060
 584900/1000000: episode: 5849, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 61.432, mean reward: 0.614 [0.509, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.048, 10.098], loss: 0.001474, mae: 0.041552, mean_q: 1.173047
 585000/1000000: episode: 5850, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 59.351, mean reward: 0.594 [0.506, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.432, 10.196], loss: 0.001449, mae: 0.041223, mean_q: 1.172395
 585100/1000000: episode: 5851, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.277, mean reward: 0.593 [0.516, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.742, 10.148], loss: 0.001429, mae: 0.041202, mean_q: 1.173011
 585200/1000000: episode: 5852, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.490, mean reward: 0.605 [0.505, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.945, 10.129], loss: 0.001514, mae: 0.042326, mean_q: 1.172712
 585300/1000000: episode: 5853, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.466, mean reward: 0.605 [0.504, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.925, 10.280], loss: 0.001515, mae: 0.042055, mean_q: 1.170044
 585400/1000000: episode: 5854, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.957, mean reward: 0.590 [0.499, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.476, 10.400], loss: 0.001491, mae: 0.041805, mean_q: 1.172731
 585500/1000000: episode: 5855, duration: 0.622s, episode steps: 100, steps per second: 161, episode reward: 58.195, mean reward: 0.582 [0.506, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.770, 10.313], loss: 0.001471, mae: 0.041240, mean_q: 1.171549
 585600/1000000: episode: 5856, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.349, mean reward: 0.593 [0.514, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.934, 10.162], loss: 0.001538, mae: 0.042876, mean_q: 1.174266
 585700/1000000: episode: 5857, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.645, mean reward: 0.596 [0.504, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.523, 10.262], loss: 0.001527, mae: 0.042507, mean_q: 1.172176
 585800/1000000: episode: 5858, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 63.082, mean reward: 0.631 [0.502, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.904, 10.100], loss: 0.001374, mae: 0.040318, mean_q: 1.170919
 585900/1000000: episode: 5859, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 62.307, mean reward: 0.623 [0.500, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.763, 10.169], loss: 0.001407, mae: 0.040894, mean_q: 1.177588
 586000/1000000: episode: 5860, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.503, mean reward: 0.575 [0.505, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.774, 10.239], loss: 0.001387, mae: 0.040200, mean_q: 1.173811
 586100/1000000: episode: 5861, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 64.136, mean reward: 0.641 [0.514, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.314, 10.098], loss: 0.001467, mae: 0.041306, mean_q: 1.177038
 586200/1000000: episode: 5862, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 56.484, mean reward: 0.565 [0.507, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.877, 10.098], loss: 0.001455, mae: 0.041157, mean_q: 1.178616
 586300/1000000: episode: 5863, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 56.707, mean reward: 0.567 [0.500, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.749, 10.208], loss: 0.001539, mae: 0.042377, mean_q: 1.178472
 586400/1000000: episode: 5864, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.726, mean reward: 0.577 [0.505, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.827, 10.191], loss: 0.001426, mae: 0.041043, mean_q: 1.175559
 586500/1000000: episode: 5865, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.842, mean reward: 0.608 [0.503, 0.841], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.016, 10.164], loss: 0.001531, mae: 0.042476, mean_q: 1.173507
 586600/1000000: episode: 5866, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.102, mean reward: 0.591 [0.513, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.539, 10.098], loss: 0.001508, mae: 0.041595, mean_q: 1.172072
 586700/1000000: episode: 5867, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 56.954, mean reward: 0.570 [0.502, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.424, 10.105], loss: 0.001444, mae: 0.040613, mean_q: 1.171907
 586800/1000000: episode: 5868, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.062, mean reward: 0.591 [0.498, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.661, 10.243], loss: 0.001482, mae: 0.041102, mean_q: 1.169670
 586900/1000000: episode: 5869, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 56.378, mean reward: 0.564 [0.502, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.223, 10.098], loss: 0.001531, mae: 0.042038, mean_q: 1.171005
 587000/1000000: episode: 5870, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 57.781, mean reward: 0.578 [0.501, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.289, 10.249], loss: 0.001502, mae: 0.041796, mean_q: 1.173059
 587100/1000000: episode: 5871, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.936, mean reward: 0.579 [0.502, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.469, 10.247], loss: 0.001436, mae: 0.040974, mean_q: 1.171625
 587200/1000000: episode: 5872, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.235, mean reward: 0.602 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.741, 10.183], loss: 0.001386, mae: 0.040417, mean_q: 1.170253
 587300/1000000: episode: 5873, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.427, mean reward: 0.594 [0.504, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.582, 10.284], loss: 0.001415, mae: 0.040756, mean_q: 1.171588
 587400/1000000: episode: 5874, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.482, mean reward: 0.595 [0.514, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.119, 10.130], loss: 0.001427, mae: 0.041109, mean_q: 1.170326
 587500/1000000: episode: 5875, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.499, mean reward: 0.575 [0.499, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.311, 10.098], loss: 0.001461, mae: 0.041587, mean_q: 1.173096
 587600/1000000: episode: 5876, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 57.833, mean reward: 0.578 [0.505, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.449, 10.098], loss: 0.001488, mae: 0.041140, mean_q: 1.172074
 587700/1000000: episode: 5877, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.271, mean reward: 0.583 [0.505, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.741, 10.098], loss: 0.001375, mae: 0.040294, mean_q: 1.163657
 587800/1000000: episode: 5878, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.702, mean reward: 0.577 [0.508, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.343, 10.098], loss: 0.001327, mae: 0.039626, mean_q: 1.167839
 587900/1000000: episode: 5879, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 58.586, mean reward: 0.586 [0.509, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.851, 10.098], loss: 0.001473, mae: 0.041342, mean_q: 1.165111
 588000/1000000: episode: 5880, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.318, mean reward: 0.573 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.193, 10.240], loss: 0.001537, mae: 0.041945, mean_q: 1.166516
 588100/1000000: episode: 5881, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.066, mean reward: 0.581 [0.502, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.392, 10.105], loss: 0.001551, mae: 0.042502, mean_q: 1.166971
 588200/1000000: episode: 5882, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 60.088, mean reward: 0.601 [0.516, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.951, 10.364], loss: 0.001504, mae: 0.042207, mean_q: 1.164735
 588300/1000000: episode: 5883, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.172, mean reward: 0.592 [0.502, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.640, 10.199], loss: 0.001386, mae: 0.039930, mean_q: 1.167926
 588400/1000000: episode: 5884, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 58.497, mean reward: 0.585 [0.502, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.516, 10.098], loss: 0.001380, mae: 0.039761, mean_q: 1.161072
 588500/1000000: episode: 5885, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 61.924, mean reward: 0.619 [0.505, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.181, 10.098], loss: 0.001416, mae: 0.040658, mean_q: 1.165432
 588600/1000000: episode: 5886, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.329, mean reward: 0.573 [0.505, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.874, 10.203], loss: 0.001457, mae: 0.041031, mean_q: 1.163621
 588700/1000000: episode: 5887, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 61.341, mean reward: 0.613 [0.503, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.460, 10.098], loss: 0.001457, mae: 0.041444, mean_q: 1.170632
 588800/1000000: episode: 5888, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.121, mean reward: 0.581 [0.498, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.027, 10.098], loss: 0.001389, mae: 0.041009, mean_q: 1.169225
 588900/1000000: episode: 5889, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.767, mean reward: 0.588 [0.500, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.177, 10.299], loss: 0.001369, mae: 0.039520, mean_q: 1.166520
 589000/1000000: episode: 5890, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.388, mean reward: 0.604 [0.503, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.270, 10.218], loss: 0.001400, mae: 0.040135, mean_q: 1.165717
 589100/1000000: episode: 5891, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.363, mean reward: 0.594 [0.510, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.181, 10.098], loss: 0.001424, mae: 0.040787, mean_q: 1.170174
 589200/1000000: episode: 5892, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 61.189, mean reward: 0.612 [0.501, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.838, 10.247], loss: 0.001397, mae: 0.040035, mean_q: 1.167748
 589300/1000000: episode: 5893, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.149, mean reward: 0.601 [0.499, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.722, 10.129], loss: 0.001406, mae: 0.040467, mean_q: 1.166610
 589400/1000000: episode: 5894, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.652, mean reward: 0.587 [0.508, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.980, 10.264], loss: 0.001452, mae: 0.041416, mean_q: 1.171040
 589500/1000000: episode: 5895, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 61.352, mean reward: 0.614 [0.500, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.010, 10.492], loss: 0.001366, mae: 0.040041, mean_q: 1.170683
 589600/1000000: episode: 5896, duration: 0.533s, episode steps: 100, steps per second: 187, episode reward: 60.105, mean reward: 0.601 [0.513, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.727, 10.272], loss: 0.001435, mae: 0.041022, mean_q: 1.171508
 589700/1000000: episode: 5897, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.527, mean reward: 0.595 [0.500, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.206, 10.099], loss: 0.001478, mae: 0.041415, mean_q: 1.171563
 589800/1000000: episode: 5898, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 64.910, mean reward: 0.649 [0.518, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.862, 10.098], loss: 0.001420, mae: 0.040629, mean_q: 1.170117
 589900/1000000: episode: 5899, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.404, mean reward: 0.584 [0.516, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.665, 10.169], loss: 0.001388, mae: 0.040499, mean_q: 1.173406
 590000/1000000: episode: 5900, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.411, mean reward: 0.584 [0.505, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.810, 10.177], loss: 0.001413, mae: 0.040421, mean_q: 1.171334
 590100/1000000: episode: 5901, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.779, mean reward: 0.598 [0.508, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.911, 10.098], loss: 0.001353, mae: 0.040487, mean_q: 1.174120
 590200/1000000: episode: 5902, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.426, mean reward: 0.584 [0.506, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.514, 10.128], loss: 0.001458, mae: 0.040993, mean_q: 1.172755
 590300/1000000: episode: 5903, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.940, mean reward: 0.569 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.142, 10.127], loss: 0.001397, mae: 0.041134, mean_q: 1.168911
 590400/1000000: episode: 5904, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 56.692, mean reward: 0.567 [0.507, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.532, 10.162], loss: 0.001320, mae: 0.039791, mean_q: 1.169206
 590500/1000000: episode: 5905, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.725, mean reward: 0.577 [0.499, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.987, 10.098], loss: 0.001414, mae: 0.040692, mean_q: 1.171198
 590600/1000000: episode: 5906, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 56.716, mean reward: 0.567 [0.505, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.049, 10.153], loss: 0.001275, mae: 0.038715, mean_q: 1.170821
 590700/1000000: episode: 5907, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 56.753, mean reward: 0.568 [0.499, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.050, 10.098], loss: 0.001431, mae: 0.040947, mean_q: 1.168083
 590800/1000000: episode: 5908, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.613, mean reward: 0.576 [0.499, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.233, 10.098], loss: 0.001300, mae: 0.039008, mean_q: 1.164564
 590900/1000000: episode: 5909, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.095, mean reward: 0.571 [0.505, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.724, 10.224], loss: 0.001325, mae: 0.039483, mean_q: 1.163644
 591000/1000000: episode: 5910, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.102, mean reward: 0.601 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.461, 10.098], loss: 0.001282, mae: 0.039410, mean_q: 1.162908
 591100/1000000: episode: 5911, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.774, mean reward: 0.588 [0.507, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.654, 10.098], loss: 0.001279, mae: 0.039009, mean_q: 1.161523
 591200/1000000: episode: 5912, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.392, mean reward: 0.594 [0.513, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.463, 10.451], loss: 0.001406, mae: 0.040650, mean_q: 1.163158
 591300/1000000: episode: 5913, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.819, mean reward: 0.578 [0.499, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.904, 10.105], loss: 0.001298, mae: 0.039568, mean_q: 1.168488
 591400/1000000: episode: 5914, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.607, mean reward: 0.586 [0.506, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.350, 10.115], loss: 0.001314, mae: 0.039153, mean_q: 1.163211
 591500/1000000: episode: 5915, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.608, mean reward: 0.596 [0.516, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.199, 10.289], loss: 0.001348, mae: 0.040062, mean_q: 1.164281
 591600/1000000: episode: 5916, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.234, mean reward: 0.592 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.470, 10.098], loss: 0.001341, mae: 0.039672, mean_q: 1.162363
 591700/1000000: episode: 5917, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.935, mean reward: 0.589 [0.510, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.933, 10.211], loss: 0.001338, mae: 0.040008, mean_q: 1.165387
 591800/1000000: episode: 5918, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.751, mean reward: 0.578 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.165, 10.098], loss: 0.001410, mae: 0.040399, mean_q: 1.162917
 591900/1000000: episode: 5919, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.084, mean reward: 0.581 [0.507, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.780, 10.098], loss: 0.001310, mae: 0.039671, mean_q: 1.164890
 592000/1000000: episode: 5920, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.816, mean reward: 0.588 [0.507, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.589, 10.098], loss: 0.001477, mae: 0.041533, mean_q: 1.164156
 592100/1000000: episode: 5921, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.507, mean reward: 0.595 [0.502, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.428, 10.098], loss: 0.001337, mae: 0.040165, mean_q: 1.164972
 592200/1000000: episode: 5922, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.658, mean reward: 0.607 [0.512, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.375, 10.098], loss: 0.001308, mae: 0.038764, mean_q: 1.163574
 592300/1000000: episode: 5923, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.867, mean reward: 0.589 [0.511, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.293, 10.379], loss: 0.001448, mae: 0.041361, mean_q: 1.168967
 592400/1000000: episode: 5924, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.789, mean reward: 0.608 [0.507, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.872, 10.110], loss: 0.001343, mae: 0.040295, mean_q: 1.163769
 592500/1000000: episode: 5925, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.708, mean reward: 0.617 [0.506, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.046, 10.098], loss: 0.001403, mae: 0.041178, mean_q: 1.167072
 592600/1000000: episode: 5926, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.127, mean reward: 0.591 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.878, 10.167], loss: 0.001404, mae: 0.041054, mean_q: 1.165426
 592700/1000000: episode: 5927, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.722, mean reward: 0.587 [0.502, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.890, 10.163], loss: 0.001376, mae: 0.040825, mean_q: 1.167965
 592800/1000000: episode: 5928, duration: 0.666s, episode steps: 100, steps per second: 150, episode reward: 58.758, mean reward: 0.588 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.636, 10.160], loss: 0.001468, mae: 0.041771, mean_q: 1.167783
 592900/1000000: episode: 5929, duration: 0.650s, episode steps: 100, steps per second: 154, episode reward: 61.576, mean reward: 0.616 [0.505, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.670, 10.098], loss: 0.001471, mae: 0.041892, mean_q: 1.168556
 593000/1000000: episode: 5930, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.236, mean reward: 0.572 [0.503, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.878, 10.258], loss: 0.001441, mae: 0.041603, mean_q: 1.168341
 593100/1000000: episode: 5931, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.946, mean reward: 0.599 [0.503, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.903, 10.398], loss: 0.001346, mae: 0.040497, mean_q: 1.172323
 593200/1000000: episode: 5932, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.588, mean reward: 0.586 [0.506, 0.875], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.048, 10.098], loss: 0.001376, mae: 0.040402, mean_q: 1.171722
 593300/1000000: episode: 5933, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.961, mean reward: 0.570 [0.506, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.928, 10.098], loss: 0.001513, mae: 0.042238, mean_q: 1.168418
 593400/1000000: episode: 5934, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.927, mean reward: 0.589 [0.503, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.602, 10.098], loss: 0.001370, mae: 0.040155, mean_q: 1.171823
 593500/1000000: episode: 5935, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.036, mean reward: 0.590 [0.501, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.224, 10.098], loss: 0.001451, mae: 0.040760, mean_q: 1.166722
 593600/1000000: episode: 5936, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.631, mean reward: 0.606 [0.507, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.722, 10.098], loss: 0.001410, mae: 0.040781, mean_q: 1.169931
 593700/1000000: episode: 5937, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.048, mean reward: 0.600 [0.512, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.366, 10.098], loss: 0.001504, mae: 0.042237, mean_q: 1.173851
 593800/1000000: episode: 5938, duration: 0.634s, episode steps: 100, steps per second: 158, episode reward: 59.487, mean reward: 0.595 [0.506, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.419, 10.098], loss: 0.001437, mae: 0.041591, mean_q: 1.169591
 593900/1000000: episode: 5939, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.428, mean reward: 0.574 [0.513, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.242, 10.098], loss: 0.001485, mae: 0.041923, mean_q: 1.172112
 594000/1000000: episode: 5940, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.086, mean reward: 0.581 [0.508, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.590, 10.125], loss: 0.001406, mae: 0.040844, mean_q: 1.169623
 594100/1000000: episode: 5941, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 63.124, mean reward: 0.631 [0.500, 0.887], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.604, 10.098], loss: 0.001416, mae: 0.041161, mean_q: 1.169004
 594200/1000000: episode: 5942, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.367, mean reward: 0.584 [0.501, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.110, 10.098], loss: 0.001478, mae: 0.042205, mean_q: 1.168728
 594300/1000000: episode: 5943, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.390, mean reward: 0.574 [0.507, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.781, 10.098], loss: 0.001419, mae: 0.041295, mean_q: 1.168488
 594400/1000000: episode: 5944, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.311, mean reward: 0.593 [0.509, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.850, 10.098], loss: 0.001422, mae: 0.041164, mean_q: 1.169015
 594500/1000000: episode: 5945, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 56.470, mean reward: 0.565 [0.504, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.465, 10.167], loss: 0.001412, mae: 0.040251, mean_q: 1.166751
 594600/1000000: episode: 5946, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.750, mean reward: 0.587 [0.505, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.729, 10.212], loss: 0.001487, mae: 0.041979, mean_q: 1.164855
 594700/1000000: episode: 5947, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.983, mean reward: 0.580 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.125, 10.098], loss: 0.001471, mae: 0.041703, mean_q: 1.165183
 594800/1000000: episode: 5948, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.229, mean reward: 0.562 [0.498, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.077, 10.098], loss: 0.001527, mae: 0.042710, mean_q: 1.161787
 594900/1000000: episode: 5949, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.779, mean reward: 0.568 [0.502, 0.650], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.521, 10.144], loss: 0.001523, mae: 0.042272, mean_q: 1.159974
 595000/1000000: episode: 5950, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.609, mean reward: 0.586 [0.503, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.103, 10.184], loss: 0.001465, mae: 0.041919, mean_q: 1.165683
 595100/1000000: episode: 5951, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.141, mean reward: 0.591 [0.498, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.729, 10.098], loss: 0.001409, mae: 0.041233, mean_q: 1.160227
 595200/1000000: episode: 5952, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.033, mean reward: 0.580 [0.499, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-2.309, 10.282], loss: 0.001383, mae: 0.040598, mean_q: 1.160736
 595300/1000000: episode: 5953, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.775, mean reward: 0.608 [0.507, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.923, 10.098], loss: 0.001389, mae: 0.040655, mean_q: 1.162920
 595400/1000000: episode: 5954, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.612, mean reward: 0.586 [0.519, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.977, 10.098], loss: 0.001486, mae: 0.042443, mean_q: 1.162646
 595500/1000000: episode: 5955, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.686, mean reward: 0.577 [0.510, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.341, 10.098], loss: 0.001527, mae: 0.042448, mean_q: 1.162672
 595600/1000000: episode: 5956, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.635, mean reward: 0.606 [0.512, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.550, 10.381], loss: 0.001425, mae: 0.041499, mean_q: 1.162735
 595700/1000000: episode: 5957, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.838, mean reward: 0.588 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.382, 10.098], loss: 0.001458, mae: 0.041474, mean_q: 1.162868
 595800/1000000: episode: 5958, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.704, mean reward: 0.597 [0.507, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.456, 10.098], loss: 0.001439, mae: 0.041303, mean_q: 1.162565
 595900/1000000: episode: 5959, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.893, mean reward: 0.599 [0.501, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.158, 10.188], loss: 0.001493, mae: 0.042343, mean_q: 1.166139
 596000/1000000: episode: 5960, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.807, mean reward: 0.588 [0.513, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.921, 10.118], loss: 0.001472, mae: 0.041426, mean_q: 1.168464
 596100/1000000: episode: 5961, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.404, mean reward: 0.584 [0.510, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.441, 10.098], loss: 0.001558, mae: 0.042833, mean_q: 1.167748
 596200/1000000: episode: 5962, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.163, mean reward: 0.572 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.819, 10.146], loss: 0.001561, mae: 0.042476, mean_q: 1.167979
 596300/1000000: episode: 5963, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.307, mean reward: 0.573 [0.500, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.079, 10.098], loss: 0.001465, mae: 0.041621, mean_q: 1.165345
 596400/1000000: episode: 5964, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.552, mean reward: 0.586 [0.502, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.361, 10.141], loss: 0.001590, mae: 0.043455, mean_q: 1.169460
 596500/1000000: episode: 5965, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.552, mean reward: 0.586 [0.505, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.953, 10.347], loss: 0.001460, mae: 0.042209, mean_q: 1.165485
 596600/1000000: episode: 5966, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.727, mean reward: 0.577 [0.498, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.963, 10.098], loss: 0.001480, mae: 0.041483, mean_q: 1.164569
 596700/1000000: episode: 5967, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.016, mean reward: 0.570 [0.510, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.974, 10.188], loss: 0.001407, mae: 0.040978, mean_q: 1.164119
 596800/1000000: episode: 5968, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.328, mean reward: 0.583 [0.506, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.747, 10.098], loss: 0.001482, mae: 0.042151, mean_q: 1.161976
 596900/1000000: episode: 5969, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.306, mean reward: 0.583 [0.510, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.414, 10.223], loss: 0.001555, mae: 0.042635, mean_q: 1.166912
 597000/1000000: episode: 5970, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.977, mean reward: 0.580 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.177, 10.108], loss: 0.001459, mae: 0.041655, mean_q: 1.164441
 597100/1000000: episode: 5971, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.986, mean reward: 0.580 [0.510, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.740, 10.154], loss: 0.001501, mae: 0.042104, mean_q: 1.164188
 597200/1000000: episode: 5972, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.478, mean reward: 0.595 [0.508, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.579, 10.362], loss: 0.001517, mae: 0.041902, mean_q: 1.162338
 597300/1000000: episode: 5973, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.237, mean reward: 0.592 [0.521, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.973, 10.098], loss: 0.001527, mae: 0.042422, mean_q: 1.163554
 597400/1000000: episode: 5974, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.661, mean reward: 0.587 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.537, 10.229], loss: 0.001490, mae: 0.042353, mean_q: 1.160597
 597500/1000000: episode: 5975, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.576, mean reward: 0.586 [0.498, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.088, 10.098], loss: 0.001613, mae: 0.043253, mean_q: 1.160999
 597600/1000000: episode: 5976, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.746, mean reward: 0.577 [0.497, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.060, 10.293], loss: 0.001437, mae: 0.040911, mean_q: 1.161880
 597700/1000000: episode: 5977, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.544, mean reward: 0.585 [0.501, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.409, 10.223], loss: 0.001490, mae: 0.041809, mean_q: 1.160385
 597800/1000000: episode: 5978, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.246, mean reward: 0.562 [0.499, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.654, 10.117], loss: 0.001431, mae: 0.041406, mean_q: 1.159699
 597900/1000000: episode: 5979, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 62.379, mean reward: 0.624 [0.508, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.579, 10.352], loss: 0.001493, mae: 0.042195, mean_q: 1.160347
 598000/1000000: episode: 5980, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 60.788, mean reward: 0.608 [0.505, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.128, 10.553], loss: 0.001436, mae: 0.041080, mean_q: 1.159261
 598100/1000000: episode: 5981, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.137, mean reward: 0.591 [0.507, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.726, 10.416], loss: 0.001426, mae: 0.041596, mean_q: 1.163006
 598200/1000000: episode: 5982, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.138, mean reward: 0.601 [0.513, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.701, 10.098], loss: 0.001561, mae: 0.042897, mean_q: 1.161953
 598300/1000000: episode: 5983, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.453, mean reward: 0.595 [0.512, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.193, 10.098], loss: 0.001338, mae: 0.040193, mean_q: 1.158678
 598400/1000000: episode: 5984, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.531, mean reward: 0.605 [0.518, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.270, 10.259], loss: 0.001638, mae: 0.044009, mean_q: 1.161375
 598500/1000000: episode: 5985, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 56.848, mean reward: 0.568 [0.508, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.518, 10.098], loss: 0.001441, mae: 0.041490, mean_q: 1.161200
 598600/1000000: episode: 5986, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.543, mean reward: 0.585 [0.512, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.483, 10.098], loss: 0.001416, mae: 0.040868, mean_q: 1.163293
 598700/1000000: episode: 5987, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 61.716, mean reward: 0.617 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.011, 10.486], loss: 0.001407, mae: 0.041113, mean_q: 1.160378
 598800/1000000: episode: 5988, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.513, mean reward: 0.575 [0.507, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.961, 10.213], loss: 0.001444, mae: 0.041653, mean_q: 1.162142
 598900/1000000: episode: 5989, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.973, mean reward: 0.580 [0.511, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.315, 10.098], loss: 0.001494, mae: 0.041797, mean_q: 1.162857
 599000/1000000: episode: 5990, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.333, mean reward: 0.603 [0.516, 0.855], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.213, 10.098], loss: 0.001579, mae: 0.042938, mean_q: 1.161455
 599100/1000000: episode: 5991, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.001, mean reward: 0.580 [0.509, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.923, 10.098], loss: 0.001495, mae: 0.042098, mean_q: 1.160791
 599200/1000000: episode: 5992, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.169, mean reward: 0.582 [0.499, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.451, 10.395], loss: 0.001389, mae: 0.040450, mean_q: 1.161541
 599300/1000000: episode: 5993, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.671, mean reward: 0.607 [0.517, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.149, 10.098], loss: 0.001479, mae: 0.041933, mean_q: 1.157502
 599400/1000000: episode: 5994, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.949, mean reward: 0.579 [0.507, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.734, 10.098], loss: 0.001517, mae: 0.041747, mean_q: 1.159135
 599500/1000000: episode: 5995, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.158, mean reward: 0.572 [0.501, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.337, 10.098], loss: 0.001493, mae: 0.041514, mean_q: 1.161608
 599600/1000000: episode: 5996, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.252, mean reward: 0.583 [0.508, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.341, 10.108], loss: 0.001483, mae: 0.041711, mean_q: 1.158551
 599700/1000000: episode: 5997, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.908, mean reward: 0.609 [0.510, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.664, 10.098], loss: 0.001596, mae: 0.043540, mean_q: 1.161107
 599800/1000000: episode: 5998, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 62.333, mean reward: 0.623 [0.524, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.413 [-0.928, 10.098], loss: 0.001373, mae: 0.040231, mean_q: 1.159456
 599900/1000000: episode: 5999, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.532, mean reward: 0.595 [0.499, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.597, 10.098], loss: 0.001373, mae: 0.040244, mean_q: 1.162172
 600000/1000000: episode: 6000, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.539, mean reward: 0.585 [0.508, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.981, 10.098], loss: 0.001515, mae: 0.042129, mean_q: 1.168822
 600100/1000000: episode: 6001, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.351, mean reward: 0.594 [0.510, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.530, 10.143], loss: 0.001446, mae: 0.041456, mean_q: 1.169644
 600200/1000000: episode: 6002, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.512, mean reward: 0.585 [0.502, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.701, 10.128], loss: 0.001518, mae: 0.042339, mean_q: 1.163554
 600300/1000000: episode: 6003, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.709, mean reward: 0.567 [0.507, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.108, 10.223], loss: 0.001508, mae: 0.041890, mean_q: 1.161394
 600400/1000000: episode: 6004, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 56.404, mean reward: 0.564 [0.504, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.616, 10.098], loss: 0.001464, mae: 0.041455, mean_q: 1.163593
 600500/1000000: episode: 6005, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.267, mean reward: 0.583 [0.502, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.712, 10.264], loss: 0.001417, mae: 0.040863, mean_q: 1.164872
 600600/1000000: episode: 6006, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.041, mean reward: 0.610 [0.509, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.581, 10.098], loss: 0.001436, mae: 0.040881, mean_q: 1.159612
 600700/1000000: episode: 6007, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.532, mean reward: 0.575 [0.504, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.601, 10.135], loss: 0.001451, mae: 0.041311, mean_q: 1.164020
 600800/1000000: episode: 6008, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 67.963, mean reward: 0.680 [0.511, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.999, 10.316], loss: 0.001425, mae: 0.040474, mean_q: 1.160331
 600900/1000000: episode: 6009, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.369, mean reward: 0.574 [0.505, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.505, 10.165], loss: 0.001489, mae: 0.041708, mean_q: 1.167841
 601000/1000000: episode: 6010, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.726, mean reward: 0.587 [0.504, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.398, 10.098], loss: 0.001598, mae: 0.043175, mean_q: 1.165744
 601100/1000000: episode: 6011, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 56.123, mean reward: 0.561 [0.508, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.864, 10.133], loss: 0.001368, mae: 0.040389, mean_q: 1.163559
 601200/1000000: episode: 6012, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 56.537, mean reward: 0.565 [0.504, 0.649], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.252, 10.269], loss: 0.001421, mae: 0.040783, mean_q: 1.169509
 601300/1000000: episode: 6013, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.735, mean reward: 0.597 [0.502, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.558, 10.141], loss: 0.001459, mae: 0.041086, mean_q: 1.162023
 601400/1000000: episode: 6014, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 57.476, mean reward: 0.575 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.992, 10.098], loss: 0.001409, mae: 0.041369, mean_q: 1.168622
 601500/1000000: episode: 6015, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.785, mean reward: 0.578 [0.497, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.111, 10.098], loss: 0.001516, mae: 0.042364, mean_q: 1.165860
 601600/1000000: episode: 6016, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.690, mean reward: 0.577 [0.498, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.120, 10.215], loss: 0.001428, mae: 0.040667, mean_q: 1.165546
 601700/1000000: episode: 6017, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.663, mean reward: 0.607 [0.502, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.055, 10.161], loss: 0.001456, mae: 0.041380, mean_q: 1.166322
 601800/1000000: episode: 6018, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.634, mean reward: 0.586 [0.504, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.887, 10.098], loss: 0.001387, mae: 0.039982, mean_q: 1.164279
 601900/1000000: episode: 6019, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.563, mean reward: 0.576 [0.497, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.926, 10.206], loss: 0.001493, mae: 0.042143, mean_q: 1.164875
 602000/1000000: episode: 6020, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.667, mean reward: 0.587 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.855, 10.098], loss: 0.001535, mae: 0.042501, mean_q: 1.169803
 602100/1000000: episode: 6021, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.053, mean reward: 0.601 [0.509, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.681, 10.329], loss: 0.001513, mae: 0.042144, mean_q: 1.164659
 602200/1000000: episode: 6022, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.636, mean reward: 0.576 [0.505, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.804, 10.308], loss: 0.001468, mae: 0.042118, mean_q: 1.168256
 602300/1000000: episode: 6023, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.142, mean reward: 0.611 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.917, 10.098], loss: 0.001429, mae: 0.041335, mean_q: 1.164714
 602400/1000000: episode: 6024, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.367, mean reward: 0.584 [0.509, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.815, 10.372], loss: 0.001443, mae: 0.041178, mean_q: 1.167133
 602500/1000000: episode: 6025, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 66.289, mean reward: 0.663 [0.510, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.080, 10.479], loss: 0.001439, mae: 0.041256, mean_q: 1.167084
 602600/1000000: episode: 6026, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.423, mean reward: 0.584 [0.510, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.377, 10.136], loss: 0.001424, mae: 0.041328, mean_q: 1.169755
 602700/1000000: episode: 6027, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 63.152, mean reward: 0.632 [0.512, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.385, 10.098], loss: 0.001438, mae: 0.040917, mean_q: 1.170164
 602800/1000000: episode: 6028, duration: 0.694s, episode steps: 100, steps per second: 144, episode reward: 59.350, mean reward: 0.593 [0.507, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.255, 10.232], loss: 0.001484, mae: 0.042218, mean_q: 1.173297
 602900/1000000: episode: 6029, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.346, mean reward: 0.593 [0.511, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.631, 10.098], loss: 0.001402, mae: 0.041118, mean_q: 1.171252
 603000/1000000: episode: 6030, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.687, mean reward: 0.597 [0.504, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.620, 10.098], loss: 0.001492, mae: 0.041939, mean_q: 1.173113
 603100/1000000: episode: 6031, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 64.357, mean reward: 0.644 [0.503, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.303, 10.475], loss: 0.001337, mae: 0.039611, mean_q: 1.170136
 603200/1000000: episode: 6032, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.398, mean reward: 0.604 [0.504, 0.841], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.902, 10.540], loss: 0.001400, mae: 0.040824, mean_q: 1.173668
 603300/1000000: episode: 6033, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 61.530, mean reward: 0.615 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.080, 10.098], loss: 0.001379, mae: 0.040548, mean_q: 1.174376
 603400/1000000: episode: 6034, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.759, mean reward: 0.588 [0.503, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.384, 10.098], loss: 0.001464, mae: 0.041912, mean_q: 1.177194
 603500/1000000: episode: 6035, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 60.062, mean reward: 0.601 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.978, 10.215], loss: 0.001362, mae: 0.040596, mean_q: 1.176628
 603600/1000000: episode: 6036, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.803, mean reward: 0.608 [0.506, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.346, 10.343], loss: 0.001445, mae: 0.041658, mean_q: 1.177513
 603700/1000000: episode: 6037, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 61.330, mean reward: 0.613 [0.506, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.626, 10.322], loss: 0.001449, mae: 0.041556, mean_q: 1.179651
 603800/1000000: episode: 6038, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 63.992, mean reward: 0.640 [0.508, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.780, 10.098], loss: 0.001374, mae: 0.040610, mean_q: 1.174581
 603900/1000000: episode: 6039, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 66.220, mean reward: 0.662 [0.511, 0.898], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.232, 10.584], loss: 0.001456, mae: 0.041650, mean_q: 1.179857
 604000/1000000: episode: 6040, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.398, mean reward: 0.584 [0.505, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.504, 10.219], loss: 0.001413, mae: 0.041021, mean_q: 1.183019
 604100/1000000: episode: 6041, duration: 0.654s, episode steps: 100, steps per second: 153, episode reward: 56.704, mean reward: 0.567 [0.508, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.399, 10.282], loss: 0.001417, mae: 0.041518, mean_q: 1.179529
 604200/1000000: episode: 6042, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.775, mean reward: 0.598 [0.498, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.211, 10.098], loss: 0.001445, mae: 0.041307, mean_q: 1.182546
 604300/1000000: episode: 6043, duration: 0.648s, episode steps: 100, steps per second: 154, episode reward: 58.431, mean reward: 0.584 [0.505, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.604, 10.236], loss: 0.001404, mae: 0.040505, mean_q: 1.178992
 604384/1000000: episode: 6044, duration: 0.457s, episode steps: 84, steps per second: 184, episode reward: 50.687, mean reward: 0.603 [0.502, 1.004], mean action: 0.000 [0.000, 0.000], mean observation: 1.280 [-1.881, 9.404], loss: 0.001414, mae: 0.041372, mean_q: 1.178643
 604484/1000000: episode: 6045, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.925, mean reward: 0.589 [0.502, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.385, 10.248], loss: 0.001352, mae: 0.040133, mean_q: 1.178570
 604584/1000000: episode: 6046, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 56.924, mean reward: 0.569 [0.497, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.431, 10.098], loss: 0.001389, mae: 0.040740, mean_q: 1.177771
 604684/1000000: episode: 6047, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 64.348, mean reward: 0.643 [0.504, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.422, 10.098], loss: 0.001475, mae: 0.042173, mean_q: 1.184286
 604784/1000000: episode: 6048, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.257, mean reward: 0.583 [0.509, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.217, 10.145], loss: 0.001543, mae: 0.042093, mean_q: 1.179255
 604884/1000000: episode: 6049, duration: 0.683s, episode steps: 100, steps per second: 146, episode reward: 59.379, mean reward: 0.594 [0.508, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.644, 10.098], loss: 0.001451, mae: 0.041299, mean_q: 1.180608
 604984/1000000: episode: 6050, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.646, mean reward: 0.606 [0.510, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.035, 10.253], loss: 0.001432, mae: 0.040721, mean_q: 1.178993
 605084/1000000: episode: 6051, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.546, mean reward: 0.605 [0.508, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.208, 10.098], loss: 0.001441, mae: 0.041589, mean_q: 1.181732
 605184/1000000: episode: 6052, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.258, mean reward: 0.583 [0.509, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.414, 10.201], loss: 0.001549, mae: 0.042804, mean_q: 1.183546
 605284/1000000: episode: 6053, duration: 0.667s, episode steps: 100, steps per second: 150, episode reward: 58.339, mean reward: 0.583 [0.502, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.805, 10.339], loss: 0.001529, mae: 0.042454, mean_q: 1.186929
 605384/1000000: episode: 6054, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.402, mean reward: 0.574 [0.505, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.541, 10.098], loss: 0.001452, mae: 0.041835, mean_q: 1.182198
 605484/1000000: episode: 6055, duration: 0.622s, episode steps: 100, steps per second: 161, episode reward: 57.701, mean reward: 0.577 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.840, 10.217], loss: 0.001551, mae: 0.042128, mean_q: 1.184359
 605584/1000000: episode: 6056, duration: 0.678s, episode steps: 100, steps per second: 148, episode reward: 58.973, mean reward: 0.590 [0.506, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.193, 10.173], loss: 0.001491, mae: 0.041808, mean_q: 1.184632
 605684/1000000: episode: 6057, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.338, mean reward: 0.583 [0.505, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.600, 10.098], loss: 0.001399, mae: 0.040618, mean_q: 1.184914
 605784/1000000: episode: 6058, duration: 0.619s, episode steps: 100, steps per second: 162, episode reward: 59.295, mean reward: 0.593 [0.526, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.436, 10.098], loss: 0.001410, mae: 0.040871, mean_q: 1.182301
 605884/1000000: episode: 6059, duration: 0.666s, episode steps: 100, steps per second: 150, episode reward: 58.279, mean reward: 0.583 [0.504, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.771, 10.139], loss: 0.001318, mae: 0.039824, mean_q: 1.181385
 605984/1000000: episode: 6060, duration: 0.643s, episode steps: 100, steps per second: 156, episode reward: 57.597, mean reward: 0.576 [0.499, 0.664], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.605, 10.195], loss: 0.001480, mae: 0.041151, mean_q: 1.183492
 606084/1000000: episode: 6061, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.580, mean reward: 0.596 [0.510, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.494, 10.279], loss: 0.001457, mae: 0.041798, mean_q: 1.176873
 606184/1000000: episode: 6062, duration: 0.634s, episode steps: 100, steps per second: 158, episode reward: 59.807, mean reward: 0.598 [0.516, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.644, 10.296], loss: 0.001462, mae: 0.041444, mean_q: 1.181909
 606284/1000000: episode: 6063, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.350, mean reward: 0.593 [0.504, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.350, 10.098], loss: 0.001529, mae: 0.042163, mean_q: 1.181294
 606384/1000000: episode: 6064, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.501, mean reward: 0.575 [0.500, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.791, 10.142], loss: 0.001441, mae: 0.041080, mean_q: 1.179304
 606484/1000000: episode: 6065, duration: 0.822s, episode steps: 100, steps per second: 122, episode reward: 60.526, mean reward: 0.605 [0.510, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.071, 10.220], loss: 0.001429, mae: 0.040972, mean_q: 1.183164
 606584/1000000: episode: 6066, duration: 0.775s, episode steps: 100, steps per second: 129, episode reward: 60.303, mean reward: 0.603 [0.510, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.409, 10.098], loss: 0.001494, mae: 0.041818, mean_q: 1.182909
 606684/1000000: episode: 6067, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.932, mean reward: 0.569 [0.508, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.905, 10.183], loss: 0.001469, mae: 0.041946, mean_q: 1.182126
 606784/1000000: episode: 6068, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.645, mean reward: 0.606 [0.505, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.738, 10.098], loss: 0.001445, mae: 0.041367, mean_q: 1.180437
 606884/1000000: episode: 6069, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.033, mean reward: 0.580 [0.504, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.729, 10.098], loss: 0.001412, mae: 0.040774, mean_q: 1.179307
 606984/1000000: episode: 6070, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 61.245, mean reward: 0.612 [0.510, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.068, 10.098], loss: 0.001500, mae: 0.041920, mean_q: 1.183483
 607084/1000000: episode: 6071, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.356, mean reward: 0.584 [0.507, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.637, 10.311], loss: 0.001493, mae: 0.042427, mean_q: 1.184170
 607184/1000000: episode: 6072, duration: 0.746s, episode steps: 100, steps per second: 134, episode reward: 58.639, mean reward: 0.586 [0.501, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.246, 10.222], loss: 0.001432, mae: 0.041073, mean_q: 1.178934
 607284/1000000: episode: 6073, duration: 1.083s, episode steps: 100, steps per second: 92, episode reward: 59.349, mean reward: 0.593 [0.502, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.421, 10.262], loss: 0.001556, mae: 0.041914, mean_q: 1.183354
 607384/1000000: episode: 6074, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.634, mean reward: 0.576 [0.499, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.606, 10.098], loss: 0.001491, mae: 0.041550, mean_q: 1.185844
 607484/1000000: episode: 6075, duration: 0.849s, episode steps: 100, steps per second: 118, episode reward: 57.929, mean reward: 0.579 [0.502, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.644, 10.101], loss: 0.001500, mae: 0.041822, mean_q: 1.179129
 607584/1000000: episode: 6076, duration: 0.897s, episode steps: 100, steps per second: 112, episode reward: 64.451, mean reward: 0.645 [0.503, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.528, 10.098], loss: 0.001472, mae: 0.041652, mean_q: 1.181064
 607684/1000000: episode: 6077, duration: 0.819s, episode steps: 100, steps per second: 122, episode reward: 59.650, mean reward: 0.597 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.696, 10.098], loss: 0.001510, mae: 0.041544, mean_q: 1.180939
 607784/1000000: episode: 6078, duration: 1.242s, episode steps: 100, steps per second: 81, episode reward: 58.087, mean reward: 0.581 [0.512, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.238, 10.240], loss: 0.001506, mae: 0.042264, mean_q: 1.181441
 607884/1000000: episode: 6079, duration: 1.145s, episode steps: 100, steps per second: 87, episode reward: 59.529, mean reward: 0.595 [0.505, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.576, 10.234], loss: 0.001524, mae: 0.041715, mean_q: 1.182440
 607984/1000000: episode: 6080, duration: 1.167s, episode steps: 100, steps per second: 86, episode reward: 57.303, mean reward: 0.573 [0.502, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.524, 10.098], loss: 0.001433, mae: 0.041350, mean_q: 1.174260
 608084/1000000: episode: 6081, duration: 1.168s, episode steps: 100, steps per second: 86, episode reward: 58.974, mean reward: 0.590 [0.503, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.758, 10.098], loss: 0.001554, mae: 0.042697, mean_q: 1.177697
 608184/1000000: episode: 6082, duration: 1.585s, episode steps: 100, steps per second: 63, episode reward: 57.462, mean reward: 0.575 [0.502, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.487, 10.134], loss: 0.001574, mae: 0.042780, mean_q: 1.177904
 608284/1000000: episode: 6083, duration: 0.907s, episode steps: 100, steps per second: 110, episode reward: 59.003, mean reward: 0.590 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.800, 10.398], loss: 0.001503, mae: 0.042322, mean_q: 1.171674
 608384/1000000: episode: 6084, duration: 1.018s, episode steps: 100, steps per second: 98, episode reward: 58.551, mean reward: 0.586 [0.502, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.536, 10.192], loss: 0.001532, mae: 0.041475, mean_q: 1.173609
 608484/1000000: episode: 6085, duration: 0.848s, episode steps: 100, steps per second: 118, episode reward: 58.636, mean reward: 0.586 [0.509, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.197, 10.286], loss: 0.001453, mae: 0.041650, mean_q: 1.172982
 608584/1000000: episode: 6086, duration: 0.689s, episode steps: 100, steps per second: 145, episode reward: 56.674, mean reward: 0.567 [0.507, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.522, 10.136], loss: 0.001576, mae: 0.043347, mean_q: 1.173257
 608684/1000000: episode: 6087, duration: 0.983s, episode steps: 100, steps per second: 102, episode reward: 59.971, mean reward: 0.600 [0.509, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.368, 10.381], loss: 0.001566, mae: 0.042472, mean_q: 1.173355
 608784/1000000: episode: 6088, duration: 0.668s, episode steps: 100, steps per second: 150, episode reward: 57.441, mean reward: 0.574 [0.502, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.921, 10.105], loss: 0.001448, mae: 0.041074, mean_q: 1.170944
 608884/1000000: episode: 6089, duration: 0.839s, episode steps: 100, steps per second: 119, episode reward: 60.861, mean reward: 0.609 [0.511, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.632, 10.098], loss: 0.001499, mae: 0.041557, mean_q: 1.170622
 608984/1000000: episode: 6090, duration: 1.070s, episode steps: 100, steps per second: 93, episode reward: 58.178, mean reward: 0.582 [0.503, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.730, 10.098], loss: 0.001451, mae: 0.041738, mean_q: 1.171335
 609084/1000000: episode: 6091, duration: 0.701s, episode steps: 100, steps per second: 143, episode reward: 58.066, mean reward: 0.581 [0.518, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.601, 10.098], loss: 0.001501, mae: 0.041874, mean_q: 1.170684
 609184/1000000: episode: 6092, duration: 0.716s, episode steps: 100, steps per second: 140, episode reward: 57.131, mean reward: 0.571 [0.509, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.807, 10.098], loss: 0.001510, mae: 0.041856, mean_q: 1.168654
 609284/1000000: episode: 6093, duration: 0.669s, episode steps: 100, steps per second: 150, episode reward: 58.145, mean reward: 0.581 [0.507, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.415, 10.098], loss: 0.001468, mae: 0.040969, mean_q: 1.167621
 609384/1000000: episode: 6094, duration: 0.871s, episode steps: 100, steps per second: 115, episode reward: 57.527, mean reward: 0.575 [0.502, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.437, 10.227], loss: 0.001500, mae: 0.042026, mean_q: 1.169281
 609484/1000000: episode: 6095, duration: 0.696s, episode steps: 100, steps per second: 144, episode reward: 56.673, mean reward: 0.567 [0.502, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.451, 10.098], loss: 0.001363, mae: 0.039887, mean_q: 1.162837
 609584/1000000: episode: 6096, duration: 0.925s, episode steps: 100, steps per second: 108, episode reward: 60.986, mean reward: 0.610 [0.498, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.707, 10.183], loss: 0.001364, mae: 0.039793, mean_q: 1.163411
 609684/1000000: episode: 6097, duration: 0.972s, episode steps: 100, steps per second: 103, episode reward: 60.028, mean reward: 0.600 [0.515, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.428, 10.325], loss: 0.001351, mae: 0.039555, mean_q: 1.163591
 609784/1000000: episode: 6098, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 57.080, mean reward: 0.571 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.696, 10.202], loss: 0.001402, mae: 0.040285, mean_q: 1.161760
 609884/1000000: episode: 6099, duration: 0.662s, episode steps: 100, steps per second: 151, episode reward: 57.801, mean reward: 0.578 [0.508, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.447, 10.322], loss: 0.001445, mae: 0.041566, mean_q: 1.165511
 609984/1000000: episode: 6100, duration: 0.701s, episode steps: 100, steps per second: 143, episode reward: 59.332, mean reward: 0.593 [0.500, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.827, 10.152], loss: 0.001405, mae: 0.040723, mean_q: 1.158282
 610084/1000000: episode: 6101, duration: 0.663s, episode steps: 100, steps per second: 151, episode reward: 58.439, mean reward: 0.584 [0.522, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.875, 10.098], loss: 0.001437, mae: 0.041130, mean_q: 1.162421
 610184/1000000: episode: 6102, duration: 0.856s, episode steps: 100, steps per second: 117, episode reward: 56.565, mean reward: 0.566 [0.507, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.716, 10.098], loss: 0.001394, mae: 0.040340, mean_q: 1.163470
 610284/1000000: episode: 6103, duration: 0.742s, episode steps: 100, steps per second: 135, episode reward: 56.690, mean reward: 0.567 [0.503, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.214, 10.249], loss: 0.001325, mae: 0.039079, mean_q: 1.163059
 610384/1000000: episode: 6104, duration: 1.016s, episode steps: 100, steps per second: 98, episode reward: 61.134, mean reward: 0.611 [0.508, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.467, 10.596], loss: 0.001335, mae: 0.039972, mean_q: 1.161277
 610484/1000000: episode: 6105, duration: 0.634s, episode steps: 100, steps per second: 158, episode reward: 57.264, mean reward: 0.573 [0.500, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.297, 10.141], loss: 0.001434, mae: 0.040969, mean_q: 1.164129
 610584/1000000: episode: 6106, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 57.948, mean reward: 0.579 [0.505, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.559, 10.098], loss: 0.001389, mae: 0.040273, mean_q: 1.161871
 610684/1000000: episode: 6107, duration: 0.735s, episode steps: 100, steps per second: 136, episode reward: 57.975, mean reward: 0.580 [0.506, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.589, 10.098], loss: 0.001355, mae: 0.040050, mean_q: 1.165072
 610784/1000000: episode: 6108, duration: 1.080s, episode steps: 100, steps per second: 93, episode reward: 58.083, mean reward: 0.581 [0.515, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.963, 10.098], loss: 0.001385, mae: 0.040346, mean_q: 1.158585
 610884/1000000: episode: 6109, duration: 0.724s, episode steps: 100, steps per second: 138, episode reward: 58.805, mean reward: 0.588 [0.504, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.227, 10.098], loss: 0.001447, mae: 0.041743, mean_q: 1.156959
 610984/1000000: episode: 6110, duration: 0.623s, episode steps: 100, steps per second: 161, episode reward: 59.035, mean reward: 0.590 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.567, 10.098], loss: 0.001465, mae: 0.041430, mean_q: 1.161719
 611084/1000000: episode: 6111, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.281, mean reward: 0.613 [0.512, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.191, 10.098], loss: 0.001410, mae: 0.040327, mean_q: 1.163018
 611184/1000000: episode: 6112, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 61.399, mean reward: 0.614 [0.502, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.574, 10.098], loss: 0.001445, mae: 0.041158, mean_q: 1.164757
 611284/1000000: episode: 6113, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.382, mean reward: 0.594 [0.502, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.492, 10.098], loss: 0.001386, mae: 0.039951, mean_q: 1.161434
 611384/1000000: episode: 6114, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 60.957, mean reward: 0.610 [0.508, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.304, 10.477], loss: 0.001346, mae: 0.040009, mean_q: 1.164441
 611484/1000000: episode: 6115, duration: 0.753s, episode steps: 100, steps per second: 133, episode reward: 62.077, mean reward: 0.621 [0.502, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.725, 10.151], loss: 0.001387, mae: 0.040824, mean_q: 1.165840
 611584/1000000: episode: 6116, duration: 0.919s, episode steps: 100, steps per second: 109, episode reward: 58.227, mean reward: 0.582 [0.501, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.907, 10.254], loss: 0.001360, mae: 0.040925, mean_q: 1.164654
 611684/1000000: episode: 6117, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.546, mean reward: 0.585 [0.506, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.300, 10.344], loss: 0.001364, mae: 0.040260, mean_q: 1.164802
 611784/1000000: episode: 6118, duration: 0.671s, episode steps: 100, steps per second: 149, episode reward: 58.766, mean reward: 0.588 [0.511, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.097, 10.305], loss: 0.001429, mae: 0.041231, mean_q: 1.164339
 611884/1000000: episode: 6119, duration: 0.845s, episode steps: 100, steps per second: 118, episode reward: 60.364, mean reward: 0.604 [0.507, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.700, 10.277], loss: 0.001344, mae: 0.040314, mean_q: 1.166002
 611984/1000000: episode: 6120, duration: 0.653s, episode steps: 100, steps per second: 153, episode reward: 58.616, mean reward: 0.586 [0.504, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.050, 10.180], loss: 0.001250, mae: 0.038774, mean_q: 1.165213
 612084/1000000: episode: 6121, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 60.523, mean reward: 0.605 [0.522, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.527, 10.098], loss: 0.001330, mae: 0.039457, mean_q: 1.164539
 612184/1000000: episode: 6122, duration: 0.658s, episode steps: 100, steps per second: 152, episode reward: 59.287, mean reward: 0.593 [0.508, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.027, 10.098], loss: 0.001278, mae: 0.038758, mean_q: 1.161785
 612284/1000000: episode: 6123, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.407, mean reward: 0.584 [0.502, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.224, 10.134], loss: 0.001380, mae: 0.041046, mean_q: 1.162916
 612384/1000000: episode: 6124, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 59.854, mean reward: 0.599 [0.499, 0.841], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.509, 10.407], loss: 0.001429, mae: 0.041484, mean_q: 1.163636
 612484/1000000: episode: 6125, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.422, mean reward: 0.584 [0.511, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.604, 10.098], loss: 0.001356, mae: 0.040269, mean_q: 1.164589
 612584/1000000: episode: 6126, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.119, mean reward: 0.591 [0.509, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.470, 10.375], loss: 0.001286, mae: 0.039334, mean_q: 1.161893
 612684/1000000: episode: 6127, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.453, mean reward: 0.585 [0.507, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.896, 10.146], loss: 0.001266, mae: 0.039246, mean_q: 1.161134
 612784/1000000: episode: 6128, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.595, mean reward: 0.586 [0.512, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.645, 10.192], loss: 0.001316, mae: 0.039756, mean_q: 1.162225
 612884/1000000: episode: 6129, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.550, mean reward: 0.586 [0.507, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.911, 10.098], loss: 0.001305, mae: 0.039509, mean_q: 1.165778
 612984/1000000: episode: 6130, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 62.232, mean reward: 0.622 [0.529, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.446, 10.098], loss: 0.001291, mae: 0.039509, mean_q: 1.160956
 613084/1000000: episode: 6131, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.662, mean reward: 0.587 [0.502, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.575, 10.315], loss: 0.001318, mae: 0.039969, mean_q: 1.162169
 613184/1000000: episode: 6132, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 56.839, mean reward: 0.568 [0.503, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.744, 10.171], loss: 0.001445, mae: 0.041342, mean_q: 1.167975
 613284/1000000: episode: 6133, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.638, mean reward: 0.596 [0.514, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.120, 10.338], loss: 0.001359, mae: 0.040364, mean_q: 1.164783
 613384/1000000: episode: 6134, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.297, mean reward: 0.593 [0.511, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.367, 10.175], loss: 0.001395, mae: 0.040643, mean_q: 1.164079
 613484/1000000: episode: 6135, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.034, mean reward: 0.600 [0.514, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.253, 10.098], loss: 0.001345, mae: 0.039835, mean_q: 1.163758
 613584/1000000: episode: 6136, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 56.584, mean reward: 0.566 [0.501, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.686, 10.098], loss: 0.001362, mae: 0.040456, mean_q: 1.164746
 613684/1000000: episode: 6137, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 56.540, mean reward: 0.565 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.337, 10.121], loss: 0.001357, mae: 0.040593, mean_q: 1.166573
 613784/1000000: episode: 6138, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.235, mean reward: 0.592 [0.516, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.944, 10.098], loss: 0.001385, mae: 0.041168, mean_q: 1.166569
 613884/1000000: episode: 6139, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.545, mean reward: 0.585 [0.503, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.480, 10.181], loss: 0.001379, mae: 0.040396, mean_q: 1.165575
 613984/1000000: episode: 6140, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 62.570, mean reward: 0.626 [0.508, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.686, 10.098], loss: 0.001443, mae: 0.041320, mean_q: 1.164085
 614084/1000000: episode: 6141, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.461, mean reward: 0.595 [0.497, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.259, 10.098], loss: 0.001474, mae: 0.042259, mean_q: 1.165288
 614184/1000000: episode: 6142, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 60.177, mean reward: 0.602 [0.506, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.070, 10.098], loss: 0.001305, mae: 0.039455, mean_q: 1.163834
 614284/1000000: episode: 6143, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.260, mean reward: 0.583 [0.502, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.898, 10.146], loss: 0.001430, mae: 0.041285, mean_q: 1.166144
 614384/1000000: episode: 6144, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 64.152, mean reward: 0.642 [0.501, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.452, 10.098], loss: 0.001379, mae: 0.040937, mean_q: 1.169325
 614484/1000000: episode: 6145, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.680, mean reward: 0.597 [0.518, 0.871], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.221, 10.098], loss: 0.001437, mae: 0.041276, mean_q: 1.172195
 614584/1000000: episode: 6146, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.709, mean reward: 0.587 [0.506, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.589, 10.136], loss: 0.001415, mae: 0.041696, mean_q: 1.166723
 614684/1000000: episode: 6147, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.246, mean reward: 0.602 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.104, 10.098], loss: 0.001427, mae: 0.041574, mean_q: 1.173285
 614784/1000000: episode: 6148, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 60.785, mean reward: 0.608 [0.514, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.520, 10.223], loss: 0.001482, mae: 0.042654, mean_q: 1.172823
 614884/1000000: episode: 6149, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.535, mean reward: 0.595 [0.513, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.660, 10.098], loss: 0.001477, mae: 0.042329, mean_q: 1.176424
 614984/1000000: episode: 6150, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 60.781, mean reward: 0.608 [0.514, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.794, 10.331], loss: 0.001623, mae: 0.044209, mean_q: 1.174730
 615084/1000000: episode: 6151, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.869, mean reward: 0.579 [0.505, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.600, 10.123], loss: 0.001620, mae: 0.043714, mean_q: 1.178517
 615184/1000000: episode: 6152, duration: 0.614s, episode steps: 100, steps per second: 163, episode reward: 62.075, mean reward: 0.621 [0.505, 0.858], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.099, 10.098], loss: 0.001404, mae: 0.041080, mean_q: 1.173917
 615284/1000000: episode: 6153, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 64.017, mean reward: 0.640 [0.510, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.106, 10.431], loss: 0.001539, mae: 0.042686, mean_q: 1.178161
 615384/1000000: episode: 6154, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.169, mean reward: 0.582 [0.501, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.705, 10.098], loss: 0.001597, mae: 0.043516, mean_q: 1.176822
 615484/1000000: episode: 6155, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 58.390, mean reward: 0.584 [0.504, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.427, 10.162], loss: 0.001509, mae: 0.042690, mean_q: 1.175119
 615584/1000000: episode: 6156, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 59.536, mean reward: 0.595 [0.503, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.654, 10.098], loss: 0.001524, mae: 0.042526, mean_q: 1.179561
 615684/1000000: episode: 6157, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.695, mean reward: 0.597 [0.525, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.485, 10.262], loss: 0.001412, mae: 0.041485, mean_q: 1.179386
 615784/1000000: episode: 6158, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.552, mean reward: 0.566 [0.504, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.980, 10.122], loss: 0.001388, mae: 0.040833, mean_q: 1.175105
 615884/1000000: episode: 6159, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.424, mean reward: 0.574 [0.508, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.646, 10.429], loss: 0.001562, mae: 0.042881, mean_q: 1.177028
 615984/1000000: episode: 6160, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.150, mean reward: 0.571 [0.504, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.473, 10.252], loss: 0.001476, mae: 0.042450, mean_q: 1.178181
 616084/1000000: episode: 6161, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.675, mean reward: 0.607 [0.511, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.330, 10.098], loss: 0.001452, mae: 0.041356, mean_q: 1.177652
 616184/1000000: episode: 6162, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.745, mean reward: 0.577 [0.505, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.888, 10.104], loss: 0.001471, mae: 0.041834, mean_q: 1.177223
 616284/1000000: episode: 6163, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.739, mean reward: 0.597 [0.500, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.606, 10.098], loss: 0.001514, mae: 0.042884, mean_q: 1.174475
 616384/1000000: episode: 6164, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.840, mean reward: 0.598 [0.511, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.517, 10.175], loss: 0.001498, mae: 0.042603, mean_q: 1.176362
 616484/1000000: episode: 6165, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.421, mean reward: 0.584 [0.500, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.744, 10.098], loss: 0.001586, mae: 0.043392, mean_q: 1.174738
 616584/1000000: episode: 6166, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.146, mean reward: 0.581 [0.504, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.056, 10.098], loss: 0.001467, mae: 0.042027, mean_q: 1.175519
 616684/1000000: episode: 6167, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.673, mean reward: 0.587 [0.511, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.543, 10.098], loss: 0.001564, mae: 0.043164, mean_q: 1.174474
 616784/1000000: episode: 6168, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 58.158, mean reward: 0.582 [0.513, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.474, 10.098], loss: 0.001574, mae: 0.043190, mean_q: 1.174932
 616884/1000000: episode: 6169, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.370, mean reward: 0.594 [0.500, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.931, 10.098], loss: 0.001569, mae: 0.043066, mean_q: 1.173555
 616984/1000000: episode: 6170, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.631, mean reward: 0.586 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.709, 10.098], loss: 0.001501, mae: 0.041971, mean_q: 1.173639
 617084/1000000: episode: 6171, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.934, mean reward: 0.579 [0.501, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.332, 10.208], loss: 0.001479, mae: 0.042006, mean_q: 1.173947
 617184/1000000: episode: 6172, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 59.218, mean reward: 0.592 [0.509, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.611, 10.143], loss: 0.001471, mae: 0.042140, mean_q: 1.175136
 617284/1000000: episode: 6173, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 64.203, mean reward: 0.642 [0.515, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.427, 10.538], loss: 0.001448, mae: 0.041187, mean_q: 1.168163
 617384/1000000: episode: 6174, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.286, mean reward: 0.583 [0.502, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.086, 10.254], loss: 0.001469, mae: 0.042023, mean_q: 1.174554
 617484/1000000: episode: 6175, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.401, mean reward: 0.594 [0.503, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.844, 10.098], loss: 0.001442, mae: 0.041354, mean_q: 1.170992
 617584/1000000: episode: 6176, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.285, mean reward: 0.623 [0.510, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.485, 10.474], loss: 0.001549, mae: 0.042614, mean_q: 1.174260
 617684/1000000: episode: 6177, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.269, mean reward: 0.573 [0.503, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.603, 10.117], loss: 0.001548, mae: 0.042703, mean_q: 1.176440
 617784/1000000: episode: 6178, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.373, mean reward: 0.584 [0.504, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.284, 10.238], loss: 0.001498, mae: 0.042067, mean_q: 1.175876
 617884/1000000: episode: 6179, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.391, mean reward: 0.594 [0.506, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.483, 10.179], loss: 0.001560, mae: 0.043326, mean_q: 1.175409
 617984/1000000: episode: 6180, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 56.588, mean reward: 0.566 [0.506, 0.653], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.449, 10.194], loss: 0.001558, mae: 0.042486, mean_q: 1.174880
 618084/1000000: episode: 6181, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.653, mean reward: 0.587 [0.513, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.862, 10.300], loss: 0.001486, mae: 0.042433, mean_q: 1.175295
 618184/1000000: episode: 6182, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.911, mean reward: 0.589 [0.500, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.662, 10.170], loss: 0.001523, mae: 0.042497, mean_q: 1.175012
 618284/1000000: episode: 6183, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.390, mean reward: 0.584 [0.501, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.585, 10.098], loss: 0.001510, mae: 0.042373, mean_q: 1.175005
 618384/1000000: episode: 6184, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.659, mean reward: 0.597 [0.506, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.414, 10.098], loss: 0.001407, mae: 0.040554, mean_q: 1.172669
 618484/1000000: episode: 6185, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.769, mean reward: 0.568 [0.505, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.602, 10.286], loss: 0.001488, mae: 0.041862, mean_q: 1.171088
 618584/1000000: episode: 6186, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.425, mean reward: 0.574 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.711, 10.098], loss: 0.001495, mae: 0.041791, mean_q: 1.175081
 618684/1000000: episode: 6187, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.702, mean reward: 0.577 [0.505, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.655, 10.098], loss: 0.001391, mae: 0.040362, mean_q: 1.171927
 618784/1000000: episode: 6188, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.825, mean reward: 0.598 [0.506, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.992, 10.150], loss: 0.001351, mae: 0.040212, mean_q: 1.171447
 618884/1000000: episode: 6189, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.108, mean reward: 0.581 [0.503, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.042, 10.162], loss: 0.001507, mae: 0.042453, mean_q: 1.170956
 618984/1000000: episode: 6190, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.127, mean reward: 0.581 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.213, 10.274], loss: 0.001438, mae: 0.041293, mean_q: 1.173342
 619084/1000000: episode: 6191, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.407, mean reward: 0.594 [0.500, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.993, 10.098], loss: 0.001400, mae: 0.040733, mean_q: 1.169158
 619184/1000000: episode: 6192, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.310, mean reward: 0.573 [0.506, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.263, 10.134], loss: 0.001396, mae: 0.040518, mean_q: 1.171792
 619284/1000000: episode: 6193, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 56.426, mean reward: 0.564 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.855, 10.108], loss: 0.001462, mae: 0.041234, mean_q: 1.175218
 619384/1000000: episode: 6194, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.355, mean reward: 0.594 [0.498, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.798, 10.279], loss: 0.001465, mae: 0.042018, mean_q: 1.167288
 619484/1000000: episode: 6195, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.771, mean reward: 0.578 [0.506, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.485, 10.146], loss: 0.001365, mae: 0.040456, mean_q: 1.165036
 619584/1000000: episode: 6196, duration: 0.691s, episode steps: 100, steps per second: 145, episode reward: 59.945, mean reward: 0.599 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.395, 10.340], loss: 0.001473, mae: 0.041305, mean_q: 1.165108
 619684/1000000: episode: 6197, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.353, mean reward: 0.574 [0.501, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.601, 10.098], loss: 0.001425, mae: 0.041210, mean_q: 1.167308
 619784/1000000: episode: 6198, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 63.382, mean reward: 0.634 [0.502, 0.847], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.884, 10.526], loss: 0.001397, mae: 0.040703, mean_q: 1.168080
 619884/1000000: episode: 6199, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.765, mean reward: 0.588 [0.511, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.363, 10.394], loss: 0.001351, mae: 0.040501, mean_q: 1.165597
 619984/1000000: episode: 6200, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.600, mean reward: 0.576 [0.499, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.368, 10.098], loss: 0.001356, mae: 0.040155, mean_q: 1.164865
 620084/1000000: episode: 6201, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.003, mean reward: 0.570 [0.503, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.634, 10.098], loss: 0.001405, mae: 0.040685, mean_q: 1.164066
 620184/1000000: episode: 6202, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.878, mean reward: 0.599 [0.503, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.085, 10.098], loss: 0.001332, mae: 0.039516, mean_q: 1.164900
 620284/1000000: episode: 6203, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 61.814, mean reward: 0.618 [0.508, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.714, 10.098], loss: 0.001320, mae: 0.040072, mean_q: 1.160131
 620384/1000000: episode: 6204, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.105, mean reward: 0.571 [0.502, 0.663], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.522, 10.098], loss: 0.001334, mae: 0.039773, mean_q: 1.162618
 620484/1000000: episode: 6205, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.132, mean reward: 0.591 [0.498, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.987, 10.205], loss: 0.001354, mae: 0.039953, mean_q: 1.162197
 620584/1000000: episode: 6206, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.336, mean reward: 0.613 [0.502, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.284, 10.416], loss: 0.001358, mae: 0.040160, mean_q: 1.165256
 620684/1000000: episode: 6207, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.612, mean reward: 0.586 [0.499, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.130, 10.481], loss: 0.001251, mae: 0.038820, mean_q: 1.161344
 620784/1000000: episode: 6208, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.832, mean reward: 0.578 [0.497, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.956, 10.182], loss: 0.001370, mae: 0.040405, mean_q: 1.165971
 620884/1000000: episode: 6209, duration: 0.624s, episode steps: 100, steps per second: 160, episode reward: 62.816, mean reward: 0.628 [0.512, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.438, 10.098], loss: 0.001462, mae: 0.041514, mean_q: 1.168461
 620984/1000000: episode: 6210, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.579, mean reward: 0.576 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.609, 10.267], loss: 0.001430, mae: 0.040982, mean_q: 1.167347
 621084/1000000: episode: 6211, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 62.833, mean reward: 0.628 [0.502, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.172, 10.498], loss: 0.001482, mae: 0.041933, mean_q: 1.167474
 621184/1000000: episode: 6212, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.981, mean reward: 0.590 [0.511, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.152, 10.153], loss: 0.001415, mae: 0.040820, mean_q: 1.163347
 621284/1000000: episode: 6213, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.102, mean reward: 0.581 [0.514, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.574, 10.098], loss: 0.001376, mae: 0.040320, mean_q: 1.163081
 621384/1000000: episode: 6214, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 56.908, mean reward: 0.569 [0.499, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.730, 10.180], loss: 0.001432, mae: 0.041154, mean_q: 1.166418
 621484/1000000: episode: 6215, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 61.965, mean reward: 0.620 [0.513, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.516, 10.098], loss: 0.001330, mae: 0.040067, mean_q: 1.164447
 621584/1000000: episode: 6216, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.560, mean reward: 0.586 [0.508, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.378, 10.098], loss: 0.001459, mae: 0.041238, mean_q: 1.170462
 621684/1000000: episode: 6217, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.006, mean reward: 0.610 [0.503, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.349, 10.447], loss: 0.001487, mae: 0.041893, mean_q: 1.170116
 621784/1000000: episode: 6218, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 56.803, mean reward: 0.568 [0.509, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.775, 10.229], loss: 0.001317, mae: 0.039622, mean_q: 1.168131
 621884/1000000: episode: 6219, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 57.551, mean reward: 0.576 [0.508, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.538, 10.153], loss: 0.001324, mae: 0.039909, mean_q: 1.165022
 621984/1000000: episode: 6220, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.874, mean reward: 0.609 [0.499, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.608, 10.098], loss: 0.001354, mae: 0.040005, mean_q: 1.163197
 622084/1000000: episode: 6221, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.461, mean reward: 0.585 [0.504, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.611, 10.098], loss: 0.001306, mae: 0.039295, mean_q: 1.169449
 622184/1000000: episode: 6222, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.857, mean reward: 0.589 [0.507, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-1.188, 10.319], loss: 0.001385, mae: 0.040100, mean_q: 1.168177
 622284/1000000: episode: 6223, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.603, mean reward: 0.616 [0.504, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.166, 10.098], loss: 0.001391, mae: 0.040936, mean_q: 1.169567
 622384/1000000: episode: 6224, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.250, mean reward: 0.582 [0.500, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.072, 10.181], loss: 0.001385, mae: 0.040557, mean_q: 1.166972
 622484/1000000: episode: 6225, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 56.826, mean reward: 0.568 [0.502, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.922, 10.098], loss: 0.001356, mae: 0.039990, mean_q: 1.167556
 622584/1000000: episode: 6226, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 61.838, mean reward: 0.618 [0.524, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.337, 10.228], loss: 0.001312, mae: 0.039613, mean_q: 1.168078
 622684/1000000: episode: 6227, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 56.281, mean reward: 0.563 [0.502, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.569, 10.098], loss: 0.001348, mae: 0.040025, mean_q: 1.169920
 622784/1000000: episode: 6228, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 56.325, mean reward: 0.563 [0.504, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.935, 10.450], loss: 0.001349, mae: 0.040155, mean_q: 1.164297
 622884/1000000: episode: 6229, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.782, mean reward: 0.608 [0.501, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.835, 10.098], loss: 0.001340, mae: 0.040058, mean_q: 1.162583
 622984/1000000: episode: 6230, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.775, mean reward: 0.578 [0.504, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.966, 10.135], loss: 0.001492, mae: 0.042160, mean_q: 1.169544
 623084/1000000: episode: 6231, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.042, mean reward: 0.600 [0.505, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.845, 10.098], loss: 0.001470, mae: 0.041426, mean_q: 1.167952
 623184/1000000: episode: 6232, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.543, mean reward: 0.585 [0.498, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.379, 10.154], loss: 0.001430, mae: 0.041057, mean_q: 1.168025
 623284/1000000: episode: 6233, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.312, mean reward: 0.593 [0.513, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.522, 10.222], loss: 0.001374, mae: 0.040190, mean_q: 1.166482
 623384/1000000: episode: 6234, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.410, mean reward: 0.584 [0.504, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.784, 10.449], loss: 0.001364, mae: 0.040732, mean_q: 1.166401
 623484/1000000: episode: 6235, duration: 0.783s, episode steps: 100, steps per second: 128, episode reward: 58.539, mean reward: 0.585 [0.503, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.823, 10.142], loss: 0.001386, mae: 0.040433, mean_q: 1.168159
 623584/1000000: episode: 6236, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.909, mean reward: 0.589 [0.510, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.495, 10.212], loss: 0.001300, mae: 0.039456, mean_q: 1.166699
 623684/1000000: episode: 6237, duration: 0.709s, episode steps: 100, steps per second: 141, episode reward: 59.438, mean reward: 0.594 [0.509, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.232, 10.327], loss: 0.001333, mae: 0.039948, mean_q: 1.165649
 623784/1000000: episode: 6238, duration: 0.797s, episode steps: 100, steps per second: 125, episode reward: 58.903, mean reward: 0.589 [0.513, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.320, 10.098], loss: 0.001382, mae: 0.040388, mean_q: 1.166958
 623884/1000000: episode: 6239, duration: 0.728s, episode steps: 100, steps per second: 137, episode reward: 60.160, mean reward: 0.602 [0.506, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.638, 10.282], loss: 0.001341, mae: 0.039945, mean_q: 1.168796
 623984/1000000: episode: 6240, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 58.837, mean reward: 0.588 [0.504, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.824, 10.098], loss: 0.001403, mae: 0.040670, mean_q: 1.167829
 624084/1000000: episode: 6241, duration: 0.660s, episode steps: 100, steps per second: 151, episode reward: 58.029, mean reward: 0.580 [0.505, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.498, 10.098], loss: 0.001357, mae: 0.040389, mean_q: 1.168141
 624184/1000000: episode: 6242, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 57.093, mean reward: 0.571 [0.502, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.521, 10.098], loss: 0.001417, mae: 0.041113, mean_q: 1.167692
 624284/1000000: episode: 6243, duration: 0.636s, episode steps: 100, steps per second: 157, episode reward: 60.841, mean reward: 0.608 [0.513, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.055, 10.103], loss: 0.001422, mae: 0.041376, mean_q: 1.170462
 624384/1000000: episode: 6244, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 57.597, mean reward: 0.576 [0.499, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.907, 10.152], loss: 0.001411, mae: 0.040867, mean_q: 1.167795
 624484/1000000: episode: 6245, duration: 0.694s, episode steps: 100, steps per second: 144, episode reward: 60.351, mean reward: 0.604 [0.506, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.692, 10.098], loss: 0.001483, mae: 0.041993, mean_q: 1.169572
 624584/1000000: episode: 6246, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.204, mean reward: 0.572 [0.503, 0.661], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.955, 10.098], loss: 0.001416, mae: 0.040592, mean_q: 1.167668
 624684/1000000: episode: 6247, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.050, mean reward: 0.590 [0.509, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.660, 10.112], loss: 0.001416, mae: 0.040198, mean_q: 1.172580
 624784/1000000: episode: 6248, duration: 0.828s, episode steps: 100, steps per second: 121, episode reward: 59.022, mean reward: 0.590 [0.500, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.704, 10.237], loss: 0.001395, mae: 0.040994, mean_q: 1.169356
 624884/1000000: episode: 6249, duration: 0.649s, episode steps: 100, steps per second: 154, episode reward: 59.770, mean reward: 0.598 [0.499, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.218, 10.135], loss: 0.001487, mae: 0.041624, mean_q: 1.172144
 624984/1000000: episode: 6250, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.372, mean reward: 0.574 [0.501, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.810, 10.148], loss: 0.001314, mae: 0.039405, mean_q: 1.168157
 625084/1000000: episode: 6251, duration: 0.658s, episode steps: 100, steps per second: 152, episode reward: 58.094, mean reward: 0.581 [0.502, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.342, 10.320], loss: 0.001503, mae: 0.041749, mean_q: 1.164214
 625184/1000000: episode: 6252, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.208, mean reward: 0.602 [0.502, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.588, 10.430], loss: 0.001533, mae: 0.042293, mean_q: 1.167516
 625284/1000000: episode: 6253, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.632, mean reward: 0.596 [0.516, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.920, 10.098], loss: 0.001475, mae: 0.041546, mean_q: 1.167313
 625384/1000000: episode: 6254, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.502, mean reward: 0.595 [0.501, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.494, 10.419], loss: 0.001455, mae: 0.041374, mean_q: 1.167542
 625484/1000000: episode: 6255, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.854, mean reward: 0.599 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.445, 10.098], loss: 0.001399, mae: 0.040852, mean_q: 1.167655
 625584/1000000: episode: 6256, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.321, mean reward: 0.603 [0.505, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-1.386, 10.279], loss: 0.001424, mae: 0.041476, mean_q: 1.168922
 625684/1000000: episode: 6257, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.126, mean reward: 0.581 [0.503, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.008, 10.098], loss: 0.001501, mae: 0.041426, mean_q: 1.171349
 625784/1000000: episode: 6258, duration: 0.615s, episode steps: 100, steps per second: 162, episode reward: 59.742, mean reward: 0.597 [0.505, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.041, 10.105], loss: 0.001454, mae: 0.041708, mean_q: 1.168818
 625884/1000000: episode: 6259, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 61.866, mean reward: 0.619 [0.502, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.630, 10.098], loss: 0.001382, mae: 0.040746, mean_q: 1.169221
 625984/1000000: episode: 6260, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 57.558, mean reward: 0.576 [0.499, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.206, 10.098], loss: 0.001286, mae: 0.039260, mean_q: 1.168625
 626084/1000000: episode: 6261, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.213, mean reward: 0.592 [0.501, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.094, 10.144], loss: 0.001461, mae: 0.041396, mean_q: 1.169545
 626184/1000000: episode: 6262, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.981, mean reward: 0.570 [0.501, 0.661], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.678, 10.135], loss: 0.001367, mae: 0.040130, mean_q: 1.163952
 626284/1000000: episode: 6263, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 60.693, mean reward: 0.607 [0.500, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.085, 10.306], loss: 0.001311, mae: 0.039274, mean_q: 1.167338
 626384/1000000: episode: 6264, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.865, mean reward: 0.599 [0.503, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.714, 10.098], loss: 0.001305, mae: 0.039559, mean_q: 1.169929
 626484/1000000: episode: 6265, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.542, mean reward: 0.585 [0.500, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.033, 10.137], loss: 0.001344, mae: 0.040267, mean_q: 1.168934
 626584/1000000: episode: 6266, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.349, mean reward: 0.593 [0.511, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.885, 10.098], loss: 0.001373, mae: 0.040467, mean_q: 1.171110
 626684/1000000: episode: 6267, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.644, mean reward: 0.606 [0.521, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.161, 10.098], loss: 0.001328, mae: 0.039476, mean_q: 1.168615
 626784/1000000: episode: 6268, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.288, mean reward: 0.583 [0.503, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.950, 10.199], loss: 0.001403, mae: 0.041030, mean_q: 1.172230
 626884/1000000: episode: 6269, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.526, mean reward: 0.585 [0.505, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.064, 10.274], loss: 0.001348, mae: 0.040570, mean_q: 1.167971
 626984/1000000: episode: 6270, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.454, mean reward: 0.585 [0.505, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.117, 10.128], loss: 0.001419, mae: 0.041140, mean_q: 1.168239
 627084/1000000: episode: 6271, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.655, mean reward: 0.597 [0.501, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.262, 10.171], loss: 0.001437, mae: 0.041081, mean_q: 1.168988
 627184/1000000: episode: 6272, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.418, mean reward: 0.584 [0.509, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.935, 10.098], loss: 0.001457, mae: 0.041680, mean_q: 1.167154
 627284/1000000: episode: 6273, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.875, mean reward: 0.589 [0.510, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.455, 10.257], loss: 0.001521, mae: 0.042579, mean_q: 1.169559
 627384/1000000: episode: 6274, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.728, mean reward: 0.607 [0.500, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.597, 10.296], loss: 0.001396, mae: 0.040333, mean_q: 1.165015
 627484/1000000: episode: 6275, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.510, mean reward: 0.595 [0.507, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.513, 10.098], loss: 0.001406, mae: 0.040858, mean_q: 1.166908
 627584/1000000: episode: 6276, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.089, mean reward: 0.611 [0.506, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.419, 10.452], loss: 0.001473, mae: 0.042138, mean_q: 1.167865
 627684/1000000: episode: 6277, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.896, mean reward: 0.589 [0.499, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.996, 10.098], loss: 0.001474, mae: 0.041889, mean_q: 1.170278
 627784/1000000: episode: 6278, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.314, mean reward: 0.573 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.276, 10.343], loss: 0.001424, mae: 0.041267, mean_q: 1.166632
 627884/1000000: episode: 6279, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.168, mean reward: 0.582 [0.508, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.424, 10.098], loss: 0.001512, mae: 0.042242, mean_q: 1.169705
 627984/1000000: episode: 6280, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.948, mean reward: 0.589 [0.506, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.966, 10.234], loss: 0.001537, mae: 0.042972, mean_q: 1.172469
 628084/1000000: episode: 6281, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.456, mean reward: 0.595 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.150, 10.098], loss: 0.001399, mae: 0.040752, mean_q: 1.167644
 628184/1000000: episode: 6282, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.397, mean reward: 0.604 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.235, 10.098], loss: 0.001439, mae: 0.041548, mean_q: 1.165930
 628284/1000000: episode: 6283, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.116, mean reward: 0.591 [0.504, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.901, 10.098], loss: 0.001446, mae: 0.041840, mean_q: 1.167739
 628384/1000000: episode: 6284, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 56.394, mean reward: 0.564 [0.503, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.044, 10.109], loss: 0.001486, mae: 0.041943, mean_q: 1.169598
 628484/1000000: episode: 6285, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.269, mean reward: 0.593 [0.500, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.281, 10.098], loss: 0.001498, mae: 0.042851, mean_q: 1.173326
 628584/1000000: episode: 6286, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.646, mean reward: 0.596 [0.506, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.144, 10.330], loss: 0.001523, mae: 0.042713, mean_q: 1.170610
 628684/1000000: episode: 6287, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.208, mean reward: 0.572 [0.502, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.954, 10.109], loss: 0.001470, mae: 0.041958, mean_q: 1.168230
 628784/1000000: episode: 6288, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.121, mean reward: 0.591 [0.504, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.929, 10.098], loss: 0.001520, mae: 0.042568, mean_q: 1.169777
 628884/1000000: episode: 6289, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.261, mean reward: 0.593 [0.501, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.952, 10.171], loss: 0.001506, mae: 0.042834, mean_q: 1.167601
 628984/1000000: episode: 6290, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.905, mean reward: 0.579 [0.499, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.653, 10.142], loss: 0.001556, mae: 0.042838, mean_q: 1.169386
 629084/1000000: episode: 6291, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.751, mean reward: 0.588 [0.508, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.505, 10.237], loss: 0.001416, mae: 0.041124, mean_q: 1.162214
 629184/1000000: episode: 6292, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.505, mean reward: 0.585 [0.502, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.042, 10.098], loss: 0.001537, mae: 0.042543, mean_q: 1.165063
 629284/1000000: episode: 6293, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.034, mean reward: 0.580 [0.502, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.257, 10.098], loss: 0.001536, mae: 0.042857, mean_q: 1.166294
 629384/1000000: episode: 6294, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.420, mean reward: 0.594 [0.499, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.373, 10.411], loss: 0.001503, mae: 0.042080, mean_q: 1.164502
 629484/1000000: episode: 6295, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 62.319, mean reward: 0.623 [0.507, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.429, 10.168], loss: 0.001509, mae: 0.042365, mean_q: 1.171010
 629584/1000000: episode: 6296, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.765, mean reward: 0.578 [0.515, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.206, 10.098], loss: 0.001590, mae: 0.043731, mean_q: 1.169734
 629684/1000000: episode: 6297, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.697, mean reward: 0.597 [0.503, 0.882], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.237, 10.208], loss: 0.001511, mae: 0.042110, mean_q: 1.167778
 629784/1000000: episode: 6298, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 56.460, mean reward: 0.565 [0.500, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-2.313, 10.136], loss: 0.001588, mae: 0.043526, mean_q: 1.170001
 629884/1000000: episode: 6299, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.093, mean reward: 0.571 [0.502, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.663, 10.098], loss: 0.001492, mae: 0.041858, mean_q: 1.164344
 629984/1000000: episode: 6300, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 56.875, mean reward: 0.569 [0.499, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.784, 10.163], loss: 0.001581, mae: 0.043451, mean_q: 1.170046
 630084/1000000: episode: 6301, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.205, mean reward: 0.602 [0.515, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.503, 10.364], loss: 0.001608, mae: 0.044241, mean_q: 1.167829
 630184/1000000: episode: 6302, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.758, mean reward: 0.608 [0.510, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.425, 10.287], loss: 0.001641, mae: 0.043800, mean_q: 1.166121
 630284/1000000: episode: 6303, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.850, mean reward: 0.589 [0.504, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.714, 10.234], loss: 0.001583, mae: 0.043518, mean_q: 1.169729
 630384/1000000: episode: 6304, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 58.707, mean reward: 0.587 [0.500, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.902, 10.098], loss: 0.001524, mae: 0.042251, mean_q: 1.167742
 630484/1000000: episode: 6305, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.649, mean reward: 0.576 [0.501, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.415, 10.210], loss: 0.001551, mae: 0.043318, mean_q: 1.171987
 630584/1000000: episode: 6306, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.430, mean reward: 0.574 [0.503, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.292, 10.212], loss: 0.001471, mae: 0.041610, mean_q: 1.165840
 630684/1000000: episode: 6307, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 60.188, mean reward: 0.602 [0.500, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.966, 10.098], loss: 0.001527, mae: 0.042558, mean_q: 1.162148
 630784/1000000: episode: 6308, duration: 0.637s, episode steps: 100, steps per second: 157, episode reward: 58.285, mean reward: 0.583 [0.504, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.546, 10.098], loss: 0.001410, mae: 0.041390, mean_q: 1.165706
 630884/1000000: episode: 6309, duration: 0.649s, episode steps: 100, steps per second: 154, episode reward: 60.421, mean reward: 0.604 [0.504, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.383, 10.098], loss: 0.001557, mae: 0.043000, mean_q: 1.161697
 630984/1000000: episode: 6310, duration: 0.645s, episode steps: 100, steps per second: 155, episode reward: 58.588, mean reward: 0.586 [0.503, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.757, 10.200], loss: 0.001623, mae: 0.043493, mean_q: 1.165259
 631084/1000000: episode: 6311, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 58.004, mean reward: 0.580 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.669, 10.098], loss: 0.001536, mae: 0.042502, mean_q: 1.163815
 631184/1000000: episode: 6312, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.040, mean reward: 0.590 [0.505, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.202, 10.175], loss: 0.001533, mae: 0.042504, mean_q: 1.160168
 631284/1000000: episode: 6313, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.230, mean reward: 0.582 [0.502, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.445, 10.117], loss: 0.001538, mae: 0.042638, mean_q: 1.166196
 631384/1000000: episode: 6314, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 57.397, mean reward: 0.574 [0.501, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-2.448, 10.098], loss: 0.001542, mae: 0.042203, mean_q: 1.164696
 631484/1000000: episode: 6315, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.761, mean reward: 0.598 [0.501, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.828, 10.098], loss: 0.001524, mae: 0.043024, mean_q: 1.167339
 631584/1000000: episode: 6316, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.612, mean reward: 0.576 [0.499, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.096, 10.098], loss: 0.001591, mae: 0.043198, mean_q: 1.166691
 631684/1000000: episode: 6317, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.462, mean reward: 0.575 [0.509, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.092, 10.114], loss: 0.001593, mae: 0.043891, mean_q: 1.165299
 631784/1000000: episode: 6318, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.405, mean reward: 0.604 [0.501, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.865, 10.337], loss: 0.001531, mae: 0.042587, mean_q: 1.164123
 631884/1000000: episode: 6319, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.399, mean reward: 0.574 [0.504, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.639, 10.115], loss: 0.001466, mae: 0.042269, mean_q: 1.163026
 631984/1000000: episode: 6320, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.092, mean reward: 0.601 [0.499, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.712, 10.098], loss: 0.001557, mae: 0.042529, mean_q: 1.165965
 632084/1000000: episode: 6321, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.577, mean reward: 0.576 [0.503, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.735, 10.145], loss: 0.001483, mae: 0.042102, mean_q: 1.162174
 632184/1000000: episode: 6322, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.104, mean reward: 0.581 [0.506, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.987, 10.098], loss: 0.001499, mae: 0.042120, mean_q: 1.164087
 632284/1000000: episode: 6323, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.564, mean reward: 0.576 [0.504, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.739, 10.271], loss: 0.001464, mae: 0.041886, mean_q: 1.162159
 632384/1000000: episode: 6324, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 61.566, mean reward: 0.616 [0.506, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.507, 10.388], loss: 0.001484, mae: 0.042152, mean_q: 1.161774
 632484/1000000: episode: 6325, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.360, mean reward: 0.584 [0.499, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.875, 10.098], loss: 0.001618, mae: 0.043589, mean_q: 1.163233
 632584/1000000: episode: 6326, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 56.830, mean reward: 0.568 [0.498, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.824, 10.158], loss: 0.001447, mae: 0.041510, mean_q: 1.159012
 632684/1000000: episode: 6327, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 62.270, mean reward: 0.623 [0.503, 0.917], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.940, 10.380], loss: 0.001536, mae: 0.042821, mean_q: 1.160382
 632784/1000000: episode: 6328, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.575, mean reward: 0.576 [0.504, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.874, 10.252], loss: 0.001494, mae: 0.042096, mean_q: 1.160588
 632884/1000000: episode: 6329, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.350, mean reward: 0.573 [0.500, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.283, 10.098], loss: 0.001443, mae: 0.041485, mean_q: 1.163805
 632984/1000000: episode: 6330, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.218, mean reward: 0.592 [0.507, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.587, 10.262], loss: 0.001529, mae: 0.042846, mean_q: 1.160687
 633084/1000000: episode: 6331, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.528, mean reward: 0.585 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.881, 10.098], loss: 0.001448, mae: 0.041162, mean_q: 1.163033
 633184/1000000: episode: 6332, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 61.742, mean reward: 0.617 [0.510, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.860, 10.098], loss: 0.001437, mae: 0.041395, mean_q: 1.161359
 633284/1000000: episode: 6333, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.715, mean reward: 0.577 [0.506, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.362, 10.098], loss: 0.001466, mae: 0.041427, mean_q: 1.159779
 633384/1000000: episode: 6334, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 59.801, mean reward: 0.598 [0.515, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.918, 10.098], loss: 0.001520, mae: 0.042291, mean_q: 1.164101
 633484/1000000: episode: 6335, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.413, mean reward: 0.574 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.176, 10.098], loss: 0.001523, mae: 0.042429, mean_q: 1.162460
 633584/1000000: episode: 6336, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.524, mean reward: 0.595 [0.513, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.669, 10.098], loss: 0.001558, mae: 0.042736, mean_q: 1.160843
 633684/1000000: episode: 6337, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.862, mean reward: 0.589 [0.510, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.268, 10.098], loss: 0.001491, mae: 0.042468, mean_q: 1.164248
 633784/1000000: episode: 6338, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.353, mean reward: 0.594 [0.499, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.406, 10.249], loss: 0.001486, mae: 0.041524, mean_q: 1.162850
 633884/1000000: episode: 6339, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.084, mean reward: 0.571 [0.502, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.498, 10.333], loss: 0.001510, mae: 0.042113, mean_q: 1.160761
 633984/1000000: episode: 6340, duration: 0.627s, episode steps: 100, steps per second: 159, episode reward: 59.859, mean reward: 0.599 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.835, 10.347], loss: 0.001405, mae: 0.040626, mean_q: 1.159763
 634084/1000000: episode: 6341, duration: 0.618s, episode steps: 100, steps per second: 162, episode reward: 57.819, mean reward: 0.578 [0.506, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.839, 10.098], loss: 0.001531, mae: 0.042054, mean_q: 1.162105
 634184/1000000: episode: 6342, duration: 0.621s, episode steps: 100, steps per second: 161, episode reward: 59.190, mean reward: 0.592 [0.507, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.395, 10.284], loss: 0.001611, mae: 0.042753, mean_q: 1.164857
 634284/1000000: episode: 6343, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.060, mean reward: 0.601 [0.503, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.036, 10.216], loss: 0.001534, mae: 0.042314, mean_q: 1.163078
 634384/1000000: episode: 6344, duration: 0.651s, episode steps: 100, steps per second: 154, episode reward: 58.309, mean reward: 0.583 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.838, 10.098], loss: 0.001428, mae: 0.041074, mean_q: 1.162894
 634484/1000000: episode: 6345, duration: 0.770s, episode steps: 100, steps per second: 130, episode reward: 58.346, mean reward: 0.583 [0.513, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.922, 10.143], loss: 0.001457, mae: 0.041747, mean_q: 1.158497
 634584/1000000: episode: 6346, duration: 0.844s, episode steps: 100, steps per second: 118, episode reward: 59.932, mean reward: 0.599 [0.499, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.521, 10.202], loss: 0.001401, mae: 0.040463, mean_q: 1.162414
 634684/1000000: episode: 6347, duration: 0.681s, episode steps: 100, steps per second: 147, episode reward: 58.446, mean reward: 0.584 [0.503, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.687, 10.098], loss: 0.001501, mae: 0.041768, mean_q: 1.163261
 634784/1000000: episode: 6348, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.941, mean reward: 0.579 [0.506, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.620, 10.249], loss: 0.001406, mae: 0.041100, mean_q: 1.159679
 634884/1000000: episode: 6349, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.505, mean reward: 0.595 [0.504, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.834, 10.223], loss: 0.001539, mae: 0.041957, mean_q: 1.163532
 634984/1000000: episode: 6350, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.570, mean reward: 0.596 [0.507, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.398, 10.098], loss: 0.001479, mae: 0.041195, mean_q: 1.163622
 635084/1000000: episode: 6351, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.560, mean reward: 0.576 [0.509, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.114, 10.210], loss: 0.001503, mae: 0.041880, mean_q: 1.164206
 635184/1000000: episode: 6352, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.082, mean reward: 0.581 [0.506, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.338, 10.098], loss: 0.001466, mae: 0.041378, mean_q: 1.162575
 635266/1000000: episode: 6353, duration: 0.509s, episode steps: 82, steps per second: 161, episode reward: 59.124, mean reward: 0.721 [0.507, 1.022], mean action: 0.000 [0.000, 0.000], mean observation: 1.278 [-1.007, 9.231], loss: 0.001492, mae: 0.042590, mean_q: 1.162893
 635366/1000000: episode: 6354, duration: 0.725s, episode steps: 100, steps per second: 138, episode reward: 59.669, mean reward: 0.597 [0.504, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.816, 10.167], loss: 0.001549, mae: 0.042232, mean_q: 1.165150
 635466/1000000: episode: 6355, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 63.618, mean reward: 0.636 [0.508, 0.868], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.164, 10.098], loss: 0.001686, mae: 0.043012, mean_q: 1.168160
 635566/1000000: episode: 6356, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.191, mean reward: 0.582 [0.499, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.477, 10.130], loss: 0.001661, mae: 0.043679, mean_q: 1.170392
 635666/1000000: episode: 6357, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.868, mean reward: 0.589 [0.509, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.915, 10.171], loss: 0.001508, mae: 0.041913, mean_q: 1.164608
 635766/1000000: episode: 6358, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 63.696, mean reward: 0.637 [0.501, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.481, 10.401], loss: 0.001453, mae: 0.041387, mean_q: 1.169373
 635866/1000000: episode: 6359, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.327, mean reward: 0.593 [0.507, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.858, 10.241], loss: 0.001487, mae: 0.042038, mean_q: 1.168404
 635966/1000000: episode: 6360, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.714, mean reward: 0.607 [0.510, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.374, 10.098], loss: 0.001584, mae: 0.042746, mean_q: 1.170719
 636066/1000000: episode: 6361, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.128, mean reward: 0.581 [0.500, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.998, 10.098], loss: 0.001681, mae: 0.043957, mean_q: 1.173032
 636166/1000000: episode: 6362, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.324, mean reward: 0.573 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.565, 10.098], loss: 0.001700, mae: 0.043483, mean_q: 1.170805
 636266/1000000: episode: 6363, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.084, mean reward: 0.601 [0.508, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.069, 10.098], loss: 0.001654, mae: 0.043433, mean_q: 1.171378
 636366/1000000: episode: 6364, duration: 0.611s, episode steps: 100, steps per second: 164, episode reward: 59.856, mean reward: 0.599 [0.508, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.520, 10.323], loss: 0.001870, mae: 0.045259, mean_q: 1.172338
 636466/1000000: episode: 6365, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.222, mean reward: 0.582 [0.504, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.844, 10.240], loss: 0.001552, mae: 0.042469, mean_q: 1.171993
 636566/1000000: episode: 6366, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.631, mean reward: 0.596 [0.505, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.941, 10.235], loss: 0.001568, mae: 0.042478, mean_q: 1.172893
 636666/1000000: episode: 6367, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.296, mean reward: 0.593 [0.508, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.288, 10.098], loss: 0.001587, mae: 0.042846, mean_q: 1.170598
 636766/1000000: episode: 6368, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.788, mean reward: 0.578 [0.501, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.240, 10.247], loss: 0.001641, mae: 0.043087, mean_q: 1.176544
 636866/1000000: episode: 6369, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.603, mean reward: 0.596 [0.499, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.219, 10.098], loss: 0.001429, mae: 0.040718, mean_q: 1.173058
 636966/1000000: episode: 6370, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.130, mean reward: 0.561 [0.507, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.964, 10.151], loss: 0.001583, mae: 0.042870, mean_q: 1.175982
 637066/1000000: episode: 6371, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 62.837, mean reward: 0.628 [0.504, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.521, 10.368], loss: 0.001750, mae: 0.044357, mean_q: 1.175225
 637166/1000000: episode: 6372, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.465, mean reward: 0.605 [0.503, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.415, 10.098], loss: 0.001555, mae: 0.042519, mean_q: 1.176263
 637266/1000000: episode: 6373, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.886, mean reward: 0.579 [0.501, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.503, 10.106], loss: 0.001567, mae: 0.042720, mean_q: 1.176743
 637366/1000000: episode: 6374, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.453, mean reward: 0.585 [0.499, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.620, 10.098], loss: 0.001592, mae: 0.043232, mean_q: 1.173933
 637466/1000000: episode: 6375, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.015, mean reward: 0.590 [0.512, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.802, 10.098], loss: 0.001524, mae: 0.041992, mean_q: 1.174921
 637566/1000000: episode: 6376, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.126, mean reward: 0.591 [0.504, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.584, 10.275], loss: 0.001597, mae: 0.042458, mean_q: 1.173816
 637666/1000000: episode: 6377, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.776, mean reward: 0.588 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.306, 10.299], loss: 0.001648, mae: 0.042985, mean_q: 1.173333
 637766/1000000: episode: 6378, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.518, mean reward: 0.595 [0.503, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.524, 10.098], loss: 0.001559, mae: 0.042907, mean_q: 1.173100
 637866/1000000: episode: 6379, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 60.134, mean reward: 0.601 [0.512, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.327, 10.098], loss: 0.001515, mae: 0.041772, mean_q: 1.173083
 637966/1000000: episode: 6380, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.970, mean reward: 0.580 [0.512, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.725, 10.098], loss: 0.001646, mae: 0.042717, mean_q: 1.175574
 638066/1000000: episode: 6381, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.610, mean reward: 0.586 [0.504, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.674, 10.098], loss: 0.001583, mae: 0.042988, mean_q: 1.179608
 638166/1000000: episode: 6382, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 66.517, mean reward: 0.665 [0.507, 0.961], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.261, 10.098], loss: 0.001645, mae: 0.043587, mean_q: 1.177372
 638266/1000000: episode: 6383, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.662, mean reward: 0.587 [0.508, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.742, 10.147], loss: 0.001521, mae: 0.042536, mean_q: 1.176181
 638366/1000000: episode: 6384, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.756, mean reward: 0.608 [0.503, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.104, 10.098], loss: 0.001537, mae: 0.042417, mean_q: 1.177274
 638466/1000000: episode: 6385, duration: 0.621s, episode steps: 100, steps per second: 161, episode reward: 58.782, mean reward: 0.588 [0.515, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.335, 10.267], loss: 0.001550, mae: 0.042470, mean_q: 1.173886
 638566/1000000: episode: 6386, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.533, mean reward: 0.575 [0.504, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.584, 10.098], loss: 0.001699, mae: 0.043560, mean_q: 1.178056
 638666/1000000: episode: 6387, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.473, mean reward: 0.575 [0.504, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.888, 10.103], loss: 0.001546, mae: 0.041944, mean_q: 1.178566
 638766/1000000: episode: 6388, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 59.208, mean reward: 0.592 [0.508, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-2.008, 10.139], loss: 0.001563, mae: 0.042482, mean_q: 1.174666
 638866/1000000: episode: 6389, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 65.017, mean reward: 0.650 [0.524, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.265, 10.362], loss: 0.001503, mae: 0.041557, mean_q: 1.177952
 638966/1000000: episode: 6390, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.048, mean reward: 0.600 [0.514, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.504, 10.220], loss: 0.001695, mae: 0.043523, mean_q: 1.181096
 639066/1000000: episode: 6391, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.094, mean reward: 0.581 [0.510, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.254, 10.098], loss: 0.001622, mae: 0.042345, mean_q: 1.180136
 639166/1000000: episode: 6392, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.423, mean reward: 0.594 [0.509, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.875, 10.098], loss: 0.001524, mae: 0.042137, mean_q: 1.178505
 639266/1000000: episode: 6393, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 61.889, mean reward: 0.619 [0.518, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.871, 10.098], loss: 0.001585, mae: 0.043092, mean_q: 1.181420
 639366/1000000: episode: 6394, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.668, mean reward: 0.587 [0.499, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.670, 10.353], loss: 0.001612, mae: 0.042890, mean_q: 1.177151
 639466/1000000: episode: 6395, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.899, mean reward: 0.599 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.542, 10.138], loss: 0.001515, mae: 0.042116, mean_q: 1.180232
 639566/1000000: episode: 6396, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.613, mean reward: 0.576 [0.498, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.796, 10.098], loss: 0.001503, mae: 0.041329, mean_q: 1.181647
 639666/1000000: episode: 6397, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.578, mean reward: 0.576 [0.504, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.370, 10.195], loss: 0.001565, mae: 0.042385, mean_q: 1.180739
 639766/1000000: episode: 6398, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 61.124, mean reward: 0.611 [0.514, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.529, 10.098], loss: 0.001540, mae: 0.042325, mean_q: 1.181874
 639866/1000000: episode: 6399, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.069, mean reward: 0.591 [0.504, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.862, 10.365], loss: 0.001567, mae: 0.042591, mean_q: 1.181168
 639966/1000000: episode: 6400, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 56.417, mean reward: 0.564 [0.500, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.280, 10.147], loss: 0.001715, mae: 0.043523, mean_q: 1.177853
 640066/1000000: episode: 6401, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.162, mean reward: 0.592 [0.515, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.894, 10.104], loss: 0.001533, mae: 0.042331, mean_q: 1.181848
 640166/1000000: episode: 6402, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.987, mean reward: 0.590 [0.507, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.374, 10.261], loss: 0.001674, mae: 0.043117, mean_q: 1.180441
 640266/1000000: episode: 6403, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.995, mean reward: 0.590 [0.511, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.776, 10.356], loss: 0.001623, mae: 0.043299, mean_q: 1.177249
 640366/1000000: episode: 6404, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.628, mean reward: 0.596 [0.505, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.214, 10.098], loss: 0.001504, mae: 0.041736, mean_q: 1.175157
 640466/1000000: episode: 6405, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.634, mean reward: 0.586 [0.503, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.931, 10.291], loss: 0.001564, mae: 0.043019, mean_q: 1.177236
 640566/1000000: episode: 6406, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 59.525, mean reward: 0.595 [0.512, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.072, 10.137], loss: 0.001493, mae: 0.042078, mean_q: 1.177569
 640666/1000000: episode: 6407, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.086, mean reward: 0.591 [0.512, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.690, 10.098], loss: 0.001615, mae: 0.043537, mean_q: 1.175785
 640766/1000000: episode: 6408, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.243, mean reward: 0.602 [0.512, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.485, 10.185], loss: 0.001408, mae: 0.041010, mean_q: 1.172776
 640866/1000000: episode: 6409, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.298, mean reward: 0.583 [0.499, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.904, 10.098], loss: 0.001494, mae: 0.042033, mean_q: 1.178268
 640966/1000000: episode: 6410, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 59.478, mean reward: 0.595 [0.513, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.005, 10.278], loss: 0.001496, mae: 0.042239, mean_q: 1.175012
 641066/1000000: episode: 6411, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.464, mean reward: 0.595 [0.510, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.169, 10.098], loss: 0.001400, mae: 0.041024, mean_q: 1.176208
 641166/1000000: episode: 6412, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.691, mean reward: 0.587 [0.500, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.267, 10.296], loss: 0.001458, mae: 0.041744, mean_q: 1.174564
 641266/1000000: episode: 6413, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.116, mean reward: 0.581 [0.503, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.250, 10.273], loss: 0.001481, mae: 0.042027, mean_q: 1.176343
 641366/1000000: episode: 6414, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.737, mean reward: 0.607 [0.509, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.355, 10.098], loss: 0.001420, mae: 0.041270, mean_q: 1.170270
 641466/1000000: episode: 6415, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.245, mean reward: 0.592 [0.506, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.898, 10.098], loss: 0.001536, mae: 0.042195, mean_q: 1.176406
 641566/1000000: episode: 6416, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.098, mean reward: 0.611 [0.516, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.888, 10.098], loss: 0.001469, mae: 0.041687, mean_q: 1.174512
 641666/1000000: episode: 6417, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 59.536, mean reward: 0.595 [0.510, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.474, 10.124], loss: 0.001598, mae: 0.043706, mean_q: 1.176017
 641766/1000000: episode: 6418, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.325, mean reward: 0.593 [0.504, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.076, 10.098], loss: 0.001362, mae: 0.040428, mean_q: 1.172336
 641866/1000000: episode: 6419, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.266, mean reward: 0.583 [0.508, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.629, 10.285], loss: 0.001458, mae: 0.041902, mean_q: 1.176333
 641966/1000000: episode: 6420, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.097, mean reward: 0.581 [0.506, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.564, 10.176], loss: 0.001464, mae: 0.041736, mean_q: 1.177552
 642066/1000000: episode: 6421, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.395, mean reward: 0.594 [0.501, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.418, 10.098], loss: 0.001450, mae: 0.041212, mean_q: 1.168299
 642166/1000000: episode: 6422, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.174, mean reward: 0.592 [0.513, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.919, 10.098], loss: 0.001456, mae: 0.041255, mean_q: 1.173629
 642266/1000000: episode: 6423, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 56.697, mean reward: 0.567 [0.504, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.490, 10.176], loss: 0.001434, mae: 0.040537, mean_q: 1.172684
 642366/1000000: episode: 6424, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.071, mean reward: 0.581 [0.506, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.048, 10.098], loss: 0.001515, mae: 0.041653, mean_q: 1.172641
 642466/1000000: episode: 6425, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.769, mean reward: 0.578 [0.503, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.178, 10.098], loss: 0.001499, mae: 0.041617, mean_q: 1.174479
 642566/1000000: episode: 6426, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.832, mean reward: 0.578 [0.513, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.769, 10.203], loss: 0.001467, mae: 0.042008, mean_q: 1.173849
 642666/1000000: episode: 6427, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.484, mean reward: 0.585 [0.504, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.347, 10.098], loss: 0.001442, mae: 0.041380, mean_q: 1.171028
 642766/1000000: episode: 6428, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 57.668, mean reward: 0.577 [0.500, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.666, 10.182], loss: 0.001398, mae: 0.040483, mean_q: 1.170264
 642866/1000000: episode: 6429, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.226, mean reward: 0.602 [0.514, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.036, 10.219], loss: 0.001500, mae: 0.041553, mean_q: 1.174319
 642966/1000000: episode: 6430, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.453, mean reward: 0.585 [0.510, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.801, 10.098], loss: 0.001436, mae: 0.041286, mean_q: 1.171975
 643066/1000000: episode: 6431, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 63.655, mean reward: 0.637 [0.507, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.956, 10.535], loss: 0.001441, mae: 0.040990, mean_q: 1.171222
 643166/1000000: episode: 6432, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.556, mean reward: 0.586 [0.497, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.138, 10.098], loss: 0.001504, mae: 0.042514, mean_q: 1.170848
 643266/1000000: episode: 6433, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 62.121, mean reward: 0.621 [0.509, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.980, 10.274], loss: 0.001380, mae: 0.040486, mean_q: 1.172752
 643366/1000000: episode: 6434, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.041, mean reward: 0.580 [0.504, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.753, 10.199], loss: 0.001352, mae: 0.040499, mean_q: 1.168129
 643466/1000000: episode: 6435, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.250, mean reward: 0.583 [0.509, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.660, 10.427], loss: 0.001464, mae: 0.041342, mean_q: 1.172283
 643566/1000000: episode: 6436, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.768, mean reward: 0.578 [0.502, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.594, 10.098], loss: 0.001465, mae: 0.041716, mean_q: 1.174703
 643666/1000000: episode: 6437, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.049, mean reward: 0.600 [0.509, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.648, 10.098], loss: 0.001364, mae: 0.040031, mean_q: 1.170300
 643766/1000000: episode: 6438, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.663, mean reward: 0.597 [0.504, 0.862], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.166, 10.229], loss: 0.001467, mae: 0.041337, mean_q: 1.173571
 643866/1000000: episode: 6439, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.237, mean reward: 0.582 [0.499, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.822, 10.098], loss: 0.001422, mae: 0.041147, mean_q: 1.171894
 643966/1000000: episode: 6440, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.915, mean reward: 0.579 [0.508, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.871, 10.098], loss: 0.001587, mae: 0.043149, mean_q: 1.170008
 644066/1000000: episode: 6441, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.282, mean reward: 0.583 [0.506, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-2.007, 10.215], loss: 0.001343, mae: 0.039842, mean_q: 1.166943
 644166/1000000: episode: 6442, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.648, mean reward: 0.576 [0.501, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.570, 10.098], loss: 0.001456, mae: 0.040778, mean_q: 1.165876
 644266/1000000: episode: 6443, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.516, mean reward: 0.585 [0.507, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.320, 10.312], loss: 0.001428, mae: 0.040467, mean_q: 1.165811
 644366/1000000: episode: 6444, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.505, mean reward: 0.605 [0.505, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.567, 10.286], loss: 0.001357, mae: 0.040014, mean_q: 1.168840
 644466/1000000: episode: 6445, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.938, mean reward: 0.599 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.954, 10.098], loss: 0.001459, mae: 0.041113, mean_q: 1.170062
 644566/1000000: episode: 6446, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.207, mean reward: 0.582 [0.510, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.195, 10.291], loss: 0.001409, mae: 0.041031, mean_q: 1.168829
 644666/1000000: episode: 6447, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.872, mean reward: 0.579 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.738, 10.098], loss: 0.001536, mae: 0.041827, mean_q: 1.169888
 644766/1000000: episode: 6448, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.017, mean reward: 0.570 [0.506, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.517, 10.098], loss: 0.001411, mae: 0.040290, mean_q: 1.165323
 644866/1000000: episode: 6449, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.928, mean reward: 0.589 [0.507, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.470, 10.269], loss: 0.001475, mae: 0.041728, mean_q: 1.167019
 644966/1000000: episode: 6450, duration: 0.635s, episode steps: 100, steps per second: 157, episode reward: 60.272, mean reward: 0.603 [0.506, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.510, 10.406], loss: 0.001422, mae: 0.040678, mean_q: 1.167133
 645066/1000000: episode: 6451, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.704, mean reward: 0.587 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.057, 10.209], loss: 0.001495, mae: 0.041852, mean_q: 1.166712
 645166/1000000: episode: 6452, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 59.008, mean reward: 0.590 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.030, 10.105], loss: 0.001416, mae: 0.040983, mean_q: 1.166432
 645266/1000000: episode: 6453, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.881, mean reward: 0.609 [0.500, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.567, 10.098], loss: 0.001455, mae: 0.041103, mean_q: 1.166732
 645366/1000000: episode: 6454, duration: 0.639s, episode steps: 100, steps per second: 156, episode reward: 58.140, mean reward: 0.581 [0.501, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.718, 10.098], loss: 0.001485, mae: 0.042205, mean_q: 1.169155
 645466/1000000: episode: 6455, duration: 0.632s, episode steps: 100, steps per second: 158, episode reward: 58.678, mean reward: 0.587 [0.501, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.236, 10.098], loss: 0.001585, mae: 0.042315, mean_q: 1.167300
 645566/1000000: episode: 6456, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.986, mean reward: 0.580 [0.500, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.819, 10.098], loss: 0.001428, mae: 0.040699, mean_q: 1.164454
 645666/1000000: episode: 6457, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.080, mean reward: 0.581 [0.509, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.855, 10.098], loss: 0.001437, mae: 0.041147, mean_q: 1.166888
 645766/1000000: episode: 6458, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.290, mean reward: 0.613 [0.504, 0.903], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.747, 10.098], loss: 0.001569, mae: 0.042694, mean_q: 1.167164
 645866/1000000: episode: 6459, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.293, mean reward: 0.593 [0.501, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.677, 10.199], loss: 0.001555, mae: 0.042309, mean_q: 1.167492
 645966/1000000: episode: 6460, duration: 0.635s, episode steps: 100, steps per second: 158, episode reward: 60.192, mean reward: 0.602 [0.503, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.517, 10.312], loss: 0.001567, mae: 0.042216, mean_q: 1.170989
 646066/1000000: episode: 6461, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 60.705, mean reward: 0.607 [0.516, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.636, 10.363], loss: 0.001475, mae: 0.041841, mean_q: 1.166873
 646166/1000000: episode: 6462, duration: 0.646s, episode steps: 100, steps per second: 155, episode reward: 58.536, mean reward: 0.585 [0.501, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.569, 10.153], loss: 0.001532, mae: 0.042314, mean_q: 1.167092
 646266/1000000: episode: 6463, duration: 0.611s, episode steps: 100, steps per second: 164, episode reward: 57.188, mean reward: 0.572 [0.510, 0.657], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.550, 10.203], loss: 0.001427, mae: 0.040841, mean_q: 1.164329
 646366/1000000: episode: 6464, duration: 0.628s, episode steps: 100, steps per second: 159, episode reward: 58.049, mean reward: 0.580 [0.510, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.099, 10.098], loss: 0.001412, mae: 0.040328, mean_q: 1.166502
 646466/1000000: episode: 6465, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.725, mean reward: 0.577 [0.514, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.918, 10.098], loss: 0.001404, mae: 0.040689, mean_q: 1.166589
 646566/1000000: episode: 6466, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.311, mean reward: 0.573 [0.504, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.576, 10.144], loss: 0.001490, mae: 0.041572, mean_q: 1.165627
 646666/1000000: episode: 6467, duration: 0.666s, episode steps: 100, steps per second: 150, episode reward: 63.130, mean reward: 0.631 [0.508, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.617, 10.098], loss: 0.001441, mae: 0.041037, mean_q: 1.166621
 646766/1000000: episode: 6468, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.460, mean reward: 0.595 [0.507, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.151, 10.277], loss: 0.001445, mae: 0.040606, mean_q: 1.164321
 646866/1000000: episode: 6469, duration: 0.653s, episode steps: 100, steps per second: 153, episode reward: 56.622, mean reward: 0.566 [0.503, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.320, 10.148], loss: 0.001443, mae: 0.040796, mean_q: 1.165507
 646966/1000000: episode: 6470, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 60.198, mean reward: 0.602 [0.516, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.376, 10.312], loss: 0.001370, mae: 0.039873, mean_q: 1.164713
 647066/1000000: episode: 6471, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.484, mean reward: 0.605 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.101, 10.098], loss: 0.001461, mae: 0.041464, mean_q: 1.165169
 647166/1000000: episode: 6472, duration: 0.644s, episode steps: 100, steps per second: 155, episode reward: 60.160, mean reward: 0.602 [0.500, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.311, 10.098], loss: 0.001379, mae: 0.040308, mean_q: 1.166745
 647266/1000000: episode: 6473, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.461, mean reward: 0.575 [0.502, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.462, 10.098], loss: 0.001349, mae: 0.039986, mean_q: 1.164763
 647366/1000000: episode: 6474, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.398, mean reward: 0.574 [0.503, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.145, 10.187], loss: 0.001333, mae: 0.040053, mean_q: 1.166324
 647466/1000000: episode: 6475, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.800, mean reward: 0.578 [0.499, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.041, 10.239], loss: 0.001492, mae: 0.041760, mean_q: 1.169703
 647566/1000000: episode: 6476, duration: 0.662s, episode steps: 100, steps per second: 151, episode reward: 57.248, mean reward: 0.572 [0.502, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.735, 10.167], loss: 0.001410, mae: 0.040830, mean_q: 1.166578
 647666/1000000: episode: 6477, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.530, mean reward: 0.595 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.786, 10.098], loss: 0.001406, mae: 0.040658, mean_q: 1.165706
 647766/1000000: episode: 6478, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 59.054, mean reward: 0.591 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.402, 10.098], loss: 0.001390, mae: 0.040260, mean_q: 1.167726
 647866/1000000: episode: 6479, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.569, mean reward: 0.576 [0.500, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.702, 10.222], loss: 0.001518, mae: 0.042342, mean_q: 1.169342
 647966/1000000: episode: 6480, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.424, mean reward: 0.584 [0.503, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.883, 10.098], loss: 0.001499, mae: 0.041861, mean_q: 1.170292
 648066/1000000: episode: 6481, duration: 0.659s, episode steps: 100, steps per second: 152, episode reward: 57.776, mean reward: 0.578 [0.505, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.391, 10.284], loss: 0.001473, mae: 0.041373, mean_q: 1.164273
 648166/1000000: episode: 6482, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.333, mean reward: 0.603 [0.511, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.499, 10.098], loss: 0.001473, mae: 0.041366, mean_q: 1.164451
 648266/1000000: episode: 6483, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 56.917, mean reward: 0.569 [0.503, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.194, 10.186], loss: 0.001497, mae: 0.041306, mean_q: 1.162317
 648366/1000000: episode: 6484, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.822, mean reward: 0.588 [0.505, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.829, 10.194], loss: 0.001457, mae: 0.040896, mean_q: 1.161203
 648466/1000000: episode: 6485, duration: 0.746s, episode steps: 100, steps per second: 134, episode reward: 59.743, mean reward: 0.597 [0.510, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.593, 10.098], loss: 0.001517, mae: 0.042254, mean_q: 1.165615
 648566/1000000: episode: 6486, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.798, mean reward: 0.578 [0.499, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.782, 10.098], loss: 0.001453, mae: 0.040989, mean_q: 1.165657
 648666/1000000: episode: 6487, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.673, mean reward: 0.607 [0.516, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.729, 10.207], loss: 0.001540, mae: 0.041815, mean_q: 1.163176
 648766/1000000: episode: 6488, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 57.723, mean reward: 0.577 [0.506, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.629, 10.098], loss: 0.001463, mae: 0.041381, mean_q: 1.165902
 648866/1000000: episode: 6489, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 56.287, mean reward: 0.563 [0.507, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.452, 10.181], loss: 0.001337, mae: 0.039296, mean_q: 1.158870
 648966/1000000: episode: 6490, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.339, mean reward: 0.593 [0.502, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.864, 10.150], loss: 0.001391, mae: 0.040079, mean_q: 1.164710
 649066/1000000: episode: 6491, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.700, mean reward: 0.577 [0.512, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.183, 10.098], loss: 0.001447, mae: 0.041119, mean_q: 1.156831
 649166/1000000: episode: 6492, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 60.558, mean reward: 0.606 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.036, 10.126], loss: 0.001431, mae: 0.040658, mean_q: 1.163605
 649266/1000000: episode: 6493, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 57.722, mean reward: 0.577 [0.508, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.313, 10.317], loss: 0.001349, mae: 0.040284, mean_q: 1.164358
 649366/1000000: episode: 6494, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 56.833, mean reward: 0.568 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.269, 10.133], loss: 0.001413, mae: 0.040478, mean_q: 1.160704
 649466/1000000: episode: 6495, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.214, mean reward: 0.612 [0.509, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.505, 10.337], loss: 0.001310, mae: 0.039690, mean_q: 1.160822
 649566/1000000: episode: 6496, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.759, mean reward: 0.588 [0.506, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.633, 10.117], loss: 0.001333, mae: 0.039925, mean_q: 1.162217
 649666/1000000: episode: 6497, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 63.954, mean reward: 0.640 [0.509, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.748, 10.098], loss: 0.001310, mae: 0.039000, mean_q: 1.163809
 649766/1000000: episode: 6498, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.194, mean reward: 0.582 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.769, 10.098], loss: 0.001374, mae: 0.039753, mean_q: 1.167433
 649866/1000000: episode: 6499, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.682, mean reward: 0.607 [0.515, 0.888], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.365, 10.282], loss: 0.001389, mae: 0.040261, mean_q: 1.164450
 649966/1000000: episode: 6500, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.445, mean reward: 0.594 [0.512, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.676, 10.113], loss: 0.001401, mae: 0.041049, mean_q: 1.165688
 650066/1000000: episode: 6501, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.301, mean reward: 0.613 [0.500, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.237, 10.258], loss: 0.001474, mae: 0.041283, mean_q: 1.166151
 650166/1000000: episode: 6502, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 61.306, mean reward: 0.613 [0.504, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.348, 10.099], loss: 0.001452, mae: 0.041479, mean_q: 1.170022
 650266/1000000: episode: 6503, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 62.734, mean reward: 0.627 [0.511, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.413 [-1.244, 10.098], loss: 0.001408, mae: 0.040763, mean_q: 1.167875
 650366/1000000: episode: 6504, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.691, mean reward: 0.597 [0.503, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.315, 10.247], loss: 0.001468, mae: 0.041624, mean_q: 1.163335
 650466/1000000: episode: 6505, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.769, mean reward: 0.598 [0.507, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.347, 10.098], loss: 0.001368, mae: 0.040308, mean_q: 1.170331
 650566/1000000: episode: 6506, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 56.848, mean reward: 0.568 [0.501, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.402, 10.098], loss: 0.001389, mae: 0.040273, mean_q: 1.170883
 650666/1000000: episode: 6507, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.404, mean reward: 0.564 [0.505, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.746, 10.158], loss: 0.001429, mae: 0.041017, mean_q: 1.167195
 650766/1000000: episode: 6508, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.291, mean reward: 0.603 [0.508, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.637, 10.510], loss: 0.001415, mae: 0.040747, mean_q: 1.166757
 650866/1000000: episode: 6509, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.470, mean reward: 0.605 [0.504, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.196, 10.250], loss: 0.001381, mae: 0.040284, mean_q: 1.167049
 650966/1000000: episode: 6510, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.675, mean reward: 0.597 [0.508, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.716, 10.104], loss: 0.001400, mae: 0.040473, mean_q: 1.168246
 651066/1000000: episode: 6511, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.767, mean reward: 0.578 [0.503, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.168, 10.114], loss: 0.001517, mae: 0.042711, mean_q: 1.166963
 651166/1000000: episode: 6512, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.669, mean reward: 0.567 [0.504, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.116, 10.098], loss: 0.001428, mae: 0.041246, mean_q: 1.168445
 651266/1000000: episode: 6513, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.622, mean reward: 0.596 [0.505, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.910, 10.098], loss: 0.001399, mae: 0.040669, mean_q: 1.169302
 651366/1000000: episode: 6514, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.349, mean reward: 0.573 [0.503, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.526, 10.149], loss: 0.001475, mae: 0.041830, mean_q: 1.172221
 651466/1000000: episode: 6515, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.607, mean reward: 0.586 [0.505, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.193, 10.098], loss: 0.001404, mae: 0.041184, mean_q: 1.167228
 651566/1000000: episode: 6516, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 62.626, mean reward: 0.626 [0.502, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.760, 10.121], loss: 0.001332, mae: 0.039896, mean_q: 1.163314
 651666/1000000: episode: 6517, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 58.295, mean reward: 0.583 [0.505, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.097, 10.098], loss: 0.001486, mae: 0.041787, mean_q: 1.166209
 651766/1000000: episode: 6518, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.275, mean reward: 0.593 [0.507, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.870, 10.169], loss: 0.001417, mae: 0.041539, mean_q: 1.169787
 651866/1000000: episode: 6519, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.280, mean reward: 0.583 [0.511, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.163, 10.340], loss: 0.001468, mae: 0.041139, mean_q: 1.169281
 651966/1000000: episode: 6520, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.751, mean reward: 0.578 [0.510, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.771, 10.287], loss: 0.001386, mae: 0.040188, mean_q: 1.169851
 652066/1000000: episode: 6521, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.271, mean reward: 0.593 [0.518, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.947, 10.098], loss: 0.001405, mae: 0.040304, mean_q: 1.166016
 652166/1000000: episode: 6522, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.333, mean reward: 0.603 [0.499, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-1.413, 10.358], loss: 0.001441, mae: 0.041290, mean_q: 1.167996
 652266/1000000: episode: 6523, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.535, mean reward: 0.575 [0.507, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.241, 10.098], loss: 0.001391, mae: 0.040654, mean_q: 1.167563
 652366/1000000: episode: 6524, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.165, mean reward: 0.582 [0.501, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.935, 10.098], loss: 0.001438, mae: 0.041066, mean_q: 1.166038
 652466/1000000: episode: 6525, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.047, mean reward: 0.590 [0.507, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.192, 10.317], loss: 0.001427, mae: 0.041721, mean_q: 1.169059
 652566/1000000: episode: 6526, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.872, mean reward: 0.569 [0.501, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.786, 10.098], loss: 0.001389, mae: 0.040015, mean_q: 1.168756
 652666/1000000: episode: 6527, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.556, mean reward: 0.566 [0.502, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.887, 10.098], loss: 0.001359, mae: 0.040134, mean_q: 1.166451
 652766/1000000: episode: 6528, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 61.223, mean reward: 0.612 [0.510, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.397, 10.098], loss: 0.001437, mae: 0.041006, mean_q: 1.170244
 652866/1000000: episode: 6529, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 64.485, mean reward: 0.645 [0.508, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.719, 10.470], loss: 0.001442, mae: 0.041302, mean_q: 1.170043
 652966/1000000: episode: 6530, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.719, mean reward: 0.607 [0.507, 0.873], mean action: 0.000 [0.000, 0.000], mean observation: 1.413 [-0.707, 10.098], loss: 0.001423, mae: 0.041028, mean_q: 1.175290
 653066/1000000: episode: 6531, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.176, mean reward: 0.572 [0.501, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.592, 10.257], loss: 0.001385, mae: 0.040495, mean_q: 1.169921
 653166/1000000: episode: 6532, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 56.859, mean reward: 0.569 [0.507, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.522, 10.177], loss: 0.001375, mae: 0.040448, mean_q: 1.168679
 653266/1000000: episode: 6533, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 59.050, mean reward: 0.591 [0.503, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.573, 10.098], loss: 0.001468, mae: 0.041277, mean_q: 1.170571
 653366/1000000: episode: 6534, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 58.695, mean reward: 0.587 [0.503, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.493, 10.098], loss: 0.001484, mae: 0.041283, mean_q: 1.174169
 653466/1000000: episode: 6535, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.660, mean reward: 0.597 [0.507, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.753, 10.098], loss: 0.001395, mae: 0.040524, mean_q: 1.171847
 653566/1000000: episode: 6536, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 59.324, mean reward: 0.593 [0.510, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.931, 10.372], loss: 0.001493, mae: 0.042067, mean_q: 1.171996
 653666/1000000: episode: 6537, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.991, mean reward: 0.590 [0.501, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.896, 10.104], loss: 0.001441, mae: 0.041330, mean_q: 1.168724
 653766/1000000: episode: 6538, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.406, mean reward: 0.584 [0.518, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.652, 10.205], loss: 0.001465, mae: 0.041604, mean_q: 1.168438
 653866/1000000: episode: 6539, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.403, mean reward: 0.584 [0.509, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.256, 10.098], loss: 0.001410, mae: 0.040651, mean_q: 1.171664
 653966/1000000: episode: 6540, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.143, mean reward: 0.581 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.207, 10.098], loss: 0.001469, mae: 0.041441, mean_q: 1.173637
 654066/1000000: episode: 6541, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.597, mean reward: 0.586 [0.508, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.457, 10.308], loss: 0.001432, mae: 0.040655, mean_q: 1.173413
 654166/1000000: episode: 6542, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 60.485, mean reward: 0.605 [0.512, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.422, 10.098], loss: 0.001474, mae: 0.041571, mean_q: 1.172786
 654266/1000000: episode: 6543, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 62.274, mean reward: 0.623 [0.508, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.275, 10.259], loss: 0.001447, mae: 0.041157, mean_q: 1.170708
 654366/1000000: episode: 6544, duration: 0.533s, episode steps: 100, steps per second: 187, episode reward: 58.856, mean reward: 0.589 [0.505, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.685, 10.098], loss: 0.001455, mae: 0.041574, mean_q: 1.173096
 654466/1000000: episode: 6545, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.745, mean reward: 0.597 [0.500, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.493, 10.276], loss: 0.001367, mae: 0.039765, mean_q: 1.174764
 654566/1000000: episode: 6546, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.329, mean reward: 0.603 [0.507, 0.885], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.673, 10.098], loss: 0.001470, mae: 0.040800, mean_q: 1.176722
 654666/1000000: episode: 6547, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.502, mean reward: 0.605 [0.504, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.203, 10.098], loss: 0.001437, mae: 0.041093, mean_q: 1.172134
 654766/1000000: episode: 6548, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.602, mean reward: 0.586 [0.501, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.593, 10.242], loss: 0.001388, mae: 0.040371, mean_q: 1.170451
 654866/1000000: episode: 6549, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.616, mean reward: 0.596 [0.508, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.499, 10.144], loss: 0.001343, mae: 0.039932, mean_q: 1.173157
 654966/1000000: episode: 6550, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.360, mean reward: 0.594 [0.504, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-2.505, 10.098], loss: 0.001348, mae: 0.039598, mean_q: 1.167199
 655066/1000000: episode: 6551, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 66.770, mean reward: 0.668 [0.506, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-2.076, 10.419], loss: 0.001452, mae: 0.040707, mean_q: 1.170387
 655166/1000000: episode: 6552, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.788, mean reward: 0.608 [0.509, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.084, 10.098], loss: 0.001585, mae: 0.042532, mean_q: 1.175390
 655266/1000000: episode: 6553, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.598, mean reward: 0.586 [0.498, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.973, 10.098], loss: 0.001420, mae: 0.040847, mean_q: 1.171261
 655366/1000000: episode: 6554, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.597, mean reward: 0.586 [0.509, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.867, 10.098], loss: 0.001605, mae: 0.042069, mean_q: 1.174640
 655466/1000000: episode: 6555, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.506, mean reward: 0.585 [0.502, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.518, 10.217], loss: 0.001540, mae: 0.042500, mean_q: 1.175833
 655566/1000000: episode: 6556, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.573, mean reward: 0.586 [0.504, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.267, 10.255], loss: 0.001598, mae: 0.042901, mean_q: 1.172807
 655666/1000000: episode: 6557, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 63.780, mean reward: 0.638 [0.514, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.518, 10.098], loss: 0.001500, mae: 0.042065, mean_q: 1.175024
 655766/1000000: episode: 6558, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.616, mean reward: 0.606 [0.509, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.847, 10.183], loss: 0.001595, mae: 0.042680, mean_q: 1.177543
 655866/1000000: episode: 6559, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.793, mean reward: 0.588 [0.512, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.445, 10.321], loss: 0.001616, mae: 0.043196, mean_q: 1.176340
 655966/1000000: episode: 6560, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.779, mean reward: 0.588 [0.503, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.570, 10.224], loss: 0.001527, mae: 0.042689, mean_q: 1.177276
 656066/1000000: episode: 6561, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.466, mean reward: 0.605 [0.509, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.762, 10.098], loss: 0.001476, mae: 0.041691, mean_q: 1.173305
 656166/1000000: episode: 6562, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.100, mean reward: 0.581 [0.504, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.749, 10.098], loss: 0.001466, mae: 0.041623, mean_q: 1.176158
 656266/1000000: episode: 6563, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.978, mean reward: 0.590 [0.514, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.760, 10.177], loss: 0.001499, mae: 0.041654, mean_q: 1.174131
 656366/1000000: episode: 6564, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.938, mean reward: 0.589 [0.508, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.727, 10.230], loss: 0.001541, mae: 0.042386, mean_q: 1.178859
 656466/1000000: episode: 6565, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.248, mean reward: 0.582 [0.502, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.858, 10.192], loss: 0.001547, mae: 0.042481, mean_q: 1.174973
 656566/1000000: episode: 6566, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.169, mean reward: 0.582 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.980, 10.098], loss: 0.001456, mae: 0.041374, mean_q: 1.176066
 656666/1000000: episode: 6567, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.995, mean reward: 0.570 [0.505, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.749, 10.125], loss: 0.001522, mae: 0.042027, mean_q: 1.175329
 656766/1000000: episode: 6568, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.405, mean reward: 0.574 [0.497, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.842, 10.127], loss: 0.001583, mae: 0.042549, mean_q: 1.172311
 656866/1000000: episode: 6569, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.000, mean reward: 0.580 [0.504, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.733, 10.211], loss: 0.001421, mae: 0.040296, mean_q: 1.172513
 656966/1000000: episode: 6570, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.512, mean reward: 0.585 [0.506, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.274, 10.098], loss: 0.001553, mae: 0.042155, mean_q: 1.172986
 657066/1000000: episode: 6571, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.907, mean reward: 0.599 [0.500, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.604, 10.407], loss: 0.001441, mae: 0.041456, mean_q: 1.175712
 657166/1000000: episode: 6572, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.413, mean reward: 0.574 [0.502, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.689, 10.098], loss: 0.001444, mae: 0.041661, mean_q: 1.172664
 657266/1000000: episode: 6573, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 60.070, mean reward: 0.601 [0.504, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.694, 10.098], loss: 0.001448, mae: 0.041072, mean_q: 1.171460
 657366/1000000: episode: 6574, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.811, mean reward: 0.598 [0.501, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.072, 10.098], loss: 0.001483, mae: 0.041593, mean_q: 1.170032
 657466/1000000: episode: 6575, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.800, mean reward: 0.608 [0.509, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.894, 10.098], loss: 0.001549, mae: 0.042628, mean_q: 1.171353
 657566/1000000: episode: 6576, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.335, mean reward: 0.603 [0.514, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.526, 10.324], loss: 0.001528, mae: 0.041968, mean_q: 1.178897
 657666/1000000: episode: 6577, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.817, mean reward: 0.608 [0.508, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.716, 10.098], loss: 0.001592, mae: 0.043132, mean_q: 1.177046
 657766/1000000: episode: 6578, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 62.156, mean reward: 0.622 [0.522, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.662, 10.098], loss: 0.001525, mae: 0.041927, mean_q: 1.173770
 657866/1000000: episode: 6579, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.849, mean reward: 0.598 [0.504, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.554, 10.424], loss: 0.001475, mae: 0.041929, mean_q: 1.177328
 657966/1000000: episode: 6580, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.892, mean reward: 0.589 [0.508, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.524, 10.098], loss: 0.001531, mae: 0.042277, mean_q: 1.178170
 658066/1000000: episode: 6581, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.081, mean reward: 0.571 [0.503, 0.669], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.690, 10.098], loss: 0.001566, mae: 0.043403, mean_q: 1.179182
 658166/1000000: episode: 6582, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.590, mean reward: 0.586 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.676, 10.102], loss: 0.001474, mae: 0.041385, mean_q: 1.176540
 658266/1000000: episode: 6583, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.977, mean reward: 0.600 [0.505, 0.865], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.517, 10.098], loss: 0.001491, mae: 0.041997, mean_q: 1.174173
 658366/1000000: episode: 6584, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.003, mean reward: 0.590 [0.506, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.274, 10.098], loss: 0.001557, mae: 0.042420, mean_q: 1.179964
 658466/1000000: episode: 6585, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 57.463, mean reward: 0.575 [0.505, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.653, 10.098], loss: 0.001571, mae: 0.042176, mean_q: 1.176978
 658566/1000000: episode: 6586, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.985, mean reward: 0.590 [0.499, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.947, 10.233], loss: 0.001551, mae: 0.042411, mean_q: 1.175316
 658666/1000000: episode: 6587, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.502, mean reward: 0.575 [0.498, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.390, 10.182], loss: 0.001475, mae: 0.041870, mean_q: 1.175993
 658766/1000000: episode: 6588, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 60.852, mean reward: 0.609 [0.517, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.529, 10.098], loss: 0.001565, mae: 0.042807, mean_q: 1.173857
 658866/1000000: episode: 6589, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.333, mean reward: 0.593 [0.503, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.823, 10.223], loss: 0.001517, mae: 0.042262, mean_q: 1.172515
 658966/1000000: episode: 6590, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.989, mean reward: 0.580 [0.509, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.775, 10.098], loss: 0.001636, mae: 0.043385, mean_q: 1.178136
 659066/1000000: episode: 6591, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.584, mean reward: 0.596 [0.500, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.220, 10.334], loss: 0.001504, mae: 0.041747, mean_q: 1.177156
 659166/1000000: episode: 6592, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 61.637, mean reward: 0.616 [0.505, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.798, 10.247], loss: 0.001569, mae: 0.042484, mean_q: 1.176365
 659266/1000000: episode: 6593, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.776, mean reward: 0.578 [0.502, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.793, 10.187], loss: 0.001613, mae: 0.043792, mean_q: 1.179005
 659366/1000000: episode: 6594, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 61.196, mean reward: 0.612 [0.514, 0.887], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.238, 10.196], loss: 0.001584, mae: 0.043379, mean_q: 1.173256
 659466/1000000: episode: 6595, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.364, mean reward: 0.584 [0.502, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.456, 10.104], loss: 0.001520, mae: 0.042429, mean_q: 1.177630
 659566/1000000: episode: 6596, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 59.388, mean reward: 0.594 [0.501, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.846, 10.186], loss: 0.001597, mae: 0.043615, mean_q: 1.175665
 659666/1000000: episode: 6597, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.002, mean reward: 0.580 [0.498, 0.880], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.229, 10.098], loss: 0.001632, mae: 0.043396, mean_q: 1.174172
 659766/1000000: episode: 6598, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 56.984, mean reward: 0.570 [0.502, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.804, 10.284], loss: 0.001671, mae: 0.044064, mean_q: 1.175790
 659866/1000000: episode: 6599, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 63.365, mean reward: 0.634 [0.519, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.838, 10.371], loss: 0.001481, mae: 0.041570, mean_q: 1.174155
 659966/1000000: episode: 6600, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 60.435, mean reward: 0.604 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.047, 10.098], loss: 0.001549, mae: 0.042524, mean_q: 1.178126
 660066/1000000: episode: 6601, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.727, mean reward: 0.587 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.261, 10.340], loss: 0.001532, mae: 0.042196, mean_q: 1.173106
 660166/1000000: episode: 6602, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.633, mean reward: 0.596 [0.504, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.565, 10.264], loss: 0.001613, mae: 0.043536, mean_q: 1.172794
 660266/1000000: episode: 6603, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.757, mean reward: 0.598 [0.509, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.843, 10.262], loss: 0.001602, mae: 0.043355, mean_q: 1.173734
 660366/1000000: episode: 6604, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.299, mean reward: 0.593 [0.504, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.260, 10.098], loss: 0.001547, mae: 0.042822, mean_q: 1.174304
 660466/1000000: episode: 6605, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.608, mean reward: 0.586 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.253, 10.141], loss: 0.001644, mae: 0.043878, mean_q: 1.174089
 660566/1000000: episode: 6606, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.804, mean reward: 0.608 [0.514, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.071, 10.098], loss: 0.001597, mae: 0.043461, mean_q: 1.169399
 660666/1000000: episode: 6607, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.428, mean reward: 0.574 [0.501, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.486, 10.098], loss: 0.001502, mae: 0.041758, mean_q: 1.172948
 660766/1000000: episode: 6608, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.073, mean reward: 0.591 [0.501, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-2.236, 10.182], loss: 0.001510, mae: 0.042270, mean_q: 1.169996
 660866/1000000: episode: 6609, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 59.109, mean reward: 0.591 [0.511, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.466, 10.098], loss: 0.001479, mae: 0.041879, mean_q: 1.167750
 660966/1000000: episode: 6610, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.905, mean reward: 0.579 [0.506, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.645, 10.192], loss: 0.001475, mae: 0.042085, mean_q: 1.170714
 661066/1000000: episode: 6611, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 57.710, mean reward: 0.577 [0.499, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.684, 10.098], loss: 0.001562, mae: 0.042701, mean_q: 1.169944
 661166/1000000: episode: 6612, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.585, mean reward: 0.596 [0.515, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.934, 10.153], loss: 0.001572, mae: 0.042510, mean_q: 1.167490
 661266/1000000: episode: 6613, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.274, mean reward: 0.583 [0.505, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.457, 10.160], loss: 0.001567, mae: 0.042209, mean_q: 1.170102
 661366/1000000: episode: 6614, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.704, mean reward: 0.597 [0.520, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.449, 10.168], loss: 0.001613, mae: 0.043494, mean_q: 1.171533
 661466/1000000: episode: 6615, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.342, mean reward: 0.593 [0.507, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.893, 10.176], loss: 0.001548, mae: 0.043220, mean_q: 1.170303
 661566/1000000: episode: 6616, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.677, mean reward: 0.597 [0.504, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.996, 10.101], loss: 0.001595, mae: 0.043738, mean_q: 1.170942
 661666/1000000: episode: 6617, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.518, mean reward: 0.575 [0.502, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.213, 10.098], loss: 0.001587, mae: 0.043630, mean_q: 1.171624
 661766/1000000: episode: 6618, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.410, mean reward: 0.594 [0.505, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.515, 10.098], loss: 0.001567, mae: 0.043285, mean_q: 1.172097
 661866/1000000: episode: 6619, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.411, mean reward: 0.574 [0.505, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.426, 10.108], loss: 0.001626, mae: 0.043976, mean_q: 1.176488
 661966/1000000: episode: 6620, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.466, mean reward: 0.595 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.768, 10.098], loss: 0.001544, mae: 0.042860, mean_q: 1.168280
 662066/1000000: episode: 6621, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.421, mean reward: 0.574 [0.501, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.758, 10.276], loss: 0.001594, mae: 0.043408, mean_q: 1.170423
 662166/1000000: episode: 6622, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.901, mean reward: 0.579 [0.507, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.084, 10.279], loss: 0.001502, mae: 0.042361, mean_q: 1.169492
 662266/1000000: episode: 6623, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.440, mean reward: 0.594 [0.504, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.127, 10.098], loss: 0.001474, mae: 0.041738, mean_q: 1.172228
 662366/1000000: episode: 6624, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 63.712, mean reward: 0.637 [0.511, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.406, 10.098], loss: 0.001470, mae: 0.041694, mean_q: 1.167826
 662466/1000000: episode: 6625, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 63.853, mean reward: 0.639 [0.514, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.753, 10.209], loss: 0.001540, mae: 0.042327, mean_q: 1.173187
 662566/1000000: episode: 6626, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.779, mean reward: 0.588 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.702, 10.247], loss: 0.001553, mae: 0.042601, mean_q: 1.174601
 662666/1000000: episode: 6627, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 57.844, mean reward: 0.578 [0.509, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.024, 10.098], loss: 0.001540, mae: 0.042218, mean_q: 1.171097
 662766/1000000: episode: 6628, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.572, mean reward: 0.606 [0.510, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.157, 10.191], loss: 0.001590, mae: 0.043071, mean_q: 1.171598
 662866/1000000: episode: 6629, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.481, mean reward: 0.605 [0.506, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.825, 10.173], loss: 0.001577, mae: 0.043441, mean_q: 1.170573
 662966/1000000: episode: 6630, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 59.377, mean reward: 0.594 [0.513, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.323, 10.238], loss: 0.001457, mae: 0.042255, mean_q: 1.169100
 663066/1000000: episode: 6631, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.184, mean reward: 0.592 [0.500, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.028, 10.249], loss: 0.001583, mae: 0.043555, mean_q: 1.173838
 663166/1000000: episode: 6632, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.063, mean reward: 0.581 [0.503, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.795, 10.098], loss: 0.001491, mae: 0.042267, mean_q: 1.172455
 663266/1000000: episode: 6633, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.799, mean reward: 0.588 [0.504, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.718, 10.139], loss: 0.001463, mae: 0.041998, mean_q: 1.172473
 663366/1000000: episode: 6634, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 65.509, mean reward: 0.655 [0.504, 0.867], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.898, 10.098], loss: 0.001522, mae: 0.042603, mean_q: 1.172275
 663466/1000000: episode: 6635, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.644, mean reward: 0.586 [0.504, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.117, 10.098], loss: 0.001541, mae: 0.042983, mean_q: 1.174321
 663566/1000000: episode: 6636, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.057, mean reward: 0.581 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.367, 10.183], loss: 0.001636, mae: 0.044181, mean_q: 1.176749
 663666/1000000: episode: 6637, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.415, mean reward: 0.584 [0.506, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.288, 10.259], loss: 0.001639, mae: 0.044007, mean_q: 1.178155
 663766/1000000: episode: 6638, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.850, mean reward: 0.599 [0.501, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.116, 10.098], loss: 0.001571, mae: 0.042879, mean_q: 1.173599
 663866/1000000: episode: 6639, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 56.788, mean reward: 0.568 [0.504, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.091, 10.176], loss: 0.001488, mae: 0.042863, mean_q: 1.170476
 663966/1000000: episode: 6640, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.203, mean reward: 0.602 [0.510, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.001, 10.187], loss: 0.001433, mae: 0.041417, mean_q: 1.172771
 664066/1000000: episode: 6641, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.095, mean reward: 0.581 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.587, 10.098], loss: 0.001443, mae: 0.041459, mean_q: 1.173934
 664166/1000000: episode: 6642, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.352, mean reward: 0.594 [0.503, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.646, 10.315], loss: 0.001590, mae: 0.043293, mean_q: 1.173766
 664266/1000000: episode: 6643, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.041, mean reward: 0.580 [0.507, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.238, 10.245], loss: 0.001596, mae: 0.044047, mean_q: 1.173285
 664366/1000000: episode: 6644, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.021, mean reward: 0.610 [0.504, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.081, 10.098], loss: 0.001527, mae: 0.042855, mean_q: 1.174826
 664466/1000000: episode: 6645, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.451, mean reward: 0.575 [0.499, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.321, 10.145], loss: 0.001423, mae: 0.041806, mean_q: 1.174811
 664566/1000000: episode: 6646, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.792, mean reward: 0.598 [0.506, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.846, 10.201], loss: 0.001542, mae: 0.042940, mean_q: 1.173526
 664666/1000000: episode: 6647, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.595, mean reward: 0.576 [0.503, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.161, 10.151], loss: 0.001445, mae: 0.041567, mean_q: 1.173973
 664766/1000000: episode: 6648, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 60.769, mean reward: 0.608 [0.518, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.005, 10.098], loss: 0.001460, mae: 0.041757, mean_q: 1.172119
 664866/1000000: episode: 6649, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 61.347, mean reward: 0.613 [0.506, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-2.344, 10.145], loss: 0.001544, mae: 0.042846, mean_q: 1.172397
 664966/1000000: episode: 6650, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.981, mean reward: 0.580 [0.509, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.184, 10.098], loss: 0.001574, mae: 0.042660, mean_q: 1.171220
 665066/1000000: episode: 6651, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.617, mean reward: 0.586 [0.502, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.776, 10.153], loss: 0.001396, mae: 0.040590, mean_q: 1.170836
 665166/1000000: episode: 6652, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.710, mean reward: 0.597 [0.508, 0.931], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.788, 10.098], loss: 0.001447, mae: 0.042007, mean_q: 1.170180
 665266/1000000: episode: 6653, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.540, mean reward: 0.605 [0.516, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.348, 10.098], loss: 0.001563, mae: 0.042677, mean_q: 1.175783
 665366/1000000: episode: 6654, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 61.041, mean reward: 0.610 [0.505, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.758, 10.098], loss: 0.001511, mae: 0.041972, mean_q: 1.170412
 665466/1000000: episode: 6655, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.499, mean reward: 0.575 [0.508, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.898, 10.208], loss: 0.001453, mae: 0.041843, mean_q: 1.176990
 665566/1000000: episode: 6656, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 61.185, mean reward: 0.612 [0.503, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.485, 10.495], loss: 0.001632, mae: 0.043110, mean_q: 1.174361
 665666/1000000: episode: 6657, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.765, mean reward: 0.588 [0.509, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.974, 10.098], loss: 0.001519, mae: 0.042253, mean_q: 1.172748
 665766/1000000: episode: 6658, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.608, mean reward: 0.576 [0.503, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.622, 10.098], loss: 0.001653, mae: 0.043979, mean_q: 1.176435
 665866/1000000: episode: 6659, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.720, mean reward: 0.587 [0.503, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.949, 10.098], loss: 0.001508, mae: 0.041888, mean_q: 1.173957
 665966/1000000: episode: 6660, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.318, mean reward: 0.583 [0.497, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.674, 10.355], loss: 0.001574, mae: 0.042461, mean_q: 1.173475
 666066/1000000: episode: 6661, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.013, mean reward: 0.570 [0.499, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.785, 10.266], loss: 0.001585, mae: 0.042625, mean_q: 1.174726
 666166/1000000: episode: 6662, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.590, mean reward: 0.596 [0.499, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.037, 10.142], loss: 0.001515, mae: 0.041911, mean_q: 1.174046
 666266/1000000: episode: 6663, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.628, mean reward: 0.606 [0.504, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.581, 10.098], loss: 0.001553, mae: 0.042691, mean_q: 1.178138
 666366/1000000: episode: 6664, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.509, mean reward: 0.595 [0.498, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.624, 10.156], loss: 0.001499, mae: 0.042154, mean_q: 1.176156
 666466/1000000: episode: 6665, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.998, mean reward: 0.580 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.945, 10.147], loss: 0.001470, mae: 0.041609, mean_q: 1.174657
 666566/1000000: episode: 6666, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.846, mean reward: 0.578 [0.509, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.969, 10.169], loss: 0.001507, mae: 0.042460, mean_q: 1.171562
 666666/1000000: episode: 6667, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.568, mean reward: 0.586 [0.510, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.314, 10.098], loss: 0.001502, mae: 0.042334, mean_q: 1.175858
 666766/1000000: episode: 6668, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.361, mean reward: 0.584 [0.500, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.592, 10.337], loss: 0.001540, mae: 0.042261, mean_q: 1.173752
 666866/1000000: episode: 6669, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 67.121, mean reward: 0.671 [0.503, 0.841], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.244, 10.306], loss: 0.001440, mae: 0.040698, mean_q: 1.172807
 666966/1000000: episode: 6670, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.488, mean reward: 0.585 [0.502, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.690, 10.238], loss: 0.001460, mae: 0.041070, mean_q: 1.174523
 667066/1000000: episode: 6671, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.968, mean reward: 0.600 [0.504, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.080, 10.210], loss: 0.001537, mae: 0.042082, mean_q: 1.178271
 667166/1000000: episode: 6672, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.235, mean reward: 0.612 [0.517, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.409 [-0.768, 10.098], loss: 0.001474, mae: 0.042330, mean_q: 1.174443
 667266/1000000: episode: 6673, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.890, mean reward: 0.599 [0.498, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.767, 10.173], loss: 0.001470, mae: 0.041416, mean_q: 1.177924
 667366/1000000: episode: 6674, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.120, mean reward: 0.601 [0.500, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.932, 10.280], loss: 0.001527, mae: 0.041811, mean_q: 1.174204
 667466/1000000: episode: 6675, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.239, mean reward: 0.582 [0.502, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.598, 10.335], loss: 0.001499, mae: 0.041265, mean_q: 1.180090
 667566/1000000: episode: 6676, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.480, mean reward: 0.575 [0.507, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.114, 10.177], loss: 0.001384, mae: 0.040485, mean_q: 1.175129
 667666/1000000: episode: 6677, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.467, mean reward: 0.575 [0.506, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.365, 10.185], loss: 0.001514, mae: 0.041297, mean_q: 1.176394
 667766/1000000: episode: 6678, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.208, mean reward: 0.572 [0.505, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.969, 10.098], loss: 0.001499, mae: 0.041411, mean_q: 1.173122
 667866/1000000: episode: 6679, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.356, mean reward: 0.594 [0.511, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.015, 10.098], loss: 0.001465, mae: 0.041324, mean_q: 1.172567
 667966/1000000: episode: 6680, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.248, mean reward: 0.572 [0.507, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.207, 10.183], loss: 0.001498, mae: 0.041923, mean_q: 1.172312
 668066/1000000: episode: 6681, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.873, mean reward: 0.589 [0.506, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.323, 10.215], loss: 0.001421, mae: 0.040306, mean_q: 1.172803
 668166/1000000: episode: 6682, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 56.925, mean reward: 0.569 [0.502, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.123, 10.098], loss: 0.001532, mae: 0.042407, mean_q: 1.169329
 668266/1000000: episode: 6683, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.662, mean reward: 0.577 [0.501, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.773, 10.098], loss: 0.001441, mae: 0.040745, mean_q: 1.170582
 668366/1000000: episode: 6684, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.894, mean reward: 0.579 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.632, 10.243], loss: 0.001507, mae: 0.042052, mean_q: 1.169364
 668466/1000000: episode: 6685, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.251, mean reward: 0.583 [0.502, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.160, 10.192], loss: 0.001490, mae: 0.041437, mean_q: 1.169189
 668566/1000000: episode: 6686, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.508, mean reward: 0.575 [0.506, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.351, 10.117], loss: 0.001503, mae: 0.041929, mean_q: 1.168856
 668666/1000000: episode: 6687, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.319, mean reward: 0.613 [0.504, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.634, 10.218], loss: 0.001515, mae: 0.041292, mean_q: 1.165786
 668766/1000000: episode: 6688, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 62.267, mean reward: 0.623 [0.507, 0.901], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.670, 10.098], loss: 0.001505, mae: 0.042185, mean_q: 1.167724
 668866/1000000: episode: 6689, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 57.031, mean reward: 0.570 [0.507, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.136, 10.201], loss: 0.001476, mae: 0.042061, mean_q: 1.169156
 668966/1000000: episode: 6690, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.956, mean reward: 0.600 [0.503, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.771, 10.315], loss: 0.001549, mae: 0.041973, mean_q: 1.167271
 669066/1000000: episode: 6691, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 60.582, mean reward: 0.606 [0.512, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.307, 10.303], loss: 0.001443, mae: 0.041157, mean_q: 1.170790
 669166/1000000: episode: 6692, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 56.933, mean reward: 0.569 [0.500, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.855, 10.182], loss: 0.001555, mae: 0.042409, mean_q: 1.169745
 669266/1000000: episode: 6693, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.685, mean reward: 0.617 [0.520, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.193, 10.227], loss: 0.001495, mae: 0.041599, mean_q: 1.172156
 669366/1000000: episode: 6694, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.985, mean reward: 0.580 [0.499, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.466, 10.106], loss: 0.001500, mae: 0.042336, mean_q: 1.170810
 669466/1000000: episode: 6695, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.381, mean reward: 0.594 [0.510, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.973, 10.236], loss: 0.001517, mae: 0.042191, mean_q: 1.170127
 669566/1000000: episode: 6696, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.175, mean reward: 0.602 [0.500, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.770, 10.098], loss: 0.001522, mae: 0.041745, mean_q: 1.169889
 669666/1000000: episode: 6697, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.657, mean reward: 0.597 [0.512, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.540, 10.101], loss: 0.001559, mae: 0.043089, mean_q: 1.170314
 669766/1000000: episode: 6698, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.969, mean reward: 0.580 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.387, 10.098], loss: 0.001397, mae: 0.040489, mean_q: 1.168726
 669866/1000000: episode: 6699, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 60.051, mean reward: 0.601 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.933, 10.289], loss: 0.001560, mae: 0.042324, mean_q: 1.168110
 669966/1000000: episode: 6700, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.301, mean reward: 0.573 [0.505, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.269, 10.156], loss: 0.001508, mae: 0.042119, mean_q: 1.165267
 670066/1000000: episode: 6701, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.982, mean reward: 0.580 [0.518, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.076, 10.098], loss: 0.001492, mae: 0.041395, mean_q: 1.167946
 670166/1000000: episode: 6702, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 60.737, mean reward: 0.607 [0.500, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.075, 10.098], loss: 0.001451, mae: 0.041328, mean_q: 1.169261
 670266/1000000: episode: 6703, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.900, mean reward: 0.589 [0.506, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.198, 10.425], loss: 0.001428, mae: 0.041361, mean_q: 1.166486
 670366/1000000: episode: 6704, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.091, mean reward: 0.581 [0.509, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.394, 10.235], loss: 0.001480, mae: 0.042143, mean_q: 1.171663
 670466/1000000: episode: 6705, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.249, mean reward: 0.582 [0.505, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.866, 10.098], loss: 0.001513, mae: 0.042398, mean_q: 1.171916
 670566/1000000: episode: 6706, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 58.826, mean reward: 0.588 [0.502, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.137, 10.098], loss: 0.001404, mae: 0.040890, mean_q: 1.165287
 670666/1000000: episode: 6707, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 58.875, mean reward: 0.589 [0.511, 0.869], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.864, 10.098], loss: 0.001470, mae: 0.041773, mean_q: 1.167441
 670766/1000000: episode: 6708, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.739, mean reward: 0.567 [0.504, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.921, 10.113], loss: 0.001462, mae: 0.041923, mean_q: 1.169589
 670866/1000000: episode: 6709, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.557, mean reward: 0.576 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.854, 10.122], loss: 0.001488, mae: 0.042187, mean_q: 1.168126
 670966/1000000: episode: 6710, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.973, mean reward: 0.610 [0.500, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.327, 10.098], loss: 0.001525, mae: 0.042289, mean_q: 1.164585
 671066/1000000: episode: 6711, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.161, mean reward: 0.572 [0.503, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.091, 10.098], loss: 0.001435, mae: 0.040980, mean_q: 1.165919
 671166/1000000: episode: 6712, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.040, mean reward: 0.600 [0.504, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.470, 10.357], loss: 0.001367, mae: 0.040700, mean_q: 1.170476
 671266/1000000: episode: 6713, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.849, mean reward: 0.618 [0.499, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.516, 10.235], loss: 0.001435, mae: 0.041390, mean_q: 1.166173
 671366/1000000: episode: 6714, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.845, mean reward: 0.578 [0.500, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.214, 10.098], loss: 0.001425, mae: 0.041387, mean_q: 1.167571
 671466/1000000: episode: 6715, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.578, mean reward: 0.596 [0.505, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.246, 10.138], loss: 0.001405, mae: 0.041428, mean_q: 1.167922
 671566/1000000: episode: 6716, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.907, mean reward: 0.619 [0.510, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.907, 10.098], loss: 0.001494, mae: 0.042057, mean_q: 1.167507
 671666/1000000: episode: 6717, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 61.033, mean reward: 0.610 [0.516, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.838, 10.098], loss: 0.001534, mae: 0.042695, mean_q: 1.173398
 671766/1000000: episode: 6718, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.528, mean reward: 0.595 [0.504, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.470, 10.228], loss: 0.001494, mae: 0.041731, mean_q: 1.170104
 671866/1000000: episode: 6719, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.431, mean reward: 0.604 [0.507, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.968, 10.203], loss: 0.001475, mae: 0.041898, mean_q: 1.165976
 671966/1000000: episode: 6720, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.349, mean reward: 0.583 [0.503, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.299, 10.108], loss: 0.001595, mae: 0.043397, mean_q: 1.170702
 672066/1000000: episode: 6721, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.398, mean reward: 0.604 [0.505, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.814, 10.405], loss: 0.001571, mae: 0.042618, mean_q: 1.164140
 672166/1000000: episode: 6722, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.327, mean reward: 0.603 [0.520, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.936, 10.098], loss: 0.001546, mae: 0.042790, mean_q: 1.164739
 672266/1000000: episode: 6723, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.459, mean reward: 0.585 [0.503, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.763, 10.197], loss: 0.001539, mae: 0.043002, mean_q: 1.165867
 672366/1000000: episode: 6724, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.734, mean reward: 0.587 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.855, 10.098], loss: 0.001478, mae: 0.042072, mean_q: 1.163899
 672466/1000000: episode: 6725, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.192, mean reward: 0.592 [0.509, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.426, 10.098], loss: 0.001559, mae: 0.043108, mean_q: 1.167952
 672566/1000000: episode: 6726, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.019, mean reward: 0.580 [0.504, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.086, 10.098], loss: 0.001552, mae: 0.042902, mean_q: 1.163772
 672666/1000000: episode: 6727, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.937, mean reward: 0.589 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.842, 10.098], loss: 0.001513, mae: 0.042746, mean_q: 1.171141
 672766/1000000: episode: 6728, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.358, mean reward: 0.574 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.732, 10.149], loss: 0.001506, mae: 0.042035, mean_q: 1.167721
 672866/1000000: episode: 6729, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 64.573, mean reward: 0.646 [0.512, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.391, 10.455], loss: 0.001545, mae: 0.042550, mean_q: 1.169520
 672966/1000000: episode: 6730, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.594, mean reward: 0.586 [0.504, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.892, 10.098], loss: 0.001535, mae: 0.042768, mean_q: 1.173098
 673066/1000000: episode: 6731, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.334, mean reward: 0.573 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.701, 10.216], loss: 0.001577, mae: 0.043350, mean_q: 1.171883
 673166/1000000: episode: 6732, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.118, mean reward: 0.581 [0.503, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.304, 10.177], loss: 0.001590, mae: 0.043856, mean_q: 1.171376
 673266/1000000: episode: 6733, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.512, mean reward: 0.585 [0.504, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.985, 10.098], loss: 0.001578, mae: 0.043346, mean_q: 1.167878
 673366/1000000: episode: 6734, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.194, mean reward: 0.572 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.121, 10.175], loss: 0.001522, mae: 0.042773, mean_q: 1.172109
 673466/1000000: episode: 6735, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.043, mean reward: 0.580 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.957, 10.172], loss: 0.001523, mae: 0.042084, mean_q: 1.170473
 673566/1000000: episode: 6736, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.049, mean reward: 0.580 [0.511, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.369, 10.185], loss: 0.001609, mae: 0.043367, mean_q: 1.166702
 673666/1000000: episode: 6737, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.509, mean reward: 0.585 [0.503, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.081, 10.206], loss: 0.001501, mae: 0.042095, mean_q: 1.168613
 673766/1000000: episode: 6738, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.404, mean reward: 0.594 [0.505, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.415, 10.104], loss: 0.001474, mae: 0.041419, mean_q: 1.169801
 673866/1000000: episode: 6739, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.645, mean reward: 0.576 [0.508, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.366, 10.262], loss: 0.001528, mae: 0.042319, mean_q: 1.170016
 673966/1000000: episode: 6740, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.775, mean reward: 0.578 [0.507, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.168, 10.185], loss: 0.001544, mae: 0.042595, mean_q: 1.169104
 674066/1000000: episode: 6741, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.782, mean reward: 0.578 [0.505, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.807, 10.255], loss: 0.001449, mae: 0.041152, mean_q: 1.165998
 674166/1000000: episode: 6742, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 60.183, mean reward: 0.602 [0.505, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.546, 10.098], loss: 0.001474, mae: 0.041655, mean_q: 1.167909
 674266/1000000: episode: 6743, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.596, mean reward: 0.596 [0.510, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.116, 10.136], loss: 0.001492, mae: 0.041325, mean_q: 1.166904
 674366/1000000: episode: 6744, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 56.648, mean reward: 0.566 [0.506, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.659, 10.155], loss: 0.001378, mae: 0.040588, mean_q: 1.165659
 674466/1000000: episode: 6745, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.874, mean reward: 0.599 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.226, 10.098], loss: 0.001373, mae: 0.040268, mean_q: 1.167038
 674566/1000000: episode: 6746, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 65.300, mean reward: 0.653 [0.504, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.624, 10.486], loss: 0.001407, mae: 0.040657, mean_q: 1.161907
 674666/1000000: episode: 6747, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.688, mean reward: 0.587 [0.511, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.816, 10.212], loss: 0.001457, mae: 0.041613, mean_q: 1.169432
 674766/1000000: episode: 6748, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.063, mean reward: 0.581 [0.510, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.492, 10.385], loss: 0.001462, mae: 0.041099, mean_q: 1.168547
 674866/1000000: episode: 6749, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.339, mean reward: 0.573 [0.500, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.705, 10.098], loss: 0.001458, mae: 0.041445, mean_q: 1.169662
 674966/1000000: episode: 6750, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 61.754, mean reward: 0.618 [0.514, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.575, 10.458], loss: 0.001456, mae: 0.041177, mean_q: 1.172442
 675066/1000000: episode: 6751, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.004, mean reward: 0.590 [0.509, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.879, 10.098], loss: 0.001483, mae: 0.042161, mean_q: 1.174011
 675166/1000000: episode: 6752, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.194, mean reward: 0.572 [0.510, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.601, 10.098], loss: 0.001443, mae: 0.040855, mean_q: 1.172873
 675266/1000000: episode: 6753, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 58.121, mean reward: 0.581 [0.509, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.339, 10.142], loss: 0.001437, mae: 0.040865, mean_q: 1.168888
 675366/1000000: episode: 6754, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.639, mean reward: 0.576 [0.503, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.303, 10.138], loss: 0.001353, mae: 0.040564, mean_q: 1.170280
 675466/1000000: episode: 6755, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.710, mean reward: 0.607 [0.508, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.966, 10.243], loss: 0.001400, mae: 0.040726, mean_q: 1.166534
 675566/1000000: episode: 6756, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.493, mean reward: 0.585 [0.507, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.002, 10.205], loss: 0.001316, mae: 0.040171, mean_q: 1.167106
 675666/1000000: episode: 6757, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.034, mean reward: 0.590 [0.505, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.442, 10.098], loss: 0.001419, mae: 0.040975, mean_q: 1.172071
 675766/1000000: episode: 6758, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.660, mean reward: 0.587 [0.506, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.687, 10.243], loss: 0.001338, mae: 0.039608, mean_q: 1.168163
 675866/1000000: episode: 6759, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.411, mean reward: 0.574 [0.503, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.978, 10.098], loss: 0.001309, mae: 0.039862, mean_q: 1.167679
 675966/1000000: episode: 6760, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.240, mean reward: 0.582 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.525, 10.098], loss: 0.001513, mae: 0.041962, mean_q: 1.171402
 676066/1000000: episode: 6761, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.192, mean reward: 0.582 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.623, 10.120], loss: 0.001476, mae: 0.041714, mean_q: 1.171504
 676166/1000000: episode: 6762, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 57.378, mean reward: 0.574 [0.505, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.058, 10.178], loss: 0.001418, mae: 0.040837, mean_q: 1.170072
 676266/1000000: episode: 6763, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.329, mean reward: 0.583 [0.506, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.236, 10.211], loss: 0.001394, mae: 0.041080, mean_q: 1.166812
 676366/1000000: episode: 6764, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.995, mean reward: 0.610 [0.508, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.619, 10.277], loss: 0.001357, mae: 0.040183, mean_q: 1.166200
 676466/1000000: episode: 6765, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 62.837, mean reward: 0.628 [0.510, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.658, 10.243], loss: 0.001460, mae: 0.041619, mean_q: 1.171763
 676566/1000000: episode: 6766, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.555, mean reward: 0.576 [0.503, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.806, 10.213], loss: 0.001316, mae: 0.039883, mean_q: 1.169845
 676666/1000000: episode: 6767, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.252, mean reward: 0.603 [0.515, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.421, 10.143], loss: 0.001355, mae: 0.040107, mean_q: 1.169347
 676766/1000000: episode: 6768, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.387, mean reward: 0.584 [0.498, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.529, 10.291], loss: 0.001334, mae: 0.039709, mean_q: 1.165116
 676866/1000000: episode: 6769, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 61.313, mean reward: 0.613 [0.517, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.592, 10.098], loss: 0.001358, mae: 0.040192, mean_q: 1.165574
 676966/1000000: episode: 6770, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 56.634, mean reward: 0.566 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.554, 10.098], loss: 0.001379, mae: 0.040581, mean_q: 1.164811
 677066/1000000: episode: 6771, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.503, mean reward: 0.575 [0.505, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.679, 10.098], loss: 0.001284, mae: 0.039396, mean_q: 1.164592
 677166/1000000: episode: 6772, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.162, mean reward: 0.592 [0.508, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.365, 10.195], loss: 0.001293, mae: 0.039331, mean_q: 1.163820
 677266/1000000: episode: 6773, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.204, mean reward: 0.592 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.987, 10.098], loss: 0.001257, mae: 0.038594, mean_q: 1.164696
 677366/1000000: episode: 6774, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.606, mean reward: 0.576 [0.506, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.744, 10.250], loss: 0.001391, mae: 0.040735, mean_q: 1.165893
 677466/1000000: episode: 6775, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.508, mean reward: 0.585 [0.499, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.693, 10.266], loss: 0.001305, mae: 0.039059, mean_q: 1.162979
 677566/1000000: episode: 6776, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 65.763, mean reward: 0.658 [0.514, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.680, 10.225], loss: 0.001319, mae: 0.039466, mean_q: 1.163513
 677666/1000000: episode: 6777, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.643, mean reward: 0.596 [0.500, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.274, 10.236], loss: 0.001409, mae: 0.041036, mean_q: 1.168564
 677766/1000000: episode: 6778, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 58.230, mean reward: 0.582 [0.504, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.570, 10.115], loss: 0.001327, mae: 0.040008, mean_q: 1.167488
 677866/1000000: episode: 6779, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.257, mean reward: 0.583 [0.510, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.509, 10.098], loss: 0.001316, mae: 0.039710, mean_q: 1.164218
 677966/1000000: episode: 6780, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.612, mean reward: 0.596 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-1.225, 10.316], loss: 0.001367, mae: 0.040548, mean_q: 1.165216
 678066/1000000: episode: 6781, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.040, mean reward: 0.600 [0.510, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.196, 10.199], loss: 0.001345, mae: 0.039965, mean_q: 1.162432
 678166/1000000: episode: 6782, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.912, mean reward: 0.579 [0.498, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.458, 10.098], loss: 0.001416, mae: 0.040909, mean_q: 1.167025
 678266/1000000: episode: 6783, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 56.883, mean reward: 0.569 [0.502, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.739, 10.098], loss: 0.001427, mae: 0.040588, mean_q: 1.164608
 678366/1000000: episode: 6784, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.451, mean reward: 0.575 [0.501, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.546, 10.174], loss: 0.001466, mae: 0.041390, mean_q: 1.165907
 678466/1000000: episode: 6785, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.068, mean reward: 0.571 [0.502, 0.663], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.965, 10.101], loss: 0.001396, mae: 0.040886, mean_q: 1.169280
 678566/1000000: episode: 6786, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.154, mean reward: 0.582 [0.500, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.574, 10.348], loss: 0.001403, mae: 0.040308, mean_q: 1.168812
 678666/1000000: episode: 6787, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.489, mean reward: 0.585 [0.504, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.641, 10.234], loss: 0.001386, mae: 0.041207, mean_q: 1.167086
 678766/1000000: episode: 6788, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.976, mean reward: 0.580 [0.500, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.068, 10.164], loss: 0.001421, mae: 0.040340, mean_q: 1.165484
 678866/1000000: episode: 6789, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.195, mean reward: 0.582 [0.522, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.660, 10.137], loss: 0.001345, mae: 0.039670, mean_q: 1.164424
 678966/1000000: episode: 6790, duration: 0.525s, episode steps: 100, steps per second: 190, episode reward: 59.731, mean reward: 0.597 [0.506, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.983, 10.311], loss: 0.001413, mae: 0.040680, mean_q: 1.164655
 679066/1000000: episode: 6791, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.486, mean reward: 0.585 [0.500, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.225, 10.250], loss: 0.001442, mae: 0.040802, mean_q: 1.168764
 679166/1000000: episode: 6792, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 66.724, mean reward: 0.667 [0.504, 0.854], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.508, 10.363], loss: 0.001465, mae: 0.040988, mean_q: 1.168713
 679266/1000000: episode: 6793, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.028, mean reward: 0.560 [0.497, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.421, 10.161], loss: 0.001523, mae: 0.041978, mean_q: 1.169534
 679366/1000000: episode: 6794, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.515, mean reward: 0.575 [0.502, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.962, 10.125], loss: 0.001363, mae: 0.039473, mean_q: 1.165225
 679466/1000000: episode: 6795, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 62.287, mean reward: 0.623 [0.513, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-0.728, 10.098], loss: 0.001379, mae: 0.040572, mean_q: 1.168938
 679566/1000000: episode: 6796, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 61.129, mean reward: 0.611 [0.513, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.581, 10.114], loss: 0.001443, mae: 0.041349, mean_q: 1.167595
 679666/1000000: episode: 6797, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.481, mean reward: 0.595 [0.504, 0.863], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.034, 10.288], loss: 0.001503, mae: 0.041771, mean_q: 1.165273
 679766/1000000: episode: 6798, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.228, mean reward: 0.572 [0.513, 0.667], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.134, 10.173], loss: 0.001369, mae: 0.040580, mean_q: 1.167460
 679866/1000000: episode: 6799, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.896, mean reward: 0.589 [0.507, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.217, 10.281], loss: 0.001428, mae: 0.041084, mean_q: 1.170160
 679966/1000000: episode: 6800, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.020, mean reward: 0.580 [0.504, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.124, 10.098], loss: 0.001444, mae: 0.040949, mean_q: 1.165826
 680066/1000000: episode: 6801, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.137, mean reward: 0.591 [0.509, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.034, 10.098], loss: 0.001466, mae: 0.041738, mean_q: 1.167874
 680166/1000000: episode: 6802, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.043, mean reward: 0.570 [0.511, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.204, 10.098], loss: 0.001444, mae: 0.041486, mean_q: 1.165104
 680266/1000000: episode: 6803, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.013, mean reward: 0.590 [0.501, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.505, 10.098], loss: 0.001390, mae: 0.040139, mean_q: 1.164969
 680366/1000000: episode: 6804, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.283, mean reward: 0.573 [0.506, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.953, 10.236], loss: 0.001546, mae: 0.042755, mean_q: 1.170721
 680466/1000000: episode: 6805, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.063, mean reward: 0.591 [0.514, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.830, 10.098], loss: 0.001433, mae: 0.041210, mean_q: 1.167644
 680566/1000000: episode: 6806, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.684, mean reward: 0.587 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.930, 10.098], loss: 0.001504, mae: 0.041591, mean_q: 1.163650
 680666/1000000: episode: 6807, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.453, mean reward: 0.585 [0.503, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.839, 10.098], loss: 0.001451, mae: 0.040963, mean_q: 1.166008
 680766/1000000: episode: 6808, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.983, mean reward: 0.610 [0.499, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.627, 10.302], loss: 0.001541, mae: 0.042013, mean_q: 1.164761
 680866/1000000: episode: 6809, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.887, mean reward: 0.589 [0.509, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.634, 10.098], loss: 0.001585, mae: 0.042653, mean_q: 1.167119
 680966/1000000: episode: 6810, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.869, mean reward: 0.589 [0.513, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.706, 10.179], loss: 0.001524, mae: 0.041918, mean_q: 1.168824
 681066/1000000: episode: 6811, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.717, mean reward: 0.577 [0.497, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.840, 10.098], loss: 0.001459, mae: 0.040969, mean_q: 1.167848
 681166/1000000: episode: 6812, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.571, mean reward: 0.586 [0.508, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.707, 10.098], loss: 0.001477, mae: 0.041504, mean_q: 1.168452
 681266/1000000: episode: 6813, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.368, mean reward: 0.574 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.430, 10.103], loss: 0.001443, mae: 0.040894, mean_q: 1.167114
 681366/1000000: episode: 6814, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 60.449, mean reward: 0.604 [0.505, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.090, 10.268], loss: 0.001497, mae: 0.041485, mean_q: 1.167854
 681466/1000000: episode: 6815, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.665, mean reward: 0.577 [0.508, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.438, 10.149], loss: 0.001457, mae: 0.041219, mean_q: 1.165206
 681566/1000000: episode: 6816, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.214, mean reward: 0.602 [0.507, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.113, 10.118], loss: 0.001466, mae: 0.041566, mean_q: 1.166402
 681666/1000000: episode: 6817, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.865, mean reward: 0.599 [0.527, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.440, 10.243], loss: 0.001535, mae: 0.042103, mean_q: 1.165800
 681766/1000000: episode: 6818, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.649, mean reward: 0.606 [0.510, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.429, 10.352], loss: 0.001576, mae: 0.042571, mean_q: 1.168771
 681866/1000000: episode: 6819, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.120, mean reward: 0.581 [0.511, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.328, 10.098], loss: 0.001504, mae: 0.042470, mean_q: 1.166949
 681966/1000000: episode: 6820, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 56.762, mean reward: 0.568 [0.501, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.415, 10.098], loss: 0.001370, mae: 0.040386, mean_q: 1.163808
 682066/1000000: episode: 6821, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.038, mean reward: 0.580 [0.502, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.935, 10.165], loss: 0.001632, mae: 0.043664, mean_q: 1.167048
 682166/1000000: episode: 6822, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.840, mean reward: 0.608 [0.510, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.210, 10.339], loss: 0.001509, mae: 0.041796, mean_q: 1.164469
 682266/1000000: episode: 6823, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.207, mean reward: 0.602 [0.508, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.743, 10.098], loss: 0.001393, mae: 0.040510, mean_q: 1.165507
 682366/1000000: episode: 6824, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.706, mean reward: 0.587 [0.511, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.912, 10.153], loss: 0.001571, mae: 0.042766, mean_q: 1.171328
 682466/1000000: episode: 6825, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.869, mean reward: 0.589 [0.500, 0.846], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.850, 10.098], loss: 0.001372, mae: 0.040552, mean_q: 1.170706
 682566/1000000: episode: 6826, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.245, mean reward: 0.582 [0.504, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.554, 10.158], loss: 0.001469, mae: 0.041562, mean_q: 1.164201
 682666/1000000: episode: 6827, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.221, mean reward: 0.592 [0.499, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.416, 10.105], loss: 0.001428, mae: 0.041199, mean_q: 1.166001
 682766/1000000: episode: 6828, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.948, mean reward: 0.589 [0.509, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.898, 10.098], loss: 0.001413, mae: 0.040932, mean_q: 1.166321
 682866/1000000: episode: 6829, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.793, mean reward: 0.578 [0.499, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.623, 10.190], loss: 0.001502, mae: 0.041781, mean_q: 1.166238
 682966/1000000: episode: 6830, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 62.070, mean reward: 0.621 [0.505, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.797, 10.098], loss: 0.001489, mae: 0.041421, mean_q: 1.164936
 683066/1000000: episode: 6831, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.368, mean reward: 0.584 [0.503, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.174, 10.194], loss: 0.001502, mae: 0.041840, mean_q: 1.164070
 683166/1000000: episode: 6832, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.054, mean reward: 0.581 [0.505, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.307, 10.333], loss: 0.001467, mae: 0.041201, mean_q: 1.164193
 683266/1000000: episode: 6833, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.354, mean reward: 0.584 [0.507, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.342, 10.098], loss: 0.001489, mae: 0.041707, mean_q: 1.166619
 683366/1000000: episode: 6834, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.009, mean reward: 0.590 [0.503, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.882, 10.098], loss: 0.001502, mae: 0.042190, mean_q: 1.167313
 683466/1000000: episode: 6835, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.721, mean reward: 0.597 [0.521, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.242, 10.384], loss: 0.001559, mae: 0.042387, mean_q: 1.168746
 683566/1000000: episode: 6836, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.054, mean reward: 0.591 [0.505, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.908, 10.098], loss: 0.001482, mae: 0.041621, mean_q: 1.165111
 683666/1000000: episode: 6837, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.622, mean reward: 0.606 [0.508, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.576, 10.098], loss: 0.001401, mae: 0.040532, mean_q: 1.164944
 683766/1000000: episode: 6838, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.492, mean reward: 0.605 [0.505, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.224, 10.098], loss: 0.001486, mae: 0.041830, mean_q: 1.168152
 683866/1000000: episode: 6839, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.329, mean reward: 0.613 [0.506, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.382, 10.098], loss: 0.001498, mae: 0.041667, mean_q: 1.168105
 683966/1000000: episode: 6840, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.092, mean reward: 0.591 [0.507, 0.854], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.068, 10.364], loss: 0.001487, mae: 0.041965, mean_q: 1.170025
 684066/1000000: episode: 6841, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 59.185, mean reward: 0.592 [0.510, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.774, 10.331], loss: 0.001467, mae: 0.041250, mean_q: 1.169523
 684166/1000000: episode: 6842, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.742, mean reward: 0.587 [0.508, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.142, 10.159], loss: 0.001493, mae: 0.041461, mean_q: 1.166739
 684266/1000000: episode: 6843, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.058, mean reward: 0.581 [0.503, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.348, 10.098], loss: 0.001488, mae: 0.041819, mean_q: 1.171235
 684366/1000000: episode: 6844, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.832, mean reward: 0.578 [0.500, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.395, 10.098], loss: 0.001446, mae: 0.041227, mean_q: 1.165355
 684466/1000000: episode: 6845, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.378, mean reward: 0.594 [0.502, 0.868], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.985, 10.098], loss: 0.001432, mae: 0.040481, mean_q: 1.166797
 684566/1000000: episode: 6846, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.344, mean reward: 0.593 [0.501, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.756, 10.098], loss: 0.001485, mae: 0.041612, mean_q: 1.166481
 684666/1000000: episode: 6847, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.824, mean reward: 0.598 [0.506, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.610, 10.098], loss: 0.001549, mae: 0.042025, mean_q: 1.166219
 684766/1000000: episode: 6848, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.407, mean reward: 0.584 [0.502, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.188, 10.098], loss: 0.001464, mae: 0.041011, mean_q: 1.164847
 684866/1000000: episode: 6849, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.096, mean reward: 0.611 [0.536, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.228, 10.098], loss: 0.001429, mae: 0.040838, mean_q: 1.165980
 684966/1000000: episode: 6850, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 56.709, mean reward: 0.567 [0.505, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-2.273, 10.099], loss: 0.001509, mae: 0.041568, mean_q: 1.168675
 685066/1000000: episode: 6851, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.746, mean reward: 0.597 [0.504, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.575, 10.163], loss: 0.001487, mae: 0.041286, mean_q: 1.168963
 685166/1000000: episode: 6852, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.374, mean reward: 0.594 [0.502, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.638, 10.098], loss: 0.001516, mae: 0.042070, mean_q: 1.169978
 685266/1000000: episode: 6853, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.817, mean reward: 0.608 [0.499, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.642, 10.437], loss: 0.001574, mae: 0.041855, mean_q: 1.168889
 685366/1000000: episode: 6854, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.622, mean reward: 0.606 [0.508, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.936, 10.234], loss: 0.001488, mae: 0.042031, mean_q: 1.171432
 685466/1000000: episode: 6855, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 56.956, mean reward: 0.570 [0.503, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.274, 10.265], loss: 0.001477, mae: 0.041457, mean_q: 1.172066
 685566/1000000: episode: 6856, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.831, mean reward: 0.598 [0.500, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.658, 10.098], loss: 0.001437, mae: 0.041154, mean_q: 1.167780
 685666/1000000: episode: 6857, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.222, mean reward: 0.582 [0.507, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.510, 10.216], loss: 0.001397, mae: 0.040402, mean_q: 1.171952
 685766/1000000: episode: 6858, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.092, mean reward: 0.581 [0.503, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.402, 10.098], loss: 0.001527, mae: 0.041933, mean_q: 1.174726
 685866/1000000: episode: 6859, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.592, mean reward: 0.606 [0.509, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.724, 10.098], loss: 0.001514, mae: 0.041792, mean_q: 1.167327
 685966/1000000: episode: 6860, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.911, mean reward: 0.589 [0.497, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.537, 10.098], loss: 0.001594, mae: 0.043334, mean_q: 1.171322
 686066/1000000: episode: 6861, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.643, mean reward: 0.586 [0.510, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.473, 10.284], loss: 0.001442, mae: 0.041242, mean_q: 1.169960
 686166/1000000: episode: 6862, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.918, mean reward: 0.579 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.614, 10.194], loss: 0.001464, mae: 0.041351, mean_q: 1.174208
 686266/1000000: episode: 6863, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 57.766, mean reward: 0.578 [0.502, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.636, 10.098], loss: 0.001500, mae: 0.041922, mean_q: 1.169455
 686366/1000000: episode: 6864, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.394, mean reward: 0.594 [0.500, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.066, 10.098], loss: 0.001611, mae: 0.043044, mean_q: 1.173314
 686466/1000000: episode: 6865, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.550, mean reward: 0.565 [0.499, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.499, 10.098], loss: 0.001488, mae: 0.041877, mean_q: 1.168975
 686566/1000000: episode: 6866, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.759, mean reward: 0.608 [0.510, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.450, 10.226], loss: 0.001582, mae: 0.042439, mean_q: 1.170619
 686666/1000000: episode: 6867, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 64.914, mean reward: 0.649 [0.505, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.445, 10.098], loss: 0.001546, mae: 0.042316, mean_q: 1.171984
 686766/1000000: episode: 6868, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.018, mean reward: 0.590 [0.508, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.623, 10.189], loss: 0.001577, mae: 0.042606, mean_q: 1.172697
 686866/1000000: episode: 6869, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 61.397, mean reward: 0.614 [0.508, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.496, 10.098], loss: 0.001561, mae: 0.043016, mean_q: 1.166768
 686966/1000000: episode: 6870, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.770, mean reward: 0.578 [0.501, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.575, 10.213], loss: 0.001487, mae: 0.041195, mean_q: 1.172220
 687066/1000000: episode: 6871, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.371, mean reward: 0.584 [0.513, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.915, 10.098], loss: 0.001506, mae: 0.041433, mean_q: 1.172269
 687166/1000000: episode: 6872, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.244, mean reward: 0.592 [0.501, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.943, 10.098], loss: 0.001563, mae: 0.042720, mean_q: 1.176049
 687266/1000000: episode: 6873, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.325, mean reward: 0.583 [0.501, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.763, 10.098], loss: 0.001436, mae: 0.040383, mean_q: 1.170862
 687366/1000000: episode: 6874, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.505, mean reward: 0.585 [0.505, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.184, 10.293], loss: 0.001376, mae: 0.040598, mean_q: 1.172925
 687466/1000000: episode: 6875, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.049, mean reward: 0.580 [0.506, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.244, 10.106], loss: 0.001478, mae: 0.041325, mean_q: 1.169598
 687566/1000000: episode: 6876, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 61.349, mean reward: 0.613 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.835, 10.345], loss: 0.001541, mae: 0.041728, mean_q: 1.173791
 687666/1000000: episode: 6877, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.940, mean reward: 0.569 [0.502, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.382, 10.098], loss: 0.001487, mae: 0.041005, mean_q: 1.174054
 687766/1000000: episode: 6878, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.319, mean reward: 0.583 [0.508, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.049, 10.263], loss: 0.001372, mae: 0.039881, mean_q: 1.172097
 687866/1000000: episode: 6879, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.866, mean reward: 0.579 [0.498, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.415, 10.098], loss: 0.001501, mae: 0.041197, mean_q: 1.172629
 687966/1000000: episode: 6880, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.199, mean reward: 0.602 [0.505, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.205, 10.098], loss: 0.001526, mae: 0.041989, mean_q: 1.171847
 688066/1000000: episode: 6881, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.011, mean reward: 0.580 [0.500, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.698, 10.210], loss: 0.001538, mae: 0.042500, mean_q: 1.172077
 688166/1000000: episode: 6882, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.648, mean reward: 0.576 [0.502, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.996, 10.098], loss: 0.001512, mae: 0.041633, mean_q: 1.167998
 688266/1000000: episode: 6883, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 56.803, mean reward: 0.568 [0.499, 0.667], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.014, 10.143], loss: 0.001577, mae: 0.042617, mean_q: 1.169463
 688366/1000000: episode: 6884, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.776, mean reward: 0.578 [0.509, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.862, 10.364], loss: 0.001425, mae: 0.040542, mean_q: 1.166416
 688466/1000000: episode: 6885, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.312, mean reward: 0.583 [0.506, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.235, 10.098], loss: 0.001406, mae: 0.040816, mean_q: 1.170419
 688566/1000000: episode: 6886, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.246, mean reward: 0.572 [0.503, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.598, 10.199], loss: 0.001532, mae: 0.041834, mean_q: 1.166907
 688666/1000000: episode: 6887, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.679, mean reward: 0.577 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.678, 10.098], loss: 0.001490, mae: 0.041605, mean_q: 1.166096
 688766/1000000: episode: 6888, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.859, mean reward: 0.579 [0.506, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.536, 10.098], loss: 0.001431, mae: 0.040633, mean_q: 1.167883
 688866/1000000: episode: 6889, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.945, mean reward: 0.599 [0.525, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.458, 10.098], loss: 0.001350, mae: 0.039621, mean_q: 1.163851
 688966/1000000: episode: 6890, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.427, mean reward: 0.604 [0.513, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.275, 10.098], loss: 0.001424, mae: 0.040370, mean_q: 1.160449
 689066/1000000: episode: 6891, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.671, mean reward: 0.577 [0.500, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.060, 10.202], loss: 0.001495, mae: 0.042330, mean_q: 1.164830
 689166/1000000: episode: 6892, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.162, mean reward: 0.602 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.727, 10.264], loss: 0.001412, mae: 0.041032, mean_q: 1.163264
 689266/1000000: episode: 6893, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.391, mean reward: 0.574 [0.506, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.387, 10.098], loss: 0.001449, mae: 0.041425, mean_q: 1.167547
 689366/1000000: episode: 6894, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.539, mean reward: 0.595 [0.513, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.054, 10.098], loss: 0.001346, mae: 0.039825, mean_q: 1.161130
 689466/1000000: episode: 6895, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.918, mean reward: 0.579 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.779, 10.170], loss: 0.001507, mae: 0.041987, mean_q: 1.163071
 689566/1000000: episode: 6896, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.667, mean reward: 0.607 [0.507, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.582, 10.098], loss: 0.001435, mae: 0.041051, mean_q: 1.164276
 689666/1000000: episode: 6897, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 60.138, mean reward: 0.601 [0.499, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.678, 10.098], loss: 0.001423, mae: 0.040824, mean_q: 1.163625
 689766/1000000: episode: 6898, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.342, mean reward: 0.583 [0.499, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.685, 10.216], loss: 0.001482, mae: 0.041705, mean_q: 1.164313
 689866/1000000: episode: 6899, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.505, mean reward: 0.575 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.848, 10.254], loss: 0.001561, mae: 0.043187, mean_q: 1.163491
 689966/1000000: episode: 6900, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.522, mean reward: 0.575 [0.498, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.499, 10.098], loss: 0.001534, mae: 0.042489, mean_q: 1.164306
 690066/1000000: episode: 6901, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 57.461, mean reward: 0.575 [0.505, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.980, 10.098], loss: 0.001462, mae: 0.041686, mean_q: 1.161821
 690166/1000000: episode: 6902, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.940, mean reward: 0.579 [0.504, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.941, 10.214], loss: 0.001396, mae: 0.040769, mean_q: 1.160575
 690266/1000000: episode: 6903, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.104, mean reward: 0.581 [0.514, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.602, 10.098], loss: 0.001502, mae: 0.041653, mean_q: 1.161537
 690366/1000000: episode: 6904, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.984, mean reward: 0.590 [0.507, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.876, 10.131], loss: 0.001538, mae: 0.042341, mean_q: 1.161522
 690466/1000000: episode: 6905, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.746, mean reward: 0.587 [0.501, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.151, 10.098], loss: 0.001521, mae: 0.042993, mean_q: 1.162685
 690566/1000000: episode: 6906, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 57.765, mean reward: 0.578 [0.506, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.267, 10.220], loss: 0.001500, mae: 0.041964, mean_q: 1.162070
 690666/1000000: episode: 6907, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.346, mean reward: 0.583 [0.516, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.351, 10.098], loss: 0.001540, mae: 0.042245, mean_q: 1.159749
 690766/1000000: episode: 6908, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 65.221, mean reward: 0.652 [0.513, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-1.274, 10.352], loss: 0.001448, mae: 0.041145, mean_q: 1.159103
 690866/1000000: episode: 6909, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.760, mean reward: 0.578 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.935, 10.098], loss: 0.001518, mae: 0.042598, mean_q: 1.163816
 690966/1000000: episode: 6910, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.585, mean reward: 0.596 [0.502, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.314, 10.262], loss: 0.001657, mae: 0.044207, mean_q: 1.166552
 691066/1000000: episode: 6911, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.206, mean reward: 0.582 [0.502, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.247, 10.098], loss: 0.001549, mae: 0.042948, mean_q: 1.165149
 691166/1000000: episode: 6912, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.081, mean reward: 0.601 [0.511, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.432, 10.229], loss: 0.001586, mae: 0.043089, mean_q: 1.161233
 691266/1000000: episode: 6913, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.882, mean reward: 0.589 [0.499, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.113, 10.143], loss: 0.001553, mae: 0.042715, mean_q: 1.162328
 691366/1000000: episode: 6914, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.025, mean reward: 0.570 [0.500, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.407, 10.182], loss: 0.001483, mae: 0.041227, mean_q: 1.162473
 691466/1000000: episode: 6915, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.942, mean reward: 0.589 [0.506, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.829, 10.098], loss: 0.001566, mae: 0.042971, mean_q: 1.161753
 691566/1000000: episode: 6916, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 59.993, mean reward: 0.600 [0.524, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.385, 10.098], loss: 0.001560, mae: 0.042478, mean_q: 1.159507
 691666/1000000: episode: 6917, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.107, mean reward: 0.601 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.263, 10.098], loss: 0.001539, mae: 0.042547, mean_q: 1.161210
 691766/1000000: episode: 6918, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.305, mean reward: 0.593 [0.506, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.074, 10.172], loss: 0.001627, mae: 0.043435, mean_q: 1.163247
 691866/1000000: episode: 6919, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.280, mean reward: 0.593 [0.506, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.592, 10.196], loss: 0.001610, mae: 0.043204, mean_q: 1.160811
 691966/1000000: episode: 6920, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.913, mean reward: 0.589 [0.498, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.386, 10.098], loss: 0.001634, mae: 0.044262, mean_q: 1.166449
 692066/1000000: episode: 6921, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 60.336, mean reward: 0.603 [0.514, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.398, 10.098], loss: 0.001606, mae: 0.043680, mean_q: 1.162185
 692166/1000000: episode: 6922, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.972, mean reward: 0.590 [0.503, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.109, 10.113], loss: 0.001581, mae: 0.043567, mean_q: 1.165094
 692266/1000000: episode: 6923, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.153, mean reward: 0.582 [0.508, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.920, 10.098], loss: 0.001498, mae: 0.041511, mean_q: 1.160897
 692366/1000000: episode: 6924, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.259, mean reward: 0.583 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.265, 10.098], loss: 0.001547, mae: 0.042652, mean_q: 1.164261
 692466/1000000: episode: 6925, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.257, mean reward: 0.573 [0.498, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.623, 10.277], loss: 0.001555, mae: 0.042781, mean_q: 1.163819
 692566/1000000: episode: 6926, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 62.132, mean reward: 0.621 [0.504, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.850, 10.098], loss: 0.001475, mae: 0.041651, mean_q: 1.160900
 692666/1000000: episode: 6927, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.779, mean reward: 0.588 [0.511, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.710, 10.098], loss: 0.001615, mae: 0.043437, mean_q: 1.163177
 692766/1000000: episode: 6928, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.855, mean reward: 0.579 [0.500, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.277, 10.407], loss: 0.001587, mae: 0.042543, mean_q: 1.162415
 692866/1000000: episode: 6929, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 59.437, mean reward: 0.594 [0.504, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.643, 10.098], loss: 0.001498, mae: 0.041887, mean_q: 1.160487
 692966/1000000: episode: 6930, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.460, mean reward: 0.585 [0.508, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.114, 10.098], loss: 0.001619, mae: 0.043405, mean_q: 1.167769
 693066/1000000: episode: 6931, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 57.441, mean reward: 0.574 [0.506, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.819, 10.286], loss: 0.001565, mae: 0.043550, mean_q: 1.165514
 693166/1000000: episode: 6932, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.818, mean reward: 0.598 [0.504, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.965, 10.098], loss: 0.001575, mae: 0.043814, mean_q: 1.166842
 693266/1000000: episode: 6933, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.797, mean reward: 0.598 [0.509, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.822, 10.098], loss: 0.001581, mae: 0.043025, mean_q: 1.165126
 693366/1000000: episode: 6934, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.697, mean reward: 0.597 [0.499, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.785, 10.403], loss: 0.001623, mae: 0.043885, mean_q: 1.163888
 693466/1000000: episode: 6935, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 57.612, mean reward: 0.576 [0.506, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.408, 10.192], loss: 0.001605, mae: 0.043201, mean_q: 1.163263
 693566/1000000: episode: 6936, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.387, mean reward: 0.594 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.897, 10.098], loss: 0.001512, mae: 0.042208, mean_q: 1.165115
 693666/1000000: episode: 6937, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.496, mean reward: 0.585 [0.503, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.276, 10.098], loss: 0.001613, mae: 0.043660, mean_q: 1.165687
 693766/1000000: episode: 6938, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.304, mean reward: 0.573 [0.503, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.775, 10.098], loss: 0.001581, mae: 0.043710, mean_q: 1.165818
 693866/1000000: episode: 6939, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.526, mean reward: 0.585 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.559, 10.098], loss: 0.001627, mae: 0.043619, mean_q: 1.167157
 693966/1000000: episode: 6940, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.737, mean reward: 0.597 [0.504, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.816, 10.357], loss: 0.001454, mae: 0.041311, mean_q: 1.164808
 694066/1000000: episode: 6941, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.358, mean reward: 0.574 [0.503, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.454, 10.235], loss: 0.001501, mae: 0.041629, mean_q: 1.164778
 694166/1000000: episode: 6942, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 61.958, mean reward: 0.620 [0.516, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.465, 10.098], loss: 0.001546, mae: 0.042634, mean_q: 1.166534
 694266/1000000: episode: 6943, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.174, mean reward: 0.572 [0.502, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.497, 10.122], loss: 0.001579, mae: 0.043425, mean_q: 1.168548
 694366/1000000: episode: 6944, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.486, mean reward: 0.585 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.564, 10.425], loss: 0.001515, mae: 0.042316, mean_q: 1.166194
 694466/1000000: episode: 6945, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.808, mean reward: 0.588 [0.511, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.262, 10.098], loss: 0.001607, mae: 0.043186, mean_q: 1.167954
 694566/1000000: episode: 6946, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 62.674, mean reward: 0.627 [0.503, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.799, 10.351], loss: 0.001543, mae: 0.042625, mean_q: 1.166337
 694666/1000000: episode: 6947, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 57.635, mean reward: 0.576 [0.497, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.543, 10.098], loss: 0.001399, mae: 0.040326, mean_q: 1.166034
 694766/1000000: episode: 6948, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.645, mean reward: 0.586 [0.511, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.401, 10.109], loss: 0.001449, mae: 0.041223, mean_q: 1.165238
 694866/1000000: episode: 6949, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.798, mean reward: 0.578 [0.497, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.791, 10.143], loss: 0.001546, mae: 0.042563, mean_q: 1.167025
 694966/1000000: episode: 6950, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 60.144, mean reward: 0.601 [0.510, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.492, 10.098], loss: 0.001426, mae: 0.040962, mean_q: 1.163339
 695066/1000000: episode: 6951, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.396, mean reward: 0.574 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.727, 10.262], loss: 0.001659, mae: 0.043672, mean_q: 1.168281
 695166/1000000: episode: 6952, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.125, mean reward: 0.581 [0.501, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.042, 10.141], loss: 0.001529, mae: 0.042764, mean_q: 1.168994
 695266/1000000: episode: 6953, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 56.436, mean reward: 0.564 [0.507, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.510, 10.206], loss: 0.001439, mae: 0.040981, mean_q: 1.167535
 695366/1000000: episode: 6954, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 62.180, mean reward: 0.622 [0.507, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.699, 10.098], loss: 0.001627, mae: 0.043194, mean_q: 1.169086
 695466/1000000: episode: 6955, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 58.664, mean reward: 0.587 [0.506, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.344, 10.200], loss: 0.001453, mae: 0.041592, mean_q: 1.167207
 695566/1000000: episode: 6956, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 58.623, mean reward: 0.586 [0.507, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.172, 10.098], loss: 0.001628, mae: 0.043665, mean_q: 1.167036
 695666/1000000: episode: 6957, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.919, mean reward: 0.579 [0.502, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.612, 10.098], loss: 0.001328, mae: 0.039589, mean_q: 1.167560
 695766/1000000: episode: 6958, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.484, mean reward: 0.565 [0.499, 0.664], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.276, 10.098], loss: 0.001410, mae: 0.040407, mean_q: 1.162902
 695866/1000000: episode: 6959, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.327, mean reward: 0.613 [0.510, 0.957], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.294, 10.421], loss: 0.001412, mae: 0.040422, mean_q: 1.161689
 695966/1000000: episode: 6960, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.605, mean reward: 0.586 [0.509, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.476, 10.098], loss: 0.001474, mae: 0.041640, mean_q: 1.160761
 696066/1000000: episode: 6961, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.714, mean reward: 0.567 [0.504, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.283, 10.098], loss: 0.001426, mae: 0.041160, mean_q: 1.164884
 696166/1000000: episode: 6962, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.695, mean reward: 0.597 [0.516, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.482, 10.189], loss: 0.001399, mae: 0.040599, mean_q: 1.165946
 696266/1000000: episode: 6963, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.967, mean reward: 0.580 [0.499, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.866, 10.098], loss: 0.001497, mae: 0.041932, mean_q: 1.165196
 696366/1000000: episode: 6964, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.348, mean reward: 0.603 [0.499, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.194, 10.213], loss: 0.001442, mae: 0.040754, mean_q: 1.161723
 696466/1000000: episode: 6965, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.231, mean reward: 0.582 [0.501, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.261, 10.233], loss: 0.001425, mae: 0.040885, mean_q: 1.164881
 696566/1000000: episode: 6966, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.518, mean reward: 0.575 [0.504, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.787, 10.098], loss: 0.001400, mae: 0.040408, mean_q: 1.159011
 696666/1000000: episode: 6967, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.183, mean reward: 0.582 [0.509, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.670, 10.156], loss: 0.001539, mae: 0.042029, mean_q: 1.164732
 696766/1000000: episode: 6968, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.217, mean reward: 0.572 [0.499, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.212, 10.225], loss: 0.001475, mae: 0.041352, mean_q: 1.162958
 696866/1000000: episode: 6969, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 62.761, mean reward: 0.628 [0.511, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.191, 10.259], loss: 0.001439, mae: 0.040967, mean_q: 1.166801
 696966/1000000: episode: 6970, duration: 0.521s, episode steps: 100, steps per second: 192, episode reward: 57.673, mean reward: 0.577 [0.503, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.145, 10.098], loss: 0.001434, mae: 0.041156, mean_q: 1.162005
 697066/1000000: episode: 6971, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.544, mean reward: 0.575 [0.502, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.097, 10.115], loss: 0.001458, mae: 0.041680, mean_q: 1.165671
 697166/1000000: episode: 6972, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.076, mean reward: 0.581 [0.508, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.808, 10.098], loss: 0.001471, mae: 0.041007, mean_q: 1.162460
 697266/1000000: episode: 6973, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.791, mean reward: 0.598 [0.510, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.822, 10.098], loss: 0.001465, mae: 0.041206, mean_q: 1.163051
 697366/1000000: episode: 6974, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.441, mean reward: 0.574 [0.505, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.745, 10.098], loss: 0.001518, mae: 0.041766, mean_q: 1.163783
 697466/1000000: episode: 6975, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.126, mean reward: 0.581 [0.500, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-2.287, 10.281], loss: 0.001499, mae: 0.041502, mean_q: 1.163847
 697566/1000000: episode: 6976, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.076, mean reward: 0.581 [0.507, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.760, 10.164], loss: 0.001418, mae: 0.040173, mean_q: 1.158355
 697666/1000000: episode: 6977, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.964, mean reward: 0.580 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.048, 10.098], loss: 0.001522, mae: 0.041739, mean_q: 1.163333
 697766/1000000: episode: 6978, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.910, mean reward: 0.579 [0.499, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.110, 10.121], loss: 0.001396, mae: 0.040564, mean_q: 1.161706
 697866/1000000: episode: 6979, duration: 0.631s, episode steps: 100, steps per second: 158, episode reward: 59.065, mean reward: 0.591 [0.505, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.660, 10.125], loss: 0.001395, mae: 0.040634, mean_q: 1.162364
 697966/1000000: episode: 6980, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.583, mean reward: 0.586 [0.503, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.402, 10.166], loss: 0.001446, mae: 0.040557, mean_q: 1.158020
 698066/1000000: episode: 6981, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.756, mean reward: 0.578 [0.502, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.488, 10.098], loss: 0.001459, mae: 0.041176, mean_q: 1.159511
 698166/1000000: episode: 6982, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.602, mean reward: 0.576 [0.502, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.468, 10.171], loss: 0.001601, mae: 0.043030, mean_q: 1.158380
 698266/1000000: episode: 6983, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 60.001, mean reward: 0.600 [0.504, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.481, 10.463], loss: 0.001483, mae: 0.041285, mean_q: 1.157833
 698366/1000000: episode: 6984, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.073, mean reward: 0.591 [0.503, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.854, 10.098], loss: 0.001535, mae: 0.041475, mean_q: 1.161840
 698466/1000000: episode: 6985, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.444, mean reward: 0.584 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.946, 10.209], loss: 0.001513, mae: 0.041881, mean_q: 1.157541
 698566/1000000: episode: 6986, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.544, mean reward: 0.565 [0.506, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.243, 10.190], loss: 0.001488, mae: 0.041628, mean_q: 1.160183
 698666/1000000: episode: 6987, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.609, mean reward: 0.576 [0.503, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.576, 10.098], loss: 0.001537, mae: 0.041951, mean_q: 1.158066
 698766/1000000: episode: 6988, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 56.168, mean reward: 0.562 [0.504, 0.633], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.653, 10.185], loss: 0.001569, mae: 0.042279, mean_q: 1.162725
 698866/1000000: episode: 6989, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.971, mean reward: 0.590 [0.510, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.643, 10.115], loss: 0.001472, mae: 0.041274, mean_q: 1.156468
 698966/1000000: episode: 6990, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 61.243, mean reward: 0.612 [0.514, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.809, 10.098], loss: 0.001546, mae: 0.042027, mean_q: 1.158632
 699066/1000000: episode: 6991, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.901, mean reward: 0.579 [0.502, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.868, 10.098], loss: 0.001467, mae: 0.041173, mean_q: 1.160130
 699166/1000000: episode: 6992, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 61.804, mean reward: 0.618 [0.516, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.967, 10.326], loss: 0.001587, mae: 0.042244, mean_q: 1.162097
 699266/1000000: episode: 6993, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 56.749, mean reward: 0.567 [0.502, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.673, 10.098], loss: 0.001475, mae: 0.041411, mean_q: 1.161440
 699366/1000000: episode: 6994, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.730, mean reward: 0.597 [0.505, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.256, 10.185], loss: 0.001597, mae: 0.042609, mean_q: 1.165380
 699466/1000000: episode: 6995, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.516, mean reward: 0.605 [0.504, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.965, 10.103], loss: 0.001567, mae: 0.042485, mean_q: 1.159416
 699566/1000000: episode: 6996, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.459, mean reward: 0.575 [0.505, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.558, 10.158], loss: 0.001507, mae: 0.041800, mean_q: 1.160488
 699666/1000000: episode: 6997, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 58.228, mean reward: 0.582 [0.511, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.570, 10.168], loss: 0.001415, mae: 0.040385, mean_q: 1.155848
 699766/1000000: episode: 6998, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.057, mean reward: 0.591 [0.503, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.251, 10.098], loss: 0.001461, mae: 0.041072, mean_q: 1.159536
 699866/1000000: episode: 6999, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.013, mean reward: 0.580 [0.501, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.726, 10.128], loss: 0.001563, mae: 0.041929, mean_q: 1.160287
 699966/1000000: episode: 7000, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 60.301, mean reward: 0.603 [0.524, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.177, 10.289], loss: 0.001476, mae: 0.041423, mean_q: 1.158808
 700066/1000000: episode: 7001, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.684, mean reward: 0.597 [0.509, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-1.745, 10.248], loss: 0.001508, mae: 0.041784, mean_q: 1.161637
 700166/1000000: episode: 7002, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.315, mean reward: 0.593 [0.506, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.009, 10.098], loss: 0.001392, mae: 0.039983, mean_q: 1.157661
 700266/1000000: episode: 7003, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.714, mean reward: 0.587 [0.499, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.111, 10.206], loss: 0.001508, mae: 0.041583, mean_q: 1.158325
 700366/1000000: episode: 7004, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.175, mean reward: 0.582 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.126, 10.098], loss: 0.001574, mae: 0.042976, mean_q: 1.160059
 700466/1000000: episode: 7005, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.193, mean reward: 0.612 [0.505, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.673, 10.180], loss: 0.001542, mae: 0.042783, mean_q: 1.161605
 700566/1000000: episode: 7006, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.159, mean reward: 0.602 [0.514, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.644, 10.206], loss: 0.001596, mae: 0.042937, mean_q: 1.158871
 700666/1000000: episode: 7007, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.904, mean reward: 0.589 [0.505, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.857, 10.100], loss: 0.001501, mae: 0.041901, mean_q: 1.161143
 700766/1000000: episode: 7008, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.966, mean reward: 0.600 [0.507, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.604, 10.369], loss: 0.001607, mae: 0.042697, mean_q: 1.160942
 700866/1000000: episode: 7009, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.266, mean reward: 0.593 [0.501, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.592, 10.130], loss: 0.001489, mae: 0.041968, mean_q: 1.162068
 700966/1000000: episode: 7010, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.112, mean reward: 0.581 [0.499, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.660, 10.098], loss: 0.001544, mae: 0.042389, mean_q: 1.162749
 701066/1000000: episode: 7011, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.566, mean reward: 0.596 [0.506, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.842, 10.210], loss: 0.001448, mae: 0.041472, mean_q: 1.161108
 701166/1000000: episode: 7012, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 59.405, mean reward: 0.594 [0.506, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.884, 10.098], loss: 0.001494, mae: 0.041655, mean_q: 1.163593
 701266/1000000: episode: 7013, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.303, mean reward: 0.583 [0.503, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.897, 10.211], loss: 0.001589, mae: 0.043370, mean_q: 1.165848
 701366/1000000: episode: 7014, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 62.474, mean reward: 0.625 [0.507, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.921, 10.313], loss: 0.001635, mae: 0.044148, mean_q: 1.166275
 701466/1000000: episode: 7015, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.305, mean reward: 0.573 [0.507, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.961, 10.220], loss: 0.001509, mae: 0.042053, mean_q: 1.168211
 701566/1000000: episode: 7016, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 59.093, mean reward: 0.591 [0.499, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.107, 10.098], loss: 0.001617, mae: 0.043573, mean_q: 1.168660
 701666/1000000: episode: 7017, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 60.905, mean reward: 0.609 [0.507, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.388, 10.098], loss: 0.001522, mae: 0.042796, mean_q: 1.164615
 701766/1000000: episode: 7018, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.486, mean reward: 0.595 [0.516, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.591, 10.098], loss: 0.001569, mae: 0.043358, mean_q: 1.166890
 701866/1000000: episode: 7019, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.994, mean reward: 0.600 [0.506, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.929, 10.098], loss: 0.001490, mae: 0.042156, mean_q: 1.163560
 701966/1000000: episode: 7020, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.605, mean reward: 0.596 [0.508, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.909, 10.122], loss: 0.001515, mae: 0.041950, mean_q: 1.163290
 702066/1000000: episode: 7021, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.937, mean reward: 0.579 [0.506, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.043, 10.098], loss: 0.001517, mae: 0.042318, mean_q: 1.164848
 702166/1000000: episode: 7022, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 60.612, mean reward: 0.606 [0.507, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.379, 10.257], loss: 0.001532, mae: 0.042486, mean_q: 1.164270
 702266/1000000: episode: 7023, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.348, mean reward: 0.593 [0.503, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.444, 10.100], loss: 0.001556, mae: 0.042555, mean_q: 1.167000
 702366/1000000: episode: 7024, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.416, mean reward: 0.584 [0.502, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.787, 10.098], loss: 0.001439, mae: 0.041279, mean_q: 1.164062
 702466/1000000: episode: 7025, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.418, mean reward: 0.574 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.432, 10.098], loss: 0.001531, mae: 0.042512, mean_q: 1.167869
 702566/1000000: episode: 7026, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.603, mean reward: 0.586 [0.501, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.627, 10.098], loss: 0.001506, mae: 0.042152, mean_q: 1.167321
 702666/1000000: episode: 7027, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.182, mean reward: 0.592 [0.502, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.757, 10.323], loss: 0.001432, mae: 0.041343, mean_q: 1.169230
 702766/1000000: episode: 7028, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.842, mean reward: 0.588 [0.503, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.598, 10.098], loss: 0.001542, mae: 0.042390, mean_q: 1.166420
 702866/1000000: episode: 7029, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 62.048, mean reward: 0.620 [0.513, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.534, 10.165], loss: 0.001446, mae: 0.041230, mean_q: 1.168805
 702966/1000000: episode: 7030, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.884, mean reward: 0.569 [0.502, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.998, 10.098], loss: 0.001518, mae: 0.042445, mean_q: 1.170885
 703066/1000000: episode: 7031, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.299, mean reward: 0.573 [0.501, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.407, 10.098], loss: 0.001531, mae: 0.042625, mean_q: 1.169591
 703166/1000000: episode: 7032, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.991, mean reward: 0.590 [0.507, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.536, 10.098], loss: 0.001586, mae: 0.043367, mean_q: 1.171854
 703266/1000000: episode: 7033, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.629, mean reward: 0.576 [0.504, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.913, 10.193], loss: 0.001584, mae: 0.043343, mean_q: 1.168361
 703366/1000000: episode: 7034, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.039, mean reward: 0.600 [0.510, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.839, 10.098], loss: 0.001549, mae: 0.042670, mean_q: 1.168003
 703466/1000000: episode: 7035, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.720, mean reward: 0.607 [0.505, 0.862], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.707, 10.537], loss: 0.001550, mae: 0.042510, mean_q: 1.167605
 703566/1000000: episode: 7036, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.134, mean reward: 0.571 [0.509, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.573, 10.098], loss: 0.001549, mae: 0.042847, mean_q: 1.168304
 703666/1000000: episode: 7037, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.088, mean reward: 0.581 [0.504, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.590, 10.098], loss: 0.001542, mae: 0.041738, mean_q: 1.170479
 703766/1000000: episode: 7038, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.604, mean reward: 0.586 [0.505, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.760, 10.371], loss: 0.001514, mae: 0.042057, mean_q: 1.169719
 703866/1000000: episode: 7039, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.310, mean reward: 0.593 [0.525, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.279, 10.266], loss: 0.001502, mae: 0.042312, mean_q: 1.170430
 703966/1000000: episode: 7040, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 60.326, mean reward: 0.603 [0.522, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.691, 10.140], loss: 0.001484, mae: 0.042093, mean_q: 1.169119
 704066/1000000: episode: 7041, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.889, mean reward: 0.619 [0.512, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.363, 10.386], loss: 0.001590, mae: 0.043782, mean_q: 1.173104
 704166/1000000: episode: 7042, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.270, mean reward: 0.593 [0.510, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.365, 10.169], loss: 0.001531, mae: 0.042374, mean_q: 1.174539
 704266/1000000: episode: 7043, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.550, mean reward: 0.605 [0.500, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.868, 10.311], loss: 0.001524, mae: 0.041836, mean_q: 1.171725
 704366/1000000: episode: 7044, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.918, mean reward: 0.579 [0.497, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.944, 10.098], loss: 0.001477, mae: 0.041733, mean_q: 1.173371
 704466/1000000: episode: 7045, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 61.165, mean reward: 0.612 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.362, 10.207], loss: 0.001538, mae: 0.042185, mean_q: 1.173279
 704566/1000000: episode: 7046, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 58.601, mean reward: 0.586 [0.507, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.710, 10.133], loss: 0.001598, mae: 0.043012, mean_q: 1.172397
 704666/1000000: episode: 7047, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.991, mean reward: 0.600 [0.521, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.688, 10.098], loss: 0.001437, mae: 0.041394, mean_q: 1.172590
 704766/1000000: episode: 7048, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 56.207, mean reward: 0.562 [0.502, 0.644], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.653, 10.098], loss: 0.001485, mae: 0.041534, mean_q: 1.171262
 704866/1000000: episode: 7049, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.308, mean reward: 0.573 [0.508, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.507, 10.098], loss: 0.001495, mae: 0.041814, mean_q: 1.171918
 704966/1000000: episode: 7050, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.370, mean reward: 0.594 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.933, 10.098], loss: 0.001523, mae: 0.042517, mean_q: 1.172727
 705066/1000000: episode: 7051, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.860, mean reward: 0.589 [0.504, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.776, 10.347], loss: 0.001425, mae: 0.041108, mean_q: 1.173359
 705166/1000000: episode: 7052, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.828, mean reward: 0.588 [0.499, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.905, 10.098], loss: 0.001430, mae: 0.040919, mean_q: 1.174133
 705266/1000000: episode: 7053, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.985, mean reward: 0.620 [0.498, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.957, 10.363], loss: 0.001517, mae: 0.042729, mean_q: 1.173975
 705366/1000000: episode: 7054, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.803, mean reward: 0.598 [0.501, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.856, 10.230], loss: 0.001519, mae: 0.042584, mean_q: 1.175900
 705466/1000000: episode: 7055, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.029, mean reward: 0.590 [0.508, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.626, 10.170], loss: 0.001399, mae: 0.040970, mean_q: 1.173301
 705566/1000000: episode: 7056, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.684, mean reward: 0.567 [0.503, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.047, 10.146], loss: 0.001426, mae: 0.041066, mean_q: 1.170825
 705666/1000000: episode: 7057, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.384, mean reward: 0.584 [0.507, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.079, 10.098], loss: 0.001462, mae: 0.041734, mean_q: 1.169168
 705766/1000000: episode: 7058, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 57.892, mean reward: 0.579 [0.500, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.824, 10.202], loss: 0.001484, mae: 0.041244, mean_q: 1.166320
 705866/1000000: episode: 7059, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.011, mean reward: 0.580 [0.508, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.784, 10.136], loss: 0.001424, mae: 0.040606, mean_q: 1.169508
 705966/1000000: episode: 7060, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.880, mean reward: 0.589 [0.505, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.195, 10.310], loss: 0.001483, mae: 0.041894, mean_q: 1.167879
 706066/1000000: episode: 7061, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.413, mean reward: 0.614 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.541, 10.305], loss: 0.001392, mae: 0.040398, mean_q: 1.168815
 706166/1000000: episode: 7062, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.145, mean reward: 0.581 [0.516, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.511, 10.143], loss: 0.001397, mae: 0.040726, mean_q: 1.172116
 706266/1000000: episode: 7063, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.696, mean reward: 0.597 [0.500, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.761, 10.281], loss: 0.001387, mae: 0.039839, mean_q: 1.173075
 706366/1000000: episode: 7064, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 61.891, mean reward: 0.619 [0.509, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.820, 10.098], loss: 0.001508, mae: 0.041997, mean_q: 1.166953
 706466/1000000: episode: 7065, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.023, mean reward: 0.580 [0.504, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.538, 10.321], loss: 0.001466, mae: 0.041553, mean_q: 1.169626
 706566/1000000: episode: 7066, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 61.981, mean reward: 0.620 [0.511, 0.911], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.109, 10.098], loss: 0.001461, mae: 0.041185, mean_q: 1.173222
 706666/1000000: episode: 7067, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.152, mean reward: 0.582 [0.502, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.634, 10.338], loss: 0.001435, mae: 0.041025, mean_q: 1.173044
 706766/1000000: episode: 7068, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.466, mean reward: 0.585 [0.499, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.065, 10.098], loss: 0.001480, mae: 0.041331, mean_q: 1.171353
 706866/1000000: episode: 7069, duration: 0.621s, episode steps: 100, steps per second: 161, episode reward: 61.087, mean reward: 0.611 [0.498, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.277, 10.349], loss: 0.001502, mae: 0.042077, mean_q: 1.170739
 706966/1000000: episode: 7070, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.619, mean reward: 0.576 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.340, 10.262], loss: 0.001472, mae: 0.041171, mean_q: 1.170624
 707066/1000000: episode: 7071, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.325, mean reward: 0.583 [0.501, 0.874], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.684, 10.098], loss: 0.001515, mae: 0.041606, mean_q: 1.174124
 707166/1000000: episode: 7072, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.289, mean reward: 0.593 [0.503, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.205, 10.195], loss: 0.001421, mae: 0.040735, mean_q: 1.168249
 707266/1000000: episode: 7073, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 60.057, mean reward: 0.601 [0.508, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.227, 10.265], loss: 0.001407, mae: 0.040054, mean_q: 1.165339
 707366/1000000: episode: 7074, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.280, mean reward: 0.583 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.757, 10.098], loss: 0.001454, mae: 0.041078, mean_q: 1.165578
 707466/1000000: episode: 7075, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 58.643, mean reward: 0.586 [0.505, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.522, 10.319], loss: 0.001483, mae: 0.042111, mean_q: 1.168633
 707566/1000000: episode: 7076, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 57.025, mean reward: 0.570 [0.501, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.782, 10.098], loss: 0.001480, mae: 0.041448, mean_q: 1.170505
 707666/1000000: episode: 7077, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.435, mean reward: 0.584 [0.502, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.631, 10.299], loss: 0.001597, mae: 0.042748, mean_q: 1.169501
 707766/1000000: episode: 7078, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.714, mean reward: 0.587 [0.506, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.628, 10.191], loss: 0.001377, mae: 0.040929, mean_q: 1.166363
 707866/1000000: episode: 7079, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.077, mean reward: 0.571 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.094, 10.098], loss: 0.001457, mae: 0.041115, mean_q: 1.166012
 707966/1000000: episode: 7080, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.142, mean reward: 0.581 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.260, 10.098], loss: 0.001467, mae: 0.041326, mean_q: 1.169509
 708066/1000000: episode: 7081, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 58.603, mean reward: 0.586 [0.510, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.922, 10.214], loss: 0.001448, mae: 0.041490, mean_q: 1.167817
 708166/1000000: episode: 7082, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.437, mean reward: 0.594 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.219, 10.186], loss: 0.001420, mae: 0.040942, mean_q: 1.165975
 708266/1000000: episode: 7083, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.890, mean reward: 0.609 [0.508, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.119, 10.098], loss: 0.001400, mae: 0.040401, mean_q: 1.167914
 708366/1000000: episode: 7084, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.006, mean reward: 0.580 [0.503, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.301, 10.098], loss: 0.001335, mae: 0.039598, mean_q: 1.169990
 708466/1000000: episode: 7085, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 57.614, mean reward: 0.576 [0.500, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.331, 10.098], loss: 0.001513, mae: 0.041281, mean_q: 1.167958
 708566/1000000: episode: 7086, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.754, mean reward: 0.578 [0.503, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.848, 10.284], loss: 0.001422, mae: 0.040450, mean_q: 1.170240
 708666/1000000: episode: 7087, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.148, mean reward: 0.581 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.470, 10.200], loss: 0.001388, mae: 0.040319, mean_q: 1.167139
 708766/1000000: episode: 7088, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 60.353, mean reward: 0.604 [0.501, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.077, 10.483], loss: 0.001361, mae: 0.040389, mean_q: 1.168365
 708866/1000000: episode: 7089, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 61.208, mean reward: 0.612 [0.498, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.042, 10.367], loss: 0.001374, mae: 0.040678, mean_q: 1.167994
 708966/1000000: episode: 7090, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 56.831, mean reward: 0.568 [0.500, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.512, 10.098], loss: 0.001435, mae: 0.040821, mean_q: 1.166442
 709066/1000000: episode: 7091, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.325, mean reward: 0.573 [0.504, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.516, 10.098], loss: 0.001398, mae: 0.040752, mean_q: 1.166250
 709166/1000000: episode: 7092, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.970, mean reward: 0.610 [0.502, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.658, 10.098], loss: 0.001445, mae: 0.041230, mean_q: 1.167301
 709266/1000000: episode: 7093, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.008, mean reward: 0.570 [0.505, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.747, 10.098], loss: 0.001465, mae: 0.042011, mean_q: 1.164411
 709366/1000000: episode: 7094, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 62.239, mean reward: 0.622 [0.508, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.084, 10.247], loss: 0.001401, mae: 0.040445, mean_q: 1.162878
 709466/1000000: episode: 7095, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.389, mean reward: 0.584 [0.511, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.951, 10.098], loss: 0.001291, mae: 0.039156, mean_q: 1.164353
 709566/1000000: episode: 7096, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.205, mean reward: 0.582 [0.507, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.215, 10.098], loss: 0.001383, mae: 0.040759, mean_q: 1.163758
 709666/1000000: episode: 7097, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.338, mean reward: 0.583 [0.509, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.241, 10.098], loss: 0.001378, mae: 0.040047, mean_q: 1.161722
 709766/1000000: episode: 7098, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.881, mean reward: 0.599 [0.521, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.468, 10.098], loss: 0.001409, mae: 0.041249, mean_q: 1.166231
 709866/1000000: episode: 7099, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.679, mean reward: 0.587 [0.502, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.756, 10.098], loss: 0.001387, mae: 0.040369, mean_q: 1.166090
 709966/1000000: episode: 7100, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.949, mean reward: 0.579 [0.499, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.734, 10.098], loss: 0.001401, mae: 0.041090, mean_q: 1.164905
 710066/1000000: episode: 7101, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.584, mean reward: 0.606 [0.507, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.480, 10.098], loss: 0.001443, mae: 0.041440, mean_q: 1.168479
 710166/1000000: episode: 7102, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.811, mean reward: 0.578 [0.509, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.998, 10.098], loss: 0.001444, mae: 0.040936, mean_q: 1.170672
 710266/1000000: episode: 7103, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.975, mean reward: 0.600 [0.505, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.619, 10.210], loss: 0.001408, mae: 0.040602, mean_q: 1.165146
 710366/1000000: episode: 7104, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.650, mean reward: 0.597 [0.501, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.063, 10.098], loss: 0.001375, mae: 0.040097, mean_q: 1.169814
 710466/1000000: episode: 7105, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.261, mean reward: 0.603 [0.506, 0.854], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.233, 10.098], loss: 0.001414, mae: 0.040541, mean_q: 1.167545
 710566/1000000: episode: 7106, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 62.891, mean reward: 0.629 [0.503, 0.879], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.532, 10.367], loss: 0.001387, mae: 0.040317, mean_q: 1.166369
 710666/1000000: episode: 7107, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.731, mean reward: 0.587 [0.505, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.737, 10.143], loss: 0.001542, mae: 0.042056, mean_q: 1.165917
 710766/1000000: episode: 7108, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.113, mean reward: 0.571 [0.500, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.496, 10.124], loss: 0.001431, mae: 0.040903, mean_q: 1.166866
 710866/1000000: episode: 7109, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.882, mean reward: 0.589 [0.498, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.217, 10.098], loss: 0.001506, mae: 0.042653, mean_q: 1.165934
 710966/1000000: episode: 7110, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.687, mean reward: 0.587 [0.499, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.966, 10.098], loss: 0.001420, mae: 0.040932, mean_q: 1.168482
 711066/1000000: episode: 7111, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 59.416, mean reward: 0.594 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.447, 10.098], loss: 0.001461, mae: 0.041367, mean_q: 1.169445
 711166/1000000: episode: 7112, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.923, mean reward: 0.619 [0.509, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.148, 10.269], loss: 0.001448, mae: 0.041069, mean_q: 1.167315
 711266/1000000: episode: 7113, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 59.325, mean reward: 0.593 [0.498, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.605, 10.175], loss: 0.001528, mae: 0.042288, mean_q: 1.170193
 711366/1000000: episode: 7114, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.773, mean reward: 0.578 [0.505, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.771, 10.114], loss: 0.001556, mae: 0.042760, mean_q: 1.168945
 711466/1000000: episode: 7115, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.334, mean reward: 0.583 [0.506, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.122, 10.100], loss: 0.001492, mae: 0.041771, mean_q: 1.167833
 711566/1000000: episode: 7116, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.821, mean reward: 0.588 [0.511, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.906, 10.186], loss: 0.001498, mae: 0.042254, mean_q: 1.167478
 711666/1000000: episode: 7117, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.335, mean reward: 0.573 [0.500, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.935, 10.098], loss: 0.001441, mae: 0.041447, mean_q: 1.165565
 711766/1000000: episode: 7118, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.851, mean reward: 0.579 [0.504, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.477, 10.098], loss: 0.001485, mae: 0.041802, mean_q: 1.168081
 711866/1000000: episode: 7119, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.972, mean reward: 0.570 [0.505, 0.664], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.634, 10.098], loss: 0.001473, mae: 0.041771, mean_q: 1.166338
 711966/1000000: episode: 7120, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.506, mean reward: 0.585 [0.516, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.475, 10.396], loss: 0.001398, mae: 0.041131, mean_q: 1.165543
 712066/1000000: episode: 7121, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.030, mean reward: 0.600 [0.503, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.083, 10.455], loss: 0.001436, mae: 0.041595, mean_q: 1.163401
 712166/1000000: episode: 7122, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.021, mean reward: 0.590 [0.508, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.597, 10.208], loss: 0.001385, mae: 0.040385, mean_q: 1.162012
 712266/1000000: episode: 7123, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.706, mean reward: 0.577 [0.499, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.612, 10.181], loss: 0.001463, mae: 0.042052, mean_q: 1.168061
 712366/1000000: episode: 7124, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.165, mean reward: 0.582 [0.499, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.966, 10.098], loss: 0.001426, mae: 0.040386, mean_q: 1.165766
 712466/1000000: episode: 7125, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.572, mean reward: 0.586 [0.510, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.806, 10.167], loss: 0.001343, mae: 0.039915, mean_q: 1.166007
 712566/1000000: episode: 7126, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.266, mean reward: 0.573 [0.501, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.272, 10.098], loss: 0.001436, mae: 0.041337, mean_q: 1.161307
 712666/1000000: episode: 7127, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.404, mean reward: 0.594 [0.509, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.552, 10.338], loss: 0.001431, mae: 0.040929, mean_q: 1.164577
 712766/1000000: episode: 7128, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.699, mean reward: 0.577 [0.510, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.869, 10.227], loss: 0.001384, mae: 0.041234, mean_q: 1.161399
 712866/1000000: episode: 7129, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.290, mean reward: 0.573 [0.506, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.405, 10.098], loss: 0.001373, mae: 0.040396, mean_q: 1.164521
 712966/1000000: episode: 7130, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.207, mean reward: 0.602 [0.503, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.250, 10.098], loss: 0.001508, mae: 0.042481, mean_q: 1.166279
 713066/1000000: episode: 7131, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.735, mean reward: 0.597 [0.506, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.104, 10.098], loss: 0.001397, mae: 0.040845, mean_q: 1.163716
 713166/1000000: episode: 7132, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.553, mean reward: 0.586 [0.503, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.086, 10.145], loss: 0.001477, mae: 0.041689, mean_q: 1.165401
 713266/1000000: episode: 7133, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.992, mean reward: 0.590 [0.509, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.963, 10.098], loss: 0.001465, mae: 0.041849, mean_q: 1.164367
 713366/1000000: episode: 7134, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.798, mean reward: 0.588 [0.512, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.991, 10.098], loss: 0.001456, mae: 0.041533, mean_q: 1.162804
 713466/1000000: episode: 7135, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.551, mean reward: 0.586 [0.514, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.239, 10.098], loss: 0.001530, mae: 0.043179, mean_q: 1.168605
 713566/1000000: episode: 7136, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 64.510, mean reward: 0.645 [0.505, 0.877], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.374, 10.420], loss: 0.001519, mae: 0.042450, mean_q: 1.166589
 713666/1000000: episode: 7137, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 61.009, mean reward: 0.610 [0.514, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.005, 10.098], loss: 0.001470, mae: 0.041974, mean_q: 1.168012
 713766/1000000: episode: 7138, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 62.705, mean reward: 0.627 [0.526, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.121, 10.098], loss: 0.001472, mae: 0.042341, mean_q: 1.168281
 713866/1000000: episode: 7139, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.029, mean reward: 0.590 [0.498, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.407, 10.098], loss: 0.001480, mae: 0.041926, mean_q: 1.169861
 713966/1000000: episode: 7140, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.575, mean reward: 0.586 [0.498, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.776, 10.098], loss: 0.001418, mae: 0.041331, mean_q: 1.170166
 714066/1000000: episode: 7141, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.170, mean reward: 0.582 [0.512, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.747, 10.236], loss: 0.001431, mae: 0.041489, mean_q: 1.169266
 714166/1000000: episode: 7142, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.306, mean reward: 0.583 [0.502, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.445, 10.167], loss: 0.001544, mae: 0.043014, mean_q: 1.171426
 714266/1000000: episode: 7143, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.561, mean reward: 0.596 [0.515, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.421, 10.098], loss: 0.001521, mae: 0.042559, mean_q: 1.169463
 714366/1000000: episode: 7144, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 61.493, mean reward: 0.615 [0.508, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-1.808, 10.250], loss: 0.001562, mae: 0.043265, mean_q: 1.167852
 714466/1000000: episode: 7145, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.086, mean reward: 0.591 [0.508, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.499, 10.098], loss: 0.001550, mae: 0.042820, mean_q: 1.171192
 714566/1000000: episode: 7146, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.264, mean reward: 0.583 [0.509, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.192, 10.301], loss: 0.001513, mae: 0.042458, mean_q: 1.170330
 714666/1000000: episode: 7147, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 62.376, mean reward: 0.624 [0.523, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.601, 10.098], loss: 0.001604, mae: 0.043555, mean_q: 1.174260
 714766/1000000: episode: 7148, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.930, mean reward: 0.589 [0.518, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.148, 10.244], loss: 0.001515, mae: 0.042254, mean_q: 1.167325
 714866/1000000: episode: 7149, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.666, mean reward: 0.587 [0.506, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.459, 10.344], loss: 0.001451, mae: 0.041481, mean_q: 1.168618
 714966/1000000: episode: 7150, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.559, mean reward: 0.586 [0.502, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.630, 10.140], loss: 0.001548, mae: 0.043372, mean_q: 1.170199
 715066/1000000: episode: 7151, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.742, mean reward: 0.577 [0.497, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.064, 10.137], loss: 0.001522, mae: 0.042791, mean_q: 1.169992
 715166/1000000: episode: 7152, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.046, mean reward: 0.580 [0.514, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.692, 10.306], loss: 0.001500, mae: 0.042127, mean_q: 1.171789
 715266/1000000: episode: 7153, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.730, mean reward: 0.587 [0.502, 0.863], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.490, 10.294], loss: 0.001574, mae: 0.043090, mean_q: 1.172643
 715366/1000000: episode: 7154, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.078, mean reward: 0.581 [0.499, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.848, 10.098], loss: 0.001478, mae: 0.041444, mean_q: 1.166770
 715466/1000000: episode: 7155, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.794, mean reward: 0.588 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.612, 10.098], loss: 0.001482, mae: 0.042090, mean_q: 1.169074
 715566/1000000: episode: 7156, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.590, mean reward: 0.596 [0.501, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.197, 10.105], loss: 0.001536, mae: 0.043142, mean_q: 1.171109
 715666/1000000: episode: 7157, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.670, mean reward: 0.587 [0.498, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.912, 10.098], loss: 0.001473, mae: 0.042006, mean_q: 1.169239
 715766/1000000: episode: 7158, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.362, mean reward: 0.594 [0.505, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-1.187, 10.258], loss: 0.001428, mae: 0.041010, mean_q: 1.166603
 715866/1000000: episode: 7159, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.301, mean reward: 0.573 [0.506, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.668, 10.098], loss: 0.001565, mae: 0.042604, mean_q: 1.170136
 715966/1000000: episode: 7160, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 62.189, mean reward: 0.622 [0.512, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.214, 10.098], loss: 0.001526, mae: 0.042286, mean_q: 1.167776
 716066/1000000: episode: 7161, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.608, mean reward: 0.576 [0.505, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.476, 10.098], loss: 0.001445, mae: 0.041615, mean_q: 1.169566
 716166/1000000: episode: 7162, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 61.336, mean reward: 0.613 [0.514, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.241, 10.098], loss: 0.001567, mae: 0.043117, mean_q: 1.167721
 716266/1000000: episode: 7163, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.276, mean reward: 0.583 [0.501, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.357, 10.189], loss: 0.001619, mae: 0.043703, mean_q: 1.169210
 716366/1000000: episode: 7164, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.949, mean reward: 0.589 [0.506, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.953, 10.098], loss: 0.001378, mae: 0.040576, mean_q: 1.166936
 716466/1000000: episode: 7165, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.848, mean reward: 0.578 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.809, 10.256], loss: 0.001464, mae: 0.041060, mean_q: 1.167104
 716566/1000000: episode: 7166, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.172, mean reward: 0.612 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.834, 10.421], loss: 0.001525, mae: 0.042488, mean_q: 1.168754
 716666/1000000: episode: 7167, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.146, mean reward: 0.591 [0.503, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.739, 10.309], loss: 0.001450, mae: 0.041663, mean_q: 1.169270
 716766/1000000: episode: 7168, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.306, mean reward: 0.573 [0.502, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.596, 10.241], loss: 0.001509, mae: 0.041703, mean_q: 1.172991
 716866/1000000: episode: 7169, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.958, mean reward: 0.600 [0.506, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.303, 10.098], loss: 0.001527, mae: 0.042401, mean_q: 1.172243
 716966/1000000: episode: 7170, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 62.489, mean reward: 0.625 [0.514, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.848, 10.215], loss: 0.001498, mae: 0.042040, mean_q: 1.172405
 717066/1000000: episode: 7171, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.413, mean reward: 0.594 [0.502, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.937, 10.098], loss: 0.001451, mae: 0.041602, mean_q: 1.173859
 717166/1000000: episode: 7172, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.710, mean reward: 0.597 [0.530, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.152, 10.125], loss: 0.001497, mae: 0.041980, mean_q: 1.175312
 717266/1000000: episode: 7173, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.397, mean reward: 0.594 [0.497, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.103, 10.144], loss: 0.001370, mae: 0.040232, mean_q: 1.168270
 717366/1000000: episode: 7174, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.988, mean reward: 0.590 [0.502, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.844, 10.104], loss: 0.001477, mae: 0.041646, mean_q: 1.172640
 717466/1000000: episode: 7175, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.180, mean reward: 0.592 [0.505, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.312, 10.098], loss: 0.001516, mae: 0.042610, mean_q: 1.173442
 717566/1000000: episode: 7176, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 62.100, mean reward: 0.621 [0.515, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.368, 10.438], loss: 0.001485, mae: 0.041922, mean_q: 1.174701
 717666/1000000: episode: 7177, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.104, mean reward: 0.591 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.141, 10.175], loss: 0.001519, mae: 0.042622, mean_q: 1.175899
 717766/1000000: episode: 7178, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.548, mean reward: 0.595 [0.502, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.471, 10.189], loss: 0.001406, mae: 0.040681, mean_q: 1.172626
 717866/1000000: episode: 7179, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.900, mean reward: 0.589 [0.500, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.625, 10.337], loss: 0.001385, mae: 0.040964, mean_q: 1.176415
 717966/1000000: episode: 7180, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.332, mean reward: 0.603 [0.511, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.365, 10.160], loss: 0.001430, mae: 0.041416, mean_q: 1.179533
 718066/1000000: episode: 7181, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.946, mean reward: 0.579 [0.509, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.098, 10.215], loss: 0.001346, mae: 0.040121, mean_q: 1.174916
 718166/1000000: episode: 7182, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.203, mean reward: 0.592 [0.500, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.313, 10.158], loss: 0.001382, mae: 0.040519, mean_q: 1.174936
 718266/1000000: episode: 7183, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 64.879, mean reward: 0.649 [0.515, 0.903], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.295, 10.098], loss: 0.001394, mae: 0.040829, mean_q: 1.174722
 718366/1000000: episode: 7184, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.482, mean reward: 0.605 [0.514, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.856, 10.252], loss: 0.001367, mae: 0.040476, mean_q: 1.175448
 718466/1000000: episode: 7185, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.053, mean reward: 0.591 [0.501, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.825, 10.098], loss: 0.001464, mae: 0.041027, mean_q: 1.180926
 718566/1000000: episode: 7186, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.727, mean reward: 0.577 [0.500, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.096, 10.098], loss: 0.001323, mae: 0.040067, mean_q: 1.175630
 718666/1000000: episode: 7187, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.334, mean reward: 0.583 [0.508, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.097, 10.098], loss: 0.001338, mae: 0.039906, mean_q: 1.172677
 718766/1000000: episode: 7188, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.650, mean reward: 0.596 [0.504, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.484, 10.098], loss: 0.001395, mae: 0.041034, mean_q: 1.175460
 718866/1000000: episode: 7189, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.302, mean reward: 0.583 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.874, 10.098], loss: 0.001392, mae: 0.040788, mean_q: 1.174373
 718966/1000000: episode: 7190, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.349, mean reward: 0.593 [0.513, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.449, 10.098], loss: 0.001393, mae: 0.040926, mean_q: 1.173735
 719066/1000000: episode: 7191, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 64.096, mean reward: 0.641 [0.510, 0.907], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.663, 10.279], loss: 0.001375, mae: 0.040445, mean_q: 1.177841
 719166/1000000: episode: 7192, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.839, mean reward: 0.598 [0.509, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.810, 10.128], loss: 0.001546, mae: 0.042423, mean_q: 1.178917
 719266/1000000: episode: 7193, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.698, mean reward: 0.577 [0.509, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.343, 10.224], loss: 0.001502, mae: 0.041793, mean_q: 1.172926
 719366/1000000: episode: 7194, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.759, mean reward: 0.608 [0.509, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.862, 10.098], loss: 0.001503, mae: 0.042149, mean_q: 1.178624
 719466/1000000: episode: 7195, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.096, mean reward: 0.571 [0.499, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.480, 10.167], loss: 0.001582, mae: 0.042744, mean_q: 1.178102
 719566/1000000: episode: 7196, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.194, mean reward: 0.592 [0.509, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.666, 10.116], loss: 0.001433, mae: 0.041010, mean_q: 1.175148
 719666/1000000: episode: 7197, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.770, mean reward: 0.588 [0.508, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.441, 10.136], loss: 0.001431, mae: 0.041278, mean_q: 1.177409
 719766/1000000: episode: 7198, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.491, mean reward: 0.585 [0.499, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.872, 10.230], loss: 0.001534, mae: 0.042269, mean_q: 1.175884
 719866/1000000: episode: 7199, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.933, mean reward: 0.579 [0.505, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.770, 10.098], loss: 0.001391, mae: 0.040552, mean_q: 1.175092
 719966/1000000: episode: 7200, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.099, mean reward: 0.601 [0.505, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.692, 10.228], loss: 0.001381, mae: 0.040249, mean_q: 1.174381
 720066/1000000: episode: 7201, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.390, mean reward: 0.574 [0.497, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.509, 10.098], loss: 0.001469, mae: 0.042108, mean_q: 1.172697
 720166/1000000: episode: 7202, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.466, mean reward: 0.605 [0.500, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.077, 10.363], loss: 0.001498, mae: 0.041924, mean_q: 1.179608
 720266/1000000: episode: 7203, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 60.563, mean reward: 0.606 [0.508, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.599, 10.121], loss: 0.001460, mae: 0.041673, mean_q: 1.177065
 720366/1000000: episode: 7204, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 64.039, mean reward: 0.640 [0.503, 0.910], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.132, 10.098], loss: 0.001471, mae: 0.041608, mean_q: 1.181504
 720466/1000000: episode: 7205, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.982, mean reward: 0.590 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.827, 10.185], loss: 0.001417, mae: 0.040917, mean_q: 1.176078
 720566/1000000: episode: 7206, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.412, mean reward: 0.574 [0.497, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.269, 10.098], loss: 0.001373, mae: 0.040377, mean_q: 1.178824
 720666/1000000: episode: 7207, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 57.127, mean reward: 0.571 [0.508, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.425, 10.276], loss: 0.001511, mae: 0.042461, mean_q: 1.176797
 720766/1000000: episode: 7208, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.682, mean reward: 0.587 [0.505, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.579, 10.098], loss: 0.001469, mae: 0.042062, mean_q: 1.178677
 720866/1000000: episode: 7209, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 61.229, mean reward: 0.612 [0.512, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.466, 10.098], loss: 0.001437, mae: 0.041843, mean_q: 1.178486
 720966/1000000: episode: 7210, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 63.084, mean reward: 0.631 [0.505, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.293, 10.098], loss: 0.001457, mae: 0.041320, mean_q: 1.180143
 721066/1000000: episode: 7211, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.463, mean reward: 0.605 [0.502, 0.883], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.808, 10.098], loss: 0.001436, mae: 0.041406, mean_q: 1.181645
 721166/1000000: episode: 7212, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.517, mean reward: 0.585 [0.503, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.295, 10.098], loss: 0.001329, mae: 0.040156, mean_q: 1.177910
 721266/1000000: episode: 7213, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.198, mean reward: 0.592 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.508, 10.359], loss: 0.001457, mae: 0.041817, mean_q: 1.179167
 721366/1000000: episode: 7214, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.833, mean reward: 0.588 [0.504, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-2.870, 10.098], loss: 0.001377, mae: 0.040878, mean_q: 1.181466
 721466/1000000: episode: 7215, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 63.184, mean reward: 0.632 [0.506, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.213, 10.286], loss: 0.001500, mae: 0.042280, mean_q: 1.182460
 721566/1000000: episode: 7216, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.995, mean reward: 0.580 [0.501, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.251, 10.098], loss: 0.001417, mae: 0.041503, mean_q: 1.182871
 721666/1000000: episode: 7217, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.612, mean reward: 0.576 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.968, 10.098], loss: 0.001501, mae: 0.042471, mean_q: 1.180672
 721766/1000000: episode: 7218, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.837, mean reward: 0.578 [0.499, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.602, 10.098], loss: 0.001503, mae: 0.042289, mean_q: 1.178366
 721866/1000000: episode: 7219, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.518, mean reward: 0.595 [0.506, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.845, 10.244], loss: 0.001562, mae: 0.043552, mean_q: 1.182107
 721966/1000000: episode: 7220, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 62.343, mean reward: 0.623 [0.508, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.579, 10.134], loss: 0.001535, mae: 0.042996, mean_q: 1.184571
 722066/1000000: episode: 7221, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.237, mean reward: 0.572 [0.503, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.705, 10.186], loss: 0.001522, mae: 0.042345, mean_q: 1.181536
 722166/1000000: episode: 7222, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.558, mean reward: 0.566 [0.501, 0.669], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.062, 10.098], loss: 0.001441, mae: 0.041604, mean_q: 1.175909
 722266/1000000: episode: 7223, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.534, mean reward: 0.595 [0.517, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.585, 10.202], loss: 0.001451, mae: 0.041885, mean_q: 1.178580
 722366/1000000: episode: 7224, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.088, mean reward: 0.581 [0.504, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.119, 10.098], loss: 0.001466, mae: 0.041820, mean_q: 1.178905
 722466/1000000: episode: 7225, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.680, mean reward: 0.577 [0.499, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.327, 10.116], loss: 0.001430, mae: 0.040732, mean_q: 1.176315
 722566/1000000: episode: 7226, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 63.658, mean reward: 0.637 [0.517, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.025, 10.537], loss: 0.001398, mae: 0.040946, mean_q: 1.178201
 722666/1000000: episode: 7227, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 63.126, mean reward: 0.631 [0.511, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.747, 10.098], loss: 0.001501, mae: 0.042138, mean_q: 1.180562
 722766/1000000: episode: 7228, duration: 0.656s, episode steps: 100, steps per second: 152, episode reward: 61.911, mean reward: 0.619 [0.504, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.664, 10.540], loss: 0.001437, mae: 0.040905, mean_q: 1.179160
 722866/1000000: episode: 7229, duration: 0.834s, episode steps: 100, steps per second: 120, episode reward: 60.828, mean reward: 0.608 [0.503, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.213, 10.098], loss: 0.001578, mae: 0.042863, mean_q: 1.179777
 722966/1000000: episode: 7230, duration: 1.077s, episode steps: 100, steps per second: 93, episode reward: 59.387, mean reward: 0.594 [0.507, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.516, 10.098], loss: 0.001538, mae: 0.042149, mean_q: 1.177471
 723066/1000000: episode: 7231, duration: 1.144s, episode steps: 100, steps per second: 87, episode reward: 57.620, mean reward: 0.576 [0.504, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.142, 10.098], loss: 0.001359, mae: 0.039465, mean_q: 1.178678
 723166/1000000: episode: 7232, duration: 1.342s, episode steps: 100, steps per second: 74, episode reward: 59.520, mean reward: 0.595 [0.502, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.704, 10.326], loss: 0.001533, mae: 0.041987, mean_q: 1.179124
 723266/1000000: episode: 7233, duration: 0.780s, episode steps: 100, steps per second: 128, episode reward: 59.081, mean reward: 0.591 [0.507, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.469, 10.098], loss: 0.001430, mae: 0.041156, mean_q: 1.176533
 723366/1000000: episode: 7234, duration: 0.734s, episode steps: 100, steps per second: 136, episode reward: 58.465, mean reward: 0.585 [0.507, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.567, 10.289], loss: 0.001400, mae: 0.040722, mean_q: 1.180554
 723466/1000000: episode: 7235, duration: 0.828s, episode steps: 100, steps per second: 121, episode reward: 57.068, mean reward: 0.571 [0.501, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.039, 10.098], loss: 0.001474, mae: 0.041945, mean_q: 1.176763
 723566/1000000: episode: 7236, duration: 0.709s, episode steps: 100, steps per second: 141, episode reward: 60.766, mean reward: 0.608 [0.502, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.506, 10.098], loss: 0.001501, mae: 0.042393, mean_q: 1.180001
 723666/1000000: episode: 7237, duration: 0.811s, episode steps: 100, steps per second: 123, episode reward: 57.666, mean reward: 0.577 [0.509, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.522, 10.098], loss: 0.001516, mae: 0.042231, mean_q: 1.182347
 723766/1000000: episode: 7238, duration: 0.775s, episode steps: 100, steps per second: 129, episode reward: 58.654, mean reward: 0.587 [0.509, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.174, 10.368], loss: 0.001468, mae: 0.041388, mean_q: 1.176247
 723866/1000000: episode: 7239, duration: 0.611s, episode steps: 100, steps per second: 164, episode reward: 61.790, mean reward: 0.618 [0.510, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.211, 10.298], loss: 0.001426, mae: 0.040775, mean_q: 1.179856
 723966/1000000: episode: 7240, duration: 0.631s, episode steps: 100, steps per second: 159, episode reward: 58.859, mean reward: 0.589 [0.510, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.077, 10.430], loss: 0.001423, mae: 0.040828, mean_q: 1.179663
 724066/1000000: episode: 7241, duration: 0.775s, episode steps: 100, steps per second: 129, episode reward: 57.412, mean reward: 0.574 [0.500, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.506, 10.138], loss: 0.001374, mae: 0.040261, mean_q: 1.176799
 724166/1000000: episode: 7242, duration: 0.658s, episode steps: 100, steps per second: 152, episode reward: 57.324, mean reward: 0.573 [0.502, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.793, 10.112], loss: 0.001491, mae: 0.041840, mean_q: 1.175825
 724266/1000000: episode: 7243, duration: 0.629s, episode steps: 100, steps per second: 159, episode reward: 57.615, mean reward: 0.576 [0.507, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.854, 10.098], loss: 0.001456, mae: 0.040990, mean_q: 1.174031
 724366/1000000: episode: 7244, duration: 0.635s, episode steps: 100, steps per second: 158, episode reward: 62.576, mean reward: 0.626 [0.502, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.948, 10.098], loss: 0.001443, mae: 0.041177, mean_q: 1.175736
 724466/1000000: episode: 7245, duration: 1.094s, episode steps: 100, steps per second: 91, episode reward: 61.283, mean reward: 0.613 [0.516, 0.941], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.768, 10.244], loss: 0.001399, mae: 0.040401, mean_q: 1.176331
 724566/1000000: episode: 7246, duration: 0.683s, episode steps: 100, steps per second: 146, episode reward: 59.818, mean reward: 0.598 [0.513, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.721, 10.207], loss: 0.001470, mae: 0.041699, mean_q: 1.176282
 724666/1000000: episode: 7247, duration: 0.653s, episode steps: 100, steps per second: 153, episode reward: 60.144, mean reward: 0.601 [0.510, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.526, 10.265], loss: 0.001516, mae: 0.041863, mean_q: 1.179789
 724766/1000000: episode: 7248, duration: 0.646s, episode steps: 100, steps per second: 155, episode reward: 58.838, mean reward: 0.588 [0.506, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.940, 10.098], loss: 0.001485, mae: 0.041238, mean_q: 1.179231
 724866/1000000: episode: 7249, duration: 0.965s, episode steps: 100, steps per second: 104, episode reward: 59.389, mean reward: 0.594 [0.510, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.075, 10.292], loss: 0.001439, mae: 0.041338, mean_q: 1.183038
 724966/1000000: episode: 7250, duration: 0.905s, episode steps: 100, steps per second: 111, episode reward: 57.603, mean reward: 0.576 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.339, 10.319], loss: 0.001456, mae: 0.040997, mean_q: 1.179584
 725066/1000000: episode: 7251, duration: 0.865s, episode steps: 100, steps per second: 116, episode reward: 63.633, mean reward: 0.636 [0.511, 0.854], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.543, 10.098], loss: 0.001591, mae: 0.043196, mean_q: 1.180699
 725166/1000000: episode: 7252, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.781, mean reward: 0.578 [0.498, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.536, 10.098], loss: 0.001466, mae: 0.041593, mean_q: 1.180454
 725266/1000000: episode: 7253, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 61.232, mean reward: 0.612 [0.503, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.762, 10.254], loss: 0.001412, mae: 0.040651, mean_q: 1.180792
 725366/1000000: episode: 7254, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.079, mean reward: 0.591 [0.502, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.243, 10.098], loss: 0.001457, mae: 0.041284, mean_q: 1.177123
 725466/1000000: episode: 7255, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.702, mean reward: 0.577 [0.499, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.032, 10.442], loss: 0.001555, mae: 0.042227, mean_q: 1.178830
 725566/1000000: episode: 7256, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.950, mean reward: 0.590 [0.513, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.637, 10.098], loss: 0.001412, mae: 0.040475, mean_q: 1.173077
 725666/1000000: episode: 7257, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.903, mean reward: 0.589 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.791, 10.098], loss: 0.001463, mae: 0.041480, mean_q: 1.179944
 725766/1000000: episode: 7258, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 62.285, mean reward: 0.623 [0.505, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.792, 10.098], loss: 0.001467, mae: 0.041460, mean_q: 1.179079
 725866/1000000: episode: 7259, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.964, mean reward: 0.590 [0.504, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.849, 10.256], loss: 0.001506, mae: 0.041733, mean_q: 1.179756
 725966/1000000: episode: 7260, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 62.592, mean reward: 0.626 [0.514, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.343, 10.326], loss: 0.001457, mae: 0.041358, mean_q: 1.171009
 726066/1000000: episode: 7261, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.763, mean reward: 0.588 [0.510, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.456, 10.145], loss: 0.001499, mae: 0.041795, mean_q: 1.176799
 726166/1000000: episode: 7262, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.526, mean reward: 0.585 [0.509, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.629, 10.098], loss: 0.001451, mae: 0.041423, mean_q: 1.175268
 726266/1000000: episode: 7263, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 56.772, mean reward: 0.568 [0.500, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.742, 10.175], loss: 0.001423, mae: 0.040965, mean_q: 1.178534
 726366/1000000: episode: 7264, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.579, mean reward: 0.596 [0.510, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.832, 10.345], loss: 0.001445, mae: 0.040768, mean_q: 1.179020
 726466/1000000: episode: 7265, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.298, mean reward: 0.603 [0.499, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.804, 10.098], loss: 0.001434, mae: 0.040658, mean_q: 1.174591
 726566/1000000: episode: 7266, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.786, mean reward: 0.588 [0.508, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.693, 10.098], loss: 0.001396, mae: 0.040727, mean_q: 1.171920
 726666/1000000: episode: 7267, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.034, mean reward: 0.590 [0.511, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.034, 10.299], loss: 0.001527, mae: 0.042205, mean_q: 1.177485
 726766/1000000: episode: 7268, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.401, mean reward: 0.574 [0.502, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.101, 10.098], loss: 0.001420, mae: 0.041127, mean_q: 1.175745
 726866/1000000: episode: 7269, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.094, mean reward: 0.581 [0.504, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.542, 10.191], loss: 0.001514, mae: 0.041462, mean_q: 1.177508
 726966/1000000: episode: 7270, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.010, mean reward: 0.570 [0.506, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.289, 10.098], loss: 0.001495, mae: 0.041498, mean_q: 1.173788
 727066/1000000: episode: 7271, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.775, mean reward: 0.588 [0.501, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.163, 10.305], loss: 0.001435, mae: 0.040910, mean_q: 1.172873
 727166/1000000: episode: 7272, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 60.096, mean reward: 0.601 [0.502, 0.855], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.799, 10.196], loss: 0.001495, mae: 0.042075, mean_q: 1.173030
 727266/1000000: episode: 7273, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 63.277, mean reward: 0.633 [0.515, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.280, 10.377], loss: 0.001506, mae: 0.041772, mean_q: 1.178224
 727366/1000000: episode: 7274, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 63.396, mean reward: 0.634 [0.501, 0.892], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.850, 10.098], loss: 0.001467, mae: 0.041590, mean_q: 1.175036
 727466/1000000: episode: 7275, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.957, mean reward: 0.600 [0.506, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.916, 10.098], loss: 0.001523, mae: 0.042218, mean_q: 1.182673
 727566/1000000: episode: 7276, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 61.506, mean reward: 0.615 [0.504, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.620, 10.174], loss: 0.001477, mae: 0.041814, mean_q: 1.180688
 727666/1000000: episode: 7277, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.077, mean reward: 0.581 [0.501, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.790, 10.120], loss: 0.001460, mae: 0.041061, mean_q: 1.183891
 727766/1000000: episode: 7278, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.486, mean reward: 0.595 [0.508, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.484, 10.098], loss: 0.001487, mae: 0.041295, mean_q: 1.177035
 727866/1000000: episode: 7279, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.568, mean reward: 0.586 [0.509, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.653, 10.098], loss: 0.001496, mae: 0.041782, mean_q: 1.176350
 727966/1000000: episode: 7280, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.915, mean reward: 0.579 [0.499, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.993, 10.222], loss: 0.001466, mae: 0.041280, mean_q: 1.175228
 728066/1000000: episode: 7281, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 62.522, mean reward: 0.625 [0.516, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.657, 10.098], loss: 0.001462, mae: 0.041722, mean_q: 1.176986
 728166/1000000: episode: 7282, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.802, mean reward: 0.588 [0.506, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.439, 10.098], loss: 0.001543, mae: 0.042056, mean_q: 1.174778
 728266/1000000: episode: 7283, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.991, mean reward: 0.590 [0.510, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.936, 10.402], loss: 0.001579, mae: 0.042809, mean_q: 1.176426
 728366/1000000: episode: 7284, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.171, mean reward: 0.592 [0.505, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.927, 10.164], loss: 0.001460, mae: 0.041050, mean_q: 1.178825
 728466/1000000: episode: 7285, duration: 0.625s, episode steps: 100, steps per second: 160, episode reward: 59.415, mean reward: 0.594 [0.507, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.674, 10.098], loss: 0.001585, mae: 0.043095, mean_q: 1.176305
 728566/1000000: episode: 7286, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 60.699, mean reward: 0.607 [0.505, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.678, 10.326], loss: 0.001615, mae: 0.043307, mean_q: 1.179342
 728666/1000000: episode: 7287, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.513, mean reward: 0.595 [0.506, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.588, 10.314], loss: 0.001568, mae: 0.042932, mean_q: 1.176448
 728766/1000000: episode: 7288, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 61.707, mean reward: 0.617 [0.520, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-2.192, 10.098], loss: 0.001385, mae: 0.040053, mean_q: 1.176435
 728866/1000000: episode: 7289, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.830, mean reward: 0.578 [0.501, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.311, 10.098], loss: 0.001560, mae: 0.042824, mean_q: 1.180226
 728966/1000000: episode: 7290, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.983, mean reward: 0.590 [0.510, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.913, 10.158], loss: 0.001636, mae: 0.043615, mean_q: 1.180031
 729066/1000000: episode: 7291, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 60.418, mean reward: 0.604 [0.506, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.385, 10.098], loss: 0.001461, mae: 0.041262, mean_q: 1.179480
 729166/1000000: episode: 7292, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.984, mean reward: 0.600 [0.498, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.826, 10.362], loss: 0.001464, mae: 0.041838, mean_q: 1.178945
 729266/1000000: episode: 7293, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 57.779, mean reward: 0.578 [0.509, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.731, 10.098], loss: 0.001439, mae: 0.041041, mean_q: 1.180448
 729366/1000000: episode: 7294, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.528, mean reward: 0.585 [0.500, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.469, 10.286], loss: 0.001448, mae: 0.041024, mean_q: 1.178681
 729466/1000000: episode: 7295, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.579, mean reward: 0.586 [0.508, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.852, 10.201], loss: 0.001498, mae: 0.041936, mean_q: 1.179966
 729566/1000000: episode: 7296, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.282, mean reward: 0.573 [0.508, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.947, 10.098], loss: 0.001461, mae: 0.041177, mean_q: 1.177300
 729666/1000000: episode: 7297, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 59.308, mean reward: 0.593 [0.510, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.467, 10.129], loss: 0.001449, mae: 0.041188, mean_q: 1.176496
 729766/1000000: episode: 7298, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.581, mean reward: 0.566 [0.498, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.019, 10.098], loss: 0.001454, mae: 0.040851, mean_q: 1.176860
 729866/1000000: episode: 7299, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.907, mean reward: 0.589 [0.513, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.864, 10.140], loss: 0.001388, mae: 0.040488, mean_q: 1.175472
 729966/1000000: episode: 7300, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.612, mean reward: 0.596 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.385, 10.107], loss: 0.001487, mae: 0.041876, mean_q: 1.173455
 730066/1000000: episode: 7301, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 56.307, mean reward: 0.563 [0.504, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.492, 10.155], loss: 0.001482, mae: 0.041364, mean_q: 1.170196
 730166/1000000: episode: 7302, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 59.769, mean reward: 0.598 [0.503, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.100, 10.196], loss: 0.001485, mae: 0.041801, mean_q: 1.175907
 730266/1000000: episode: 7303, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.131, mean reward: 0.581 [0.506, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.620, 10.098], loss: 0.001460, mae: 0.040982, mean_q: 1.170617
 730366/1000000: episode: 7304, duration: 0.630s, episode steps: 100, steps per second: 159, episode reward: 60.934, mean reward: 0.609 [0.505, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.744, 10.378], loss: 0.001439, mae: 0.041171, mean_q: 1.172821
 730466/1000000: episode: 7305, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.752, mean reward: 0.598 [0.505, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.686, 10.250], loss: 0.001453, mae: 0.040909, mean_q: 1.172004
 730566/1000000: episode: 7306, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.658, mean reward: 0.597 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.644, 10.184], loss: 0.001397, mae: 0.040542, mean_q: 1.175531
 730666/1000000: episode: 7307, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.208, mean reward: 0.582 [0.502, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.054, 10.098], loss: 0.001442, mae: 0.041341, mean_q: 1.175321
 730766/1000000: episode: 7308, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.069, mean reward: 0.601 [0.511, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.384, 10.291], loss: 0.001375, mae: 0.040393, mean_q: 1.172033
 730866/1000000: episode: 7309, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.107, mean reward: 0.581 [0.500, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.555, 10.335], loss: 0.001417, mae: 0.040847, mean_q: 1.174560
 730966/1000000: episode: 7310, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.515, mean reward: 0.585 [0.506, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.582, 10.314], loss: 0.001421, mae: 0.040630, mean_q: 1.170267
 731066/1000000: episode: 7311, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.110, mean reward: 0.581 [0.504, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.572, 10.243], loss: 0.001404, mae: 0.040383, mean_q: 1.170631
 731166/1000000: episode: 7312, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.921, mean reward: 0.579 [0.499, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.079, 10.098], loss: 0.001396, mae: 0.040317, mean_q: 1.171020
 731266/1000000: episode: 7313, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.692, mean reward: 0.597 [0.506, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.773, 10.233], loss: 0.001489, mae: 0.041505, mean_q: 1.175942
 731366/1000000: episode: 7314, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.275, mean reward: 0.593 [0.513, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.661, 10.109], loss: 0.001294, mae: 0.039271, mean_q: 1.170725
 731466/1000000: episode: 7315, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.669, mean reward: 0.577 [0.503, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.332, 10.098], loss: 0.001392, mae: 0.040157, mean_q: 1.168839
 731566/1000000: episode: 7316, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.258, mean reward: 0.583 [0.504, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.855, 10.149], loss: 0.001354, mae: 0.039413, mean_q: 1.169991
 731666/1000000: episode: 7317, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.759, mean reward: 0.588 [0.517, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.359, 10.098], loss: 0.001405, mae: 0.040935, mean_q: 1.169004
 731766/1000000: episode: 7318, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 57.608, mean reward: 0.576 [0.514, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.558, 10.105], loss: 0.001342, mae: 0.039365, mean_q: 1.169978
 731866/1000000: episode: 7319, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 58.391, mean reward: 0.584 [0.507, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.599, 10.187], loss: 0.001399, mae: 0.040052, mean_q: 1.169210
 731966/1000000: episode: 7320, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.033, mean reward: 0.580 [0.501, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.931, 10.227], loss: 0.001343, mae: 0.039872, mean_q: 1.170228
 732066/1000000: episode: 7321, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.652, mean reward: 0.597 [0.516, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.080, 10.098], loss: 0.001394, mae: 0.039848, mean_q: 1.171971
 732166/1000000: episode: 7322, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.205, mean reward: 0.592 [0.503, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.351, 10.098], loss: 0.001325, mae: 0.039875, mean_q: 1.172569
 732266/1000000: episode: 7323, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 65.231, mean reward: 0.652 [0.517, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.542, 10.098], loss: 0.001341, mae: 0.039974, mean_q: 1.168245
 732366/1000000: episode: 7324, duration: 0.725s, episode steps: 100, steps per second: 138, episode reward: 58.364, mean reward: 0.584 [0.505, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.229, 10.098], loss: 0.001360, mae: 0.040215, mean_q: 1.171462
 732466/1000000: episode: 7325, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.056, mean reward: 0.581 [0.498, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.448, 10.121], loss: 0.001402, mae: 0.040454, mean_q: 1.172282
 732566/1000000: episode: 7326, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 61.128, mean reward: 0.611 [0.505, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.894, 10.416], loss: 0.001445, mae: 0.041084, mean_q: 1.169973
 732666/1000000: episode: 7327, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 62.217, mean reward: 0.622 [0.502, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.668, 10.485], loss: 0.001361, mae: 0.040197, mean_q: 1.170998
 732766/1000000: episode: 7328, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.784, mean reward: 0.598 [0.509, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.165, 10.347], loss: 0.001370, mae: 0.040163, mean_q: 1.170817
 732866/1000000: episode: 7329, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.202, mean reward: 0.612 [0.508, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.581, 10.098], loss: 0.001403, mae: 0.040097, mean_q: 1.171482
 732966/1000000: episode: 7330, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.769, mean reward: 0.578 [0.503, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.714, 10.174], loss: 0.001367, mae: 0.039985, mean_q: 1.171692
 733066/1000000: episode: 7331, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 61.131, mean reward: 0.611 [0.508, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.177, 10.098], loss: 0.001280, mae: 0.038749, mean_q: 1.170830
 733166/1000000: episode: 7332, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.784, mean reward: 0.588 [0.501, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.813, 10.126], loss: 0.001366, mae: 0.040270, mean_q: 1.171809
 733266/1000000: episode: 7333, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.506, mean reward: 0.605 [0.512, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.450, 10.177], loss: 0.001273, mae: 0.038783, mean_q: 1.173399
 733366/1000000: episode: 7334, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.491, mean reward: 0.575 [0.498, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.028, 10.098], loss: 0.001311, mae: 0.039265, mean_q: 1.170476
 733466/1000000: episode: 7335, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.923, mean reward: 0.589 [0.512, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.848, 10.300], loss: 0.001335, mae: 0.039645, mean_q: 1.173795
 733566/1000000: episode: 7336, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.111, mean reward: 0.581 [0.512, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.807, 10.164], loss: 0.001321, mae: 0.039145, mean_q: 1.172855
 733666/1000000: episode: 7337, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 57.933, mean reward: 0.579 [0.513, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.437, 10.098], loss: 0.001230, mae: 0.038266, mean_q: 1.169787
 733766/1000000: episode: 7338, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.955, mean reward: 0.580 [0.499, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.404, 10.098], loss: 0.001384, mae: 0.040193, mean_q: 1.167504
 733866/1000000: episode: 7339, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 57.383, mean reward: 0.574 [0.507, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.882, 10.098], loss: 0.001355, mae: 0.039678, mean_q: 1.170341
 733966/1000000: episode: 7340, duration: 0.611s, episode steps: 100, steps per second: 164, episode reward: 60.954, mean reward: 0.610 [0.513, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.735, 10.098], loss: 0.001312, mae: 0.039442, mean_q: 1.167234
 734066/1000000: episode: 7341, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.426, mean reward: 0.584 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.238, 10.098], loss: 0.001256, mae: 0.038760, mean_q: 1.167072
 734166/1000000: episode: 7342, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 64.070, mean reward: 0.641 [0.517, 0.879], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.858, 10.436], loss: 0.001282, mae: 0.039594, mean_q: 1.168753
 734266/1000000: episode: 7343, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 56.546, mean reward: 0.565 [0.504, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.635, 10.128], loss: 0.001203, mae: 0.037296, mean_q: 1.168379
 734366/1000000: episode: 7344, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.575, mean reward: 0.586 [0.507, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.938, 10.098], loss: 0.001240, mae: 0.038615, mean_q: 1.171421
 734466/1000000: episode: 7345, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.627, mean reward: 0.606 [0.516, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.512, 10.098], loss: 0.001270, mae: 0.038527, mean_q: 1.170668
 734566/1000000: episode: 7346, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.821, mean reward: 0.588 [0.502, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.629, 10.238], loss: 0.001300, mae: 0.039681, mean_q: 1.165252
 734666/1000000: episode: 7347, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 56.611, mean reward: 0.566 [0.502, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.401, 10.197], loss: 0.001338, mae: 0.040017, mean_q: 1.168161
 734766/1000000: episode: 7348, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.611, mean reward: 0.576 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.683, 10.290], loss: 0.001348, mae: 0.039950, mean_q: 1.169634
 734866/1000000: episode: 7349, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.313, mean reward: 0.573 [0.502, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.784, 10.157], loss: 0.001326, mae: 0.039335, mean_q: 1.170802
 734966/1000000: episode: 7350, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.050, mean reward: 0.600 [0.512, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.703, 10.098], loss: 0.001432, mae: 0.041455, mean_q: 1.171105
 735066/1000000: episode: 7351, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 62.655, mean reward: 0.627 [0.507, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.712, 10.098], loss: 0.001382, mae: 0.040229, mean_q: 1.168154
 735166/1000000: episode: 7352, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 64.837, mean reward: 0.648 [0.505, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.850, 10.098], loss: 0.001292, mae: 0.038599, mean_q: 1.170204
 735266/1000000: episode: 7353, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.481, mean reward: 0.605 [0.503, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.246, 10.098], loss: 0.001275, mae: 0.039318, mean_q: 1.175579
 735366/1000000: episode: 7354, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.045, mean reward: 0.580 [0.507, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.194, 10.098], loss: 0.001294, mae: 0.038893, mean_q: 1.178504
 735466/1000000: episode: 7355, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.096, mean reward: 0.601 [0.509, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.230, 10.154], loss: 0.001307, mae: 0.039844, mean_q: 1.172477
 735566/1000000: episode: 7356, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.998, mean reward: 0.600 [0.498, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.594, 10.098], loss: 0.001227, mae: 0.038199, mean_q: 1.174056
 735666/1000000: episode: 7357, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.485, mean reward: 0.585 [0.501, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.748, 10.141], loss: 0.001358, mae: 0.040299, mean_q: 1.174478
 735766/1000000: episode: 7358, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 59.589, mean reward: 0.596 [0.501, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.968, 10.177], loss: 0.001348, mae: 0.040380, mean_q: 1.175219
 735866/1000000: episode: 7359, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 60.814, mean reward: 0.608 [0.506, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.515, 10.157], loss: 0.001326, mae: 0.039620, mean_q: 1.174363
 735966/1000000: episode: 7360, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.244, mean reward: 0.572 [0.502, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.714, 10.236], loss: 0.001437, mae: 0.041532, mean_q: 1.179086
 736066/1000000: episode: 7361, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.631, mean reward: 0.586 [0.507, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.451, 10.098], loss: 0.001320, mae: 0.039802, mean_q: 1.177849
 736166/1000000: episode: 7362, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 61.769, mean reward: 0.618 [0.510, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.258, 10.098], loss: 0.001236, mae: 0.038480, mean_q: 1.174365
 736266/1000000: episode: 7363, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.771, mean reward: 0.568 [0.502, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.400, 10.183], loss: 0.001266, mae: 0.039210, mean_q: 1.176278
 736366/1000000: episode: 7364, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.471, mean reward: 0.585 [0.499, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.237, 10.113], loss: 0.001240, mae: 0.038571, mean_q: 1.172754
 736466/1000000: episode: 7365, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 59.146, mean reward: 0.591 [0.503, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.130, 10.098], loss: 0.001269, mae: 0.039218, mean_q: 1.174268
 736566/1000000: episode: 7366, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.419, mean reward: 0.604 [0.502, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.882, 10.098], loss: 0.001382, mae: 0.040569, mean_q: 1.178160
 736666/1000000: episode: 7367, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.913, mean reward: 0.589 [0.503, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.358, 10.344], loss: 0.001328, mae: 0.040019, mean_q: 1.172154
 736766/1000000: episode: 7368, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.094, mean reward: 0.581 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.988, 10.227], loss: 0.001459, mae: 0.041580, mean_q: 1.177088
 736866/1000000: episode: 7369, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 63.295, mean reward: 0.633 [0.509, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.622, 10.306], loss: 0.001400, mae: 0.041040, mean_q: 1.180495
 736966/1000000: episode: 7370, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.756, mean reward: 0.608 [0.506, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.113, 10.268], loss: 0.001360, mae: 0.040193, mean_q: 1.176237
 737066/1000000: episode: 7371, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.511, mean reward: 0.575 [0.504, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.779, 10.307], loss: 0.001412, mae: 0.041145, mean_q: 1.177151
 737166/1000000: episode: 7372, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.878, mean reward: 0.579 [0.507, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.253, 10.254], loss: 0.001414, mae: 0.041232, mean_q: 1.176112
 737266/1000000: episode: 7373, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.273, mean reward: 0.613 [0.500, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.860, 10.549], loss: 0.001412, mae: 0.041120, mean_q: 1.176821
 737366/1000000: episode: 7374, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.370, mean reward: 0.604 [0.510, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.164, 10.342], loss: 0.001361, mae: 0.040175, mean_q: 1.178266
 737466/1000000: episode: 7375, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.128, mean reward: 0.571 [0.511, 0.659], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.122, 10.212], loss: 0.001412, mae: 0.041288, mean_q: 1.175391
 737566/1000000: episode: 7376, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.202, mean reward: 0.582 [0.502, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.496, 10.098], loss: 0.001424, mae: 0.040957, mean_q: 1.180158
 737666/1000000: episode: 7377, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.158, mean reward: 0.572 [0.501, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.241, 10.224], loss: 0.001427, mae: 0.041247, mean_q: 1.174683
 737766/1000000: episode: 7378, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.894, mean reward: 0.589 [0.507, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.719, 10.098], loss: 0.001354, mae: 0.039841, mean_q: 1.172808
 737866/1000000: episode: 7379, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.472, mean reward: 0.585 [0.509, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.369, 10.144], loss: 0.001456, mae: 0.041942, mean_q: 1.172828
 737966/1000000: episode: 7380, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.224, mean reward: 0.582 [0.516, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.191, 10.098], loss: 0.001375, mae: 0.040746, mean_q: 1.174314
 738066/1000000: episode: 7381, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.501, mean reward: 0.585 [0.501, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.786, 10.098], loss: 0.001353, mae: 0.040861, mean_q: 1.171561
 738166/1000000: episode: 7382, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.558, mean reward: 0.596 [0.503, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.604, 10.098], loss: 0.001438, mae: 0.041673, mean_q: 1.170624
 738266/1000000: episode: 7383, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.888, mean reward: 0.579 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.376, 10.098], loss: 0.001334, mae: 0.040266, mean_q: 1.172927
 738366/1000000: episode: 7384, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.100, mean reward: 0.581 [0.504, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.341, 10.116], loss: 0.001441, mae: 0.041380, mean_q: 1.172205
 738466/1000000: episode: 7385, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.847, mean reward: 0.578 [0.503, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.871, 10.215], loss: 0.001450, mae: 0.041336, mean_q: 1.169699
 738566/1000000: episode: 7386, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 56.474, mean reward: 0.565 [0.499, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.290, 10.158], loss: 0.001428, mae: 0.041160, mean_q: 1.170409
 738666/1000000: episode: 7387, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.127, mean reward: 0.581 [0.501, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.890, 10.098], loss: 0.001383, mae: 0.040796, mean_q: 1.170678
 738766/1000000: episode: 7388, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.125, mean reward: 0.601 [0.499, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.199, 10.255], loss: 0.001367, mae: 0.039802, mean_q: 1.171051
 738866/1000000: episode: 7389, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.419, mean reward: 0.584 [0.498, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.558, 10.225], loss: 0.001394, mae: 0.040801, mean_q: 1.172624
 738966/1000000: episode: 7390, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.743, mean reward: 0.587 [0.510, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.951, 10.232], loss: 0.001473, mae: 0.041764, mean_q: 1.168087
 739066/1000000: episode: 7391, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.216, mean reward: 0.602 [0.510, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.070, 10.098], loss: 0.001383, mae: 0.040290, mean_q: 1.166617
 739166/1000000: episode: 7392, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 57.743, mean reward: 0.577 [0.500, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.578, 10.098], loss: 0.001419, mae: 0.041221, mean_q: 1.169393
 739266/1000000: episode: 7393, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.772, mean reward: 0.598 [0.505, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.033, 10.098], loss: 0.001444, mae: 0.041692, mean_q: 1.167344
 739366/1000000: episode: 7394, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.780, mean reward: 0.588 [0.506, 0.869], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.310, 10.102], loss: 0.001397, mae: 0.040564, mean_q: 1.169165
 739466/1000000: episode: 7395, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.856, mean reward: 0.579 [0.501, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.799, 10.197], loss: 0.001428, mae: 0.041579, mean_q: 1.167659
 739566/1000000: episode: 7396, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.232, mean reward: 0.582 [0.507, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.084, 10.098], loss: 0.001370, mae: 0.040571, mean_q: 1.170703
 739666/1000000: episode: 7397, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 55.263, mean reward: 0.553 [0.504, 0.664], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.578, 10.098], loss: 0.001404, mae: 0.040866, mean_q: 1.170825
 739766/1000000: episode: 7398, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.541, mean reward: 0.585 [0.499, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.973, 10.098], loss: 0.001470, mae: 0.041735, mean_q: 1.164648
 739866/1000000: episode: 7399, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.086, mean reward: 0.591 [0.518, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.562, 10.098], loss: 0.001466, mae: 0.041600, mean_q: 1.168543
 739966/1000000: episode: 7400, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.606, mean reward: 0.576 [0.510, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.602, 10.098], loss: 0.001566, mae: 0.043440, mean_q: 1.169942
 740066/1000000: episode: 7401, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 62.477, mean reward: 0.625 [0.506, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.632, 10.098], loss: 0.001472, mae: 0.042098, mean_q: 1.164620
 740166/1000000: episode: 7402, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 57.662, mean reward: 0.577 [0.501, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.521, 10.098], loss: 0.001520, mae: 0.042330, mean_q: 1.167778
 740266/1000000: episode: 7403, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.979, mean reward: 0.610 [0.502, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.135, 10.098], loss: 0.001427, mae: 0.041390, mean_q: 1.164610
 740366/1000000: episode: 7404, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.919, mean reward: 0.589 [0.502, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.823, 10.358], loss: 0.001467, mae: 0.041804, mean_q: 1.164461
 740466/1000000: episode: 7405, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 60.368, mean reward: 0.604 [0.511, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.895, 10.210], loss: 0.001483, mae: 0.041914, mean_q: 1.164922
 740566/1000000: episode: 7406, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.165, mean reward: 0.602 [0.499, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.276, 10.098], loss: 0.001534, mae: 0.042684, mean_q: 1.170358
 740666/1000000: episode: 7407, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 61.422, mean reward: 0.614 [0.499, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.003, 10.105], loss: 0.001440, mae: 0.041174, mean_q: 1.167510
 740766/1000000: episode: 7408, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.718, mean reward: 0.587 [0.507, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.288, 10.244], loss: 0.001434, mae: 0.041180, mean_q: 1.165933
 740866/1000000: episode: 7409, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.845, mean reward: 0.588 [0.510, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.762, 10.098], loss: 0.001446, mae: 0.041441, mean_q: 1.169334
 740966/1000000: episode: 7410, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.483, mean reward: 0.585 [0.498, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.325, 10.098], loss: 0.001348, mae: 0.039804, mean_q: 1.163562
 741066/1000000: episode: 7411, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.990, mean reward: 0.580 [0.512, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.366, 10.154], loss: 0.001502, mae: 0.041985, mean_q: 1.169389
 741166/1000000: episode: 7412, duration: 0.520s, episode steps: 100, steps per second: 192, episode reward: 59.220, mean reward: 0.592 [0.501, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.546, 10.098], loss: 0.001421, mae: 0.041056, mean_q: 1.163947
 741266/1000000: episode: 7413, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.355, mean reward: 0.574 [0.505, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.830, 10.201], loss: 0.001523, mae: 0.042350, mean_q: 1.168168
 741366/1000000: episode: 7414, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.408, mean reward: 0.584 [0.498, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.901, 10.385], loss: 0.001413, mae: 0.041128, mean_q: 1.166480
 741466/1000000: episode: 7415, duration: 0.618s, episode steps: 100, steps per second: 162, episode reward: 59.554, mean reward: 0.596 [0.497, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.139, 10.098], loss: 0.001428, mae: 0.040973, mean_q: 1.163229
 741566/1000000: episode: 7416, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.901, mean reward: 0.599 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.313, 10.422], loss: 0.001536, mae: 0.042425, mean_q: 1.167565
 741666/1000000: episode: 7417, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.029, mean reward: 0.580 [0.512, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.502, 10.098], loss: 0.001415, mae: 0.041253, mean_q: 1.169194
 741766/1000000: episode: 7418, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.471, mean reward: 0.585 [0.509, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.901, 10.098], loss: 0.001450, mae: 0.041531, mean_q: 1.164029
 741866/1000000: episode: 7419, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.967, mean reward: 0.590 [0.511, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.561, 10.174], loss: 0.001609, mae: 0.043247, mean_q: 1.161547
 741966/1000000: episode: 7420, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.904, mean reward: 0.579 [0.510, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.888, 10.098], loss: 0.001566, mae: 0.042594, mean_q: 1.164836
 742066/1000000: episode: 7421, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.533, mean reward: 0.595 [0.502, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.771, 10.098], loss: 0.001482, mae: 0.042020, mean_q: 1.166230
 742166/1000000: episode: 7422, duration: 0.528s, episode steps: 100, steps per second: 190, episode reward: 58.481, mean reward: 0.585 [0.505, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.565, 10.277], loss: 0.001427, mae: 0.041185, mean_q: 1.159934
 742266/1000000: episode: 7423, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.855, mean reward: 0.579 [0.507, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.351, 10.098], loss: 0.001370, mae: 0.040455, mean_q: 1.162344
 742366/1000000: episode: 7424, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 63.274, mean reward: 0.633 [0.501, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.475, 10.350], loss: 0.001422, mae: 0.040822, mean_q: 1.160233
 742466/1000000: episode: 7425, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.812, mean reward: 0.578 [0.506, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.079, 10.299], loss: 0.001401, mae: 0.040873, mean_q: 1.160347
 742566/1000000: episode: 7426, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.589, mean reward: 0.596 [0.506, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.230, 10.133], loss: 0.001448, mae: 0.041751, mean_q: 1.162416
 742666/1000000: episode: 7427, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.014, mean reward: 0.600 [0.513, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.607, 10.295], loss: 0.001448, mae: 0.041384, mean_q: 1.166939
 742766/1000000: episode: 7428, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.466, mean reward: 0.575 [0.501, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.699, 10.149], loss: 0.001489, mae: 0.042482, mean_q: 1.165307
 742866/1000000: episode: 7429, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.696, mean reward: 0.577 [0.513, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.586, 10.123], loss: 0.001539, mae: 0.042364, mean_q: 1.166490
 742966/1000000: episode: 7430, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.335, mean reward: 0.593 [0.504, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.852, 10.098], loss: 0.001458, mae: 0.042010, mean_q: 1.165524
 743066/1000000: episode: 7431, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.680, mean reward: 0.577 [0.500, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.156, 10.146], loss: 0.001514, mae: 0.042492, mean_q: 1.166513
 743166/1000000: episode: 7432, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.835, mean reward: 0.578 [0.507, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.611, 10.098], loss: 0.001446, mae: 0.041599, mean_q: 1.163016
 743266/1000000: episode: 7433, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 61.230, mean reward: 0.612 [0.509, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.910, 10.098], loss: 0.001540, mae: 0.042683, mean_q: 1.164594
 743366/1000000: episode: 7434, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.372, mean reward: 0.584 [0.511, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.478, 10.098], loss: 0.001473, mae: 0.041933, mean_q: 1.164083
 743466/1000000: episode: 7435, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.729, mean reward: 0.587 [0.509, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.709, 10.098], loss: 0.001566, mae: 0.042450, mean_q: 1.166221
 743566/1000000: episode: 7436, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.010, mean reward: 0.590 [0.512, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.150, 10.238], loss: 0.001352, mae: 0.040259, mean_q: 1.164984
 743666/1000000: episode: 7437, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.502, mean reward: 0.575 [0.508, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.105, 10.268], loss: 0.001491, mae: 0.041610, mean_q: 1.165524
 743766/1000000: episode: 7438, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.521, mean reward: 0.615 [0.507, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-2.102, 10.098], loss: 0.001485, mae: 0.041833, mean_q: 1.166699
 743866/1000000: episode: 7439, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.848, mean reward: 0.588 [0.499, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.167, 10.098], loss: 0.001456, mae: 0.041467, mean_q: 1.168416
 743966/1000000: episode: 7440, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.278, mean reward: 0.583 [0.503, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.904, 10.462], loss: 0.001527, mae: 0.042411, mean_q: 1.164999
 744066/1000000: episode: 7441, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.758, mean reward: 0.578 [0.505, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.692, 10.150], loss: 0.001380, mae: 0.040380, mean_q: 1.165078
 744166/1000000: episode: 7442, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 59.498, mean reward: 0.595 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.453, 10.098], loss: 0.001398, mae: 0.039974, mean_q: 1.163272
 744266/1000000: episode: 7443, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.663, mean reward: 0.577 [0.506, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.851, 10.098], loss: 0.001501, mae: 0.042297, mean_q: 1.169086
 744366/1000000: episode: 7444, duration: 0.523s, episode steps: 100, steps per second: 191, episode reward: 58.636, mean reward: 0.586 [0.502, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.031, 10.166], loss: 0.001469, mae: 0.041544, mean_q: 1.166329
 744466/1000000: episode: 7445, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.888, mean reward: 0.589 [0.511, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.925, 10.297], loss: 0.001440, mae: 0.041370, mean_q: 1.167022
 744566/1000000: episode: 7446, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.015, mean reward: 0.590 [0.502, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.345, 10.098], loss: 0.001485, mae: 0.041722, mean_q: 1.165061
 744666/1000000: episode: 7447, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.957, mean reward: 0.590 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.928, 10.378], loss: 0.001501, mae: 0.042339, mean_q: 1.168795
 744766/1000000: episode: 7448, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.178, mean reward: 0.582 [0.498, 0.869], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.116, 10.265], loss: 0.001400, mae: 0.040662, mean_q: 1.168563
 744866/1000000: episode: 7449, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.626, mean reward: 0.586 [0.514, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.515, 10.254], loss: 0.001312, mae: 0.039607, mean_q: 1.165729
 744966/1000000: episode: 7450, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.725, mean reward: 0.587 [0.518, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.722, 10.144], loss: 0.001504, mae: 0.041745, mean_q: 1.166429
 745066/1000000: episode: 7451, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.360, mean reward: 0.594 [0.507, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.985, 10.168], loss: 0.001422, mae: 0.041097, mean_q: 1.166036
 745166/1000000: episode: 7452, duration: 0.610s, episode steps: 100, steps per second: 164, episode reward: 61.526, mean reward: 0.615 [0.498, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.497, 10.098], loss: 0.001359, mae: 0.040133, mean_q: 1.163968
 745266/1000000: episode: 7453, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 62.269, mean reward: 0.623 [0.507, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.746, 10.302], loss: 0.001434, mae: 0.041281, mean_q: 1.169398
 745366/1000000: episode: 7454, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.983, mean reward: 0.610 [0.515, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.187, 10.098], loss: 0.001451, mae: 0.041496, mean_q: 1.163789
 745466/1000000: episode: 7455, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.268, mean reward: 0.573 [0.500, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.560, 10.153], loss: 0.001447, mae: 0.040498, mean_q: 1.168330
 745566/1000000: episode: 7456, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.526, mean reward: 0.605 [0.525, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.742, 10.142], loss: 0.001525, mae: 0.042397, mean_q: 1.169411
 745666/1000000: episode: 7457, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.331, mean reward: 0.573 [0.503, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.874, 10.098], loss: 0.001411, mae: 0.041089, mean_q: 1.167351
 745766/1000000: episode: 7458, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 61.858, mean reward: 0.619 [0.516, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.628, 10.235], loss: 0.001492, mae: 0.041282, mean_q: 1.168013
 745866/1000000: episode: 7459, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.919, mean reward: 0.579 [0.512, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.016, 10.098], loss: 0.001446, mae: 0.040395, mean_q: 1.168795
 745966/1000000: episode: 7460, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.352, mean reward: 0.584 [0.499, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.968, 10.105], loss: 0.001389, mae: 0.040287, mean_q: 1.168329
 746066/1000000: episode: 7461, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 61.450, mean reward: 0.615 [0.506, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.477, 10.153], loss: 0.001452, mae: 0.040765, mean_q: 1.168613
 746166/1000000: episode: 7462, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 64.366, mean reward: 0.644 [0.506, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.331, 10.098], loss: 0.001407, mae: 0.040087, mean_q: 1.166130
 746266/1000000: episode: 7463, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.875, mean reward: 0.589 [0.507, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.805, 10.098], loss: 0.001406, mae: 0.040394, mean_q: 1.173470
 746366/1000000: episode: 7464, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 61.998, mean reward: 0.620 [0.503, 0.927], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.713, 10.098], loss: 0.001414, mae: 0.040978, mean_q: 1.172500
 746466/1000000: episode: 7465, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.620, mean reward: 0.596 [0.526, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.952, 10.267], loss: 0.001418, mae: 0.040185, mean_q: 1.173413
 746566/1000000: episode: 7466, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.603, mean reward: 0.606 [0.508, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.061, 10.156], loss: 0.001353, mae: 0.039697, mean_q: 1.171287
 746666/1000000: episode: 7467, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.518, mean reward: 0.615 [0.514, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.961, 10.098], loss: 0.001538, mae: 0.042102, mean_q: 1.176486
 746766/1000000: episode: 7468, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.887, mean reward: 0.619 [0.502, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.979, 10.098], loss: 0.001470, mae: 0.041667, mean_q: 1.175249
 746866/1000000: episode: 7469, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.559, mean reward: 0.606 [0.508, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.477, 10.098], loss: 0.001408, mae: 0.040577, mean_q: 1.173966
 746966/1000000: episode: 7470, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 59.651, mean reward: 0.597 [0.509, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.498, 10.098], loss: 0.001389, mae: 0.040439, mean_q: 1.175795
 747066/1000000: episode: 7471, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.515, mean reward: 0.575 [0.506, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.029, 10.190], loss: 0.001403, mae: 0.040707, mean_q: 1.179063
 747166/1000000: episode: 7472, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.414, mean reward: 0.594 [0.511, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.169, 10.321], loss: 0.001418, mae: 0.040509, mean_q: 1.172386
 747266/1000000: episode: 7473, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.821, mean reward: 0.588 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.426, 10.125], loss: 0.001476, mae: 0.041342, mean_q: 1.176247
 747366/1000000: episode: 7474, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.060, mean reward: 0.601 [0.511, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.227, 10.273], loss: 0.001464, mae: 0.040469, mean_q: 1.176410
 747466/1000000: episode: 7475, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 62.295, mean reward: 0.623 [0.515, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.447, 10.348], loss: 0.001350, mae: 0.040010, mean_q: 1.179096
 747566/1000000: episode: 7476, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 63.714, mean reward: 0.637 [0.504, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.143, 10.169], loss: 0.001328, mae: 0.039147, mean_q: 1.177247
 747666/1000000: episode: 7477, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 58.796, mean reward: 0.588 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.933, 10.329], loss: 0.001423, mae: 0.040408, mean_q: 1.178098
 747766/1000000: episode: 7478, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 59.504, mean reward: 0.595 [0.508, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.296, 10.245], loss: 0.001347, mae: 0.039680, mean_q: 1.176448
 747866/1000000: episode: 7479, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.850, mean reward: 0.618 [0.505, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.553, 10.098], loss: 0.001441, mae: 0.040512, mean_q: 1.180394
 747966/1000000: episode: 7480, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.567, mean reward: 0.586 [0.503, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.718, 10.098], loss: 0.001371, mae: 0.039637, mean_q: 1.180914
 748066/1000000: episode: 7481, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.196, mean reward: 0.592 [0.501, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.562, 10.098], loss: 0.001408, mae: 0.040511, mean_q: 1.181482
 748166/1000000: episode: 7482, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.754, mean reward: 0.588 [0.509, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.464, 10.098], loss: 0.001483, mae: 0.040680, mean_q: 1.178212
 748266/1000000: episode: 7483, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.583, mean reward: 0.586 [0.505, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.616, 10.190], loss: 0.001435, mae: 0.040350, mean_q: 1.180471
 748366/1000000: episode: 7484, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.979, mean reward: 0.590 [0.518, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.711, 10.305], loss: 0.001396, mae: 0.040085, mean_q: 1.176522
 748466/1000000: episode: 7485, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.434, mean reward: 0.594 [0.505, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.082, 10.098], loss: 0.001449, mae: 0.040173, mean_q: 1.179993
 748566/1000000: episode: 7486, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.397, mean reward: 0.574 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.548, 10.129], loss: 0.001415, mae: 0.040375, mean_q: 1.179246
 748666/1000000: episode: 7487, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.940, mean reward: 0.589 [0.507, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.102, 10.098], loss: 0.001516, mae: 0.041844, mean_q: 1.180417
 748766/1000000: episode: 7488, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 66.384, mean reward: 0.664 [0.500, 0.871], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.374, 10.505], loss: 0.001393, mae: 0.040779, mean_q: 1.178234
 748866/1000000: episode: 7489, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.472, mean reward: 0.595 [0.505, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.429, 10.167], loss: 0.001477, mae: 0.041277, mean_q: 1.183712
 748966/1000000: episode: 7490, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.962, mean reward: 0.580 [0.500, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.092, 10.173], loss: 0.001463, mae: 0.041302, mean_q: 1.184441
 749066/1000000: episode: 7491, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 58.680, mean reward: 0.587 [0.516, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.500, 10.354], loss: 0.001567, mae: 0.041957, mean_q: 1.184163
 749166/1000000: episode: 7492, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.916, mean reward: 0.589 [0.503, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.082, 10.163], loss: 0.001494, mae: 0.041294, mean_q: 1.186082
 749266/1000000: episode: 7493, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.047, mean reward: 0.580 [0.499, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.066, 10.098], loss: 0.001492, mae: 0.041383, mean_q: 1.187192
 749366/1000000: episode: 7494, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 55.774, mean reward: 0.558 [0.503, 0.666], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.647, 10.098], loss: 0.001479, mae: 0.040618, mean_q: 1.184017
 749466/1000000: episode: 7495, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 60.324, mean reward: 0.603 [0.504, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.067, 10.182], loss: 0.001517, mae: 0.041112, mean_q: 1.182874
 749566/1000000: episode: 7496, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.306, mean reward: 0.603 [0.504, 0.865], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.503, 10.098], loss: 0.001492, mae: 0.041148, mean_q: 1.181481
 749666/1000000: episode: 7497, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.291, mean reward: 0.593 [0.505, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.008, 10.098], loss: 0.001473, mae: 0.041591, mean_q: 1.183920
 749766/1000000: episode: 7498, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.254, mean reward: 0.593 [0.512, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.726, 10.422], loss: 0.001511, mae: 0.041495, mean_q: 1.183441
 749866/1000000: episode: 7499, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.169, mean reward: 0.582 [0.506, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.153, 10.098], loss: 0.001429, mae: 0.041172, mean_q: 1.181187
 749966/1000000: episode: 7500, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.257, mean reward: 0.583 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.323, 10.170], loss: 0.001453, mae: 0.041476, mean_q: 1.183705
 750066/1000000: episode: 7501, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.094, mean reward: 0.591 [0.509, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.349, 10.286], loss: 0.001534, mae: 0.042334, mean_q: 1.183794
 750166/1000000: episode: 7502, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 60.438, mean reward: 0.604 [0.506, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.298, 10.098], loss: 0.001433, mae: 0.041071, mean_q: 1.182185
 750266/1000000: episode: 7503, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.893, mean reward: 0.599 [0.509, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.737, 10.098], loss: 0.001453, mae: 0.041044, mean_q: 1.180666
 750366/1000000: episode: 7504, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.663, mean reward: 0.597 [0.505, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.428, 10.098], loss: 0.001622, mae: 0.042909, mean_q: 1.182761
 750466/1000000: episode: 7505, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.731, mean reward: 0.587 [0.510, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.579, 10.151], loss: 0.001464, mae: 0.041482, mean_q: 1.185187
 750566/1000000: episode: 7506, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.412, mean reward: 0.594 [0.516, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.813, 10.098], loss: 0.001501, mae: 0.041628, mean_q: 1.179851
 750666/1000000: episode: 7507, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.567, mean reward: 0.596 [0.503, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.912, 10.172], loss: 0.001529, mae: 0.042117, mean_q: 1.182643
 750766/1000000: episode: 7508, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.929, mean reward: 0.579 [0.503, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.991, 10.153], loss: 0.001473, mae: 0.041552, mean_q: 1.185727
 750866/1000000: episode: 7509, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.217, mean reward: 0.592 [0.517, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.389, 10.221], loss: 0.001605, mae: 0.042937, mean_q: 1.180442
 750966/1000000: episode: 7510, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.099, mean reward: 0.571 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.024, 10.098], loss: 0.001598, mae: 0.043289, mean_q: 1.182577
 751066/1000000: episode: 7511, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.759, mean reward: 0.578 [0.501, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.558, 10.098], loss: 0.001530, mae: 0.041606, mean_q: 1.181258
 751166/1000000: episode: 7512, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.201, mean reward: 0.602 [0.503, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.924, 10.098], loss: 0.001556, mae: 0.042598, mean_q: 1.180708
 751266/1000000: episode: 7513, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.632, mean reward: 0.576 [0.502, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.726, 10.098], loss: 0.001569, mae: 0.042642, mean_q: 1.180655
 751366/1000000: episode: 7514, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.438, mean reward: 0.604 [0.497, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.870, 10.098], loss: 0.001482, mae: 0.041564, mean_q: 1.178201
 751466/1000000: episode: 7515, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.018, mean reward: 0.580 [0.509, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.154, 10.351], loss: 0.001479, mae: 0.041146, mean_q: 1.176582
 751566/1000000: episode: 7516, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.915, mean reward: 0.619 [0.513, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.253, 10.391], loss: 0.001523, mae: 0.042194, mean_q: 1.174858
 751666/1000000: episode: 7517, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.948, mean reward: 0.609 [0.508, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.567, 10.098], loss: 0.001446, mae: 0.041168, mean_q: 1.180973
 751766/1000000: episode: 7518, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 61.098, mean reward: 0.611 [0.510, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.270, 10.098], loss: 0.001531, mae: 0.041114, mean_q: 1.176641
 751866/1000000: episode: 7519, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.451, mean reward: 0.585 [0.507, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.060, 10.103], loss: 0.001481, mae: 0.041523, mean_q: 1.174020
 751966/1000000: episode: 7520, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.173, mean reward: 0.602 [0.508, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.263, 10.098], loss: 0.001496, mae: 0.041782, mean_q: 1.176256
 752066/1000000: episode: 7521, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.611, mean reward: 0.586 [0.506, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.676, 10.098], loss: 0.001441, mae: 0.040638, mean_q: 1.177707
 752166/1000000: episode: 7522, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.833, mean reward: 0.588 [0.506, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.698, 10.187], loss: 0.001517, mae: 0.041777, mean_q: 1.177395
 752266/1000000: episode: 7523, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.475, mean reward: 0.575 [0.508, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.589, 10.264], loss: 0.001496, mae: 0.041446, mean_q: 1.173847
 752366/1000000: episode: 7524, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.340, mean reward: 0.573 [0.508, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.719, 10.256], loss: 0.001534, mae: 0.041466, mean_q: 1.176691
 752466/1000000: episode: 7525, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 59.418, mean reward: 0.594 [0.514, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.798, 10.098], loss: 0.001463, mae: 0.040622, mean_q: 1.173408
 752566/1000000: episode: 7526, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.283, mean reward: 0.583 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.668, 10.267], loss: 0.001458, mae: 0.041481, mean_q: 1.173065
 752666/1000000: episode: 7527, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.209, mean reward: 0.572 [0.502, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.633, 10.116], loss: 0.001398, mae: 0.040555, mean_q: 1.170535
 752766/1000000: episode: 7528, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.369, mean reward: 0.594 [0.517, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.747, 10.259], loss: 0.001463, mae: 0.041404, mean_q: 1.170838
 752866/1000000: episode: 7529, duration: 0.635s, episode steps: 100, steps per second: 158, episode reward: 59.771, mean reward: 0.598 [0.511, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.878, 10.172], loss: 0.001522, mae: 0.042026, mean_q: 1.168452
 752966/1000000: episode: 7530, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 62.286, mean reward: 0.623 [0.512, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.206, 10.441], loss: 0.001553, mae: 0.041827, mean_q: 1.169186
 753066/1000000: episode: 7531, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.457, mean reward: 0.585 [0.502, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.560, 10.207], loss: 0.001535, mae: 0.042433, mean_q: 1.168439
 753166/1000000: episode: 7532, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.222, mean reward: 0.602 [0.506, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.454, 10.346], loss: 0.001560, mae: 0.042683, mean_q: 1.167845
 753266/1000000: episode: 7533, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.141, mean reward: 0.601 [0.505, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.136, 10.388], loss: 0.001587, mae: 0.043410, mean_q: 1.170774
 753366/1000000: episode: 7534, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 61.637, mean reward: 0.616 [0.516, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.203, 10.098], loss: 0.001551, mae: 0.042263, mean_q: 1.173032
 753466/1000000: episode: 7535, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.893, mean reward: 0.589 [0.506, 0.905], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.087, 10.168], loss: 0.001447, mae: 0.040697, mean_q: 1.172357
 753566/1000000: episode: 7536, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.395, mean reward: 0.584 [0.503, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.050, 10.102], loss: 0.001559, mae: 0.042022, mean_q: 1.174281
 753666/1000000: episode: 7537, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.956, mean reward: 0.590 [0.511, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.824, 10.098], loss: 0.001547, mae: 0.042269, mean_q: 1.175069
 753766/1000000: episode: 7538, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.154, mean reward: 0.582 [0.501, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.892, 10.177], loss: 0.001578, mae: 0.042586, mean_q: 1.171565
 753866/1000000: episode: 7539, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.239, mean reward: 0.572 [0.510, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.019, 10.098], loss: 0.001498, mae: 0.041435, mean_q: 1.170583
 753966/1000000: episode: 7540, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.519, mean reward: 0.595 [0.513, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.665, 10.098], loss: 0.001517, mae: 0.042432, mean_q: 1.168594
 754066/1000000: episode: 7541, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 62.615, mean reward: 0.626 [0.517, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.279, 10.362], loss: 0.001438, mae: 0.040756, mean_q: 1.171122
 754166/1000000: episode: 7542, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 64.298, mean reward: 0.643 [0.512, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.097, 10.098], loss: 0.001494, mae: 0.041347, mean_q: 1.168322
 754266/1000000: episode: 7543, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.779, mean reward: 0.578 [0.504, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.457, 10.098], loss: 0.001580, mae: 0.042715, mean_q: 1.172791
 754366/1000000: episode: 7544, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.728, mean reward: 0.587 [0.506, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.624, 10.203], loss: 0.001514, mae: 0.041799, mean_q: 1.175584
 754466/1000000: episode: 7545, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 61.624, mean reward: 0.616 [0.510, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.896, 10.098], loss: 0.001541, mae: 0.042597, mean_q: 1.176908
 754566/1000000: episode: 7546, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.575, mean reward: 0.596 [0.509, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.322, 10.098], loss: 0.001490, mae: 0.041454, mean_q: 1.174757
 754666/1000000: episode: 7547, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.240, mean reward: 0.582 [0.500, 0.846], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.933, 10.098], loss: 0.001571, mae: 0.042864, mean_q: 1.176706
 754766/1000000: episode: 7548, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.736, mean reward: 0.577 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.691, 10.098], loss: 0.001502, mae: 0.041660, mean_q: 1.173637
 754866/1000000: episode: 7549, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.507, mean reward: 0.575 [0.499, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.698, 10.231], loss: 0.001597, mae: 0.042884, mean_q: 1.175643
 754966/1000000: episode: 7550, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.011, mean reward: 0.580 [0.503, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.322, 10.233], loss: 0.001562, mae: 0.042138, mean_q: 1.172832
 755066/1000000: episode: 7551, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 63.840, mean reward: 0.638 [0.506, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.967, 10.530], loss: 0.001711, mae: 0.043955, mean_q: 1.179030
 755166/1000000: episode: 7552, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 60.008, mean reward: 0.600 [0.503, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.070, 10.098], loss: 0.001585, mae: 0.042651, mean_q: 1.176642
 755266/1000000: episode: 7553, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 61.318, mean reward: 0.613 [0.511, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.431, 10.098], loss: 0.001499, mae: 0.041317, mean_q: 1.178172
 755366/1000000: episode: 7554, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.971, mean reward: 0.590 [0.503, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.958, 10.098], loss: 0.001596, mae: 0.042570, mean_q: 1.177178
 755466/1000000: episode: 7555, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.341, mean reward: 0.573 [0.504, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.969, 10.134], loss: 0.001530, mae: 0.042280, mean_q: 1.174691
 755566/1000000: episode: 7556, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.258, mean reward: 0.583 [0.499, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.739, 10.219], loss: 0.001496, mae: 0.042092, mean_q: 1.176565
 755666/1000000: episode: 7557, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.730, mean reward: 0.607 [0.517, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.164, 10.098], loss: 0.001640, mae: 0.043676, mean_q: 1.177732
 755766/1000000: episode: 7558, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.287, mean reward: 0.583 [0.506, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.615, 10.098], loss: 0.001610, mae: 0.043553, mean_q: 1.175380
 755866/1000000: episode: 7559, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.834, mean reward: 0.578 [0.505, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.845, 10.156], loss: 0.001535, mae: 0.042785, mean_q: 1.176152
 755966/1000000: episode: 7560, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.430, mean reward: 0.574 [0.499, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.485, 10.201], loss: 0.001451, mae: 0.041107, mean_q: 1.176982
 756066/1000000: episode: 7561, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 60.294, mean reward: 0.603 [0.504, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.284, 10.344], loss: 0.001551, mae: 0.042416, mean_q: 1.175896
 756166/1000000: episode: 7562, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.395, mean reward: 0.584 [0.506, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.404, 10.270], loss: 0.001396, mae: 0.040285, mean_q: 1.175294
 756266/1000000: episode: 7563, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.518, mean reward: 0.605 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.632, 10.181], loss: 0.001523, mae: 0.042311, mean_q: 1.178151
 756366/1000000: episode: 7564, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.732, mean reward: 0.587 [0.505, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.692, 10.098], loss: 0.001520, mae: 0.042188, mean_q: 1.172774
 756466/1000000: episode: 7565, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.183, mean reward: 0.572 [0.501, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.493, 10.098], loss: 0.001398, mae: 0.040531, mean_q: 1.176011
 756566/1000000: episode: 7566, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.831, mean reward: 0.578 [0.503, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.916, 10.165], loss: 0.001446, mae: 0.041628, mean_q: 1.174293
 756666/1000000: episode: 7567, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.118, mean reward: 0.581 [0.499, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.313, 10.149], loss: 0.001437, mae: 0.041650, mean_q: 1.171847
 756766/1000000: episode: 7568, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.400, mean reward: 0.584 [0.503, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.865, 10.156], loss: 0.001622, mae: 0.043601, mean_q: 1.171724
 756866/1000000: episode: 7569, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.281, mean reward: 0.583 [0.504, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.516, 10.249], loss: 0.001484, mae: 0.041631, mean_q: 1.171638
 756966/1000000: episode: 7570, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 61.074, mean reward: 0.611 [0.514, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.930, 10.098], loss: 0.001465, mae: 0.041739, mean_q: 1.169338
 757066/1000000: episode: 7571, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.473, mean reward: 0.585 [0.521, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.290, 10.250], loss: 0.001505, mae: 0.042168, mean_q: 1.171696
 757166/1000000: episode: 7572, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.639, mean reward: 0.596 [0.506, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.514, 10.262], loss: 0.001477, mae: 0.041553, mean_q: 1.172141
 757266/1000000: episode: 7573, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 56.372, mean reward: 0.564 [0.507, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.560, 10.098], loss: 0.001526, mae: 0.041977, mean_q: 1.173570
 757366/1000000: episode: 7574, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.945, mean reward: 0.579 [0.510, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.195, 10.098], loss: 0.001473, mae: 0.041307, mean_q: 1.171264
 757466/1000000: episode: 7575, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.175, mean reward: 0.592 [0.506, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.730, 10.098], loss: 0.001452, mae: 0.041292, mean_q: 1.170504
 757566/1000000: episode: 7576, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.575, mean reward: 0.586 [0.504, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.137, 10.359], loss: 0.001440, mae: 0.041073, mean_q: 1.174227
 757666/1000000: episode: 7577, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.416, mean reward: 0.564 [0.504, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.258, 10.098], loss: 0.001422, mae: 0.040861, mean_q: 1.169839
 757766/1000000: episode: 7578, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.194, mean reward: 0.572 [0.505, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.830, 10.209], loss: 0.001429, mae: 0.040905, mean_q: 1.169244
 757866/1000000: episode: 7579, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.187, mean reward: 0.582 [0.499, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.376, 10.098], loss: 0.001447, mae: 0.041587, mean_q: 1.169935
 757966/1000000: episode: 7580, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.414, mean reward: 0.574 [0.500, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.891, 10.156], loss: 0.001533, mae: 0.042344, mean_q: 1.169903
 758066/1000000: episode: 7581, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.479, mean reward: 0.585 [0.506, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.318, 10.190], loss: 0.001492, mae: 0.042450, mean_q: 1.171160
 758166/1000000: episode: 7582, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.096, mean reward: 0.591 [0.502, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.260, 10.122], loss: 0.001524, mae: 0.042361, mean_q: 1.166917
 758266/1000000: episode: 7583, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.611, mean reward: 0.596 [0.498, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.745, 10.364], loss: 0.001513, mae: 0.042243, mean_q: 1.169164
 758366/1000000: episode: 7584, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.209, mean reward: 0.592 [0.500, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.102, 10.098], loss: 0.001545, mae: 0.043255, mean_q: 1.165161
 758466/1000000: episode: 7585, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.099, mean reward: 0.571 [0.506, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.973, 10.215], loss: 0.001460, mae: 0.042103, mean_q: 1.160826
 758566/1000000: episode: 7586, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.856, mean reward: 0.599 [0.510, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.681, 10.098], loss: 0.001469, mae: 0.041793, mean_q: 1.162392
 758666/1000000: episode: 7587, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.650, mean reward: 0.587 [0.501, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.159, 10.171], loss: 0.001577, mae: 0.043096, mean_q: 1.167663
 758766/1000000: episode: 7588, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.179, mean reward: 0.582 [0.509, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.629, 10.156], loss: 0.001559, mae: 0.042561, mean_q: 1.164933
 758866/1000000: episode: 7589, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.288, mean reward: 0.603 [0.509, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.706, 10.240], loss: 0.001505, mae: 0.042465, mean_q: 1.166375
 758966/1000000: episode: 7590, duration: 0.608s, episode steps: 100, steps per second: 164, episode reward: 59.832, mean reward: 0.598 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.318, 10.098], loss: 0.001465, mae: 0.042036, mean_q: 1.165729
 759066/1000000: episode: 7591, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.197, mean reward: 0.572 [0.508, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.348, 10.098], loss: 0.001446, mae: 0.041290, mean_q: 1.167114
 759166/1000000: episode: 7592, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.203, mean reward: 0.582 [0.507, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.521, 10.098], loss: 0.001424, mae: 0.041069, mean_q: 1.163388
 759266/1000000: episode: 7593, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.799, mean reward: 0.578 [0.502, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.773, 10.131], loss: 0.001567, mae: 0.042848, mean_q: 1.164607
 759366/1000000: episode: 7594, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.033, mean reward: 0.590 [0.510, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.231, 10.146], loss: 0.001486, mae: 0.041837, mean_q: 1.158696
 759466/1000000: episode: 7595, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.771, mean reward: 0.578 [0.500, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-2.267, 10.497], loss: 0.001378, mae: 0.040858, mean_q: 1.164712
 759566/1000000: episode: 7596, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 60.805, mean reward: 0.608 [0.502, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.844, 10.098], loss: 0.001491, mae: 0.042170, mean_q: 1.158747
 759666/1000000: episode: 7597, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.603, mean reward: 0.576 [0.501, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.418, 10.140], loss: 0.001455, mae: 0.041510, mean_q: 1.159723
 759766/1000000: episode: 7598, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.038, mean reward: 0.580 [0.507, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.589, 10.098], loss: 0.001477, mae: 0.042400, mean_q: 1.161296
 759866/1000000: episode: 7599, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.679, mean reward: 0.587 [0.510, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.931, 10.169], loss: 0.001454, mae: 0.041828, mean_q: 1.161618
 759966/1000000: episode: 7600, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.501, mean reward: 0.595 [0.499, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.397, 10.098], loss: 0.001434, mae: 0.041619, mean_q: 1.159733
 760066/1000000: episode: 7601, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.709, mean reward: 0.587 [0.502, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.283, 10.186], loss: 0.001478, mae: 0.042726, mean_q: 1.161775
 760166/1000000: episode: 7602, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.665, mean reward: 0.587 [0.507, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.901, 10.121], loss: 0.001465, mae: 0.042234, mean_q: 1.162996
 760266/1000000: episode: 7603, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.402, mean reward: 0.614 [0.508, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.521, 10.098], loss: 0.001383, mae: 0.041024, mean_q: 1.157573
 760366/1000000: episode: 7604, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.312, mean reward: 0.603 [0.508, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.429, 10.098], loss: 0.001420, mae: 0.041384, mean_q: 1.162353
 760466/1000000: episode: 7605, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: 58.406, mean reward: 0.584 [0.501, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.401, 10.143], loss: 0.001351, mae: 0.040357, mean_q: 1.161309
 760566/1000000: episode: 7606, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.930, mean reward: 0.599 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.416, 10.098], loss: 0.001420, mae: 0.041214, mean_q: 1.158537
 760666/1000000: episode: 7607, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.947, mean reward: 0.579 [0.503, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.035, 10.219], loss: 0.001358, mae: 0.040253, mean_q: 1.161348
 760766/1000000: episode: 7608, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.836, mean reward: 0.598 [0.499, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.775, 10.098], loss: 0.001408, mae: 0.041488, mean_q: 1.159997
 760866/1000000: episode: 7609, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.710, mean reward: 0.597 [0.503, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.454, 10.133], loss: 0.001421, mae: 0.041350, mean_q: 1.163504
 760966/1000000: episode: 7610, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.972, mean reward: 0.600 [0.508, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.211, 10.226], loss: 0.001455, mae: 0.041750, mean_q: 1.164469
 761066/1000000: episode: 7611, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.060, mean reward: 0.611 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.731, 10.387], loss: 0.001412, mae: 0.041378, mean_q: 1.162274
 761166/1000000: episode: 7612, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.814, mean reward: 0.578 [0.498, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.632, 10.272], loss: 0.001471, mae: 0.041671, mean_q: 1.163000
 761266/1000000: episode: 7613, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.044, mean reward: 0.580 [0.500, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.819, 10.166], loss: 0.001381, mae: 0.040757, mean_q: 1.162094
 761366/1000000: episode: 7614, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.258, mean reward: 0.593 [0.500, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.560, 10.098], loss: 0.001440, mae: 0.041922, mean_q: 1.162223
 761466/1000000: episode: 7615, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.104, mean reward: 0.571 [0.499, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.521, 10.148], loss: 0.001431, mae: 0.041229, mean_q: 1.163168
 761566/1000000: episode: 7616, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 60.953, mean reward: 0.610 [0.510, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.124, 10.098], loss: 0.001433, mae: 0.041516, mean_q: 1.162527
 761666/1000000: episode: 7617, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.729, mean reward: 0.587 [0.503, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.772, 10.149], loss: 0.001349, mae: 0.041104, mean_q: 1.165427
 761766/1000000: episode: 7618, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.389, mean reward: 0.604 [0.508, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.811, 10.386], loss: 0.001365, mae: 0.040812, mean_q: 1.163478
 761866/1000000: episode: 7619, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.781, mean reward: 0.598 [0.515, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.074, 10.098], loss: 0.001358, mae: 0.040004, mean_q: 1.165270
 761966/1000000: episode: 7620, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 58.604, mean reward: 0.586 [0.510, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.372, 10.203], loss: 0.001434, mae: 0.041459, mean_q: 1.165882
 762066/1000000: episode: 7621, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 56.514, mean reward: 0.565 [0.500, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.654, 10.134], loss: 0.001369, mae: 0.040627, mean_q: 1.162188
 762166/1000000: episode: 7622, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 62.094, mean reward: 0.621 [0.502, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.461, 10.354], loss: 0.001400, mae: 0.041007, mean_q: 1.162482
 762266/1000000: episode: 7623, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.270, mean reward: 0.593 [0.504, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.279, 10.446], loss: 0.001437, mae: 0.041620, mean_q: 1.164303
 762366/1000000: episode: 7624, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.031, mean reward: 0.570 [0.500, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.130, 10.105], loss: 0.001325, mae: 0.040503, mean_q: 1.167268
 762466/1000000: episode: 7625, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.665, mean reward: 0.587 [0.505, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.154, 10.153], loss: 0.001420, mae: 0.041551, mean_q: 1.166324
 762566/1000000: episode: 7626, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.083, mean reward: 0.591 [0.503, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.911, 10.098], loss: 0.001468, mae: 0.042178, mean_q: 1.163580
 762666/1000000: episode: 7627, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 55.885, mean reward: 0.559 [0.501, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.254, 10.225], loss: 0.001435, mae: 0.041808, mean_q: 1.164561
 762766/1000000: episode: 7628, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.169, mean reward: 0.582 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.795, 10.098], loss: 0.001452, mae: 0.042230, mean_q: 1.166083
 762866/1000000: episode: 7629, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.529, mean reward: 0.585 [0.501, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.684, 10.235], loss: 0.001446, mae: 0.042203, mean_q: 1.163658
 762966/1000000: episode: 7630, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 61.551, mean reward: 0.616 [0.519, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.808, 10.454], loss: 0.001392, mae: 0.040867, mean_q: 1.164477
 763066/1000000: episode: 7631, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.521, mean reward: 0.585 [0.504, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.355, 10.200], loss: 0.001440, mae: 0.041421, mean_q: 1.166408
 763166/1000000: episode: 7632, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.611, mean reward: 0.586 [0.508, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.906, 10.098], loss: 0.001469, mae: 0.041588, mean_q: 1.167632
 763266/1000000: episode: 7633, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.859, mean reward: 0.599 [0.503, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.847, 10.098], loss: 0.001381, mae: 0.040784, mean_q: 1.166793
 763366/1000000: episode: 7634, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 61.057, mean reward: 0.611 [0.510, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.798, 10.098], loss: 0.001384, mae: 0.040375, mean_q: 1.165649
 763466/1000000: episode: 7635, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 62.434, mean reward: 0.624 [0.505, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.769, 10.408], loss: 0.001511, mae: 0.043014, mean_q: 1.168636
 763566/1000000: episode: 7636, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.629, mean reward: 0.576 [0.505, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.730, 10.225], loss: 0.001369, mae: 0.040524, mean_q: 1.167901
 763666/1000000: episode: 7637, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 62.037, mean reward: 0.620 [0.512, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.925, 10.374], loss: 0.001485, mae: 0.042350, mean_q: 1.169493
 763766/1000000: episode: 7638, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.976, mean reward: 0.580 [0.520, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.451, 10.104], loss: 0.001385, mae: 0.041336, mean_q: 1.168488
 763866/1000000: episode: 7639, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.519, mean reward: 0.595 [0.508, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.316, 10.098], loss: 0.001424, mae: 0.042070, mean_q: 1.169207
 763966/1000000: episode: 7640, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 60.124, mean reward: 0.601 [0.506, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.459, 10.098], loss: 0.001284, mae: 0.039316, mean_q: 1.169306
 764066/1000000: episode: 7641, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.758, mean reward: 0.578 [0.508, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.383, 10.098], loss: 0.001349, mae: 0.040549, mean_q: 1.169095
 764166/1000000: episode: 7642, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.681, mean reward: 0.577 [0.501, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.708, 10.098], loss: 0.001434, mae: 0.041839, mean_q: 1.169605
 764266/1000000: episode: 7643, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.302, mean reward: 0.583 [0.505, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.498, 10.185], loss: 0.001421, mae: 0.041550, mean_q: 1.170250
 764366/1000000: episode: 7644, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 57.916, mean reward: 0.579 [0.516, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.606, 10.270], loss: 0.001370, mae: 0.040973, mean_q: 1.167293
 764466/1000000: episode: 7645, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.204, mean reward: 0.592 [0.509, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.004, 10.229], loss: 0.001420, mae: 0.041571, mean_q: 1.170171
 764566/1000000: episode: 7646, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.598, mean reward: 0.606 [0.514, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.710, 10.098], loss: 0.001387, mae: 0.040733, mean_q: 1.166665
 764666/1000000: episode: 7647, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.804, mean reward: 0.608 [0.529, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.443, 10.098], loss: 0.001460, mae: 0.041963, mean_q: 1.173957
 764766/1000000: episode: 7648, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.221, mean reward: 0.602 [0.516, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.688, 10.098], loss: 0.001471, mae: 0.041612, mean_q: 1.172175
 764866/1000000: episode: 7649, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.105, mean reward: 0.601 [0.504, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.555, 10.335], loss: 0.001420, mae: 0.040831, mean_q: 1.175691
 764966/1000000: episode: 7650, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.918, mean reward: 0.599 [0.509, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.678, 10.113], loss: 0.001355, mae: 0.040212, mean_q: 1.170563
 765066/1000000: episode: 7651, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.386, mean reward: 0.604 [0.501, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.788, 10.098], loss: 0.001341, mae: 0.039999, mean_q: 1.175193
 765166/1000000: episode: 7652, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 56.779, mean reward: 0.568 [0.500, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.749, 10.197], loss: 0.001351, mae: 0.040597, mean_q: 1.175909
 765266/1000000: episode: 7653, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.950, mean reward: 0.600 [0.508, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.738, 10.283], loss: 0.001483, mae: 0.041728, mean_q: 1.175229
 765366/1000000: episode: 7654, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.668, mean reward: 0.577 [0.501, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.734, 10.203], loss: 0.001339, mae: 0.040460, mean_q: 1.170137
 765466/1000000: episode: 7655, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.544, mean reward: 0.585 [0.508, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.620, 10.134], loss: 0.001415, mae: 0.041321, mean_q: 1.172108
 765566/1000000: episode: 7656, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.923, mean reward: 0.609 [0.510, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.566, 10.340], loss: 0.001339, mae: 0.040130, mean_q: 1.175276
 765666/1000000: episode: 7657, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.635, mean reward: 0.586 [0.507, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.468, 10.219], loss: 0.001364, mae: 0.040211, mean_q: 1.175066
 765766/1000000: episode: 7658, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 59.018, mean reward: 0.590 [0.510, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.656, 10.098], loss: 0.001358, mae: 0.040140, mean_q: 1.170305
 765866/1000000: episode: 7659, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 60.990, mean reward: 0.610 [0.513, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.823, 10.098], loss: 0.001357, mae: 0.039866, mean_q: 1.168762
 765966/1000000: episode: 7660, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 60.037, mean reward: 0.600 [0.513, 0.882], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.510, 10.140], loss: 0.001422, mae: 0.040724, mean_q: 1.172675
 766066/1000000: episode: 7661, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.096, mean reward: 0.581 [0.501, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.607, 10.116], loss: 0.001381, mae: 0.041085, mean_q: 1.168392
 766166/1000000: episode: 7662, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.196, mean reward: 0.592 [0.503, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.776, 10.134], loss: 0.001451, mae: 0.041178, mean_q: 1.172150
 766266/1000000: episode: 7663, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.957, mean reward: 0.590 [0.499, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.532, 10.098], loss: 0.001376, mae: 0.040347, mean_q: 1.173635
 766366/1000000: episode: 7664, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.954, mean reward: 0.580 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.327, 10.127], loss: 0.001464, mae: 0.041809, mean_q: 1.174773
 766466/1000000: episode: 7665, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.817, mean reward: 0.578 [0.501, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.619, 10.098], loss: 0.001406, mae: 0.040674, mean_q: 1.172723
 766566/1000000: episode: 7666, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 60.548, mean reward: 0.605 [0.510, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.860, 10.098], loss: 0.001442, mae: 0.041476, mean_q: 1.173244
 766666/1000000: episode: 7667, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.236, mean reward: 0.572 [0.503, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.755, 10.140], loss: 0.001471, mae: 0.042202, mean_q: 1.171637
 766766/1000000: episode: 7668, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 60.168, mean reward: 0.602 [0.517, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.297, 10.098], loss: 0.001346, mae: 0.039756, mean_q: 1.171417
 766866/1000000: episode: 7669, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.099, mean reward: 0.581 [0.509, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.747, 10.144], loss: 0.001494, mae: 0.042355, mean_q: 1.172233
 766966/1000000: episode: 7670, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.847, mean reward: 0.588 [0.501, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.490, 10.176], loss: 0.001426, mae: 0.041006, mean_q: 1.174547
 767066/1000000: episode: 7671, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.651, mean reward: 0.597 [0.510, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.554, 10.320], loss: 0.001379, mae: 0.040750, mean_q: 1.173235
 767166/1000000: episode: 7672, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.812, mean reward: 0.598 [0.505, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.433, 10.367], loss: 0.001430, mae: 0.041043, mean_q: 1.171471
 767266/1000000: episode: 7673, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.782, mean reward: 0.568 [0.506, 0.654], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.026, 10.098], loss: 0.001471, mae: 0.041570, mean_q: 1.171335
 767366/1000000: episode: 7674, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 58.705, mean reward: 0.587 [0.507, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.700, 10.200], loss: 0.001423, mae: 0.041048, mean_q: 1.169451
 767466/1000000: episode: 7675, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.930, mean reward: 0.599 [0.505, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-2.048, 10.098], loss: 0.001317, mae: 0.039258, mean_q: 1.168211
 767566/1000000: episode: 7676, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.897, mean reward: 0.579 [0.501, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.209, 10.098], loss: 0.001342, mae: 0.039914, mean_q: 1.169449
 767666/1000000: episode: 7677, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.290, mean reward: 0.593 [0.500, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.257, 10.148], loss: 0.001302, mae: 0.039526, mean_q: 1.171464
 767766/1000000: episode: 7678, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.630, mean reward: 0.576 [0.499, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.381, 10.098], loss: 0.001391, mae: 0.040201, mean_q: 1.171469
 767866/1000000: episode: 7679, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.231, mean reward: 0.582 [0.499, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.613, 10.197], loss: 0.001417, mae: 0.041192, mean_q: 1.173375
 767966/1000000: episode: 7680, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.561, mean reward: 0.606 [0.509, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.564, 10.402], loss: 0.001470, mae: 0.041674, mean_q: 1.173053
 768066/1000000: episode: 7681, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 64.418, mean reward: 0.644 [0.519, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.700, 10.285], loss: 0.001452, mae: 0.041305, mean_q: 1.171093
 768166/1000000: episode: 7682, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.804, mean reward: 0.598 [0.518, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.775, 10.365], loss: 0.001469, mae: 0.041672, mean_q: 1.173395
 768266/1000000: episode: 7683, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.921, mean reward: 0.589 [0.513, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.582, 10.185], loss: 0.001372, mae: 0.040291, mean_q: 1.173223
 768366/1000000: episode: 7684, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.532, mean reward: 0.565 [0.506, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.050, 10.185], loss: 0.001474, mae: 0.041855, mean_q: 1.171540
 768466/1000000: episode: 7685, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.406, mean reward: 0.604 [0.509, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.505, 10.098], loss: 0.001321, mae: 0.039835, mean_q: 1.172477
 768566/1000000: episode: 7686, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.690, mean reward: 0.587 [0.506, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.422, 10.149], loss: 0.001446, mae: 0.041206, mean_q: 1.172828
 768666/1000000: episode: 7687, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 57.857, mean reward: 0.579 [0.501, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.617, 10.234], loss: 0.001496, mae: 0.041755, mean_q: 1.172245
 768766/1000000: episode: 7688, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.644, mean reward: 0.586 [0.508, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.402, 10.155], loss: 0.001344, mae: 0.040124, mean_q: 1.168790
 768866/1000000: episode: 7689, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.007, mean reward: 0.580 [0.507, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.532, 10.098], loss: 0.001372, mae: 0.040142, mean_q: 1.168340
 768966/1000000: episode: 7690, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.669, mean reward: 0.587 [0.500, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.972, 10.098], loss: 0.001343, mae: 0.039480, mean_q: 1.169626
 769066/1000000: episode: 7691, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.155, mean reward: 0.582 [0.506, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.917, 10.199], loss: 0.001410, mae: 0.040563, mean_q: 1.171628
 769166/1000000: episode: 7692, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.610, mean reward: 0.586 [0.503, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.032, 10.109], loss: 0.001444, mae: 0.040801, mean_q: 1.171152
 769266/1000000: episode: 7693, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.800, mean reward: 0.598 [0.517, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.754, 10.171], loss: 0.001329, mae: 0.040141, mean_q: 1.169058
 769366/1000000: episode: 7694, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.148, mean reward: 0.571 [0.500, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.582, 10.098], loss: 0.001397, mae: 0.040852, mean_q: 1.168562
 769466/1000000: episode: 7695, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.490, mean reward: 0.595 [0.507, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.482, 10.172], loss: 0.001362, mae: 0.040414, mean_q: 1.169941
 769566/1000000: episode: 7696, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.907, mean reward: 0.609 [0.501, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.800, 10.220], loss: 0.001437, mae: 0.041235, mean_q: 1.169913
 769666/1000000: episode: 7697, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.473, mean reward: 0.575 [0.503, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.723, 10.098], loss: 0.001421, mae: 0.040983, mean_q: 1.168176
 769766/1000000: episode: 7698, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.102, mean reward: 0.581 [0.503, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.993, 10.098], loss: 0.001401, mae: 0.040699, mean_q: 1.165697
 769866/1000000: episode: 7699, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.617, mean reward: 0.586 [0.503, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-2.093, 10.255], loss: 0.001396, mae: 0.040796, mean_q: 1.167424
 769966/1000000: episode: 7700, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 60.355, mean reward: 0.604 [0.499, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.636, 10.098], loss: 0.001461, mae: 0.041389, mean_q: 1.166053
 770066/1000000: episode: 7701, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.155, mean reward: 0.572 [0.509, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.557, 10.207], loss: 0.001344, mae: 0.040340, mean_q: 1.166966
 770166/1000000: episode: 7702, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.999, mean reward: 0.570 [0.499, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.615, 10.115], loss: 0.001570, mae: 0.042408, mean_q: 1.163970
 770266/1000000: episode: 7703, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.419, mean reward: 0.584 [0.500, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.765, 10.098], loss: 0.001376, mae: 0.040495, mean_q: 1.166674
 770366/1000000: episode: 7704, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.365, mean reward: 0.594 [0.509, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.474, 10.119], loss: 0.001468, mae: 0.041469, mean_q: 1.166526
 770466/1000000: episode: 7705, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 63.181, mean reward: 0.632 [0.511, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.776, 10.098], loss: 0.001449, mae: 0.041122, mean_q: 1.167765
 770566/1000000: episode: 7706, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.338, mean reward: 0.573 [0.504, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.418, 10.163], loss: 0.001434, mae: 0.041640, mean_q: 1.168114
 770666/1000000: episode: 7707, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.499, mean reward: 0.585 [0.498, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.389, 10.098], loss: 0.001479, mae: 0.041721, mean_q: 1.168041
 770766/1000000: episode: 7708, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 57.379, mean reward: 0.574 [0.500, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.009, 10.188], loss: 0.001398, mae: 0.041205, mean_q: 1.163201
 770866/1000000: episode: 7709, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.402, mean reward: 0.594 [0.506, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.432, 10.098], loss: 0.001484, mae: 0.041983, mean_q: 1.165510
 770966/1000000: episode: 7710, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 61.067, mean reward: 0.611 [0.514, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.527, 10.336], loss: 0.001482, mae: 0.041753, mean_q: 1.163448
 771066/1000000: episode: 7711, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.344, mean reward: 0.613 [0.507, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.843, 10.098], loss: 0.001422, mae: 0.041345, mean_q: 1.164854
 771166/1000000: episode: 7712, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 57.098, mean reward: 0.571 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.753, 10.334], loss: 0.001358, mae: 0.040471, mean_q: 1.168053
 771266/1000000: episode: 7713, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 60.414, mean reward: 0.604 [0.505, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.577, 10.179], loss: 0.001394, mae: 0.040949, mean_q: 1.164176
 771366/1000000: episode: 7714, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.641, mean reward: 0.596 [0.510, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.582, 10.132], loss: 0.001480, mae: 0.041906, mean_q: 1.166322
 771466/1000000: episode: 7715, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.967, mean reward: 0.590 [0.503, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.896, 10.164], loss: 0.001352, mae: 0.040058, mean_q: 1.167781
 771566/1000000: episode: 7716, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.559, mean reward: 0.576 [0.509, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.846, 10.178], loss: 0.001283, mae: 0.039185, mean_q: 1.166404
 771666/1000000: episode: 7717, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.951, mean reward: 0.580 [0.509, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.541, 10.206], loss: 0.001390, mae: 0.041134, mean_q: 1.164169
 771766/1000000: episode: 7718, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.648, mean reward: 0.576 [0.503, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.264, 10.136], loss: 0.001365, mae: 0.040262, mean_q: 1.168345
 771866/1000000: episode: 7719, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.877, mean reward: 0.589 [0.506, 0.940], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.334, 10.098], loss: 0.001344, mae: 0.039440, mean_q: 1.165391
 771966/1000000: episode: 7720, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.555, mean reward: 0.586 [0.502, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-2.179, 10.360], loss: 0.001530, mae: 0.042810, mean_q: 1.168864
 772066/1000000: episode: 7721, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.427, mean reward: 0.584 [0.499, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.716, 10.098], loss: 0.001463, mae: 0.041581, mean_q: 1.163218
 772166/1000000: episode: 7722, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.609, mean reward: 0.566 [0.505, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.093, 10.176], loss: 0.001493, mae: 0.041832, mean_q: 1.165920
 772266/1000000: episode: 7723, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.582, mean reward: 0.596 [0.502, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.739, 10.098], loss: 0.001503, mae: 0.042047, mean_q: 1.165802
 772366/1000000: episode: 7724, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.591, mean reward: 0.606 [0.504, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.642, 10.098], loss: 0.001619, mae: 0.043039, mean_q: 1.163826
 772466/1000000: episode: 7725, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.494, mean reward: 0.585 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.670, 10.098], loss: 0.001423, mae: 0.041400, mean_q: 1.165972
 772566/1000000: episode: 7726, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.446, mean reward: 0.574 [0.515, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.900, 10.119], loss: 0.001453, mae: 0.041335, mean_q: 1.162450
 772666/1000000: episode: 7727, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 56.578, mean reward: 0.566 [0.503, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.572, 10.146], loss: 0.001467, mae: 0.041616, mean_q: 1.162881
 772766/1000000: episode: 7728, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 61.482, mean reward: 0.615 [0.517, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.021, 10.286], loss: 0.001427, mae: 0.041189, mean_q: 1.162342
 772866/1000000: episode: 7729, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 59.234, mean reward: 0.592 [0.508, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.928, 10.199], loss: 0.001430, mae: 0.041119, mean_q: 1.163424
 772966/1000000: episode: 7730, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.109, mean reward: 0.591 [0.506, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.779, 10.304], loss: 0.001474, mae: 0.041306, mean_q: 1.167485
 773066/1000000: episode: 7731, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.191, mean reward: 0.572 [0.503, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.891, 10.333], loss: 0.001508, mae: 0.041911, mean_q: 1.163543
 773166/1000000: episode: 7732, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 56.817, mean reward: 0.568 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.671, 10.140], loss: 0.001528, mae: 0.042314, mean_q: 1.161451
 773266/1000000: episode: 7733, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.256, mean reward: 0.583 [0.497, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.993, 10.098], loss: 0.001482, mae: 0.041995, mean_q: 1.158588
 773366/1000000: episode: 7734, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.344, mean reward: 0.583 [0.502, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.810, 10.107], loss: 0.001605, mae: 0.043427, mean_q: 1.163446
 773466/1000000: episode: 7735, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.739, mean reward: 0.617 [0.508, 0.862], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.893, 10.560], loss: 0.001523, mae: 0.042302, mean_q: 1.161525
 773566/1000000: episode: 7736, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.078, mean reward: 0.591 [0.509, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.820, 10.098], loss: 0.001659, mae: 0.044169, mean_q: 1.165367
 773666/1000000: episode: 7737, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 61.244, mean reward: 0.612 [0.500, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.545, 10.098], loss: 0.001509, mae: 0.042353, mean_q: 1.166914
 773766/1000000: episode: 7738, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.878, mean reward: 0.589 [0.508, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.934, 10.098], loss: 0.001536, mae: 0.042497, mean_q: 1.161913
 773866/1000000: episode: 7739, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 58.295, mean reward: 0.583 [0.510, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.227, 10.252], loss: 0.001528, mae: 0.042096, mean_q: 1.166619
 773966/1000000: episode: 7740, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.544, mean reward: 0.595 [0.511, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.183, 10.098], loss: 0.001584, mae: 0.042758, mean_q: 1.165029
 774066/1000000: episode: 7741, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.764, mean reward: 0.588 [0.509, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.701, 10.155], loss: 0.001466, mae: 0.041948, mean_q: 1.159247
 774166/1000000: episode: 7742, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 57.984, mean reward: 0.580 [0.504, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.984, 10.232], loss: 0.001506, mae: 0.041926, mean_q: 1.159823
 774266/1000000: episode: 7743, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.350, mean reward: 0.594 [0.511, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.580, 10.098], loss: 0.001516, mae: 0.042344, mean_q: 1.160476
 774366/1000000: episode: 7744, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 61.047, mean reward: 0.610 [0.507, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.981, 10.098], loss: 0.001437, mae: 0.041505, mean_q: 1.160837
 774466/1000000: episode: 7745, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.144, mean reward: 0.581 [0.503, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.718, 10.250], loss: 0.001531, mae: 0.042473, mean_q: 1.163021
 774566/1000000: episode: 7746, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 61.039, mean reward: 0.610 [0.503, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.493, 10.161], loss: 0.001480, mae: 0.041804, mean_q: 1.159402
 774666/1000000: episode: 7747, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.041, mean reward: 0.580 [0.509, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.785, 10.098], loss: 0.001476, mae: 0.041869, mean_q: 1.167755
 774766/1000000: episode: 7748, duration: 0.629s, episode steps: 100, steps per second: 159, episode reward: 56.848, mean reward: 0.568 [0.500, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.467, 10.291], loss: 0.001519, mae: 0.042041, mean_q: 1.166371
 774866/1000000: episode: 7749, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.834, mean reward: 0.578 [0.502, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.199, 10.098], loss: 0.001432, mae: 0.040889, mean_q: 1.166990
 774966/1000000: episode: 7750, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 62.099, mean reward: 0.621 [0.501, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.063, 10.223], loss: 0.001523, mae: 0.042024, mean_q: 1.163725
 775066/1000000: episode: 7751, duration: 0.622s, episode steps: 100, steps per second: 161, episode reward: 60.778, mean reward: 0.608 [0.508, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.461, 10.098], loss: 0.001392, mae: 0.041152, mean_q: 1.164579
 775166/1000000: episode: 7752, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 62.619, mean reward: 0.626 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.977, 10.439], loss: 0.001501, mae: 0.041565, mean_q: 1.169856
 775266/1000000: episode: 7753, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.096, mean reward: 0.591 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.753, 10.098], loss: 0.001470, mae: 0.041456, mean_q: 1.164889
 775366/1000000: episode: 7754, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.188, mean reward: 0.592 [0.502, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-2.497, 10.248], loss: 0.001476, mae: 0.041676, mean_q: 1.168345
 775466/1000000: episode: 7755, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.909, mean reward: 0.599 [0.506, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.522, 10.384], loss: 0.001531, mae: 0.042383, mean_q: 1.165194
 775566/1000000: episode: 7756, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.351, mean reward: 0.584 [0.502, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.427, 10.098], loss: 0.001500, mae: 0.042155, mean_q: 1.167699
 775666/1000000: episode: 7757, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 56.661, mean reward: 0.567 [0.500, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.576, 10.104], loss: 0.001487, mae: 0.041454, mean_q: 1.167580
 775766/1000000: episode: 7758, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.002, mean reward: 0.580 [0.499, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.354, 10.098], loss: 0.001450, mae: 0.042065, mean_q: 1.171289
 775866/1000000: episode: 7759, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 57.332, mean reward: 0.573 [0.500, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.374, 10.098], loss: 0.001371, mae: 0.040695, mean_q: 1.164271
 775966/1000000: episode: 7760, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.798, mean reward: 0.608 [0.501, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.128, 10.098], loss: 0.001448, mae: 0.041852, mean_q: 1.167224
 776066/1000000: episode: 7761, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 63.100, mean reward: 0.631 [0.535, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.494, 10.098], loss: 0.001447, mae: 0.042020, mean_q: 1.165102
 776166/1000000: episode: 7762, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.728, mean reward: 0.577 [0.507, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.521, 10.272], loss: 0.001538, mae: 0.042894, mean_q: 1.168267
 776266/1000000: episode: 7763, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.756, mean reward: 0.588 [0.503, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.411, 10.101], loss: 0.001548, mae: 0.042683, mean_q: 1.169194
 776366/1000000: episode: 7764, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 58.014, mean reward: 0.580 [0.506, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.684, 10.106], loss: 0.001426, mae: 0.041416, mean_q: 1.165522
 776466/1000000: episode: 7765, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.289, mean reward: 0.583 [0.501, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.213, 10.098], loss: 0.001535, mae: 0.043171, mean_q: 1.168028
 776566/1000000: episode: 7766, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 58.413, mean reward: 0.584 [0.513, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.785, 10.388], loss: 0.001389, mae: 0.040627, mean_q: 1.165050
 776666/1000000: episode: 7767, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.163, mean reward: 0.592 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.258, 10.098], loss: 0.001437, mae: 0.041897, mean_q: 1.167533
 776766/1000000: episode: 7768, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.531, mean reward: 0.575 [0.501, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.905, 10.163], loss: 0.001514, mae: 0.041991, mean_q: 1.166251
 776866/1000000: episode: 7769, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.423, mean reward: 0.594 [0.506, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.949, 10.098], loss: 0.001460, mae: 0.041793, mean_q: 1.167061
 776966/1000000: episode: 7770, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.678, mean reward: 0.597 [0.505, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-2.070, 10.098], loss: 0.001468, mae: 0.041339, mean_q: 1.167084
 777066/1000000: episode: 7771, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 62.824, mean reward: 0.628 [0.531, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.991, 10.302], loss: 0.001390, mae: 0.040952, mean_q: 1.168762
 777166/1000000: episode: 7772, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.014, mean reward: 0.590 [0.507, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.929, 10.221], loss: 0.001489, mae: 0.041737, mean_q: 1.172606
 777266/1000000: episode: 7773, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.070, mean reward: 0.591 [0.508, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.106, 10.098], loss: 0.001464, mae: 0.041345, mean_q: 1.170032
 777366/1000000: episode: 7774, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.404, mean reward: 0.584 [0.501, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.979, 10.121], loss: 0.001474, mae: 0.042142, mean_q: 1.167395
 777466/1000000: episode: 7775, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.032, mean reward: 0.600 [0.503, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.519, 10.098], loss: 0.001452, mae: 0.041535, mean_q: 1.168038
 777566/1000000: episode: 7776, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.182, mean reward: 0.592 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.950, 10.411], loss: 0.001456, mae: 0.041988, mean_q: 1.168774
 777666/1000000: episode: 7777, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 58.107, mean reward: 0.581 [0.503, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.515, 10.360], loss: 0.001435, mae: 0.041465, mean_q: 1.174567
 777766/1000000: episode: 7778, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 62.251, mean reward: 0.623 [0.527, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.030, 10.350], loss: 0.001532, mae: 0.042097, mean_q: 1.171182
 777866/1000000: episode: 7779, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.368, mean reward: 0.594 [0.506, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.341, 10.098], loss: 0.001431, mae: 0.041709, mean_q: 1.172895
 777966/1000000: episode: 7780, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.100, mean reward: 0.571 [0.501, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.921, 10.107], loss: 0.001392, mae: 0.040740, mean_q: 1.172646
 778066/1000000: episode: 7781, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.458, mean reward: 0.575 [0.498, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.887, 10.276], loss: 0.001516, mae: 0.042352, mean_q: 1.169789
 778166/1000000: episode: 7782, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 57.926, mean reward: 0.579 [0.503, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.180, 10.132], loss: 0.001444, mae: 0.041013, mean_q: 1.169926
 778266/1000000: episode: 7783, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 59.044, mean reward: 0.590 [0.530, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.362, 10.261], loss: 0.001337, mae: 0.040151, mean_q: 1.170993
 778366/1000000: episode: 7784, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.665, mean reward: 0.607 [0.513, 0.863], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.395, 10.440], loss: 0.001413, mae: 0.041681, mean_q: 1.173416
 778466/1000000: episode: 7785, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.948, mean reward: 0.599 [0.513, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.086, 10.270], loss: 0.001413, mae: 0.041227, mean_q: 1.168420
 778566/1000000: episode: 7786, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.225, mean reward: 0.602 [0.502, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.750, 10.098], loss: 0.001375, mae: 0.040698, mean_q: 1.172886
 778666/1000000: episode: 7787, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.541, mean reward: 0.595 [0.511, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.374, 10.098], loss: 0.001517, mae: 0.042414, mean_q: 1.174535
 778766/1000000: episode: 7788, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.375, mean reward: 0.594 [0.507, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.427, 10.179], loss: 0.001479, mae: 0.041792, mean_q: 1.171073
 778866/1000000: episode: 7789, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.832, mean reward: 0.618 [0.509, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.379, 10.098], loss: 0.001465, mae: 0.041786, mean_q: 1.175372
 778966/1000000: episode: 7790, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.795, mean reward: 0.598 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.453, 10.218], loss: 0.001464, mae: 0.041722, mean_q: 1.176983
 779066/1000000: episode: 7791, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.051, mean reward: 0.591 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.572, 10.098], loss: 0.001412, mae: 0.041048, mean_q: 1.174706
 779166/1000000: episode: 7792, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.640, mean reward: 0.576 [0.509, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.419, 10.108], loss: 0.001429, mae: 0.041194, mean_q: 1.176323
 779266/1000000: episode: 7793, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.509, mean reward: 0.605 [0.502, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.018, 10.260], loss: 0.001451, mae: 0.041342, mean_q: 1.174965
 779366/1000000: episode: 7794, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.815, mean reward: 0.598 [0.509, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.743, 10.098], loss: 0.001410, mae: 0.040390, mean_q: 1.173337
 779466/1000000: episode: 7795, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.213, mean reward: 0.582 [0.505, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.921, 10.098], loss: 0.001306, mae: 0.039542, mean_q: 1.172459
 779566/1000000: episode: 7796, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.776, mean reward: 0.608 [0.504, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.788, 10.098], loss: 0.001450, mae: 0.041369, mean_q: 1.170637
 779666/1000000: episode: 7797, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 60.616, mean reward: 0.606 [0.512, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.866, 10.273], loss: 0.001428, mae: 0.040541, mean_q: 1.173587
 779766/1000000: episode: 7798, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.860, mean reward: 0.579 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.838, 10.176], loss: 0.001438, mae: 0.041327, mean_q: 1.178256
 779866/1000000: episode: 7799, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.233, mean reward: 0.602 [0.505, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.468, 10.143], loss: 0.001401, mae: 0.040187, mean_q: 1.173968
 779966/1000000: episode: 7800, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.015, mean reward: 0.590 [0.497, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.544, 10.191], loss: 0.001532, mae: 0.041912, mean_q: 1.175575
 780066/1000000: episode: 7801, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.360, mean reward: 0.594 [0.522, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.301, 10.098], loss: 0.001501, mae: 0.041179, mean_q: 1.176580
 780166/1000000: episode: 7802, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.514, mean reward: 0.595 [0.504, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.893, 10.130], loss: 0.001469, mae: 0.041649, mean_q: 1.174933
 780266/1000000: episode: 7803, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.808, mean reward: 0.588 [0.508, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.293, 10.133], loss: 0.001476, mae: 0.041324, mean_q: 1.173974
 780366/1000000: episode: 7804, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.101, mean reward: 0.591 [0.500, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.152, 10.120], loss: 0.001438, mae: 0.041527, mean_q: 1.171963
 780466/1000000: episode: 7805, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.350, mean reward: 0.583 [0.499, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.298, 10.107], loss: 0.001379, mae: 0.040471, mean_q: 1.171692
 780566/1000000: episode: 7806, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.974, mean reward: 0.590 [0.514, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.099, 10.139], loss: 0.001464, mae: 0.041506, mean_q: 1.169904
 780666/1000000: episode: 7807, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.715, mean reward: 0.587 [0.513, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.596, 10.098], loss: 0.001356, mae: 0.040493, mean_q: 1.171752
 780766/1000000: episode: 7808, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 57.828, mean reward: 0.578 [0.505, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.855, 10.098], loss: 0.001476, mae: 0.042348, mean_q: 1.175105
 780866/1000000: episode: 7809, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.483, mean reward: 0.585 [0.499, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.752, 10.288], loss: 0.001469, mae: 0.041058, mean_q: 1.174489
 780966/1000000: episode: 7810, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.834, mean reward: 0.598 [0.498, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.663, 10.361], loss: 0.001420, mae: 0.040655, mean_q: 1.170961
 781066/1000000: episode: 7811, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 61.462, mean reward: 0.615 [0.504, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.981, 10.098], loss: 0.001333, mae: 0.039241, mean_q: 1.173844
 781166/1000000: episode: 7812, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.626, mean reward: 0.586 [0.501, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.989, 10.109], loss: 0.001415, mae: 0.041040, mean_q: 1.173244
 781266/1000000: episode: 7813, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.345, mean reward: 0.573 [0.499, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.142, 10.098], loss: 0.001531, mae: 0.042168, mean_q: 1.174907
 781366/1000000: episode: 7814, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.599, mean reward: 0.606 [0.503, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.148, 10.388], loss: 0.001484, mae: 0.041889, mean_q: 1.175260
 781466/1000000: episode: 7815, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.454, mean reward: 0.585 [0.499, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.479, 10.199], loss: 0.001391, mae: 0.040763, mean_q: 1.172615
 781566/1000000: episode: 7816, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.325, mean reward: 0.583 [0.501, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.698, 10.098], loss: 0.001465, mae: 0.041559, mean_q: 1.173482
 781666/1000000: episode: 7817, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.998, mean reward: 0.580 [0.510, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.141, 10.140], loss: 0.001482, mae: 0.041860, mean_q: 1.173448
 781766/1000000: episode: 7818, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.823, mean reward: 0.578 [0.508, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.542, 10.098], loss: 0.001507, mae: 0.042216, mean_q: 1.175017
 781866/1000000: episode: 7819, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.548, mean reward: 0.565 [0.499, 0.666], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.108, 10.160], loss: 0.001444, mae: 0.040521, mean_q: 1.172353
 781966/1000000: episode: 7820, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.957, mean reward: 0.580 [0.499, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.441, 10.117], loss: 0.001456, mae: 0.041297, mean_q: 1.174176
 782066/1000000: episode: 7821, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.371, mean reward: 0.574 [0.503, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.067, 10.098], loss: 0.001438, mae: 0.040740, mean_q: 1.170005
 782166/1000000: episode: 7822, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 64.426, mean reward: 0.644 [0.547, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.521, 10.098], loss: 0.001463, mae: 0.041290, mean_q: 1.167468
 782266/1000000: episode: 7823, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 61.403, mean reward: 0.614 [0.520, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.323, 10.220], loss: 0.001392, mae: 0.040367, mean_q: 1.171049
 782366/1000000: episode: 7824, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.476, mean reward: 0.605 [0.505, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.783, 10.262], loss: 0.001342, mae: 0.039934, mean_q: 1.173375
 782466/1000000: episode: 7825, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.830, mean reward: 0.608 [0.515, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.452, 10.098], loss: 0.001395, mae: 0.040092, mean_q: 1.173712
 782566/1000000: episode: 7826, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.660, mean reward: 0.587 [0.498, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.312, 10.280], loss: 0.001412, mae: 0.040997, mean_q: 1.174726
 782666/1000000: episode: 7827, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.960, mean reward: 0.580 [0.504, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.451, 10.098], loss: 0.001487, mae: 0.041792, mean_q: 1.171462
 782766/1000000: episode: 7828, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.096, mean reward: 0.591 [0.499, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.958, 10.114], loss: 0.001451, mae: 0.041299, mean_q: 1.171611
 782866/1000000: episode: 7829, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.861, mean reward: 0.599 [0.501, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.130, 10.136], loss: 0.001421, mae: 0.040540, mean_q: 1.171332
 782966/1000000: episode: 7830, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.918, mean reward: 0.579 [0.503, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.834, 10.196], loss: 0.001527, mae: 0.041640, mean_q: 1.171273
 783066/1000000: episode: 7831, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.470, mean reward: 0.595 [0.501, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.004, 10.098], loss: 0.001451, mae: 0.040995, mean_q: 1.173887
 783166/1000000: episode: 7832, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.100, mean reward: 0.571 [0.504, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.107, 10.173], loss: 0.001422, mae: 0.040852, mean_q: 1.173992
 783266/1000000: episode: 7833, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.641, mean reward: 0.576 [0.503, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.858, 10.098], loss: 0.001401, mae: 0.040423, mean_q: 1.171824
 783366/1000000: episode: 7834, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.398, mean reward: 0.594 [0.518, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.878, 10.295], loss: 0.001493, mae: 0.041929, mean_q: 1.174440
 783466/1000000: episode: 7835, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.118, mean reward: 0.571 [0.506, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.832, 10.240], loss: 0.001372, mae: 0.040878, mean_q: 1.168223
 783566/1000000: episode: 7836, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 59.199, mean reward: 0.592 [0.520, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.481, 10.098], loss: 0.001396, mae: 0.040088, mean_q: 1.167284
 783666/1000000: episode: 7837, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.862, mean reward: 0.609 [0.506, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.028, 10.377], loss: 0.001427, mae: 0.041139, mean_q: 1.169742
 783766/1000000: episode: 7838, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 59.235, mean reward: 0.592 [0.504, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.439, 10.098], loss: 0.001446, mae: 0.041373, mean_q: 1.169132
 783866/1000000: episode: 7839, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.733, mean reward: 0.577 [0.502, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.869, 10.249], loss: 0.001391, mae: 0.040500, mean_q: 1.170440
 783966/1000000: episode: 7840, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.145, mean reward: 0.571 [0.497, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.991, 10.142], loss: 0.001375, mae: 0.040256, mean_q: 1.167190
 784066/1000000: episode: 7841, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.561, mean reward: 0.576 [0.501, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.594, 10.098], loss: 0.001474, mae: 0.041553, mean_q: 1.171553
 784166/1000000: episode: 7842, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.376, mean reward: 0.574 [0.499, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.746, 10.171], loss: 0.001589, mae: 0.042814, mean_q: 1.172184
 784266/1000000: episode: 7843, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 60.457, mean reward: 0.605 [0.507, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.287, 10.305], loss: 0.001457, mae: 0.041181, mean_q: 1.166865
 784366/1000000: episode: 7844, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.281, mean reward: 0.583 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.839, 10.098], loss: 0.001423, mae: 0.041005, mean_q: 1.171904
 784466/1000000: episode: 7845, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.713, mean reward: 0.597 [0.504, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.993, 10.098], loss: 0.001417, mae: 0.040692, mean_q: 1.167156
 784566/1000000: episode: 7846, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 56.192, mean reward: 0.562 [0.505, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.309, 10.098], loss: 0.001453, mae: 0.041696, mean_q: 1.166925
 784666/1000000: episode: 7847, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.633, mean reward: 0.596 [0.508, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.613, 10.125], loss: 0.001389, mae: 0.040854, mean_q: 1.166044
 784766/1000000: episode: 7848, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.759, mean reward: 0.588 [0.498, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.926, 10.098], loss: 0.001469, mae: 0.041428, mean_q: 1.166199
 784866/1000000: episode: 7849, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 62.267, mean reward: 0.623 [0.520, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.314, 10.098], loss: 0.001450, mae: 0.041335, mean_q: 1.164976
 784966/1000000: episode: 7850, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.220, mean reward: 0.582 [0.503, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.044, 10.130], loss: 0.001458, mae: 0.041704, mean_q: 1.166703
 785066/1000000: episode: 7851, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 56.566, mean reward: 0.566 [0.499, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.825, 10.146], loss: 0.001451, mae: 0.040918, mean_q: 1.164208
 785166/1000000: episode: 7852, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.849, mean reward: 0.588 [0.503, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.453, 10.098], loss: 0.001446, mae: 0.041640, mean_q: 1.164133
 785266/1000000: episode: 7853, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.675, mean reward: 0.597 [0.505, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.962, 10.507], loss: 0.001386, mae: 0.040687, mean_q: 1.162710
 785366/1000000: episode: 7854, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.715, mean reward: 0.587 [0.502, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.557, 10.098], loss: 0.001409, mae: 0.040584, mean_q: 1.164257
 785466/1000000: episode: 7855, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.344, mean reward: 0.583 [0.501, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.176, 10.279], loss: 0.001392, mae: 0.040266, mean_q: 1.164591
 785566/1000000: episode: 7856, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.893, mean reward: 0.589 [0.500, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.645, 10.118], loss: 0.001302, mae: 0.039240, mean_q: 1.161760
 785666/1000000: episode: 7857, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.931, mean reward: 0.579 [0.500, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.201, 10.098], loss: 0.001398, mae: 0.040549, mean_q: 1.164038
 785766/1000000: episode: 7858, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 58.895, mean reward: 0.589 [0.504, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.773, 10.141], loss: 0.001390, mae: 0.040529, mean_q: 1.164298
 785866/1000000: episode: 7859, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.059, mean reward: 0.601 [0.498, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.552, 10.345], loss: 0.001365, mae: 0.040223, mean_q: 1.161982
 785966/1000000: episode: 7860, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.776, mean reward: 0.608 [0.504, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.992, 10.228], loss: 0.001355, mae: 0.039842, mean_q: 1.166321
 786066/1000000: episode: 7861, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.250, mean reward: 0.572 [0.499, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.741, 10.160], loss: 0.001312, mae: 0.039597, mean_q: 1.162656
 786166/1000000: episode: 7862, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 62.205, mean reward: 0.622 [0.511, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.881, 10.098], loss: 0.001377, mae: 0.040252, mean_q: 1.164056
 786266/1000000: episode: 7863, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 60.277, mean reward: 0.603 [0.506, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.511, 10.180], loss: 0.001397, mae: 0.040695, mean_q: 1.166629
 786366/1000000: episode: 7864, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.969, mean reward: 0.600 [0.529, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.907, 10.247], loss: 0.001371, mae: 0.040251, mean_q: 1.168495
 786466/1000000: episode: 7865, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 64.733, mean reward: 0.647 [0.499, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.398, 10.098], loss: 0.001402, mae: 0.040808, mean_q: 1.165214
 786566/1000000: episode: 7866, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.048, mean reward: 0.590 [0.514, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.146, 10.267], loss: 0.001382, mae: 0.040200, mean_q: 1.168347
 786666/1000000: episode: 7867, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.931, mean reward: 0.599 [0.499, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.885, 10.171], loss: 0.001419, mae: 0.040702, mean_q: 1.171562
 786766/1000000: episode: 7868, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 60.220, mean reward: 0.602 [0.512, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.324, 10.346], loss: 0.001422, mae: 0.040930, mean_q: 1.170581
 786866/1000000: episode: 7869, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 63.912, mean reward: 0.639 [0.524, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.175, 10.273], loss: 0.001413, mae: 0.040679, mean_q: 1.172480
 786966/1000000: episode: 7870, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.241, mean reward: 0.572 [0.501, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.827, 10.189], loss: 0.001345, mae: 0.040303, mean_q: 1.174986
 787066/1000000: episode: 7871, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.026, mean reward: 0.580 [0.507, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.245, 10.341], loss: 0.001350, mae: 0.040030, mean_q: 1.169351
 787166/1000000: episode: 7872, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.037, mean reward: 0.570 [0.509, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.716, 10.098], loss: 0.001477, mae: 0.041511, mean_q: 1.174546
 787266/1000000: episode: 7873, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.264, mean reward: 0.573 [0.504, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.369, 10.310], loss: 0.001283, mae: 0.039515, mean_q: 1.170177
 787366/1000000: episode: 7874, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 58.608, mean reward: 0.586 [0.511, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.891, 10.098], loss: 0.001344, mae: 0.039913, mean_q: 1.168554
 787466/1000000: episode: 7875, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.091, mean reward: 0.591 [0.505, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.683, 10.098], loss: 0.001393, mae: 0.040648, mean_q: 1.167695
 787566/1000000: episode: 7876, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.704, mean reward: 0.577 [0.506, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.629, 10.156], loss: 0.001426, mae: 0.041288, mean_q: 1.169287
 787666/1000000: episode: 7877, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.812, mean reward: 0.578 [0.511, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.466, 10.136], loss: 0.001419, mae: 0.040878, mean_q: 1.170501
 787766/1000000: episode: 7878, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.517, mean reward: 0.575 [0.502, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.448, 10.098], loss: 0.001414, mae: 0.040962, mean_q: 1.167312
 787866/1000000: episode: 7879, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.633, mean reward: 0.596 [0.507, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.602, 10.259], loss: 0.001434, mae: 0.041381, mean_q: 1.168230
 787966/1000000: episode: 7880, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 57.888, mean reward: 0.579 [0.508, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.875, 10.098], loss: 0.001352, mae: 0.039949, mean_q: 1.162037
 788066/1000000: episode: 7881, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.867, mean reward: 0.579 [0.501, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.893, 10.098], loss: 0.001322, mae: 0.040110, mean_q: 1.167636
 788166/1000000: episode: 7882, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.466, mean reward: 0.595 [0.509, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.863, 10.098], loss: 0.001344, mae: 0.039753, mean_q: 1.168702
 788266/1000000: episode: 7883, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 63.006, mean reward: 0.630 [0.501, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.251, 10.098], loss: 0.001356, mae: 0.040667, mean_q: 1.167436
 788366/1000000: episode: 7884, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.025, mean reward: 0.600 [0.506, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.795, 10.098], loss: 0.001451, mae: 0.041569, mean_q: 1.169142
 788466/1000000: episode: 7885, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.580, mean reward: 0.586 [0.509, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.180, 10.098], loss: 0.001314, mae: 0.039208, mean_q: 1.167926
 788566/1000000: episode: 7886, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.512, mean reward: 0.585 [0.506, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.660, 10.098], loss: 0.001335, mae: 0.039807, mean_q: 1.168587
 788666/1000000: episode: 7887, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.125, mean reward: 0.581 [0.510, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.343, 10.098], loss: 0.001438, mae: 0.040688, mean_q: 1.168886
 788766/1000000: episode: 7888, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.754, mean reward: 0.578 [0.500, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.325, 10.098], loss: 0.001388, mae: 0.040680, mean_q: 1.169990
 788866/1000000: episode: 7889, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.035, mean reward: 0.570 [0.519, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.770, 10.135], loss: 0.001401, mae: 0.040850, mean_q: 1.167428
 788966/1000000: episode: 7890, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.774, mean reward: 0.588 [0.500, 0.883], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.932, 10.098], loss: 0.001289, mae: 0.039284, mean_q: 1.170485
 789066/1000000: episode: 7891, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 58.957, mean reward: 0.590 [0.507, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.833, 10.098], loss: 0.001403, mae: 0.040756, mean_q: 1.169481
 789166/1000000: episode: 7892, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.639, mean reward: 0.566 [0.504, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.935, 10.098], loss: 0.001377, mae: 0.040417, mean_q: 1.165369
 789266/1000000: episode: 7893, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 58.384, mean reward: 0.584 [0.500, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.020, 10.098], loss: 0.001358, mae: 0.040187, mean_q: 1.167264
 789366/1000000: episode: 7894, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.112, mean reward: 0.601 [0.505, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.316, 10.354], loss: 0.001343, mae: 0.040378, mean_q: 1.169990
 789466/1000000: episode: 7895, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.428, mean reward: 0.574 [0.501, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.750, 10.227], loss: 0.001393, mae: 0.040067, mean_q: 1.171002
 789566/1000000: episode: 7896, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.344, mean reward: 0.573 [0.500, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.927, 10.336], loss: 0.001342, mae: 0.040065, mean_q: 1.167276
 789666/1000000: episode: 7897, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 59.650, mean reward: 0.597 [0.504, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.350, 10.166], loss: 0.001334, mae: 0.039772, mean_q: 1.166294
 789766/1000000: episode: 7898, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.551, mean reward: 0.586 [0.502, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.132, 10.098], loss: 0.001341, mae: 0.040301, mean_q: 1.170492
 789866/1000000: episode: 7899, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.471, mean reward: 0.575 [0.503, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.672, 10.109], loss: 0.001404, mae: 0.040688, mean_q: 1.168493
 789966/1000000: episode: 7900, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.213, mean reward: 0.572 [0.504, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.546, 10.162], loss: 0.001390, mae: 0.040814, mean_q: 1.169299
 790066/1000000: episode: 7901, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.336, mean reward: 0.603 [0.516, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.889, 10.156], loss: 0.001327, mae: 0.040011, mean_q: 1.165520
 790166/1000000: episode: 7902, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.632, mean reward: 0.586 [0.514, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.310, 10.241], loss: 0.001325, mae: 0.039595, mean_q: 1.164850
 790266/1000000: episode: 7903, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 61.876, mean reward: 0.619 [0.508, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.128, 10.394], loss: 0.001315, mae: 0.039733, mean_q: 1.165216
 790366/1000000: episode: 7904, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.450, mean reward: 0.584 [0.500, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.793, 10.098], loss: 0.001307, mae: 0.039483, mean_q: 1.167605
 790466/1000000: episode: 7905, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.145, mean reward: 0.591 [0.507, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.325, 10.288], loss: 0.001300, mae: 0.039208, mean_q: 1.165331
 790566/1000000: episode: 7906, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 57.337, mean reward: 0.573 [0.501, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.694, 10.098], loss: 0.001303, mae: 0.039324, mean_q: 1.168759
 790666/1000000: episode: 7907, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.808, mean reward: 0.598 [0.508, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.861, 10.251], loss: 0.001352, mae: 0.040069, mean_q: 1.171914
 790766/1000000: episode: 7908, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.446, mean reward: 0.594 [0.513, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.800, 10.224], loss: 0.001479, mae: 0.041049, mean_q: 1.166444
 790866/1000000: episode: 7909, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 59.712, mean reward: 0.597 [0.503, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.518, 10.098], loss: 0.001401, mae: 0.040381, mean_q: 1.166929
 790966/1000000: episode: 7910, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.510, mean reward: 0.585 [0.513, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.702, 10.251], loss: 0.001432, mae: 0.040621, mean_q: 1.168896
 791066/1000000: episode: 7911, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 63.115, mean reward: 0.631 [0.506, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.592, 10.161], loss: 0.001373, mae: 0.040833, mean_q: 1.168596
 791166/1000000: episode: 7912, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.450, mean reward: 0.574 [0.506, 0.669], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.538, 10.100], loss: 0.001312, mae: 0.039706, mean_q: 1.166523
 791266/1000000: episode: 7913, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.387, mean reward: 0.594 [0.504, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.162, 10.216], loss: 0.001358, mae: 0.040064, mean_q: 1.164601
 791366/1000000: episode: 7914, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.478, mean reward: 0.595 [0.505, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.595, 10.247], loss: 0.001511, mae: 0.041701, mean_q: 1.167035
 791466/1000000: episode: 7915, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.800, mean reward: 0.588 [0.507, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.809, 10.139], loss: 0.001420, mae: 0.040408, mean_q: 1.164473
 791566/1000000: episode: 7916, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.917, mean reward: 0.589 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.922, 10.098], loss: 0.001420, mae: 0.040423, mean_q: 1.162804
 791666/1000000: episode: 7917, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.082, mean reward: 0.601 [0.513, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.480, 10.098], loss: 0.001409, mae: 0.040613, mean_q: 1.162247
 791766/1000000: episode: 7918, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 58.943, mean reward: 0.589 [0.502, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.838, 10.334], loss: 0.001493, mae: 0.040678, mean_q: 1.160622
 791866/1000000: episode: 7919, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.295, mean reward: 0.573 [0.499, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.434, 10.338], loss: 0.001420, mae: 0.040714, mean_q: 1.163719
 791966/1000000: episode: 7920, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 56.997, mean reward: 0.570 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.567, 10.172], loss: 0.001499, mae: 0.041585, mean_q: 1.162853
 792066/1000000: episode: 7921, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 60.889, mean reward: 0.609 [0.507, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.708, 10.098], loss: 0.001411, mae: 0.040323, mean_q: 1.160172
 792166/1000000: episode: 7922, duration: 0.617s, episode steps: 100, steps per second: 162, episode reward: 57.717, mean reward: 0.577 [0.505, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.536, 10.098], loss: 0.001441, mae: 0.041211, mean_q: 1.161710
 792266/1000000: episode: 7923, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.431, mean reward: 0.594 [0.501, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.658, 10.239], loss: 0.001476, mae: 0.041444, mean_q: 1.165297
 792366/1000000: episode: 7924, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 56.502, mean reward: 0.565 [0.498, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.153, 10.281], loss: 0.001377, mae: 0.040365, mean_q: 1.163628
 792466/1000000: episode: 7925, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.087, mean reward: 0.601 [0.509, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.983, 10.098], loss: 0.001474, mae: 0.041438, mean_q: 1.162072
 792566/1000000: episode: 7926, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.587, mean reward: 0.586 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.498, 10.119], loss: 0.001475, mae: 0.041158, mean_q: 1.164162
 792666/1000000: episode: 7927, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 61.000, mean reward: 0.610 [0.505, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.138, 10.098], loss: 0.001451, mae: 0.041281, mean_q: 1.166649
 792766/1000000: episode: 7928, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 56.530, mean reward: 0.565 [0.501, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.012, 10.108], loss: 0.001389, mae: 0.040665, mean_q: 1.164436
 792866/1000000: episode: 7929, duration: 0.757s, episode steps: 100, steps per second: 132, episode reward: 61.094, mean reward: 0.611 [0.500, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.897, 10.098], loss: 0.001391, mae: 0.040560, mean_q: 1.164529
 792966/1000000: episode: 7930, duration: 0.906s, episode steps: 100, steps per second: 110, episode reward: 56.634, mean reward: 0.566 [0.500, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.917, 10.098], loss: 0.001428, mae: 0.040712, mean_q: 1.163739
 793066/1000000: episode: 7931, duration: 0.697s, episode steps: 100, steps per second: 143, episode reward: 60.717, mean reward: 0.607 [0.506, 0.896], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.087, 10.180], loss: 0.001382, mae: 0.040365, mean_q: 1.163026
 793166/1000000: episode: 7932, duration: 0.733s, episode steps: 100, steps per second: 136, episode reward: 58.550, mean reward: 0.585 [0.502, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.366, 10.098], loss: 0.001481, mae: 0.041021, mean_q: 1.161709
 793266/1000000: episode: 7933, duration: 0.714s, episode steps: 100, steps per second: 140, episode reward: 58.916, mean reward: 0.589 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.949, 10.098], loss: 0.001415, mae: 0.040259, mean_q: 1.161044
 793366/1000000: episode: 7934, duration: 0.726s, episode steps: 100, steps per second: 138, episode reward: 58.656, mean reward: 0.587 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.603, 10.105], loss: 0.001550, mae: 0.042359, mean_q: 1.164214
 793466/1000000: episode: 7935, duration: 1.233s, episode steps: 100, steps per second: 81, episode reward: 57.590, mean reward: 0.576 [0.504, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.678, 10.144], loss: 0.001377, mae: 0.040139, mean_q: 1.163849
 793566/1000000: episode: 7936, duration: 0.865s, episode steps: 100, steps per second: 116, episode reward: 59.451, mean reward: 0.595 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.842, 10.098], loss: 0.001441, mae: 0.040917, mean_q: 1.162050
 793666/1000000: episode: 7937, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.868, mean reward: 0.599 [0.515, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-1.025, 10.098], loss: 0.001566, mae: 0.042017, mean_q: 1.163635
 793766/1000000: episode: 7938, duration: 0.749s, episode steps: 100, steps per second: 134, episode reward: 58.798, mean reward: 0.588 [0.504, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.724, 10.279], loss: 0.001479, mae: 0.041100, mean_q: 1.160105
 793866/1000000: episode: 7939, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 60.175, mean reward: 0.602 [0.500, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.618, 10.359], loss: 0.001402, mae: 0.040668, mean_q: 1.163987
 793966/1000000: episode: 7940, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.332, mean reward: 0.583 [0.501, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.845, 10.098], loss: 0.001464, mae: 0.041231, mean_q: 1.164865
 794066/1000000: episode: 7941, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 59.192, mean reward: 0.592 [0.508, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.411, 10.140], loss: 0.001506, mae: 0.041932, mean_q: 1.169254
 794166/1000000: episode: 7942, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.898, mean reward: 0.579 [0.504, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.983, 10.321], loss: 0.001532, mae: 0.041454, mean_q: 1.166475
 794266/1000000: episode: 7943, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 61.058, mean reward: 0.611 [0.523, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.300, 10.485], loss: 0.001519, mae: 0.041646, mean_q: 1.167869
 794366/1000000: episode: 7944, duration: 0.662s, episode steps: 100, steps per second: 151, episode reward: 58.179, mean reward: 0.582 [0.498, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.645, 10.098], loss: 0.001524, mae: 0.041721, mean_q: 1.165906
 794466/1000000: episode: 7945, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.718, mean reward: 0.587 [0.503, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.694, 10.149], loss: 0.001608, mae: 0.042853, mean_q: 1.167436
 794566/1000000: episode: 7946, duration: 0.658s, episode steps: 100, steps per second: 152, episode reward: 58.537, mean reward: 0.585 [0.509, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.656, 10.235], loss: 0.001553, mae: 0.042702, mean_q: 1.169654
 794666/1000000: episode: 7947, duration: 0.821s, episode steps: 100, steps per second: 122, episode reward: 61.185, mean reward: 0.612 [0.516, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.054, 10.133], loss: 0.001485, mae: 0.041744, mean_q: 1.169207
 794766/1000000: episode: 7948, duration: 1.273s, episode steps: 100, steps per second: 79, episode reward: 61.355, mean reward: 0.614 [0.519, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.450, 10.243], loss: 0.001539, mae: 0.042324, mean_q: 1.169105
 794866/1000000: episode: 7949, duration: 0.769s, episode steps: 100, steps per second: 130, episode reward: 58.022, mean reward: 0.580 [0.501, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.553, 10.131], loss: 0.001574, mae: 0.042389, mean_q: 1.167140
 794966/1000000: episode: 7950, duration: 0.734s, episode steps: 100, steps per second: 136, episode reward: 58.828, mean reward: 0.588 [0.509, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.624, 10.098], loss: 0.001585, mae: 0.043481, mean_q: 1.172721
 795066/1000000: episode: 7951, duration: 0.629s, episode steps: 100, steps per second: 159, episode reward: 57.500, mean reward: 0.575 [0.508, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.147, 10.108], loss: 0.001485, mae: 0.041419, mean_q: 1.167946
 795166/1000000: episode: 7952, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 59.866, mean reward: 0.599 [0.503, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.538, 10.152], loss: 0.001525, mae: 0.042370, mean_q: 1.168736
 795266/1000000: episode: 7953, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.402, mean reward: 0.584 [0.500, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.954, 10.223], loss: 0.001506, mae: 0.042046, mean_q: 1.165639
 795366/1000000: episode: 7954, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 58.465, mean reward: 0.585 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.878, 10.098], loss: 0.001527, mae: 0.041965, mean_q: 1.165799
 795466/1000000: episode: 7955, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 60.902, mean reward: 0.609 [0.512, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.176, 10.276], loss: 0.001498, mae: 0.041665, mean_q: 1.168382
 795566/1000000: episode: 7956, duration: 0.644s, episode steps: 100, steps per second: 155, episode reward: 58.311, mean reward: 0.583 [0.509, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.112, 10.359], loss: 0.001518, mae: 0.041820, mean_q: 1.169153
 795666/1000000: episode: 7957, duration: 0.640s, episode steps: 100, steps per second: 156, episode reward: 58.739, mean reward: 0.587 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.728, 10.376], loss: 0.001497, mae: 0.041773, mean_q: 1.168685
 795766/1000000: episode: 7958, duration: 0.611s, episode steps: 100, steps per second: 164, episode reward: 57.969, mean reward: 0.580 [0.507, 0.669], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.823, 10.098], loss: 0.001630, mae: 0.043404, mean_q: 1.171069
 795866/1000000: episode: 7959, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.463, mean reward: 0.575 [0.502, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.366, 10.098], loss: 0.001571, mae: 0.043135, mean_q: 1.169691
 795966/1000000: episode: 7960, duration: 0.713s, episode steps: 100, steps per second: 140, episode reward: 58.900, mean reward: 0.589 [0.503, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.245, 10.197], loss: 0.001594, mae: 0.043232, mean_q: 1.167089
 796066/1000000: episode: 7961, duration: 0.617s, episode steps: 100, steps per second: 162, episode reward: 63.187, mean reward: 0.632 [0.509, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.218, 10.280], loss: 0.001577, mae: 0.043153, mean_q: 1.168944
 796166/1000000: episode: 7962, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 62.877, mean reward: 0.629 [0.529, 0.855], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.535, 10.098], loss: 0.001472, mae: 0.041869, mean_q: 1.171070
 796266/1000000: episode: 7963, duration: 0.631s, episode steps: 100, steps per second: 158, episode reward: 57.690, mean reward: 0.577 [0.501, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.800, 10.098], loss: 0.001487, mae: 0.041298, mean_q: 1.166261
 796366/1000000: episode: 7964, duration: 0.624s, episode steps: 100, steps per second: 160, episode reward: 57.217, mean reward: 0.572 [0.499, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.826, 10.138], loss: 0.001595, mae: 0.042745, mean_q: 1.170349
 796466/1000000: episode: 7965, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 58.943, mean reward: 0.589 [0.516, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.612, 10.102], loss: 0.001569, mae: 0.042287, mean_q: 1.173086
 796566/1000000: episode: 7966, duration: 0.631s, episode steps: 100, steps per second: 159, episode reward: 58.271, mean reward: 0.583 [0.509, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.252, 10.098], loss: 0.001550, mae: 0.042931, mean_q: 1.168919
 796666/1000000: episode: 7967, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 61.158, mean reward: 0.612 [0.498, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.992, 10.320], loss: 0.001474, mae: 0.041820, mean_q: 1.169384
 796766/1000000: episode: 7968, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 59.133, mean reward: 0.591 [0.498, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.830, 10.106], loss: 0.001530, mae: 0.042024, mean_q: 1.167106
 796866/1000000: episode: 7969, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 59.163, mean reward: 0.592 [0.505, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.985, 10.389], loss: 0.001560, mae: 0.043065, mean_q: 1.169714
 796966/1000000: episode: 7970, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 57.091, mean reward: 0.571 [0.502, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.587, 10.098], loss: 0.001395, mae: 0.040812, mean_q: 1.170568
 797066/1000000: episode: 7971, duration: 0.622s, episode steps: 100, steps per second: 161, episode reward: 57.271, mean reward: 0.573 [0.500, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.909, 10.184], loss: 0.001497, mae: 0.042020, mean_q: 1.168072
 797166/1000000: episode: 7972, duration: 0.683s, episode steps: 100, steps per second: 146, episode reward: 58.555, mean reward: 0.586 [0.503, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.461, 10.213], loss: 0.001470, mae: 0.041917, mean_q: 1.167946
 797266/1000000: episode: 7973, duration: 0.724s, episode steps: 100, steps per second: 138, episode reward: 60.610, mean reward: 0.606 [0.504, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.051, 10.098], loss: 0.001601, mae: 0.042454, mean_q: 1.168046
 797366/1000000: episode: 7974, duration: 0.689s, episode steps: 100, steps per second: 145, episode reward: 57.726, mean reward: 0.577 [0.501, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.532, 10.277], loss: 0.001496, mae: 0.042048, mean_q: 1.168612
 797466/1000000: episode: 7975, duration: 0.695s, episode steps: 100, steps per second: 144, episode reward: 57.972, mean reward: 0.580 [0.506, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.957, 10.117], loss: 0.001532, mae: 0.042529, mean_q: 1.168062
 797566/1000000: episode: 7976, duration: 0.714s, episode steps: 100, steps per second: 140, episode reward: 57.642, mean reward: 0.576 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.687, 10.098], loss: 0.001439, mae: 0.041296, mean_q: 1.169808
 797666/1000000: episode: 7977, duration: 0.680s, episode steps: 100, steps per second: 147, episode reward: 58.296, mean reward: 0.583 [0.499, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.965, 10.098], loss: 0.001521, mae: 0.042511, mean_q: 1.168367
 797766/1000000: episode: 7978, duration: 0.707s, episode steps: 100, steps per second: 141, episode reward: 58.043, mean reward: 0.580 [0.506, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.307, 10.098], loss: 0.001461, mae: 0.041837, mean_q: 1.166363
 797866/1000000: episode: 7979, duration: 0.711s, episode steps: 100, steps per second: 141, episode reward: 58.965, mean reward: 0.590 [0.509, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.868, 10.098], loss: 0.001494, mae: 0.041832, mean_q: 1.167038
 797966/1000000: episode: 7980, duration: 0.689s, episode steps: 100, steps per second: 145, episode reward: 58.658, mean reward: 0.587 [0.511, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.655, 10.117], loss: 0.001474, mae: 0.041396, mean_q: 1.166927
 798066/1000000: episode: 7981, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 61.514, mean reward: 0.615 [0.497, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.628, 10.098], loss: 0.001507, mae: 0.042095, mean_q: 1.167442
 798166/1000000: episode: 7982, duration: 0.618s, episode steps: 100, steps per second: 162, episode reward: 59.353, mean reward: 0.594 [0.501, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.435, 10.098], loss: 0.001417, mae: 0.040515, mean_q: 1.167137
 798266/1000000: episode: 7983, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 59.544, mean reward: 0.595 [0.513, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.985, 10.287], loss: 0.001519, mae: 0.042009, mean_q: 1.169313
 798366/1000000: episode: 7984, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 63.032, mean reward: 0.630 [0.506, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.050, 10.507], loss: 0.001511, mae: 0.042012, mean_q: 1.168048
 798466/1000000: episode: 7985, duration: 0.618s, episode steps: 100, steps per second: 162, episode reward: 61.099, mean reward: 0.611 [0.509, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.711, 10.151], loss: 0.001564, mae: 0.042865, mean_q: 1.174112
 798566/1000000: episode: 7986, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 59.198, mean reward: 0.592 [0.498, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.425, 10.278], loss: 0.001587, mae: 0.043193, mean_q: 1.174113
 798666/1000000: episode: 7987, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 59.115, mean reward: 0.591 [0.512, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.795, 10.150], loss: 0.001501, mae: 0.041772, mean_q: 1.173476
 798766/1000000: episode: 7988, duration: 0.608s, episode steps: 100, steps per second: 165, episode reward: 58.420, mean reward: 0.584 [0.507, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.945, 10.098], loss: 0.001542, mae: 0.042425, mean_q: 1.171330
 798866/1000000: episode: 7989, duration: 0.627s, episode steps: 100, steps per second: 159, episode reward: 56.990, mean reward: 0.570 [0.499, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.182, 10.098], loss: 0.001368, mae: 0.040470, mean_q: 1.171138
 798966/1000000: episode: 7990, duration: 0.687s, episode steps: 100, steps per second: 146, episode reward: 59.210, mean reward: 0.592 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.904, 10.209], loss: 0.001444, mae: 0.041251, mean_q: 1.172302
 799066/1000000: episode: 7991, duration: 0.716s, episode steps: 100, steps per second: 140, episode reward: 56.978, mean reward: 0.570 [0.501, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.341, 10.254], loss: 0.001482, mae: 0.041876, mean_q: 1.172718
 799166/1000000: episode: 7992, duration: 0.695s, episode steps: 100, steps per second: 144, episode reward: 57.480, mean reward: 0.575 [0.499, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.842, 10.334], loss: 0.001446, mae: 0.041459, mean_q: 1.171568
 799266/1000000: episode: 7993, duration: 0.697s, episode steps: 100, steps per second: 143, episode reward: 57.406, mean reward: 0.574 [0.507, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.261, 10.098], loss: 0.001418, mae: 0.041090, mean_q: 1.168236
 799366/1000000: episode: 7994, duration: 0.693s, episode steps: 100, steps per second: 144, episode reward: 61.923, mean reward: 0.619 [0.506, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.116, 10.404], loss: 0.001521, mae: 0.042463, mean_q: 1.167991
 799466/1000000: episode: 7995, duration: 0.719s, episode steps: 100, steps per second: 139, episode reward: 58.063, mean reward: 0.581 [0.508, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.202, 10.098], loss: 0.001450, mae: 0.041692, mean_q: 1.168925
 799566/1000000: episode: 7996, duration: 0.704s, episode steps: 100, steps per second: 142, episode reward: 58.119, mean reward: 0.581 [0.513, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.868, 10.201], loss: 0.001480, mae: 0.041556, mean_q: 1.170009
 799666/1000000: episode: 7997, duration: 0.727s, episode steps: 100, steps per second: 138, episode reward: 58.286, mean reward: 0.583 [0.499, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.619, 10.098], loss: 0.001391, mae: 0.040530, mean_q: 1.168165
 799766/1000000: episode: 7998, duration: 0.696s, episode steps: 100, steps per second: 144, episode reward: 58.978, mean reward: 0.590 [0.510, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.987, 10.155], loss: 0.001438, mae: 0.040809, mean_q: 1.165592
 799866/1000000: episode: 7999, duration: 0.745s, episode steps: 100, steps per second: 134, episode reward: 59.717, mean reward: 0.597 [0.508, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.826, 10.098], loss: 0.001503, mae: 0.042016, mean_q: 1.168018
 799966/1000000: episode: 8000, duration: 0.669s, episode steps: 100, steps per second: 149, episode reward: 57.752, mean reward: 0.578 [0.505, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.034, 10.098], loss: 0.001481, mae: 0.041619, mean_q: 1.165637
 800066/1000000: episode: 8001, duration: 0.716s, episode steps: 100, steps per second: 140, episode reward: 60.929, mean reward: 0.609 [0.512, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.892, 10.280], loss: 0.001406, mae: 0.040546, mean_q: 1.163178
 800166/1000000: episode: 8002, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 63.690, mean reward: 0.637 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.992, 10.098], loss: 0.001362, mae: 0.040294, mean_q: 1.172267
 800266/1000000: episode: 8003, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.082, mean reward: 0.581 [0.503, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.750, 10.098], loss: 0.001457, mae: 0.040654, mean_q: 1.168855
 800366/1000000: episode: 8004, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.133, mean reward: 0.581 [0.511, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.045, 10.176], loss: 0.001460, mae: 0.041728, mean_q: 1.169251
 800466/1000000: episode: 8005, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.131, mean reward: 0.571 [0.500, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.309, 10.155], loss: 0.001430, mae: 0.041072, mean_q: 1.165222
 800566/1000000: episode: 8006, duration: 0.610s, episode steps: 100, steps per second: 164, episode reward: 59.155, mean reward: 0.592 [0.507, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.039, 10.098], loss: 0.001466, mae: 0.041560, mean_q: 1.168188
 800666/1000000: episode: 8007, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 57.637, mean reward: 0.576 [0.500, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.701, 10.275], loss: 0.001502, mae: 0.042225, mean_q: 1.170354
 800766/1000000: episode: 8008, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 62.508, mean reward: 0.625 [0.504, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.658, 10.098], loss: 0.001501, mae: 0.041880, mean_q: 1.171836
 800866/1000000: episode: 8009, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.819, mean reward: 0.608 [0.509, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.805, 10.247], loss: 0.001466, mae: 0.041736, mean_q: 1.170494
 800966/1000000: episode: 8010, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.625, mean reward: 0.576 [0.499, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.450, 10.162], loss: 0.001389, mae: 0.040648, mean_q: 1.171507
 801066/1000000: episode: 8011, duration: 0.619s, episode steps: 100, steps per second: 162, episode reward: 57.883, mean reward: 0.579 [0.500, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.816, 10.098], loss: 0.001430, mae: 0.040990, mean_q: 1.172193
 801166/1000000: episode: 8012, duration: 0.622s, episode steps: 100, steps per second: 161, episode reward: 61.650, mean reward: 0.616 [0.514, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.602, 10.436], loss: 0.001376, mae: 0.040466, mean_q: 1.168083
 801266/1000000: episode: 8013, duration: 0.617s, episode steps: 100, steps per second: 162, episode reward: 59.014, mean reward: 0.590 [0.507, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.615, 10.098], loss: 0.001469, mae: 0.041642, mean_q: 1.170954
 801366/1000000: episode: 8014, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 62.776, mean reward: 0.628 [0.499, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-0.745, 10.365], loss: 0.001411, mae: 0.040960, mean_q: 1.169060
 801466/1000000: episode: 8015, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.724, mean reward: 0.587 [0.513, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.598, 10.138], loss: 0.001449, mae: 0.041080, mean_q: 1.171856
 801566/1000000: episode: 8016, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.027, mean reward: 0.590 [0.518, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.461, 10.209], loss: 0.001426, mae: 0.040771, mean_q: 1.172518
 801666/1000000: episode: 8017, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 59.344, mean reward: 0.593 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.538, 10.098], loss: 0.001465, mae: 0.041784, mean_q: 1.167200
 801766/1000000: episode: 8018, duration: 0.611s, episode steps: 100, steps per second: 164, episode reward: 57.386, mean reward: 0.574 [0.508, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.659, 10.120], loss: 0.001323, mae: 0.039671, mean_q: 1.171538
 801866/1000000: episode: 8019, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 63.235, mean reward: 0.632 [0.508, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.472, 10.098], loss: 0.001373, mae: 0.039693, mean_q: 1.168121
 801966/1000000: episode: 8020, duration: 0.703s, episode steps: 100, steps per second: 142, episode reward: 63.316, mean reward: 0.633 [0.509, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.803, 10.098], loss: 0.001428, mae: 0.041057, mean_q: 1.170121
 802066/1000000: episode: 8021, duration: 0.698s, episode steps: 100, steps per second: 143, episode reward: 58.701, mean reward: 0.587 [0.508, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.028, 10.098], loss: 0.001442, mae: 0.042030, mean_q: 1.176751
 802166/1000000: episode: 8022, duration: 0.708s, episode steps: 100, steps per second: 141, episode reward: 57.324, mean reward: 0.573 [0.508, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.601, 10.285], loss: 0.001378, mae: 0.041028, mean_q: 1.176115
 802266/1000000: episode: 8023, duration: 0.898s, episode steps: 100, steps per second: 111, episode reward: 58.161, mean reward: 0.582 [0.504, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.203, 10.148], loss: 0.001386, mae: 0.040462, mean_q: 1.173744
 802366/1000000: episode: 8024, duration: 0.713s, episode steps: 100, steps per second: 140, episode reward: 60.148, mean reward: 0.601 [0.505, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.780, 10.098], loss: 0.001349, mae: 0.039648, mean_q: 1.172371
 802466/1000000: episode: 8025, duration: 0.686s, episode steps: 100, steps per second: 146, episode reward: 62.993, mean reward: 0.630 [0.513, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.619, 10.098], loss: 0.001464, mae: 0.041702, mean_q: 1.174649
 802566/1000000: episode: 8026, duration: 0.690s, episode steps: 100, steps per second: 145, episode reward: 57.473, mean reward: 0.575 [0.507, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.625, 10.114], loss: 0.001260, mae: 0.039008, mean_q: 1.175375
 802666/1000000: episode: 8027, duration: 0.676s, episode steps: 100, steps per second: 148, episode reward: 58.305, mean reward: 0.583 [0.502, 0.843], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.523, 10.098], loss: 0.001363, mae: 0.039789, mean_q: 1.174679
 802766/1000000: episode: 8028, duration: 0.677s, episode steps: 100, steps per second: 148, episode reward: 59.938, mean reward: 0.599 [0.506, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.987, 10.098], loss: 0.001392, mae: 0.040656, mean_q: 1.174065
 802866/1000000: episode: 8029, duration: 0.669s, episode steps: 100, steps per second: 149, episode reward: 60.920, mean reward: 0.609 [0.508, 0.898], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.528, 10.098], loss: 0.001455, mae: 0.041357, mean_q: 1.178200
 802966/1000000: episode: 8030, duration: 0.650s, episode steps: 100, steps per second: 154, episode reward: 58.785, mean reward: 0.588 [0.507, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.197, 10.098], loss: 0.001447, mae: 0.041349, mean_q: 1.176328
 803066/1000000: episode: 8031, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 60.063, mean reward: 0.601 [0.515, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.830, 10.098], loss: 0.001390, mae: 0.039828, mean_q: 1.177518
 803166/1000000: episode: 8032, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.860, mean reward: 0.589 [0.515, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.144, 10.197], loss: 0.001411, mae: 0.040808, mean_q: 1.173336
 803266/1000000: episode: 8033, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.171, mean reward: 0.572 [0.502, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.605, 10.098], loss: 0.001466, mae: 0.041666, mean_q: 1.175492
 803366/1000000: episode: 8034, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.023, mean reward: 0.580 [0.505, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.737, 10.098], loss: 0.001376, mae: 0.039928, mean_q: 1.172060
 803466/1000000: episode: 8035, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.360, mean reward: 0.594 [0.515, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.016, 10.098], loss: 0.001477, mae: 0.041765, mean_q: 1.177460
 803566/1000000: episode: 8036, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.513, mean reward: 0.585 [0.508, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-2.462, 10.131], loss: 0.001357, mae: 0.040207, mean_q: 1.171119
 803666/1000000: episode: 8037, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.105, mean reward: 0.581 [0.515, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.669, 10.124], loss: 0.001396, mae: 0.040727, mean_q: 1.170303
 803766/1000000: episode: 8038, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.904, mean reward: 0.609 [0.506, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.765, 10.205], loss: 0.001514, mae: 0.041866, mean_q: 1.172781
 803866/1000000: episode: 8039, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.480, mean reward: 0.585 [0.506, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.916, 10.404], loss: 0.001438, mae: 0.041009, mean_q: 1.169472
 803966/1000000: episode: 8040, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.755, mean reward: 0.608 [0.499, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.449, 10.285], loss: 0.001500, mae: 0.041662, mean_q: 1.171517
 804066/1000000: episode: 8041, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.744, mean reward: 0.567 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.592, 10.206], loss: 0.001438, mae: 0.041796, mean_q: 1.174338
 804166/1000000: episode: 8042, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.330, mean reward: 0.573 [0.507, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.379, 10.246], loss: 0.001655, mae: 0.043851, mean_q: 1.172085
 804266/1000000: episode: 8043, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 62.345, mean reward: 0.623 [0.510, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.972, 10.098], loss: 0.001447, mae: 0.041380, mean_q: 1.170082
 804366/1000000: episode: 8044, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.219, mean reward: 0.592 [0.513, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.215, 10.214], loss: 0.001430, mae: 0.041232, mean_q: 1.174215
 804466/1000000: episode: 8045, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.999, mean reward: 0.580 [0.510, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.166, 10.098], loss: 0.001389, mae: 0.040280, mean_q: 1.173451
 804566/1000000: episode: 8046, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 58.318, mean reward: 0.583 [0.503, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.637, 10.231], loss: 0.001494, mae: 0.041962, mean_q: 1.176685
 804666/1000000: episode: 8047, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 56.922, mean reward: 0.569 [0.508, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.545, 10.167], loss: 0.001520, mae: 0.041734, mean_q: 1.176073
 804766/1000000: episode: 8048, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.121, mean reward: 0.591 [0.507, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.146, 10.098], loss: 0.001523, mae: 0.041567, mean_q: 1.174293
 804866/1000000: episode: 8049, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.614, mean reward: 0.596 [0.503, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.272, 10.098], loss: 0.001422, mae: 0.041299, mean_q: 1.172983
 804966/1000000: episode: 8050, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 55.940, mean reward: 0.559 [0.502, 0.654], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.879, 10.106], loss: 0.001484, mae: 0.041728, mean_q: 1.174849
 805066/1000000: episode: 8051, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.842, mean reward: 0.588 [0.511, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.649, 10.098], loss: 0.001395, mae: 0.040427, mean_q: 1.174651
 805166/1000000: episode: 8052, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.176, mean reward: 0.572 [0.503, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.010, 10.098], loss: 0.001383, mae: 0.040097, mean_q: 1.171016
 805266/1000000: episode: 8053, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.494, mean reward: 0.585 [0.513, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.933, 10.276], loss: 0.001411, mae: 0.041132, mean_q: 1.170471
 805366/1000000: episode: 8054, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.452, mean reward: 0.585 [0.507, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.730, 10.098], loss: 0.001447, mae: 0.041015, mean_q: 1.173025
 805466/1000000: episode: 8055, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 65.131, mean reward: 0.651 [0.514, 0.886], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.467, 10.386], loss: 0.001463, mae: 0.041294, mean_q: 1.171573
 805566/1000000: episode: 8056, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.827, mean reward: 0.588 [0.510, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.995, 10.243], loss: 0.001418, mae: 0.040789, mean_q: 1.173082
 805666/1000000: episode: 8057, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.362, mean reward: 0.594 [0.500, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.831, 10.098], loss: 0.001491, mae: 0.041620, mean_q: 1.173468
 805766/1000000: episode: 8058, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.266, mean reward: 0.593 [0.498, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.282, 10.135], loss: 0.001429, mae: 0.040851, mean_q: 1.173029
 805866/1000000: episode: 8059, duration: 0.610s, episode steps: 100, steps per second: 164, episode reward: 61.908, mean reward: 0.619 [0.532, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-1.199, 10.098], loss: 0.001505, mae: 0.042662, mean_q: 1.173896
 805966/1000000: episode: 8060, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.750, mean reward: 0.587 [0.502, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.290, 10.098], loss: 0.001447, mae: 0.041287, mean_q: 1.174088
 806066/1000000: episode: 8061, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.321, mean reward: 0.583 [0.502, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.907, 10.225], loss: 0.001598, mae: 0.043107, mean_q: 1.172396
 806166/1000000: episode: 8062, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.379, mean reward: 0.584 [0.509, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.664, 10.098], loss: 0.001550, mae: 0.041906, mean_q: 1.174546
 806266/1000000: episode: 8063, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.843, mean reward: 0.578 [0.509, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.032, 10.184], loss: 0.001498, mae: 0.041578, mean_q: 1.170536
 806366/1000000: episode: 8064, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.524, mean reward: 0.595 [0.505, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.781, 10.098], loss: 0.001508, mae: 0.042004, mean_q: 1.172742
 806466/1000000: episode: 8065, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.875, mean reward: 0.589 [0.505, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.894, 10.153], loss: 0.001511, mae: 0.041721, mean_q: 1.169152
 806566/1000000: episode: 8066, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 60.627, mean reward: 0.606 [0.516, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.242, 10.303], loss: 0.001497, mae: 0.041504, mean_q: 1.169197
 806666/1000000: episode: 8067, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.400, mean reward: 0.594 [0.506, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.292, 10.186], loss: 0.001473, mae: 0.041579, mean_q: 1.169622
 806766/1000000: episode: 8068, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 57.585, mean reward: 0.576 [0.513, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.933, 10.098], loss: 0.001546, mae: 0.041444, mean_q: 1.172779
 806866/1000000: episode: 8069, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 56.949, mean reward: 0.569 [0.511, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.022, 10.098], loss: 0.001592, mae: 0.042361, mean_q: 1.168524
 806966/1000000: episode: 8070, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.846, mean reward: 0.598 [0.501, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.123, 10.098], loss: 0.001602, mae: 0.042732, mean_q: 1.171456
 807066/1000000: episode: 8071, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 56.545, mean reward: 0.565 [0.503, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.047, 10.107], loss: 0.001539, mae: 0.042363, mean_q: 1.169712
 807166/1000000: episode: 8072, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.899, mean reward: 0.589 [0.505, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.628, 10.098], loss: 0.001510, mae: 0.041652, mean_q: 1.168236
 807266/1000000: episode: 8073, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 60.013, mean reward: 0.600 [0.501, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.949, 10.112], loss: 0.001513, mae: 0.041627, mean_q: 1.167991
 807366/1000000: episode: 8074, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.045, mean reward: 0.590 [0.507, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.442, 10.098], loss: 0.001516, mae: 0.041837, mean_q: 1.167994
 807466/1000000: episode: 8075, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.542, mean reward: 0.595 [0.511, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.409, 10.098], loss: 0.001562, mae: 0.042262, mean_q: 1.169326
 807566/1000000: episode: 8076, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 64.062, mean reward: 0.641 [0.510, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.351, 10.098], loss: 0.001490, mae: 0.041292, mean_q: 1.171035
 807666/1000000: episode: 8077, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.932, mean reward: 0.579 [0.507, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-2.024, 10.098], loss: 0.001630, mae: 0.042565, mean_q: 1.171737
 807766/1000000: episode: 8078, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.830, mean reward: 0.578 [0.499, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.526, 10.331], loss: 0.001498, mae: 0.041603, mean_q: 1.167602
 807866/1000000: episode: 8079, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.780, mean reward: 0.598 [0.505, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-2.218, 10.166], loss: 0.001589, mae: 0.042291, mean_q: 1.170937
 807966/1000000: episode: 8080, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.038, mean reward: 0.570 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.765, 10.098], loss: 0.001441, mae: 0.041374, mean_q: 1.164587
 808066/1000000: episode: 8081, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.567, mean reward: 0.606 [0.513, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.323, 10.098], loss: 0.001558, mae: 0.042206, mean_q: 1.164782
 808166/1000000: episode: 8082, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.555, mean reward: 0.596 [0.512, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.879, 10.098], loss: 0.001515, mae: 0.041658, mean_q: 1.168076
 808266/1000000: episode: 8083, duration: 0.657s, episode steps: 100, steps per second: 152, episode reward: 58.039, mean reward: 0.580 [0.500, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.099, 10.230], loss: 0.001445, mae: 0.041161, mean_q: 1.169096
 808366/1000000: episode: 8084, duration: 0.635s, episode steps: 100, steps per second: 158, episode reward: 59.909, mean reward: 0.599 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.979, 10.432], loss: 0.001463, mae: 0.041096, mean_q: 1.168766
 808466/1000000: episode: 8085, duration: 0.663s, episode steps: 100, steps per second: 151, episode reward: 58.492, mean reward: 0.585 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.558, 10.126], loss: 0.001482, mae: 0.041573, mean_q: 1.170051
 808566/1000000: episode: 8086, duration: 0.632s, episode steps: 100, steps per second: 158, episode reward: 57.546, mean reward: 0.575 [0.498, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.674, 10.191], loss: 0.001519, mae: 0.041426, mean_q: 1.165988
 808666/1000000: episode: 8087, duration: 0.617s, episode steps: 100, steps per second: 162, episode reward: 56.967, mean reward: 0.570 [0.500, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.561, 10.125], loss: 0.001450, mae: 0.040503, mean_q: 1.167888
 808766/1000000: episode: 8088, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.575, mean reward: 0.586 [0.517, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.400, 10.331], loss: 0.001439, mae: 0.040776, mean_q: 1.168585
 808866/1000000: episode: 8089, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.172, mean reward: 0.582 [0.505, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.779, 10.098], loss: 0.001626, mae: 0.042725, mean_q: 1.167439
 808966/1000000: episode: 8090, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 56.200, mean reward: 0.562 [0.501, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.261, 10.249], loss: 0.001422, mae: 0.040800, mean_q: 1.162726
 809066/1000000: episode: 8091, duration: 0.630s, episode steps: 100, steps per second: 159, episode reward: 61.658, mean reward: 0.617 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.639, 10.199], loss: 0.001447, mae: 0.040555, mean_q: 1.161348
 809166/1000000: episode: 8092, duration: 1.295s, episode steps: 100, steps per second: 77, episode reward: 57.809, mean reward: 0.578 [0.497, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.305, 10.098], loss: 0.001532, mae: 0.042194, mean_q: 1.169973
 809266/1000000: episode: 8093, duration: 0.747s, episode steps: 100, steps per second: 134, episode reward: 57.260, mean reward: 0.573 [0.499, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-2.006, 10.098], loss: 0.001549, mae: 0.041656, mean_q: 1.168086
 809366/1000000: episode: 8094, duration: 0.623s, episode steps: 100, steps per second: 161, episode reward: 63.115, mean reward: 0.631 [0.514, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.788, 10.098], loss: 0.001496, mae: 0.041579, mean_q: 1.162913
 809466/1000000: episode: 8095, duration: 0.737s, episode steps: 100, steps per second: 136, episode reward: 59.651, mean reward: 0.597 [0.510, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.619, 10.326], loss: 0.001548, mae: 0.042433, mean_q: 1.167510
 809566/1000000: episode: 8096, duration: 1.094s, episode steps: 100, steps per second: 91, episode reward: 58.536, mean reward: 0.585 [0.510, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.393, 10.098], loss: 0.001578, mae: 0.042854, mean_q: 1.167721
 809666/1000000: episode: 8097, duration: 1.207s, episode steps: 100, steps per second: 83, episode reward: 57.183, mean reward: 0.572 [0.508, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.849, 10.098], loss: 0.001520, mae: 0.042244, mean_q: 1.167717
 809766/1000000: episode: 8098, duration: 1.294s, episode steps: 100, steps per second: 77, episode reward: 62.194, mean reward: 0.622 [0.498, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.755, 10.499], loss: 0.001550, mae: 0.042008, mean_q: 1.167442
 809866/1000000: episode: 8099, duration: 0.849s, episode steps: 100, steps per second: 118, episode reward: 55.756, mean reward: 0.558 [0.500, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.042, 10.109], loss: 0.001514, mae: 0.041838, mean_q: 1.165078
 809966/1000000: episode: 8100, duration: 0.630s, episode steps: 100, steps per second: 159, episode reward: 58.723, mean reward: 0.587 [0.507, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.399, 10.295], loss: 0.001452, mae: 0.040660, mean_q: 1.165323
 810066/1000000: episode: 8101, duration: 0.729s, episode steps: 100, steps per second: 137, episode reward: 62.980, mean reward: 0.630 [0.515, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.552, 10.335], loss: 0.001449, mae: 0.040975, mean_q: 1.168198
 810166/1000000: episode: 8102, duration: 0.785s, episode steps: 100, steps per second: 127, episode reward: 58.332, mean reward: 0.583 [0.502, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.375, 10.098], loss: 0.001486, mae: 0.041302, mean_q: 1.168851
 810266/1000000: episode: 8103, duration: 0.726s, episode steps: 100, steps per second: 138, episode reward: 57.753, mean reward: 0.578 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.024, 10.098], loss: 0.001482, mae: 0.041247, mean_q: 1.168827
 810366/1000000: episode: 8104, duration: 0.708s, episode steps: 100, steps per second: 141, episode reward: 59.284, mean reward: 0.593 [0.508, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.643, 10.098], loss: 0.001475, mae: 0.041365, mean_q: 1.169617
 810466/1000000: episode: 8105, duration: 0.649s, episode steps: 100, steps per second: 154, episode reward: 58.303, mean reward: 0.583 [0.500, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.351, 10.216], loss: 0.001390, mae: 0.040169, mean_q: 1.168423
 810566/1000000: episode: 8106, duration: 0.628s, episode steps: 100, steps per second: 159, episode reward: 58.367, mean reward: 0.584 [0.498, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.176, 10.098], loss: 0.001405, mae: 0.040743, mean_q: 1.169176
 810666/1000000: episode: 8107, duration: 0.721s, episode steps: 100, steps per second: 139, episode reward: 57.893, mean reward: 0.579 [0.510, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-2.025, 10.098], loss: 0.001483, mae: 0.041427, mean_q: 1.166196
 810766/1000000: episode: 8108, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.161, mean reward: 0.582 [0.514, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.629, 10.479], loss: 0.001393, mae: 0.040060, mean_q: 1.170775
 810866/1000000: episode: 8109, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.231, mean reward: 0.572 [0.509, 0.669], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.736, 10.098], loss: 0.001454, mae: 0.040977, mean_q: 1.166487
 810966/1000000: episode: 8110, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 56.733, mean reward: 0.567 [0.508, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.748, 10.098], loss: 0.001405, mae: 0.040302, mean_q: 1.163621
 811066/1000000: episode: 8111, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 57.220, mean reward: 0.572 [0.507, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.393, 10.164], loss: 0.001454, mae: 0.041039, mean_q: 1.165376
 811166/1000000: episode: 8112, duration: 0.833s, episode steps: 100, steps per second: 120, episode reward: 61.863, mean reward: 0.619 [0.500, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.178, 10.329], loss: 0.001267, mae: 0.038815, mean_q: 1.163801
 811266/1000000: episode: 8113, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 57.511, mean reward: 0.575 [0.499, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.100, 10.433], loss: 0.001463, mae: 0.041055, mean_q: 1.167137
 811366/1000000: episode: 8114, duration: 0.656s, episode steps: 100, steps per second: 152, episode reward: 57.074, mean reward: 0.571 [0.509, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.984, 10.098], loss: 0.001275, mae: 0.038423, mean_q: 1.161581
 811466/1000000: episode: 8115, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 59.804, mean reward: 0.598 [0.501, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.143, 10.098], loss: 0.001327, mae: 0.039763, mean_q: 1.160513
 811566/1000000: episode: 8116, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 57.493, mean reward: 0.575 [0.503, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.945, 10.106], loss: 0.001419, mae: 0.040853, mean_q: 1.164406
 811666/1000000: episode: 8117, duration: 0.618s, episode steps: 100, steps per second: 162, episode reward: 56.867, mean reward: 0.569 [0.505, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.777, 10.098], loss: 0.001437, mae: 0.040752, mean_q: 1.163262
 811766/1000000: episode: 8118, duration: 0.645s, episode steps: 100, steps per second: 155, episode reward: 59.350, mean reward: 0.594 [0.513, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.560, 10.098], loss: 0.001260, mae: 0.039089, mean_q: 1.159307
 811866/1000000: episode: 8119, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 60.596, mean reward: 0.606 [0.500, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.264, 10.098], loss: 0.001312, mae: 0.039681, mean_q: 1.164551
 811966/1000000: episode: 8120, duration: 0.608s, episode steps: 100, steps per second: 165, episode reward: 58.143, mean reward: 0.581 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.008, 10.274], loss: 0.001319, mae: 0.039772, mean_q: 1.161972
 812066/1000000: episode: 8121, duration: 0.641s, episode steps: 100, steps per second: 156, episode reward: 58.761, mean reward: 0.588 [0.505, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.681, 10.397], loss: 0.001331, mae: 0.039887, mean_q: 1.164242
 812166/1000000: episode: 8122, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 59.749, mean reward: 0.597 [0.518, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.666, 10.118], loss: 0.001348, mae: 0.039555, mean_q: 1.163410
 812266/1000000: episode: 8123, duration: 0.661s, episode steps: 100, steps per second: 151, episode reward: 59.128, mean reward: 0.591 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.667, 10.098], loss: 0.001350, mae: 0.039641, mean_q: 1.162213
 812366/1000000: episode: 8124, duration: 0.623s, episode steps: 100, steps per second: 160, episode reward: 58.151, mean reward: 0.582 [0.511, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.260, 10.260], loss: 0.001313, mae: 0.039283, mean_q: 1.164057
 812466/1000000: episode: 8125, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.472, mean reward: 0.585 [0.507, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.366, 10.281], loss: 0.001329, mae: 0.039549, mean_q: 1.163130
 812566/1000000: episode: 8126, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.334, mean reward: 0.583 [0.498, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.555, 10.098], loss: 0.001302, mae: 0.039066, mean_q: 1.157990
 812666/1000000: episode: 8127, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 57.981, mean reward: 0.580 [0.505, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.823, 10.098], loss: 0.001311, mae: 0.039359, mean_q: 1.159534
 812766/1000000: episode: 8128, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 57.744, mean reward: 0.577 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.701, 10.098], loss: 0.001325, mae: 0.039255, mean_q: 1.160528
 812866/1000000: episode: 8129, duration: 0.645s, episode steps: 100, steps per second: 155, episode reward: 56.936, mean reward: 0.569 [0.503, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.420, 10.120], loss: 0.001352, mae: 0.039982, mean_q: 1.161966
 812966/1000000: episode: 8130, duration: 0.634s, episode steps: 100, steps per second: 158, episode reward: 57.975, mean reward: 0.580 [0.501, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.558, 10.341], loss: 0.001338, mae: 0.039635, mean_q: 1.161175
 813066/1000000: episode: 8131, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.581, mean reward: 0.586 [0.503, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.673, 10.098], loss: 0.001322, mae: 0.039737, mean_q: 1.160112
 813166/1000000: episode: 8132, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.023, mean reward: 0.570 [0.501, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.601, 10.169], loss: 0.001313, mae: 0.039483, mean_q: 1.155855
 813266/1000000: episode: 8133, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 66.053, mean reward: 0.661 [0.501, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.219, 10.244], loss: 0.001348, mae: 0.039577, mean_q: 1.157522
 813366/1000000: episode: 8134, duration: 0.615s, episode steps: 100, steps per second: 162, episode reward: 58.640, mean reward: 0.586 [0.508, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.256, 10.098], loss: 0.001343, mae: 0.039756, mean_q: 1.164075
 813466/1000000: episode: 8135, duration: 0.755s, episode steps: 100, steps per second: 133, episode reward: 59.150, mean reward: 0.592 [0.508, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.537, 10.126], loss: 0.001375, mae: 0.040408, mean_q: 1.160880
 813566/1000000: episode: 8136, duration: 0.732s, episode steps: 100, steps per second: 137, episode reward: 58.489, mean reward: 0.585 [0.506, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.404, 10.098], loss: 0.001290, mae: 0.038837, mean_q: 1.161075
 813666/1000000: episode: 8137, duration: 0.618s, episode steps: 100, steps per second: 162, episode reward: 58.213, mean reward: 0.582 [0.500, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.765, 10.098], loss: 0.001298, mae: 0.039120, mean_q: 1.162067
 813766/1000000: episode: 8138, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 57.535, mean reward: 0.575 [0.503, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.643, 10.165], loss: 0.001452, mae: 0.041388, mean_q: 1.163188
 813866/1000000: episode: 8139, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 59.875, mean reward: 0.599 [0.500, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.807, 10.098], loss: 0.001412, mae: 0.040712, mean_q: 1.158130
 813966/1000000: episode: 8140, duration: 0.643s, episode steps: 100, steps per second: 156, episode reward: 57.944, mean reward: 0.579 [0.499, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.561, 10.244], loss: 0.001406, mae: 0.040758, mean_q: 1.161655
 814066/1000000: episode: 8141, duration: 0.691s, episode steps: 100, steps per second: 145, episode reward: 59.456, mean reward: 0.595 [0.509, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.268, 10.098], loss: 0.001421, mae: 0.040999, mean_q: 1.161512
 814166/1000000: episode: 8142, duration: 0.663s, episode steps: 100, steps per second: 151, episode reward: 60.596, mean reward: 0.606 [0.506, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.386, 10.326], loss: 0.001355, mae: 0.040406, mean_q: 1.165208
 814266/1000000: episode: 8143, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.059, mean reward: 0.581 [0.505, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.314, 10.098], loss: 0.001371, mae: 0.040115, mean_q: 1.162604
 814366/1000000: episode: 8144, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.283, mean reward: 0.593 [0.510, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.832, 10.098], loss: 0.001381, mae: 0.040630, mean_q: 1.163102
 814466/1000000: episode: 8145, duration: 0.651s, episode steps: 100, steps per second: 154, episode reward: 57.335, mean reward: 0.573 [0.500, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.545, 10.140], loss: 0.001454, mae: 0.041598, mean_q: 1.160652
 814566/1000000: episode: 8146, duration: 0.800s, episode steps: 100, steps per second: 125, episode reward: 60.056, mean reward: 0.601 [0.506, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.835, 10.098], loss: 0.001318, mae: 0.039748, mean_q: 1.156836
 814666/1000000: episode: 8147, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.455, mean reward: 0.585 [0.505, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.784, 10.098], loss: 0.001399, mae: 0.040896, mean_q: 1.163886
 814766/1000000: episode: 8148, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.908, mean reward: 0.579 [0.507, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.296, 10.098], loss: 0.001412, mae: 0.041202, mean_q: 1.163539
 814866/1000000: episode: 8149, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 57.929, mean reward: 0.579 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.283, 10.417], loss: 0.001362, mae: 0.040231, mean_q: 1.157906
 814966/1000000: episode: 8150, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.248, mean reward: 0.592 [0.503, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.726, 10.098], loss: 0.001408, mae: 0.040731, mean_q: 1.159660
 815066/1000000: episode: 8151, duration: 0.728s, episode steps: 100, steps per second: 137, episode reward: 64.691, mean reward: 0.647 [0.503, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.415, 10.208], loss: 0.001418, mae: 0.040878, mean_q: 1.159829
 815166/1000000: episode: 8152, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 57.064, mean reward: 0.571 [0.504, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.342, 10.165], loss: 0.001487, mae: 0.042092, mean_q: 1.163164
 815266/1000000: episode: 8153, duration: 0.625s, episode steps: 100, steps per second: 160, episode reward: 62.338, mean reward: 0.623 [0.507, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.689, 10.292], loss: 0.001314, mae: 0.039515, mean_q: 1.161063
 815366/1000000: episode: 8154, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 61.198, mean reward: 0.612 [0.500, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.105, 10.261], loss: 0.001451, mae: 0.041533, mean_q: 1.164943
 815466/1000000: episode: 8155, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 56.930, mean reward: 0.569 [0.505, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.685, 10.098], loss: 0.001325, mae: 0.039739, mean_q: 1.162204
 815566/1000000: episode: 8156, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 61.620, mean reward: 0.616 [0.509, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.768, 10.163], loss: 0.001373, mae: 0.040337, mean_q: 1.163246
 815666/1000000: episode: 8157, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 58.089, mean reward: 0.581 [0.498, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.065, 10.192], loss: 0.001299, mae: 0.039542, mean_q: 1.163798
 815766/1000000: episode: 8158, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.892, mean reward: 0.589 [0.505, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.783, 10.098], loss: 0.001390, mae: 0.040585, mean_q: 1.161887
 815866/1000000: episode: 8159, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.290, mean reward: 0.593 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.592, 10.352], loss: 0.001355, mae: 0.040443, mean_q: 1.164096
 815966/1000000: episode: 8160, duration: 0.690s, episode steps: 100, steps per second: 145, episode reward: 58.125, mean reward: 0.581 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.649, 10.185], loss: 0.001399, mae: 0.040919, mean_q: 1.170207
 816066/1000000: episode: 8161, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.220, mean reward: 0.602 [0.512, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.621, 10.098], loss: 0.001396, mae: 0.040404, mean_q: 1.163383
 816166/1000000: episode: 8162, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 57.385, mean reward: 0.574 [0.513, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.733, 10.098], loss: 0.001418, mae: 0.041080, mean_q: 1.163848
 816266/1000000: episode: 8163, duration: 0.634s, episode steps: 100, steps per second: 158, episode reward: 57.427, mean reward: 0.574 [0.503, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.742, 10.098], loss: 0.001420, mae: 0.041445, mean_q: 1.168395
 816366/1000000: episode: 8164, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.415, mean reward: 0.584 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.535, 10.098], loss: 0.001393, mae: 0.040692, mean_q: 1.163274
 816466/1000000: episode: 8165, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.238, mean reward: 0.582 [0.499, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.026, 10.269], loss: 0.001466, mae: 0.041422, mean_q: 1.165112
 816566/1000000: episode: 8166, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.263, mean reward: 0.583 [0.500, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.670, 10.098], loss: 0.001356, mae: 0.039990, mean_q: 1.165372
 816666/1000000: episode: 8167, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.680, mean reward: 0.577 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.290, 10.098], loss: 0.001444, mae: 0.041194, mean_q: 1.169193
 816766/1000000: episode: 8168, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.515, mean reward: 0.605 [0.523, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.041, 10.098], loss: 0.001534, mae: 0.042359, mean_q: 1.167141
 816866/1000000: episode: 8169, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 57.781, mean reward: 0.578 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.724, 10.299], loss: 0.001364, mae: 0.040013, mean_q: 1.165798
 816966/1000000: episode: 8170, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 61.151, mean reward: 0.612 [0.503, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.249, 10.098], loss: 0.001419, mae: 0.041274, mean_q: 1.163172
 817066/1000000: episode: 8171, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 60.845, mean reward: 0.608 [0.499, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.468, 10.134], loss: 0.001441, mae: 0.040977, mean_q: 1.168069
 817166/1000000: episode: 8172, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.848, mean reward: 0.568 [0.498, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.799, 10.138], loss: 0.001467, mae: 0.041423, mean_q: 1.165109
 817266/1000000: episode: 8173, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.705, mean reward: 0.597 [0.502, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.937, 10.098], loss: 0.001501, mae: 0.042012, mean_q: 1.164457
 817366/1000000: episode: 8174, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.262, mean reward: 0.593 [0.499, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.984, 10.102], loss: 0.001538, mae: 0.042109, mean_q: 1.167494
 817466/1000000: episode: 8175, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 61.591, mean reward: 0.616 [0.508, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.834, 10.098], loss: 0.001467, mae: 0.041606, mean_q: 1.163461
 817566/1000000: episode: 8176, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.095, mean reward: 0.601 [0.511, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.516, 10.240], loss: 0.001574, mae: 0.043220, mean_q: 1.170337
 817666/1000000: episode: 8177, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.552, mean reward: 0.596 [0.508, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.962, 10.098], loss: 0.001468, mae: 0.042172, mean_q: 1.167666
 817766/1000000: episode: 8178, duration: 0.772s, episode steps: 100, steps per second: 130, episode reward: 57.631, mean reward: 0.576 [0.499, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.623, 10.175], loss: 0.001482, mae: 0.042170, mean_q: 1.169883
 817866/1000000: episode: 8179, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 60.112, mean reward: 0.601 [0.506, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.600, 10.098], loss: 0.001517, mae: 0.042746, mean_q: 1.170472
 817966/1000000: episode: 8180, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.562, mean reward: 0.596 [0.508, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.059, 10.162], loss: 0.001436, mae: 0.041597, mean_q: 1.170150
 818066/1000000: episode: 8181, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.760, mean reward: 0.588 [0.502, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.591, 10.124], loss: 0.001414, mae: 0.041546, mean_q: 1.172910
 818166/1000000: episode: 8182, duration: 0.669s, episode steps: 100, steps per second: 150, episode reward: 59.611, mean reward: 0.596 [0.501, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.875, 10.274], loss: 0.001467, mae: 0.041886, mean_q: 1.173409
 818266/1000000: episode: 8183, duration: 0.641s, episode steps: 100, steps per second: 156, episode reward: 59.084, mean reward: 0.591 [0.505, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.546, 10.410], loss: 0.001428, mae: 0.041464, mean_q: 1.164601
 818366/1000000: episode: 8184, duration: 0.875s, episode steps: 100, steps per second: 114, episode reward: 57.230, mean reward: 0.572 [0.500, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.163, 10.204], loss: 0.001540, mae: 0.043131, mean_q: 1.169499
 818466/1000000: episode: 8185, duration: 0.649s, episode steps: 100, steps per second: 154, episode reward: 58.388, mean reward: 0.584 [0.504, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.404, 10.256], loss: 0.001499, mae: 0.041947, mean_q: 1.170469
 818566/1000000: episode: 8186, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.703, mean reward: 0.577 [0.514, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.785, 10.159], loss: 0.001497, mae: 0.042159, mean_q: 1.169856
 818666/1000000: episode: 8187, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.874, mean reward: 0.589 [0.501, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.945, 10.168], loss: 0.001553, mae: 0.042860, mean_q: 1.170365
 818766/1000000: episode: 8188, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.126, mean reward: 0.591 [0.506, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.607, 10.216], loss: 0.001478, mae: 0.041773, mean_q: 1.169119
 818866/1000000: episode: 8189, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 57.415, mean reward: 0.574 [0.508, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.579, 10.267], loss: 0.001478, mae: 0.042287, mean_q: 1.171120
 818966/1000000: episode: 8190, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 57.464, mean reward: 0.575 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.154, 10.175], loss: 0.001449, mae: 0.041733, mean_q: 1.167746
 819066/1000000: episode: 8191, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.063, mean reward: 0.581 [0.499, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.818, 10.098], loss: 0.001426, mae: 0.041059, mean_q: 1.167607
 819166/1000000: episode: 8192, duration: 0.623s, episode steps: 100, steps per second: 161, episode reward: 59.645, mean reward: 0.596 [0.506, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.831, 10.098], loss: 0.001502, mae: 0.042115, mean_q: 1.166641
 819266/1000000: episode: 8193, duration: 0.660s, episode steps: 100, steps per second: 151, episode reward: 57.516, mean reward: 0.575 [0.509, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.996, 10.098], loss: 0.001422, mae: 0.040822, mean_q: 1.163224
 819366/1000000: episode: 8194, duration: 0.656s, episode steps: 100, steps per second: 152, episode reward: 60.744, mean reward: 0.607 [0.503, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.754, 10.321], loss: 0.001385, mae: 0.040928, mean_q: 1.167156
 819466/1000000: episode: 8195, duration: 0.676s, episode steps: 100, steps per second: 148, episode reward: 56.512, mean reward: 0.565 [0.501, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.702, 10.154], loss: 0.001523, mae: 0.042056, mean_q: 1.169656
 819566/1000000: episode: 8196, duration: 0.680s, episode steps: 100, steps per second: 147, episode reward: 57.712, mean reward: 0.577 [0.507, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.845, 10.239], loss: 0.001455, mae: 0.041433, mean_q: 1.168600
 819666/1000000: episode: 8197, duration: 0.633s, episode steps: 100, steps per second: 158, episode reward: 58.641, mean reward: 0.586 [0.509, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.107, 10.098], loss: 0.001512, mae: 0.042134, mean_q: 1.164465
 819766/1000000: episode: 8198, duration: 0.735s, episode steps: 100, steps per second: 136, episode reward: 57.757, mean reward: 0.578 [0.503, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.494, 10.098], loss: 0.001512, mae: 0.042295, mean_q: 1.166777
 819866/1000000: episode: 8199, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 58.893, mean reward: 0.589 [0.512, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.658, 10.098], loss: 0.001526, mae: 0.042089, mean_q: 1.167892
 819966/1000000: episode: 8200, duration: 0.651s, episode steps: 100, steps per second: 154, episode reward: 58.476, mean reward: 0.585 [0.514, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.363, 10.098], loss: 0.001413, mae: 0.041302, mean_q: 1.167729
 820066/1000000: episode: 8201, duration: 0.688s, episode steps: 100, steps per second: 145, episode reward: 56.075, mean reward: 0.561 [0.498, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.674, 10.098], loss: 0.001476, mae: 0.041651, mean_q: 1.161916
 820166/1000000: episode: 8202, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 57.047, mean reward: 0.570 [0.503, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.904, 10.098], loss: 0.001544, mae: 0.042291, mean_q: 1.162184
 820266/1000000: episode: 8203, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 62.373, mean reward: 0.624 [0.521, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.706, 10.098], loss: 0.001478, mae: 0.041473, mean_q: 1.162243
 820366/1000000: episode: 8204, duration: 0.755s, episode steps: 100, steps per second: 132, episode reward: 57.653, mean reward: 0.577 [0.506, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.656, 10.207], loss: 0.001468, mae: 0.041208, mean_q: 1.162804
 820466/1000000: episode: 8205, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.077, mean reward: 0.581 [0.503, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.794, 10.098], loss: 0.001485, mae: 0.041517, mean_q: 1.160286
 820566/1000000: episode: 8206, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.239, mean reward: 0.602 [0.501, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.196, 10.185], loss: 0.001542, mae: 0.042984, mean_q: 1.165082
 820666/1000000: episode: 8207, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.954, mean reward: 0.580 [0.507, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.209, 10.098], loss: 0.001418, mae: 0.041263, mean_q: 1.160243
 820766/1000000: episode: 8208, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 60.149, mean reward: 0.601 [0.502, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.417, 10.098], loss: 0.001456, mae: 0.041469, mean_q: 1.161559
 820866/1000000: episode: 8209, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.776, mean reward: 0.578 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.559, 10.169], loss: 0.001474, mae: 0.041892, mean_q: 1.159813
 820966/1000000: episode: 8210, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.487, mean reward: 0.595 [0.500, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.491, 10.365], loss: 0.001586, mae: 0.043297, mean_q: 1.164342
 821066/1000000: episode: 8211, duration: 0.621s, episode steps: 100, steps per second: 161, episode reward: 58.880, mean reward: 0.589 [0.498, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.376, 10.098], loss: 0.001494, mae: 0.042062, mean_q: 1.163019
 821166/1000000: episode: 8212, duration: 0.654s, episode steps: 100, steps per second: 153, episode reward: 57.524, mean reward: 0.575 [0.501, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.033, 10.113], loss: 0.001417, mae: 0.041767, mean_q: 1.161848
 821266/1000000: episode: 8213, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 58.714, mean reward: 0.587 [0.507, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.136, 10.224], loss: 0.001518, mae: 0.041891, mean_q: 1.162398
 821366/1000000: episode: 8214, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.369, mean reward: 0.594 [0.513, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.499, 10.328], loss: 0.001547, mae: 0.043120, mean_q: 1.164589
 821466/1000000: episode: 8215, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.712, mean reward: 0.597 [0.516, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.243, 10.316], loss: 0.001502, mae: 0.041308, mean_q: 1.160795
 821566/1000000: episode: 8216, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 57.707, mean reward: 0.577 [0.502, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.627, 10.098], loss: 0.001536, mae: 0.042379, mean_q: 1.163468
 821666/1000000: episode: 8217, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.602, mean reward: 0.576 [0.498, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.245, 10.098], loss: 0.001524, mae: 0.042295, mean_q: 1.160926
 821766/1000000: episode: 8218, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.062, mean reward: 0.621 [0.513, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.610, 10.228], loss: 0.001470, mae: 0.042073, mean_q: 1.161186
 821866/1000000: episode: 8219, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.718, mean reward: 0.597 [0.502, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.990, 10.328], loss: 0.001525, mae: 0.041928, mean_q: 1.165343
 821966/1000000: episode: 8220, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 59.444, mean reward: 0.594 [0.500, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.865, 10.157], loss: 0.001462, mae: 0.041632, mean_q: 1.165596
 822066/1000000: episode: 8221, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.216, mean reward: 0.612 [0.519, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.775, 10.210], loss: 0.001423, mae: 0.040850, mean_q: 1.162400
 822166/1000000: episode: 8222, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.795, mean reward: 0.618 [0.505, 0.882], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.134, 10.098], loss: 0.001517, mae: 0.041750, mean_q: 1.165187
 822266/1000000: episode: 8223, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.962, mean reward: 0.580 [0.503, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.850, 10.129], loss: 0.001493, mae: 0.042017, mean_q: 1.164899
 822366/1000000: episode: 8224, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.798, mean reward: 0.578 [0.503, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.560, 10.098], loss: 0.001500, mae: 0.042189, mean_q: 1.165047
 822466/1000000: episode: 8225, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.732, mean reward: 0.577 [0.503, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.870, 10.177], loss: 0.001469, mae: 0.041324, mean_q: 1.164605
 822566/1000000: episode: 8226, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.327, mean reward: 0.573 [0.497, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.168, 10.098], loss: 0.001445, mae: 0.040871, mean_q: 1.161224
 822666/1000000: episode: 8227, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.170, mean reward: 0.592 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.348, 10.351], loss: 0.001482, mae: 0.041719, mean_q: 1.160843
 822766/1000000: episode: 8228, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 61.508, mean reward: 0.615 [0.510, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.462, 10.312], loss: 0.001445, mae: 0.041311, mean_q: 1.159268
 822866/1000000: episode: 8229, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.142, mean reward: 0.601 [0.510, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.621, 10.098], loss: 0.001518, mae: 0.042400, mean_q: 1.161348
 822966/1000000: episode: 8230, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.724, mean reward: 0.607 [0.503, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.202, 10.455], loss: 0.001527, mae: 0.041954, mean_q: 1.164734
 823066/1000000: episode: 8231, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.043, mean reward: 0.590 [0.508, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.918, 10.259], loss: 0.001491, mae: 0.041631, mean_q: 1.164762
 823166/1000000: episode: 8232, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.798, mean reward: 0.578 [0.503, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.403, 10.098], loss: 0.001519, mae: 0.042215, mean_q: 1.162883
 823266/1000000: episode: 8233, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.831, mean reward: 0.578 [0.501, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.668, 10.098], loss: 0.001569, mae: 0.042930, mean_q: 1.163100
 823366/1000000: episode: 8234, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 60.984, mean reward: 0.610 [0.511, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.979, 10.098], loss: 0.001564, mae: 0.042020, mean_q: 1.163117
 823466/1000000: episode: 8235, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.252, mean reward: 0.583 [0.500, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.927, 10.148], loss: 0.001508, mae: 0.042155, mean_q: 1.162797
 823566/1000000: episode: 8236, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 61.272, mean reward: 0.613 [0.512, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.780, 10.284], loss: 0.001571, mae: 0.043250, mean_q: 1.164163
 823666/1000000: episode: 8237, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.463, mean reward: 0.595 [0.500, 0.881], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.843, 10.098], loss: 0.001515, mae: 0.041503, mean_q: 1.163347
 823766/1000000: episode: 8238, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 57.474, mean reward: 0.575 [0.504, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.881, 10.098], loss: 0.001558, mae: 0.042795, mean_q: 1.167922
 823866/1000000: episode: 8239, duration: 0.637s, episode steps: 100, steps per second: 157, episode reward: 58.411, mean reward: 0.584 [0.512, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.945, 10.098], loss: 0.001577, mae: 0.042760, mean_q: 1.170336
 823966/1000000: episode: 8240, duration: 0.621s, episode steps: 100, steps per second: 161, episode reward: 57.965, mean reward: 0.580 [0.504, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.046, 10.300], loss: 0.001531, mae: 0.042387, mean_q: 1.168623
 824066/1000000: episode: 8241, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.448, mean reward: 0.594 [0.502, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.763, 10.219], loss: 0.001517, mae: 0.042470, mean_q: 1.165467
 824166/1000000: episode: 8242, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.225, mean reward: 0.582 [0.502, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.410, 10.098], loss: 0.001535, mae: 0.042355, mean_q: 1.164765
 824266/1000000: episode: 8243, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.691, mean reward: 0.577 [0.507, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.131, 10.142], loss: 0.001487, mae: 0.041880, mean_q: 1.163058
 824366/1000000: episode: 8244, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.783, mean reward: 0.588 [0.499, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.647, 10.139], loss: 0.001529, mae: 0.042321, mean_q: 1.162410
 824466/1000000: episode: 8245, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.519, mean reward: 0.575 [0.500, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.980, 10.134], loss: 0.001506, mae: 0.042426, mean_q: 1.164563
 824566/1000000: episode: 8246, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.606, mean reward: 0.576 [0.507, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.462, 10.098], loss: 0.001407, mae: 0.041199, mean_q: 1.159868
 824666/1000000: episode: 8247, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.165, mean reward: 0.582 [0.511, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.381, 10.208], loss: 0.001529, mae: 0.042852, mean_q: 1.164742
 824766/1000000: episode: 8248, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 56.327, mean reward: 0.563 [0.501, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.740, 10.305], loss: 0.001417, mae: 0.040572, mean_q: 1.166052
 824866/1000000: episode: 8249, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.794, mean reward: 0.578 [0.508, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.274, 10.098], loss: 0.001465, mae: 0.041482, mean_q: 1.162965
 824966/1000000: episode: 8250, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.799, mean reward: 0.578 [0.513, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.191, 10.174], loss: 0.001464, mae: 0.041256, mean_q: 1.163451
 825066/1000000: episode: 8251, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 65.151, mean reward: 0.652 [0.523, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.681, 10.098], loss: 0.001470, mae: 0.041587, mean_q: 1.164364
 825166/1000000: episode: 8252, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.387, mean reward: 0.594 [0.506, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.327, 10.413], loss: 0.001564, mae: 0.043087, mean_q: 1.166818
 825266/1000000: episode: 8253, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.167, mean reward: 0.602 [0.501, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.846, 10.193], loss: 0.001600, mae: 0.043247, mean_q: 1.167950
 825366/1000000: episode: 8254, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.251, mean reward: 0.583 [0.499, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.861, 10.120], loss: 0.001570, mae: 0.042998, mean_q: 1.168422
 825466/1000000: episode: 8255, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.299, mean reward: 0.583 [0.500, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.616, 10.098], loss: 0.001499, mae: 0.042314, mean_q: 1.165062
 825566/1000000: episode: 8256, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 59.593, mean reward: 0.596 [0.504, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.752, 10.142], loss: 0.001433, mae: 0.041342, mean_q: 1.171953
 825666/1000000: episode: 8257, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.628, mean reward: 0.576 [0.508, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.634, 10.173], loss: 0.001532, mae: 0.042837, mean_q: 1.167436
 825766/1000000: episode: 8258, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 58.612, mean reward: 0.586 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.895, 10.098], loss: 0.001423, mae: 0.041462, mean_q: 1.162473
 825866/1000000: episode: 8259, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 58.491, mean reward: 0.585 [0.513, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.990, 10.098], loss: 0.001554, mae: 0.042818, mean_q: 1.166925
 825966/1000000: episode: 8260, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.688, mean reward: 0.577 [0.508, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.917, 10.209], loss: 0.001500, mae: 0.041737, mean_q: 1.166460
 826066/1000000: episode: 8261, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.061, mean reward: 0.571 [0.505, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.766, 10.233], loss: 0.001477, mae: 0.041380, mean_q: 1.165796
 826166/1000000: episode: 8262, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 59.158, mean reward: 0.592 [0.508, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.576, 10.248], loss: 0.001441, mae: 0.041407, mean_q: 1.166021
 826266/1000000: episode: 8263, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 57.916, mean reward: 0.579 [0.500, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.653, 10.101], loss: 0.001482, mae: 0.041717, mean_q: 1.166405
 826366/1000000: episode: 8264, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.136, mean reward: 0.591 [0.503, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.608, 10.259], loss: 0.001450, mae: 0.041608, mean_q: 1.164272
 826466/1000000: episode: 8265, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.300, mean reward: 0.573 [0.502, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.892, 10.098], loss: 0.001551, mae: 0.043199, mean_q: 1.169940
 826566/1000000: episode: 8266, duration: 0.533s, episode steps: 100, steps per second: 187, episode reward: 59.643, mean reward: 0.596 [0.502, 0.919], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.799, 10.098], loss: 0.001411, mae: 0.040826, mean_q: 1.164358
 826666/1000000: episode: 8267, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.369, mean reward: 0.584 [0.503, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.617, 10.098], loss: 0.001481, mae: 0.041617, mean_q: 1.164481
 826766/1000000: episode: 8268, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.904, mean reward: 0.589 [0.504, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.824, 10.121], loss: 0.001433, mae: 0.040905, mean_q: 1.163473
 826866/1000000: episode: 8269, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.858, mean reward: 0.619 [0.501, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.579, 10.395], loss: 0.001475, mae: 0.042006, mean_q: 1.162199
 826966/1000000: episode: 8270, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 63.184, mean reward: 0.632 [0.507, 0.893], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.823, 10.186], loss: 0.001662, mae: 0.043775, mean_q: 1.168708
 827066/1000000: episode: 8271, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 56.973, mean reward: 0.570 [0.508, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.415, 10.098], loss: 0.001508, mae: 0.041974, mean_q: 1.167309
 827166/1000000: episode: 8272, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.547, mean reward: 0.575 [0.503, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.684, 10.098], loss: 0.001462, mae: 0.041620, mean_q: 1.163180
 827266/1000000: episode: 8273, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 58.799, mean reward: 0.588 [0.509, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.852, 10.269], loss: 0.001571, mae: 0.042836, mean_q: 1.163646
 827366/1000000: episode: 8274, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 61.620, mean reward: 0.616 [0.510, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.987, 10.248], loss: 0.001560, mae: 0.042317, mean_q: 1.166618
 827466/1000000: episode: 8275, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.087, mean reward: 0.611 [0.535, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.442, 10.314], loss: 0.001416, mae: 0.040968, mean_q: 1.168048
 827566/1000000: episode: 8276, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 56.853, mean reward: 0.569 [0.499, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.410, 10.178], loss: 0.001564, mae: 0.042316, mean_q: 1.165679
 827666/1000000: episode: 8277, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 59.578, mean reward: 0.596 [0.500, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.604, 10.098], loss: 0.001528, mae: 0.042433, mean_q: 1.166615
 827766/1000000: episode: 8278, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.487, mean reward: 0.595 [0.507, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.721, 10.365], loss: 0.001539, mae: 0.042611, mean_q: 1.166672
 827866/1000000: episode: 8279, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 56.598, mean reward: 0.566 [0.511, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.274, 10.135], loss: 0.001539, mae: 0.042627, mean_q: 1.163088
 827966/1000000: episode: 8280, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.118, mean reward: 0.591 [0.505, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.486, 10.276], loss: 0.001578, mae: 0.042621, mean_q: 1.166141
 828066/1000000: episode: 8281, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.972, mean reward: 0.580 [0.500, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.935, 10.098], loss: 0.001642, mae: 0.043130, mean_q: 1.163431
 828166/1000000: episode: 8282, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.510, mean reward: 0.575 [0.512, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.813, 10.193], loss: 0.001551, mae: 0.042769, mean_q: 1.164865
 828266/1000000: episode: 8283, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.914, mean reward: 0.599 [0.505, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.835, 10.249], loss: 0.001499, mae: 0.041489, mean_q: 1.165885
 828366/1000000: episode: 8284, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.721, mean reward: 0.587 [0.516, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.414, 10.332], loss: 0.001492, mae: 0.041633, mean_q: 1.163663
 828466/1000000: episode: 8285, duration: 0.620s, episode steps: 100, steps per second: 161, episode reward: 59.775, mean reward: 0.598 [0.506, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.178, 10.309], loss: 0.001472, mae: 0.041396, mean_q: 1.163173
 828566/1000000: episode: 8286, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.039, mean reward: 0.600 [0.503, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.335, 10.238], loss: 0.001478, mae: 0.042059, mean_q: 1.165806
 828666/1000000: episode: 8287, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.557, mean reward: 0.566 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.941, 10.098], loss: 0.001343, mae: 0.039895, mean_q: 1.161969
 828766/1000000: episode: 8288, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 59.068, mean reward: 0.591 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.341, 10.098], loss: 0.001588, mae: 0.042669, mean_q: 1.162406
 828866/1000000: episode: 8289, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.030, mean reward: 0.580 [0.503, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.069, 10.098], loss: 0.001473, mae: 0.041496, mean_q: 1.163730
 828966/1000000: episode: 8290, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 59.741, mean reward: 0.597 [0.501, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.531, 10.098], loss: 0.001499, mae: 0.041907, mean_q: 1.164821
 829066/1000000: episode: 8291, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 61.164, mean reward: 0.612 [0.499, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.416, 10.449], loss: 0.001519, mae: 0.042009, mean_q: 1.166360
 829166/1000000: episode: 8292, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.685, mean reward: 0.597 [0.501, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.275, 10.322], loss: 0.001452, mae: 0.040921, mean_q: 1.162933
 829266/1000000: episode: 8293, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 56.982, mean reward: 0.570 [0.501, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.434, 10.098], loss: 0.001444, mae: 0.040830, mean_q: 1.163133
 829366/1000000: episode: 8294, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.501, mean reward: 0.575 [0.507, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.795, 10.098], loss: 0.001517, mae: 0.042213, mean_q: 1.161839
 829466/1000000: episode: 8295, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.338, mean reward: 0.593 [0.509, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.773, 10.098], loss: 0.001582, mae: 0.042134, mean_q: 1.162989
 829566/1000000: episode: 8296, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.886, mean reward: 0.589 [0.501, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.094, 10.333], loss: 0.001459, mae: 0.041700, mean_q: 1.162747
 829666/1000000: episode: 8297, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 57.660, mean reward: 0.577 [0.501, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.512, 10.275], loss: 0.001513, mae: 0.041720, mean_q: 1.163569
 829766/1000000: episode: 8298, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.231, mean reward: 0.582 [0.503, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.867, 10.103], loss: 0.001515, mae: 0.041792, mean_q: 1.165385
 829866/1000000: episode: 8299, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.921, mean reward: 0.579 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.470, 10.138], loss: 0.001460, mae: 0.042176, mean_q: 1.165375
 829966/1000000: episode: 8300, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.862, mean reward: 0.579 [0.500, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.245, 10.197], loss: 0.001505, mae: 0.041894, mean_q: 1.167913
 830066/1000000: episode: 8301, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.206, mean reward: 0.582 [0.501, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.005, 10.098], loss: 0.001444, mae: 0.041014, mean_q: 1.163264
 830166/1000000: episode: 8302, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.084, mean reward: 0.581 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.344, 10.227], loss: 0.001514, mae: 0.041966, mean_q: 1.163229
 830266/1000000: episode: 8303, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.031, mean reward: 0.580 [0.507, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.625, 10.323], loss: 0.001561, mae: 0.042848, mean_q: 1.161734
 830366/1000000: episode: 8304, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.868, mean reward: 0.579 [0.505, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.476, 10.115], loss: 0.001519, mae: 0.042682, mean_q: 1.162214
 830466/1000000: episode: 8305, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.628, mean reward: 0.586 [0.510, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.953, 10.098], loss: 0.001492, mae: 0.042008, mean_q: 1.165441
 830566/1000000: episode: 8306, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 59.239, mean reward: 0.592 [0.518, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.091, 10.098], loss: 0.001576, mae: 0.042628, mean_q: 1.163029
 830666/1000000: episode: 8307, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.282, mean reward: 0.593 [0.510, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.591, 10.294], loss: 0.001525, mae: 0.041558, mean_q: 1.159363
 830766/1000000: episode: 8308, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 61.203, mean reward: 0.612 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.267, 10.442], loss: 0.001442, mae: 0.041210, mean_q: 1.159228
 830866/1000000: episode: 8309, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.670, mean reward: 0.567 [0.504, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.847, 10.123], loss: 0.001485, mae: 0.041438, mean_q: 1.160900
 830966/1000000: episode: 8310, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.464, mean reward: 0.595 [0.513, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.832, 10.245], loss: 0.001502, mae: 0.041621, mean_q: 1.162177
 831066/1000000: episode: 8311, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.426, mean reward: 0.574 [0.508, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.326, 10.116], loss: 0.001464, mae: 0.041441, mean_q: 1.163091
 831166/1000000: episode: 8312, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 56.977, mean reward: 0.570 [0.505, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.686, 10.098], loss: 0.001503, mae: 0.041737, mean_q: 1.162263
 831266/1000000: episode: 8313, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.811, mean reward: 0.578 [0.516, 0.654], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.160, 10.281], loss: 0.001572, mae: 0.041933, mean_q: 1.166031
 831366/1000000: episode: 8314, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.539, mean reward: 0.585 [0.505, 0.879], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.868, 10.152], loss: 0.001442, mae: 0.040967, mean_q: 1.163144
 831466/1000000: episode: 8315, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.866, mean reward: 0.589 [0.505, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.660, 10.368], loss: 0.001400, mae: 0.040281, mean_q: 1.161728
 831566/1000000: episode: 8316, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.530, mean reward: 0.605 [0.497, 0.929], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.137, 10.098], loss: 0.001444, mae: 0.040954, mean_q: 1.161581
 831666/1000000: episode: 8317, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 60.855, mean reward: 0.609 [0.505, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.780, 10.098], loss: 0.001453, mae: 0.040600, mean_q: 1.165681
 831766/1000000: episode: 8318, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 58.667, mean reward: 0.587 [0.511, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.036, 10.098], loss: 0.001593, mae: 0.042211, mean_q: 1.165348
 831866/1000000: episode: 8319, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.167, mean reward: 0.572 [0.512, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.414, 10.115], loss: 0.001494, mae: 0.041236, mean_q: 1.164545
 831966/1000000: episode: 8320, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.729, mean reward: 0.577 [0.514, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.981, 10.214], loss: 0.001510, mae: 0.041595, mean_q: 1.161360
 832066/1000000: episode: 8321, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.763, mean reward: 0.578 [0.501, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.640, 10.098], loss: 0.001448, mae: 0.040602, mean_q: 1.162346
 832166/1000000: episode: 8322, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.616, mean reward: 0.596 [0.501, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.393, 10.218], loss: 0.001443, mae: 0.040702, mean_q: 1.163003
 832266/1000000: episode: 8323, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.074, mean reward: 0.571 [0.501, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.876, 10.136], loss: 0.001375, mae: 0.039916, mean_q: 1.160230
 832366/1000000: episode: 8324, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.280, mean reward: 0.573 [0.506, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.978, 10.189], loss: 0.001459, mae: 0.041604, mean_q: 1.159996
 832466/1000000: episode: 8325, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.850, mean reward: 0.588 [0.511, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.550, 10.182], loss: 0.001498, mae: 0.041631, mean_q: 1.157491
 832566/1000000: episode: 8326, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 58.491, mean reward: 0.585 [0.506, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.457, 10.206], loss: 0.001447, mae: 0.040984, mean_q: 1.159300
 832666/1000000: episode: 8327, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.279, mean reward: 0.583 [0.511, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.083, 10.208], loss: 0.001495, mae: 0.041249, mean_q: 1.156643
 832766/1000000: episode: 8328, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.540, mean reward: 0.595 [0.510, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.874, 10.098], loss: 0.001434, mae: 0.040950, mean_q: 1.159118
 832866/1000000: episode: 8329, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.435, mean reward: 0.584 [0.511, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.423, 10.098], loss: 0.001432, mae: 0.041522, mean_q: 1.159336
 832966/1000000: episode: 8330, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 61.250, mean reward: 0.613 [0.505, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.894, 10.280], loss: 0.001538, mae: 0.042146, mean_q: 1.157548
 833066/1000000: episode: 8331, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 62.143, mean reward: 0.621 [0.505, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.716, 10.098], loss: 0.001485, mae: 0.041159, mean_q: 1.159060
 833166/1000000: episode: 8332, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 56.453, mean reward: 0.565 [0.501, 0.669], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.808, 10.157], loss: 0.001423, mae: 0.041001, mean_q: 1.160045
 833266/1000000: episode: 8333, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.723, mean reward: 0.577 [0.503, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.468, 10.098], loss: 0.001555, mae: 0.041920, mean_q: 1.162238
 833366/1000000: episode: 8334, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 60.033, mean reward: 0.600 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.430, 10.480], loss: 0.001547, mae: 0.042631, mean_q: 1.159818
 833466/1000000: episode: 8335, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.025, mean reward: 0.580 [0.502, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.690, 10.098], loss: 0.001474, mae: 0.040834, mean_q: 1.159535
 833566/1000000: episode: 8336, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.680, mean reward: 0.607 [0.502, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.667, 10.098], loss: 0.001496, mae: 0.041353, mean_q: 1.160614
 833666/1000000: episode: 8337, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.289, mean reward: 0.613 [0.502, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.937, 10.098], loss: 0.001531, mae: 0.042388, mean_q: 1.161851
 833766/1000000: episode: 8338, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.178, mean reward: 0.612 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.481, 10.098], loss: 0.001394, mae: 0.040293, mean_q: 1.159098
 833866/1000000: episode: 8339, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 56.868, mean reward: 0.569 [0.507, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.667, 10.098], loss: 0.001575, mae: 0.042747, mean_q: 1.162086
 833966/1000000: episode: 8340, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.410, mean reward: 0.594 [0.515, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.777, 10.136], loss: 0.001463, mae: 0.041102, mean_q: 1.162631
 834066/1000000: episode: 8341, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.373, mean reward: 0.604 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.993, 10.098], loss: 0.001433, mae: 0.041024, mean_q: 1.159726
 834166/1000000: episode: 8342, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.117, mean reward: 0.601 [0.510, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.155, 10.098], loss: 0.001412, mae: 0.041024, mean_q: 1.164458
 834266/1000000: episode: 8343, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 59.629, mean reward: 0.596 [0.503, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.696, 10.254], loss: 0.001467, mae: 0.041215, mean_q: 1.163351
 834366/1000000: episode: 8344, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.218, mean reward: 0.592 [0.506, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.444, 10.098], loss: 0.001504, mae: 0.041770, mean_q: 1.164412
 834466/1000000: episode: 8345, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.942, mean reward: 0.589 [0.501, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.687, 10.222], loss: 0.001470, mae: 0.042312, mean_q: 1.161950
 834566/1000000: episode: 8346, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.577, mean reward: 0.606 [0.503, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.174, 10.098], loss: 0.001453, mae: 0.041780, mean_q: 1.163524
 834666/1000000: episode: 8347, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.114, mean reward: 0.591 [0.504, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.545, 10.099], loss: 0.001589, mae: 0.042517, mean_q: 1.165260
 834766/1000000: episode: 8348, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.283, mean reward: 0.573 [0.499, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.779, 10.123], loss: 0.001617, mae: 0.043359, mean_q: 1.165024
 834866/1000000: episode: 8349, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.861, mean reward: 0.599 [0.501, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.679, 10.098], loss: 0.001672, mae: 0.044531, mean_q: 1.166021
 834966/1000000: episode: 8350, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.270, mean reward: 0.593 [0.498, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.420, 10.121], loss: 0.001586, mae: 0.043278, mean_q: 1.165538
 835066/1000000: episode: 8351, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.330, mean reward: 0.573 [0.500, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.618, 10.133], loss: 0.001435, mae: 0.041223, mean_q: 1.166183
 835166/1000000: episode: 8352, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.625, mean reward: 0.576 [0.499, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.799, 10.110], loss: 0.001538, mae: 0.042232, mean_q: 1.165302
 835266/1000000: episode: 8353, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.766, mean reward: 0.578 [0.498, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.973, 10.098], loss: 0.001560, mae: 0.042312, mean_q: 1.164338
 835366/1000000: episode: 8354, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.954, mean reward: 0.590 [0.506, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.451, 10.165], loss: 0.001446, mae: 0.041315, mean_q: 1.166508
 835466/1000000: episode: 8355, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 56.811, mean reward: 0.568 [0.503, 0.668], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.999, 10.295], loss: 0.001554, mae: 0.042439, mean_q: 1.169123
 835566/1000000: episode: 8356, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.547, mean reward: 0.575 [0.505, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.690, 10.098], loss: 0.001384, mae: 0.040608, mean_q: 1.164307
 835666/1000000: episode: 8357, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.734, mean reward: 0.577 [0.498, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.035, 10.112], loss: 0.001489, mae: 0.041799, mean_q: 1.163724
 835766/1000000: episode: 8358, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 60.677, mean reward: 0.607 [0.506, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.120, 10.172], loss: 0.001510, mae: 0.041986, mean_q: 1.166067
 835866/1000000: episode: 8359, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 61.928, mean reward: 0.619 [0.512, 0.832], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.923, 10.235], loss: 0.001564, mae: 0.043048, mean_q: 1.167160
 835966/1000000: episode: 8360, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.424, mean reward: 0.574 [0.504, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.094, 10.098], loss: 0.001538, mae: 0.042652, mean_q: 1.167929
 836066/1000000: episode: 8361, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.549, mean reward: 0.575 [0.503, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.724, 10.143], loss: 0.001495, mae: 0.042117, mean_q: 1.165496
 836166/1000000: episode: 8362, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 61.705, mean reward: 0.617 [0.505, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.336, 10.200], loss: 0.001602, mae: 0.043021, mean_q: 1.167919
 836266/1000000: episode: 8363, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 61.884, mean reward: 0.619 [0.516, 0.858], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.998, 10.450], loss: 0.001477, mae: 0.041780, mean_q: 1.168652
 836366/1000000: episode: 8364, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.430, mean reward: 0.584 [0.498, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.392, 10.099], loss: 0.001463, mae: 0.041289, mean_q: 1.166586
 836466/1000000: episode: 8365, duration: 0.520s, episode steps: 100, steps per second: 192, episode reward: 59.112, mean reward: 0.591 [0.499, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.677, 10.098], loss: 0.001474, mae: 0.041433, mean_q: 1.167757
 836566/1000000: episode: 8366, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 58.757, mean reward: 0.588 [0.510, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.745, 10.098], loss: 0.001455, mae: 0.041458, mean_q: 1.167305
 836666/1000000: episode: 8367, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.490, mean reward: 0.575 [0.502, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.172, 10.098], loss: 0.001492, mae: 0.042458, mean_q: 1.166255
 836766/1000000: episode: 8368, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.089, mean reward: 0.581 [0.510, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.651, 10.388], loss: 0.001585, mae: 0.043660, mean_q: 1.168287
 836866/1000000: episode: 8369, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.970, mean reward: 0.580 [0.501, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.706, 10.098], loss: 0.001634, mae: 0.044135, mean_q: 1.170573
 836966/1000000: episode: 8370, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.519, mean reward: 0.575 [0.500, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.492, 10.098], loss: 0.001605, mae: 0.043848, mean_q: 1.168277
 837066/1000000: episode: 8371, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 61.165, mean reward: 0.612 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.543, 10.099], loss: 0.001508, mae: 0.041782, mean_q: 1.163562
 837166/1000000: episode: 8372, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.550, mean reward: 0.576 [0.505, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.626, 10.181], loss: 0.001510, mae: 0.042625, mean_q: 1.166781
 837266/1000000: episode: 8373, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 57.520, mean reward: 0.575 [0.509, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.733, 10.130], loss: 0.001461, mae: 0.041777, mean_q: 1.167918
 837366/1000000: episode: 8374, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.142, mean reward: 0.581 [0.500, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.461, 10.436], loss: 0.001523, mae: 0.042240, mean_q: 1.165541
 837466/1000000: episode: 8375, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.665, mean reward: 0.587 [0.515, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.812, 10.198], loss: 0.001540, mae: 0.042268, mean_q: 1.166013
 837566/1000000: episode: 8376, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.545, mean reward: 0.575 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.685, 10.115], loss: 0.001593, mae: 0.043195, mean_q: 1.164950
 837666/1000000: episode: 8377, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.574, mean reward: 0.576 [0.498, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.204, 10.098], loss: 0.001592, mae: 0.042942, mean_q: 1.164140
 837766/1000000: episode: 8378, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 59.092, mean reward: 0.591 [0.518, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.378, 10.337], loss: 0.001516, mae: 0.042710, mean_q: 1.164100
 837866/1000000: episode: 8379, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.056, mean reward: 0.591 [0.502, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.218, 10.172], loss: 0.001584, mae: 0.043158, mean_q: 1.165262
 837966/1000000: episode: 8380, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.940, mean reward: 0.589 [0.512, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.588, 10.168], loss: 0.001570, mae: 0.042622, mean_q: 1.163722
 838066/1000000: episode: 8381, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.293, mean reward: 0.583 [0.502, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.930, 10.098], loss: 0.001525, mae: 0.042257, mean_q: 1.163502
 838166/1000000: episode: 8382, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.552, mean reward: 0.586 [0.500, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.303, 10.099], loss: 0.001550, mae: 0.043397, mean_q: 1.165295
 838266/1000000: episode: 8383, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 57.478, mean reward: 0.575 [0.506, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.580, 10.258], loss: 0.001651, mae: 0.044037, mean_q: 1.165313
 838366/1000000: episode: 8384, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.102, mean reward: 0.581 [0.498, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.221, 10.098], loss: 0.001495, mae: 0.042777, mean_q: 1.161683
 838466/1000000: episode: 8385, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.896, mean reward: 0.599 [0.511, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.850, 10.098], loss: 0.001587, mae: 0.043215, mean_q: 1.163708
 838566/1000000: episode: 8386, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.818, mean reward: 0.588 [0.499, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.671, 10.155], loss: 0.001631, mae: 0.043406, mean_q: 1.164447
 838666/1000000: episode: 8387, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.891, mean reward: 0.579 [0.506, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.552, 10.098], loss: 0.001558, mae: 0.042896, mean_q: 1.163958
 838766/1000000: episode: 8388, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.494, mean reward: 0.595 [0.513, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.072, 10.363], loss: 0.001476, mae: 0.041435, mean_q: 1.163690
 838866/1000000: episode: 8389, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 61.111, mean reward: 0.611 [0.518, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.548, 10.098], loss: 0.001554, mae: 0.042752, mean_q: 1.164107
 838966/1000000: episode: 8390, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.871, mean reward: 0.599 [0.502, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.568, 10.139], loss: 0.001496, mae: 0.041820, mean_q: 1.163329
 839066/1000000: episode: 8391, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 56.960, mean reward: 0.570 [0.501, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.198, 10.098], loss: 0.001566, mae: 0.043062, mean_q: 1.163582
 839166/1000000: episode: 8392, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.812, mean reward: 0.598 [0.505, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.490, 10.098], loss: 0.001525, mae: 0.042384, mean_q: 1.163639
 839266/1000000: episode: 8393, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.790, mean reward: 0.598 [0.502, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.230, 10.463], loss: 0.001497, mae: 0.041835, mean_q: 1.161081
 839366/1000000: episode: 8394, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.618, mean reward: 0.606 [0.503, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.466, 10.220], loss: 0.001523, mae: 0.042280, mean_q: 1.165813
 839466/1000000: episode: 8395, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.838, mean reward: 0.588 [0.499, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-2.490, 10.098], loss: 0.001550, mae: 0.042418, mean_q: 1.163469
 839566/1000000: episode: 8396, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 58.267, mean reward: 0.583 [0.503, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.348, 10.098], loss: 0.001538, mae: 0.042748, mean_q: 1.168372
 839666/1000000: episode: 8397, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.858, mean reward: 0.589 [0.510, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.484, 10.319], loss: 0.001444, mae: 0.041559, mean_q: 1.163338
 839766/1000000: episode: 8398, duration: 0.628s, episode steps: 100, steps per second: 159, episode reward: 60.338, mean reward: 0.603 [0.508, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.583, 10.329], loss: 0.001496, mae: 0.041512, mean_q: 1.161325
 839866/1000000: episode: 8399, duration: 0.620s, episode steps: 100, steps per second: 161, episode reward: 60.073, mean reward: 0.601 [0.502, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.703, 10.248], loss: 0.001528, mae: 0.042301, mean_q: 1.158754
 839966/1000000: episode: 8400, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.559, mean reward: 0.576 [0.505, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.908, 10.104], loss: 0.001506, mae: 0.041922, mean_q: 1.161343
 840066/1000000: episode: 8401, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.327, mean reward: 0.573 [0.508, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.508, 10.098], loss: 0.001443, mae: 0.041548, mean_q: 1.164002
 840166/1000000: episode: 8402, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 56.760, mean reward: 0.568 [0.502, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.617, 10.098], loss: 0.001556, mae: 0.042551, mean_q: 1.163745
 840266/1000000: episode: 8403, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.832, mean reward: 0.588 [0.509, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.015, 10.098], loss: 0.001468, mae: 0.041531, mean_q: 1.162536
 840366/1000000: episode: 8404, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.732, mean reward: 0.577 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.958, 10.098], loss: 0.001556, mae: 0.042731, mean_q: 1.163044
 840466/1000000: episode: 8405, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.319, mean reward: 0.583 [0.502, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.481, 10.166], loss: 0.001413, mae: 0.041147, mean_q: 1.162779
 840566/1000000: episode: 8406, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.650, mean reward: 0.586 [0.498, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.781, 10.145], loss: 0.001553, mae: 0.043050, mean_q: 1.164075
 840666/1000000: episode: 8407, duration: 0.656s, episode steps: 100, steps per second: 152, episode reward: 58.666, mean reward: 0.587 [0.512, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.391, 10.098], loss: 0.001522, mae: 0.042390, mean_q: 1.164118
 840766/1000000: episode: 8408, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.662, mean reward: 0.597 [0.500, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.333, 10.098], loss: 0.001479, mae: 0.041797, mean_q: 1.163247
 840866/1000000: episode: 8409, duration: 0.769s, episode steps: 100, steps per second: 130, episode reward: 58.151, mean reward: 0.582 [0.507, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.766, 10.159], loss: 0.001454, mae: 0.041787, mean_q: 1.159699
 840966/1000000: episode: 8410, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 62.311, mean reward: 0.623 [0.507, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.416, 10.098], loss: 0.001507, mae: 0.042315, mean_q: 1.161876
 841066/1000000: episode: 8411, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.749, mean reward: 0.607 [0.510, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.080, 10.221], loss: 0.001511, mae: 0.042347, mean_q: 1.164904
 841166/1000000: episode: 8412, duration: 0.684s, episode steps: 100, steps per second: 146, episode reward: 58.355, mean reward: 0.584 [0.504, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.004, 10.098], loss: 0.001569, mae: 0.043060, mean_q: 1.163446
 841266/1000000: episode: 8413, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 61.542, mean reward: 0.615 [0.510, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.331, 10.105], loss: 0.001567, mae: 0.042992, mean_q: 1.166088
 841366/1000000: episode: 8414, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.784, mean reward: 0.588 [0.501, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.348, 10.098], loss: 0.001500, mae: 0.042318, mean_q: 1.164402
 841466/1000000: episode: 8415, duration: 0.611s, episode steps: 100, steps per second: 164, episode reward: 63.390, mean reward: 0.634 [0.515, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-2.031, 10.281], loss: 0.001570, mae: 0.043121, mean_q: 1.165246
 841566/1000000: episode: 8416, duration: 0.648s, episode steps: 100, steps per second: 154, episode reward: 63.853, mean reward: 0.639 [0.513, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.805, 10.353], loss: 0.001525, mae: 0.042451, mean_q: 1.169500
 841666/1000000: episode: 8417, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.052, mean reward: 0.591 [0.499, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.636, 10.332], loss: 0.001459, mae: 0.041618, mean_q: 1.168158
 841766/1000000: episode: 8418, duration: 0.608s, episode steps: 100, steps per second: 164, episode reward: 59.221, mean reward: 0.592 [0.510, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-0.889, 10.098], loss: 0.001513, mae: 0.041897, mean_q: 1.168496
 841866/1000000: episode: 8419, duration: 0.670s, episode steps: 100, steps per second: 149, episode reward: 58.139, mean reward: 0.581 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.293, 10.098], loss: 0.001478, mae: 0.042166, mean_q: 1.170253
 841966/1000000: episode: 8420, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.771, mean reward: 0.578 [0.508, 0.667], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.379, 10.098], loss: 0.001548, mae: 0.042636, mean_q: 1.167988
 842066/1000000: episode: 8421, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.071, mean reward: 0.581 [0.497, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.867, 10.185], loss: 0.001499, mae: 0.042152, mean_q: 1.166187
 842166/1000000: episode: 8422, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.929, mean reward: 0.579 [0.500, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.090, 10.226], loss: 0.001413, mae: 0.040726, mean_q: 1.168960
 842266/1000000: episode: 8423, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.950, mean reward: 0.599 [0.516, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.649, 10.098], loss: 0.001542, mae: 0.042535, mean_q: 1.167902
 842366/1000000: episode: 8424, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 57.239, mean reward: 0.572 [0.500, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.853, 10.098], loss: 0.001577, mae: 0.042935, mean_q: 1.167768
 842466/1000000: episode: 8425, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 62.358, mean reward: 0.624 [0.499, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.610, 10.098], loss: 0.001569, mae: 0.042764, mean_q: 1.167437
 842566/1000000: episode: 8426, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.436, mean reward: 0.584 [0.500, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.626, 10.098], loss: 0.001504, mae: 0.042114, mean_q: 1.170290
 842666/1000000: episode: 8427, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.447, mean reward: 0.614 [0.508, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.267, 10.405], loss: 0.001502, mae: 0.042072, mean_q: 1.169770
 842766/1000000: episode: 8428, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.815, mean reward: 0.588 [0.509, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.807, 10.130], loss: 0.001495, mae: 0.041817, mean_q: 1.171488
 842866/1000000: episode: 8429, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.885, mean reward: 0.579 [0.508, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.534, 10.098], loss: 0.001543, mae: 0.042092, mean_q: 1.171788
 842966/1000000: episode: 8430, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 58.654, mean reward: 0.587 [0.506, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.825, 10.300], loss: 0.001491, mae: 0.041817, mean_q: 1.169270
 843066/1000000: episode: 8431, duration: 0.637s, episode steps: 100, steps per second: 157, episode reward: 61.602, mean reward: 0.616 [0.504, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.793, 10.098], loss: 0.001606, mae: 0.043487, mean_q: 1.171996
 843166/1000000: episode: 8432, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.996, mean reward: 0.590 [0.505, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.707, 10.248], loss: 0.001585, mae: 0.042925, mean_q: 1.171286
 843266/1000000: episode: 8433, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 59.370, mean reward: 0.594 [0.506, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.709, 10.322], loss: 0.001534, mae: 0.042612, mean_q: 1.172895
 843366/1000000: episode: 8434, duration: 0.642s, episode steps: 100, steps per second: 156, episode reward: 57.600, mean reward: 0.576 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.269, 10.128], loss: 0.001537, mae: 0.042062, mean_q: 1.175749
 843466/1000000: episode: 8435, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.607, mean reward: 0.596 [0.503, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.761, 10.098], loss: 0.001538, mae: 0.042269, mean_q: 1.173942
 843566/1000000: episode: 8436, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 62.447, mean reward: 0.624 [0.511, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.676, 10.272], loss: 0.001587, mae: 0.043464, mean_q: 1.173274
 843666/1000000: episode: 8437, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 60.353, mean reward: 0.604 [0.507, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.986, 10.107], loss: 0.001598, mae: 0.043679, mean_q: 1.171504
 843766/1000000: episode: 8438, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.759, mean reward: 0.588 [0.500, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.101, 10.098], loss: 0.001639, mae: 0.043250, mean_q: 1.174951
 843866/1000000: episode: 8439, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.676, mean reward: 0.607 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.118, 10.098], loss: 0.001452, mae: 0.041148, mean_q: 1.174697
 843966/1000000: episode: 8440, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 57.528, mean reward: 0.575 [0.500, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.307, 10.098], loss: 0.001592, mae: 0.042898, mean_q: 1.173645
 844066/1000000: episode: 8441, duration: 0.704s, episode steps: 100, steps per second: 142, episode reward: 59.107, mean reward: 0.591 [0.505, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.944, 10.152], loss: 0.001607, mae: 0.043627, mean_q: 1.177433
 844166/1000000: episode: 8442, duration: 0.745s, episode steps: 100, steps per second: 134, episode reward: 60.066, mean reward: 0.601 [0.510, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.949, 10.235], loss: 0.001614, mae: 0.043288, mean_q: 1.174249
 844266/1000000: episode: 8443, duration: 0.628s, episode steps: 100, steps per second: 159, episode reward: 59.562, mean reward: 0.596 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.040, 10.252], loss: 0.001598, mae: 0.043260, mean_q: 1.177596
 844366/1000000: episode: 8444, duration: 0.742s, episode steps: 100, steps per second: 135, episode reward: 59.569, mean reward: 0.596 [0.508, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.049, 10.098], loss: 0.001664, mae: 0.043917, mean_q: 1.175269
 844466/1000000: episode: 8445, duration: 0.799s, episode steps: 100, steps per second: 125, episode reward: 58.223, mean reward: 0.582 [0.502, 0.675], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.619, 10.100], loss: 0.001529, mae: 0.042459, mean_q: 1.176949
 844566/1000000: episode: 8446, duration: 0.688s, episode steps: 100, steps per second: 145, episode reward: 61.583, mean reward: 0.616 [0.506, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.202, 10.241], loss: 0.001615, mae: 0.043127, mean_q: 1.174446
 844666/1000000: episode: 8447, duration: 0.655s, episode steps: 100, steps per second: 153, episode reward: 58.364, mean reward: 0.584 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.762, 10.098], loss: 0.001534, mae: 0.042426, mean_q: 1.174417
 844766/1000000: episode: 8448, duration: 0.804s, episode steps: 100, steps per second: 124, episode reward: 58.763, mean reward: 0.588 [0.501, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.658, 10.098], loss: 0.001583, mae: 0.043010, mean_q: 1.175788
 844866/1000000: episode: 8449, duration: 0.654s, episode steps: 100, steps per second: 153, episode reward: 62.375, mean reward: 0.624 [0.519, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.760, 10.098], loss: 0.001576, mae: 0.043213, mean_q: 1.175575
 844966/1000000: episode: 8450, duration: 0.649s, episode steps: 100, steps per second: 154, episode reward: 56.953, mean reward: 0.570 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.963, 10.206], loss: 0.001495, mae: 0.041936, mean_q: 1.175369
 845066/1000000: episode: 8451, duration: 0.801s, episode steps: 100, steps per second: 125, episode reward: 57.627, mean reward: 0.576 [0.498, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.888, 10.269], loss: 0.001461, mae: 0.041443, mean_q: 1.172745
 845166/1000000: episode: 8452, duration: 0.944s, episode steps: 100, steps per second: 106, episode reward: 58.817, mean reward: 0.588 [0.507, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.178, 10.336], loss: 0.001520, mae: 0.042555, mean_q: 1.177200
 845266/1000000: episode: 8453, duration: 0.658s, episode steps: 100, steps per second: 152, episode reward: 58.901, mean reward: 0.589 [0.502, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.610, 10.332], loss: 0.001573, mae: 0.043109, mean_q: 1.176637
 845366/1000000: episode: 8454, duration: 0.666s, episode steps: 100, steps per second: 150, episode reward: 57.224, mean reward: 0.572 [0.514, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.986, 10.155], loss: 0.001544, mae: 0.042891, mean_q: 1.174862
 845466/1000000: episode: 8455, duration: 0.654s, episode steps: 100, steps per second: 153, episode reward: 59.592, mean reward: 0.596 [0.500, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.587, 10.098], loss: 0.001469, mae: 0.041768, mean_q: 1.177735
 845566/1000000: episode: 8456, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.457, mean reward: 0.595 [0.506, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.035, 10.315], loss: 0.001566, mae: 0.042907, mean_q: 1.177442
 845666/1000000: episode: 8457, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.994, mean reward: 0.590 [0.508, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.289, 10.098], loss: 0.001474, mae: 0.041941, mean_q: 1.173297
 845766/1000000: episode: 8458, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 58.609, mean reward: 0.586 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.346, 10.339], loss: 0.001530, mae: 0.042424, mean_q: 1.177141
 845866/1000000: episode: 8459, duration: 0.617s, episode steps: 100, steps per second: 162, episode reward: 59.172, mean reward: 0.592 [0.516, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.930, 10.098], loss: 0.001506, mae: 0.042200, mean_q: 1.176259
 845966/1000000: episode: 8460, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.819, mean reward: 0.588 [0.502, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.143, 10.163], loss: 0.001599, mae: 0.043295, mean_q: 1.177697
 846066/1000000: episode: 8461, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.416, mean reward: 0.604 [0.505, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.774, 10.272], loss: 0.001376, mae: 0.040661, mean_q: 1.176688
 846166/1000000: episode: 8462, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.522, mean reward: 0.575 [0.502, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.190, 10.098], loss: 0.001431, mae: 0.040414, mean_q: 1.175127
 846266/1000000: episode: 8463, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 60.429, mean reward: 0.604 [0.498, 0.873], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.598, 10.206], loss: 0.001489, mae: 0.042351, mean_q: 1.176104
 846366/1000000: episode: 8464, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.442, mean reward: 0.574 [0.506, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.554, 10.135], loss: 0.001523, mae: 0.042133, mean_q: 1.173418
 846466/1000000: episode: 8465, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.011, mean reward: 0.610 [0.532, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.410, 10.245], loss: 0.001463, mae: 0.041626, mean_q: 1.171369
 846566/1000000: episode: 8466, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.444, mean reward: 0.584 [0.503, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.887, 10.149], loss: 0.001499, mae: 0.042266, mean_q: 1.174961
 846666/1000000: episode: 8467, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 56.675, mean reward: 0.567 [0.499, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.301, 10.140], loss: 0.001577, mae: 0.043004, mean_q: 1.173174
 846766/1000000: episode: 8468, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.605, mean reward: 0.576 [0.502, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.073, 10.255], loss: 0.001519, mae: 0.042094, mean_q: 1.170214
 846866/1000000: episode: 8469, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.172, mean reward: 0.592 [0.507, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.550, 10.098], loss: 0.001491, mae: 0.042596, mean_q: 1.175364
 846966/1000000: episode: 8470, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.204, mean reward: 0.582 [0.499, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.337, 10.098], loss: 0.001472, mae: 0.041682, mean_q: 1.170928
 847066/1000000: episode: 8471, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.180, mean reward: 0.582 [0.502, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.865, 10.128], loss: 0.001340, mae: 0.039880, mean_q: 1.170440
 847166/1000000: episode: 8472, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 59.783, mean reward: 0.598 [0.509, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.842, 10.304], loss: 0.001444, mae: 0.041577, mean_q: 1.170965
 847266/1000000: episode: 8473, duration: 0.604s, episode steps: 100, steps per second: 165, episode reward: 62.143, mean reward: 0.621 [0.517, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.676, 10.098], loss: 0.001445, mae: 0.041520, mean_q: 1.170259
 847366/1000000: episode: 8474, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.944, mean reward: 0.579 [0.509, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.575, 10.098], loss: 0.001527, mae: 0.042661, mean_q: 1.173435
 847466/1000000: episode: 8475, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.073, mean reward: 0.581 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.402, 10.098], loss: 0.001424, mae: 0.040775, mean_q: 1.169201
 847566/1000000: episode: 8476, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 59.071, mean reward: 0.591 [0.500, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.963, 10.098], loss: 0.001394, mae: 0.040606, mean_q: 1.172757
 847666/1000000: episode: 8477, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 59.651, mean reward: 0.597 [0.506, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.359, 10.172], loss: 0.001521, mae: 0.042421, mean_q: 1.171488
 847766/1000000: episode: 8478, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.725, mean reward: 0.577 [0.505, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.302, 10.147], loss: 0.001539, mae: 0.042795, mean_q: 1.171435
 847866/1000000: episode: 8479, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.101, mean reward: 0.581 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.587, 10.145], loss: 0.001531, mae: 0.042379, mean_q: 1.168934
 847966/1000000: episode: 8480, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.064, mean reward: 0.591 [0.518, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.557, 10.191], loss: 0.001456, mae: 0.041627, mean_q: 1.168762
 848066/1000000: episode: 8481, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.478, mean reward: 0.565 [0.504, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.558, 10.127], loss: 0.001493, mae: 0.042602, mean_q: 1.167896
 848166/1000000: episode: 8482, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 62.216, mean reward: 0.622 [0.504, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.303, 10.098], loss: 0.001441, mae: 0.041634, mean_q: 1.165172
 848266/1000000: episode: 8483, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 60.483, mean reward: 0.605 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.933, 10.250], loss: 0.001412, mae: 0.041179, mean_q: 1.169001
 848366/1000000: episode: 8484, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.978, mean reward: 0.610 [0.517, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.788, 10.243], loss: 0.001444, mae: 0.041785, mean_q: 1.171448
 848466/1000000: episode: 8485, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.398, mean reward: 0.604 [0.525, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.027, 10.098], loss: 0.001419, mae: 0.040702, mean_q: 1.169407
 848566/1000000: episode: 8486, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.158, mean reward: 0.602 [0.500, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.395, 10.098], loss: 0.001352, mae: 0.040482, mean_q: 1.169355
 848666/1000000: episode: 8487, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.358, mean reward: 0.574 [0.501, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.095, 10.098], loss: 0.001394, mae: 0.040806, mean_q: 1.170900
 848766/1000000: episode: 8488, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.584, mean reward: 0.586 [0.507, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.692, 10.157], loss: 0.001378, mae: 0.040833, mean_q: 1.169937
 848866/1000000: episode: 8489, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.990, mean reward: 0.600 [0.517, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.941, 10.287], loss: 0.001441, mae: 0.041548, mean_q: 1.168173
 848966/1000000: episode: 8490, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.207, mean reward: 0.582 [0.514, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.540, 10.098], loss: 0.001448, mae: 0.041087, mean_q: 1.167217
 849066/1000000: episode: 8491, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.939, mean reward: 0.569 [0.505, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.020, 10.105], loss: 0.001464, mae: 0.042502, mean_q: 1.170303
 849166/1000000: episode: 8492, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.539, mean reward: 0.595 [0.501, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.537, 10.098], loss: 0.001421, mae: 0.041212, mean_q: 1.166428
 849266/1000000: episode: 8493, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.936, mean reward: 0.579 [0.500, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.790, 10.225], loss: 0.001413, mae: 0.041457, mean_q: 1.168155
 849366/1000000: episode: 8494, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 60.882, mean reward: 0.609 [0.523, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.450, 10.132], loss: 0.001401, mae: 0.041261, mean_q: 1.168151
 849466/1000000: episode: 8495, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.152, mean reward: 0.572 [0.506, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.172, 10.112], loss: 0.001424, mae: 0.040959, mean_q: 1.168491
 849566/1000000: episode: 8496, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.616, mean reward: 0.576 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.724, 10.098], loss: 0.001390, mae: 0.040988, mean_q: 1.168676
 849666/1000000: episode: 8497, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.974, mean reward: 0.600 [0.502, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.769, 10.098], loss: 0.001326, mae: 0.040029, mean_q: 1.165921
 849766/1000000: episode: 8498, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.772, mean reward: 0.588 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.797, 10.216], loss: 0.001387, mae: 0.041062, mean_q: 1.165549
 849866/1000000: episode: 8499, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.833, mean reward: 0.608 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.650, 10.098], loss: 0.001408, mae: 0.041186, mean_q: 1.165220
 849966/1000000: episode: 8500, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.834, mean reward: 0.608 [0.510, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.705, 10.098], loss: 0.001359, mae: 0.040575, mean_q: 1.167796
 850066/1000000: episode: 8501, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.031, mean reward: 0.600 [0.503, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.515, 10.098], loss: 0.001390, mae: 0.040996, mean_q: 1.168676
 850166/1000000: episode: 8502, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.557, mean reward: 0.596 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.869, 10.408], loss: 0.001414, mae: 0.040776, mean_q: 1.169019
 850266/1000000: episode: 8503, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 65.730, mean reward: 0.657 [0.518, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.500, 10.440], loss: 0.001441, mae: 0.041513, mean_q: 1.171497
 850366/1000000: episode: 8504, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.236, mean reward: 0.582 [0.505, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.798, 10.205], loss: 0.001363, mae: 0.040925, mean_q: 1.173026
 850466/1000000: episode: 8505, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.268, mean reward: 0.593 [0.505, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.831, 10.098], loss: 0.001345, mae: 0.040230, mean_q: 1.173119
 850566/1000000: episode: 8506, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.928, mean reward: 0.579 [0.503, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.313, 10.098], loss: 0.001450, mae: 0.041860, mean_q: 1.171700
 850666/1000000: episode: 8507, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.985, mean reward: 0.580 [0.503, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.485, 10.098], loss: 0.001432, mae: 0.041221, mean_q: 1.166448
 850766/1000000: episode: 8508, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.212, mean reward: 0.582 [0.502, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.752, 10.098], loss: 0.001438, mae: 0.041498, mean_q: 1.169353
 850866/1000000: episode: 8509, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.565, mean reward: 0.596 [0.504, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.200, 10.180], loss: 0.001589, mae: 0.042991, mean_q: 1.171321
 850966/1000000: episode: 8510, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.076, mean reward: 0.591 [0.511, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.679, 10.213], loss: 0.001515, mae: 0.042583, mean_q: 1.171931
 851066/1000000: episode: 8511, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.824, mean reward: 0.588 [0.498, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.823, 10.098], loss: 0.001578, mae: 0.043170, mean_q: 1.172755
 851166/1000000: episode: 8512, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.936, mean reward: 0.589 [0.500, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.429, 10.098], loss: 0.001475, mae: 0.041947, mean_q: 1.168336
 851266/1000000: episode: 8513, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.655, mean reward: 0.587 [0.507, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.391, 10.260], loss: 0.001467, mae: 0.042170, mean_q: 1.169981
 851366/1000000: episode: 8514, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.829, mean reward: 0.598 [0.518, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.607, 10.098], loss: 0.001456, mae: 0.041975, mean_q: 1.170349
 851466/1000000: episode: 8515, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.501, mean reward: 0.605 [0.504, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.211, 10.204], loss: 0.001480, mae: 0.042034, mean_q: 1.171844
 851566/1000000: episode: 8516, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.739, mean reward: 0.597 [0.503, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.274, 10.098], loss: 0.001470, mae: 0.042534, mean_q: 1.170444
 851666/1000000: episode: 8517, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.243, mean reward: 0.582 [0.510, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.716, 10.166], loss: 0.001514, mae: 0.042411, mean_q: 1.177019
 851766/1000000: episode: 8518, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.363, mean reward: 0.574 [0.503, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.622, 10.098], loss: 0.001448, mae: 0.041429, mean_q: 1.168987
 851866/1000000: episode: 8519, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.253, mean reward: 0.613 [0.499, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.304, 10.098], loss: 0.001468, mae: 0.041708, mean_q: 1.172836
 851966/1000000: episode: 8520, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.182, mean reward: 0.592 [0.513, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.401, 10.098], loss: 0.001542, mae: 0.042862, mean_q: 1.173842
 852066/1000000: episode: 8521, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.123, mean reward: 0.591 [0.497, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.362, 10.159], loss: 0.001478, mae: 0.041853, mean_q: 1.173671
 852166/1000000: episode: 8522, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.161, mean reward: 0.602 [0.497, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.976, 10.301], loss: 0.001470, mae: 0.042309, mean_q: 1.175171
 852266/1000000: episode: 8523, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.176, mean reward: 0.602 [0.501, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.472, 10.284], loss: 0.001539, mae: 0.042699, mean_q: 1.178071
 852366/1000000: episode: 8524, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.100, mean reward: 0.581 [0.504, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.724, 10.158], loss: 0.001518, mae: 0.042243, mean_q: 1.171490
 852466/1000000: episode: 8525, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.999, mean reward: 0.590 [0.503, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.711, 10.098], loss: 0.001521, mae: 0.042923, mean_q: 1.174735
 852566/1000000: episode: 8526, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.873, mean reward: 0.579 [0.505, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.863, 10.098], loss: 0.001556, mae: 0.042789, mean_q: 1.173523
 852666/1000000: episode: 8527, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.289, mean reward: 0.573 [0.505, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.877, 10.098], loss: 0.001400, mae: 0.040847, mean_q: 1.172841
 852766/1000000: episode: 8528, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 59.303, mean reward: 0.593 [0.513, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.869, 10.149], loss: 0.001372, mae: 0.040366, mean_q: 1.173500
 852866/1000000: episode: 8529, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 61.236, mean reward: 0.612 [0.506, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.644, 10.098], loss: 0.001460, mae: 0.041638, mean_q: 1.173827
 852966/1000000: episode: 8530, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.162, mean reward: 0.572 [0.498, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.478, 10.098], loss: 0.001428, mae: 0.040800, mean_q: 1.172193
 853066/1000000: episode: 8531, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 62.261, mean reward: 0.623 [0.506, 0.855], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.294, 10.143], loss: 0.001564, mae: 0.042699, mean_q: 1.175041
 853166/1000000: episode: 8532, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.559, mean reward: 0.616 [0.503, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.928, 10.098], loss: 0.001527, mae: 0.042358, mean_q: 1.173251
 853266/1000000: episode: 8533, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 59.279, mean reward: 0.593 [0.509, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.575, 10.476], loss: 0.001436, mae: 0.041517, mean_q: 1.171984
 853366/1000000: episode: 8534, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.555, mean reward: 0.606 [0.502, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.597, 10.098], loss: 0.001451, mae: 0.041383, mean_q: 1.171240
 853466/1000000: episode: 8535, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.977, mean reward: 0.590 [0.501, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.543, 10.122], loss: 0.001576, mae: 0.043545, mean_q: 1.172900
 853566/1000000: episode: 8536, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 56.941, mean reward: 0.569 [0.512, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.241, 10.232], loss: 0.001560, mae: 0.043414, mean_q: 1.172810
 853666/1000000: episode: 8537, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.279, mean reward: 0.583 [0.503, 0.817], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.361, 10.147], loss: 0.001511, mae: 0.042776, mean_q: 1.173415
 853766/1000000: episode: 8538, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 59.182, mean reward: 0.592 [0.501, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.509, 10.153], loss: 0.001501, mae: 0.041892, mean_q: 1.171629
 853866/1000000: episode: 8539, duration: 0.621s, episode steps: 100, steps per second: 161, episode reward: 60.107, mean reward: 0.601 [0.501, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.773, 10.333], loss: 0.001582, mae: 0.043140, mean_q: 1.172623
 853966/1000000: episode: 8540, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.253, mean reward: 0.573 [0.500, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.438, 10.098], loss: 0.001488, mae: 0.042690, mean_q: 1.173404
 854066/1000000: episode: 8541, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.966, mean reward: 0.580 [0.508, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.802, 10.174], loss: 0.001549, mae: 0.042416, mean_q: 1.173722
 854166/1000000: episode: 8542, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 62.699, mean reward: 0.627 [0.502, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.175, 10.098], loss: 0.001469, mae: 0.042212, mean_q: 1.172941
 854266/1000000: episode: 8543, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 60.324, mean reward: 0.603 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.787, 10.226], loss: 0.001500, mae: 0.042255, mean_q: 1.174623
 854366/1000000: episode: 8544, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 60.296, mean reward: 0.603 [0.506, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.320, 10.098], loss: 0.001530, mae: 0.042295, mean_q: 1.175706
 854466/1000000: episode: 8545, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.139, mean reward: 0.601 [0.498, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.976, 10.098], loss: 0.001587, mae: 0.043596, mean_q: 1.174238
 854566/1000000: episode: 8546, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.493, mean reward: 0.595 [0.505, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.105, 10.379], loss: 0.001719, mae: 0.045403, mean_q: 1.176638
 854666/1000000: episode: 8547, duration: 0.623s, episode steps: 100, steps per second: 161, episode reward: 58.189, mean reward: 0.582 [0.502, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.505, 10.161], loss: 0.001695, mae: 0.044924, mean_q: 1.179074
 854766/1000000: episode: 8548, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 57.078, mean reward: 0.571 [0.517, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.899, 10.109], loss: 0.001648, mae: 0.044402, mean_q: 1.178403
 854866/1000000: episode: 8549, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.521, mean reward: 0.585 [0.499, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.230, 10.098], loss: 0.001619, mae: 0.043343, mean_q: 1.175061
 854966/1000000: episode: 8550, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.385, mean reward: 0.594 [0.503, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.930, 10.098], loss: 0.001643, mae: 0.044151, mean_q: 1.171227
 855066/1000000: episode: 8551, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.695, mean reward: 0.607 [0.521, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.122, 10.220], loss: 0.001530, mae: 0.042300, mean_q: 1.176741
 855166/1000000: episode: 8552, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 56.730, mean reward: 0.567 [0.507, 0.665], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.017, 10.230], loss: 0.001640, mae: 0.043664, mean_q: 1.175759
 855266/1000000: episode: 8553, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 61.032, mean reward: 0.610 [0.516, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.326, 10.151], loss: 0.001558, mae: 0.042875, mean_q: 1.167821
 855366/1000000: episode: 8554, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.538, mean reward: 0.585 [0.499, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.677, 10.201], loss: 0.001544, mae: 0.042826, mean_q: 1.175238
 855466/1000000: episode: 8555, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.360, mean reward: 0.604 [0.512, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.817, 10.374], loss: 0.001462, mae: 0.041617, mean_q: 1.170481
 855566/1000000: episode: 8556, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.079, mean reward: 0.571 [0.504, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.354, 10.139], loss: 0.001565, mae: 0.043125, mean_q: 1.172206
 855666/1000000: episode: 8557, duration: 0.614s, episode steps: 100, steps per second: 163, episode reward: 58.562, mean reward: 0.586 [0.501, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-1.114, 10.276], loss: 0.001546, mae: 0.042478, mean_q: 1.172226
 855766/1000000: episode: 8558, duration: 0.640s, episode steps: 100, steps per second: 156, episode reward: 59.575, mean reward: 0.596 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.162, 10.098], loss: 0.001497, mae: 0.042362, mean_q: 1.172792
 855866/1000000: episode: 8559, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.150, mean reward: 0.572 [0.502, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.229, 10.098], loss: 0.001540, mae: 0.042656, mean_q: 1.172501
 855966/1000000: episode: 8560, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.739, mean reward: 0.577 [0.502, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.975, 10.098], loss: 0.001546, mae: 0.042806, mean_q: 1.173674
 856066/1000000: episode: 8561, duration: 0.620s, episode steps: 100, steps per second: 161, episode reward: 57.446, mean reward: 0.574 [0.511, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.220, 10.271], loss: 0.001542, mae: 0.042676, mean_q: 1.170392
 856166/1000000: episode: 8562, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.520, mean reward: 0.605 [0.512, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.621, 10.311], loss: 0.001565, mae: 0.042818, mean_q: 1.171275
 856266/1000000: episode: 8563, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.334, mean reward: 0.593 [0.499, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.822, 10.098], loss: 0.001594, mae: 0.042806, mean_q: 1.170872
 856366/1000000: episode: 8564, duration: 0.736s, episode steps: 100, steps per second: 136, episode reward: 57.464, mean reward: 0.575 [0.505, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.227, 10.153], loss: 0.001495, mae: 0.042145, mean_q: 1.168111
 856466/1000000: episode: 8565, duration: 0.669s, episode steps: 100, steps per second: 149, episode reward: 59.060, mean reward: 0.591 [0.511, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-1.260, 10.098], loss: 0.001717, mae: 0.044026, mean_q: 1.172282
 856566/1000000: episode: 8566, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.040, mean reward: 0.580 [0.508, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.931, 10.098], loss: 0.001573, mae: 0.042535, mean_q: 1.167527
 856666/1000000: episode: 8567, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.135, mean reward: 0.581 [0.500, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.544, 10.233], loss: 0.001554, mae: 0.042105, mean_q: 1.172110
 856766/1000000: episode: 8568, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 56.968, mean reward: 0.570 [0.497, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.577, 10.098], loss: 0.001647, mae: 0.043668, mean_q: 1.171018
 856866/1000000: episode: 8569, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.182, mean reward: 0.572 [0.501, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.380, 10.312], loss: 0.001551, mae: 0.042429, mean_q: 1.166048
 856966/1000000: episode: 8570, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.487, mean reward: 0.585 [0.507, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.968, 10.363], loss: 0.001531, mae: 0.042024, mean_q: 1.167563
 857066/1000000: episode: 8571, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.640, mean reward: 0.596 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.559, 10.098], loss: 0.001556, mae: 0.042178, mean_q: 1.168389
 857166/1000000: episode: 8572, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.452, mean reward: 0.575 [0.501, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.905, 10.126], loss: 0.001566, mae: 0.042455, mean_q: 1.169538
 857266/1000000: episode: 8573, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.385, mean reward: 0.584 [0.500, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.028, 10.200], loss: 0.001462, mae: 0.040997, mean_q: 1.167284
 857366/1000000: episode: 8574, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.113, mean reward: 0.571 [0.504, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.461, 10.256], loss: 0.001582, mae: 0.042747, mean_q: 1.168827
 857466/1000000: episode: 8575, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 62.481, mean reward: 0.625 [0.498, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.895, 10.313], loss: 0.001656, mae: 0.043990, mean_q: 1.168455
 857566/1000000: episode: 8576, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 57.348, mean reward: 0.573 [0.506, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.828, 10.098], loss: 0.001532, mae: 0.042164, mean_q: 1.163580
 857666/1000000: episode: 8577, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.615, mean reward: 0.576 [0.499, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.705, 10.249], loss: 0.001579, mae: 0.042517, mean_q: 1.168605
 857766/1000000: episode: 8578, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.587, mean reward: 0.566 [0.503, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.587, 10.217], loss: 0.001497, mae: 0.041760, mean_q: 1.166609
 857866/1000000: episode: 8579, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 61.644, mean reward: 0.616 [0.513, 0.908], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.830, 10.098], loss: 0.001541, mae: 0.042482, mean_q: 1.161770
 857966/1000000: episode: 8580, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.276, mean reward: 0.593 [0.506, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.416, 10.098], loss: 0.001534, mae: 0.042322, mean_q: 1.162618
 858066/1000000: episode: 8581, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.905, mean reward: 0.579 [0.506, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.938, 10.153], loss: 0.001540, mae: 0.041915, mean_q: 1.162681
 858166/1000000: episode: 8582, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.938, mean reward: 0.579 [0.509, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.434, 10.098], loss: 0.001503, mae: 0.042404, mean_q: 1.161567
 858266/1000000: episode: 8583, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 59.427, mean reward: 0.594 [0.504, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.045, 10.098], loss: 0.001508, mae: 0.042231, mean_q: 1.161441
 858366/1000000: episode: 8584, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.750, mean reward: 0.597 [0.517, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.062, 10.204], loss: 0.001595, mae: 0.043010, mean_q: 1.164104
 858466/1000000: episode: 8585, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.567, mean reward: 0.596 [0.504, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.890, 10.484], loss: 0.001467, mae: 0.040902, mean_q: 1.162187
 858566/1000000: episode: 8586, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.393, mean reward: 0.604 [0.502, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.603, 10.153], loss: 0.001453, mae: 0.041387, mean_q: 1.162669
 858666/1000000: episode: 8587, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.209, mean reward: 0.572 [0.503, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.227, 10.098], loss: 0.001558, mae: 0.043018, mean_q: 1.167475
 858766/1000000: episode: 8588, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.196, mean reward: 0.602 [0.504, 0.898], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.531, 10.098], loss: 0.001424, mae: 0.040821, mean_q: 1.162949
 858866/1000000: episode: 8589, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.286, mean reward: 0.573 [0.502, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.493, 10.213], loss: 0.001525, mae: 0.041724, mean_q: 1.162167
 858966/1000000: episode: 8590, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.460, mean reward: 0.595 [0.500, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.189, 10.098], loss: 0.001470, mae: 0.041536, mean_q: 1.162302
 859066/1000000: episode: 8591, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 63.324, mean reward: 0.633 [0.507, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.658, 10.264], loss: 0.001487, mae: 0.041202, mean_q: 1.162269
 859166/1000000: episode: 8592, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 62.966, mean reward: 0.630 [0.514, 0.879], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.796, 10.401], loss: 0.001470, mae: 0.041646, mean_q: 1.161615
 859266/1000000: episode: 8593, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.902, mean reward: 0.599 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.682, 10.098], loss: 0.001364, mae: 0.040109, mean_q: 1.168641
 859366/1000000: episode: 8594, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.901, mean reward: 0.579 [0.505, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.393, 10.098], loss: 0.001446, mae: 0.040749, mean_q: 1.162698
 859466/1000000: episode: 8595, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.395, mean reward: 0.594 [0.511, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.885, 10.251], loss: 0.001430, mae: 0.040645, mean_q: 1.163289
 859566/1000000: episode: 8596, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 61.381, mean reward: 0.614 [0.512, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.869, 10.098], loss: 0.001448, mae: 0.041214, mean_q: 1.163983
 859666/1000000: episode: 8597, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.995, mean reward: 0.600 [0.517, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.485, 10.250], loss: 0.001395, mae: 0.040307, mean_q: 1.164113
 859766/1000000: episode: 8598, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.483, mean reward: 0.575 [0.504, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.797, 10.098], loss: 0.001381, mae: 0.040277, mean_q: 1.165651
 859866/1000000: episode: 8599, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.742, mean reward: 0.587 [0.503, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.107, 10.189], loss: 0.001434, mae: 0.040930, mean_q: 1.164101
 859966/1000000: episode: 8600, duration: 0.628s, episode steps: 100, steps per second: 159, episode reward: 56.246, mean reward: 0.562 [0.505, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.989, 10.166], loss: 0.001377, mae: 0.040090, mean_q: 1.165154
 860066/1000000: episode: 8601, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.172, mean reward: 0.592 [0.511, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.888, 10.098], loss: 0.001467, mae: 0.041508, mean_q: 1.163743
 860166/1000000: episode: 8602, duration: 0.623s, episode steps: 100, steps per second: 161, episode reward: 62.070, mean reward: 0.621 [0.503, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.700, 10.269], loss: 0.001520, mae: 0.041472, mean_q: 1.165841
 860266/1000000: episode: 8603, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.594, mean reward: 0.576 [0.504, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.611, 10.342], loss: 0.001511, mae: 0.041715, mean_q: 1.166862
 860366/1000000: episode: 8604, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.634, mean reward: 0.586 [0.511, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.132, 10.098], loss: 0.001413, mae: 0.040423, mean_q: 1.165597
 860466/1000000: episode: 8605, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.152, mean reward: 0.592 [0.506, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.921, 10.222], loss: 0.001492, mae: 0.041378, mean_q: 1.165379
 860566/1000000: episode: 8606, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.339, mean reward: 0.593 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.741, 10.098], loss: 0.001468, mae: 0.041638, mean_q: 1.167901
 860666/1000000: episode: 8607, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 58.522, mean reward: 0.585 [0.510, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.094, 10.098], loss: 0.001502, mae: 0.041784, mean_q: 1.167526
 860766/1000000: episode: 8608, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.699, mean reward: 0.567 [0.504, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.797, 10.159], loss: 0.001419, mae: 0.040412, mean_q: 1.167393
 860866/1000000: episode: 8609, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 59.661, mean reward: 0.597 [0.512, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.878, 10.098], loss: 0.001445, mae: 0.041320, mean_q: 1.166677
 860966/1000000: episode: 8610, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.868, mean reward: 0.589 [0.509, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.084, 10.213], loss: 0.001423, mae: 0.041177, mean_q: 1.169472
 861066/1000000: episode: 8611, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.837, mean reward: 0.588 [0.503, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.737, 10.098], loss: 0.001377, mae: 0.040469, mean_q: 1.166498
 861166/1000000: episode: 8612, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.503, mean reward: 0.585 [0.516, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.463, 10.249], loss: 0.001463, mae: 0.041552, mean_q: 1.170848
 861266/1000000: episode: 8613, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 60.023, mean reward: 0.600 [0.512, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.844, 10.098], loss: 0.001522, mae: 0.042294, mean_q: 1.166813
 861366/1000000: episode: 8614, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.147, mean reward: 0.591 [0.508, 0.874], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.577, 10.098], loss: 0.001369, mae: 0.040206, mean_q: 1.163832
 861466/1000000: episode: 8615, duration: 0.534s, episode steps: 100, steps per second: 187, episode reward: 59.289, mean reward: 0.593 [0.504, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.525, 10.232], loss: 0.001415, mae: 0.041299, mean_q: 1.169535
 861566/1000000: episode: 8616, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.849, mean reward: 0.588 [0.511, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.389, 10.204], loss: 0.001377, mae: 0.040957, mean_q: 1.163854
 861666/1000000: episode: 8617, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.205, mean reward: 0.582 [0.508, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.545, 10.219], loss: 0.001330, mae: 0.040036, mean_q: 1.168034
 861766/1000000: episode: 8618, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 62.122, mean reward: 0.621 [0.513, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.871, 10.098], loss: 0.001327, mae: 0.039444, mean_q: 1.167408
 861866/1000000: episode: 8619, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 59.983, mean reward: 0.600 [0.513, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.092, 10.299], loss: 0.001465, mae: 0.041440, mean_q: 1.169993
 861966/1000000: episode: 8620, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.243, mean reward: 0.582 [0.508, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.235, 10.098], loss: 0.001390, mae: 0.040946, mean_q: 1.166454
 862066/1000000: episode: 8621, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 59.343, mean reward: 0.593 [0.505, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.192, 10.098], loss: 0.001487, mae: 0.042158, mean_q: 1.168786
 862166/1000000: episode: 8622, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.552, mean reward: 0.586 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.127, 10.151], loss: 0.001423, mae: 0.040919, mean_q: 1.169905
 862266/1000000: episode: 8623, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.909, mean reward: 0.579 [0.501, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.426, 10.263], loss: 0.001411, mae: 0.040694, mean_q: 1.165551
 862366/1000000: episode: 8624, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.792, mean reward: 0.578 [0.498, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.390, 10.207], loss: 0.001435, mae: 0.040793, mean_q: 1.170619
 862466/1000000: episode: 8625, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.109, mean reward: 0.581 [0.498, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.253, 10.218], loss: 0.001434, mae: 0.040922, mean_q: 1.169994
 862566/1000000: episode: 8626, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.678, mean reward: 0.597 [0.500, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.571, 10.098], loss: 0.001373, mae: 0.040333, mean_q: 1.169564
 862666/1000000: episode: 8627, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.679, mean reward: 0.577 [0.503, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.924, 10.098], loss: 0.001456, mae: 0.041905, mean_q: 1.171514
 862766/1000000: episode: 8628, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.720, mean reward: 0.587 [0.503, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.471, 10.098], loss: 0.001417, mae: 0.040678, mean_q: 1.170594
 862866/1000000: episode: 8629, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.412, mean reward: 0.574 [0.504, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.463, 10.129], loss: 0.001528, mae: 0.042791, mean_q: 1.168247
 862966/1000000: episode: 8630, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.494, mean reward: 0.585 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.778, 10.098], loss: 0.001360, mae: 0.040314, mean_q: 1.168660
 863066/1000000: episode: 8631, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.042, mean reward: 0.600 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.051, 10.204], loss: 0.001416, mae: 0.040792, mean_q: 1.168220
 863166/1000000: episode: 8632, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 59.581, mean reward: 0.596 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.103, 10.186], loss: 0.001287, mae: 0.039435, mean_q: 1.169206
 863266/1000000: episode: 8633, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.621, mean reward: 0.576 [0.503, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.183, 10.098], loss: 0.001350, mae: 0.040307, mean_q: 1.169860
 863366/1000000: episode: 8634, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.142, mean reward: 0.591 [0.501, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.466, 10.098], loss: 0.001407, mae: 0.040577, mean_q: 1.167061
 863466/1000000: episode: 8635, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.556, mean reward: 0.616 [0.509, 0.895], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.966, 10.445], loss: 0.001422, mae: 0.040486, mean_q: 1.167374
 863566/1000000: episode: 8636, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 57.361, mean reward: 0.574 [0.504, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.657, 10.098], loss: 0.001286, mae: 0.039764, mean_q: 1.167314
 863666/1000000: episode: 8637, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.984, mean reward: 0.580 [0.499, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.195, 10.208], loss: 0.001396, mae: 0.039966, mean_q: 1.168072
 863766/1000000: episode: 8638, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.056, mean reward: 0.591 [0.502, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.688, 10.168], loss: 0.001429, mae: 0.041234, mean_q: 1.168998
 863866/1000000: episode: 8639, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.273, mean reward: 0.583 [0.506, 0.874], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.990, 10.098], loss: 0.001453, mae: 0.041567, mean_q: 1.165420
 863966/1000000: episode: 8640, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.956, mean reward: 0.600 [0.510, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.401, 10.237], loss: 0.001377, mae: 0.040365, mean_q: 1.168596
 864066/1000000: episode: 8641, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.595, mean reward: 0.606 [0.498, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.243, 10.098], loss: 0.001444, mae: 0.040953, mean_q: 1.165466
 864166/1000000: episode: 8642, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.402, mean reward: 0.584 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.278, 10.137], loss: 0.001368, mae: 0.040372, mean_q: 1.165892
 864266/1000000: episode: 8643, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.504, mean reward: 0.575 [0.500, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.940, 10.289], loss: 0.001472, mae: 0.041865, mean_q: 1.168545
 864366/1000000: episode: 8644, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.858, mean reward: 0.589 [0.508, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.099, 10.273], loss: 0.001510, mae: 0.042405, mean_q: 1.170223
 864466/1000000: episode: 8645, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.936, mean reward: 0.589 [0.513, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.367, 10.098], loss: 0.001517, mae: 0.042689, mean_q: 1.167392
 864566/1000000: episode: 8646, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.972, mean reward: 0.580 [0.508, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.256, 10.098], loss: 0.001403, mae: 0.040375, mean_q: 1.164973
 864666/1000000: episode: 8647, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.071, mean reward: 0.571 [0.502, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.088, 10.098], loss: 0.001412, mae: 0.041155, mean_q: 1.161288
 864766/1000000: episode: 8648, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.500, mean reward: 0.595 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.087, 10.098], loss: 0.001450, mae: 0.040890, mean_q: 1.163154
 864866/1000000: episode: 8649, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.839, mean reward: 0.578 [0.504, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.810, 10.148], loss: 0.001382, mae: 0.040322, mean_q: 1.166060
 864966/1000000: episode: 8650, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.633, mean reward: 0.586 [0.499, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.101, 10.244], loss: 0.001525, mae: 0.042218, mean_q: 1.164857
 865066/1000000: episode: 8651, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.442, mean reward: 0.574 [0.506, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.366, 10.258], loss: 0.001451, mae: 0.041527, mean_q: 1.164112
 865166/1000000: episode: 8652, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.103, mean reward: 0.581 [0.503, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.322, 10.098], loss: 0.001562, mae: 0.043098, mean_q: 1.164674
 865266/1000000: episode: 8653, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 58.328, mean reward: 0.583 [0.505, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.606, 10.098], loss: 0.001435, mae: 0.041077, mean_q: 1.163722
 865366/1000000: episode: 8654, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.141, mean reward: 0.591 [0.506, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.974, 10.286], loss: 0.001537, mae: 0.042925, mean_q: 1.165930
 865466/1000000: episode: 8655, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.902, mean reward: 0.569 [0.507, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.721, 10.190], loss: 0.001451, mae: 0.041606, mean_q: 1.163818
 865566/1000000: episode: 8656, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 60.014, mean reward: 0.600 [0.512, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.677, 10.098], loss: 0.001397, mae: 0.040763, mean_q: 1.162599
 865666/1000000: episode: 8657, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.494, mean reward: 0.595 [0.511, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.681, 10.098], loss: 0.001448, mae: 0.041355, mean_q: 1.161559
 865766/1000000: episode: 8658, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.037, mean reward: 0.590 [0.503, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.563, 10.098], loss: 0.001467, mae: 0.041634, mean_q: 1.160517
 865866/1000000: episode: 8659, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.631, mean reward: 0.576 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.879, 10.200], loss: 0.001506, mae: 0.042271, mean_q: 1.162861
 865966/1000000: episode: 8660, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.399, mean reward: 0.574 [0.506, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.863, 10.098], loss: 0.001437, mae: 0.040960, mean_q: 1.159755
 866066/1000000: episode: 8661, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.688, mean reward: 0.587 [0.518, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.596, 10.316], loss: 0.001531, mae: 0.042253, mean_q: 1.162194
 866166/1000000: episode: 8662, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 63.158, mean reward: 0.632 [0.514, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.357, 10.098], loss: 0.001408, mae: 0.041065, mean_q: 1.163726
 866266/1000000: episode: 8663, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 62.013, mean reward: 0.620 [0.509, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.732, 10.318], loss: 0.001399, mae: 0.041024, mean_q: 1.166155
 866366/1000000: episode: 8664, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 58.718, mean reward: 0.587 [0.505, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.778, 10.098], loss: 0.001489, mae: 0.041615, mean_q: 1.166350
 866466/1000000: episode: 8665, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 60.340, mean reward: 0.603 [0.509, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.788, 10.190], loss: 0.001470, mae: 0.041774, mean_q: 1.163388
 866566/1000000: episode: 8666, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.932, mean reward: 0.579 [0.505, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.439, 10.127], loss: 0.001482, mae: 0.042027, mean_q: 1.166156
 866666/1000000: episode: 8667, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.271, mean reward: 0.593 [0.512, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.290, 10.211], loss: 0.001512, mae: 0.042357, mean_q: 1.166466
 866766/1000000: episode: 8668, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.792, mean reward: 0.598 [0.515, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.457, 10.205], loss: 0.001526, mae: 0.042644, mean_q: 1.164698
 866866/1000000: episode: 8669, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.557, mean reward: 0.586 [0.503, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.383, 10.125], loss: 0.001444, mae: 0.041156, mean_q: 1.162607
 866966/1000000: episode: 8670, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 62.986, mean reward: 0.630 [0.508, 0.872], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.903, 10.281], loss: 0.001449, mae: 0.041315, mean_q: 1.164330
 867066/1000000: episode: 8671, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.665, mean reward: 0.587 [0.511, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.459, 10.477], loss: 0.001391, mae: 0.040562, mean_q: 1.164251
 867166/1000000: episode: 8672, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.513, mean reward: 0.575 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.011, 10.256], loss: 0.001426, mae: 0.040938, mean_q: 1.167417
 867266/1000000: episode: 8673, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.868, mean reward: 0.609 [0.516, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.639, 10.285], loss: 0.001427, mae: 0.041032, mean_q: 1.166924
 867366/1000000: episode: 8674, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.102, mean reward: 0.571 [0.505, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.412, 10.098], loss: 0.001337, mae: 0.039795, mean_q: 1.164860
 867466/1000000: episode: 8675, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 58.100, mean reward: 0.581 [0.498, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.313, 10.108], loss: 0.001458, mae: 0.041044, mean_q: 1.166067
 867566/1000000: episode: 8676, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.612, mean reward: 0.596 [0.514, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.690, 10.298], loss: 0.001494, mae: 0.041515, mean_q: 1.167220
 867666/1000000: episode: 8677, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.186, mean reward: 0.582 [0.510, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.615, 10.098], loss: 0.001397, mae: 0.040635, mean_q: 1.166654
 867766/1000000: episode: 8678, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.449, mean reward: 0.574 [0.505, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.328, 10.098], loss: 0.001472, mae: 0.041239, mean_q: 1.166891
 867866/1000000: episode: 8679, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.662, mean reward: 0.577 [0.512, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.430, 10.098], loss: 0.001442, mae: 0.041262, mean_q: 1.167964
 867966/1000000: episode: 8680, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 59.358, mean reward: 0.594 [0.506, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.168, 10.170], loss: 0.001460, mae: 0.041288, mean_q: 1.164334
 868066/1000000: episode: 8681, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.480, mean reward: 0.585 [0.503, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.977, 10.123], loss: 0.001463, mae: 0.041427, mean_q: 1.166882
 868166/1000000: episode: 8682, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.541, mean reward: 0.595 [0.507, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.869, 10.390], loss: 0.001347, mae: 0.039470, mean_q: 1.163103
 868266/1000000: episode: 8683, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.015, mean reward: 0.570 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.759, 10.103], loss: 0.001491, mae: 0.041289, mean_q: 1.165428
 868366/1000000: episode: 8684, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 60.747, mean reward: 0.607 [0.532, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.802, 10.285], loss: 0.001415, mae: 0.040867, mean_q: 1.166664
 868466/1000000: episode: 8685, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.237, mean reward: 0.602 [0.504, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.608, 10.098], loss: 0.001447, mae: 0.041333, mean_q: 1.162486
 868566/1000000: episode: 8686, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.442, mean reward: 0.604 [0.499, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.922, 10.098], loss: 0.001493, mae: 0.042232, mean_q: 1.166102
 868666/1000000: episode: 8687, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 61.222, mean reward: 0.612 [0.516, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.853, 10.098], loss: 0.001497, mae: 0.042024, mean_q: 1.164902
 868766/1000000: episode: 8688, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 57.605, mean reward: 0.576 [0.504, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.025, 10.098], loss: 0.001433, mae: 0.040910, mean_q: 1.165050
 868866/1000000: episode: 8689, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.322, mean reward: 0.603 [0.503, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.363, 10.098], loss: 0.001467, mae: 0.042017, mean_q: 1.166650
 868966/1000000: episode: 8690, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.942, mean reward: 0.579 [0.501, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.964, 10.098], loss: 0.001505, mae: 0.042349, mean_q: 1.167889
 869066/1000000: episode: 8691, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 57.610, mean reward: 0.576 [0.499, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.843, 10.321], loss: 0.001538, mae: 0.042981, mean_q: 1.168249
 869166/1000000: episode: 8692, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.872, mean reward: 0.579 [0.499, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.989, 10.098], loss: 0.001456, mae: 0.041726, mean_q: 1.166199
 869266/1000000: episode: 8693, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.745, mean reward: 0.587 [0.500, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.630, 10.203], loss: 0.001499, mae: 0.041988, mean_q: 1.166090
 869366/1000000: episode: 8694, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.402, mean reward: 0.594 [0.497, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.025, 10.180], loss: 0.001480, mae: 0.042022, mean_q: 1.166311
 869466/1000000: episode: 8695, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.668, mean reward: 0.587 [0.504, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.689, 10.147], loss: 0.001436, mae: 0.041401, mean_q: 1.165701
 869566/1000000: episode: 8696, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.864, mean reward: 0.579 [0.505, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.441, 10.269], loss: 0.001420, mae: 0.040990, mean_q: 1.162635
 869666/1000000: episode: 8697, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.681, mean reward: 0.597 [0.505, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.324, 10.213], loss: 0.001396, mae: 0.040597, mean_q: 1.166537
 869766/1000000: episode: 8698, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 64.099, mean reward: 0.641 [0.505, 0.986], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.740, 10.676], loss: 0.001490, mae: 0.041964, mean_q: 1.164003
 869866/1000000: episode: 8699, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.208, mean reward: 0.582 [0.500, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.679, 10.099], loss: 0.001497, mae: 0.042061, mean_q: 1.167221
 869966/1000000: episode: 8700, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.146, mean reward: 0.571 [0.502, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.933, 10.098], loss: 0.001529, mae: 0.042631, mean_q: 1.168953
 870066/1000000: episode: 8701, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.933, mean reward: 0.599 [0.505, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.368, 10.331], loss: 0.001528, mae: 0.043178, mean_q: 1.170953
 870166/1000000: episode: 8702, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 58.871, mean reward: 0.589 [0.513, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.319, 10.122], loss: 0.001504, mae: 0.042634, mean_q: 1.168805
 870266/1000000: episode: 8703, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.682, mean reward: 0.587 [0.505, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.524, 10.129], loss: 0.001520, mae: 0.042353, mean_q: 1.169269
 870366/1000000: episode: 8704, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.682, mean reward: 0.577 [0.505, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.818, 10.098], loss: 0.001575, mae: 0.042600, mean_q: 1.172265
 870466/1000000: episode: 8705, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.644, mean reward: 0.576 [0.506, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.118, 10.100], loss: 0.001494, mae: 0.042251, mean_q: 1.168903
 870566/1000000: episode: 8706, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 56.877, mean reward: 0.569 [0.502, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.486, 10.098], loss: 0.001564, mae: 0.042954, mean_q: 1.164749
 870666/1000000: episode: 8707, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.976, mean reward: 0.590 [0.506, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.337, 10.098], loss: 0.001507, mae: 0.042225, mean_q: 1.167414
 870766/1000000: episode: 8708, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 62.170, mean reward: 0.622 [0.541, 0.883], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.181, 10.098], loss: 0.001424, mae: 0.041280, mean_q: 1.166318
 870866/1000000: episode: 8709, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.065, mean reward: 0.591 [0.509, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.061, 10.098], loss: 0.001525, mae: 0.042414, mean_q: 1.170143
 870966/1000000: episode: 8710, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.756, mean reward: 0.588 [0.502, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.868, 10.098], loss: 0.001461, mae: 0.041531, mean_q: 1.169252
 871066/1000000: episode: 8711, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.815, mean reward: 0.598 [0.499, 0.882], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.511, 10.186], loss: 0.001455, mae: 0.041129, mean_q: 1.169300
 871166/1000000: episode: 8712, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.308, mean reward: 0.573 [0.506, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.645, 10.098], loss: 0.001540, mae: 0.042296, mean_q: 1.167954
 871266/1000000: episode: 8713, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 61.545, mean reward: 0.615 [0.514, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.178, 10.178], loss: 0.001554, mae: 0.042773, mean_q: 1.167508
 871366/1000000: episode: 8714, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.292, mean reward: 0.583 [0.507, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.785, 10.218], loss: 0.001450, mae: 0.041643, mean_q: 1.168675
 871466/1000000: episode: 8715, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.977, mean reward: 0.620 [0.517, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.939, 10.098], loss: 0.001520, mae: 0.042452, mean_q: 1.169079
 871566/1000000: episode: 8716, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.663, mean reward: 0.577 [0.498, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.534, 10.157], loss: 0.001564, mae: 0.043216, mean_q: 1.172971
 871666/1000000: episode: 8717, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 56.687, mean reward: 0.567 [0.503, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.853, 10.137], loss: 0.001556, mae: 0.042736, mean_q: 1.169595
 871766/1000000: episode: 8718, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.728, mean reward: 0.577 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.426, 10.142], loss: 0.001479, mae: 0.041330, mean_q: 1.167245
 871866/1000000: episode: 8719, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 56.461, mean reward: 0.565 [0.509, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.687, 10.098], loss: 0.001629, mae: 0.043740, mean_q: 1.168169
 871966/1000000: episode: 8720, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.011, mean reward: 0.590 [0.520, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.912, 10.098], loss: 0.001497, mae: 0.042174, mean_q: 1.162578
 872066/1000000: episode: 8721, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.879, mean reward: 0.579 [0.499, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.488, 10.098], loss: 0.001596, mae: 0.043380, mean_q: 1.165368
 872166/1000000: episode: 8722, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.603, mean reward: 0.586 [0.504, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.511, 10.098], loss: 0.001655, mae: 0.044002, mean_q: 1.164753
 872266/1000000: episode: 8723, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.612, mean reward: 0.576 [0.509, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.536, 10.098], loss: 0.001624, mae: 0.043520, mean_q: 1.163291
 872366/1000000: episode: 8724, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.450, mean reward: 0.585 [0.499, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.103, 10.098], loss: 0.001550, mae: 0.042582, mean_q: 1.163370
 872466/1000000: episode: 8725, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.445, mean reward: 0.574 [0.510, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.639, 10.098], loss: 0.001565, mae: 0.043361, mean_q: 1.163404
 872566/1000000: episode: 8726, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.472, mean reward: 0.595 [0.506, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.983, 10.098], loss: 0.001489, mae: 0.042189, mean_q: 1.164069
 872666/1000000: episode: 8727, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 60.977, mean reward: 0.610 [0.519, 0.875], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.394, 10.243], loss: 0.001544, mae: 0.042729, mean_q: 1.163619
 872766/1000000: episode: 8728, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.604, mean reward: 0.596 [0.508, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.512, 10.098], loss: 0.001528, mae: 0.042405, mean_q: 1.165601
 872866/1000000: episode: 8729, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.002, mean reward: 0.590 [0.500, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.301, 10.319], loss: 0.001569, mae: 0.042648, mean_q: 1.166037
 872966/1000000: episode: 8730, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.715, mean reward: 0.617 [0.501, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.163, 10.098], loss: 0.001619, mae: 0.043660, mean_q: 1.168825
 873066/1000000: episode: 8731, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.775, mean reward: 0.588 [0.506, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.530, 10.231], loss: 0.001553, mae: 0.042755, mean_q: 1.167522
 873166/1000000: episode: 8732, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.609, mean reward: 0.586 [0.508, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.656, 10.199], loss: 0.001592, mae: 0.043306, mean_q: 1.166892
 873266/1000000: episode: 8733, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.002, mean reward: 0.580 [0.505, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.393, 10.114], loss: 0.001647, mae: 0.044649, mean_q: 1.168294
 873366/1000000: episode: 8734, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.763, mean reward: 0.578 [0.503, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.266, 10.244], loss: 0.001607, mae: 0.043189, mean_q: 1.166436
 873466/1000000: episode: 8735, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.089, mean reward: 0.581 [0.507, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.578, 10.123], loss: 0.001636, mae: 0.043402, mean_q: 1.166351
 873566/1000000: episode: 8736, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.593, mean reward: 0.586 [0.501, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.519, 10.098], loss: 0.001575, mae: 0.043004, mean_q: 1.166492
 873666/1000000: episode: 8737, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.541, mean reward: 0.585 [0.511, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.184, 10.247], loss: 0.001574, mae: 0.043561, mean_q: 1.166487
 873766/1000000: episode: 8738, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 62.265, mean reward: 0.623 [0.501, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.312, 10.460], loss: 0.001603, mae: 0.043510, mean_q: 1.167999
 873866/1000000: episode: 8739, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 57.798, mean reward: 0.578 [0.501, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.778, 10.217], loss: 0.001638, mae: 0.044193, mean_q: 1.166932
 873966/1000000: episode: 8740, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.259, mean reward: 0.603 [0.507, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.859, 10.098], loss: 0.001603, mae: 0.043760, mean_q: 1.165385
 874066/1000000: episode: 8741, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.492, mean reward: 0.575 [0.501, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.333, 10.123], loss: 0.001512, mae: 0.042554, mean_q: 1.164581
 874166/1000000: episode: 8742, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.377, mean reward: 0.574 [0.503, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.837, 10.098], loss: 0.001513, mae: 0.042504, mean_q: 1.167777
 874266/1000000: episode: 8743, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.309, mean reward: 0.593 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.549, 10.118], loss: 0.001523, mae: 0.042202, mean_q: 1.166072
 874366/1000000: episode: 8744, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.133, mean reward: 0.581 [0.506, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.883, 10.098], loss: 0.001636, mae: 0.043514, mean_q: 1.167685
 874466/1000000: episode: 8745, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.953, mean reward: 0.580 [0.506, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.680, 10.131], loss: 0.001498, mae: 0.042197, mean_q: 1.169795
 874566/1000000: episode: 8746, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 61.054, mean reward: 0.611 [0.503, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.773, 10.248], loss: 0.001540, mae: 0.042039, mean_q: 1.164858
 874666/1000000: episode: 8747, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.500, mean reward: 0.595 [0.505, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.831, 10.098], loss: 0.001528, mae: 0.042700, mean_q: 1.164673
 874766/1000000: episode: 8748, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.286, mean reward: 0.583 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.603, 10.110], loss: 0.001517, mae: 0.042217, mean_q: 1.165399
 874866/1000000: episode: 8749, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 58.975, mean reward: 0.590 [0.499, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.841, 10.098], loss: 0.001481, mae: 0.041976, mean_q: 1.166054
 874966/1000000: episode: 8750, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.528, mean reward: 0.585 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.644, 10.098], loss: 0.001514, mae: 0.041643, mean_q: 1.162033
 875066/1000000: episode: 8751, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.320, mean reward: 0.603 [0.501, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.295, 10.292], loss: 0.001468, mae: 0.041565, mean_q: 1.167441
 875166/1000000: episode: 8752, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.825, mean reward: 0.588 [0.506, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.445 [-0.733, 10.098], loss: 0.001472, mae: 0.041571, mean_q: 1.165875
 875266/1000000: episode: 8753, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.293, mean reward: 0.583 [0.508, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.019, 10.206], loss: 0.001464, mae: 0.041246, mean_q: 1.165226
 875366/1000000: episode: 8754, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.890, mean reward: 0.599 [0.505, 0.855], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.008, 10.098], loss: 0.001556, mae: 0.042593, mean_q: 1.162829
 875466/1000000: episode: 8755, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.260, mean reward: 0.573 [0.507, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.152, 10.098], loss: 0.001634, mae: 0.042955, mean_q: 1.164146
 875566/1000000: episode: 8756, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 62.168, mean reward: 0.622 [0.502, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.144, 10.098], loss: 0.001642, mae: 0.043320, mean_q: 1.168432
 875666/1000000: episode: 8757, duration: 0.642s, episode steps: 100, steps per second: 156, episode reward: 59.717, mean reward: 0.597 [0.508, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.938, 10.098], loss: 0.001574, mae: 0.043188, mean_q: 1.166576
 875766/1000000: episode: 8758, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.814, mean reward: 0.588 [0.519, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.463, 10.289], loss: 0.001580, mae: 0.043337, mean_q: 1.165579
 875866/1000000: episode: 8759, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 61.475, mean reward: 0.615 [0.513, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.925, 10.377], loss: 0.001514, mae: 0.042188, mean_q: 1.168516
 875966/1000000: episode: 8760, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.454, mean reward: 0.585 [0.500, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.182, 10.177], loss: 0.001521, mae: 0.042512, mean_q: 1.169054
 876066/1000000: episode: 8761, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.866, mean reward: 0.609 [0.507, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.039, 10.098], loss: 0.001568, mae: 0.042532, mean_q: 1.164575
 876166/1000000: episode: 8762, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.729, mean reward: 0.587 [0.504, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.823, 10.098], loss: 0.001662, mae: 0.044455, mean_q: 1.168063
 876266/1000000: episode: 8763, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 62.133, mean reward: 0.621 [0.513, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.713, 10.098], loss: 0.001561, mae: 0.042584, mean_q: 1.167512
 876366/1000000: episode: 8764, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.274, mean reward: 0.573 [0.509, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.474, 10.388], loss: 0.001488, mae: 0.042255, mean_q: 1.170592
 876466/1000000: episode: 8765, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.734, mean reward: 0.587 [0.503, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.140, 10.098], loss: 0.001537, mae: 0.042920, mean_q: 1.167534
 876566/1000000: episode: 8766, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 58.602, mean reward: 0.586 [0.502, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.993, 10.136], loss: 0.001581, mae: 0.042769, mean_q: 1.165516
 876666/1000000: episode: 8767, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 62.768, mean reward: 0.628 [0.512, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.700, 10.358], loss: 0.001541, mae: 0.042520, mean_q: 1.168325
 876766/1000000: episode: 8768, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.598, mean reward: 0.576 [0.501, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.328, 10.142], loss: 0.001545, mae: 0.042980, mean_q: 1.169224
 876866/1000000: episode: 8769, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.979, mean reward: 0.600 [0.513, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.764, 10.399], loss: 0.001583, mae: 0.043015, mean_q: 1.171187
 876966/1000000: episode: 8770, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.246, mean reward: 0.592 [0.505, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.349, 10.098], loss: 0.001597, mae: 0.043260, mean_q: 1.171816
 877066/1000000: episode: 8771, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.240, mean reward: 0.582 [0.520, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.639, 10.344], loss: 0.001614, mae: 0.043732, mean_q: 1.169379
 877166/1000000: episode: 8772, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 63.095, mean reward: 0.631 [0.510, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.382, 10.098], loss: 0.001596, mae: 0.043487, mean_q: 1.174395
 877266/1000000: episode: 8773, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 64.563, mean reward: 0.646 [0.500, 0.870], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-0.624, 10.098], loss: 0.001505, mae: 0.042264, mean_q: 1.171029
 877366/1000000: episode: 8774, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.960, mean reward: 0.590 [0.511, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.152, 10.098], loss: 0.001472, mae: 0.041708, mean_q: 1.175333
 877466/1000000: episode: 8775, duration: 0.631s, episode steps: 100, steps per second: 159, episode reward: 57.328, mean reward: 0.573 [0.501, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.698, 10.153], loss: 0.001499, mae: 0.042062, mean_q: 1.176968
 877566/1000000: episode: 8776, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 56.622, mean reward: 0.566 [0.505, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.967, 10.098], loss: 0.001650, mae: 0.043621, mean_q: 1.174462
 877666/1000000: episode: 8777, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.066, mean reward: 0.571 [0.504, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.830, 10.169], loss: 0.001531, mae: 0.042848, mean_q: 1.173723
 877766/1000000: episode: 8778, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.225, mean reward: 0.592 [0.502, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.575, 10.183], loss: 0.001415, mae: 0.040814, mean_q: 1.171084
 877866/1000000: episode: 8779, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 59.312, mean reward: 0.593 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.936, 10.098], loss: 0.001497, mae: 0.042559, mean_q: 1.174325
 877966/1000000: episode: 8780, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.493, mean reward: 0.595 [0.506, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.833, 10.259], loss: 0.001482, mae: 0.042260, mean_q: 1.171336
 878066/1000000: episode: 8781, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.336, mean reward: 0.573 [0.502, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.794, 10.098], loss: 0.001572, mae: 0.042997, mean_q: 1.172008
 878166/1000000: episode: 8782, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.745, mean reward: 0.577 [0.499, 0.916], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.079, 10.477], loss: 0.001569, mae: 0.043189, mean_q: 1.174353
 878266/1000000: episode: 8783, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.317, mean reward: 0.573 [0.506, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.578, 10.241], loss: 0.001631, mae: 0.043724, mean_q: 1.176348
 878366/1000000: episode: 8784, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.402, mean reward: 0.604 [0.500, 0.912], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.237, 10.098], loss: 0.001549, mae: 0.042491, mean_q: 1.169967
 878466/1000000: episode: 8785, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.633, mean reward: 0.586 [0.498, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.787, 10.098], loss: 0.001557, mae: 0.042944, mean_q: 1.174809
 878566/1000000: episode: 8786, duration: 0.768s, episode steps: 100, steps per second: 130, episode reward: 58.473, mean reward: 0.585 [0.508, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.180, 10.098], loss: 0.001514, mae: 0.041869, mean_q: 1.173888
 878666/1000000: episode: 8787, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 62.591, mean reward: 0.626 [0.523, 0.867], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.107, 10.098], loss: 0.001496, mae: 0.041553, mean_q: 1.171386
 878766/1000000: episode: 8788, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.593, mean reward: 0.576 [0.511, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.324, 10.098], loss: 0.001490, mae: 0.041716, mean_q: 1.171249
 878866/1000000: episode: 8789, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.072, mean reward: 0.591 [0.510, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.975, 10.192], loss: 0.001502, mae: 0.041831, mean_q: 1.171481
 878966/1000000: episode: 8790, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 60.138, mean reward: 0.601 [0.515, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.692, 10.098], loss: 0.001550, mae: 0.042615, mean_q: 1.175068
 879066/1000000: episode: 8791, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.010, mean reward: 0.580 [0.504, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.401, 10.171], loss: 0.001552, mae: 0.042578, mean_q: 1.173091
 879166/1000000: episode: 8792, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.481, mean reward: 0.595 [0.500, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.978, 10.098], loss: 0.001512, mae: 0.042108, mean_q: 1.175265
 879266/1000000: episode: 8793, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.263, mean reward: 0.593 [0.516, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.271, 10.098], loss: 0.001632, mae: 0.043600, mean_q: 1.173649
 879366/1000000: episode: 8794, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 56.970, mean reward: 0.570 [0.504, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.401, 10.098], loss: 0.001593, mae: 0.042690, mean_q: 1.176236
 879466/1000000: episode: 8795, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.275, mean reward: 0.593 [0.500, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.138, 10.312], loss: 0.001612, mae: 0.044000, mean_q: 1.169402
 879566/1000000: episode: 8796, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.930, mean reward: 0.569 [0.499, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.357, 10.176], loss: 0.001617, mae: 0.043811, mean_q: 1.175039
 879666/1000000: episode: 8797, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.437, mean reward: 0.614 [0.504, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.636, 10.098], loss: 0.001491, mae: 0.042038, mean_q: 1.172179
 879766/1000000: episode: 8798, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 60.115, mean reward: 0.601 [0.505, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.060, 10.422], loss: 0.001484, mae: 0.041316, mean_q: 1.173462
 879866/1000000: episode: 8799, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.434, mean reward: 0.574 [0.500, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.115, 10.098], loss: 0.001513, mae: 0.042327, mean_q: 1.172052
 879966/1000000: episode: 8800, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.226, mean reward: 0.592 [0.507, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.234, 10.281], loss: 0.001653, mae: 0.043531, mean_q: 1.172645
 880066/1000000: episode: 8801, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.464, mean reward: 0.575 [0.505, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.624, 10.098], loss: 0.001474, mae: 0.041201, mean_q: 1.171551
 880166/1000000: episode: 8802, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.867, mean reward: 0.609 [0.513, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-1.721, 10.138], loss: 0.001598, mae: 0.043218, mean_q: 1.168763
 880266/1000000: episode: 8803, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.113, mean reward: 0.591 [0.508, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.349, 10.098], loss: 0.001591, mae: 0.043161, mean_q: 1.176794
 880366/1000000: episode: 8804, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.365, mean reward: 0.604 [0.505, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.757, 10.358], loss: 0.001533, mae: 0.042742, mean_q: 1.173069
 880466/1000000: episode: 8805, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.233, mean reward: 0.582 [0.505, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.234, 10.098], loss: 0.001457, mae: 0.041398, mean_q: 1.172760
 880566/1000000: episode: 8806, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.665, mean reward: 0.587 [0.498, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.226, 10.098], loss: 0.001517, mae: 0.041518, mean_q: 1.172145
 880666/1000000: episode: 8807, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.194, mean reward: 0.592 [0.511, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.924, 10.098], loss: 0.001432, mae: 0.041177, mean_q: 1.170475
 880766/1000000: episode: 8808, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 59.521, mean reward: 0.595 [0.509, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.688, 10.098], loss: 0.001540, mae: 0.042196, mean_q: 1.172683
 880866/1000000: episode: 8809, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.926, mean reward: 0.579 [0.506, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.919, 10.098], loss: 0.001486, mae: 0.041822, mean_q: 1.172252
 880966/1000000: episode: 8810, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.478, mean reward: 0.575 [0.510, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.924, 10.155], loss: 0.001447, mae: 0.041294, mean_q: 1.169306
 881066/1000000: episode: 8811, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 59.085, mean reward: 0.591 [0.502, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.387, 10.098], loss: 0.001496, mae: 0.040979, mean_q: 1.172950
 881166/1000000: episode: 8812, duration: 0.532s, episode steps: 100, steps per second: 188, episode reward: 59.222, mean reward: 0.592 [0.525, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.659, 10.098], loss: 0.001440, mae: 0.041254, mean_q: 1.168614
 881266/1000000: episode: 8813, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.781, mean reward: 0.578 [0.504, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.766, 10.198], loss: 0.001485, mae: 0.041154, mean_q: 1.169468
 881366/1000000: episode: 8814, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.033, mean reward: 0.570 [0.504, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.413, 10.098], loss: 0.001381, mae: 0.040240, mean_q: 1.165702
 881466/1000000: episode: 8815, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.214, mean reward: 0.592 [0.508, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.436, 10.199], loss: 0.001477, mae: 0.041686, mean_q: 1.167230
 881566/1000000: episode: 8816, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.578, mean reward: 0.566 [0.503, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.634, 10.197], loss: 0.001576, mae: 0.042733, mean_q: 1.168737
 881666/1000000: episode: 8817, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.583, mean reward: 0.586 [0.503, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.610, 10.183], loss: 0.001513, mae: 0.041105, mean_q: 1.168601
 881766/1000000: episode: 8818, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.522, mean reward: 0.615 [0.500, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.309, 10.421], loss: 0.001498, mae: 0.041229, mean_q: 1.163968
 881866/1000000: episode: 8819, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.927, mean reward: 0.589 [0.505, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.719, 10.098], loss: 0.001527, mae: 0.041895, mean_q: 1.168263
 881966/1000000: episode: 8820, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.070, mean reward: 0.601 [0.497, 0.943], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.972, 10.233], loss: 0.001459, mae: 0.040941, mean_q: 1.167652
 882066/1000000: episode: 8821, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.577, mean reward: 0.596 [0.501, 0.960], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.906, 10.378], loss: 0.001552, mae: 0.041917, mean_q: 1.168581
 882166/1000000: episode: 8822, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 62.487, mean reward: 0.625 [0.518, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.817, 10.277], loss: 0.001549, mae: 0.042124, mean_q: 1.166613
 882266/1000000: episode: 8823, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 59.462, mean reward: 0.595 [0.501, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-2.237, 10.098], loss: 0.001459, mae: 0.040604, mean_q: 1.165604
 882366/1000000: episode: 8824, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.897, mean reward: 0.579 [0.501, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.930, 10.098], loss: 0.001596, mae: 0.042167, mean_q: 1.166231
 882466/1000000: episode: 8825, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.411, mean reward: 0.604 [0.505, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.725, 10.098], loss: 0.001464, mae: 0.040678, mean_q: 1.166266
 882566/1000000: episode: 8826, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.991, mean reward: 0.600 [0.509, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.408, 10.143], loss: 0.001530, mae: 0.041774, mean_q: 1.169077
 882666/1000000: episode: 8827, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 61.962, mean reward: 0.620 [0.519, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.626, 10.098], loss: 0.001648, mae: 0.042779, mean_q: 1.172205
 882766/1000000: episode: 8828, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.416, mean reward: 0.584 [0.517, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.967, 10.303], loss: 0.001516, mae: 0.041984, mean_q: 1.169881
 882866/1000000: episode: 8829, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 58.616, mean reward: 0.586 [0.506, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.542, 10.200], loss: 0.001542, mae: 0.041967, mean_q: 1.163763
 882966/1000000: episode: 8830, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.769, mean reward: 0.588 [0.501, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.594, 10.127], loss: 0.001477, mae: 0.040595, mean_q: 1.166986
 883066/1000000: episode: 8831, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.026, mean reward: 0.600 [0.510, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.857, 10.149], loss: 0.001623, mae: 0.042652, mean_q: 1.164468
 883166/1000000: episode: 8832, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.869, mean reward: 0.599 [0.499, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.481, 10.304], loss: 0.001615, mae: 0.042809, mean_q: 1.166608
 883266/1000000: episode: 8833, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 57.525, mean reward: 0.575 [0.505, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.816, 10.152], loss: 0.001503, mae: 0.042033, mean_q: 1.168887
 883366/1000000: episode: 8834, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 58.967, mean reward: 0.590 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.877, 10.098], loss: 0.001605, mae: 0.042636, mean_q: 1.172273
 883466/1000000: episode: 8835, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 61.196, mean reward: 0.612 [0.514, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.700, 10.149], loss: 0.001587, mae: 0.043238, mean_q: 1.171700
 883566/1000000: episode: 8836, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.755, mean reward: 0.588 [0.505, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.161, 10.098], loss: 0.001523, mae: 0.041934, mean_q: 1.170895
 883666/1000000: episode: 8837, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 62.296, mean reward: 0.623 [0.505, 0.879], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.127, 10.199], loss: 0.001475, mae: 0.041419, mean_q: 1.172617
 883766/1000000: episode: 8838, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 58.985, mean reward: 0.590 [0.497, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.275, 10.201], loss: 0.001410, mae: 0.040065, mean_q: 1.167185
 883866/1000000: episode: 8839, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.139, mean reward: 0.581 [0.507, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.429, 10.098], loss: 0.001471, mae: 0.041132, mean_q: 1.170501
 883966/1000000: episode: 8840, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.304, mean reward: 0.573 [0.500, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.328, 10.300], loss: 0.001611, mae: 0.042779, mean_q: 1.168862
 884066/1000000: episode: 8841, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 59.131, mean reward: 0.591 [0.501, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.182, 10.136], loss: 0.001484, mae: 0.041491, mean_q: 1.169917
 884166/1000000: episode: 8842, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.965, mean reward: 0.580 [0.508, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.099, 10.098], loss: 0.001635, mae: 0.043172, mean_q: 1.167154
 884266/1000000: episode: 8843, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.876, mean reward: 0.619 [0.502, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.196, 10.153], loss: 0.001574, mae: 0.042504, mean_q: 1.168090
 884366/1000000: episode: 8844, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.107, mean reward: 0.571 [0.499, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.311, 10.175], loss: 0.001609, mae: 0.043021, mean_q: 1.172106
 884466/1000000: episode: 8845, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.724, mean reward: 0.607 [0.501, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.656, 10.296], loss: 0.001585, mae: 0.042557, mean_q: 1.168674
 884566/1000000: episode: 8846, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.789, mean reward: 0.598 [0.509, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.738, 10.098], loss: 0.001576, mae: 0.042295, mean_q: 1.173660
 884666/1000000: episode: 8847, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.385, mean reward: 0.584 [0.503, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.499, 10.176], loss: 0.001552, mae: 0.042240, mean_q: 1.172588
 884766/1000000: episode: 8848, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.625, mean reward: 0.596 [0.501, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.568, 10.098], loss: 0.001592, mae: 0.042851, mean_q: 1.171164
 884866/1000000: episode: 8849, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.484, mean reward: 0.605 [0.510, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.783, 10.098], loss: 0.001580, mae: 0.042850, mean_q: 1.172698
 884966/1000000: episode: 8850, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 59.158, mean reward: 0.592 [0.499, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.399, 10.098], loss: 0.001504, mae: 0.042064, mean_q: 1.171036
 885066/1000000: episode: 8851, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.073, mean reward: 0.581 [0.507, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.911, 10.309], loss: 0.001652, mae: 0.043357, mean_q: 1.176827
 885166/1000000: episode: 8852, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.668, mean reward: 0.577 [0.498, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.848, 10.314], loss: 0.001584, mae: 0.042591, mean_q: 1.171422
 885266/1000000: episode: 8853, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.585, mean reward: 0.586 [0.506, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.656, 10.098], loss: 0.001545, mae: 0.041903, mean_q: 1.169426
 885366/1000000: episode: 8854, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.079, mean reward: 0.581 [0.511, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.497, 10.137], loss: 0.001482, mae: 0.041366, mean_q: 1.169311
 885466/1000000: episode: 8855, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.999, mean reward: 0.610 [0.504, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.522, 10.322], loss: 0.001472, mae: 0.041627, mean_q: 1.172200
 885566/1000000: episode: 8856, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.167, mean reward: 0.582 [0.511, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.696, 10.098], loss: 0.001541, mae: 0.042437, mean_q: 1.175051
 885666/1000000: episode: 8857, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.391, mean reward: 0.574 [0.506, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.099, 10.098], loss: 0.001553, mae: 0.042588, mean_q: 1.174235
 885766/1000000: episode: 8858, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.998, mean reward: 0.580 [0.508, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.232, 10.197], loss: 0.001570, mae: 0.042191, mean_q: 1.171778
 885866/1000000: episode: 8859, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.380, mean reward: 0.584 [0.502, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.976, 10.098], loss: 0.001552, mae: 0.042089, mean_q: 1.172514
 885966/1000000: episode: 8860, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 56.502, mean reward: 0.565 [0.503, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.665, 10.170], loss: 0.001598, mae: 0.043387, mean_q: 1.172797
 886066/1000000: episode: 8861, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.711, mean reward: 0.577 [0.505, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.541, 10.098], loss: 0.001435, mae: 0.041272, mean_q: 1.171152
 886166/1000000: episode: 8862, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.071, mean reward: 0.581 [0.505, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.396, 10.162], loss: 0.001505, mae: 0.041845, mean_q: 1.170221
 886266/1000000: episode: 8863, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 61.980, mean reward: 0.620 [0.513, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.510, 10.339], loss: 0.001574, mae: 0.042974, mean_q: 1.168333
 886366/1000000: episode: 8864, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.698, mean reward: 0.587 [0.507, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.052, 10.098], loss: 0.001493, mae: 0.041516, mean_q: 1.170396
 886466/1000000: episode: 8865, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 58.512, mean reward: 0.585 [0.500, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.670, 10.274], loss: 0.001469, mae: 0.041350, mean_q: 1.167089
 886566/1000000: episode: 8866, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.054, mean reward: 0.581 [0.503, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.680, 10.141], loss: 0.001553, mae: 0.042656, mean_q: 1.174113
 886666/1000000: episode: 8867, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.464, mean reward: 0.575 [0.504, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.333, 10.098], loss: 0.001592, mae: 0.042907, mean_q: 1.171098
 886766/1000000: episode: 8868, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.145, mean reward: 0.581 [0.507, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.551, 10.200], loss: 0.001620, mae: 0.043800, mean_q: 1.174652
 886866/1000000: episode: 8869, duration: 0.624s, episode steps: 100, steps per second: 160, episode reward: 59.383, mean reward: 0.594 [0.504, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.770, 10.250], loss: 0.001691, mae: 0.044467, mean_q: 1.173814
 886966/1000000: episode: 8870, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.222, mean reward: 0.572 [0.501, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.539, 10.181], loss: 0.001502, mae: 0.042143, mean_q: 1.165780
 887066/1000000: episode: 8871, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.572, mean reward: 0.576 [0.504, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.795, 10.098], loss: 0.001520, mae: 0.042413, mean_q: 1.168857
 887166/1000000: episode: 8872, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.027, mean reward: 0.580 [0.510, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.437, 10.149], loss: 0.001524, mae: 0.042152, mean_q: 1.166422
 887266/1000000: episode: 8873, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.953, mean reward: 0.610 [0.523, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.856, 10.364], loss: 0.001513, mae: 0.042741, mean_q: 1.171094
 887366/1000000: episode: 8874, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.890, mean reward: 0.569 [0.498, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.569, 10.135], loss: 0.001475, mae: 0.041629, mean_q: 1.165967
 887466/1000000: episode: 8875, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.846, mean reward: 0.578 [0.501, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.932, 10.100], loss: 0.001431, mae: 0.041393, mean_q: 1.162800
 887566/1000000: episode: 8876, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.425, mean reward: 0.604 [0.519, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.742, 10.098], loss: 0.001477, mae: 0.041618, mean_q: 1.165077
 887666/1000000: episode: 8877, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.689, mean reward: 0.577 [0.503, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.767, 10.178], loss: 0.001511, mae: 0.041776, mean_q: 1.163968
 887766/1000000: episode: 8878, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.775, mean reward: 0.588 [0.504, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.525, 10.237], loss: 0.001468, mae: 0.041343, mean_q: 1.161745
 887866/1000000: episode: 8879, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.679, mean reward: 0.577 [0.499, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.202, 10.235], loss: 0.001597, mae: 0.043319, mean_q: 1.165932
 887966/1000000: episode: 8880, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.828, mean reward: 0.578 [0.500, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.183, 10.166], loss: 0.001521, mae: 0.042447, mean_q: 1.169134
 888066/1000000: episode: 8881, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.545, mean reward: 0.575 [0.504, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.823, 10.333], loss: 0.001556, mae: 0.042659, mean_q: 1.162126
 888166/1000000: episode: 8882, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.602, mean reward: 0.586 [0.506, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.757, 10.263], loss: 0.001478, mae: 0.041569, mean_q: 1.164382
 888266/1000000: episode: 8883, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.124, mean reward: 0.601 [0.518, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.220, 10.098], loss: 0.001470, mae: 0.041319, mean_q: 1.161147
 888366/1000000: episode: 8884, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.110, mean reward: 0.581 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.809, 10.098], loss: 0.001420, mae: 0.040700, mean_q: 1.161447
 888466/1000000: episode: 8885, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.753, mean reward: 0.568 [0.499, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.620, 10.125], loss: 0.001484, mae: 0.041817, mean_q: 1.164324
 888566/1000000: episode: 8886, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.541, mean reward: 0.595 [0.502, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.669, 10.098], loss: 0.001484, mae: 0.042075, mean_q: 1.157877
 888666/1000000: episode: 8887, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.034, mean reward: 0.590 [0.504, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.564, 10.098], loss: 0.001462, mae: 0.041216, mean_q: 1.158213
 888766/1000000: episode: 8888, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.599, mean reward: 0.606 [0.505, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.961, 10.137], loss: 0.001515, mae: 0.042123, mean_q: 1.156118
 888866/1000000: episode: 8889, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 62.509, mean reward: 0.625 [0.508, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.217, 10.098], loss: 0.001471, mae: 0.041903, mean_q: 1.157484
 888966/1000000: episode: 8890, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 61.360, mean reward: 0.614 [0.512, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.129, 10.098], loss: 0.001507, mae: 0.042153, mean_q: 1.162685
 889066/1000000: episode: 8891, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 65.229, mean reward: 0.652 [0.534, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.315, 10.337], loss: 0.001425, mae: 0.041334, mean_q: 1.161909
 889166/1000000: episode: 8892, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.871, mean reward: 0.589 [0.501, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.842, 10.098], loss: 0.001573, mae: 0.043068, mean_q: 1.166817
 889266/1000000: episode: 8893, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.863, mean reward: 0.589 [0.498, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.483, 10.215], loss: 0.001497, mae: 0.041766, mean_q: 1.163482
 889366/1000000: episode: 8894, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 63.878, mean reward: 0.639 [0.512, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.851, 10.536], loss: 0.001447, mae: 0.041660, mean_q: 1.165406
 889466/1000000: episode: 8895, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.308, mean reward: 0.583 [0.503, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.559, 10.098], loss: 0.001532, mae: 0.042575, mean_q: 1.165391
 889566/1000000: episode: 8896, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.416, mean reward: 0.574 [0.498, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.109, 10.151], loss: 0.001534, mae: 0.042173, mean_q: 1.162826
 889666/1000000: episode: 8897, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.721, mean reward: 0.597 [0.509, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.258, 10.240], loss: 0.001520, mae: 0.041685, mean_q: 1.166346
 889766/1000000: episode: 8898, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 58.142, mean reward: 0.581 [0.501, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.395, 10.180], loss: 0.001519, mae: 0.042295, mean_q: 1.164147
 889866/1000000: episode: 8899, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.412, mean reward: 0.584 [0.513, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.531, 10.098], loss: 0.001407, mae: 0.040563, mean_q: 1.164773
 889966/1000000: episode: 8900, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.400, mean reward: 0.584 [0.502, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.792, 10.098], loss: 0.001353, mae: 0.040624, mean_q: 1.165501
 890066/1000000: episode: 8901, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.098, mean reward: 0.571 [0.504, 0.859], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.810, 10.098], loss: 0.001522, mae: 0.042490, mean_q: 1.162705
 890166/1000000: episode: 8902, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 63.459, mean reward: 0.635 [0.522, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.150, 10.523], loss: 0.001434, mae: 0.040812, mean_q: 1.166013
 890266/1000000: episode: 8903, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 59.875, mean reward: 0.599 [0.499, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.222, 10.098], loss: 0.001476, mae: 0.041819, mean_q: 1.165180
 890366/1000000: episode: 8904, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.814, mean reward: 0.608 [0.501, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.166, 10.130], loss: 0.001453, mae: 0.041844, mean_q: 1.167846
 890466/1000000: episode: 8905, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.406, mean reward: 0.584 [0.508, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.155, 10.128], loss: 0.001537, mae: 0.042265, mean_q: 1.168231
 890566/1000000: episode: 8906, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.058, mean reward: 0.571 [0.505, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.264, 10.098], loss: 0.001481, mae: 0.041741, mean_q: 1.164478
 890666/1000000: episode: 8907, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.756, mean reward: 0.578 [0.506, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.939, 10.098], loss: 0.001570, mae: 0.042883, mean_q: 1.168932
 890766/1000000: episode: 8908, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 59.688, mean reward: 0.597 [0.503, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.651, 10.098], loss: 0.001623, mae: 0.043607, mean_q: 1.168083
 890866/1000000: episode: 8909, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.056, mean reward: 0.581 [0.507, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.567, 10.121], loss: 0.001424, mae: 0.040772, mean_q: 1.163955
 890966/1000000: episode: 8910, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 61.659, mean reward: 0.617 [0.504, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.074, 10.282], loss: 0.001541, mae: 0.042845, mean_q: 1.165880
 891066/1000000: episode: 8911, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.111, mean reward: 0.591 [0.509, 0.866], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.767, 10.297], loss: 0.001431, mae: 0.041097, mean_q: 1.165602
 891166/1000000: episode: 8912, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.678, mean reward: 0.587 [0.501, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.160, 10.098], loss: 0.001563, mae: 0.042818, mean_q: 1.170547
 891266/1000000: episode: 8913, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.621, mean reward: 0.586 [0.504, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.974, 10.098], loss: 0.001629, mae: 0.043026, mean_q: 1.169648
 891366/1000000: episode: 8914, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.956, mean reward: 0.580 [0.502, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.218, 10.098], loss: 0.001531, mae: 0.042249, mean_q: 1.169384
 891466/1000000: episode: 8915, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.046, mean reward: 0.600 [0.503, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.335, 10.098], loss: 0.001417, mae: 0.041427, mean_q: 1.166995
 891566/1000000: episode: 8916, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 61.379, mean reward: 0.614 [0.501, 0.861], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.117, 10.098], loss: 0.001525, mae: 0.041471, mean_q: 1.171857
 891666/1000000: episode: 8917, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.889, mean reward: 0.589 [0.507, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.533, 10.247], loss: 0.001504, mae: 0.041556, mean_q: 1.171252
 891766/1000000: episode: 8918, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.415, mean reward: 0.604 [0.514, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.720, 10.483], loss: 0.001401, mae: 0.039850, mean_q: 1.167528
 891866/1000000: episode: 8919, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 61.131, mean reward: 0.611 [0.509, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.133, 10.370], loss: 0.001501, mae: 0.041349, mean_q: 1.174954
 891966/1000000: episode: 8920, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.440, mean reward: 0.604 [0.514, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.014, 10.098], loss: 0.001491, mae: 0.041752, mean_q: 1.175663
 892066/1000000: episode: 8921, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.592, mean reward: 0.586 [0.503, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.749, 10.167], loss: 0.001567, mae: 0.042224, mean_q: 1.174235
 892166/1000000: episode: 8922, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.186, mean reward: 0.602 [0.502, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.247, 10.098], loss: 0.001475, mae: 0.041449, mean_q: 1.177096
 892266/1000000: episode: 8923, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 61.479, mean reward: 0.615 [0.504, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.667, 10.365], loss: 0.001496, mae: 0.041333, mean_q: 1.175576
 892366/1000000: episode: 8924, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 59.898, mean reward: 0.599 [0.509, 0.846], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.862, 10.259], loss: 0.001574, mae: 0.042613, mean_q: 1.174712
 892466/1000000: episode: 8925, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.689, mean reward: 0.587 [0.509, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.543, 10.176], loss: 0.001485, mae: 0.041336, mean_q: 1.179290
 892566/1000000: episode: 8926, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.223, mean reward: 0.592 [0.499, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.147, 10.112], loss: 0.001429, mae: 0.040725, mean_q: 1.174003
 892666/1000000: episode: 8927, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 58.570, mean reward: 0.586 [0.512, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.285, 10.172], loss: 0.001508, mae: 0.041671, mean_q: 1.176534
 892766/1000000: episode: 8928, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 61.509, mean reward: 0.615 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.491, 10.098], loss: 0.001704, mae: 0.043495, mean_q: 1.178858
 892866/1000000: episode: 8929, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.852, mean reward: 0.609 [0.511, 0.880], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.988, 10.098], loss: 0.001503, mae: 0.041783, mean_q: 1.178093
 892966/1000000: episode: 8930, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.655, mean reward: 0.587 [0.504, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.645, 10.098], loss: 0.001528, mae: 0.042153, mean_q: 1.179456
 893066/1000000: episode: 8931, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 57.437, mean reward: 0.574 [0.507, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.262, 10.182], loss: 0.001439, mae: 0.041398, mean_q: 1.178629
 893166/1000000: episode: 8932, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.580, mean reward: 0.576 [0.509, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.974, 10.098], loss: 0.001598, mae: 0.043202, mean_q: 1.183141
 893266/1000000: episode: 8933, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.804, mean reward: 0.588 [0.498, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.945, 10.098], loss: 0.001640, mae: 0.043578, mean_q: 1.177298
 893366/1000000: episode: 8934, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.432, mean reward: 0.594 [0.504, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.413, 10.221], loss: 0.001521, mae: 0.041858, mean_q: 1.179338
 893466/1000000: episode: 8935, duration: 0.634s, episode steps: 100, steps per second: 158, episode reward: 56.704, mean reward: 0.567 [0.506, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.482, 10.098], loss: 0.001552, mae: 0.042108, mean_q: 1.177261
 893566/1000000: episode: 8936, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.782, mean reward: 0.598 [0.517, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.718, 10.257], loss: 0.001537, mae: 0.042152, mean_q: 1.180542
 893666/1000000: episode: 8937, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.252, mean reward: 0.583 [0.500, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.008, 10.190], loss: 0.001556, mae: 0.042424, mean_q: 1.182884
 893766/1000000: episode: 8938, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.584, mean reward: 0.586 [0.501, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.620, 10.116], loss: 0.001375, mae: 0.040208, mean_q: 1.178970
 893866/1000000: episode: 8939, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.531, mean reward: 0.585 [0.502, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.695, 10.207], loss: 0.001413, mae: 0.041088, mean_q: 1.176699
 893966/1000000: episode: 8940, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.247, mean reward: 0.582 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.840, 10.284], loss: 0.001457, mae: 0.041149, mean_q: 1.174008
 894066/1000000: episode: 8941, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.106, mean reward: 0.591 [0.501, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.520, 10.110], loss: 0.001496, mae: 0.041806, mean_q: 1.176110
 894166/1000000: episode: 8942, duration: 0.631s, episode steps: 100, steps per second: 158, episode reward: 60.552, mean reward: 0.606 [0.511, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.559, 10.536], loss: 0.001621, mae: 0.042452, mean_q: 1.174573
 894266/1000000: episode: 8943, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.742, mean reward: 0.597 [0.514, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.170, 10.098], loss: 0.001502, mae: 0.042207, mean_q: 1.177544
 894366/1000000: episode: 8944, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 59.230, mean reward: 0.592 [0.510, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.634, 10.098], loss: 0.001486, mae: 0.041403, mean_q: 1.172156
 894466/1000000: episode: 8945, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 63.045, mean reward: 0.630 [0.523, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.450, 10.319], loss: 0.001440, mae: 0.041118, mean_q: 1.174547
 894566/1000000: episode: 8946, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.885, mean reward: 0.569 [0.504, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.681, 10.138], loss: 0.001538, mae: 0.041905, mean_q: 1.176892
 894666/1000000: episode: 8947, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 60.679, mean reward: 0.607 [0.517, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.562, 10.303], loss: 0.001547, mae: 0.042060, mean_q: 1.171767
 894766/1000000: episode: 8948, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 63.789, mean reward: 0.638 [0.510, 0.948], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.881, 10.346], loss: 0.001500, mae: 0.041810, mean_q: 1.174702
 894866/1000000: episode: 8949, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 57.887, mean reward: 0.579 [0.506, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.897, 10.098], loss: 0.001398, mae: 0.039823, mean_q: 1.176418
 894966/1000000: episode: 8950, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.997, mean reward: 0.590 [0.505, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.866, 10.191], loss: 0.001507, mae: 0.042104, mean_q: 1.177865
 895066/1000000: episode: 8951, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.964, mean reward: 0.580 [0.499, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.038, 10.098], loss: 0.001480, mae: 0.041186, mean_q: 1.174019
 895166/1000000: episode: 8952, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 60.030, mean reward: 0.600 [0.511, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.027, 10.363], loss: 0.001596, mae: 0.042774, mean_q: 1.174752
 895266/1000000: episode: 8953, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.093, mean reward: 0.581 [0.505, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.588, 10.098], loss: 0.001497, mae: 0.041883, mean_q: 1.174644
 895366/1000000: episode: 8954, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.430, mean reward: 0.574 [0.507, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.821, 10.098], loss: 0.001405, mae: 0.040788, mean_q: 1.171907
 895466/1000000: episode: 8955, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.130, mean reward: 0.581 [0.515, 0.815], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.788, 10.098], loss: 0.001406, mae: 0.040601, mean_q: 1.171225
 895566/1000000: episode: 8956, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.747, mean reward: 0.597 [0.507, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.819, 10.098], loss: 0.001585, mae: 0.042508, mean_q: 1.177086
 895666/1000000: episode: 8957, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.668, mean reward: 0.577 [0.510, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.379, 10.263], loss: 0.001484, mae: 0.041824, mean_q: 1.174819
 895766/1000000: episode: 8958, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 60.413, mean reward: 0.604 [0.503, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.109, 10.098], loss: 0.001492, mae: 0.041109, mean_q: 1.172964
 895866/1000000: episode: 8959, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.067, mean reward: 0.601 [0.497, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.326, 10.098], loss: 0.001369, mae: 0.040369, mean_q: 1.173426
 895966/1000000: episode: 8960, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.658, mean reward: 0.597 [0.506, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.836, 10.162], loss: 0.001578, mae: 0.042253, mean_q: 1.175186
 896066/1000000: episode: 8961, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.453, mean reward: 0.605 [0.510, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.833, 10.231], loss: 0.001490, mae: 0.042158, mean_q: 1.175216
 896166/1000000: episode: 8962, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 63.029, mean reward: 0.630 [0.505, 0.928], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.527, 10.493], loss: 0.001522, mae: 0.042272, mean_q: 1.178373
 896266/1000000: episode: 8963, duration: 0.604s, episode steps: 100, steps per second: 165, episode reward: 61.233, mean reward: 0.612 [0.502, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.838, 10.147], loss: 0.001585, mae: 0.042642, mean_q: 1.180012
 896366/1000000: episode: 8964, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.382, mean reward: 0.584 [0.502, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.663, 10.188], loss: 0.001629, mae: 0.043268, mean_q: 1.181183
 896466/1000000: episode: 8965, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.400, mean reward: 0.614 [0.524, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.747, 10.364], loss: 0.001577, mae: 0.042843, mean_q: 1.180045
 896566/1000000: episode: 8966, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.980, mean reward: 0.590 [0.501, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.552, 10.350], loss: 0.001486, mae: 0.041320, mean_q: 1.180017
 896666/1000000: episode: 8967, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 57.583, mean reward: 0.576 [0.503, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.307, 10.098], loss: 0.001474, mae: 0.042105, mean_q: 1.179772
 896766/1000000: episode: 8968, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.370, mean reward: 0.594 [0.501, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.117, 10.291], loss: 0.001460, mae: 0.040967, mean_q: 1.177364
 896866/1000000: episode: 8969, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.961, mean reward: 0.620 [0.518, 0.772], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.630, 10.098], loss: 0.001603, mae: 0.042769, mean_q: 1.176649
 896966/1000000: episode: 8970, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 60.820, mean reward: 0.608 [0.507, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.946, 10.098], loss: 0.001545, mae: 0.042008, mean_q: 1.178210
 897066/1000000: episode: 8971, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.206, mean reward: 0.582 [0.512, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.634, 10.098], loss: 0.001397, mae: 0.040458, mean_q: 1.178800
 897166/1000000: episode: 8972, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.381, mean reward: 0.604 [0.510, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.908, 10.098], loss: 0.001462, mae: 0.041613, mean_q: 1.177690
 897266/1000000: episode: 8973, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 59.125, mean reward: 0.591 [0.511, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.633, 10.098], loss: 0.001484, mae: 0.041574, mean_q: 1.173945
 897366/1000000: episode: 8974, duration: 0.601s, episode steps: 100, steps per second: 167, episode reward: 64.078, mean reward: 0.641 [0.501, 0.933], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.685, 10.098], loss: 0.001521, mae: 0.041515, mean_q: 1.177291
 897466/1000000: episode: 8975, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 62.248, mean reward: 0.622 [0.499, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.318, 10.098], loss: 0.001454, mae: 0.041165, mean_q: 1.178276
 897566/1000000: episode: 8976, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.823, mean reward: 0.588 [0.506, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.441, 10.320], loss: 0.001396, mae: 0.040424, mean_q: 1.179175
 897666/1000000: episode: 8977, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.333, mean reward: 0.603 [0.512, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.375, 10.098], loss: 0.001394, mae: 0.040676, mean_q: 1.175352
 897766/1000000: episode: 8978, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 59.371, mean reward: 0.594 [0.510, 0.887], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.537, 10.098], loss: 0.001398, mae: 0.040381, mean_q: 1.178191
 897866/1000000: episode: 8979, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 63.362, mean reward: 0.634 [0.510, 0.897], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.801, 10.346], loss: 0.001519, mae: 0.042605, mean_q: 1.177374
 897966/1000000: episode: 8980, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.389, mean reward: 0.574 [0.500, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.139, 10.256], loss: 0.001483, mae: 0.041563, mean_q: 1.178819
 898066/1000000: episode: 8981, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.273, mean reward: 0.583 [0.511, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.820, 10.098], loss: 0.001483, mae: 0.042114, mean_q: 1.177080
 898166/1000000: episode: 8982, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 58.660, mean reward: 0.587 [0.503, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.373, 10.098], loss: 0.001559, mae: 0.042342, mean_q: 1.181247
 898266/1000000: episode: 8983, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.786, mean reward: 0.568 [0.501, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.769, 10.255], loss: 0.001415, mae: 0.040702, mean_q: 1.180683
 898366/1000000: episode: 8984, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 59.723, mean reward: 0.597 [0.512, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.986, 10.381], loss: 0.001359, mae: 0.040333, mean_q: 1.174454
 898466/1000000: episode: 8985, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.966, mean reward: 0.580 [0.505, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.626, 10.098], loss: 0.001537, mae: 0.041868, mean_q: 1.183082
 898566/1000000: episode: 8986, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.962, mean reward: 0.580 [0.505, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.069, 10.107], loss: 0.001409, mae: 0.040192, mean_q: 1.179974
 898666/1000000: episode: 8987, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.648, mean reward: 0.566 [0.499, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.523, 10.103], loss: 0.001427, mae: 0.041002, mean_q: 1.176863
 898766/1000000: episode: 8988, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.411, mean reward: 0.584 [0.501, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.829, 10.098], loss: 0.001533, mae: 0.042178, mean_q: 1.177134
 898866/1000000: episode: 8989, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.724, mean reward: 0.617 [0.503, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.900, 10.098], loss: 0.001467, mae: 0.041164, mean_q: 1.180108
 898966/1000000: episode: 8990, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.449, mean reward: 0.594 [0.501, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.973, 10.098], loss: 0.001459, mae: 0.041815, mean_q: 1.184389
 899066/1000000: episode: 8991, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.991, mean reward: 0.590 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.864, 10.168], loss: 0.001428, mae: 0.040428, mean_q: 1.178328
 899166/1000000: episode: 8992, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 57.386, mean reward: 0.574 [0.497, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.017, 10.261], loss: 0.001446, mae: 0.041021, mean_q: 1.179567
 899266/1000000: episode: 8993, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.831, mean reward: 0.598 [0.500, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.646, 10.145], loss: 0.001339, mae: 0.039706, mean_q: 1.177201
 899366/1000000: episode: 8994, duration: 0.597s, episode steps: 100, steps per second: 168, episode reward: 61.084, mean reward: 0.611 [0.507, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.641, 10.098], loss: 0.001382, mae: 0.040164, mean_q: 1.175316
 899466/1000000: episode: 8995, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 58.847, mean reward: 0.588 [0.502, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.542, 10.382], loss: 0.001381, mae: 0.040564, mean_q: 1.178762
 899566/1000000: episode: 8996, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.858, mean reward: 0.589 [0.506, 0.824], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.044, 10.098], loss: 0.001435, mae: 0.040955, mean_q: 1.179087
 899666/1000000: episode: 8997, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.848, mean reward: 0.578 [0.506, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.059, 10.142], loss: 0.001536, mae: 0.042232, mean_q: 1.176222
 899766/1000000: episode: 8998, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.289, mean reward: 0.593 [0.503, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.986, 10.385], loss: 0.001453, mae: 0.041150, mean_q: 1.176037
 899866/1000000: episode: 8999, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.248, mean reward: 0.582 [0.499, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.854, 10.225], loss: 0.001431, mae: 0.041238, mean_q: 1.176476
 899966/1000000: episode: 9000, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.642, mean reward: 0.566 [0.502, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.333, 10.136], loss: 0.001431, mae: 0.040786, mean_q: 1.174364
 900066/1000000: episode: 9001, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.007, mean reward: 0.590 [0.505, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.280, 10.104], loss: 0.001451, mae: 0.040677, mean_q: 1.173795
 900166/1000000: episode: 9002, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.941, mean reward: 0.609 [0.503, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.899, 10.262], loss: 0.001393, mae: 0.040651, mean_q: 1.176972
 900266/1000000: episode: 9003, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.656, mean reward: 0.597 [0.505, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.479, 10.098], loss: 0.001472, mae: 0.041105, mean_q: 1.179805
 900366/1000000: episode: 9004, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.992, mean reward: 0.600 [0.502, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.183, 10.398], loss: 0.001421, mae: 0.040830, mean_q: 1.176880
 900466/1000000: episode: 9005, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.459, mean reward: 0.585 [0.502, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.719, 10.119], loss: 0.001403, mae: 0.039619, mean_q: 1.176954
 900566/1000000: episode: 9006, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 61.118, mean reward: 0.611 [0.512, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.835, 10.098], loss: 0.001403, mae: 0.040744, mean_q: 1.175669
 900666/1000000: episode: 9007, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.647, mean reward: 0.586 [0.506, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.399, 10.098], loss: 0.001391, mae: 0.040744, mean_q: 1.180600
 900766/1000000: episode: 9008, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 61.370, mean reward: 0.614 [0.514, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.950, 10.363], loss: 0.001354, mae: 0.039812, mean_q: 1.176132
 900866/1000000: episode: 9009, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 59.412, mean reward: 0.594 [0.502, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.468, 10.409], loss: 0.001531, mae: 0.041553, mean_q: 1.181370
 900966/1000000: episode: 9010, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 58.411, mean reward: 0.584 [0.506, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.705, 10.098], loss: 0.001440, mae: 0.040904, mean_q: 1.177743
 901066/1000000: episode: 9011, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.090, mean reward: 0.601 [0.507, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.370, 10.218], loss: 0.001507, mae: 0.041475, mean_q: 1.179251
 901166/1000000: episode: 9012, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 60.261, mean reward: 0.603 [0.503, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.518, 10.098], loss: 0.001367, mae: 0.040042, mean_q: 1.176823
 901266/1000000: episode: 9013, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.228, mean reward: 0.602 [0.506, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.271, 10.343], loss: 0.001402, mae: 0.040917, mean_q: 1.176892
 901366/1000000: episode: 9014, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.861, mean reward: 0.589 [0.502, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.694, 10.098], loss: 0.001352, mae: 0.040035, mean_q: 1.176971
 901466/1000000: episode: 9015, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.935, mean reward: 0.589 [0.519, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.745, 10.236], loss: 0.001388, mae: 0.040623, mean_q: 1.174854
 901566/1000000: episode: 9016, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.407, mean reward: 0.574 [0.507, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.794, 10.098], loss: 0.001389, mae: 0.040466, mean_q: 1.176064
 901666/1000000: episode: 9017, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.616, mean reward: 0.606 [0.499, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.933, 10.098], loss: 0.001462, mae: 0.041162, mean_q: 1.176724
 901766/1000000: episode: 9018, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.416, mean reward: 0.584 [0.509, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.978, 10.098], loss: 0.001391, mae: 0.040127, mean_q: 1.173574
 901866/1000000: episode: 9019, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.805, mean reward: 0.608 [0.503, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.742, 10.098], loss: 0.001407, mae: 0.040131, mean_q: 1.175136
 901966/1000000: episode: 9020, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 61.451, mean reward: 0.615 [0.504, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.921, 10.357], loss: 0.001449, mae: 0.040409, mean_q: 1.178461
 902066/1000000: episode: 9021, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.852, mean reward: 0.589 [0.504, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.455, 10.226], loss: 0.001424, mae: 0.041143, mean_q: 1.172064
 902166/1000000: episode: 9022, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.540, mean reward: 0.585 [0.500, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.708, 10.200], loss: 0.001365, mae: 0.040176, mean_q: 1.170896
 902266/1000000: episode: 9023, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.066, mean reward: 0.601 [0.506, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.595, 10.098], loss: 0.001336, mae: 0.039601, mean_q: 1.174016
 902366/1000000: episode: 9024, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.136, mean reward: 0.601 [0.513, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.494, 10.098], loss: 0.001491, mae: 0.041472, mean_q: 1.175464
 902466/1000000: episode: 9025, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.449, mean reward: 0.584 [0.506, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.530, 10.098], loss: 0.001567, mae: 0.042687, mean_q: 1.172429
 902566/1000000: episode: 9026, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 57.281, mean reward: 0.573 [0.500, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.395, 10.098], loss: 0.001528, mae: 0.042084, mean_q: 1.173154
 902666/1000000: episode: 9027, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.329, mean reward: 0.603 [0.513, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.678, 10.326], loss: 0.001523, mae: 0.042902, mean_q: 1.172763
 902766/1000000: episode: 9028, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.224, mean reward: 0.582 [0.510, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.980, 10.098], loss: 0.001324, mae: 0.040008, mean_q: 1.172011
 902866/1000000: episode: 9029, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 59.791, mean reward: 0.598 [0.505, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.751, 10.185], loss: 0.001415, mae: 0.040910, mean_q: 1.168212
 902966/1000000: episode: 9030, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.209, mean reward: 0.592 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.905, 10.098], loss: 0.001508, mae: 0.042014, mean_q: 1.171139
 903066/1000000: episode: 9031, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.438, mean reward: 0.584 [0.501, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.589, 10.098], loss: 0.001466, mae: 0.041310, mean_q: 1.168647
 903166/1000000: episode: 9032, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.961, mean reward: 0.580 [0.501, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.377, 10.169], loss: 0.001527, mae: 0.041977, mean_q: 1.172874
 903266/1000000: episode: 9033, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.220, mean reward: 0.612 [0.512, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.822, 10.151], loss: 0.001423, mae: 0.041059, mean_q: 1.170926
 903366/1000000: episode: 9034, duration: 0.529s, episode steps: 100, steps per second: 189, episode reward: 58.234, mean reward: 0.582 [0.501, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.619, 10.098], loss: 0.001609, mae: 0.043574, mean_q: 1.172037
 903466/1000000: episode: 9035, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.701, mean reward: 0.607 [0.510, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.965, 10.098], loss: 0.001501, mae: 0.042004, mean_q: 1.169232
 903566/1000000: episode: 9036, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.110, mean reward: 0.601 [0.509, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.261, 10.294], loss: 0.001454, mae: 0.041532, mean_q: 1.173557
 903666/1000000: episode: 9037, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 63.173, mean reward: 0.632 [0.499, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.812, 10.098], loss: 0.001525, mae: 0.042162, mean_q: 1.173349
 903766/1000000: episode: 9038, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.911, mean reward: 0.579 [0.512, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.436, 10.098], loss: 0.001398, mae: 0.040864, mean_q: 1.175563
 903866/1000000: episode: 9039, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.928, mean reward: 0.579 [0.501, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.397, 10.120], loss: 0.001492, mae: 0.041544, mean_q: 1.176599
 903966/1000000: episode: 9040, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.267, mean reward: 0.603 [0.497, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.570, 10.098], loss: 0.001483, mae: 0.041471, mean_q: 1.176962
 904066/1000000: episode: 9041, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.308, mean reward: 0.583 [0.505, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.281, 10.098], loss: 0.001423, mae: 0.040553, mean_q: 1.176914
 904166/1000000: episode: 9042, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.571, mean reward: 0.596 [0.511, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.445, 10.206], loss: 0.001458, mae: 0.041672, mean_q: 1.177435
 904266/1000000: episode: 9043, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.065, mean reward: 0.581 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.089, 10.163], loss: 0.001487, mae: 0.041427, mean_q: 1.174901
 904366/1000000: episode: 9044, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.415, mean reward: 0.574 [0.500, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.852, 10.158], loss: 0.001504, mae: 0.041585, mean_q: 1.174363
 904466/1000000: episode: 9045, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.210, mean reward: 0.612 [0.519, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.606, 10.098], loss: 0.001549, mae: 0.042504, mean_q: 1.175264
 904566/1000000: episode: 9046, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.368, mean reward: 0.594 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.700, 10.182], loss: 0.001526, mae: 0.042039, mean_q: 1.175105
 904666/1000000: episode: 9047, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 62.634, mean reward: 0.626 [0.503, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.450, 10.098], loss: 0.001580, mae: 0.043427, mean_q: 1.178138
 904766/1000000: episode: 9048, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.928, mean reward: 0.579 [0.506, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.948, 10.098], loss: 0.001529, mae: 0.042871, mean_q: 1.177476
 904866/1000000: episode: 9049, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.653, mean reward: 0.577 [0.502, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.815, 10.118], loss: 0.001542, mae: 0.043230, mean_q: 1.179180
 904966/1000000: episode: 9050, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 58.002, mean reward: 0.580 [0.503, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.305, 10.208], loss: 0.001484, mae: 0.042624, mean_q: 1.177117
 905066/1000000: episode: 9051, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.667, mean reward: 0.597 [0.502, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.226, 10.098], loss: 0.001493, mae: 0.042287, mean_q: 1.180181
 905166/1000000: episode: 9052, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 61.919, mean reward: 0.619 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.874, 10.404], loss: 0.001508, mae: 0.042988, mean_q: 1.177040
 905266/1000000: episode: 9053, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 60.245, mean reward: 0.602 [0.512, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.079, 10.278], loss: 0.001496, mae: 0.043065, mean_q: 1.180504
 905366/1000000: episode: 9054, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.402, mean reward: 0.594 [0.505, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.829, 10.180], loss: 0.001509, mae: 0.042540, mean_q: 1.178002
 905466/1000000: episode: 9055, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.514, mean reward: 0.585 [0.511, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.975, 10.165], loss: 0.001479, mae: 0.042473, mean_q: 1.175852
 905566/1000000: episode: 9056, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.606, mean reward: 0.596 [0.500, 0.878], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.699, 10.098], loss: 0.001458, mae: 0.041980, mean_q: 1.180161
 905666/1000000: episode: 9057, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.938, mean reward: 0.619 [0.512, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.530, 10.098], loss: 0.001429, mae: 0.041609, mean_q: 1.176343
 905766/1000000: episode: 9058, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.305, mean reward: 0.583 [0.500, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.448, 10.098], loss: 0.001471, mae: 0.041546, mean_q: 1.175162
 905866/1000000: episode: 9059, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.489, mean reward: 0.615 [0.508, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.187, 10.098], loss: 0.001432, mae: 0.041837, mean_q: 1.177426
 905966/1000000: episode: 9060, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.465, mean reward: 0.595 [0.501, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.490, 10.178], loss: 0.001468, mae: 0.042054, mean_q: 1.174530
 906066/1000000: episode: 9061, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.004, mean reward: 0.590 [0.501, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.476, 10.309], loss: 0.001558, mae: 0.042694, mean_q: 1.177027
 906166/1000000: episode: 9062, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.425, mean reward: 0.584 [0.504, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.309, 10.256], loss: 0.001458, mae: 0.042193, mean_q: 1.180406
 906266/1000000: episode: 9063, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.665, mean reward: 0.577 [0.500, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.503, 10.135], loss: 0.001410, mae: 0.041273, mean_q: 1.178055
 906366/1000000: episode: 9064, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.096, mean reward: 0.581 [0.498, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.238, 10.098], loss: 0.001489, mae: 0.042643, mean_q: 1.175646
 906466/1000000: episode: 9065, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.025, mean reward: 0.600 [0.504, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.057, 10.098], loss: 0.001507, mae: 0.042519, mean_q: 1.173842
 906566/1000000: episode: 9066, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 60.080, mean reward: 0.601 [0.503, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.759, 10.279], loss: 0.001538, mae: 0.042741, mean_q: 1.173215
 906666/1000000: episode: 9067, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.275, mean reward: 0.593 [0.512, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.954, 10.191], loss: 0.001557, mae: 0.043605, mean_q: 1.177567
 906766/1000000: episode: 9068, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.390, mean reward: 0.614 [0.509, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.195, 10.281], loss: 0.001539, mae: 0.042703, mean_q: 1.177444
 906866/1000000: episode: 9069, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.561, mean reward: 0.586 [0.506, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.752, 10.098], loss: 0.001394, mae: 0.041276, mean_q: 1.171301
 906966/1000000: episode: 9070, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 60.460, mean reward: 0.605 [0.511, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.934, 10.173], loss: 0.001486, mae: 0.041600, mean_q: 1.176628
 907066/1000000: episode: 9071, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.689, mean reward: 0.577 [0.505, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.525, 10.098], loss: 0.001499, mae: 0.043054, mean_q: 1.177274
 907166/1000000: episode: 9072, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.362, mean reward: 0.574 [0.505, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.979, 10.254], loss: 0.001457, mae: 0.041850, mean_q: 1.177385
 907266/1000000: episode: 9073, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.114, mean reward: 0.581 [0.505, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.929, 10.371], loss: 0.001572, mae: 0.043656, mean_q: 1.177902
 907366/1000000: episode: 9074, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.119, mean reward: 0.591 [0.506, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.858, 10.396], loss: 0.001414, mae: 0.040958, mean_q: 1.176514
 907466/1000000: episode: 9075, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.787, mean reward: 0.578 [0.503, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.973, 10.193], loss: 0.001441, mae: 0.041213, mean_q: 1.171213
 907566/1000000: episode: 9076, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 60.194, mean reward: 0.602 [0.516, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.607, 10.098], loss: 0.001507, mae: 0.042430, mean_q: 1.173942
 907666/1000000: episode: 9077, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.142, mean reward: 0.581 [0.506, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.158, 10.119], loss: 0.001502, mae: 0.042821, mean_q: 1.172953
 907766/1000000: episode: 9078, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 58.151, mean reward: 0.582 [0.504, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.862, 10.098], loss: 0.001416, mae: 0.041174, mean_q: 1.170691
 907866/1000000: episode: 9079, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.514, mean reward: 0.585 [0.508, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.575, 10.174], loss: 0.001444, mae: 0.041343, mean_q: 1.171178
 907966/1000000: episode: 9080, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.843, mean reward: 0.598 [0.503, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.655, 10.098], loss: 0.001484, mae: 0.041962, mean_q: 1.172682
 908066/1000000: episode: 9081, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.466, mean reward: 0.605 [0.504, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.290, 10.196], loss: 0.001480, mae: 0.042016, mean_q: 1.170683
 908166/1000000: episode: 9082, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.424, mean reward: 0.604 [0.508, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.755, 10.141], loss: 0.001433, mae: 0.041208, mean_q: 1.174061
 908266/1000000: episode: 9083, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.639, mean reward: 0.576 [0.501, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.283, 10.113], loss: 0.001514, mae: 0.042187, mean_q: 1.173756
 908366/1000000: episode: 9084, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 60.993, mean reward: 0.610 [0.509, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.413 [-1.082, 10.098], loss: 0.001567, mae: 0.043330, mean_q: 1.177324
 908466/1000000: episode: 9085, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.308, mean reward: 0.583 [0.499, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.997, 10.121], loss: 0.001358, mae: 0.040742, mean_q: 1.173533
 908566/1000000: episode: 9086, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 58.568, mean reward: 0.586 [0.497, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.677, 10.170], loss: 0.001498, mae: 0.041876, mean_q: 1.174239
 908666/1000000: episode: 9087, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.389, mean reward: 0.584 [0.523, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.198, 10.366], loss: 0.001576, mae: 0.043283, mean_q: 1.173424
 908766/1000000: episode: 9088, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.062, mean reward: 0.581 [0.504, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.827, 10.120], loss: 0.001524, mae: 0.042774, mean_q: 1.173537
 908866/1000000: episode: 9089, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.816, mean reward: 0.598 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.779, 10.173], loss: 0.001484, mae: 0.041979, mean_q: 1.171811
 908966/1000000: episode: 9090, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.701, mean reward: 0.617 [0.512, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.879, 10.281], loss: 0.001468, mae: 0.041860, mean_q: 1.174704
 909066/1000000: episode: 9091, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.872, mean reward: 0.619 [0.509, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.629, 10.482], loss: 0.001492, mae: 0.042566, mean_q: 1.172575
 909166/1000000: episode: 9092, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 64.127, mean reward: 0.641 [0.511, 0.858], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.019, 10.098], loss: 0.001498, mae: 0.042223, mean_q: 1.170499
 909266/1000000: episode: 9093, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.061, mean reward: 0.581 [0.500, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.897, 10.098], loss: 0.001451, mae: 0.041643, mean_q: 1.177766
 909366/1000000: episode: 9094, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 61.152, mean reward: 0.612 [0.501, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.602, 10.384], loss: 0.001567, mae: 0.042563, mean_q: 1.178131
 909466/1000000: episode: 9095, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.186, mean reward: 0.592 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.721, 10.098], loss: 0.001358, mae: 0.040583, mean_q: 1.174157
 909566/1000000: episode: 9096, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 59.492, mean reward: 0.595 [0.505, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.620, 10.098], loss: 0.001480, mae: 0.041989, mean_q: 1.178596
 909666/1000000: episode: 9097, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.305, mean reward: 0.583 [0.500, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.024, 10.339], loss: 0.001473, mae: 0.041708, mean_q: 1.170734
 909766/1000000: episode: 9098, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.815, mean reward: 0.598 [0.507, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.294, 10.098], loss: 0.001501, mae: 0.042168, mean_q: 1.175382
 909866/1000000: episode: 9099, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.708, mean reward: 0.577 [0.503, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.398, 10.173], loss: 0.001436, mae: 0.041985, mean_q: 1.176492
 909966/1000000: episode: 9100, duration: 0.614s, episode steps: 100, steps per second: 163, episode reward: 58.337, mean reward: 0.583 [0.515, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.255, 10.177], loss: 0.001475, mae: 0.041735, mean_q: 1.176737
 910066/1000000: episode: 9101, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.986, mean reward: 0.610 [0.498, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.186, 10.098], loss: 0.001516, mae: 0.042698, mean_q: 1.176170
 910166/1000000: episode: 9102, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.305, mean reward: 0.593 [0.513, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.588, 10.266], loss: 0.001467, mae: 0.041862, mean_q: 1.175190
 910266/1000000: episode: 9103, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.538, mean reward: 0.585 [0.502, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.529, 10.098], loss: 0.001425, mae: 0.041247, mean_q: 1.174511
 910366/1000000: episode: 9104, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 59.586, mean reward: 0.596 [0.518, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.952, 10.185], loss: 0.001433, mae: 0.041170, mean_q: 1.171803
 910466/1000000: episode: 9105, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.865, mean reward: 0.589 [0.503, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.371, 10.182], loss: 0.001488, mae: 0.042199, mean_q: 1.173818
 910566/1000000: episode: 9106, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.014, mean reward: 0.580 [0.510, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.978, 10.145], loss: 0.001479, mae: 0.041662, mean_q: 1.173470
 910666/1000000: episode: 9107, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 56.955, mean reward: 0.570 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.623, 10.098], loss: 0.001501, mae: 0.041909, mean_q: 1.170791
 910766/1000000: episode: 9108, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.387, mean reward: 0.594 [0.505, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.608, 10.098], loss: 0.001463, mae: 0.041406, mean_q: 1.174009
 910866/1000000: episode: 9109, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.160, mean reward: 0.602 [0.507, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.742, 10.165], loss: 0.001528, mae: 0.042703, mean_q: 1.173218
 910966/1000000: episode: 9110, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.010, mean reward: 0.590 [0.501, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-2.224, 10.098], loss: 0.001390, mae: 0.040572, mean_q: 1.171609
 911066/1000000: episode: 9111, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.667, mean reward: 0.597 [0.508, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.695, 10.098], loss: 0.001415, mae: 0.041176, mean_q: 1.173002
 911166/1000000: episode: 9112, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 56.641, mean reward: 0.566 [0.502, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.541, 10.216], loss: 0.001480, mae: 0.042508, mean_q: 1.170695
 911266/1000000: episode: 9113, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.064, mean reward: 0.591 [0.499, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.747, 10.300], loss: 0.001503, mae: 0.042501, mean_q: 1.172209
 911366/1000000: episode: 9114, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 56.939, mean reward: 0.569 [0.511, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.399, 10.098], loss: 0.001396, mae: 0.041639, mean_q: 1.171526
 911466/1000000: episode: 9115, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.051, mean reward: 0.591 [0.502, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.283, 10.359], loss: 0.001490, mae: 0.042093, mean_q: 1.172928
 911566/1000000: episode: 9116, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 56.206, mean reward: 0.562 [0.503, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.358, 10.194], loss: 0.001437, mae: 0.041555, mean_q: 1.172470
 911666/1000000: episode: 9117, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 61.227, mean reward: 0.612 [0.511, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-0.852, 10.098], loss: 0.001333, mae: 0.039776, mean_q: 1.172871
 911766/1000000: episode: 9118, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.592, mean reward: 0.586 [0.500, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.048, 10.142], loss: 0.001356, mae: 0.040125, mean_q: 1.166384
 911866/1000000: episode: 9119, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.044, mean reward: 0.580 [0.510, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.908, 10.165], loss: 0.001384, mae: 0.041150, mean_q: 1.173395
 911966/1000000: episode: 9120, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.515, mean reward: 0.595 [0.506, 0.785], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.513, 10.228], loss: 0.001462, mae: 0.041152, mean_q: 1.170127
 912066/1000000: episode: 9121, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 59.514, mean reward: 0.595 [0.515, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.607, 10.186], loss: 0.001371, mae: 0.040737, mean_q: 1.171923
 912166/1000000: episode: 9122, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.653, mean reward: 0.587 [0.503, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.531, 10.220], loss: 0.001282, mae: 0.039152, mean_q: 1.169307
 912266/1000000: episode: 9123, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.548, mean reward: 0.595 [0.504, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.186, 10.098], loss: 0.001387, mae: 0.040453, mean_q: 1.171134
 912366/1000000: episode: 9124, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.105, mean reward: 0.591 [0.504, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.371, 10.098], loss: 0.001352, mae: 0.040308, mean_q: 1.173003
 912466/1000000: episode: 9125, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.731, mean reward: 0.577 [0.500, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.536, 10.214], loss: 0.001489, mae: 0.042047, mean_q: 1.173455
 912566/1000000: episode: 9126, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 57.865, mean reward: 0.579 [0.507, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.473, 10.098], loss: 0.001411, mae: 0.041174, mean_q: 1.170635
 912666/1000000: episode: 9127, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.809, mean reward: 0.588 [0.515, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.219, 10.160], loss: 0.001421, mae: 0.041471, mean_q: 1.171365
 912766/1000000: episode: 9128, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.693, mean reward: 0.587 [0.507, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.104, 10.099], loss: 0.001404, mae: 0.041465, mean_q: 1.175422
 912866/1000000: episode: 9129, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.837, mean reward: 0.598 [0.498, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.118, 10.098], loss: 0.001487, mae: 0.042290, mean_q: 1.175219
 912966/1000000: episode: 9130, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.950, mean reward: 0.580 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.303, 10.098], loss: 0.001398, mae: 0.041280, mean_q: 1.175004
 913066/1000000: episode: 9131, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 64.739, mean reward: 0.647 [0.529, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.684, 10.098], loss: 0.001359, mae: 0.040374, mean_q: 1.170538
 913166/1000000: episode: 9132, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.792, mean reward: 0.578 [0.504, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.410, 10.162], loss: 0.001311, mae: 0.039967, mean_q: 1.170709
 913266/1000000: episode: 9133, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.107, mean reward: 0.571 [0.509, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.747, 10.098], loss: 0.001323, mae: 0.040357, mean_q: 1.170712
 913366/1000000: episode: 9134, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.713, mean reward: 0.577 [0.501, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.714, 10.183], loss: 0.001419, mae: 0.041244, mean_q: 1.169082
 913466/1000000: episode: 9135, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 58.386, mean reward: 0.584 [0.511, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.604, 10.098], loss: 0.001368, mae: 0.040341, mean_q: 1.170723
 913566/1000000: episode: 9136, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 61.798, mean reward: 0.618 [0.503, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.692, 10.098], loss: 0.001345, mae: 0.040401, mean_q: 1.168370
 913666/1000000: episode: 9137, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.397, mean reward: 0.594 [0.500, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.731, 10.098], loss: 0.001395, mae: 0.040956, mean_q: 1.168272
 913766/1000000: episode: 9138, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 59.384, mean reward: 0.594 [0.504, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.389, 10.232], loss: 0.001325, mae: 0.039999, mean_q: 1.171177
 913866/1000000: episode: 9139, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 63.723, mean reward: 0.637 [0.506, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.369, 10.387], loss: 0.001334, mae: 0.039815, mean_q: 1.170167
 913966/1000000: episode: 9140, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.904, mean reward: 0.609 [0.520, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.670, 10.226], loss: 0.001438, mae: 0.041781, mean_q: 1.174164
 914066/1000000: episode: 9141, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.418, mean reward: 0.584 [0.507, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.162, 10.098], loss: 0.001337, mae: 0.040731, mean_q: 1.169868
 914166/1000000: episode: 9142, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.348, mean reward: 0.573 [0.499, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.924, 10.222], loss: 0.001354, mae: 0.040719, mean_q: 1.167825
 914266/1000000: episode: 9143, duration: 0.522s, episode steps: 100, steps per second: 192, episode reward: 57.984, mean reward: 0.580 [0.499, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.468, 10.098], loss: 0.001366, mae: 0.040328, mean_q: 1.168187
 914366/1000000: episode: 9144, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.364, mean reward: 0.594 [0.503, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.957, 10.130], loss: 0.001333, mae: 0.040503, mean_q: 1.168950
 914466/1000000: episode: 9145, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.678, mean reward: 0.587 [0.500, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.341, 10.192], loss: 0.001347, mae: 0.040471, mean_q: 1.166829
 914566/1000000: episode: 9146, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.351, mean reward: 0.584 [0.506, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.265, 10.098], loss: 0.001418, mae: 0.041293, mean_q: 1.166688
 914666/1000000: episode: 9147, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.851, mean reward: 0.579 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.658, 10.098], loss: 0.001571, mae: 0.043506, mean_q: 1.166898
 914766/1000000: episode: 9148, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.331, mean reward: 0.613 [0.503, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.915, 10.098], loss: 0.001393, mae: 0.040621, mean_q: 1.167200
 914866/1000000: episode: 9149, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.577, mean reward: 0.596 [0.500, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.874, 10.178], loss: 0.001420, mae: 0.041459, mean_q: 1.168279
 914966/1000000: episode: 9150, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.887, mean reward: 0.589 [0.516, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.706, 10.098], loss: 0.001396, mae: 0.041339, mean_q: 1.169607
 915066/1000000: episode: 9151, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.434, mean reward: 0.574 [0.509, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.187, 10.098], loss: 0.001402, mae: 0.041240, mean_q: 1.168886
 915166/1000000: episode: 9152, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.308, mean reward: 0.573 [0.499, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.678, 10.098], loss: 0.001412, mae: 0.041157, mean_q: 1.168363
 915266/1000000: episode: 9153, duration: 0.580s, episode steps: 100, steps per second: 173, episode reward: 62.449, mean reward: 0.624 [0.512, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.733, 10.110], loss: 0.001339, mae: 0.040203, mean_q: 1.167435
 915366/1000000: episode: 9154, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.174, mean reward: 0.582 [0.506, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.131, 10.098], loss: 0.001232, mae: 0.038621, mean_q: 1.163598
 915466/1000000: episode: 9155, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.572, mean reward: 0.586 [0.507, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.083, 10.098], loss: 0.001424, mae: 0.041180, mean_q: 1.166912
 915566/1000000: episode: 9156, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 61.173, mean reward: 0.612 [0.510, 0.852], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.626, 10.098], loss: 0.001331, mae: 0.040095, mean_q: 1.169908
 915666/1000000: episode: 9157, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 62.451, mean reward: 0.625 [0.508, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.676, 10.450], loss: 0.001313, mae: 0.039905, mean_q: 1.168049
 915766/1000000: episode: 9158, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.431, mean reward: 0.594 [0.502, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.594, 10.098], loss: 0.001376, mae: 0.040196, mean_q: 1.170411
 915866/1000000: episode: 9159, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.478, mean reward: 0.595 [0.508, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.368, 10.255], loss: 0.001339, mae: 0.039357, mean_q: 1.168364
 915966/1000000: episode: 9160, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 60.555, mean reward: 0.606 [0.505, 0.872], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.244, 10.098], loss: 0.001362, mae: 0.039756, mean_q: 1.168371
 916066/1000000: episode: 9161, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.049, mean reward: 0.580 [0.508, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.739, 10.098], loss: 0.001485, mae: 0.042207, mean_q: 1.171510
 916166/1000000: episode: 9162, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.582, mean reward: 0.586 [0.504, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.669, 10.098], loss: 0.001549, mae: 0.042772, mean_q: 1.171047
 916266/1000000: episode: 9163, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.638, mean reward: 0.576 [0.508, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.727, 10.113], loss: 0.001372, mae: 0.040475, mean_q: 1.172143
 916366/1000000: episode: 9164, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.477, mean reward: 0.605 [0.524, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.725, 10.279], loss: 0.001404, mae: 0.041099, mean_q: 1.168456
 916466/1000000: episode: 9165, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 58.670, mean reward: 0.587 [0.510, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.784, 10.179], loss: 0.001441, mae: 0.041323, mean_q: 1.174239
 916566/1000000: episode: 9166, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.847, mean reward: 0.588 [0.500, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.773, 10.228], loss: 0.001446, mae: 0.041405, mean_q: 1.171597
 916666/1000000: episode: 9167, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 61.837, mean reward: 0.618 [0.505, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.395, 10.098], loss: 0.001400, mae: 0.041275, mean_q: 1.169398
 916766/1000000: episode: 9168, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 58.703, mean reward: 0.587 [0.519, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.596, 10.187], loss: 0.001464, mae: 0.042082, mean_q: 1.175182
 916866/1000000: episode: 9169, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 61.123, mean reward: 0.611 [0.510, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.511, 10.444], loss: 0.001453, mae: 0.041274, mean_q: 1.173902
 916966/1000000: episode: 9170, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 56.597, mean reward: 0.566 [0.503, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.344, 10.098], loss: 0.001451, mae: 0.041290, mean_q: 1.171952
 917066/1000000: episode: 9171, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 62.872, mean reward: 0.629 [0.508, 0.882], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.904, 10.205], loss: 0.001517, mae: 0.042825, mean_q: 1.177738
 917166/1000000: episode: 9172, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 56.802, mean reward: 0.568 [0.505, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.834, 10.098], loss: 0.001360, mae: 0.040654, mean_q: 1.172061
 917266/1000000: episode: 9173, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.075, mean reward: 0.591 [0.504, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.510, 10.210], loss: 0.001456, mae: 0.041363, mean_q: 1.171530
 917366/1000000: episode: 9174, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.015, mean reward: 0.590 [0.509, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.567, 10.098], loss: 0.001522, mae: 0.042342, mean_q: 1.176557
 917466/1000000: episode: 9175, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.342, mean reward: 0.583 [0.504, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.467, 10.098], loss: 0.001595, mae: 0.042931, mean_q: 1.174070
 917566/1000000: episode: 9176, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.830, mean reward: 0.598 [0.504, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.391, 10.266], loss: 0.001516, mae: 0.042339, mean_q: 1.175773
 917666/1000000: episode: 9177, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.721, mean reward: 0.577 [0.503, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.994, 10.098], loss: 0.001492, mae: 0.041443, mean_q: 1.176969
 917766/1000000: episode: 9178, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 59.802, mean reward: 0.598 [0.502, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.560, 10.098], loss: 0.001441, mae: 0.041227, mean_q: 1.176980
 917866/1000000: episode: 9179, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.166, mean reward: 0.572 [0.502, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.138, 10.110], loss: 0.001406, mae: 0.040649, mean_q: 1.175104
 917966/1000000: episode: 9180, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 60.072, mean reward: 0.601 [0.502, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.833, 10.098], loss: 0.001503, mae: 0.041444, mean_q: 1.172014
 918066/1000000: episode: 9181, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 61.874, mean reward: 0.619 [0.503, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.488, 10.098], loss: 0.001478, mae: 0.040809, mean_q: 1.170691
 918166/1000000: episode: 9182, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.989, mean reward: 0.590 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.086, 10.200], loss: 0.001438, mae: 0.041255, mean_q: 1.178762
 918266/1000000: episode: 9183, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.115, mean reward: 0.581 [0.499, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.462, 10.098], loss: 0.001500, mae: 0.041470, mean_q: 1.176860
 918366/1000000: episode: 9184, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 56.911, mean reward: 0.569 [0.505, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.844, 10.098], loss: 0.001471, mae: 0.041667, mean_q: 1.173698
 918466/1000000: episode: 9185, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 57.531, mean reward: 0.575 [0.508, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.006, 10.113], loss: 0.001508, mae: 0.042010, mean_q: 1.173413
 918566/1000000: episode: 9186, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 61.375, mean reward: 0.614 [0.512, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.671, 10.422], loss: 0.001500, mae: 0.041476, mean_q: 1.169675
 918666/1000000: episode: 9187, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 63.045, mean reward: 0.630 [0.502, 0.841], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.504, 10.397], loss: 0.001426, mae: 0.040731, mean_q: 1.171523
 918766/1000000: episode: 9188, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.260, mean reward: 0.583 [0.509, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.661, 10.098], loss: 0.001453, mae: 0.041349, mean_q: 1.171049
 918866/1000000: episode: 9189, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.347, mean reward: 0.573 [0.499, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.827, 10.098], loss: 0.001461, mae: 0.041442, mean_q: 1.174356
 918966/1000000: episode: 9190, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 60.635, mean reward: 0.606 [0.503, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.006, 10.098], loss: 0.001460, mae: 0.041252, mean_q: 1.172297
 919066/1000000: episode: 9191, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.180, mean reward: 0.592 [0.508, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.007, 10.098], loss: 0.001465, mae: 0.041323, mean_q: 1.172173
 919166/1000000: episode: 9192, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.330, mean reward: 0.573 [0.503, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.539, 10.185], loss: 0.001496, mae: 0.041922, mean_q: 1.171615
 919266/1000000: episode: 9193, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.439, mean reward: 0.574 [0.505, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.752, 10.170], loss: 0.001558, mae: 0.042151, mean_q: 1.173589
 919366/1000000: episode: 9194, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.715, mean reward: 0.597 [0.505, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.669, 10.158], loss: 0.001424, mae: 0.040391, mean_q: 1.171728
 919466/1000000: episode: 9195, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.382, mean reward: 0.594 [0.500, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.269, 10.098], loss: 0.001497, mae: 0.042075, mean_q: 1.177280
 919566/1000000: episode: 9196, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.528, mean reward: 0.595 [0.508, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.147, 10.314], loss: 0.001493, mae: 0.041309, mean_q: 1.171774
 919666/1000000: episode: 9197, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 65.672, mean reward: 0.657 [0.525, 0.898], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.740, 10.465], loss: 0.001549, mae: 0.042779, mean_q: 1.176270
 919766/1000000: episode: 9198, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.446, mean reward: 0.584 [0.501, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.931, 10.228], loss: 0.001483, mae: 0.041538, mean_q: 1.176857
 919866/1000000: episode: 9199, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 62.203, mean reward: 0.622 [0.505, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.313, 10.098], loss: 0.001505, mae: 0.041884, mean_q: 1.174334
 919966/1000000: episode: 9200, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.713, mean reward: 0.597 [0.508, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.417, 10.098], loss: 0.001449, mae: 0.040857, mean_q: 1.173541
 920066/1000000: episode: 9201, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.490, mean reward: 0.595 [0.505, 0.872], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.982, 10.098], loss: 0.001452, mae: 0.041231, mean_q: 1.176283
 920166/1000000: episode: 9202, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.808, mean reward: 0.568 [0.509, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.254, 10.098], loss: 0.001505, mae: 0.041577, mean_q: 1.178527
 920266/1000000: episode: 9203, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.631, mean reward: 0.596 [0.510, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.270, 10.140], loss: 0.001439, mae: 0.040994, mean_q: 1.176659
 920366/1000000: episode: 9204, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 60.215, mean reward: 0.602 [0.501, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.796, 10.098], loss: 0.001455, mae: 0.040803, mean_q: 1.174281
 920466/1000000: episode: 9205, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.086, mean reward: 0.581 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.811, 10.098], loss: 0.001623, mae: 0.042924, mean_q: 1.175702
 920566/1000000: episode: 9206, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 57.848, mean reward: 0.578 [0.512, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.056, 10.177], loss: 0.001432, mae: 0.041181, mean_q: 1.176762
 920666/1000000: episode: 9207, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.394, mean reward: 0.584 [0.500, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.758, 10.098], loss: 0.001626, mae: 0.042952, mean_q: 1.174946
 920766/1000000: episode: 9208, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 56.766, mean reward: 0.568 [0.505, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.987, 10.098], loss: 0.001421, mae: 0.040824, mean_q: 1.171323
 920866/1000000: episode: 9209, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.446, mean reward: 0.594 [0.520, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.841, 10.258], loss: 0.001572, mae: 0.042356, mean_q: 1.176167
 920966/1000000: episode: 9210, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 58.879, mean reward: 0.589 [0.505, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.685, 10.223], loss: 0.001515, mae: 0.041879, mean_q: 1.172192
 921066/1000000: episode: 9211, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.411, mean reward: 0.594 [0.506, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.575, 10.098], loss: 0.001427, mae: 0.041023, mean_q: 1.170831
 921166/1000000: episode: 9212, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.906, mean reward: 0.589 [0.504, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.397, 10.107], loss: 0.001510, mae: 0.042190, mean_q: 1.173254
 921266/1000000: episode: 9213, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 62.756, mean reward: 0.628 [0.504, 0.869], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.231, 10.282], loss: 0.001549, mae: 0.042565, mean_q: 1.175377
 921366/1000000: episode: 9214, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.026, mean reward: 0.600 [0.502, 0.889], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.432, 10.130], loss: 0.001483, mae: 0.041751, mean_q: 1.176522
 921466/1000000: episode: 9215, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.985, mean reward: 0.600 [0.510, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.183, 10.098], loss: 0.001511, mae: 0.042362, mean_q: 1.175120
 921566/1000000: episode: 9216, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.520, mean reward: 0.585 [0.506, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.639, 10.257], loss: 0.001511, mae: 0.042496, mean_q: 1.176397
 921666/1000000: episode: 9217, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.060, mean reward: 0.601 [0.504, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.972, 10.098], loss: 0.001432, mae: 0.040780, mean_q: 1.176141
 921766/1000000: episode: 9218, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 57.466, mean reward: 0.575 [0.500, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.309, 10.131], loss: 0.001445, mae: 0.041181, mean_q: 1.174743
 921866/1000000: episode: 9219, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.317, mean reward: 0.573 [0.499, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.003, 10.252], loss: 0.001474, mae: 0.041900, mean_q: 1.171074
 921966/1000000: episode: 9220, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.234, mean reward: 0.592 [0.510, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.919, 10.345], loss: 0.001394, mae: 0.041104, mean_q: 1.169303
 922066/1000000: episode: 9221, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 57.467, mean reward: 0.575 [0.501, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.495, 10.313], loss: 0.001490, mae: 0.041712, mean_q: 1.167642
 922166/1000000: episode: 9222, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.176, mean reward: 0.602 [0.505, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.875, 10.301], loss: 0.001426, mae: 0.041410, mean_q: 1.171770
 922266/1000000: episode: 9223, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.656, mean reward: 0.607 [0.514, 0.849], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.390, 10.252], loss: 0.001417, mae: 0.040810, mean_q: 1.172737
 922366/1000000: episode: 9224, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.011, mean reward: 0.580 [0.499, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.906, 10.286], loss: 0.001427, mae: 0.041055, mean_q: 1.172615
 922466/1000000: episode: 9225, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.449, mean reward: 0.574 [0.504, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.482, 10.098], loss: 0.001479, mae: 0.041427, mean_q: 1.171916
 922566/1000000: episode: 9226, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.403, mean reward: 0.584 [0.506, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.921, 10.098], loss: 0.001507, mae: 0.042251, mean_q: 1.168048
 922666/1000000: episode: 9227, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.654, mean reward: 0.577 [0.509, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.168, 10.098], loss: 0.001510, mae: 0.042008, mean_q: 1.172050
 922766/1000000: episode: 9228, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 62.805, mean reward: 0.628 [0.513, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.733, 10.098], loss: 0.001444, mae: 0.041062, mean_q: 1.169923
 922866/1000000: episode: 9229, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.547, mean reward: 0.585 [0.511, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.022, 10.424], loss: 0.001437, mae: 0.041146, mean_q: 1.174497
 922966/1000000: episode: 9230, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 59.003, mean reward: 0.590 [0.498, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.733, 10.104], loss: 0.001561, mae: 0.043018, mean_q: 1.174918
 923066/1000000: episode: 9231, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.522, mean reward: 0.585 [0.500, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.768, 10.244], loss: 0.001506, mae: 0.042240, mean_q: 1.173171
 923166/1000000: episode: 9232, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 58.628, mean reward: 0.586 [0.502, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.632, 10.098], loss: 0.001450, mae: 0.040901, mean_q: 1.168566
 923266/1000000: episode: 9233, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 65.247, mean reward: 0.652 [0.513, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.415, 10.574], loss: 0.001423, mae: 0.040311, mean_q: 1.171812
 923366/1000000: episode: 9234, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.827, mean reward: 0.588 [0.509, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.806, 10.098], loss: 0.001427, mae: 0.040683, mean_q: 1.175388
 923466/1000000: episode: 9235, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.642, mean reward: 0.576 [0.513, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.095, 10.194], loss: 0.001368, mae: 0.040448, mean_q: 1.176761
 923566/1000000: episode: 9236, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.445, mean reward: 0.584 [0.498, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.312, 10.198], loss: 0.001480, mae: 0.041906, mean_q: 1.173227
 923666/1000000: episode: 9237, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.682, mean reward: 0.587 [0.498, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.479, 10.098], loss: 0.001382, mae: 0.040768, mean_q: 1.172978
 923766/1000000: episode: 9238, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.129, mean reward: 0.581 [0.502, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-1.132, 10.098], loss: 0.001451, mae: 0.040905, mean_q: 1.166689
 923866/1000000: episode: 9239, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.795, mean reward: 0.578 [0.500, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.497, 10.150], loss: 0.001466, mae: 0.041709, mean_q: 1.174870
 923966/1000000: episode: 9240, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.904, mean reward: 0.599 [0.521, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.401, 10.098], loss: 0.001477, mae: 0.041604, mean_q: 1.172812
 924066/1000000: episode: 9241, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.333, mean reward: 0.573 [0.510, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.958, 10.098], loss: 0.001422, mae: 0.040936, mean_q: 1.172764
 924166/1000000: episode: 9242, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.918, mean reward: 0.589 [0.502, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.812, 10.102], loss: 0.001371, mae: 0.040186, mean_q: 1.171527
 924266/1000000: episode: 9243, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.059, mean reward: 0.601 [0.498, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.693, 10.098], loss: 0.001435, mae: 0.041263, mean_q: 1.171738
 924366/1000000: episode: 9244, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.076, mean reward: 0.581 [0.504, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.692, 10.191], loss: 0.001511, mae: 0.041920, mean_q: 1.171134
 924466/1000000: episode: 9245, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.135, mean reward: 0.571 [0.501, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.406, 10.098], loss: 0.001485, mae: 0.041727, mean_q: 1.171602
 924566/1000000: episode: 9246, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.164, mean reward: 0.592 [0.504, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.311, 10.098], loss: 0.001520, mae: 0.041907, mean_q: 1.169532
 924666/1000000: episode: 9247, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.545, mean reward: 0.585 [0.511, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.159, 10.200], loss: 0.001518, mae: 0.042092, mean_q: 1.169186
 924766/1000000: episode: 9248, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 63.882, mean reward: 0.639 [0.530, 0.855], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.933, 10.423], loss: 0.001486, mae: 0.041754, mean_q: 1.168274
 924866/1000000: episode: 9249, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 60.640, mean reward: 0.606 [0.507, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.770, 10.098], loss: 0.001445, mae: 0.041505, mean_q: 1.170179
 924966/1000000: episode: 9250, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.885, mean reward: 0.579 [0.503, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.789, 10.098], loss: 0.001525, mae: 0.042862, mean_q: 1.169994
 925066/1000000: episode: 9251, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 60.365, mean reward: 0.604 [0.502, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.220, 10.134], loss: 0.001468, mae: 0.042355, mean_q: 1.172447
 925166/1000000: episode: 9252, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 60.252, mean reward: 0.603 [0.512, 0.721], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.043, 10.098], loss: 0.001478, mae: 0.042273, mean_q: 1.168624
 925266/1000000: episode: 9253, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.287, mean reward: 0.583 [0.503, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.398, 10.158], loss: 0.001404, mae: 0.040506, mean_q: 1.167355
 925366/1000000: episode: 9254, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.152, mean reward: 0.582 [0.511, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.872, 10.098], loss: 0.001461, mae: 0.041691, mean_q: 1.169082
 925466/1000000: episode: 9255, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.395, mean reward: 0.574 [0.501, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.383, 10.098], loss: 0.001509, mae: 0.042286, mean_q: 1.169823
 925566/1000000: episode: 9256, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.390, mean reward: 0.594 [0.509, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.378, 10.238], loss: 0.001519, mae: 0.042417, mean_q: 1.169063
 925666/1000000: episode: 9257, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.830, mean reward: 0.618 [0.508, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-1.097, 10.098], loss: 0.001546, mae: 0.042592, mean_q: 1.171769
 925766/1000000: episode: 9258, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.761, mean reward: 0.588 [0.500, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.496, 10.253], loss: 0.001424, mae: 0.040888, mean_q: 1.174139
 925866/1000000: episode: 9259, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.264, mean reward: 0.593 [0.508, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.966, 10.100], loss: 0.001476, mae: 0.042256, mean_q: 1.173986
 925966/1000000: episode: 9260, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.573, mean reward: 0.566 [0.503, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.407, 10.148], loss: 0.001474, mae: 0.041495, mean_q: 1.168288
 926066/1000000: episode: 9261, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 60.942, mean reward: 0.609 [0.500, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.590, 10.164], loss: 0.001494, mae: 0.041991, mean_q: 1.168983
 926166/1000000: episode: 9262, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 56.735, mean reward: 0.567 [0.500, 0.663], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.130, 10.113], loss: 0.001530, mae: 0.042950, mean_q: 1.171594
 926266/1000000: episode: 9263, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.925, mean reward: 0.589 [0.515, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.276, 10.333], loss: 0.001522, mae: 0.042427, mean_q: 1.172970
 926366/1000000: episode: 9264, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.984, mean reward: 0.580 [0.514, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.845, 10.098], loss: 0.001534, mae: 0.043113, mean_q: 1.173138
 926466/1000000: episode: 9265, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.750, mean reward: 0.588 [0.516, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.934, 10.151], loss: 0.001390, mae: 0.041198, mean_q: 1.170607
 926566/1000000: episode: 9266, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 61.294, mean reward: 0.613 [0.504, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.555, 10.098], loss: 0.001354, mae: 0.040210, mean_q: 1.167170
 926666/1000000: episode: 9267, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 59.743, mean reward: 0.597 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.981, 10.358], loss: 0.001493, mae: 0.042356, mean_q: 1.168386
 926766/1000000: episode: 9268, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 61.756, mean reward: 0.618 [0.504, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.444, 10.264], loss: 0.001457, mae: 0.041550, mean_q: 1.168532
 926866/1000000: episode: 9269, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.088, mean reward: 0.581 [0.503, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.607, 10.187], loss: 0.001418, mae: 0.041571, mean_q: 1.172268
 926966/1000000: episode: 9270, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.701, mean reward: 0.587 [0.503, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.116, 10.098], loss: 0.001331, mae: 0.040181, mean_q: 1.169804
 927066/1000000: episode: 9271, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.711, mean reward: 0.587 [0.502, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.452, 10.156], loss: 0.001361, mae: 0.040365, mean_q: 1.166614
 927166/1000000: episode: 9272, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.439, mean reward: 0.574 [0.504, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.299, 10.204], loss: 0.001391, mae: 0.041243, mean_q: 1.168968
 927266/1000000: episode: 9273, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 60.268, mean reward: 0.603 [0.507, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.425, 10.295], loss: 0.001399, mae: 0.040852, mean_q: 1.164866
 927366/1000000: episode: 9274, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.923, mean reward: 0.599 [0.512, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.442, 10.324], loss: 0.001401, mae: 0.040830, mean_q: 1.167210
 927466/1000000: episode: 9275, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.373, mean reward: 0.584 [0.501, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.682, 10.146], loss: 0.001418, mae: 0.040369, mean_q: 1.168629
 927566/1000000: episode: 9276, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 63.808, mean reward: 0.638 [0.533, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.323, 10.098], loss: 0.001440, mae: 0.041716, mean_q: 1.171762
 927666/1000000: episode: 9277, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.127, mean reward: 0.581 [0.504, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.114, 10.098], loss: 0.001434, mae: 0.041321, mean_q: 1.167308
 927766/1000000: episode: 9278, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 59.604, mean reward: 0.596 [0.506, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.602, 10.472], loss: 0.001412, mae: 0.041122, mean_q: 1.170833
 927866/1000000: episode: 9279, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.813, mean reward: 0.578 [0.498, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.900, 10.098], loss: 0.001432, mae: 0.041073, mean_q: 1.169525
 927966/1000000: episode: 9280, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 58.382, mean reward: 0.584 [0.506, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.063, 10.098], loss: 0.001505, mae: 0.042189, mean_q: 1.174805
 928066/1000000: episode: 9281, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 60.082, mean reward: 0.601 [0.506, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.610, 10.209], loss: 0.001441, mae: 0.041211, mean_q: 1.172275
 928166/1000000: episode: 9282, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.318, mean reward: 0.603 [0.514, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.444, 10.098], loss: 0.001401, mae: 0.040696, mean_q: 1.174653
 928266/1000000: episode: 9283, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 58.513, mean reward: 0.585 [0.503, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.844, 10.172], loss: 0.001465, mae: 0.041890, mean_q: 1.171236
 928366/1000000: episode: 9284, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.497, mean reward: 0.575 [0.505, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.963, 10.098], loss: 0.001423, mae: 0.040822, mean_q: 1.169658
 928466/1000000: episode: 9285, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.302, mean reward: 0.593 [0.499, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.192, 10.376], loss: 0.001493, mae: 0.042142, mean_q: 1.169779
 928566/1000000: episode: 9286, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 56.834, mean reward: 0.568 [0.501, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.274, 10.098], loss: 0.001488, mae: 0.041639, mean_q: 1.168312
 928666/1000000: episode: 9287, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.861, mean reward: 0.589 [0.505, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.717, 10.110], loss: 0.001506, mae: 0.042354, mean_q: 1.169562
 928766/1000000: episode: 9288, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.092, mean reward: 0.591 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.788, 10.203], loss: 0.001447, mae: 0.041321, mean_q: 1.169105
 928866/1000000: episode: 9289, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.383, mean reward: 0.584 [0.502, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.711, 10.133], loss: 0.001496, mae: 0.041786, mean_q: 1.170434
 928966/1000000: episode: 9290, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 58.322, mean reward: 0.583 [0.508, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.419, 10.116], loss: 0.001436, mae: 0.040642, mean_q: 1.170129
 929066/1000000: episode: 9291, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.111, mean reward: 0.591 [0.513, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.254, 10.098], loss: 0.001496, mae: 0.041831, mean_q: 1.170730
 929166/1000000: episode: 9292, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.665, mean reward: 0.587 [0.511, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.215, 10.237], loss: 0.001472, mae: 0.041494, mean_q: 1.169586
 929266/1000000: episode: 9293, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.436, mean reward: 0.594 [0.504, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.406, 10.098], loss: 0.001494, mae: 0.041972, mean_q: 1.169180
 929366/1000000: episode: 9294, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.958, mean reward: 0.590 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.571, 10.098], loss: 0.001451, mae: 0.041608, mean_q: 1.168376
 929466/1000000: episode: 9295, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 57.427, mean reward: 0.574 [0.504, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.443, 10.151], loss: 0.001413, mae: 0.041149, mean_q: 1.172891
 929566/1000000: episode: 9296, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 56.744, mean reward: 0.567 [0.505, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.954, 10.098], loss: 0.001403, mae: 0.040629, mean_q: 1.169781
 929666/1000000: episode: 9297, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 59.338, mean reward: 0.593 [0.510, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.440, 10.098], loss: 0.001480, mae: 0.041881, mean_q: 1.168271
 929766/1000000: episode: 9298, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 58.318, mean reward: 0.583 [0.507, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.562, 10.110], loss: 0.001464, mae: 0.042157, mean_q: 1.166650
 929866/1000000: episode: 9299, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.422, mean reward: 0.584 [0.502, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.297, 10.186], loss: 0.001479, mae: 0.041931, mean_q: 1.166858
 929966/1000000: episode: 9300, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.212, mean reward: 0.592 [0.510, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.700, 10.098], loss: 0.001442, mae: 0.041583, mean_q: 1.165261
 930066/1000000: episode: 9301, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 56.710, mean reward: 0.567 [0.503, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.933, 10.172], loss: 0.001484, mae: 0.041679, mean_q: 1.167092
 930166/1000000: episode: 9302, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.097, mean reward: 0.601 [0.507, 0.933], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.649, 10.148], loss: 0.001475, mae: 0.041291, mean_q: 1.163323
 930266/1000000: episode: 9303, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 62.372, mean reward: 0.624 [0.507, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.806, 10.098], loss: 0.001458, mae: 0.041008, mean_q: 1.165791
 930366/1000000: episode: 9304, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.986, mean reward: 0.590 [0.503, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.536, 10.353], loss: 0.001520, mae: 0.042280, mean_q: 1.167801
 930466/1000000: episode: 9305, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.522, mean reward: 0.575 [0.508, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.315, 10.185], loss: 0.001528, mae: 0.042956, mean_q: 1.168345
 930566/1000000: episode: 9306, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.872, mean reward: 0.589 [0.504, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.246, 10.098], loss: 0.001608, mae: 0.042952, mean_q: 1.166678
 930666/1000000: episode: 9307, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.364, mean reward: 0.594 [0.512, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.763, 10.098], loss: 0.001496, mae: 0.041886, mean_q: 1.168935
 930766/1000000: episode: 9308, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.827, mean reward: 0.608 [0.514, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.244, 10.098], loss: 0.001372, mae: 0.039894, mean_q: 1.165027
 930866/1000000: episode: 9309, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.152, mean reward: 0.592 [0.507, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.006, 10.098], loss: 0.001527, mae: 0.041870, mean_q: 1.169343
 930966/1000000: episode: 9310, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.749, mean reward: 0.607 [0.510, 0.845], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.108, 10.247], loss: 0.001440, mae: 0.041193, mean_q: 1.168591
 931066/1000000: episode: 9311, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.563, mean reward: 0.586 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.918, 10.118], loss: 0.001603, mae: 0.042940, mean_q: 1.167204
 931166/1000000: episode: 9312, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.191, mean reward: 0.572 [0.501, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.576, 10.098], loss: 0.001574, mae: 0.042582, mean_q: 1.168010
 931266/1000000: episode: 9313, duration: 0.604s, episode steps: 100, steps per second: 165, episode reward: 58.199, mean reward: 0.582 [0.501, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.050, 10.098], loss: 0.001438, mae: 0.041265, mean_q: 1.166674
 931366/1000000: episode: 9314, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.332, mean reward: 0.603 [0.510, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.808, 10.098], loss: 0.001495, mae: 0.042179, mean_q: 1.167423
 931466/1000000: episode: 9315, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.941, mean reward: 0.589 [0.501, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.448, 10.098], loss: 0.001496, mae: 0.042099, mean_q: 1.167505
 931566/1000000: episode: 9316, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 56.393, mean reward: 0.564 [0.504, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.047, 10.152], loss: 0.001524, mae: 0.041568, mean_q: 1.168983
 931666/1000000: episode: 9317, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.572, mean reward: 0.586 [0.501, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.292, 10.281], loss: 0.001470, mae: 0.041464, mean_q: 1.165399
 931766/1000000: episode: 9318, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.535, mean reward: 0.595 [0.512, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.790, 10.390], loss: 0.001575, mae: 0.042465, mean_q: 1.166480
 931866/1000000: episode: 9319, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 62.475, mean reward: 0.625 [0.511, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.603, 10.261], loss: 0.001477, mae: 0.041353, mean_q: 1.165044
 931966/1000000: episode: 9320, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.517, mean reward: 0.575 [0.502, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.256, 10.193], loss: 0.001503, mae: 0.042205, mean_q: 1.171306
 932066/1000000: episode: 9321, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 57.612, mean reward: 0.576 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.853, 10.168], loss: 0.001424, mae: 0.041197, mean_q: 1.167017
 932166/1000000: episode: 9322, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.685, mean reward: 0.587 [0.502, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.731, 10.164], loss: 0.001525, mae: 0.041736, mean_q: 1.166633
 932266/1000000: episode: 9323, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 59.485, mean reward: 0.595 [0.501, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.949, 10.098], loss: 0.001430, mae: 0.041184, mean_q: 1.167752
 932366/1000000: episode: 9324, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.605, mean reward: 0.596 [0.507, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.473, 10.098], loss: 0.001452, mae: 0.041323, mean_q: 1.165990
 932466/1000000: episode: 9325, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 57.715, mean reward: 0.577 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.673, 10.168], loss: 0.001528, mae: 0.042538, mean_q: 1.168711
 932566/1000000: episode: 9326, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.777, mean reward: 0.598 [0.517, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.533, 10.167], loss: 0.001384, mae: 0.040526, mean_q: 1.162726
 932666/1000000: episode: 9327, duration: 0.523s, episode steps: 100, steps per second: 191, episode reward: 57.196, mean reward: 0.572 [0.505, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.483, 10.098], loss: 0.001429, mae: 0.040222, mean_q: 1.164302
 932766/1000000: episode: 9328, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.647, mean reward: 0.586 [0.505, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.922, 10.098], loss: 0.001443, mae: 0.041181, mean_q: 1.163268
 932866/1000000: episode: 9329, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 58.665, mean reward: 0.587 [0.500, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.802, 10.098], loss: 0.001459, mae: 0.041065, mean_q: 1.162330
 932966/1000000: episode: 9330, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 61.712, mean reward: 0.617 [0.506, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.703, 10.332], loss: 0.001452, mae: 0.040984, mean_q: 1.165111
 933066/1000000: episode: 9331, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.680, mean reward: 0.587 [0.504, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.303, 10.147], loss: 0.001509, mae: 0.041410, mean_q: 1.163993
 933166/1000000: episode: 9332, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.837, mean reward: 0.588 [0.509, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.386, 10.098], loss: 0.001576, mae: 0.042401, mean_q: 1.166321
 933266/1000000: episode: 9333, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.658, mean reward: 0.567 [0.499, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.989, 10.151], loss: 0.001498, mae: 0.041521, mean_q: 1.164504
 933366/1000000: episode: 9334, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.947, mean reward: 0.579 [0.500, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.000, 10.098], loss: 0.001507, mae: 0.041576, mean_q: 1.162663
 933466/1000000: episode: 9335, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 62.277, mean reward: 0.623 [0.515, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.583, 10.421], loss: 0.001495, mae: 0.041627, mean_q: 1.163405
 933566/1000000: episode: 9336, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.147, mean reward: 0.571 [0.503, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.277, 10.098], loss: 0.001443, mae: 0.041291, mean_q: 1.163741
 933666/1000000: episode: 9337, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.084, mean reward: 0.571 [0.502, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.374, 10.098], loss: 0.001522, mae: 0.042377, mean_q: 1.169107
 933766/1000000: episode: 9338, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 58.215, mean reward: 0.582 [0.504, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.677, 10.098], loss: 0.001414, mae: 0.040704, mean_q: 1.163387
 933866/1000000: episode: 9339, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 59.191, mean reward: 0.592 [0.511, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.250, 10.098], loss: 0.001428, mae: 0.040741, mean_q: 1.162737
 933966/1000000: episode: 9340, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.602, mean reward: 0.586 [0.506, 0.829], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.781, 10.098], loss: 0.001440, mae: 0.040899, mean_q: 1.162549
 934066/1000000: episode: 9341, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.666, mean reward: 0.587 [0.510, 0.864], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.389, 10.111], loss: 0.001511, mae: 0.041754, mean_q: 1.166934
 934166/1000000: episode: 9342, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 57.909, mean reward: 0.579 [0.503, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.918, 10.098], loss: 0.001473, mae: 0.041218, mean_q: 1.164911
 934266/1000000: episode: 9343, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 57.313, mean reward: 0.573 [0.500, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.618, 10.219], loss: 0.001452, mae: 0.040988, mean_q: 1.163772
 934366/1000000: episode: 9344, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.634, mean reward: 0.576 [0.503, 0.674], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.748, 10.098], loss: 0.001519, mae: 0.041380, mean_q: 1.161542
 934466/1000000: episode: 9345, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.571, mean reward: 0.586 [0.505, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.288, 10.165], loss: 0.001422, mae: 0.040585, mean_q: 1.162122
 934566/1000000: episode: 9346, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 60.116, mean reward: 0.601 [0.515, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-1.213, 10.453], loss: 0.001458, mae: 0.041026, mean_q: 1.162613
 934666/1000000: episode: 9347, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.725, mean reward: 0.597 [0.504, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.982, 10.469], loss: 0.001488, mae: 0.041351, mean_q: 1.164573
 934766/1000000: episode: 9348, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 59.176, mean reward: 0.592 [0.503, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.285, 10.098], loss: 0.001561, mae: 0.042495, mean_q: 1.167045
 934866/1000000: episode: 9349, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 57.944, mean reward: 0.579 [0.503, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.841, 10.098], loss: 0.001415, mae: 0.040633, mean_q: 1.165071
 934966/1000000: episode: 9350, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 64.324, mean reward: 0.643 [0.514, 0.864], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.339, 10.098], loss: 0.001482, mae: 0.041487, mean_q: 1.165426
 935066/1000000: episode: 9351, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.400, mean reward: 0.574 [0.500, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.829, 10.098], loss: 0.001451, mae: 0.040865, mean_q: 1.167411
 935166/1000000: episode: 9352, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 57.910, mean reward: 0.579 [0.511, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.605, 10.187], loss: 0.001443, mae: 0.041063, mean_q: 1.166241
 935266/1000000: episode: 9353, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 64.448, mean reward: 0.644 [0.505, 0.836], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.636, 10.298], loss: 0.001417, mae: 0.040427, mean_q: 1.167953
 935366/1000000: episode: 9354, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.710, mean reward: 0.587 [0.505, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.573, 10.098], loss: 0.001482, mae: 0.041480, mean_q: 1.167135
 935466/1000000: episode: 9355, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.477, mean reward: 0.585 [0.501, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.203, 10.268], loss: 0.001384, mae: 0.040290, mean_q: 1.165822
 935566/1000000: episode: 9356, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 61.472, mean reward: 0.615 [0.504, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.566, 10.310], loss: 0.001483, mae: 0.041882, mean_q: 1.168811
 935666/1000000: episode: 9357, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.535, mean reward: 0.585 [0.508, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.949, 10.117], loss: 0.001439, mae: 0.041716, mean_q: 1.168617
 935766/1000000: episode: 9358, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 65.973, mean reward: 0.660 [0.507, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.419, 10.098], loss: 0.001468, mae: 0.041454, mean_q: 1.169422
 935866/1000000: episode: 9359, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 57.577, mean reward: 0.576 [0.506, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.319, 10.098], loss: 0.001464, mae: 0.041537, mean_q: 1.171211
 935966/1000000: episode: 9360, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.276, mean reward: 0.573 [0.505, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.907, 10.098], loss: 0.001468, mae: 0.041391, mean_q: 1.172304
 936066/1000000: episode: 9361, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.148, mean reward: 0.591 [0.509, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.542, 10.370], loss: 0.001422, mae: 0.040665, mean_q: 1.167359
 936166/1000000: episode: 9362, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.982, mean reward: 0.590 [0.506, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.312, 10.098], loss: 0.001602, mae: 0.042779, mean_q: 1.173068
 936266/1000000: episode: 9363, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.110, mean reward: 0.611 [0.518, 0.873], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.091, 10.116], loss: 0.001348, mae: 0.039740, mean_q: 1.170338
 936366/1000000: episode: 9364, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.084, mean reward: 0.601 [0.506, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.535, 10.306], loss: 0.001520, mae: 0.041566, mean_q: 1.167442
 936466/1000000: episode: 9365, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 56.783, mean reward: 0.568 [0.499, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.470, 10.351], loss: 0.001351, mae: 0.040014, mean_q: 1.167655
 936566/1000000: episode: 9366, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 62.857, mean reward: 0.629 [0.501, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.447, 10.098], loss: 0.001473, mae: 0.041302, mean_q: 1.172150
 936666/1000000: episode: 9367, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.253, mean reward: 0.593 [0.504, 0.874], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.522, 10.262], loss: 0.001498, mae: 0.042084, mean_q: 1.172478
 936766/1000000: episode: 9368, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.303, mean reward: 0.573 [0.502, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.476, 10.118], loss: 0.001508, mae: 0.042441, mean_q: 1.171812
 936866/1000000: episode: 9369, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.739, mean reward: 0.587 [0.501, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.040, 10.261], loss: 0.001464, mae: 0.041645, mean_q: 1.170124
 936966/1000000: episode: 9370, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.159, mean reward: 0.582 [0.501, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.783, 10.098], loss: 0.001544, mae: 0.042392, mean_q: 1.172040
 937066/1000000: episode: 9371, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.905, mean reward: 0.579 [0.500, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.607, 10.098], loss: 0.001541, mae: 0.042227, mean_q: 1.172656
 937166/1000000: episode: 9372, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.906, mean reward: 0.599 [0.505, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.565, 10.247], loss: 0.001567, mae: 0.042511, mean_q: 1.169833
 937266/1000000: episode: 9373, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 56.987, mean reward: 0.570 [0.503, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.769, 10.127], loss: 0.001368, mae: 0.040161, mean_q: 1.165611
 937366/1000000: episode: 9374, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.609, mean reward: 0.596 [0.502, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.064, 10.413], loss: 0.001573, mae: 0.042350, mean_q: 1.172047
 937466/1000000: episode: 9375, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.984, mean reward: 0.600 [0.506, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.018, 10.126], loss: 0.001636, mae: 0.043127, mean_q: 1.171780
 937566/1000000: episode: 9376, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 61.189, mean reward: 0.612 [0.502, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.788, 10.098], loss: 0.001487, mae: 0.041579, mean_q: 1.173543
 937666/1000000: episode: 9377, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.741, mean reward: 0.597 [0.509, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.405, 10.098], loss: 0.001458, mae: 0.041834, mean_q: 1.170235
 937766/1000000: episode: 9378, duration: 0.530s, episode steps: 100, steps per second: 189, episode reward: 58.182, mean reward: 0.582 [0.501, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.753, 10.123], loss: 0.001501, mae: 0.042226, mean_q: 1.175299
 937866/1000000: episode: 9379, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 59.181, mean reward: 0.592 [0.500, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.691, 10.365], loss: 0.001508, mae: 0.042048, mean_q: 1.171968
 937966/1000000: episode: 9380, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 63.172, mean reward: 0.632 [0.513, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.673, 10.098], loss: 0.001610, mae: 0.043675, mean_q: 1.173098
 938066/1000000: episode: 9381, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.371, mean reward: 0.584 [0.499, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.417, 10.215], loss: 0.001572, mae: 0.042882, mean_q: 1.171513
 938166/1000000: episode: 9382, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 61.260, mean reward: 0.613 [0.509, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.607, 10.427], loss: 0.001627, mae: 0.043260, mean_q: 1.172185
 938266/1000000: episode: 9383, duration: 0.612s, episode steps: 100, steps per second: 164, episode reward: 59.611, mean reward: 0.596 [0.506, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.931, 10.250], loss: 0.001571, mae: 0.043608, mean_q: 1.176835
 938366/1000000: episode: 9384, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 59.252, mean reward: 0.593 [0.500, 0.839], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.613, 10.135], loss: 0.001503, mae: 0.042416, mean_q: 1.176354
 938466/1000000: episode: 9385, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.059, mean reward: 0.581 [0.506, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.882, 10.226], loss: 0.001520, mae: 0.041764, mean_q: 1.172756
 938566/1000000: episode: 9386, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 56.645, mean reward: 0.566 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.514, 10.213], loss: 0.001666, mae: 0.044266, mean_q: 1.175454
 938666/1000000: episode: 9387, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 63.919, mean reward: 0.639 [0.515, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.705, 10.098], loss: 0.001726, mae: 0.044459, mean_q: 1.173632
 938766/1000000: episode: 9388, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 56.681, mean reward: 0.567 [0.499, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.767, 10.098], loss: 0.001573, mae: 0.043155, mean_q: 1.177530
 938866/1000000: episode: 9389, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 60.612, mean reward: 0.606 [0.505, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.361, 10.348], loss: 0.001560, mae: 0.042959, mean_q: 1.178564
 938966/1000000: episode: 9390, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.794, mean reward: 0.588 [0.500, 0.887], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.965, 10.358], loss: 0.001596, mae: 0.043238, mean_q: 1.174164
 939066/1000000: episode: 9391, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.139, mean reward: 0.581 [0.514, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.011, 10.098], loss: 0.001625, mae: 0.043614, mean_q: 1.176136
 939166/1000000: episode: 9392, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.357, mean reward: 0.584 [0.498, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.929, 10.098], loss: 0.001649, mae: 0.043117, mean_q: 1.173548
 939266/1000000: episode: 9393, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.892, mean reward: 0.599 [0.515, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.140, 10.246], loss: 0.001682, mae: 0.044277, mean_q: 1.178591
 939366/1000000: episode: 9394, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 58.808, mean reward: 0.588 [0.514, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.603, 10.098], loss: 0.001563, mae: 0.042150, mean_q: 1.176158
 939466/1000000: episode: 9395, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 57.455, mean reward: 0.575 [0.499, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.961, 10.168], loss: 0.001606, mae: 0.042939, mean_q: 1.176775
 939566/1000000: episode: 9396, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 61.460, mean reward: 0.615 [0.505, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.751, 10.418], loss: 0.001567, mae: 0.042588, mean_q: 1.175736
 939666/1000000: episode: 9397, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.521, mean reward: 0.585 [0.501, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.631, 10.098], loss: 0.001546, mae: 0.042576, mean_q: 1.177103
 939766/1000000: episode: 9398, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 58.852, mean reward: 0.589 [0.504, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.818, 10.164], loss: 0.001541, mae: 0.041803, mean_q: 1.176692
 939866/1000000: episode: 9399, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.810, mean reward: 0.618 [0.524, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.913, 10.407], loss: 0.001525, mae: 0.042288, mean_q: 1.175623
 939966/1000000: episode: 9400, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.732, mean reward: 0.607 [0.523, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.687, 10.267], loss: 0.001538, mae: 0.042240, mean_q: 1.177213
 940066/1000000: episode: 9401, duration: 0.520s, episode steps: 100, steps per second: 192, episode reward: 58.186, mean reward: 0.582 [0.501, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.810, 10.112], loss: 0.001609, mae: 0.043276, mean_q: 1.180986
 940166/1000000: episode: 9402, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 59.402, mean reward: 0.594 [0.512, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.216, 10.098], loss: 0.001636, mae: 0.043036, mean_q: 1.178223
 940266/1000000: episode: 9403, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.918, mean reward: 0.589 [0.500, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.307, 10.367], loss: 0.001644, mae: 0.043749, mean_q: 1.178347
 940366/1000000: episode: 9404, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 55.997, mean reward: 0.560 [0.503, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.156, 10.232], loss: 0.001590, mae: 0.042594, mean_q: 1.177100
 940466/1000000: episode: 9405, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 57.113, mean reward: 0.571 [0.505, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.702, 10.116], loss: 0.001605, mae: 0.042873, mean_q: 1.172184
 940566/1000000: episode: 9406, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.177, mean reward: 0.612 [0.509, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.302, 10.098], loss: 0.001560, mae: 0.042493, mean_q: 1.176774
 940666/1000000: episode: 9407, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.028, mean reward: 0.580 [0.504, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.256, 10.315], loss: 0.001534, mae: 0.042463, mean_q: 1.175555
 940766/1000000: episode: 9408, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.155, mean reward: 0.582 [0.501, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.764, 10.115], loss: 0.001576, mae: 0.042750, mean_q: 1.172792
 940866/1000000: episode: 9409, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 59.678, mean reward: 0.597 [0.507, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.563, 10.305], loss: 0.001504, mae: 0.042068, mean_q: 1.170873
 940966/1000000: episode: 9410, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 55.926, mean reward: 0.559 [0.501, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.895, 10.098], loss: 0.001548, mae: 0.041733, mean_q: 1.175885
 941066/1000000: episode: 9411, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.142, mean reward: 0.611 [0.518, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.870, 10.098], loss: 0.001393, mae: 0.040782, mean_q: 1.170907
 941166/1000000: episode: 9412, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 57.931, mean reward: 0.579 [0.502, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.827, 10.102], loss: 0.001534, mae: 0.042498, mean_q: 1.170959
 941266/1000000: episode: 9413, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 56.914, mean reward: 0.569 [0.504, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.931, 10.098], loss: 0.001525, mae: 0.041752, mean_q: 1.170277
 941366/1000000: episode: 9414, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 59.393, mean reward: 0.594 [0.509, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.908, 10.098], loss: 0.001500, mae: 0.041235, mean_q: 1.168172
 941466/1000000: episode: 9415, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.407, mean reward: 0.584 [0.501, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.164, 10.098], loss: 0.001590, mae: 0.042774, mean_q: 1.170621
 941566/1000000: episode: 9416, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.040, mean reward: 0.590 [0.505, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.503, 10.267], loss: 0.001526, mae: 0.041825, mean_q: 1.170362
 941666/1000000: episode: 9417, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 56.850, mean reward: 0.568 [0.501, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.523, 10.255], loss: 0.001566, mae: 0.042389, mean_q: 1.171160
 941766/1000000: episode: 9418, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.189, mean reward: 0.592 [0.513, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.454, 10.170], loss: 0.001379, mae: 0.040089, mean_q: 1.168313
 941866/1000000: episode: 9419, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 60.087, mean reward: 0.601 [0.507, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.016, 10.265], loss: 0.001450, mae: 0.040841, mean_q: 1.167139
 941966/1000000: episode: 9420, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 57.846, mean reward: 0.578 [0.502, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.074, 10.106], loss: 0.001506, mae: 0.042193, mean_q: 1.173142
 942066/1000000: episode: 9421, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 58.278, mean reward: 0.583 [0.500, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.562, 10.214], loss: 0.001455, mae: 0.041166, mean_q: 1.166389
 942166/1000000: episode: 9422, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.268, mean reward: 0.573 [0.505, 0.694], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.763, 10.270], loss: 0.001324, mae: 0.039491, mean_q: 1.168101
 942266/1000000: episode: 9423, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.593, mean reward: 0.586 [0.505, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.660, 10.205], loss: 0.001481, mae: 0.041494, mean_q: 1.169080
 942366/1000000: episode: 9424, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.417, mean reward: 0.574 [0.508, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-2.048, 10.145], loss: 0.001456, mae: 0.041383, mean_q: 1.167251
 942466/1000000: episode: 9425, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.126, mean reward: 0.581 [0.505, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.089, 10.246], loss: 0.001398, mae: 0.040331, mean_q: 1.168096
 942566/1000000: episode: 9426, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.005, mean reward: 0.580 [0.502, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.680, 10.259], loss: 0.001467, mae: 0.041680, mean_q: 1.167311
 942666/1000000: episode: 9427, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.940, mean reward: 0.589 [0.509, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.477, 10.346], loss: 0.001457, mae: 0.041567, mean_q: 1.166542
 942766/1000000: episode: 9428, duration: 0.537s, episode steps: 100, steps per second: 186, episode reward: 61.883, mean reward: 0.619 [0.507, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.508, 10.401], loss: 0.001375, mae: 0.040400, mean_q: 1.164158
 942866/1000000: episode: 9429, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 61.132, mean reward: 0.611 [0.524, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.699, 10.406], loss: 0.001345, mae: 0.040180, mean_q: 1.164743
 942966/1000000: episode: 9430, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.636, mean reward: 0.596 [0.509, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.436, 10.098], loss: 0.001379, mae: 0.040423, mean_q: 1.169079
 943066/1000000: episode: 9431, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 61.379, mean reward: 0.614 [0.501, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.538, 10.520], loss: 0.001392, mae: 0.040001, mean_q: 1.169699
 943166/1000000: episode: 9432, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.627, mean reward: 0.586 [0.513, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.503, 10.187], loss: 0.001333, mae: 0.039363, mean_q: 1.164850
 943266/1000000: episode: 9433, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 56.806, mean reward: 0.568 [0.506, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.408, 10.175], loss: 0.001375, mae: 0.040516, mean_q: 1.165648
 943366/1000000: episode: 9434, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 59.630, mean reward: 0.596 [0.501, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.395, 10.116], loss: 0.001457, mae: 0.041689, mean_q: 1.168210
 943466/1000000: episode: 9435, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 56.591, mean reward: 0.566 [0.503, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.723, 10.098], loss: 0.001391, mae: 0.040328, mean_q: 1.169105
 943566/1000000: episode: 9436, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 56.718, mean reward: 0.567 [0.503, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.711, 10.098], loss: 0.001322, mae: 0.039355, mean_q: 1.165897
 943666/1000000: episode: 9437, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 58.253, mean reward: 0.583 [0.506, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.878, 10.099], loss: 0.001303, mae: 0.039294, mean_q: 1.161537
 943766/1000000: episode: 9438, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 63.332, mean reward: 0.633 [0.506, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.594, 10.528], loss: 0.001328, mae: 0.039783, mean_q: 1.163696
 943866/1000000: episode: 9439, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.415, mean reward: 0.574 [0.502, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.901, 10.098], loss: 0.001405, mae: 0.040522, mean_q: 1.163664
 943966/1000000: episode: 9440, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 57.511, mean reward: 0.575 [0.501, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.472, 10.222], loss: 0.001397, mae: 0.040723, mean_q: 1.166423
 944066/1000000: episode: 9441, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 62.164, mean reward: 0.622 [0.512, 0.843], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.382, 10.098], loss: 0.001336, mae: 0.039505, mean_q: 1.164579
 944166/1000000: episode: 9442, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 62.159, mean reward: 0.622 [0.512, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.675, 10.341], loss: 0.001386, mae: 0.040271, mean_q: 1.166842
 944266/1000000: episode: 9443, duration: 0.576s, episode steps: 100, steps per second: 173, episode reward: 60.646, mean reward: 0.606 [0.513, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.807, 10.228], loss: 0.001354, mae: 0.040226, mean_q: 1.165778
 944366/1000000: episode: 9444, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 56.346, mean reward: 0.563 [0.505, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.614, 10.098], loss: 0.001295, mae: 0.039813, mean_q: 1.163620
 944466/1000000: episode: 9445, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 61.157, mean reward: 0.612 [0.509, 0.808], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.997, 10.241], loss: 0.001383, mae: 0.040339, mean_q: 1.169263
 944566/1000000: episode: 9446, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 56.791, mean reward: 0.568 [0.505, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.642, 10.098], loss: 0.001373, mae: 0.040260, mean_q: 1.166913
 944666/1000000: episode: 9447, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.870, mean reward: 0.599 [0.504, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.769, 10.129], loss: 0.001417, mae: 0.040862, mean_q: 1.166688
 944766/1000000: episode: 9448, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.605, mean reward: 0.586 [0.510, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.940, 10.098], loss: 0.001457, mae: 0.041658, mean_q: 1.165260
 944866/1000000: episode: 9449, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 62.409, mean reward: 0.624 [0.508, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.745, 10.342], loss: 0.001408, mae: 0.041356, mean_q: 1.164749
 944966/1000000: episode: 9450, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 56.973, mean reward: 0.570 [0.502, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.394, 10.101], loss: 0.001456, mae: 0.040969, mean_q: 1.166439
 945066/1000000: episode: 9451, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.242, mean reward: 0.602 [0.514, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.988, 10.098], loss: 0.001490, mae: 0.042056, mean_q: 1.165989
 945166/1000000: episode: 9452, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.617, mean reward: 0.606 [0.502, 0.843], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.531, 10.153], loss: 0.001465, mae: 0.041650, mean_q: 1.167300
 945266/1000000: episode: 9453, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.001, mean reward: 0.580 [0.506, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.876, 10.198], loss: 0.001379, mae: 0.040611, mean_q: 1.166405
 945366/1000000: episode: 9454, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 62.948, mean reward: 0.629 [0.504, 0.872], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.446, 10.363], loss: 0.001508, mae: 0.042270, mean_q: 1.165511
 945466/1000000: episode: 9455, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.859, mean reward: 0.599 [0.501, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.797, 10.151], loss: 0.001467, mae: 0.041675, mean_q: 1.169074
 945566/1000000: episode: 9456, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 56.539, mean reward: 0.565 [0.502, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.083, 10.104], loss: 0.001527, mae: 0.042002, mean_q: 1.168648
 945666/1000000: episode: 9457, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.864, mean reward: 0.589 [0.504, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.291, 10.098], loss: 0.001561, mae: 0.043249, mean_q: 1.168930
 945766/1000000: episode: 9458, duration: 0.604s, episode steps: 100, steps per second: 165, episode reward: 58.461, mean reward: 0.585 [0.501, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.595, 10.261], loss: 0.001420, mae: 0.041386, mean_q: 1.167424
 945866/1000000: episode: 9459, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.078, mean reward: 0.581 [0.504, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.604, 10.098], loss: 0.001450, mae: 0.041292, mean_q: 1.166026
 945966/1000000: episode: 9460, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.908, mean reward: 0.579 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.399, 10.098], loss: 0.001477, mae: 0.042127, mean_q: 1.168231
 946066/1000000: episode: 9461, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 56.350, mean reward: 0.563 [0.501, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.265, 10.098], loss: 0.001443, mae: 0.041702, mean_q: 1.166968
 946166/1000000: episode: 9462, duration: 0.510s, episode steps: 100, steps per second: 196, episode reward: 59.059, mean reward: 0.591 [0.523, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.522, 10.098], loss: 0.001536, mae: 0.042721, mean_q: 1.168506
 946266/1000000: episode: 9463, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 60.177, mean reward: 0.602 [0.526, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.039, 10.381], loss: 0.001604, mae: 0.044066, mean_q: 1.171058
 946366/1000000: episode: 9464, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 60.367, mean reward: 0.604 [0.498, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.135, 10.328], loss: 0.001521, mae: 0.042352, mean_q: 1.171748
 946466/1000000: episode: 9465, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.737, mean reward: 0.597 [0.504, 0.846], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.752, 10.268], loss: 0.001533, mae: 0.042675, mean_q: 1.171559
 946566/1000000: episode: 9466, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.066, mean reward: 0.571 [0.503, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.916, 10.098], loss: 0.001583, mae: 0.043292, mean_q: 1.170399
 946666/1000000: episode: 9467, duration: 0.548s, episode steps: 100, steps per second: 183, episode reward: 59.817, mean reward: 0.598 [0.500, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.857, 10.290], loss: 0.001525, mae: 0.042920, mean_q: 1.171351
 946766/1000000: episode: 9468, duration: 0.542s, episode steps: 100, steps per second: 185, episode reward: 59.813, mean reward: 0.598 [0.511, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.513, 10.321], loss: 0.001507, mae: 0.042269, mean_q: 1.173325
 946866/1000000: episode: 9469, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 62.325, mean reward: 0.623 [0.507, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.736, 10.388], loss: 0.001543, mae: 0.043176, mean_q: 1.164982
 946966/1000000: episode: 9470, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 59.701, mean reward: 0.597 [0.511, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.329, 10.098], loss: 0.001550, mae: 0.042851, mean_q: 1.170856
 947066/1000000: episode: 9471, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.148, mean reward: 0.581 [0.505, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.669, 10.098], loss: 0.001726, mae: 0.044592, mean_q: 1.173208
 947166/1000000: episode: 9472, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 59.500, mean reward: 0.595 [0.505, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.878, 10.315], loss: 0.001564, mae: 0.043187, mean_q: 1.170822
 947266/1000000: episode: 9473, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 57.120, mean reward: 0.571 [0.507, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.907, 10.113], loss: 0.001589, mae: 0.043325, mean_q: 1.171190
 947366/1000000: episode: 9474, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.944, mean reward: 0.579 [0.504, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.293, 10.141], loss: 0.001558, mae: 0.043320, mean_q: 1.169734
 947466/1000000: episode: 9475, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.318, mean reward: 0.593 [0.506, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.967, 10.169], loss: 0.001503, mae: 0.042982, mean_q: 1.173919
 947566/1000000: episode: 9476, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 62.361, mean reward: 0.624 [0.505, 0.864], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.839, 10.098], loss: 0.001493, mae: 0.042044, mean_q: 1.167961
 947666/1000000: episode: 9477, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.653, mean reward: 0.577 [0.501, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.995, 10.130], loss: 0.001616, mae: 0.044086, mean_q: 1.174675
 947766/1000000: episode: 9478, duration: 0.611s, episode steps: 100, steps per second: 164, episode reward: 58.227, mean reward: 0.582 [0.511, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.265, 10.333], loss: 0.001505, mae: 0.041871, mean_q: 1.173100
 947866/1000000: episode: 9479, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 61.030, mean reward: 0.610 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.759, 10.227], loss: 0.001577, mae: 0.043631, mean_q: 1.172796
 947966/1000000: episode: 9480, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 62.789, mean reward: 0.628 [0.519, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.669, 10.199], loss: 0.001548, mae: 0.043040, mean_q: 1.175526
 948066/1000000: episode: 9481, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.360, mean reward: 0.594 [0.510, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.751, 10.098], loss: 0.001474, mae: 0.041849, mean_q: 1.171949
 948166/1000000: episode: 9482, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.291, mean reward: 0.593 [0.509, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.980, 10.106], loss: 0.001518, mae: 0.042394, mean_q: 1.172976
 948266/1000000: episode: 9483, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.467, mean reward: 0.575 [0.500, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.507, 10.183], loss: 0.001433, mae: 0.041369, mean_q: 1.173564
 948366/1000000: episode: 9484, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 58.689, mean reward: 0.587 [0.503, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.413, 10.098], loss: 0.001490, mae: 0.041952, mean_q: 1.169846
 948466/1000000: episode: 9485, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 65.200, mean reward: 0.652 [0.500, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.407, 10.521], loss: 0.001464, mae: 0.041766, mean_q: 1.175551
 948566/1000000: episode: 9486, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.528, mean reward: 0.595 [0.499, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.597, 10.098], loss: 0.001515, mae: 0.042426, mean_q: 1.180319
 948666/1000000: episode: 9487, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.666, mean reward: 0.587 [0.514, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.805, 10.172], loss: 0.001526, mae: 0.042421, mean_q: 1.175654
 948766/1000000: episode: 9488, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 59.321, mean reward: 0.593 [0.508, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.998, 10.098], loss: 0.001586, mae: 0.042897, mean_q: 1.177324
 948866/1000000: episode: 9489, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 57.790, mean reward: 0.578 [0.497, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.247, 10.098], loss: 0.001593, mae: 0.043411, mean_q: 1.174734
 948966/1000000: episode: 9490, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 64.008, mean reward: 0.640 [0.532, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.227, 10.395], loss: 0.001481, mae: 0.042038, mean_q: 1.180680
 949066/1000000: episode: 9491, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 56.558, mean reward: 0.566 [0.501, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.697, 10.318], loss: 0.001540, mae: 0.042303, mean_q: 1.175990
 949166/1000000: episode: 9492, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.993, mean reward: 0.590 [0.505, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.563, 10.098], loss: 0.001634, mae: 0.043647, mean_q: 1.176231
 949266/1000000: episode: 9493, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 58.692, mean reward: 0.587 [0.509, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.804, 10.098], loss: 0.001454, mae: 0.041174, mean_q: 1.172567
 949366/1000000: episode: 9494, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 61.750, mean reward: 0.618 [0.506, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.862, 10.098], loss: 0.001445, mae: 0.041076, mean_q: 1.173001
 949466/1000000: episode: 9495, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.494, mean reward: 0.585 [0.504, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.466, 10.098], loss: 0.001489, mae: 0.041998, mean_q: 1.177695
 949566/1000000: episode: 9496, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.794, mean reward: 0.588 [0.502, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.543, 10.098], loss: 0.001520, mae: 0.042268, mean_q: 1.173226
 949666/1000000: episode: 9497, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.027, mean reward: 0.590 [0.500, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.088, 10.152], loss: 0.001457, mae: 0.041777, mean_q: 1.173560
 949766/1000000: episode: 9498, duration: 0.638s, episode steps: 100, steps per second: 157, episode reward: 58.810, mean reward: 0.588 [0.499, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.898, 10.098], loss: 0.001539, mae: 0.042877, mean_q: 1.176770
 949866/1000000: episode: 9499, duration: 0.629s, episode steps: 100, steps per second: 159, episode reward: 60.151, mean reward: 0.602 [0.508, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.958, 10.098], loss: 0.001626, mae: 0.043637, mean_q: 1.175379
 949966/1000000: episode: 9500, duration: 0.716s, episode steps: 100, steps per second: 140, episode reward: 56.825, mean reward: 0.568 [0.502, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.827, 10.256], loss: 0.001564, mae: 0.042567, mean_q: 1.172263
 950066/1000000: episode: 9501, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 58.408, mean reward: 0.584 [0.501, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.047, 10.135], loss: 0.001560, mae: 0.042483, mean_q: 1.174841
 950166/1000000: episode: 9502, duration: 0.752s, episode steps: 100, steps per second: 133, episode reward: 60.541, mean reward: 0.605 [0.499, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.058, 10.456], loss: 0.001629, mae: 0.043620, mean_q: 1.175127
 950266/1000000: episode: 9503, duration: 0.886s, episode steps: 100, steps per second: 113, episode reward: 57.672, mean reward: 0.577 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.339, 10.098], loss: 0.001542, mae: 0.042822, mean_q: 1.175981
 950366/1000000: episode: 9504, duration: 0.878s, episode steps: 100, steps per second: 114, episode reward: 60.013, mean reward: 0.600 [0.498, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.903, 10.098], loss: 0.001504, mae: 0.042271, mean_q: 1.174744
 950466/1000000: episode: 9505, duration: 1.164s, episode steps: 100, steps per second: 86, episode reward: 58.812, mean reward: 0.588 [0.503, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.876, 10.098], loss: 0.001470, mae: 0.041784, mean_q: 1.171894
 950566/1000000: episode: 9506, duration: 0.968s, episode steps: 100, steps per second: 103, episode reward: 61.235, mean reward: 0.612 [0.503, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.429, 10.239], loss: 0.001505, mae: 0.042013, mean_q: 1.172291
 950666/1000000: episode: 9507, duration: 0.880s, episode steps: 100, steps per second: 114, episode reward: 58.331, mean reward: 0.583 [0.503, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.443, 10.098], loss: 0.001495, mae: 0.041822, mean_q: 1.171967
 950766/1000000: episode: 9508, duration: 0.901s, episode steps: 100, steps per second: 111, episode reward: 58.795, mean reward: 0.588 [0.501, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.045, 10.098], loss: 0.001535, mae: 0.042091, mean_q: 1.177557
 950866/1000000: episode: 9509, duration: 0.843s, episode steps: 100, steps per second: 119, episode reward: 56.793, mean reward: 0.568 [0.502, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.989, 10.126], loss: 0.001621, mae: 0.043384, mean_q: 1.177142
 950966/1000000: episode: 9510, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 57.280, mean reward: 0.573 [0.501, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.462, 10.098], loss: 0.001453, mae: 0.041078, mean_q: 1.173111
 951066/1000000: episode: 9511, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.510, mean reward: 0.595 [0.512, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.175, 10.151], loss: 0.001519, mae: 0.042060, mean_q: 1.175299
 951166/1000000: episode: 9512, duration: 0.624s, episode steps: 100, steps per second: 160, episode reward: 59.975, mean reward: 0.600 [0.497, 0.798], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.194, 10.141], loss: 0.001504, mae: 0.042253, mean_q: 1.176233
 951266/1000000: episode: 9513, duration: 0.640s, episode steps: 100, steps per second: 156, episode reward: 58.906, mean reward: 0.589 [0.507, 0.886], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.791, 10.243], loss: 0.001489, mae: 0.041102, mean_q: 1.172183
 951366/1000000: episode: 9514, duration: 0.715s, episode steps: 100, steps per second: 140, episode reward: 59.266, mean reward: 0.593 [0.504, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.672, 10.115], loss: 0.001464, mae: 0.041059, mean_q: 1.171023
 951466/1000000: episode: 9515, duration: 0.636s, episode steps: 100, steps per second: 157, episode reward: 61.097, mean reward: 0.611 [0.509, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.421, 10.098], loss: 0.001517, mae: 0.041436, mean_q: 1.171392
 951566/1000000: episode: 9516, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.517, mean reward: 0.595 [0.512, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.916, 10.098], loss: 0.001492, mae: 0.041537, mean_q: 1.173870
 951666/1000000: episode: 9517, duration: 0.757s, episode steps: 100, steps per second: 132, episode reward: 59.476, mean reward: 0.595 [0.513, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.740, 10.241], loss: 0.001579, mae: 0.042296, mean_q: 1.174179
 951766/1000000: episode: 9518, duration: 0.916s, episode steps: 100, steps per second: 109, episode reward: 59.146, mean reward: 0.591 [0.501, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.880, 10.344], loss: 0.001562, mae: 0.042163, mean_q: 1.174983
 951866/1000000: episode: 9519, duration: 0.853s, episode steps: 100, steps per second: 117, episode reward: 56.669, mean reward: 0.567 [0.503, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.779, 10.146], loss: 0.001533, mae: 0.041789, mean_q: 1.173405
 951966/1000000: episode: 9520, duration: 0.787s, episode steps: 100, steps per second: 127, episode reward: 61.980, mean reward: 0.620 [0.509, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.576, 10.098], loss: 0.001508, mae: 0.041590, mean_q: 1.174385
 952066/1000000: episode: 9521, duration: 0.634s, episode steps: 100, steps per second: 158, episode reward: 58.767, mean reward: 0.588 [0.506, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.229, 10.227], loss: 0.001578, mae: 0.042712, mean_q: 1.174842
 952166/1000000: episode: 9522, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.139, mean reward: 0.591 [0.500, 0.886], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.469, 10.261], loss: 0.001658, mae: 0.042972, mean_q: 1.178271
 952266/1000000: episode: 9523, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 57.785, mean reward: 0.578 [0.498, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.403, 10.161], loss: 0.001640, mae: 0.042901, mean_q: 1.174877
 952366/1000000: episode: 9524, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.602, mean reward: 0.596 [0.511, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-2.181, 10.387], loss: 0.001641, mae: 0.042515, mean_q: 1.176350
 952466/1000000: episode: 9525, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.411, mean reward: 0.574 [0.514, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.913, 10.309], loss: 0.001538, mae: 0.042048, mean_q: 1.174679
 952566/1000000: episode: 9526, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 58.853, mean reward: 0.589 [0.512, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.367, 10.157], loss: 0.001583, mae: 0.042984, mean_q: 1.174277
 952666/1000000: episode: 9527, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.898, mean reward: 0.599 [0.513, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.475, 10.213], loss: 0.001626, mae: 0.043253, mean_q: 1.173447
 952766/1000000: episode: 9528, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.853, mean reward: 0.569 [0.503, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.547, 10.098], loss: 0.001588, mae: 0.042669, mean_q: 1.173497
 952866/1000000: episode: 9529, duration: 0.654s, episode steps: 100, steps per second: 153, episode reward: 57.445, mean reward: 0.574 [0.505, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.387, 10.114], loss: 0.001659, mae: 0.043460, mean_q: 1.169857
 952966/1000000: episode: 9530, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.838, mean reward: 0.578 [0.503, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.500, 10.098], loss: 0.001540, mae: 0.041997, mean_q: 1.169063
 953066/1000000: episode: 9531, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 60.035, mean reward: 0.600 [0.504, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.109, 10.270], loss: 0.001591, mae: 0.042132, mean_q: 1.168324
 953166/1000000: episode: 9532, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 58.665, mean reward: 0.587 [0.502, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.999, 10.211], loss: 0.001571, mae: 0.041513, mean_q: 1.170334
 953266/1000000: episode: 9533, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.162, mean reward: 0.582 [0.503, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.829, 10.098], loss: 0.001500, mae: 0.041395, mean_q: 1.169133
 953366/1000000: episode: 9534, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 64.194, mean reward: 0.642 [0.501, 0.813], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.301, 10.436], loss: 0.001597, mae: 0.042049, mean_q: 1.172112
 953466/1000000: episode: 9535, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 61.935, mean reward: 0.619 [0.508, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.227, 10.098], loss: 0.001731, mae: 0.044142, mean_q: 1.171493
 953566/1000000: episode: 9536, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.171, mean reward: 0.582 [0.503, 0.678], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.357, 10.140], loss: 0.001580, mae: 0.042287, mean_q: 1.170369
 953666/1000000: episode: 9537, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.096, mean reward: 0.591 [0.504, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.118, 10.098], loss: 0.001766, mae: 0.044285, mean_q: 1.172420
 953766/1000000: episode: 9538, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 62.265, mean reward: 0.623 [0.504, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.650, 10.203], loss: 0.001544, mae: 0.041935, mean_q: 1.172280
 953866/1000000: episode: 9539, duration: 0.648s, episode steps: 100, steps per second: 154, episode reward: 58.732, mean reward: 0.587 [0.499, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.527, 10.201], loss: 0.001601, mae: 0.042929, mean_q: 1.174309
 953966/1000000: episode: 9540, duration: 0.657s, episode steps: 100, steps per second: 152, episode reward: 59.721, mean reward: 0.597 [0.501, 0.819], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.465, 10.215], loss: 0.001652, mae: 0.043205, mean_q: 1.172098
 954066/1000000: episode: 9541, duration: 0.645s, episode steps: 100, steps per second: 155, episode reward: 62.927, mean reward: 0.629 [0.515, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.463, 10.098], loss: 0.001637, mae: 0.042820, mean_q: 1.174220
 954166/1000000: episode: 9542, duration: 0.587s, episode steps: 100, steps per second: 171, episode reward: 62.359, mean reward: 0.624 [0.515, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.865, 10.306], loss: 0.001608, mae: 0.042684, mean_q: 1.170086
 954266/1000000: episode: 9543, duration: 0.626s, episode steps: 100, steps per second: 160, episode reward: 60.756, mean reward: 0.608 [0.504, 0.807], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.332, 10.372], loss: 0.001556, mae: 0.042379, mean_q: 1.174217
 954366/1000000: episode: 9544, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.794, mean reward: 0.588 [0.512, 0.838], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.322, 10.336], loss: 0.001672, mae: 0.043142, mean_q: 1.175791
 954466/1000000: episode: 9545, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 58.546, mean reward: 0.585 [0.500, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.898, 10.222], loss: 0.001743, mae: 0.044441, mean_q: 1.174734
 954566/1000000: episode: 9546, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 61.810, mean reward: 0.618 [0.522, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.774, 10.323], loss: 0.001686, mae: 0.043343, mean_q: 1.169997
 954666/1000000: episode: 9547, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.515, mean reward: 0.585 [0.502, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.530, 10.277], loss: 0.001700, mae: 0.043968, mean_q: 1.175980
 954766/1000000: episode: 9548, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.811, mean reward: 0.578 [0.512, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.800, 10.103], loss: 0.001682, mae: 0.042942, mean_q: 1.175018
 954866/1000000: episode: 9549, duration: 0.531s, episode steps: 100, steps per second: 188, episode reward: 57.640, mean reward: 0.576 [0.509, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.162, 10.197], loss: 0.001573, mae: 0.042726, mean_q: 1.177528
 954966/1000000: episode: 9550, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 57.729, mean reward: 0.577 [0.503, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.763, 10.098], loss: 0.001553, mae: 0.042349, mean_q: 1.177020
 955066/1000000: episode: 9551, duration: 0.608s, episode steps: 100, steps per second: 165, episode reward: 60.169, mean reward: 0.602 [0.509, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.849, 10.106], loss: 0.001523, mae: 0.042188, mean_q: 1.174404
 955166/1000000: episode: 9552, duration: 0.597s, episode steps: 100, steps per second: 167, episode reward: 59.012, mean reward: 0.590 [0.498, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.132, 10.098], loss: 0.001703, mae: 0.044031, mean_q: 1.176152
 955266/1000000: episode: 9553, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 59.438, mean reward: 0.594 [0.509, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.257, 10.495], loss: 0.001584, mae: 0.042847, mean_q: 1.175842
 955366/1000000: episode: 9554, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.481, mean reward: 0.585 [0.511, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.550, 10.138], loss: 0.001621, mae: 0.043037, mean_q: 1.175702
 955466/1000000: episode: 9555, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.183, mean reward: 0.572 [0.503, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.516, 10.098], loss: 0.001589, mae: 0.042250, mean_q: 1.170860
 955566/1000000: episode: 9556, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 58.566, mean reward: 0.586 [0.510, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.366, 10.198], loss: 0.001514, mae: 0.041957, mean_q: 1.173291
 955666/1000000: episode: 9557, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 58.225, mean reward: 0.582 [0.500, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.513, 10.226], loss: 0.001614, mae: 0.042433, mean_q: 1.171479
 955766/1000000: episode: 9558, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.122, mean reward: 0.581 [0.498, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.345, 10.224], loss: 0.001614, mae: 0.042883, mean_q: 1.172810
 955866/1000000: episode: 9559, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.880, mean reward: 0.589 [0.510, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.828, 10.152], loss: 0.001519, mae: 0.041966, mean_q: 1.171552
 955966/1000000: episode: 9560, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 61.221, mean reward: 0.612 [0.516, 0.856], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.131, 10.204], loss: 0.001597, mae: 0.043218, mean_q: 1.174280
 956066/1000000: episode: 9561, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 57.746, mean reward: 0.577 [0.502, 0.688], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.428, 10.244], loss: 0.001674, mae: 0.043877, mean_q: 1.176247
 956166/1000000: episode: 9562, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.393, mean reward: 0.594 [0.508, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.022, 10.320], loss: 0.001693, mae: 0.044032, mean_q: 1.176043
 956266/1000000: episode: 9563, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 56.685, mean reward: 0.567 [0.501, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.742, 10.226], loss: 0.001651, mae: 0.043999, mean_q: 1.175361
 956366/1000000: episode: 9564, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 59.347, mean reward: 0.593 [0.503, 0.895], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.441, 10.239], loss: 0.001603, mae: 0.043091, mean_q: 1.173112
 956466/1000000: episode: 9565, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 57.580, mean reward: 0.576 [0.512, 0.704], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.324, 10.098], loss: 0.001606, mae: 0.043312, mean_q: 1.171733
 956566/1000000: episode: 9566, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.829, mean reward: 0.608 [0.514, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.894, 10.098], loss: 0.001490, mae: 0.041371, mean_q: 1.170823
 956666/1000000: episode: 9567, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 62.754, mean reward: 0.628 [0.513, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.343, 10.098], loss: 0.001655, mae: 0.044043, mean_q: 1.171481
 956766/1000000: episode: 9568, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 63.301, mean reward: 0.633 [0.501, 0.872], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.838, 10.098], loss: 0.001593, mae: 0.042561, mean_q: 1.176336
 956866/1000000: episode: 9569, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 62.376, mean reward: 0.624 [0.515, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.508, 10.098], loss: 0.001549, mae: 0.042481, mean_q: 1.173910
 956966/1000000: episode: 9570, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.463, mean reward: 0.585 [0.511, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.478, 10.098], loss: 0.001546, mae: 0.042687, mean_q: 1.172076
 957066/1000000: episode: 9571, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.948, mean reward: 0.589 [0.511, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.108, 10.098], loss: 0.001698, mae: 0.043869, mean_q: 1.180011
 957166/1000000: episode: 9572, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 57.912, mean reward: 0.579 [0.503, 0.880], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.849, 10.105], loss: 0.001566, mae: 0.042386, mean_q: 1.176906
 957266/1000000: episode: 9573, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 60.253, mean reward: 0.603 [0.505, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.899, 10.098], loss: 0.001555, mae: 0.042947, mean_q: 1.174985
 957366/1000000: episode: 9574, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.604, mean reward: 0.586 [0.499, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.512, 10.429], loss: 0.001510, mae: 0.041919, mean_q: 1.178271
 957466/1000000: episode: 9575, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.896, mean reward: 0.609 [0.516, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.172, 10.098], loss: 0.001597, mae: 0.042478, mean_q: 1.174642
 957566/1000000: episode: 9576, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.557, mean reward: 0.596 [0.521, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.328, 10.098], loss: 0.001639, mae: 0.043404, mean_q: 1.182248
 957666/1000000: episode: 9577, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.766, mean reward: 0.588 [0.508, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.395, 10.098], loss: 0.001547, mae: 0.042133, mean_q: 1.178121
 957766/1000000: episode: 9578, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.206, mean reward: 0.582 [0.503, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.974, 10.123], loss: 0.001540, mae: 0.041665, mean_q: 1.176358
 957866/1000000: episode: 9579, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 57.604, mean reward: 0.576 [0.505, 0.830], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.517, 10.098], loss: 0.001671, mae: 0.043734, mean_q: 1.176032
 957966/1000000: episode: 9580, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 56.901, mean reward: 0.569 [0.506, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.526, 10.164], loss: 0.001601, mae: 0.043070, mean_q: 1.177914
 958066/1000000: episode: 9581, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.218, mean reward: 0.582 [0.509, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.191, 10.144], loss: 0.001484, mae: 0.041618, mean_q: 1.173450
 958166/1000000: episode: 9582, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 59.111, mean reward: 0.591 [0.512, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.912, 10.224], loss: 0.001709, mae: 0.043565, mean_q: 1.175761
 958266/1000000: episode: 9583, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.094, mean reward: 0.611 [0.508, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.830, 10.098], loss: 0.001618, mae: 0.043146, mean_q: 1.174621
 958366/1000000: episode: 9584, duration: 0.536s, episode steps: 100, steps per second: 186, episode reward: 57.589, mean reward: 0.576 [0.499, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.231, 10.103], loss: 0.001596, mae: 0.042820, mean_q: 1.176485
 958466/1000000: episode: 9585, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 57.629, mean reward: 0.576 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.219, 10.193], loss: 0.001590, mae: 0.042673, mean_q: 1.174643
 958566/1000000: episode: 9586, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 58.560, mean reward: 0.586 [0.505, 0.823], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.469, 10.190], loss: 0.001591, mae: 0.042973, mean_q: 1.171068
 958666/1000000: episode: 9587, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 59.118, mean reward: 0.591 [0.507, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.237, 10.098], loss: 0.001599, mae: 0.043105, mean_q: 1.178145
 958766/1000000: episode: 9588, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 56.748, mean reward: 0.567 [0.504, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.018, 10.098], loss: 0.001567, mae: 0.042453, mean_q: 1.170117
 958866/1000000: episode: 9589, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.710, mean reward: 0.587 [0.508, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.225, 10.098], loss: 0.001565, mae: 0.042145, mean_q: 1.170812
 958966/1000000: episode: 9590, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.397, mean reward: 0.584 [0.501, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.095, 10.203], loss: 0.001629, mae: 0.043243, mean_q: 1.173075
 959066/1000000: episode: 9591, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.473, mean reward: 0.585 [0.505, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.847, 10.098], loss: 0.001694, mae: 0.043427, mean_q: 1.168441
 959166/1000000: episode: 9592, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.096, mean reward: 0.581 [0.505, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.275, 10.098], loss: 0.001476, mae: 0.040811, mean_q: 1.166003
 959266/1000000: episode: 9593, duration: 0.526s, episode steps: 100, steps per second: 190, episode reward: 58.078, mean reward: 0.581 [0.500, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.165, 10.098], loss: 0.001534, mae: 0.041772, mean_q: 1.164683
 959366/1000000: episode: 9594, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.683, mean reward: 0.587 [0.512, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.722, 10.098], loss: 0.001489, mae: 0.042022, mean_q: 1.168319
 959466/1000000: episode: 9595, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 57.898, mean reward: 0.579 [0.504, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.543, 10.098], loss: 0.001615, mae: 0.043308, mean_q: 1.170217
 959566/1000000: episode: 9596, duration: 0.563s, episode steps: 100, steps per second: 177, episode reward: 57.764, mean reward: 0.578 [0.508, 0.700], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.479, 10.226], loss: 0.001527, mae: 0.042304, mean_q: 1.165248
 959666/1000000: episode: 9597, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.162, mean reward: 0.602 [0.516, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.566, 10.244], loss: 0.001537, mae: 0.042603, mean_q: 1.167740
 959766/1000000: episode: 9598, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 61.267, mean reward: 0.613 [0.510, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.575, 10.162], loss: 0.001506, mae: 0.041770, mean_q: 1.169122
 959866/1000000: episode: 9599, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 62.912, mean reward: 0.629 [0.515, 0.857], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.254, 10.247], loss: 0.001521, mae: 0.042173, mean_q: 1.168997
 959966/1000000: episode: 9600, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.524, mean reward: 0.585 [0.503, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.763, 10.098], loss: 0.001619, mae: 0.043446, mean_q: 1.169179
 960066/1000000: episode: 9601, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 57.593, mean reward: 0.576 [0.504, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.376, 10.147], loss: 0.001597, mae: 0.043061, mean_q: 1.168220
 960166/1000000: episode: 9602, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 58.966, mean reward: 0.590 [0.509, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.969, 10.098], loss: 0.001462, mae: 0.041498, mean_q: 1.165302
 960266/1000000: episode: 9603, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.393, mean reward: 0.594 [0.499, 0.909], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.383, 10.098], loss: 0.001533, mae: 0.042302, mean_q: 1.164479
 960366/1000000: episode: 9604, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 61.462, mean reward: 0.615 [0.522, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.982, 10.225], loss: 0.001465, mae: 0.041863, mean_q: 1.168124
 960466/1000000: episode: 9605, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.512, mean reward: 0.585 [0.504, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.760, 10.098], loss: 0.001518, mae: 0.041923, mean_q: 1.167182
 960566/1000000: episode: 9606, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.045, mean reward: 0.570 [0.502, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.583, 10.158], loss: 0.001557, mae: 0.042184, mean_q: 1.168916
 960666/1000000: episode: 9607, duration: 0.590s, episode steps: 100, steps per second: 170, episode reward: 58.234, mean reward: 0.582 [0.500, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.374, 10.144], loss: 0.001623, mae: 0.042803, mean_q: 1.170284
 960766/1000000: episode: 9608, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.982, mean reward: 0.580 [0.508, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.063, 10.281], loss: 0.001447, mae: 0.040739, mean_q: 1.164686
 960866/1000000: episode: 9609, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 58.198, mean reward: 0.582 [0.504, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.894, 10.098], loss: 0.001610, mae: 0.043203, mean_q: 1.169565
 960966/1000000: episode: 9610, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.802, mean reward: 0.588 [0.502, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.804, 10.159], loss: 0.001566, mae: 0.042411, mean_q: 1.165682
 961066/1000000: episode: 9611, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.344, mean reward: 0.593 [0.501, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.720, 10.193], loss: 0.001599, mae: 0.042838, mean_q: 1.165356
 961166/1000000: episode: 9612, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.799, mean reward: 0.588 [0.501, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.272, 10.139], loss: 0.001458, mae: 0.041523, mean_q: 1.166666
 961266/1000000: episode: 9613, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.703, mean reward: 0.607 [0.514, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.465, 10.169], loss: 0.001467, mae: 0.041032, mean_q: 1.165224
 961366/1000000: episode: 9614, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 60.091, mean reward: 0.601 [0.509, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.153, 10.098], loss: 0.001629, mae: 0.043473, mean_q: 1.168452
 961466/1000000: episode: 9615, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.110, mean reward: 0.581 [0.504, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.205, 10.232], loss: 0.001506, mae: 0.041943, mean_q: 1.170700
 961566/1000000: episode: 9616, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 57.974, mean reward: 0.580 [0.507, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.276, 10.150], loss: 0.001596, mae: 0.042453, mean_q: 1.169904
 961666/1000000: episode: 9617, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.567, mean reward: 0.576 [0.501, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.355, 10.222], loss: 0.001535, mae: 0.042993, mean_q: 1.167553
 961766/1000000: episode: 9618, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.111, mean reward: 0.581 [0.509, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.735, 10.098], loss: 0.001559, mae: 0.042338, mean_q: 1.167194
 961866/1000000: episode: 9619, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.899, mean reward: 0.579 [0.503, 0.706], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.916, 10.098], loss: 0.001525, mae: 0.042409, mean_q: 1.164991
 961966/1000000: episode: 9620, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.553, mean reward: 0.576 [0.504, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.072, 10.233], loss: 0.001565, mae: 0.042301, mean_q: 1.161483
 962066/1000000: episode: 9621, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 58.195, mean reward: 0.582 [0.508, 0.702], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.613, 10.207], loss: 0.001591, mae: 0.043281, mean_q: 1.164702
 962166/1000000: episode: 9622, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.189, mean reward: 0.582 [0.513, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.224, 10.146], loss: 0.001525, mae: 0.042458, mean_q: 1.161297
 962266/1000000: episode: 9623, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.636, mean reward: 0.586 [0.506, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.841, 10.100], loss: 0.001572, mae: 0.042561, mean_q: 1.163962
 962366/1000000: episode: 9624, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.616, mean reward: 0.586 [0.504, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.583, 10.098], loss: 0.001561, mae: 0.042800, mean_q: 1.161802
 962466/1000000: episode: 9625, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 62.008, mean reward: 0.620 [0.518, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.114, 10.328], loss: 0.001620, mae: 0.043634, mean_q: 1.162759
 962566/1000000: episode: 9626, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.636, mean reward: 0.596 [0.520, 0.810], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.821, 10.233], loss: 0.001705, mae: 0.044540, mean_q: 1.161760
 962666/1000000: episode: 9627, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 61.366, mean reward: 0.614 [0.513, 0.794], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.415, 10.297], loss: 0.001648, mae: 0.043902, mean_q: 1.165248
 962766/1000000: episode: 9628, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 60.217, mean reward: 0.602 [0.531, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.409, 10.098], loss: 0.001455, mae: 0.041222, mean_q: 1.164025
 962866/1000000: episode: 9629, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 57.163, mean reward: 0.572 [0.502, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.616, 10.098], loss: 0.001652, mae: 0.044020, mean_q: 1.165968
 962966/1000000: episode: 9630, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 61.480, mean reward: 0.615 [0.501, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.580, 10.098], loss: 0.001474, mae: 0.041334, mean_q: 1.166373
 963066/1000000: episode: 9631, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.766, mean reward: 0.588 [0.502, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.596, 10.195], loss: 0.001542, mae: 0.042530, mean_q: 1.164612
 963166/1000000: episode: 9632, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.185, mean reward: 0.582 [0.499, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.674, 10.262], loss: 0.001561, mae: 0.042379, mean_q: 1.168330
 963266/1000000: episode: 9633, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.669, mean reward: 0.577 [0.499, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.798, 10.286], loss: 0.001477, mae: 0.041408, mean_q: 1.164740
 963366/1000000: episode: 9634, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 61.469, mean reward: 0.615 [0.510, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.071, 10.339], loss: 0.001564, mae: 0.042432, mean_q: 1.162527
 963466/1000000: episode: 9635, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.378, mean reward: 0.584 [0.500, 0.909], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.661, 10.198], loss: 0.001597, mae: 0.042387, mean_q: 1.167585
 963566/1000000: episode: 9636, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.437, mean reward: 0.584 [0.508, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.639, 10.204], loss: 0.001547, mae: 0.042806, mean_q: 1.165962
 963666/1000000: episode: 9637, duration: 0.542s, episode steps: 100, steps per second: 184, episode reward: 56.282, mean reward: 0.563 [0.502, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.741, 10.098], loss: 0.001685, mae: 0.044011, mean_q: 1.166793
 963766/1000000: episode: 9638, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 60.244, mean reward: 0.602 [0.506, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.911, 10.271], loss: 0.001542, mae: 0.041863, mean_q: 1.164594
 963866/1000000: episode: 9639, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 60.778, mean reward: 0.608 [0.514, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.900, 10.155], loss: 0.001517, mae: 0.041773, mean_q: 1.166768
 963966/1000000: episode: 9640, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 59.993, mean reward: 0.600 [0.520, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.681, 10.209], loss: 0.001582, mae: 0.042805, mean_q: 1.164649
 964066/1000000: episode: 9641, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 58.183, mean reward: 0.582 [0.497, 0.801], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.231, 10.380], loss: 0.001470, mae: 0.041355, mean_q: 1.166312
 964166/1000000: episode: 9642, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.409, mean reward: 0.584 [0.502, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.029, 10.098], loss: 0.001458, mae: 0.041720, mean_q: 1.168822
 964266/1000000: episode: 9643, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.096, mean reward: 0.601 [0.504, 0.776], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.856, 10.098], loss: 0.001605, mae: 0.042661, mean_q: 1.169851
 964366/1000000: episode: 9644, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 57.938, mean reward: 0.579 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.157, 10.173], loss: 0.001590, mae: 0.043248, mean_q: 1.168589
 964466/1000000: episode: 9645, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.688, mean reward: 0.587 [0.502, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.473, 10.098], loss: 0.001555, mae: 0.042285, mean_q: 1.169966
 964566/1000000: episode: 9646, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 63.464, mean reward: 0.635 [0.508, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.026, 10.473], loss: 0.001607, mae: 0.042812, mean_q: 1.166713
 964666/1000000: episode: 9647, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.454, mean reward: 0.585 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.693, 10.098], loss: 0.001469, mae: 0.041845, mean_q: 1.167220
 964766/1000000: episode: 9648, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.380, mean reward: 0.584 [0.504, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.720, 10.098], loss: 0.001560, mae: 0.042633, mean_q: 1.167513
 964866/1000000: episode: 9649, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 59.936, mean reward: 0.599 [0.503, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.046, 10.359], loss: 0.001593, mae: 0.043408, mean_q: 1.166597
 964966/1000000: episode: 9650, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 59.461, mean reward: 0.595 [0.504, 0.827], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.895, 10.098], loss: 0.001543, mae: 0.042597, mean_q: 1.166088
 965066/1000000: episode: 9651, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 60.120, mean reward: 0.601 [0.512, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.966, 10.389], loss: 0.001668, mae: 0.043292, mean_q: 1.167965
 965166/1000000: episode: 9652, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 60.422, mean reward: 0.604 [0.506, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.753, 10.390], loss: 0.001583, mae: 0.042740, mean_q: 1.165940
 965266/1000000: episode: 9653, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.679, mean reward: 0.577 [0.508, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.462, 10.098], loss: 0.001436, mae: 0.041717, mean_q: 1.167547
 965366/1000000: episode: 9654, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.019, mean reward: 0.600 [0.502, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.918, 10.194], loss: 0.001443, mae: 0.041160, mean_q: 1.169807
 965466/1000000: episode: 9655, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 61.187, mean reward: 0.612 [0.516, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.148, 10.507], loss: 0.001459, mae: 0.041598, mean_q: 1.169495
 965566/1000000: episode: 9656, duration: 0.573s, episode steps: 100, steps per second: 175, episode reward: 58.015, mean reward: 0.580 [0.506, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.522, 10.173], loss: 0.001467, mae: 0.041671, mean_q: 1.169842
 965666/1000000: episode: 9657, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 57.988, mean reward: 0.580 [0.507, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.918, 10.126], loss: 0.001575, mae: 0.042993, mean_q: 1.168738
 965766/1000000: episode: 9658, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.029, mean reward: 0.610 [0.512, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.679, 10.098], loss: 0.001458, mae: 0.041798, mean_q: 1.169479
 965866/1000000: episode: 9659, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 60.747, mean reward: 0.607 [0.503, 0.812], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.066, 10.098], loss: 0.001504, mae: 0.042210, mean_q: 1.169870
 965966/1000000: episode: 9660, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 60.141, mean reward: 0.601 [0.510, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.332, 10.098], loss: 0.001474, mae: 0.041534, mean_q: 1.173187
 966066/1000000: episode: 9661, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.917, mean reward: 0.589 [0.504, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.119, 10.098], loss: 0.001576, mae: 0.042713, mean_q: 1.174372
 966166/1000000: episode: 9662, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.546, mean reward: 0.595 [0.510, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.115, 10.116], loss: 0.001555, mae: 0.042935, mean_q: 1.169544
 966266/1000000: episode: 9663, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 61.711, mean reward: 0.617 [0.516, 0.850], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.402, 10.098], loss: 0.001491, mae: 0.042318, mean_q: 1.168878
 966366/1000000: episode: 9664, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 56.669, mean reward: 0.567 [0.499, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.989, 10.115], loss: 0.001507, mae: 0.042128, mean_q: 1.165996
 966466/1000000: episode: 9665, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 56.048, mean reward: 0.560 [0.499, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.542, 10.407], loss: 0.001468, mae: 0.041418, mean_q: 1.174814
 966566/1000000: episode: 9666, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 56.187, mean reward: 0.562 [0.499, 0.697], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.723, 10.149], loss: 0.001586, mae: 0.042873, mean_q: 1.172279
 966666/1000000: episode: 9667, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.876, mean reward: 0.579 [0.504, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.441, 10.136], loss: 0.001576, mae: 0.042715, mean_q: 1.170446
 966766/1000000: episode: 9668, duration: 0.567s, episode steps: 100, steps per second: 177, episode reward: 60.923, mean reward: 0.609 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.526, 10.359], loss: 0.001620, mae: 0.043470, mean_q: 1.174142
 966866/1000000: episode: 9669, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 61.482, mean reward: 0.615 [0.501, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.913, 10.098], loss: 0.001553, mae: 0.042420, mean_q: 1.171896
 966966/1000000: episode: 9670, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.229, mean reward: 0.612 [0.514, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.487, 10.302], loss: 0.001479, mae: 0.041256, mean_q: 1.176000
 967066/1000000: episode: 9671, duration: 0.576s, episode steps: 100, steps per second: 174, episode reward: 59.667, mean reward: 0.597 [0.512, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.812, 10.098], loss: 0.001495, mae: 0.041932, mean_q: 1.174673
 967166/1000000: episode: 9672, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 57.033, mean reward: 0.570 [0.503, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.769, 10.098], loss: 0.001533, mae: 0.042494, mean_q: 1.175929
 967266/1000000: episode: 9673, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 58.065, mean reward: 0.581 [0.511, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.403, 10.138], loss: 0.001491, mae: 0.042213, mean_q: 1.177561
 967366/1000000: episode: 9674, duration: 0.548s, episode steps: 100, steps per second: 182, episode reward: 59.799, mean reward: 0.598 [0.506, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.227, 10.098], loss: 0.001665, mae: 0.043702, mean_q: 1.175580
 967466/1000000: episode: 9675, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.620, mean reward: 0.596 [0.509, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.818, 10.327], loss: 0.001452, mae: 0.041580, mean_q: 1.176256
 967566/1000000: episode: 9676, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 58.371, mean reward: 0.584 [0.506, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.825, 10.118], loss: 0.001536, mae: 0.042469, mean_q: 1.177565
 967666/1000000: episode: 9677, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 58.824, mean reward: 0.588 [0.499, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.474, 10.114], loss: 0.001516, mae: 0.041850, mean_q: 1.171936
 967766/1000000: episode: 9678, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.651, mean reward: 0.587 [0.504, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.820, 10.098], loss: 0.001614, mae: 0.042899, mean_q: 1.170644
 967866/1000000: episode: 9679, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 60.045, mean reward: 0.600 [0.502, 0.748], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.321, 10.290], loss: 0.001543, mae: 0.041706, mean_q: 1.172475
 967966/1000000: episode: 9680, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.282, mean reward: 0.613 [0.512, 0.888], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.457, 10.098], loss: 0.001553, mae: 0.042711, mean_q: 1.174652
 968066/1000000: episode: 9681, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.581, mean reward: 0.586 [0.497, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.641, 10.098], loss: 0.001549, mae: 0.041886, mean_q: 1.171959
 968166/1000000: episode: 9682, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 57.216, mean reward: 0.572 [0.506, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.544, 10.200], loss: 0.001422, mae: 0.040238, mean_q: 1.171552
 968266/1000000: episode: 9683, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 64.129, mean reward: 0.641 [0.504, 0.911], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-2.800, 10.438], loss: 0.001591, mae: 0.042502, mean_q: 1.174837
 968366/1000000: episode: 9684, duration: 0.527s, episode steps: 100, steps per second: 190, episode reward: 59.243, mean reward: 0.592 [0.507, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.449, 10.098], loss: 0.001474, mae: 0.041718, mean_q: 1.174896
 968466/1000000: episode: 9685, duration: 0.518s, episode steps: 100, steps per second: 193, episode reward: 60.593, mean reward: 0.606 [0.502, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.398, 10.119], loss: 0.001556, mae: 0.042320, mean_q: 1.175394
 968566/1000000: episode: 9686, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 57.966, mean reward: 0.580 [0.505, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.360, 10.098], loss: 0.001426, mae: 0.040451, mean_q: 1.174191
 968666/1000000: episode: 9687, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 58.440, mean reward: 0.584 [0.504, 0.853], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.656, 10.098], loss: 0.001515, mae: 0.042039, mean_q: 1.178734
 968766/1000000: episode: 9688, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 60.165, mean reward: 0.602 [0.503, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.877, 10.120], loss: 0.001551, mae: 0.042760, mean_q: 1.178227
 968866/1000000: episode: 9689, duration: 0.528s, episode steps: 100, steps per second: 189, episode reward: 58.230, mean reward: 0.582 [0.505, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.576, 10.282], loss: 0.001535, mae: 0.042175, mean_q: 1.176688
 968966/1000000: episode: 9690, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.247, mean reward: 0.582 [0.507, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.478, 10.098], loss: 0.001567, mae: 0.042648, mean_q: 1.172734
 969066/1000000: episode: 9691, duration: 0.604s, episode steps: 100, steps per second: 166, episode reward: 60.071, mean reward: 0.601 [0.505, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.339, 10.098], loss: 0.001508, mae: 0.042161, mean_q: 1.174173
 969166/1000000: episode: 9692, duration: 0.614s, episode steps: 100, steps per second: 163, episode reward: 59.480, mean reward: 0.595 [0.514, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.749, 10.098], loss: 0.001487, mae: 0.041828, mean_q: 1.177762
 969266/1000000: episode: 9693, duration: 0.651s, episode steps: 100, steps per second: 154, episode reward: 57.108, mean reward: 0.571 [0.503, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.594, 10.098], loss: 0.001495, mae: 0.041742, mean_q: 1.171200
 969366/1000000: episode: 9694, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.567, mean reward: 0.586 [0.511, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.685, 10.269], loss: 0.001461, mae: 0.041365, mean_q: 1.174990
 969466/1000000: episode: 9695, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.569, mean reward: 0.576 [0.504, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.656, 10.331], loss: 0.001528, mae: 0.041346, mean_q: 1.172650
 969566/1000000: episode: 9696, duration: 0.621s, episode steps: 100, steps per second: 161, episode reward: 58.470, mean reward: 0.585 [0.502, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.607, 10.210], loss: 0.001488, mae: 0.041592, mean_q: 1.171634
 969666/1000000: episode: 9697, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.995, mean reward: 0.580 [0.498, 0.686], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.555, 10.256], loss: 0.001502, mae: 0.041627, mean_q: 1.170832
 969766/1000000: episode: 9698, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 61.132, mean reward: 0.611 [0.508, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.288, 10.098], loss: 0.001408, mae: 0.040897, mean_q: 1.169294
 969866/1000000: episode: 9699, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.008, mean reward: 0.560 [0.501, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.583, 10.098], loss: 0.001495, mae: 0.041566, mean_q: 1.174268
 969966/1000000: episode: 9700, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 64.702, mean reward: 0.647 [0.507, 0.834], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.756, 10.531], loss: 0.001462, mae: 0.040903, mean_q: 1.168141
 970066/1000000: episode: 9701, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 59.169, mean reward: 0.592 [0.504, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.813, 10.098], loss: 0.001544, mae: 0.042064, mean_q: 1.170147
 970166/1000000: episode: 9702, duration: 0.612s, episode steps: 100, steps per second: 163, episode reward: 57.820, mean reward: 0.578 [0.508, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.903, 10.152], loss: 0.001428, mae: 0.040776, mean_q: 1.168450
 970266/1000000: episode: 9703, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 64.432, mean reward: 0.644 [0.515, 0.814], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.431, 10.331], loss: 0.001375, mae: 0.039964, mean_q: 1.169755
 970366/1000000: episode: 9704, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 63.433, mean reward: 0.634 [0.527, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.687, 10.098], loss: 0.001417, mae: 0.040529, mean_q: 1.174852
 970466/1000000: episode: 9705, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 58.059, mean reward: 0.581 [0.501, 0.777], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.018, 10.140], loss: 0.001519, mae: 0.041717, mean_q: 1.174746
 970566/1000000: episode: 9706, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.252, mean reward: 0.603 [0.511, 0.951], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.410, 10.104], loss: 0.001367, mae: 0.039944, mean_q: 1.175200
 970666/1000000: episode: 9707, duration: 0.551s, episode steps: 100, steps per second: 182, episode reward: 58.758, mean reward: 0.588 [0.503, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.224, 10.098], loss: 0.001565, mae: 0.042359, mean_q: 1.176896
 970766/1000000: episode: 9708, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 58.281, mean reward: 0.583 [0.501, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.835, 10.098], loss: 0.001382, mae: 0.040266, mean_q: 1.175436
 970866/1000000: episode: 9709, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.502, mean reward: 0.585 [0.509, 0.761], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.644, 10.210], loss: 0.001422, mae: 0.040394, mean_q: 1.174194
 970966/1000000: episode: 9710, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.946, mean reward: 0.579 [0.505, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.548, 10.115], loss: 0.001441, mae: 0.040702, mean_q: 1.172922
 971066/1000000: episode: 9711, duration: 0.618s, episode steps: 100, steps per second: 162, episode reward: 57.576, mean reward: 0.576 [0.505, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.000, 10.248], loss: 0.001427, mae: 0.041192, mean_q: 1.176256
 971166/1000000: episode: 9712, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.581, mean reward: 0.606 [0.503, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.113, 10.111], loss: 0.001434, mae: 0.040678, mean_q: 1.175090
 971266/1000000: episode: 9713, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.540, mean reward: 0.595 [0.511, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.364, 10.237], loss: 0.001452, mae: 0.040763, mean_q: 1.173403
 971366/1000000: episode: 9714, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 58.346, mean reward: 0.583 [0.508, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.796, 10.192], loss: 0.001380, mae: 0.040203, mean_q: 1.169839
 971466/1000000: episode: 9715, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.265, mean reward: 0.583 [0.505, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.139, 10.098], loss: 0.001517, mae: 0.042263, mean_q: 1.173556
 971566/1000000: episode: 9716, duration: 0.593s, episode steps: 100, steps per second: 169, episode reward: 60.510, mean reward: 0.605 [0.502, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.599, 10.098], loss: 0.001522, mae: 0.041839, mean_q: 1.173212
 971666/1000000: episode: 9717, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 60.007, mean reward: 0.600 [0.497, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.474, 10.246], loss: 0.001558, mae: 0.042340, mean_q: 1.176809
 971766/1000000: episode: 9718, duration: 0.545s, episode steps: 100, steps per second: 183, episode reward: 58.510, mean reward: 0.585 [0.503, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.850, 10.107], loss: 0.001502, mae: 0.041777, mean_q: 1.178494
 971866/1000000: episode: 9719, duration: 0.600s, episode steps: 100, steps per second: 167, episode reward: 57.546, mean reward: 0.575 [0.503, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.305, 10.098], loss: 0.001410, mae: 0.040498, mean_q: 1.172264
 971966/1000000: episode: 9720, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 57.724, mean reward: 0.577 [0.504, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.597, 10.098], loss: 0.001458, mae: 0.041038, mean_q: 1.173777
 972066/1000000: episode: 9721, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.719, mean reward: 0.597 [0.505, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.217, 10.431], loss: 0.001630, mae: 0.043434, mean_q: 1.172102
 972166/1000000: episode: 9722, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.331, mean reward: 0.573 [0.506, 0.671], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.512, 10.275], loss: 0.001489, mae: 0.041244, mean_q: 1.170194
 972266/1000000: episode: 9723, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 60.645, mean reward: 0.606 [0.512, 0.797], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.023, 10.098], loss: 0.001508, mae: 0.041439, mean_q: 1.174163
 972366/1000000: episode: 9724, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 60.949, mean reward: 0.609 [0.510, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.595, 10.098], loss: 0.001569, mae: 0.042595, mean_q: 1.175313
 972466/1000000: episode: 9725, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 57.517, mean reward: 0.575 [0.501, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-0.966, 10.098], loss: 0.001458, mae: 0.041444, mean_q: 1.172098
 972566/1000000: episode: 9726, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.686, mean reward: 0.587 [0.513, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.036, 10.114], loss: 0.001383, mae: 0.040106, mean_q: 1.172999
 972666/1000000: episode: 9727, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 56.819, mean reward: 0.568 [0.498, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.458, 10.141], loss: 0.001507, mae: 0.042246, mean_q: 1.171476
 972766/1000000: episode: 9728, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.921, mean reward: 0.579 [0.499, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.949, 10.107], loss: 0.001486, mae: 0.041440, mean_q: 1.170299
 972866/1000000: episode: 9729, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 58.388, mean reward: 0.584 [0.508, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.741, 10.098], loss: 0.001497, mae: 0.041952, mean_q: 1.168993
 972966/1000000: episode: 9730, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.698, mean reward: 0.577 [0.501, 0.707], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.831, 10.274], loss: 0.001381, mae: 0.039953, mean_q: 1.166806
 973066/1000000: episode: 9731, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.995, mean reward: 0.590 [0.504, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.238, 10.153], loss: 0.001433, mae: 0.040989, mean_q: 1.168867
 973166/1000000: episode: 9732, duration: 0.539s, episode steps: 100, steps per second: 185, episode reward: 61.452, mean reward: 0.615 [0.506, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.189, 10.511], loss: 0.001507, mae: 0.042016, mean_q: 1.172416
 973266/1000000: episode: 9733, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 61.002, mean reward: 0.610 [0.513, 0.842], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.742, 10.098], loss: 0.001526, mae: 0.041681, mean_q: 1.168862
 973366/1000000: episode: 9734, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.392, mean reward: 0.564 [0.502, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.503, 10.179], loss: 0.001506, mae: 0.041875, mean_q: 1.167701
 973466/1000000: episode: 9735, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 57.417, mean reward: 0.574 [0.509, 0.683], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.724, 10.098], loss: 0.001472, mae: 0.041467, mean_q: 1.168559
 973566/1000000: episode: 9736, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 62.095, mean reward: 0.621 [0.508, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.631, 10.222], loss: 0.001462, mae: 0.041303, mean_q: 1.168166
 973666/1000000: episode: 9737, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.797, mean reward: 0.578 [0.500, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.491, 10.098], loss: 0.001396, mae: 0.040718, mean_q: 1.169857
 973766/1000000: episode: 9738, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 60.733, mean reward: 0.607 [0.501, 0.846], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.885, 10.129], loss: 0.001511, mae: 0.041990, mean_q: 1.168545
 973866/1000000: episode: 9739, duration: 0.606s, episode steps: 100, steps per second: 165, episode reward: 60.799, mean reward: 0.608 [0.509, 0.840], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.017, 10.098], loss: 0.001534, mae: 0.042374, mean_q: 1.168903
 973966/1000000: episode: 9740, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 59.720, mean reward: 0.597 [0.500, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.788, 10.098], loss: 0.001497, mae: 0.042200, mean_q: 1.174163
 974066/1000000: episode: 9741, duration: 0.533s, episode steps: 100, steps per second: 188, episode reward: 60.494, mean reward: 0.605 [0.504, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.081, 10.373], loss: 0.001472, mae: 0.041740, mean_q: 1.170607
 974166/1000000: episode: 9742, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 62.179, mean reward: 0.622 [0.502, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.882, 10.098], loss: 0.001481, mae: 0.041455, mean_q: 1.175234
 974266/1000000: episode: 9743, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.578, mean reward: 0.586 [0.503, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.078, 10.098], loss: 0.001497, mae: 0.041813, mean_q: 1.170427
 974366/1000000: episode: 9744, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 61.383, mean reward: 0.614 [0.510, 0.778], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.295, 10.098], loss: 0.001455, mae: 0.040991, mean_q: 1.172775
 974466/1000000: episode: 9745, duration: 0.547s, episode steps: 100, steps per second: 183, episode reward: 57.776, mean reward: 0.578 [0.504, 0.787], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.757, 10.098], loss: 0.001481, mae: 0.042009, mean_q: 1.172439
 974566/1000000: episode: 9746, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.591, mean reward: 0.576 [0.512, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.140, 10.098], loss: 0.001349, mae: 0.040502, mean_q: 1.173776
 974666/1000000: episode: 9747, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.625, mean reward: 0.586 [0.507, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.849, 10.098], loss: 0.001446, mae: 0.040885, mean_q: 1.172617
 974766/1000000: episode: 9748, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 61.190, mean reward: 0.612 [0.507, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.628, 10.098], loss: 0.001481, mae: 0.042233, mean_q: 1.173886
 974866/1000000: episode: 9749, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.183, mean reward: 0.602 [0.503, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.008, 10.098], loss: 0.001520, mae: 0.042113, mean_q: 1.171037
 974966/1000000: episode: 9750, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 57.442, mean reward: 0.574 [0.502, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.171, 10.135], loss: 0.001505, mae: 0.042293, mean_q: 1.172230
 975066/1000000: episode: 9751, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.677, mean reward: 0.587 [0.503, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.038, 10.160], loss: 0.001494, mae: 0.041844, mean_q: 1.170996
 975166/1000000: episode: 9752, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 61.549, mean reward: 0.615 [0.510, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.172, 10.098], loss: 0.001488, mae: 0.041664, mean_q: 1.174022
 975266/1000000: episode: 9753, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.496, mean reward: 0.595 [0.499, 0.809], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-1.286, 10.235], loss: 0.001453, mae: 0.041832, mean_q: 1.172681
 975366/1000000: episode: 9754, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.097, mean reward: 0.581 [0.501, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.528, 10.241], loss: 0.001421, mae: 0.041338, mean_q: 1.169932
 975466/1000000: episode: 9755, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 58.502, mean reward: 0.585 [0.505, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.275, 10.098], loss: 0.001509, mae: 0.041936, mean_q: 1.170516
 975566/1000000: episode: 9756, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 57.415, mean reward: 0.574 [0.502, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.740, 10.251], loss: 0.001530, mae: 0.042802, mean_q: 1.170379
 975666/1000000: episode: 9757, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 58.891, mean reward: 0.589 [0.510, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.508, 10.105], loss: 0.001551, mae: 0.042765, mean_q: 1.168562
 975766/1000000: episode: 9758, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.017, mean reward: 0.580 [0.504, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.962, 10.098], loss: 0.001426, mae: 0.041115, mean_q: 1.168766
 975866/1000000: episode: 9759, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 63.169, mean reward: 0.632 [0.512, 0.900], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.225, 10.400], loss: 0.001441, mae: 0.041548, mean_q: 1.168896
 975966/1000000: episode: 9760, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 59.153, mean reward: 0.592 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.023, 10.178], loss: 0.001475, mae: 0.041752, mean_q: 1.172484
 976066/1000000: episode: 9761, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 58.928, mean reward: 0.589 [0.505, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.747, 10.098], loss: 0.001399, mae: 0.041031, mean_q: 1.165794
 976166/1000000: episode: 9762, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.922, mean reward: 0.579 [0.502, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.652, 10.256], loss: 0.001453, mae: 0.042232, mean_q: 1.173309
 976266/1000000: episode: 9763, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.463, mean reward: 0.605 [0.510, 0.727], mean action: 0.000 [0.000, 0.000], mean observation: 1.411 [-0.585, 10.098], loss: 0.001587, mae: 0.043191, mean_q: 1.173418
 976366/1000000: episode: 9764, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.283, mean reward: 0.603 [0.501, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.541, 10.098], loss: 0.001523, mae: 0.042386, mean_q: 1.172389
 976466/1000000: episode: 9765, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.489, mean reward: 0.575 [0.500, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.678, 10.132], loss: 0.001509, mae: 0.042595, mean_q: 1.172625
 976566/1000000: episode: 9766, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 62.146, mean reward: 0.621 [0.512, 0.822], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.481, 10.098], loss: 0.001506, mae: 0.042807, mean_q: 1.172414
 976666/1000000: episode: 9767, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 59.321, mean reward: 0.593 [0.503, 0.803], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.711, 10.174], loss: 0.001472, mae: 0.042578, mean_q: 1.176663
 976766/1000000: episode: 9768, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.130, mean reward: 0.581 [0.508, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.955, 10.175], loss: 0.001452, mae: 0.041269, mean_q: 1.170877
 976866/1000000: episode: 9769, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.330, mean reward: 0.573 [0.504, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.637, 10.098], loss: 0.001522, mae: 0.042524, mean_q: 1.171496
 976966/1000000: episode: 9770, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 56.914, mean reward: 0.569 [0.510, 0.676], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.296, 10.155], loss: 0.001590, mae: 0.043451, mean_q: 1.170037
 977066/1000000: episode: 9771, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 57.747, mean reward: 0.577 [0.503, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.506, 10.098], loss: 0.001515, mae: 0.042432, mean_q: 1.169970
 977166/1000000: episode: 9772, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 60.387, mean reward: 0.604 [0.503, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.414 [-1.475, 10.098], loss: 0.001557, mae: 0.042443, mean_q: 1.168262
 977266/1000000: episode: 9773, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.671, mean reward: 0.587 [0.507, 0.766], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.569, 10.394], loss: 0.001512, mae: 0.042404, mean_q: 1.173499
 977366/1000000: episode: 9774, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.685, mean reward: 0.577 [0.511, 0.715], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.622, 10.098], loss: 0.001531, mae: 0.042213, mean_q: 1.170646
 977466/1000000: episode: 9775, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 62.580, mean reward: 0.626 [0.498, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.057, 10.098], loss: 0.001591, mae: 0.043711, mean_q: 1.173810
 977566/1000000: episode: 9776, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 60.076, mean reward: 0.601 [0.505, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.271, 10.242], loss: 0.001504, mae: 0.042123, mean_q: 1.172986
 977666/1000000: episode: 9777, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.047, mean reward: 0.580 [0.500, 0.763], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.548, 10.146], loss: 0.001550, mae: 0.042614, mean_q: 1.175611
 977766/1000000: episode: 9778, duration: 0.541s, episode steps: 100, steps per second: 185, episode reward: 58.376, mean reward: 0.584 [0.507, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.571, 10.098], loss: 0.001536, mae: 0.042761, mean_q: 1.174343
 977866/1000000: episode: 9779, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.712, mean reward: 0.577 [0.503, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-1.368, 10.351], loss: 0.001565, mae: 0.043328, mean_q: 1.174550
 977966/1000000: episode: 9780, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 58.254, mean reward: 0.583 [0.505, 0.732], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.670, 10.098], loss: 0.001438, mae: 0.041130, mean_q: 1.171425
 978066/1000000: episode: 9781, duration: 0.536s, episode steps: 100, steps per second: 187, episode reward: 58.738, mean reward: 0.587 [0.504, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.565, 10.286], loss: 0.001528, mae: 0.042119, mean_q: 1.170249
 978166/1000000: episode: 9782, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 58.551, mean reward: 0.586 [0.498, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.781, 10.098], loss: 0.001544, mae: 0.042905, mean_q: 1.172612
 978266/1000000: episode: 9783, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 59.092, mean reward: 0.591 [0.499, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.128, 10.102], loss: 0.001467, mae: 0.041999, mean_q: 1.170029
 978366/1000000: episode: 9784, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.329, mean reward: 0.583 [0.500, 0.811], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.720, 10.128], loss: 0.001538, mae: 0.042462, mean_q: 1.171475
 978466/1000000: episode: 9785, duration: 0.543s, episode steps: 100, steps per second: 184, episode reward: 58.069, mean reward: 0.581 [0.499, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.949, 10.202], loss: 0.001610, mae: 0.043855, mean_q: 1.171974
 978566/1000000: episode: 9786, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 59.564, mean reward: 0.596 [0.505, 0.725], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.119, 10.181], loss: 0.001554, mae: 0.042854, mean_q: 1.170613
 978666/1000000: episode: 9787, duration: 0.539s, episode steps: 100, steps per second: 186, episode reward: 58.481, mean reward: 0.585 [0.504, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.691, 10.098], loss: 0.001566, mae: 0.042756, mean_q: 1.170342
 978766/1000000: episode: 9788, duration: 0.540s, episode steps: 100, steps per second: 185, episode reward: 60.619, mean reward: 0.606 [0.508, 0.833], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.164, 10.098], loss: 0.001633, mae: 0.043881, mean_q: 1.170741
 978866/1000000: episode: 9789, duration: 0.560s, episode steps: 100, steps per second: 179, episode reward: 59.173, mean reward: 0.592 [0.503, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.521, 10.098], loss: 0.001477, mae: 0.041784, mean_q: 1.169690
 978966/1000000: episode: 9790, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 57.874, mean reward: 0.579 [0.506, 0.673], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.474, 10.174], loss: 0.001526, mae: 0.042725, mean_q: 1.170541
 979066/1000000: episode: 9791, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.759, mean reward: 0.578 [0.509, 0.672], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.418, 10.241], loss: 0.001497, mae: 0.042838, mean_q: 1.171816
 979166/1000000: episode: 9792, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.269, mean reward: 0.583 [0.501, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-1.017, 10.180], loss: 0.001477, mae: 0.041849, mean_q: 1.171625
 979266/1000000: episode: 9793, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 56.627, mean reward: 0.566 [0.506, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.112, 10.218], loss: 0.001554, mae: 0.042850, mean_q: 1.167589
 979366/1000000: episode: 9794, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.052, mean reward: 0.591 [0.499, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-1.651, 10.098], loss: 0.001512, mae: 0.042611, mean_q: 1.165069
 979466/1000000: episode: 9795, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 58.091, mean reward: 0.581 [0.504, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.815, 10.121], loss: 0.001477, mae: 0.042150, mean_q: 1.167869
 979566/1000000: episode: 9796, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 60.089, mean reward: 0.601 [0.514, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.599, 10.098], loss: 0.001602, mae: 0.044009, mean_q: 1.169021
 979666/1000000: episode: 9797, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.739, mean reward: 0.597 [0.503, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.601, 10.359], loss: 0.001560, mae: 0.043330, mean_q: 1.168558
 979766/1000000: episode: 9798, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 60.014, mean reward: 0.600 [0.508, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.180, 10.363], loss: 0.001457, mae: 0.041879, mean_q: 1.165813
 979866/1000000: episode: 9799, duration: 0.551s, episode steps: 100, steps per second: 181, episode reward: 60.624, mean reward: 0.606 [0.513, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.237, 10.098], loss: 0.001480, mae: 0.042048, mean_q: 1.164592
 979966/1000000: episode: 9800, duration: 0.583s, episode steps: 100, steps per second: 172, episode reward: 58.960, mean reward: 0.590 [0.500, 0.756], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.378, 10.098], loss: 0.001497, mae: 0.042026, mean_q: 1.166361
 980066/1000000: episode: 9801, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.912, mean reward: 0.589 [0.499, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.634, 10.226], loss: 0.001514, mae: 0.042595, mean_q: 1.166097
 980166/1000000: episode: 9802, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 59.434, mean reward: 0.594 [0.510, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.210, 10.157], loss: 0.001507, mae: 0.042369, mean_q: 1.167297
 980266/1000000: episode: 9803, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 59.545, mean reward: 0.595 [0.510, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.399, 10.280], loss: 0.001430, mae: 0.041514, mean_q: 1.166417
 980366/1000000: episode: 9804, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.120, mean reward: 0.601 [0.505, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.859, 10.098], loss: 0.001552, mae: 0.043011, mean_q: 1.170420
 980466/1000000: episode: 9805, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.968, mean reward: 0.580 [0.502, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.400, 10.244], loss: 0.001423, mae: 0.040598, mean_q: 1.166116
 980566/1000000: episode: 9806, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 61.788, mean reward: 0.618 [0.510, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.762, 10.338], loss: 0.001434, mae: 0.040987, mean_q: 1.169987
 980666/1000000: episode: 9807, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 60.129, mean reward: 0.601 [0.509, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.578, 10.417], loss: 0.001468, mae: 0.042064, mean_q: 1.173180
 980766/1000000: episode: 9808, duration: 0.557s, episode steps: 100, steps per second: 180, episode reward: 60.597, mean reward: 0.606 [0.502, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.442 [-0.759, 10.461], loss: 0.001426, mae: 0.041096, mean_q: 1.168676
 980866/1000000: episode: 9809, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.793, mean reward: 0.578 [0.507, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.562, 10.189], loss: 0.001410, mae: 0.041165, mean_q: 1.165794
 980966/1000000: episode: 9810, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 57.137, mean reward: 0.571 [0.508, 0.701], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.332, 10.098], loss: 0.001487, mae: 0.041857, mean_q: 1.164321
 981066/1000000: episode: 9811, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.409, mean reward: 0.594 [0.499, 0.783], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.589, 10.189], loss: 0.001509, mae: 0.042044, mean_q: 1.168017
 981166/1000000: episode: 9812, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.372, mean reward: 0.584 [0.506, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.530, 10.098], loss: 0.001375, mae: 0.040293, mean_q: 1.167888
 981266/1000000: episode: 9813, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 56.828, mean reward: 0.568 [0.499, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.594, 10.172], loss: 0.001450, mae: 0.041080, mean_q: 1.165954
 981366/1000000: episode: 9814, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 57.229, mean reward: 0.572 [0.503, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.431, 10.098], loss: 0.001462, mae: 0.041389, mean_q: 1.164836
 981466/1000000: episode: 9815, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.931, mean reward: 0.589 [0.502, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.416 [-0.518, 10.098], loss: 0.001456, mae: 0.041612, mean_q: 1.165579
 981566/1000000: episode: 9816, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.806, mean reward: 0.598 [0.500, 0.791], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.913, 10.170], loss: 0.001414, mae: 0.040534, mean_q: 1.161723
 981666/1000000: episode: 9817, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 58.922, mean reward: 0.589 [0.499, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.103, 10.175], loss: 0.001355, mae: 0.040281, mean_q: 1.166425
 981766/1000000: episode: 9818, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.310, mean reward: 0.593 [0.499, 0.796], mean action: 0.000 [0.000, 0.000], mean observation: 1.444 [-0.631, 10.398], loss: 0.001469, mae: 0.041803, mean_q: 1.165608
 981866/1000000: episode: 9819, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.450, mean reward: 0.594 [0.500, 0.745], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.140, 10.262], loss: 0.001484, mae: 0.041612, mean_q: 1.165794
 981966/1000000: episode: 9820, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.363, mean reward: 0.564 [0.502, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.677, 10.105], loss: 0.001386, mae: 0.040922, mean_q: 1.168630
 982066/1000000: episode: 9821, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 60.950, mean reward: 0.610 [0.508, 0.730], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.559, 10.098], loss: 0.001320, mae: 0.039413, mean_q: 1.166968
 982166/1000000: episode: 9822, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.301, mean reward: 0.583 [0.507, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.528, 10.158], loss: 0.001344, mae: 0.039706, mean_q: 1.165516
 982266/1000000: episode: 9823, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 59.972, mean reward: 0.600 [0.512, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.934, 10.292], loss: 0.001384, mae: 0.040720, mean_q: 1.168069
 982366/1000000: episode: 9824, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.179, mean reward: 0.572 [0.507, 0.680], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.254, 10.156], loss: 0.001423, mae: 0.041040, mean_q: 1.167540
 982466/1000000: episode: 9825, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 59.512, mean reward: 0.595 [0.499, 0.759], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.407, 10.098], loss: 0.001402, mae: 0.041259, mean_q: 1.165145
 982566/1000000: episode: 9826, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 58.881, mean reward: 0.589 [0.504, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.895, 10.098], loss: 0.001323, mae: 0.040347, mean_q: 1.166923
 982666/1000000: episode: 9827, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.573, mean reward: 0.586 [0.510, 0.818], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.436, 10.281], loss: 0.001389, mae: 0.040158, mean_q: 1.164040
 982766/1000000: episode: 9828, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.453, mean reward: 0.605 [0.502, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.924, 10.402], loss: 0.001408, mae: 0.041248, mean_q: 1.165992
 982866/1000000: episode: 9829, duration: 0.659s, episode steps: 100, steps per second: 152, episode reward: 58.555, mean reward: 0.586 [0.509, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.967, 10.098], loss: 0.001284, mae: 0.039180, mean_q: 1.165872
 982966/1000000: episode: 9830, duration: 0.666s, episode steps: 100, steps per second: 150, episode reward: 57.246, mean reward: 0.572 [0.507, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.805, 10.117], loss: 0.001356, mae: 0.040126, mean_q: 1.165065
 983066/1000000: episode: 9831, duration: 0.758s, episode steps: 100, steps per second: 132, episode reward: 56.996, mean reward: 0.570 [0.499, 0.714], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.773, 10.098], loss: 0.001413, mae: 0.041381, mean_q: 1.166283
 983166/1000000: episode: 9832, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 57.955, mean reward: 0.580 [0.507, 0.740], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.662, 10.098], loss: 0.001348, mae: 0.039738, mean_q: 1.166409
 983266/1000000: episode: 9833, duration: 0.624s, episode steps: 100, steps per second: 160, episode reward: 58.301, mean reward: 0.583 [0.500, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-1.310, 10.145], loss: 0.001371, mae: 0.040481, mean_q: 1.166416
 983366/1000000: episode: 9834, duration: 0.788s, episode steps: 100, steps per second: 127, episode reward: 57.803, mean reward: 0.578 [0.510, 0.820], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.936, 10.339], loss: 0.001403, mae: 0.040771, mean_q: 1.169349
 983466/1000000: episode: 9835, duration: 0.705s, episode steps: 100, steps per second: 142, episode reward: 58.606, mean reward: 0.586 [0.501, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.415, 10.206], loss: 0.001393, mae: 0.040294, mean_q: 1.169318
 983566/1000000: episode: 9836, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 57.513, mean reward: 0.575 [0.503, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.263, 10.319], loss: 0.001389, mae: 0.040369, mean_q: 1.165175
 983666/1000000: episode: 9837, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 62.384, mean reward: 0.624 [0.516, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.211, 10.125], loss: 0.001438, mae: 0.041279, mean_q: 1.168793
 983766/1000000: episode: 9838, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 57.608, mean reward: 0.576 [0.517, 0.687], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.370, 10.197], loss: 0.001288, mae: 0.039367, mean_q: 1.163707
 983866/1000000: episode: 9839, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 59.698, mean reward: 0.597 [0.499, 0.789], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.191, 10.098], loss: 0.001321, mae: 0.040195, mean_q: 1.165491
 983966/1000000: episode: 9840, duration: 0.556s, episode steps: 100, steps per second: 180, episode reward: 59.940, mean reward: 0.599 [0.506, 0.804], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.929, 10.259], loss: 0.001424, mae: 0.040655, mean_q: 1.165173
 984066/1000000: episode: 9841, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 58.401, mean reward: 0.584 [0.502, 0.713], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.735, 10.106], loss: 0.001422, mae: 0.040803, mean_q: 1.167680
 984166/1000000: episode: 9842, duration: 0.560s, episode steps: 100, steps per second: 178, episode reward: 57.435, mean reward: 0.574 [0.506, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.146, 10.098], loss: 0.001272, mae: 0.038051, mean_q: 1.165098
 984266/1000000: episode: 9843, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.754, mean reward: 0.588 [0.506, 0.800], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.072, 10.274], loss: 0.001402, mae: 0.040722, mean_q: 1.167294
 984366/1000000: episode: 9844, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 59.774, mean reward: 0.598 [0.507, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.891, 10.098], loss: 0.001413, mae: 0.040677, mean_q: 1.166419
 984466/1000000: episode: 9845, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 57.559, mean reward: 0.576 [0.501, 0.710], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.006, 10.271], loss: 0.001355, mae: 0.040222, mean_q: 1.165110
 984566/1000000: episode: 9846, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.509, mean reward: 0.575 [0.500, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.103, 10.098], loss: 0.001314, mae: 0.039657, mean_q: 1.164014
 984666/1000000: episode: 9847, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 60.850, mean reward: 0.608 [0.506, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.123, 10.098], loss: 0.001370, mae: 0.039979, mean_q: 1.165600
 984766/1000000: episode: 9848, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.709, mean reward: 0.587 [0.499, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.659, 10.209], loss: 0.001341, mae: 0.039465, mean_q: 1.165038
 984866/1000000: episode: 9849, duration: 0.568s, episode steps: 100, steps per second: 176, episode reward: 62.266, mean reward: 0.623 [0.513, 0.844], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.622, 10.432], loss: 0.001265, mae: 0.038890, mean_q: 1.162994
 984966/1000000: episode: 9850, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 57.409, mean reward: 0.574 [0.502, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.296, 10.241], loss: 0.001331, mae: 0.039499, mean_q: 1.163331
 985066/1000000: episode: 9851, duration: 0.554s, episode steps: 100, steps per second: 180, episode reward: 56.450, mean reward: 0.565 [0.501, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.801, 10.098], loss: 0.001311, mae: 0.039709, mean_q: 1.165107
 985166/1000000: episode: 9852, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 57.572, mean reward: 0.576 [0.501, 0.696], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.441, 10.275], loss: 0.001379, mae: 0.040070, mean_q: 1.163226
 985266/1000000: episode: 9853, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 56.941, mean reward: 0.569 [0.505, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.633, 10.157], loss: 0.001303, mae: 0.039664, mean_q: 1.161065
 985366/1000000: episode: 9854, duration: 0.646s, episode steps: 100, steps per second: 155, episode reward: 56.891, mean reward: 0.569 [0.500, 0.724], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.840, 10.098], loss: 0.001430, mae: 0.041053, mean_q: 1.160639
 985466/1000000: episode: 9855, duration: 0.671s, episode steps: 100, steps per second: 149, episode reward: 58.157, mean reward: 0.582 [0.505, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.561, 10.158], loss: 0.001322, mae: 0.039917, mean_q: 1.158335
 985566/1000000: episode: 9856, duration: 0.589s, episode steps: 100, steps per second: 170, episode reward: 57.585, mean reward: 0.576 [0.499, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.780, 10.098], loss: 0.001429, mae: 0.041234, mean_q: 1.161300
 985666/1000000: episode: 9857, duration: 0.849s, episode steps: 100, steps per second: 118, episode reward: 57.896, mean reward: 0.579 [0.514, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.187, 10.126], loss: 0.001356, mae: 0.040259, mean_q: 1.159913
 985766/1000000: episode: 9858, duration: 0.850s, episode steps: 100, steps per second: 118, episode reward: 58.483, mean reward: 0.585 [0.515, 0.729], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.994, 10.098], loss: 0.001386, mae: 0.040613, mean_q: 1.154899
 985866/1000000: episode: 9859, duration: 0.857s, episode steps: 100, steps per second: 117, episode reward: 57.760, mean reward: 0.578 [0.511, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.799, 10.275], loss: 0.001336, mae: 0.039574, mean_q: 1.155958
 985966/1000000: episode: 9860, duration: 0.958s, episode steps: 100, steps per second: 104, episode reward: 57.354, mean reward: 0.574 [0.513, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.517, 10.098], loss: 0.001354, mae: 0.040611, mean_q: 1.156794
 986066/1000000: episode: 9861, duration: 0.661s, episode steps: 100, steps per second: 151, episode reward: 58.577, mean reward: 0.586 [0.505, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.372, 10.345], loss: 0.001240, mae: 0.038299, mean_q: 1.154800
 986166/1000000: episode: 9862, duration: 0.664s, episode steps: 100, steps per second: 151, episode reward: 61.223, mean reward: 0.612 [0.506, 0.903], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.497, 10.449], loss: 0.001365, mae: 0.039957, mean_q: 1.159320
 986266/1000000: episode: 9863, duration: 0.629s, episode steps: 100, steps per second: 159, episode reward: 57.739, mean reward: 0.577 [0.499, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.925, 10.362], loss: 0.001496, mae: 0.042034, mean_q: 1.160482
 986366/1000000: episode: 9864, duration: 0.602s, episode steps: 100, steps per second: 166, episode reward: 60.157, mean reward: 0.602 [0.504, 0.743], mean action: 0.000 [0.000, 0.000], mean observation: 1.415 [-0.666, 10.098], loss: 0.001364, mae: 0.040165, mean_q: 1.161153
 986466/1000000: episode: 9865, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.978, mean reward: 0.580 [0.508, 0.765], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.542, 10.098], loss: 0.001373, mae: 0.040010, mean_q: 1.158633
 986566/1000000: episode: 9866, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 58.565, mean reward: 0.586 [0.505, 0.681], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.456, 10.098], loss: 0.001399, mae: 0.041003, mean_q: 1.160910
 986666/1000000: episode: 9867, duration: 0.575s, episode steps: 100, steps per second: 174, episode reward: 61.780, mean reward: 0.618 [0.499, 0.790], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.046, 10.098], loss: 0.001431, mae: 0.041210, mean_q: 1.159447
 986766/1000000: episode: 9868, duration: 0.628s, episode steps: 100, steps per second: 159, episode reward: 60.580, mean reward: 0.606 [0.499, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-2.402, 10.098], loss: 0.001323, mae: 0.039979, mean_q: 1.160764
 986866/1000000: episode: 9869, duration: 0.603s, episode steps: 100, steps per second: 166, episode reward: 60.358, mean reward: 0.604 [0.510, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.067, 10.098], loss: 0.001316, mae: 0.039523, mean_q: 1.162472
 986966/1000000: episode: 9870, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 57.364, mean reward: 0.574 [0.501, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.809, 10.098], loss: 0.001377, mae: 0.040647, mean_q: 1.162999
 987066/1000000: episode: 9871, duration: 0.538s, episode steps: 100, steps per second: 186, episode reward: 56.890, mean reward: 0.569 [0.498, 0.709], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-1.528, 10.098], loss: 0.001244, mae: 0.037998, mean_q: 1.159291
 987166/1000000: episode: 9872, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 56.881, mean reward: 0.569 [0.502, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-0.821, 10.213], loss: 0.001378, mae: 0.040191, mean_q: 1.158807
 987266/1000000: episode: 9873, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 59.266, mean reward: 0.593 [0.504, 0.771], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.087, 10.098], loss: 0.001283, mae: 0.039416, mean_q: 1.157200
 987366/1000000: episode: 9874, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.807, mean reward: 0.588 [0.506, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.583, 10.098], loss: 0.001321, mae: 0.039876, mean_q: 1.161815
 987466/1000000: episode: 9875, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 61.379, mean reward: 0.614 [0.513, 0.786], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.682, 10.361], loss: 0.001346, mae: 0.039846, mean_q: 1.160982
 987566/1000000: episode: 9876, duration: 0.564s, episode steps: 100, steps per second: 177, episode reward: 66.214, mean reward: 0.662 [0.513, 0.880], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-1.161, 10.502], loss: 0.001347, mae: 0.039812, mean_q: 1.160468
 987666/1000000: episode: 9877, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.047, mean reward: 0.570 [0.500, 0.769], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.772, 10.098], loss: 0.001308, mae: 0.039174, mean_q: 1.161579
 987766/1000000: episode: 9878, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.735, mean reward: 0.587 [0.504, 0.860], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.558, 10.292], loss: 0.001315, mae: 0.039303, mean_q: 1.161132
 987866/1000000: episode: 9879, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 58.335, mean reward: 0.583 [0.510, 0.690], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-1.031, 10.320], loss: 0.001369, mae: 0.040266, mean_q: 1.163317
 987966/1000000: episode: 9880, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 58.094, mean reward: 0.581 [0.500, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.749, 10.200], loss: 0.001326, mae: 0.040253, mean_q: 1.162206
 988066/1000000: episode: 9881, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.312, mean reward: 0.603 [0.502, 0.716], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.007, 10.241], loss: 0.001425, mae: 0.041088, mean_q: 1.165376
 988166/1000000: episode: 9882, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 58.648, mean reward: 0.586 [0.502, 0.782], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-2.180, 10.179], loss: 0.001367, mae: 0.040043, mean_q: 1.164353
 988266/1000000: episode: 9883, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 61.675, mean reward: 0.617 [0.502, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.929, 10.098], loss: 0.001479, mae: 0.041987, mean_q: 1.165550
 988366/1000000: episode: 9884, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 56.992, mean reward: 0.570 [0.505, 0.692], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.674, 10.155], loss: 0.001329, mae: 0.039611, mean_q: 1.162806
 988466/1000000: episode: 9885, duration: 0.623s, episode steps: 100, steps per second: 161, episode reward: 60.990, mean reward: 0.610 [0.506, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.320, 10.306], loss: 0.001407, mae: 0.040479, mean_q: 1.164757
 988566/1000000: episode: 9886, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.719, mean reward: 0.577 [0.505, 0.742], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.606, 10.098], loss: 0.001411, mae: 0.041015, mean_q: 1.166597
 988666/1000000: episode: 9887, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: 58.988, mean reward: 0.590 [0.510, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.792, 10.157], loss: 0.001448, mae: 0.041442, mean_q: 1.166539
 988766/1000000: episode: 9888, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 57.849, mean reward: 0.578 [0.510, 0.703], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.871, 10.098], loss: 0.001415, mae: 0.040814, mean_q: 1.165529
 988866/1000000: episode: 9889, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.540, mean reward: 0.585 [0.517, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.775, 10.123], loss: 0.001238, mae: 0.038273, mean_q: 1.165910
 988966/1000000: episode: 9890, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 57.188, mean reward: 0.572 [0.499, 0.693], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-1.196, 10.159], loss: 0.001414, mae: 0.041412, mean_q: 1.165236
 989066/1000000: episode: 9891, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 57.503, mean reward: 0.575 [0.506, 0.746], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.223, 10.142], loss: 0.001392, mae: 0.040700, mean_q: 1.159762
 989166/1000000: episode: 9892, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 59.023, mean reward: 0.590 [0.507, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.583, 10.222], loss: 0.001423, mae: 0.041283, mean_q: 1.168433
 989266/1000000: episode: 9893, duration: 0.601s, episode steps: 100, steps per second: 166, episode reward: 58.914, mean reward: 0.589 [0.506, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.308, 10.125], loss: 0.001446, mae: 0.041751, mean_q: 1.166251
 989366/1000000: episode: 9894, duration: 0.614s, episode steps: 100, steps per second: 163, episode reward: 61.437, mean reward: 0.614 [0.504, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.588, 10.098], loss: 0.001383, mae: 0.040057, mean_q: 1.166686
 989466/1000000: episode: 9895, duration: 0.596s, episode steps: 100, steps per second: 168, episode reward: 58.152, mean reward: 0.582 [0.508, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.654, 10.141], loss: 0.001513, mae: 0.041566, mean_q: 1.163758
 989566/1000000: episode: 9896, duration: 0.608s, episode steps: 100, steps per second: 164, episode reward: 59.146, mean reward: 0.591 [0.500, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.432, 10.109], loss: 0.001435, mae: 0.041322, mean_q: 1.162352
 989666/1000000: episode: 9897, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 58.577, mean reward: 0.586 [0.502, 0.747], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.022, 10.175], loss: 0.001398, mae: 0.040525, mean_q: 1.166126
 989766/1000000: episode: 9898, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 61.043, mean reward: 0.610 [0.511, 0.793], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-0.423, 10.098], loss: 0.001405, mae: 0.040427, mean_q: 1.164387
 989866/1000000: episode: 9899, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.185, mean reward: 0.582 [0.503, 0.691], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-1.013, 10.175], loss: 0.001427, mae: 0.041610, mean_q: 1.163944
 989966/1000000: episode: 9900, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.696, mean reward: 0.597 [0.503, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.840, 10.244], loss: 0.001517, mae: 0.041765, mean_q: 1.162406
 990066/1000000: episode: 9901, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.333, mean reward: 0.593 [0.506, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.916, 10.258], loss: 0.001342, mae: 0.040226, mean_q: 1.162769
 990166/1000000: episode: 9902, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 62.470, mean reward: 0.625 [0.500, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.770, 10.098], loss: 0.001348, mae: 0.040037, mean_q: 1.168063
 990266/1000000: episode: 9903, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 60.486, mean reward: 0.605 [0.514, 0.781], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.460, 10.263], loss: 0.001393, mae: 0.040918, mean_q: 1.167762
 990366/1000000: episode: 9904, duration: 0.545s, episode steps: 100, steps per second: 184, episode reward: 57.903, mean reward: 0.579 [0.507, 0.695], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.788, 10.142], loss: 0.001316, mae: 0.039870, mean_q: 1.168658
 990466/1000000: episode: 9905, duration: 0.552s, episode steps: 100, steps per second: 181, episode reward: 56.834, mean reward: 0.568 [0.500, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.513, 10.189], loss: 0.001382, mae: 0.040392, mean_q: 1.167764
 990566/1000000: episode: 9906, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 59.387, mean reward: 0.594 [0.512, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.419 [-1.539, 10.098], loss: 0.001377, mae: 0.040281, mean_q: 1.168833
 990666/1000000: episode: 9907, duration: 0.544s, episode steps: 100, steps per second: 184, episode reward: 59.940, mean reward: 0.599 [0.507, 0.757], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.595, 10.098], loss: 0.001541, mae: 0.043147, mean_q: 1.170649
 990766/1000000: episode: 9908, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 63.307, mean reward: 0.633 [0.503, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-0.489, 10.098], loss: 0.001405, mae: 0.041117, mean_q: 1.171926
 990866/1000000: episode: 9909, duration: 0.618s, episode steps: 100, steps per second: 162, episode reward: 61.829, mean reward: 0.618 [0.505, 0.851], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.615, 10.308], loss: 0.001524, mae: 0.042351, mean_q: 1.172977
 990966/1000000: episode: 9910, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.237, mean reward: 0.572 [0.514, 0.679], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.854, 10.139], loss: 0.001419, mae: 0.041117, mean_q: 1.173303
 991066/1000000: episode: 9911, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.328, mean reward: 0.583 [0.500, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.326, 10.140], loss: 0.001342, mae: 0.040561, mean_q: 1.172873
 991166/1000000: episode: 9912, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 58.093, mean reward: 0.581 [0.503, 0.677], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.335, 10.098], loss: 0.001424, mae: 0.041121, mean_q: 1.173715
 991266/1000000: episode: 9913, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 59.334, mean reward: 0.593 [0.503, 0.749], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.864, 10.098], loss: 0.001373, mae: 0.040361, mean_q: 1.172400
 991366/1000000: episode: 9914, duration: 0.605s, episode steps: 100, steps per second: 165, episode reward: 61.088, mean reward: 0.611 [0.510, 0.828], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.812, 10.098], loss: 0.001423, mae: 0.041231, mean_q: 1.170849
 991466/1000000: episode: 9915, duration: 0.550s, episode steps: 100, steps per second: 182, episode reward: 57.309, mean reward: 0.573 [0.506, 0.770], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.265, 10.098], loss: 0.001477, mae: 0.041962, mean_q: 1.174280
 991566/1000000: episode: 9916, duration: 0.535s, episode steps: 100, steps per second: 187, episode reward: 60.371, mean reward: 0.604 [0.499, 0.738], mean action: 0.000 [0.000, 0.000], mean observation: 1.420 [-0.569, 10.098], loss: 0.001379, mae: 0.040412, mean_q: 1.174359
 991666/1000000: episode: 9917, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 58.160, mean reward: 0.582 [0.506, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.531, 10.098], loss: 0.001395, mae: 0.040834, mean_q: 1.174396
 991766/1000000: episode: 9918, duration: 0.613s, episode steps: 100, steps per second: 163, episode reward: 57.601, mean reward: 0.576 [0.504, 0.739], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-0.663, 10.272], loss: 0.001396, mae: 0.040995, mean_q: 1.173365
 991866/1000000: episode: 9919, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.388, mean reward: 0.584 [0.500, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.270, 10.098], loss: 0.001345, mae: 0.040516, mean_q: 1.173053
 991966/1000000: episode: 9920, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 59.986, mean reward: 0.600 [0.513, 0.792], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.282, 10.098], loss: 0.001363, mae: 0.040181, mean_q: 1.170169
 992066/1000000: episode: 9921, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 58.081, mean reward: 0.581 [0.506, 0.736], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.324, 10.287], loss: 0.001423, mae: 0.041316, mean_q: 1.169458
 992166/1000000: episode: 9922, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 56.925, mean reward: 0.569 [0.503, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.098, 10.098], loss: 0.001377, mae: 0.040338, mean_q: 1.172955
 992266/1000000: episode: 9923, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.485, mean reward: 0.585 [0.504, 0.774], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.472, 10.301], loss: 0.001370, mae: 0.040551, mean_q: 1.173410
 992366/1000000: episode: 9924, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 57.726, mean reward: 0.577 [0.509, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.259, 10.121], loss: 0.001447, mae: 0.041224, mean_q: 1.170364
 992466/1000000: episode: 9925, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.764, mean reward: 0.588 [0.511, 0.764], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.764, 10.098], loss: 0.001429, mae: 0.040731, mean_q: 1.171380
 992566/1000000: episode: 9926, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 59.894, mean reward: 0.599 [0.502, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.753, 10.210], loss: 0.001375, mae: 0.040483, mean_q: 1.169885
 992666/1000000: episode: 9927, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 59.439, mean reward: 0.594 [0.508, 0.711], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.510, 10.098], loss: 0.001441, mae: 0.042058, mean_q: 1.169757
 992766/1000000: episode: 9928, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 59.568, mean reward: 0.596 [0.503, 0.780], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.183, 10.113], loss: 0.001412, mae: 0.040770, mean_q: 1.166468
 992866/1000000: episode: 9929, duration: 0.624s, episode steps: 100, steps per second: 160, episode reward: 58.851, mean reward: 0.589 [0.509, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.571, 10.348], loss: 0.001433, mae: 0.041092, mean_q: 1.168079
 992966/1000000: episode: 9930, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 56.954, mean reward: 0.570 [0.502, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-0.717, 10.408], loss: 0.001391, mae: 0.040957, mean_q: 1.167883
 993066/1000000: episode: 9931, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.302, mean reward: 0.593 [0.509, 0.728], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.296, 10.098], loss: 0.001303, mae: 0.038866, mean_q: 1.165998
 993166/1000000: episode: 9932, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 59.268, mean reward: 0.593 [0.506, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.116, 10.098], loss: 0.001410, mae: 0.040962, mean_q: 1.164930
 993266/1000000: episode: 9933, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 59.336, mean reward: 0.593 [0.502, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-1.165, 10.102], loss: 0.001464, mae: 0.041630, mean_q: 1.167873
 993366/1000000: episode: 9934, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 60.549, mean reward: 0.605 [0.509, 0.755], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.944, 10.382], loss: 0.001488, mae: 0.042008, mean_q: 1.168873
 993466/1000000: episode: 9935, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 57.818, mean reward: 0.578 [0.501, 0.723], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-1.143, 10.164], loss: 0.001500, mae: 0.041905, mean_q: 1.168917
 993566/1000000: episode: 9936, duration: 0.590s, episode steps: 100, steps per second: 169, episode reward: 56.482, mean reward: 0.565 [0.503, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.089, 10.098], loss: 0.001377, mae: 0.040559, mean_q: 1.166541
 993666/1000000: episode: 9937, duration: 0.565s, episode steps: 100, steps per second: 177, episode reward: 58.213, mean reward: 0.582 [0.501, 0.768], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.765, 10.164], loss: 0.001442, mae: 0.041613, mean_q: 1.164382
 993766/1000000: episode: 9938, duration: 0.587s, episode steps: 100, steps per second: 170, episode reward: 61.712, mean reward: 0.617 [0.523, 0.752], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.311, 10.333], loss: 0.001410, mae: 0.040851, mean_q: 1.167743
 993866/1000000: episode: 9939, duration: 0.554s, episode steps: 100, steps per second: 181, episode reward: 60.389, mean reward: 0.604 [0.523, 0.881], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.391, 10.098], loss: 0.001567, mae: 0.043057, mean_q: 1.169355
 993966/1000000: episode: 9940, duration: 0.549s, episode steps: 100, steps per second: 182, episode reward: 60.563, mean reward: 0.606 [0.507, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.628, 10.098], loss: 0.001424, mae: 0.041257, mean_q: 1.169845
 994066/1000000: episode: 9941, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.480, mean reward: 0.595 [0.503, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.213, 10.144], loss: 0.001448, mae: 0.041385, mean_q: 1.168559
 994166/1000000: episode: 9942, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 59.866, mean reward: 0.599 [0.510, 0.754], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-1.175, 10.102], loss: 0.001568, mae: 0.042546, mean_q: 1.173848
 994266/1000000: episode: 9943, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 58.886, mean reward: 0.589 [0.501, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.503, 10.214], loss: 0.001484, mae: 0.041660, mean_q: 1.170467
 994366/1000000: episode: 9944, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 61.234, mean reward: 0.612 [0.514, 0.788], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.662, 10.098], loss: 0.001496, mae: 0.041803, mean_q: 1.175224
 994466/1000000: episode: 9945, duration: 0.569s, episode steps: 100, steps per second: 176, episode reward: 61.767, mean reward: 0.618 [0.511, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.435 [-0.903, 10.232], loss: 0.001434, mae: 0.040776, mean_q: 1.169793
 994566/1000000: episode: 9946, duration: 0.557s, episode steps: 100, steps per second: 179, episode reward: 60.325, mean reward: 0.603 [0.504, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.304, 10.098], loss: 0.001503, mae: 0.042103, mean_q: 1.173025
 994666/1000000: episode: 9947, duration: 0.615s, episode steps: 100, steps per second: 163, episode reward: 59.141, mean reward: 0.591 [0.512, 0.775], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.087, 10.098], loss: 0.001546, mae: 0.042451, mean_q: 1.171383
 994766/1000000: episode: 9948, duration: 0.579s, episode steps: 100, steps per second: 173, episode reward: 57.075, mean reward: 0.571 [0.501, 0.682], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.415, 10.150], loss: 0.001470, mae: 0.041684, mean_q: 1.174451
 994866/1000000: episode: 9949, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.123, mean reward: 0.581 [0.515, 0.684], mean action: 0.000 [0.000, 0.000], mean observation: 1.433 [-0.891, 10.194], loss: 0.001413, mae: 0.040686, mean_q: 1.173036
 994966/1000000: episode: 9950, duration: 0.580s, episode steps: 100, steps per second: 172, episode reward: 58.301, mean reward: 0.583 [0.500, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.782, 10.183], loss: 0.001432, mae: 0.041213, mean_q: 1.172613
 995066/1000000: episode: 9951, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.888, mean reward: 0.589 [0.504, 0.825], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-1.023, 10.098], loss: 0.001495, mae: 0.041934, mean_q: 1.173714
 995166/1000000: episode: 9952, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 56.875, mean reward: 0.569 [0.508, 0.685], mean action: 0.000 [0.000, 0.000], mean observation: 1.437 [-1.207, 10.207], loss: 0.001490, mae: 0.041858, mean_q: 1.173190
 995266/1000000: episode: 9953, duration: 0.624s, episode steps: 100, steps per second: 160, episode reward: 58.209, mean reward: 0.582 [0.505, 0.708], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.858, 10.098], loss: 0.001501, mae: 0.042136, mean_q: 1.172730
 995366/1000000: episode: 9954, duration: 0.607s, episode steps: 100, steps per second: 165, episode reward: 58.743, mean reward: 0.587 [0.499, 0.734], mean action: 0.000 [0.000, 0.000], mean observation: 1.443 [-0.980, 10.285], loss: 0.001497, mae: 0.041428, mean_q: 1.166108
 995466/1000000: episode: 9955, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 57.370, mean reward: 0.574 [0.504, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.436 [-0.509, 10.363], loss: 0.001423, mae: 0.040660, mean_q: 1.169795
 995566/1000000: episode: 9956, duration: 0.572s, episode steps: 100, steps per second: 175, episode reward: 57.898, mean reward: 0.579 [0.503, 0.689], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.882, 10.098], loss: 0.001525, mae: 0.042144, mean_q: 1.170568
 995666/1000000: episode: 9957, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 64.339, mean reward: 0.643 [0.504, 0.831], mean action: 0.000 [0.000, 0.000], mean observation: 1.412 [-0.672, 10.098], loss: 0.001584, mae: 0.043281, mean_q: 1.172497
 995766/1000000: episode: 9958, duration: 0.558s, episode steps: 100, steps per second: 179, episode reward: 59.602, mean reward: 0.596 [0.503, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.839, 10.098], loss: 0.001446, mae: 0.041406, mean_q: 1.169227
 995866/1000000: episode: 9959, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 59.058, mean reward: 0.591 [0.517, 0.720], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.582, 10.285], loss: 0.001475, mae: 0.041549, mean_q: 1.166374
 995966/1000000: episode: 9960, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.274, mean reward: 0.583 [0.502, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.646, 10.098], loss: 0.001441, mae: 0.041280, mean_q: 1.167620
 996066/1000000: episode: 9961, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 58.308, mean reward: 0.583 [0.506, 0.750], mean action: 0.000 [0.000, 0.000], mean observation: 1.429 [-0.514, 10.098], loss: 0.001512, mae: 0.041672, mean_q: 1.165344
 996166/1000000: episode: 9962, duration: 0.616s, episode steps: 100, steps per second: 162, episode reward: 61.508, mean reward: 0.615 [0.514, 0.762], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.825, 10.098], loss: 0.001558, mae: 0.042397, mean_q: 1.168172
 996266/1000000: episode: 9963, duration: 0.571s, episode steps: 100, steps per second: 175, episode reward: 58.831, mean reward: 0.588 [0.499, 0.753], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.999, 10.098], loss: 0.001483, mae: 0.041214, mean_q: 1.169066
 996366/1000000: episode: 9964, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 60.128, mean reward: 0.601 [0.501, 0.767], mean action: 0.000 [0.000, 0.000], mean observation: 1.434 [-0.485, 10.360], loss: 0.001514, mae: 0.041709, mean_q: 1.167013
 996466/1000000: episode: 9965, duration: 0.599s, episode steps: 100, steps per second: 167, episode reward: 59.624, mean reward: 0.596 [0.521, 0.837], mean action: 0.000 [0.000, 0.000], mean observation: 1.421 [-1.208, 10.098], loss: 0.001476, mae: 0.042114, mean_q: 1.169265
 996566/1000000: episode: 9966, duration: 0.591s, episode steps: 100, steps per second: 169, episode reward: 59.507, mean reward: 0.595 [0.507, 0.731], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.893, 10.098], loss: 0.001512, mae: 0.042172, mean_q: 1.170562
 996666/1000000: episode: 9967, duration: 0.609s, episode steps: 100, steps per second: 164, episode reward: 59.967, mean reward: 0.600 [0.502, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.382, 10.098], loss: 0.001455, mae: 0.041336, mean_q: 1.167909
 996766/1000000: episode: 9968, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 64.040, mean reward: 0.640 [0.511, 0.799], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.858, 10.098], loss: 0.001464, mae: 0.041181, mean_q: 1.170775
 996866/1000000: episode: 9969, duration: 0.594s, episode steps: 100, steps per second: 168, episode reward: 57.273, mean reward: 0.573 [0.501, 0.744], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.486, 10.230], loss: 0.001555, mae: 0.042005, mean_q: 1.172046
 996966/1000000: episode: 9970, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 62.082, mean reward: 0.621 [0.506, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-0.272, 10.098], loss: 0.001461, mae: 0.041803, mean_q: 1.171933
 997066/1000000: episode: 9971, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.843, mean reward: 0.588 [0.505, 0.795], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.693, 10.098], loss: 0.001432, mae: 0.040803, mean_q: 1.173091
 997166/1000000: episode: 9972, duration: 0.559s, episode steps: 100, steps per second: 179, episode reward: 56.857, mean reward: 0.569 [0.499, 0.718], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.840, 10.154], loss: 0.001526, mae: 0.042344, mean_q: 1.171784
 997266/1000000: episode: 9973, duration: 0.570s, episode steps: 100, steps per second: 175, episode reward: 58.786, mean reward: 0.588 [0.501, 0.779], mean action: 0.000 [0.000, 0.000], mean observation: 1.424 [-1.008, 10.098], loss: 0.001519, mae: 0.041897, mean_q: 1.175177
 997366/1000000: episode: 9974, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.286, mean reward: 0.583 [0.505, 0.712], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.043, 10.098], loss: 0.001472, mae: 0.041861, mean_q: 1.176654
 997466/1000000: episode: 9975, duration: 0.578s, episode steps: 100, steps per second: 173, episode reward: 58.661, mean reward: 0.587 [0.509, 0.726], mean action: 0.000 [0.000, 0.000], mean observation: 1.439 [-0.271, 10.209], loss: 0.001500, mae: 0.042116, mean_q: 1.174742
 997566/1000000: episode: 9976, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 58.143, mean reward: 0.581 [0.515, 0.699], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.006, 10.098], loss: 0.001584, mae: 0.042917, mean_q: 1.172587
 997666/1000000: episode: 9977, duration: 0.555s, episode steps: 100, steps per second: 180, episode reward: 59.198, mean reward: 0.592 [0.507, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.440 [-0.598, 10.363], loss: 0.001470, mae: 0.041557, mean_q: 1.169761
 997766/1000000: episode: 9978, duration: 0.573s, episode steps: 100, steps per second: 174, episode reward: 58.811, mean reward: 0.588 [0.513, 0.826], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-1.787, 10.203], loss: 0.001530, mae: 0.042338, mean_q: 1.171437
 997866/1000000: episode: 9979, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 60.447, mean reward: 0.604 [0.504, 0.835], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.524, 10.449], loss: 0.001483, mae: 0.042000, mean_q: 1.173405
 997966/1000000: episode: 9980, duration: 0.588s, episode steps: 100, steps per second: 170, episode reward: 57.933, mean reward: 0.579 [0.508, 0.737], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.589, 10.322], loss: 0.001496, mae: 0.041896, mean_q: 1.175053
 998066/1000000: episode: 9981, duration: 0.586s, episode steps: 100, steps per second: 171, episode reward: 58.500, mean reward: 0.585 [0.498, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.432 [-0.925, 10.114], loss: 0.001514, mae: 0.042290, mean_q: 1.174576
 998166/1000000: episode: 9982, duration: 0.574s, episode steps: 100, steps per second: 174, episode reward: 61.187, mean reward: 0.612 [0.516, 0.735], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-0.342, 10.098], loss: 0.001596, mae: 0.042986, mean_q: 1.173792
 998266/1000000: episode: 9983, duration: 0.581s, episode steps: 100, steps per second: 172, episode reward: 57.534, mean reward: 0.575 [0.504, 0.719], mean action: 0.000 [0.000, 0.000], mean observation: 1.431 [-0.718, 10.098], loss: 0.001503, mae: 0.041997, mean_q: 1.174053
 998366/1000000: episode: 9984, duration: 0.567s, episode steps: 100, steps per second: 176, episode reward: 62.230, mean reward: 0.622 [0.500, 0.758], mean action: 0.000 [0.000, 0.000], mean observation: 1.418 [-1.650, 10.098], loss: 0.001492, mae: 0.041779, mean_q: 1.173367
 998466/1000000: episode: 9985, duration: 0.553s, episode steps: 100, steps per second: 181, episode reward: 60.559, mean reward: 0.606 [0.506, 0.805], mean action: 0.000 [0.000, 0.000], mean observation: 1.441 [-0.822, 10.380], loss: 0.001481, mae: 0.041690, mean_q: 1.171283
 998566/1000000: episode: 9986, duration: 0.546s, episode steps: 100, steps per second: 183, episode reward: 58.127, mean reward: 0.581 [0.504, 0.751], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.531, 10.098], loss: 0.001570, mae: 0.042290, mean_q: 1.174860
 998666/1000000: episode: 9987, duration: 0.577s, episode steps: 100, steps per second: 173, episode reward: 58.920, mean reward: 0.589 [0.509, 0.821], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-1.165, 10.233], loss: 0.001527, mae: 0.042141, mean_q: 1.176871
 998766/1000000: episode: 9988, duration: 0.585s, episode steps: 100, steps per second: 171, episode reward: 57.114, mean reward: 0.571 [0.503, 0.733], mean action: 0.000 [0.000, 0.000], mean observation: 1.423 [-0.845, 10.139], loss: 0.001484, mae: 0.041379, mean_q: 1.173217
 998866/1000000: episode: 9989, duration: 0.584s, episode steps: 100, steps per second: 171, episode reward: 58.577, mean reward: 0.586 [0.503, 0.717], mean action: 0.000 [0.000, 0.000], mean observation: 1.427 [-0.866, 10.175], loss: 0.001561, mae: 0.042685, mean_q: 1.171937
 998966/1000000: episode: 9990, duration: 0.598s, episode steps: 100, steps per second: 167, episode reward: 59.291, mean reward: 0.593 [0.502, 0.848], mean action: 0.000 [0.000, 0.000], mean observation: 1.425 [-0.893, 10.158], loss: 0.001452, mae: 0.041120, mean_q: 1.172894
 999066/1000000: episode: 9991, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 55.977, mean reward: 0.560 [0.499, 0.784], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.306, 10.151], loss: 0.001535, mae: 0.041998, mean_q: 1.173408
 999166/1000000: episode: 9992, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 59.238, mean reward: 0.592 [0.498, 0.802], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.754, 10.098], loss: 0.001567, mae: 0.042934, mean_q: 1.172873
 999266/1000000: episode: 9993, duration: 0.561s, episode steps: 100, steps per second: 178, episode reward: 58.538, mean reward: 0.585 [0.510, 0.705], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.833, 10.202], loss: 0.001554, mae: 0.042641, mean_q: 1.171089
 999366/1000000: episode: 9994, duration: 0.563s, episode steps: 100, steps per second: 178, episode reward: 59.095, mean reward: 0.591 [0.507, 0.741], mean action: 0.000 [0.000, 0.000], mean observation: 1.428 [-0.428, 10.098], loss: 0.001525, mae: 0.041895, mean_q: 1.170118
 999466/1000000: episode: 9995, duration: 0.592s, episode steps: 100, steps per second: 169, episode reward: 58.329, mean reward: 0.583 [0.521, 0.698], mean action: 0.000 [0.000, 0.000], mean observation: 1.417 [-0.800, 10.098], loss: 0.001443, mae: 0.041638, mean_q: 1.170051
 999566/1000000: episode: 9996, duration: 0.570s, episode steps: 100, steps per second: 176, episode reward: 61.454, mean reward: 0.615 [0.510, 0.806], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-1.583, 10.531], loss: 0.001459, mae: 0.040621, mean_q: 1.169421
 999666/1000000: episode: 9997, duration: 0.562s, episode steps: 100, steps per second: 178, episode reward: 59.831, mean reward: 0.598 [0.514, 0.760], mean action: 0.000 [0.000, 0.000], mean observation: 1.426 [-0.970, 10.098], loss: 0.001519, mae: 0.042045, mean_q: 1.170602
 999766/1000000: episode: 9998, duration: 0.583s, episode steps: 100, steps per second: 171, episode reward: 62.908, mean reward: 0.629 [0.513, 0.773], mean action: 0.000 [0.000, 0.000], mean observation: 1.422 [-1.253, 10.162], loss: 0.001574, mae: 0.042812, mean_q: 1.172015
 999866/1000000: episode: 9999, duration: 0.566s, episode steps: 100, steps per second: 177, episode reward: 60.360, mean reward: 0.604 [0.508, 0.816], mean action: 0.000 [0.000, 0.000], mean observation: 1.430 [-0.771, 10.098], loss: 0.001543, mae: 0.042856, mean_q: 1.171749
 999966/1000000: episode: 10000, duration: 0.582s, episode steps: 100, steps per second: 172, episode reward: 57.638, mean reward: 0.576 [0.506, 0.722], mean action: 0.000 [0.000, 0.000], mean observation: 1.438 [-1.489, 10.103], loss: 0.001558, mae: 0.042677, mean_q: 1.175375
done, took 5694.376 seconds
[Info] End Uniform Random Simulation. Falsification occurred 0 times.
